--- 
title: "Introduction to Bayesian Econometrics: A GUIded tour"
author: "Andrés Ramírez-Hassan"
date: "`r Sys.Date()`"
output: pdf_document
#description: This is a minimal example of using the bookdown package to write a book.
#  The output format for this example is bookdown::gitbook.
documentclass: book
link-citations: yes
bibliography:
- book.bib
- packages.bib
site: bookdown::bookdown_site
biblio-style: apalike
---

# Description

Introduction to Bayesian econometrics: A GUIded tour is aimed at those who want to apply Bayesian regression analysis having good theory understanding, but not having time to develop programming skills. This book provides a graphical user interface (GUI) to carry out Bayesian regression in a very friendly environment.

This book is designed for teaching and applied purposes at an introductory level; we present the basic theory underlying all regression models that we developed in our GUI. We also show how to implement these models using R software, carry out some applications to highlight the potential of Bayesian regression, and have theory and computational exercises.

```{r include=FALSE}
# automatically create a bib database for R packages
knitr::write_bib(c(
  .packages(), 'bookdown', 'knitr', 'rmarkdown'
), 'packages.bib')
```

<!--chapter:end:index.Rmd-->

# Introduction {#intro}

This chapter will have important concepts in Bayesian inference, a brief guide about the rest of the book, and how to download and install our graphical user interface (GUI).

<!--chapter:end:01-intro.Rmd-->

# Basic formal concepts

We will introduce formal concepts in Bayesian inference starting with the Bayes’ rule, all its components with their formal definitions and basic examples. In addition, we will introduce the basics of Bayesian inference based on decision theory under uncertainty, and introduce other  important concepts like utility function, loss function, risk function, optimal rules, etc.

<!--chapter:end:02-literature.Rmd-->

# Conceptual differences between Bayesian and Frequentist statistical approaches

We will give a historical and philosophical perspective about Bayesian statistics and econometrics highlighting differences compared with the frequentist approach.

<!--chapter:end:03-method.Rmd-->

# Objective and subjective Bayesian approaches

The Bayesian approach can be broadly classified in two schools: objective and subjective. We will describe their main characteristics, explaining their differences, and how to implement them. We put particular attention to elicitation techniques, that is, how to transform expert knowledge into prior probabilistic statements. 

<!--chapter:end:04-application.Rmd-->

# Basic statistical models: Conjugate families

We will introduce conjugate families in basic statistical models with examples, solving them analytically and computationally using R. We will have some mathematical, and computational exercises in R.

<!--chapter:end:05-summary.Rmd-->

`r if (knitr::is_html_output()) '
# References {-}
'`

<!--chapter:end:06-references.Rmd-->

# Simulation methods {#sim}

Simulation methods are very important in modern Bayesian inference. We will introduce Importance sampling, Gibbs and Metropolis-Hastings, as well as how to calculate the marginal likelihood, which most of the times does not have analytical solution. We also will have examples showing how solve them in R, as well as mathematical and computational exercises in R.

<!--chapter:end:07-simulation.Rmd-->

# Univariate regression {#unireg}

We will describe how to perform Bayesian inference in univariate models: normal-inverse gamma, logit, probit, multinomial probit and logit, ordered probit, negative binomial, tobit, quantile regression, and Bayesian bootstrap in linear models. We show their formal framework, some applications, and how to perform inference using our GUI as well as R. We will also have mathematical and computational exercises in our GUI and in R.

<!--chapter:end:08-univariatereg.Rmd-->

# Multivariate regression {#multi}

We will show the formal framework of simple multivariate regression, seemingly unrelated regression, instrumental variables and multivariate probit. We perform some applications using our GUI and R. We will have mathematical and computational exercises in our GUI and in R. 

<!--chapter:end:09-multivariatereg.Rmd-->

# Time series {#time}

We will show the state-space representation of time series models with their theory foundation, and perform applications using R and our GUI. We will have mathematical and computational exercises in our GUI and in R.

<!--chapter:end:10-timeseries.Rmd-->

# Longitudinal regression {#Longi}

We will describe the theory framework of Bayesian longitudinal models. Particularly, the normal, logit, and poisson models. We will perform some applications using our GUI and R. There will be mathematical and computational exercises using our GUI and R.

<!--chapter:end:11-longitudinal.Rmd-->

# Bayesian model averaging {#bma}

We will show how to perform Bayesian model averaging. There are two issue to handle here: models space and the marginal likelihood. The former will be tackled using Markov chain Monte Carlo model composition, Occam’s window and stochastic search variable selection. The latter can be overcome using analytical solutions or Laplace approximation. We will show the theory underlying these approaches, how to perform BMA using our GUI and R for linear models: exogenous and endogenous, and non-linear models: logit, gamma and poisson. We will have also mathematical and computational exercises in R and our GUI.

<!--chapter:end:12-bma.Rmd-->

# Convergence diagnostics {#diag}

We will show convergence diagnostics, graphical such as trace plots and autocorrelation plots, and statistical tests by Geweke, Raftery and Lewis, and Heidelberger and Welch. We will describe them, and how to use their results with applications in our GUI and R.

<!--chapter:end:13-diagnostics.Rmd-->

# Nonparametric regression {#nonpara}

We present Dirichlet process and Gaussian process.

<!--chapter:end:14-nonparametric.Rmd-->

# Recent developments {#recent}

We will describe recent methodological developments such as variational Bayes (VB) and approximate Bayesian computation (ABC), and computational algorithms such as sequential Monte Carlo, Hamiltonian Monte Carlo and population Monte Carlo.

<!--chapter:end:15-recent.Rmd-->

