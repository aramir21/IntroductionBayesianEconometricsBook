<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>6.1 Normal model | Introduction to Bayesian Econometrics</title>
  <meta name="description" content="The subject of this textbook is Bayesian regression analysis, and its main aim is to provide introductory level theory foundation, and facilitate applicability of Bayesian inference." />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="6.1 Normal model | Introduction to Bayesian Econometrics" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="The subject of this textbook is Bayesian regression analysis, and its main aim is to provide introductory level theory foundation, and facilitate applicability of Bayesian inference." />
  <meta name="github-repo" content="https://github.com/aramir21/IntroductionBayesianEconometricsBook" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="6.1 Normal model | Introduction to Bayesian Econometrics" />
  
  <meta name="twitter:description" content="The subject of this textbook is Bayesian regression analysis, and its main aim is to provide introductory level theory foundation, and facilitate applicability of Bayesian inference." />
  

<meta name="author" content="Andrés Ramírez-Hassan" />


<meta name="date" content="2021-05-23" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="unireg.html"/>
<link rel="next" href="logit-model.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Introduction to Bayesian Econometrics: A GUIded tour</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction</a><ul>
<li class="chapter" data-level="" data-path="to-instructors-and-students.html"><a href="to-instructors-and-students.html"><i class="fa fa-check"></i>To instructors and students</a></li>
<li class="chapter" data-level="" data-path="a-brief-presentation-of-r-software.html"><a href="a-brief-presentation-of-r-software.html"><i class="fa fa-check"></i>A brief presentation of R software</a></li>
<li class="chapter" data-level="" data-path="acknowledgments.html"><a href="acknowledgments.html"><i class="fa fa-check"></i>Acknowledgments</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="basics.html"><a href="basics.html"><i class="fa fa-check"></i><b>1</b> Basic formal concepts</a><ul>
<li class="chapter" data-level="1.1" data-path="sec11.html"><a href="sec11.html"><i class="fa fa-check"></i><b>1.1</b> The Bayes’ rule</a></li>
<li class="chapter" data-level="1.2" data-path="sec12.html"><a href="sec12.html"><i class="fa fa-check"></i><b>1.2</b> Bayesian framework: A brief summary of theory</a></li>
<li class="chapter" data-level="1.3" data-path="sec13.html"><a href="sec13.html"><i class="fa fa-check"></i><b>1.3</b> Bayesian reports: Decision theory under uncertainty</a></li>
<li class="chapter" data-level="1.4" data-path="summary-chapter-1.html"><a href="summary-chapter-1.html"><i class="fa fa-check"></i><b>1.4</b> Summary: Chapter 1</a></li>
<li class="chapter" data-level="1.5" data-path="exercises-chapter-1.html"><a href="exercises-chapter-1.html"><i class="fa fa-check"></i><b>1.5</b> Exercises: Chapter 1</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="bayfre.html"><a href="bayfre.html"><i class="fa fa-check"></i><b>2</b> Conceptual differences between the Bayesian and the Frequentist statistical approaches</a><ul>
<li class="chapter" data-level="2.1" data-path="sec21.html"><a href="sec21.html"><i class="fa fa-check"></i><b>2.1</b> The concept of probability</a></li>
<li class="chapter" data-level="2.2" data-path="sec22.html"><a href="sec22.html"><i class="fa fa-check"></i><b>2.2</b> Subjectivity is not the key</a></li>
<li class="chapter" data-level="2.3" data-path="sec23.html"><a href="sec23.html"><i class="fa fa-check"></i><b>2.3</b> Estimation, hypothesis testing and prediction</a></li>
<li class="chapter" data-level="2.4" data-path="sec24.html"><a href="sec24.html"><i class="fa fa-check"></i><b>2.4</b> The likelihood principle</a></li>
<li class="chapter" data-level="2.5" data-path="sec25.html"><a href="sec25.html"><i class="fa fa-check"></i><b>2.5</b> Logic of argumentation</a></li>
<li class="chapter" data-level="2.6" data-path="sec25A.html"><a href="sec25A.html"><i class="fa fa-check"></i><b>2.6</b> Why is not the Bayesian approach that popular?</a></li>
<li class="chapter" data-level="2.7" data-path="sec26.html"><a href="sec26.html"><i class="fa fa-check"></i><b>2.7</b> A simple working example</a></li>
<li class="chapter" data-level="2.8" data-path="sec27.html"><a href="sec27.html"><i class="fa fa-check"></i><b>2.8</b> Summary: Chapter 2</a></li>
<li class="chapter" data-level="2.9" data-path="exercises-chapter-2.html"><a href="exercises-chapter-2.html"><i class="fa fa-check"></i><b>2.9</b> Exercises: Chapter 2</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="objsub.html"><a href="objsub.html"><i class="fa fa-check"></i><b>3</b> Objective and subjective Bayesian approaches</a><ul>
<li class="chapter" data-level="3.1" data-path="sec31.html"><a href="sec31.html"><i class="fa fa-check"></i><b>3.1</b> Objective Bayesian priors</a><ul>
<li class="chapter" data-level="3.1.1" data-path="sec31.html"><a href="sec31.html#empirical-bayes"><i class="fa fa-check"></i><b>3.1.1</b> Empirical Bayes</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="sec32.html"><a href="sec32.html"><i class="fa fa-check"></i><b>3.2</b> Subjective Bayesian priors</a><ul>
<li class="chapter" data-level="3.2.1" data-path="sec32.html"><a href="sec32.html#human-heuristics"><i class="fa fa-check"></i><b>3.2.1</b> Human heuristics</a></li>
<li class="chapter" data-level="3.2.2" data-path="sec32.html"><a href="sec32.html#elicitation"><i class="fa fa-check"></i><b>3.2.2</b> Elicitation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="conjfam.html"><a href="conjfam.html"><i class="fa fa-check"></i><b>4</b> Basic statistical models: Conjugate families</a><ul>
<li class="chapter" data-level="4.1" data-path="sec41.html"><a href="sec41.html"><i class="fa fa-check"></i><b>4.1</b> Motivation of conjugate families</a></li>
<li class="chapter" data-level="4.2" data-path="sec42.html"><a href="sec42.html"><i class="fa fa-check"></i><b>4.2</b> Conjugate prior to exponential family</a></li>
<li class="chapter" data-level="4.3" data-path="linear-regression-the-conjugate-normal-normalinverse-gamma-model.html"><a href="linear-regression-the-conjugate-normal-normalinverse-gamma-model.html"><i class="fa fa-check"></i><b>4.3</b> Linear regression: The conjugate normal-normal/inverse gamma model</a></li>
<li class="chapter" data-level="4.4" data-path="multivariate-linear-regression-the-conjugate-normal-normalinverse-wishart-model.html"><a href="multivariate-linear-regression-the-conjugate-normal-normalinverse-wishart-model.html"><i class="fa fa-check"></i><b>4.4</b> Multivariate linear regression: The conjugate normal-normal/inverse Wishart model</a></li>
<li class="chapter" data-level="4.5" data-path="computational-examples.html"><a href="computational-examples.html"><i class="fa fa-check"></i><b>4.5</b> Computational examples</a></li>
<li class="chapter" data-level="4.6" data-path="summary-chapter-4.html"><a href="summary-chapter-4.html"><i class="fa fa-check"></i><b>4.6</b> Summary: Chapter 4</a></li>
<li class="chapter" data-level="4.7" data-path="exercises-chapter-4.html"><a href="exercises-chapter-4.html"><i class="fa fa-check"></i><b>4.7</b> Exercises: Chapter 4</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="sim.html"><a href="sim.html"><i class="fa fa-check"></i><b>5</b> Simulation methods</a></li>
<li class="chapter" data-level="6" data-path="unireg.html"><a href="unireg.html"><i class="fa fa-check"></i><b>6</b> Univariate regression</a><ul>
<li class="chapter" data-level="6.1" data-path="normal-model.html"><a href="normal-model.html"><i class="fa fa-check"></i><b>6.1</b> Normal model</a></li>
<li class="chapter" data-level="6.2" data-path="logit-model.html"><a href="logit-model.html"><i class="fa fa-check"></i><b>6.2</b> Logit model</a></li>
<li class="chapter" data-level="6.3" data-path="probit-model.html"><a href="probit-model.html"><i class="fa fa-check"></i><b>6.3</b> Probit model</a></li>
<li class="chapter" data-level="6.4" data-path="summary-chapter-6.html"><a href="summary-chapter-6.html"><i class="fa fa-check"></i><b>6.4</b> Summary: Chapter 6</a></li>
<li class="chapter" data-level="6.5" data-path="exercises-chapter-6.html"><a href="exercises-chapter-6.html"><i class="fa fa-check"></i><b>6.5</b> Exercises: Chapter 6</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="multi.html"><a href="multi.html"><i class="fa fa-check"></i><b>7</b> Multivariate regression</a></li>
<li class="chapter" data-level="8" data-path="time.html"><a href="time.html"><i class="fa fa-check"></i><b>8</b> Time series</a></li>
<li class="chapter" data-level="9" data-path="longi.html"><a href="longi.html"><i class="fa fa-check"></i><b>9</b> Longitudinal regression</a></li>
<li class="chapter" data-level="10" data-path="diag.html"><a href="diag.html"><i class="fa fa-check"></i><b>10</b> Convergence diagnostics</a></li>
<li class="chapter" data-level="11" data-path="bma.html"><a href="bma.html"><i class="fa fa-check"></i><b>11</b> Bayesian model averaging in variable selection</a></li>
<li class="chapter" data-level="12" data-path="nonpara.html"><a href="nonpara.html"><i class="fa fa-check"></i><b>12</b> Nonparametric regression</a></li>
<li class="chapter" data-level="13" data-path="recent.html"><a href="recent.html"><i class="fa fa-check"></i><b>13</b> Recent developments</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i>Appendix</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to Bayesian Econometrics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="normal-model" class="section level2">
<h2><span class="header-section-number">6.1</span> Normal model</h2>
<p>The Gaussian linear model specifies <span class="math inline">\({\bf{y}}={\bf{X}}\beta+\bf{\mu}\)</span> such that <span class="math inline">\(\bf{\mu}\sim N(\bf{0},\sigma^2\bf{I}_N)\)</span> is an stochastic error, <span class="math inline">\({\bf{X}}\)</span> is a <span class="math inline">\(N \times K\)</span> matrix of regressors, <span class="math inline">\(\beta\)</span> is a <span class="math inline">\(K\)</span>-dimensional vector of coefficients, <span class="math inline">\({\bf{y}}\)</span> is an <span class="math inline">\(N\)</span>-dimensional vector of a dependent variable, and <span class="math inline">\(N\)</span> is the number of units.</p>
<p>The conjugate independent priors for the parameters are
<span class="math inline">\(\beta \sim N(\beta_0, {\bf{B}}_0)\)</span> and
<span class="math inline">\(\sigma^2 \sim IG(\alpha_0/2, \delta_0/2)\)</span>. Given the likelihood function, <span class="math inline">\(p(\beta, \sigma^2|{\bf{y}}, {\bf{X}}) = (2\pi\sigma^2)^{-\frac{N}{2}} \exp \left\{-\frac{1}{2\sigma^2} ({\bf{y}} - \bf{X\beta})^{\top}({\bf{y}} - \bf{X\beta}) \right\}\)</span>, the conditional posterior distributions are</p>
<p><span class="math display">\[\begin{align}
\beta|\sigma^2, {\bf{y}}, {\bf{X}} \sim N(\beta_n, \sigma^2{\bf{B}}_n),
\end{align}\]</span>
and
<span class="math display">\[\begin{align}
\sigma^2|\beta, {\bf{y}}, {\bf{X}} \sim IG(\alpha_n/2, \delta_n/2),
\end{align}\]</span></p>
<p>where <span class="math inline">\({\bf{B}}_n = ({\bf{B}}_0^{-1} + \sigma^{-2} {\bf{X}}^{\top}{\bf{X}})^{-1}\)</span>, <span class="math inline">\(\beta_n= {\bf{B}}_n({\bf{B}}_0^{-1}\beta_0 + \sigma^{-2} {\bf{X}}^{\top}{\bf{y}})\)</span>, <span class="math inline">\(\alpha_n = \alpha_0 + N\)</span> and <span class="math inline">\(\delta_n = \delta_0 + ({\bf{y}}-{\bf{X}}\beta)^{\top}({\bf{y}}-{\bf{X}}\beta)\)</span>.</p>
<p>We can employ the Gibbs sampler in this model due to having standard conditional posterior distributions.</p>
<p><strong>Application: The market value of soccer players in Europe</strong></p>
<p>Let’s analyze the determinants of the market value of soccer players. In particular, we use the dataset <em>1ValueFootballPlayers.csv</em> which is in folder <em>DataApp</em> (see Table <a href="appendix.html#tab:tabDataApp">13.3</a> for details) in our github repository <a href="https://github.com/besmarter/BSTApp">(https://github.com/besmarter/BSTApp)</a>. This dataset was used by <span class="citation">(Serna Rodríguez, Ramírez Hassan, and Coad <a href="#ref-Serna2018" role="doc-biblioref">2019</a>)</span> to finding the determinants of high performance soccer players in the five most important national leagues in Europe.</p>
<p>The specification of the model is</p>
<p><span class="math display">\[\begin{align}
\log(\text{Value}_i)&amp;=\beta_1+\beta_2\text{Perf}_i+\beta_3\text{Perf}^2_i+\beta_4\text{Age}_i+\beta_5\text{Age}^2_i+\beta_6\text{NatTeam}_i+\beta_7\text{Goals}_i\\
&amp;+\beta_8\text{Goals}^2_i+\beta_9\text{Exp}_i+\beta_{10}\text{Exp}^2_i+\beta_{11}\text{Assists}_i,
\end{align}\]</span></p>
<p>where <em>Value</em> is the market value in Euros (2017), <em>Perf</em> is a measure of performance, <em>Age</em> is the players’ age in years, <em>NatTem</em> is an indicator variable that takes the value of 1 if the player has been on the national team, <em>Goals</em> is the number of goals scored by the player during his career, <em>Exp</em> is his experience in years, and <em>Assists</em> is the number of assist made by the player in the 2015–2016 season.</p>
<p>We assume that the dependent variable distributes normal, then we use a normal-inverse gamma model using vague conjugate priors where <span class="math inline">\({\bf{B}}_0=1000{\bf{I}}_{10}\)</span>, <span class="math inline">\(\beta_0={\bf{0}}_{10}\)</span>, <span class="math inline">\(\alpha_0=0.001\)</span> and <span class="math inline">\(\delta_0=0.001\)</span>. We perform a Gibbs sampler with 10,000 MCMC iterations plus a burn-in equal to 5,000, and a thinning parameter equal to 1.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="normal-model.html#cb1-1"></a><span class="kw">set.seed</span>(<span class="dv">010101</span>) <span class="co"># Set a seed for replicability of results</span></span>
<span id="cb1-2"><a href="normal-model.html#cb1-2"></a><span class="co"># Download data from github</span></span>
<span id="cb1-3"><a href="normal-model.html#cb1-3"></a><span class="co"># urlfile &lt;- &#39;https://raw.githubusercontent.com/besmarter/BSTApp/master/DataApp/1ValueFootballPlayers.csv&#39;</span></span>
<span id="cb1-4"><a href="normal-model.html#cb1-4"></a><span class="co"># mydata &lt;- read.csv(urlfile)</span></span>
<span id="cb1-5"><a href="normal-model.html#cb1-5"></a>mydata &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&quot;DataApplications/1ValueFootballPlayers.csv&quot;</span>, <span class="dt">header =</span> T, <span class="dt">sep =</span> <span class="st">&quot;,&quot;</span>)</span>
<span id="cb1-6"><a href="normal-model.html#cb1-6"></a><span class="kw">attach</span>(mydata)</span>
<span id="cb1-7"><a href="normal-model.html#cb1-7"></a><span class="kw">str</span>(mydata)</span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    335 obs. of  13 variables:
##  $ Player   : Factor w/ 335 levels &quot;Aaron Cresswell&quot;,..: 194 13 72 254 162 211 76 287 165 316 ...
##  $ Value    : int  22000000 7500000 18000000 15000000 18000000 25000000 40000000 30000000 55000000 9000000 ...
##  $ ValueCens: int  22000000 7500000 18000000 15000000 18000000 25000000 40000000 30000000 55000000 9000000 ...
##  $ Perf     : int  7 9 33 6 34 25 31 12 35 29 ...
##  $ Perf2    : int  49 81 1089 36 1156 625 961 144 1225 841 ...
##  $ Age      : int  24 27 23 24 30 22 31 26 25 29 ...
##  $ Age2     : int  576 729 529 576 900 484 961 676 625 841 ...
##  $ NatTeam  : int  1 1 1 1 1 1 1 1 1 0 ...
##  $ Goals    : int  0 27 27 34 0 18 26 8 28 43 ...
##  $ Goals2   : int  0 729 729 1156 0 324 676 64 784 1849 ...
##  $ Exp      : num  10.01 16.01 7.01 8.01 12.01 ...
##  $ Exp2     : num  100.2 256.4 49.1 64.1 144.2 ...
##  $ Assists  : int  0 0 4 1 0 0 1 0 5 7 ...</code></pre>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="normal-model.html#cb3-1"></a>y &lt;-<span class="st"> </span><span class="kw">log</span>(Value) <span class="co"># Dependent variable</span></span>
<span id="cb3-2"><a href="normal-model.html#cb3-2"></a>X &lt;-<span class="st"> </span><span class="kw">cbind</span>(<span class="dv">1</span>,<span class="kw">as.matrix</span>(mydata[, <span class="dv">4</span><span class="op">:</span><span class="dv">13</span>])) <span class="co"># Regressors</span></span>
<span id="cb3-3"><a href="normal-model.html#cb3-3"></a>N &lt;-<span class="st"> </span><span class="kw">dim</span>(X)[<span class="dv">1</span>] <span class="co"># Sample size</span></span>
<span id="cb3-4"><a href="normal-model.html#cb3-4"></a>K &lt;-<span class="st"> </span><span class="kw">dim</span>(X)[<span class="dv">2</span>] <span class="co"># Number of regressors including a constant</span></span>
<span id="cb3-5"><a href="normal-model.html#cb3-5"></a></span>
<span id="cb3-6"><a href="normal-model.html#cb3-6"></a><span class="co"># Hyperparameters</span></span>
<span id="cb3-7"><a href="normal-model.html#cb3-7"></a>B0 &lt;-<span class="st"> </span><span class="dv">1000</span><span class="op">*</span><span class="kw">diag</span>(K) <span class="co"># Prior covariance matrix Normal distribution</span></span>
<span id="cb3-8"><a href="normal-model.html#cb3-8"></a>B0i &lt;-<span class="st"> </span><span class="kw">solve</span>(B0) <span class="co"># Prior precision matrix Normal distribution </span></span>
<span id="cb3-9"><a href="normal-model.html#cb3-9"></a>b0 &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>,K) <span class="co"># Prior mean Normal distribution</span></span>
<span id="cb3-10"><a href="normal-model.html#cb3-10"></a>a0 &lt;-<span class="st"> </span><span class="fl">0.001</span> <span class="co"># Prior shape parameter inverse-gamma distribution</span></span>
<span id="cb3-11"><a href="normal-model.html#cb3-11"></a>d0 &lt;-<span class="st"> </span><span class="fl">0.001</span> <span class="co"># Prior rate parameter inverse-gamma distribution </span></span>
<span id="cb3-12"><a href="normal-model.html#cb3-12"></a></span>
<span id="cb3-13"><a href="normal-model.html#cb3-13"></a><span class="co"># MCMC parameters</span></span>
<span id="cb3-14"><a href="normal-model.html#cb3-14"></a>it &lt;-<span class="st"> </span><span class="dv">10000</span> <span class="co"># Iterations after burn-in</span></span>
<span id="cb3-15"><a href="normal-model.html#cb3-15"></a>burn &lt;-<span class="st"> </span><span class="dv">5000</span> <span class="co"># Burn-in</span></span>
<span id="cb3-16"><a href="normal-model.html#cb3-16"></a>tot &lt;-<span class="st"> </span>burn <span class="op">+</span><span class="st"> </span>it <span class="co"># Total iterations</span></span>
<span id="cb3-17"><a href="normal-model.html#cb3-17"></a></span>
<span id="cb3-18"><a href="normal-model.html#cb3-18"></a><span class="co">###### 1. Programming the Gibbs sampler #######</span></span>
<span id="cb3-19"><a href="normal-model.html#cb3-19"></a><span class="co"># Space and initial setting</span></span>
<span id="cb3-20"><a href="normal-model.html#cb3-20"></a>betaGibbs &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dv">0</span>,tot,K) <span class="co"># Space for posterior beta</span></span>
<span id="cb3-21"><a href="normal-model.html#cb3-21"></a>varGibbs &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dv">1</span>,tot,<span class="dv">1</span>) <span class="co"># Space for posterior sigma^2</span></span>
<span id="cb3-22"><a href="normal-model.html#cb3-22"></a>sigma2_<span class="dv">0</span> &lt;-<span class="st"> </span><span class="dv">2</span> <span class="co"># Initial sigma^2</span></span>
<span id="cb3-23"><a href="normal-model.html#cb3-23"></a>Bn &lt;-<span class="st"> </span><span class="kw">solve</span>(B0i<span class="op">+</span>sigma2_<span class="dv">0</span><span class="op">^</span>{<span class="op">-</span><span class="dv">1</span>}<span class="op">*</span><span class="kw">t</span>(X)<span class="op">%*%</span>X) <span class="co"># Initial covariance matrix beta</span></span>
<span id="cb3-24"><a href="normal-model.html#cb3-24"></a>bn &lt;-<span class="st"> </span>Bn<span class="op">%*%</span>(B0i<span class="op">%*%</span>b0<span class="op">+</span>sigma2_<span class="dv">0</span><span class="op">^</span>{<span class="op">-</span><span class="dv">1</span>}<span class="op">*</span><span class="kw">t</span>(X)<span class="op">%*%</span>y) <span class="co"># Initial mean beta</span></span>
<span id="cb3-25"><a href="normal-model.html#cb3-25"></a>an &lt;-<span class="st"> </span>a0<span class="op">+</span>N <span class="co"># Posterior alpha</span></span>
<span id="cb3-26"><a href="normal-model.html#cb3-26"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>tot){</span>
<span id="cb3-27"><a href="normal-model.html#cb3-27"></a>  BetaG &lt;-<span class="st"> </span>MASS<span class="op">::</span><span class="kw">mvrnorm</span>(<span class="dv">1</span>, <span class="dt">mu=</span>bn, <span class="dt">Sigma=</span>Bn) <span class="co"># Draw of posterior beta</span></span>
<span id="cb3-28"><a href="normal-model.html#cb3-28"></a>  dn &lt;-<span class="st"> </span>d0<span class="op">+</span><span class="kw">t</span>(y<span class="op">-</span>X<span class="op">%*%</span>BetaG)<span class="op">%*%</span>(y<span class="op">-</span>X<span class="op">%*%</span>BetaG) <span class="co"># Posterior delta</span></span>
<span id="cb3-29"><a href="normal-model.html#cb3-29"></a>  sigma2 &lt;-<span class="st"> </span>pscl<span class="op">::</span><span class="kw">rigamma</span>(<span class="dv">1</span>,an<span class="op">/</span><span class="dv">2</span>,dn<span class="op">/</span><span class="dv">2</span>) <span class="co"># Draw of posterior variance</span></span>
<span id="cb3-30"><a href="normal-model.html#cb3-30"></a>  Bn &lt;-<span class="st"> </span><span class="kw">solve</span>(B0i<span class="op">+</span>sigma2<span class="op">^</span>{<span class="op">-</span><span class="dv">1</span>}<span class="op">*</span><span class="kw">t</span>(X)<span class="op">%*%</span>X) <span class="co"># Posterior covariance beta</span></span>
<span id="cb3-31"><a href="normal-model.html#cb3-31"></a>  bn &lt;-<span class="st"> </span>Bn<span class="op">%*%</span>(B0i<span class="op">%*%</span>b0<span class="op">+</span>sigma2<span class="op">^</span>{<span class="op">-</span><span class="dv">1</span>}<span class="op">*</span><span class="kw">t</span>(X)<span class="op">%*%</span>y) <span class="co"># Posterior mean beta</span></span>
<span id="cb3-32"><a href="normal-model.html#cb3-32"></a>  betaGibbs[i,] &lt;-<span class="st"> </span>BetaG</span>
<span id="cb3-33"><a href="normal-model.html#cb3-33"></a>  varGibbs[i,] &lt;-<span class="st"> </span>sigma2</span>
<span id="cb3-34"><a href="normal-model.html#cb3-34"></a>}</span>
<span id="cb3-35"><a href="normal-model.html#cb3-35"></a><span class="co"># Draws after burn-in</span></span>
<span id="cb3-36"><a href="normal-model.html#cb3-36"></a>PostPar &lt;-<span class="st"> </span>coda<span class="op">::</span><span class="kw">mcmc</span>(<span class="kw">cbind</span>(betaGibbs[burn<span class="op">:</span>it,], varGibbs[burn<span class="op">:</span>it,]))</span>
<span id="cb3-37"><a href="normal-model.html#cb3-37"></a><span class="co"># Names</span></span>
<span id="cb3-38"><a href="normal-model.html#cb3-38"></a><span class="kw">colnames</span>(PostPar) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Cte&quot;</span>, <span class="kw">names</span>(mydata)[<span class="op">-</span><span class="kw">c</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>)], <span class="st">&quot;Variance&quot;</span>)</span>
<span id="cb3-39"><a href="normal-model.html#cb3-39"></a><span class="co"># Summary posterior draws</span></span>
<span id="cb3-40"><a href="normal-model.html#cb3-40"></a><span class="kw">summary</span>(PostPar) </span></code></pre></div>
<pre><code>## 
## Iterations = 1:5001
## Thinning interval = 1 
## Number of chains = 1 
## Sample size per chain = 5001 
## 
## 1. Empirical mean and standard deviation for each variable,
##    plus standard error of the mean:
## 
##                Mean        SD  Naive SE Time-series SE
## Cte       3.719e+00 2.202e+00 3.114e-02      3.188e-02
## Perf      2.798e-02 1.650e-02 2.333e-04      2.333e-04
## Perf2     1.604e-04 4.977e-04 7.038e-06      7.206e-06
## Age       7.744e-01 1.794e-01 2.536e-03      2.593e-03
## Age2     -1.646e-02 3.348e-03 4.734e-05      4.845e-05
## NatTeam   8.492e-01 1.178e-01 1.666e-03      1.704e-03
## Goals     1.169e-02 3.503e-03 4.953e-05      4.953e-05
## Goals2   -2.408e-05 1.874e-05 2.649e-07      2.649e-07
## Exp       2.011e-01 6.277e-02 8.876e-04      8.876e-04
## Exp2     -6.878e-03 2.713e-03 3.837e-05      3.837e-05
## Assists   2.012e-02 2.425e-02 3.430e-04      3.430e-04
## Variance  9.745e-01 7.619e-02 1.077e-03      1.112e-03
## 
## 2. Quantiles for each variable:
## 
##                2.5%        25%        50%        75%      97.5%
## Cte      -6.444e-01  2.243e+00  3.7431200  5.170e+00  7.978e+00
## Perf     -4.207e-03  1.661e-02  0.0281211  3.902e-02  6.023e-02
## Perf2    -8.097e-04 -1.724e-04  0.0001627  4.935e-04  1.124e-03
## Age       4.227e-01  6.544e-01  0.7723884  8.947e-01  1.131e+00
## Age2     -2.297e-02 -1.871e-02 -0.0163819 -1.419e-02 -9.984e-03
## NatTeam   6.217e-01  7.699e-01  0.8492834  9.300e-01  1.081e+00
## Goals     4.769e-03  9.315e-03  0.0116816  1.406e-02  1.857e-02
## Goals2   -6.188e-05 -3.643e-05 -0.0000240 -1.157e-05  1.272e-05
## Exp       8.013e-02  1.586e-01  0.1997035  2.441e-01  3.249e-01
## Exp2     -1.224e-02 -8.727e-03 -0.0068425 -5.056e-03 -1.714e-03
## Assists  -2.716e-02  3.785e-03  0.0202098  3.698e-02  6.760e-02
## Variance  8.347e-01  9.219e-01  0.9701447  1.026e+00  1.132e+00</code></pre>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="normal-model.html#cb5-1"></a><span class="co"># Trace and density plots</span></span>
<span id="cb5-2"><a href="normal-model.html#cb5-2"></a><span class="kw">plot</span>(PostPar)</span></code></pre></div>
<p><img src="BayesianEconometrics_files/figure-html/unnamed-chunk-1-1..svg" width="672" /><img src="BayesianEconometrics_files/figure-html/unnamed-chunk-1-2..svg" width="672" /><img src="BayesianEconometrics_files/figure-html/unnamed-chunk-1-3..svg" width="672" /><img src="BayesianEconometrics_files/figure-html/unnamed-chunk-1-4..svg" width="672" /></p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="normal-model.html#cb6-1"></a><span class="co"># Autocorrelation plots</span></span>
<span id="cb6-2"><a href="normal-model.html#cb6-2"></a>coda<span class="op">::</span><span class="kw">autocorr.plot</span>(PostPar)</span></code></pre></div>
<p><img src="BayesianEconometrics_files/figure-html/unnamed-chunk-1-5..svg" width="672" /><img src="BayesianEconometrics_files/figure-html/unnamed-chunk-1-6..svg" width="672" /></p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="normal-model.html#cb7-1"></a><span class="co"># Convergence diagnostics</span></span>
<span id="cb7-2"><a href="normal-model.html#cb7-2"></a>coda<span class="op">::</span><span class="kw">geweke.diag</span>(PostPar)</span></code></pre></div>
<pre><code>## 
## Fraction in 1st window = 0.1
## Fraction in 2nd window = 0.5 
## 
##      Cte     Perf    Perf2      Age     Age2  NatTeam    Goals   Goals2 
## -0.79112  1.45439 -1.50703  0.46945 -0.24099 -0.07577 -0.68005  0.51859 
##      Exp     Exp2  Assists Variance 
##  0.67734 -0.99537 -0.10185  0.78761</code></pre>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="normal-model.html#cb9-1"></a>coda<span class="op">::</span><span class="kw">raftery.diag</span>(PostPar,<span class="dt">q=</span><span class="fl">0.5</span>,<span class="dt">r=</span><span class="fl">0.025</span>,<span class="dt">s =</span> <span class="fl">0.95</span>)</span></code></pre></div>
<pre><code>## 
## Quantile (q) = 0.5
## Accuracy (r) = +/- 0.025
## Probability (s) = 0.95 
##                                                 
##           Burn-in  Total Lower bound  Dependence
##           (M)      (N)   (Nmin)       factor (I)
##  Cte      2        1574  1537         1.020     
##  Perf     2        1478  1537         0.962     
##  Perf2    2        1570  1537         1.020     
##  Age      1        1541  1537         1.000     
##  Age2     2        1560  1537         1.010     
##  NatTeam  2        1588  1537         1.030     
##  Goals    2        1590  1537         1.030     
##  Goals2   1        1538  1537         1.000     
##  Exp      2        1555  1537         1.010     
##  Exp2     1        1542  1537         1.000     
##  Assists  2        1583  1537         1.030     
##  Variance 2        1589  1537         1.030</code></pre>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="normal-model.html#cb11-1"></a>coda<span class="op">::</span><span class="kw">heidel.diag</span>(PostPar)</span></code></pre></div>
<pre><code>##                                        
##          Stationarity start     p-value
##          test         iteration        
## Cte      passed         1       0.7888 
## Perf     failed        NA       0.0174 
## Perf2    passed       502       0.0584 
## Age      passed         1       0.6905 
## Age2     passed         1       0.6479 
## NatTeam  passed         1       0.9541 
## Goals    passed         1       0.3700 
## Goals2   passed         1       0.6803 
## Exp      passed         1       0.2319 
## Exp2     passed         1       0.1838 
## Assists  passed         1       0.2814 
## Variance passed         1       0.7429 
##                                       
##          Halfwidth Mean      Halfwidth
##          test                         
## Cte      passed     3.72e+00 6.25e-02 
## Perf     &lt;NA&gt;             NA       NA 
## Perf2    passed     1.63e-04 1.49e-05 
## Age      passed     7.74e-01 5.08e-03 
## Age2     passed    -1.65e-02 9.50e-05 
## NatTeam  passed     8.49e-01 3.34e-03 
## Goals    passed     1.17e-02 9.71e-05 
## Goals2   passed    -2.41e-05 5.19e-07 
## Exp      passed     2.01e-01 1.74e-03 
## Exp2     passed    -6.88e-03 7.52e-05 
## Assists  passed     2.01e-02 6.72e-04 
## Variance passed     9.75e-01 2.18e-03</code></pre>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="normal-model.html#cb13-1"></a><span class="co">###### 2. Using a library: MCMCpack #######</span></span>
<span id="cb13-2"><a href="normal-model.html#cb13-2"></a>Reg &lt;-<span class="st"> </span>MCMCpack<span class="op">::</span><span class="kw">MCMCregress</span>(y<span class="op">~</span>X<span class="dv">-1</span>, <span class="dt">burnin =</span> burn, <span class="dt">mcmc =</span> it, <span class="dt">b0 =</span> b0, <span class="dt">B0 =</span> B0i, <span class="dt">c0 =</span> a0, <span class="dt">d0 =</span> d0)</span>
<span id="cb13-3"><a href="normal-model.html#cb13-3"></a><span class="kw">summary</span>(Reg)</span></code></pre></div>
<pre><code>## 
## Iterations = 5001:15000
## Thinning interval = 1 
## Number of chains = 1 
## Sample size per chain = 10000 
## 
## 1. Empirical mean and standard deviation for each variable,
##    plus standard error of the mean:
## 
##                Mean        SD  Naive SE Time-series SE
## X         3.711e+00 2.230e+00 2.230e-02      2.230e-02
## XPerf     2.784e-02 1.643e-02 1.643e-04      1.643e-04
## XPerf2    1.629e-04 4.938e-04 4.938e-06      4.938e-06
## XAge      7.754e-01 1.816e-01 1.816e-03      1.816e-03
## XAge2    -1.648e-02 3.383e-03 3.383e-05      3.383e-05
## XNatTeam  8.500e-01 1.181e-01 1.181e-03      1.201e-03
## XGoals    1.175e-02 3.468e-03 3.468e-05      3.468e-05
## XGoals2  -2.447e-05 1.865e-05 1.865e-07      1.865e-07
## XExp      2.005e-01 6.295e-02 6.295e-04      6.295e-04
## XExp2    -6.830e-03 2.726e-03 2.726e-05      2.726e-05
## XAssists  2.015e-02 2.468e-02 2.468e-04      2.468e-04
## sigma2    9.739e-01 7.696e-02 7.696e-04      7.967e-04
## 
## 2. Quantiles for each variable:
## 
##                2.5%        25%        50%        75%      97.5%
## X        -6.129e-01  2.178e+00  3.692e+00  5.207e+00  8.100e+00
## XPerf    -4.408e-03  1.660e-02  2.793e-02  3.887e-02  6.027e-02
## XPerf2   -8.052e-04 -1.739e-04  1.604e-04  4.941e-04  1.133e-03
## XAge      4.167e-01  6.533e-01  7.756e-01  9.001e-01  1.125e+00
## XAge2    -2.301e-02 -1.882e-02 -1.649e-02 -1.419e-02 -9.842e-03
## XNatTeam  6.136e-01  7.718e-01  8.502e-01  9.299e-01  1.082e+00
## XGoals    4.959e-03  9.401e-03  1.174e-02  1.411e-02  1.859e-02
## XGoals2  -6.116e-05 -3.724e-05 -2.418e-05 -1.179e-05  1.182e-05
## XExp      7.644e-02  1.580e-01  1.996e-01  2.435e-01  3.234e-01
## XExp2    -1.228e-02 -8.685e-03 -6.820e-03 -4.986e-03 -1.469e-03
## XAssists -2.828e-02  3.625e-03  2.019e-02  3.677e-02  6.964e-02
## sigma2    8.316e-01  9.201e-01  9.703e-01  1.023e+00  1.134e+00</code></pre>
<p>When using our GUI (third approach), the first step is to type <strong>shiny::runGitHub(“besmarter/BSTApp” , launch.browser=T)</strong> in the R package console or any R code editor to run our GUI,<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a> and then select <em>Univariate Models</em> on the top panel. The radio button on the left hand side shows the specific models inside this generic class. Users should select <em>Normal</em> model (see Figure <a href="normal-model.html#fig:Fig1">6.1</a>).</p>

<div class="figure" style="text-align: center"><span id="fig:Fig1"></span>
<img src="images/Figure1.png" alt="Univariate models: Normal/normal-inverse gamma model." width="80%" />
<p class="caption">
Figure 6.1: Univariate models: Normal/normal-inverse gamma model.
</p>
</div>
<p>The right hand side panel displays a widget to upload the input dataset, which should be a csv file with headers in the first row. Users also should select the kind of separator used in the input file: comma, semicolon, or tab (use the folders <em>DataSim</em> and <em>DataApp</em> for the input file templates). Once users upload the dataset, they can see a data preview. Range sliders help to set the number of iterations of the MCMC and the amount of burn-in, and the thinning parameter can be selected as well. After this, users should specify the equation. This can be done with the formula builder, where users can select the dependent variable, and the independent variables, and then click on the “Build formula” tab. Users can see in the “Main Equation” space the formula expressed in the format used by R. See Main equation box in Figure <a href="normal-model.html#fig:Fig2">6.2</a>, observe that in this case the depedent variable is <span class="math inline">\(\log\text{Value}\)</span> rather than <span class="math inline">\(\text{Value}\)</span>, then we should modify directly the Main equation box writing <span class="math inline">\(log(Value)\)</span>. In general, users can modify this box if necessary, for instance, including higher order or interaction terms, other transformation are also allowed. This is done directly in the “Main Equation” space taking into account that this extra terms should follow formula command structure (see <a href="https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/formula" class="uri">https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/formula</a>). Note that the class of univariate models includes the intercept by default, except ordered probit, where the specification has to do this explicitly, that is, ordered probit models do not admit an intercept for identification issues (see below). Finally, users should define the hyperparameters of the prior; for instance, in the normal-inverse gamma model, these are the mean, covariance, shape, and scale (see Figure <a href="normal-model.html#fig:Fig2">6.2</a>). However, users should take into account that our GUI has "non-informative’’ hyperparameters by default in all our modelling frameworks, so the last part is not a requirement.</p>

<div class="figure" style="text-align: center"><span id="fig:Fig2"></span>
<img src="images/Figure2.png" alt="Normal/normal-inverse gamma model: Formula builder and hyperparameters." width="80%" />
<p class="caption">
Figure 6.2: Normal/normal-inverse gamma model: Formula builder and hyperparameters.
</p>
</div>
<p>After this specification process, users should click the <em>Go!</em> button to initiate the estimation. Our GUI displays the summary statistics and convergence diagnostics after this process is finished (see Figure <a href="normal-model.html#fig:Fig3">6.3</a>). There are also widgets to download posterior chains (csv file) and graphs (pdf and eps files). Note that the order of the coefficients in the results (summary, posterior chains, and graphs) is first for the location parameters, and then for the scale parameters.</p>

<div class="figure" style="text-align: center"><span id="fig:Fig3"></span>
<img src="images/Figure3.png" alt="Normal/normal-inverse gamma model: Results." width="80%" />
<p class="caption">
Figure 6.3: Normal/normal-inverse gamma model: Results.
</p>
</div>
<p>As expected, the results using the three approach (programming, library and GUI) are very similar. These suggest that age, squared age, national team, goals, experience, and squared experience are relevant regressors. For instance, we found that the 2.5% and 97.5% percentiles of the posterior estimate associated with the variable Goals are 4.57e-03 and 1.82e-02. These values can be used to find the 95% symmetric credible interval. This means that there is a 0.95 probability that the population parameter lies in (4.57e-03, 1.82e-02), which would suggest that this variable is relevant to explain the market value of a soccer player.<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a> We also found that the effect of having been on the national team has a 95% credible interval equal to (0.58, 1.04) with a median equal to 0.81, that is, an increase of the market value of the player of 124.8% (<span class="math inline">\(\exp(0.81)-1\)</span>) compared with a player that has not ever been on a national team. The posterior distribution of this variable can be seen in Figure <a href="normal-model.html#fig:Fig10">6.4</a>. This graph is automatically generated by the GUI, and can be downloaded in the zip file named <em>Posterior Graphs.csv</em>; but we should take into account that the national team is the sixth variable, remember that by default the intercept is the first variable.</p>

<div class="figure" style="text-align: center"><span id="fig:Fig10"></span>
<img src="images/Fig1.png" alt="Posterior distribution: National team." width="50%" />
<p class="caption">
Figure 6.4: Posterior distribution: National team.
</p>
</div>
<p>We show all the posterior densities as well as the trace and correlation plots to visualize convergence of the posterior chains. Trace plots look stable, and autocorrelation plots decrease very quickly. In addition, convergence statistics (Geweke’s <span class="citation">(Geweke <a href="#ref-Geweke1992" role="doc-biblioref">1992</a>)</span>, Raftery and Lewis <span class="citation">(Raftery and Lewis <a href="#ref-Raftery1992" role="doc-biblioref">1992</a>)</span>, and Heidelberger and Welch’s tests <span class="citation">(Heidelberger and Welch <a href="#ref-Heidelberger1983" role="doc-biblioref">1983</a>)</span>) suggest that the posterior draws come from stationary distributions (see Chapter <a href="diag.html#diag">10</a> for technical details).</p>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-Geweke1992">
<p>Geweke, J. 1992. “Bayesian Statistics.” In. Clarendon Press, Oxford, UK.</p>
</div>
<div id="ref-Heidelberger1983">
<p>Heidelberger, P., and P. D. Welch. 1983. “Simulation Run Length Control in the Presence of an Initial Transient.” <em>Operations Research</em> 31 (6): 1109–44.</p>
</div>
<div id="ref-Raftery1992">
<p>Raftery, A. E., and S. M. Lewis. 1992. “One Long Run with Diagnostics: Implementation Strategies for Markov Chain Monte Carlo.” <em>Statistical Science</em> 7: 493–97.</p>
</div>
<div id="ref-Serna2018">
<p>Serna Rodríguez, M., A. Ramírez Hassan, and A. Coad. 2019. “Uncovering Value Drivers of High Performance Soccer Players.” <em>Journal of Sport Economics</em> 20 (6): 819–49.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p>I strongly recommend to type the code line rather than copy and paste it.<a href="normal-model.html#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p>Users should take into account that formal inference (hypothesis tests) in a Bayesian framework is based on Bayes factors.<a href="normal-model.html#fnref2" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="unireg.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="logit-model.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/aramir21/IntroductionBayesianEconometricsBook/06-Univariatereg.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
