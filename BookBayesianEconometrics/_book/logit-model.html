<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>6.2 Logit model | Introduction to Bayesian Econometrics</title>
  <meta name="description" content="The subject of this textbook is Bayesian regression analysis, and its main aim is to provide introductory level theory foundation, and facilitate applicability of Bayesian inference." />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="6.2 Logit model | Introduction to Bayesian Econometrics" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="The subject of this textbook is Bayesian regression analysis, and its main aim is to provide introductory level theory foundation, and facilitate applicability of Bayesian inference." />
  <meta name="github-repo" content="https://github.com/aramir21/IntroductionBayesianEconometricsBook" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="6.2 Logit model | Introduction to Bayesian Econometrics" />
  
  <meta name="twitter:description" content="The subject of this textbook is Bayesian regression analysis, and its main aim is to provide introductory level theory foundation, and facilitate applicability of Bayesian inference." />
  

<meta name="author" content="Andrés Ramírez-Hassan" />


<meta name="date" content="2021-05-23" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="normal-model.html"/>
<link rel="next" href="probit-model.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Introduction to Bayesian Econometrics: A GUIded tour</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction</a><ul>
<li class="chapter" data-level="" data-path="to-instructors-and-students.html"><a href="to-instructors-and-students.html"><i class="fa fa-check"></i>To instructors and students</a></li>
<li class="chapter" data-level="" data-path="a-brief-presentation-of-r-software.html"><a href="a-brief-presentation-of-r-software.html"><i class="fa fa-check"></i>A brief presentation of R software</a></li>
<li class="chapter" data-level="" data-path="acknowledgments.html"><a href="acknowledgments.html"><i class="fa fa-check"></i>Acknowledgments</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="basics.html"><a href="basics.html"><i class="fa fa-check"></i><b>1</b> Basic formal concepts</a><ul>
<li class="chapter" data-level="1.1" data-path="sec11.html"><a href="sec11.html"><i class="fa fa-check"></i><b>1.1</b> The Bayes’ rule</a></li>
<li class="chapter" data-level="1.2" data-path="sec12.html"><a href="sec12.html"><i class="fa fa-check"></i><b>1.2</b> Bayesian framework: A brief summary of theory</a></li>
<li class="chapter" data-level="1.3" data-path="sec13.html"><a href="sec13.html"><i class="fa fa-check"></i><b>1.3</b> Bayesian reports: Decision theory under uncertainty</a></li>
<li class="chapter" data-level="1.4" data-path="summary-chapter-1.html"><a href="summary-chapter-1.html"><i class="fa fa-check"></i><b>1.4</b> Summary: Chapter 1</a></li>
<li class="chapter" data-level="1.5" data-path="exercises-chapter-1.html"><a href="exercises-chapter-1.html"><i class="fa fa-check"></i><b>1.5</b> Exercises: Chapter 1</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="bayfre.html"><a href="bayfre.html"><i class="fa fa-check"></i><b>2</b> Conceptual differences between the Bayesian and the Frequentist statistical approaches</a><ul>
<li class="chapter" data-level="2.1" data-path="sec21.html"><a href="sec21.html"><i class="fa fa-check"></i><b>2.1</b> The concept of probability</a></li>
<li class="chapter" data-level="2.2" data-path="sec22.html"><a href="sec22.html"><i class="fa fa-check"></i><b>2.2</b> Subjectivity is not the key</a></li>
<li class="chapter" data-level="2.3" data-path="sec23.html"><a href="sec23.html"><i class="fa fa-check"></i><b>2.3</b> Estimation, hypothesis testing and prediction</a></li>
<li class="chapter" data-level="2.4" data-path="sec24.html"><a href="sec24.html"><i class="fa fa-check"></i><b>2.4</b> The likelihood principle</a></li>
<li class="chapter" data-level="2.5" data-path="sec25.html"><a href="sec25.html"><i class="fa fa-check"></i><b>2.5</b> Logic of argumentation</a></li>
<li class="chapter" data-level="2.6" data-path="sec25A.html"><a href="sec25A.html"><i class="fa fa-check"></i><b>2.6</b> Why is not the Bayesian approach that popular?</a></li>
<li class="chapter" data-level="2.7" data-path="sec26.html"><a href="sec26.html"><i class="fa fa-check"></i><b>2.7</b> A simple working example</a></li>
<li class="chapter" data-level="2.8" data-path="sec27.html"><a href="sec27.html"><i class="fa fa-check"></i><b>2.8</b> Summary: Chapter 2</a></li>
<li class="chapter" data-level="2.9" data-path="exercises-chapter-2.html"><a href="exercises-chapter-2.html"><i class="fa fa-check"></i><b>2.9</b> Exercises: Chapter 2</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="objsub.html"><a href="objsub.html"><i class="fa fa-check"></i><b>3</b> Objective and subjective Bayesian approaches</a><ul>
<li class="chapter" data-level="3.1" data-path="sec31.html"><a href="sec31.html"><i class="fa fa-check"></i><b>3.1</b> Objective Bayesian priors</a><ul>
<li class="chapter" data-level="3.1.1" data-path="sec31.html"><a href="sec31.html#empirical-bayes"><i class="fa fa-check"></i><b>3.1.1</b> Empirical Bayes</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="sec32.html"><a href="sec32.html"><i class="fa fa-check"></i><b>3.2</b> Subjective Bayesian priors</a><ul>
<li class="chapter" data-level="3.2.1" data-path="sec32.html"><a href="sec32.html#human-heuristics"><i class="fa fa-check"></i><b>3.2.1</b> Human heuristics</a></li>
<li class="chapter" data-level="3.2.2" data-path="sec32.html"><a href="sec32.html#elicitation"><i class="fa fa-check"></i><b>3.2.2</b> Elicitation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="conjfam.html"><a href="conjfam.html"><i class="fa fa-check"></i><b>4</b> Basic statistical models: Conjugate families</a><ul>
<li class="chapter" data-level="4.1" data-path="sec41.html"><a href="sec41.html"><i class="fa fa-check"></i><b>4.1</b> Motivation of conjugate families</a></li>
<li class="chapter" data-level="4.2" data-path="sec42.html"><a href="sec42.html"><i class="fa fa-check"></i><b>4.2</b> Conjugate prior to exponential family</a></li>
<li class="chapter" data-level="4.3" data-path="linear-regression-the-conjugate-normal-normalinverse-gamma-model.html"><a href="linear-regression-the-conjugate-normal-normalinverse-gamma-model.html"><i class="fa fa-check"></i><b>4.3</b> Linear regression: The conjugate normal-normal/inverse gamma model</a></li>
<li class="chapter" data-level="4.4" data-path="multivariate-linear-regression-the-conjugate-normal-normalinverse-wishart-model.html"><a href="multivariate-linear-regression-the-conjugate-normal-normalinverse-wishart-model.html"><i class="fa fa-check"></i><b>4.4</b> Multivariate linear regression: The conjugate normal-normal/inverse Wishart model</a></li>
<li class="chapter" data-level="4.5" data-path="computational-examples.html"><a href="computational-examples.html"><i class="fa fa-check"></i><b>4.5</b> Computational examples</a></li>
<li class="chapter" data-level="4.6" data-path="summary-chapter-4.html"><a href="summary-chapter-4.html"><i class="fa fa-check"></i><b>4.6</b> Summary: Chapter 4</a></li>
<li class="chapter" data-level="4.7" data-path="exercises-chapter-4.html"><a href="exercises-chapter-4.html"><i class="fa fa-check"></i><b>4.7</b> Exercises: Chapter 4</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="sim.html"><a href="sim.html"><i class="fa fa-check"></i><b>5</b> Simulation methods</a></li>
<li class="chapter" data-level="6" data-path="unireg.html"><a href="unireg.html"><i class="fa fa-check"></i><b>6</b> Univariate regression</a><ul>
<li class="chapter" data-level="6.1" data-path="normal-model.html"><a href="normal-model.html"><i class="fa fa-check"></i><b>6.1</b> Normal model</a></li>
<li class="chapter" data-level="6.2" data-path="logit-model.html"><a href="logit-model.html"><i class="fa fa-check"></i><b>6.2</b> Logit model</a></li>
<li class="chapter" data-level="6.3" data-path="probit-model.html"><a href="probit-model.html"><i class="fa fa-check"></i><b>6.3</b> Probit model</a></li>
<li class="chapter" data-level="6.4" data-path="summary-chapter-6.html"><a href="summary-chapter-6.html"><i class="fa fa-check"></i><b>6.4</b> Summary: Chapter 6</a></li>
<li class="chapter" data-level="6.5" data-path="exercises-chapter-6.html"><a href="exercises-chapter-6.html"><i class="fa fa-check"></i><b>6.5</b> Exercises: Chapter 6</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="multi.html"><a href="multi.html"><i class="fa fa-check"></i><b>7</b> Multivariate regression</a></li>
<li class="chapter" data-level="8" data-path="time.html"><a href="time.html"><i class="fa fa-check"></i><b>8</b> Time series</a></li>
<li class="chapter" data-level="9" data-path="longi.html"><a href="longi.html"><i class="fa fa-check"></i><b>9</b> Longitudinal regression</a></li>
<li class="chapter" data-level="10" data-path="diag.html"><a href="diag.html"><i class="fa fa-check"></i><b>10</b> Convergence diagnostics</a></li>
<li class="chapter" data-level="11" data-path="bma.html"><a href="bma.html"><i class="fa fa-check"></i><b>11</b> Bayesian model averaging in variable selection</a></li>
<li class="chapter" data-level="12" data-path="nonpara.html"><a href="nonpara.html"><i class="fa fa-check"></i><b>12</b> Nonparametric regression</a></li>
<li class="chapter" data-level="13" data-path="recent.html"><a href="recent.html"><i class="fa fa-check"></i><b>13</b> Recent developments</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i>Appendix</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to Bayesian Econometrics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="logit-model" class="section level2">
<h2><span class="header-section-number">6.2</span> Logit model</h2>
<p>In the logit model the dependent variable is binary, <span class="math inline">\(Y_i=\left\{1,0\right\}\)</span>, then it follows a Bernoulli distribution, <span class="math inline">\(Y_i\stackrel{ind} {\thicksim}B(\pi_i)\)</span>, that is, <span class="math inline">\(p(Y_i=1)=\pi_i\)</span>, such that <span class="math inline">\(\pi_i=\frac{\exp\left\{{\bf{x}}_i^{\top}\beta\right\}}{1+\exp\left\{{\bf{x}}_i^{\top}\beta\right\}}\)</span>.</p>
<p>The likelihood function of the logit model is</p>
<p><span class="math display">\[\begin{align}
  p(\mathbf{y}|\beta,\mathbf{X})&amp;=\prod_{i=1}^N \pi_i^{y_i}(1-\pi_i)^{1-y_i}\\
  &amp;=\prod_{i=1}^N\left(\frac{\exp\left\{{\bf{x}}_i^{\top}\beta\right\}}{1+\exp\left\{{\bf{x}}_i^{\top}\beta\right\}}\right)^{y_i}\left(\frac{1}{1+\exp\left\{{\bf{x}}_i^{\top}\beta\right\}}\right)^{1-y_i}.
\end{align}\]</span></p>
<p>I specify a Normal distribution as prior, <span class="math inline">\(\beta\sim N({\bf{\beta}}_0,{\bf{B}}_0)\)</span>. Then, the posterior distribution is</p>
<p><span class="math display">\[\begin{align}
  \pi(\beta|\mathbf{y},\mathbf{X})&amp;\propto\prod_{i=1}^N\left(\frac{\exp\left\{{\bf{x}}_i^{\top}\beta\right\}}{1+\exp\left\{{\bf{x}}_i^{\top}\beta\right\}}\right)^{y_i}\left(\frac{1}{1+\exp\left\{{\bf{x}}_i^{\top}\beta\right\}}\right)^{1-y_i}\times\exp\left\{-\frac{1}{2}(\beta-\beta_0)^{\top}\mathbf{B}_0(\beta-\beta_0)\right\}.
\end{align}\]</span></p>
<p>The logit model does not have a standard posterior distribution. Then, a random walk Metropolis–Hastings algorithm can be used to obtain draws from the posterior distribution. A potential proposal is a multivariate Normal centered at the current value, with covariance matrix <span class="math inline">\(\tau^2({\bf{B}}_0^{-1}+\widehat{{\bf{\Sigma}}}^{-1})^{-1}\)</span>, where <span class="math inline">\(\tau&gt;0\)</span> is a tuning parameter and <span class="math inline">\(\widehat{\bf{\Sigma}}\)</span> is the sample covariance matrix from the maximum likelihood estimation <span class="citation">(Martin, Quinn, and Park <a href="#ref-Martin2011" role="doc-biblioref">2011</a>)</span>.<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a></p>
<p>Observe that <span class="math inline">\(\log(p(\mathbf{y}|\beta,\mathbf{X}))=\sum_{i=1}^Ny_i{\bf{x}}_i^{\top}\beta-\log(1+\exp({\bf{x}}_i^{\top}\beta))\)</span>. I am going to use this expression when calculating the acceptance parameter in the computational implementation of the Metropolist-Hastings algorithm. In particular, the acceptance parameter is <span class="math inline">\(\alpha=\min\left\{1, \exp(\log(p(\mathbf{y}|\beta^{c},\mathbf{X}))+\log(\pi(\beta^c))-(\log(p(\mathbf{y}|\beta^{(s-1)},\mathbf{X}))+\log(\pi(\beta^{(s-1)}))))\right\}\)</span>, where <span class="math inline">\(\beta^c\)</span> and <span class="math inline">\(\beta^{(s-1)}\)</span> are draws from the proposal distribution and previous iteration of the Markov chain, respectively.<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a></p>
<p><strong>Simulation</strong></p>
<p>Let’s do a simulation exercise to check the performance of the algorithms. Set <span class="math inline">\(\beta=\begin{bmatrix}0.5 &amp; 0.8 &amp; -1.2\end{bmatrix}^{\top}\)</span>, <span class="math inline">\(\mathbf{x}_{ik}\sim N(0,1)\)</span>, <span class="math inline">\(k=2,3\)</span> and <span class="math inline">\(i=1,2,\dots,10000\)</span>.</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="logit-model.html#cb15-1"></a><span class="kw">set.seed</span>(<span class="dv">010101</span>) <span class="co"># Set a seed for replicability of results</span></span>
<span id="cb15-2"><a href="logit-model.html#cb15-2"></a>N &lt;-<span class="st"> </span><span class="dv">10000</span> <span class="co"># Sample size</span></span>
<span id="cb15-3"><a href="logit-model.html#cb15-3"></a>B &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="fl">0.5</span>, <span class="fl">0.8</span>, <span class="fl">-1.2</span>) <span class="co"># Population location parameters</span></span>
<span id="cb15-4"><a href="logit-model.html#cb15-4"></a>x2 &lt;-<span class="st"> </span><span class="kw">rnorm</span>(N) <span class="co"># Regressor</span></span>
<span id="cb15-5"><a href="logit-model.html#cb15-5"></a>x3 &lt;-<span class="st"> </span><span class="kw">rnorm</span>(N) <span class="co"># Regressor</span></span>
<span id="cb15-6"><a href="logit-model.html#cb15-6"></a>X &lt;-<span class="st"> </span><span class="kw">cbind</span>(<span class="dv">1</span>, x2, x3) <span class="co"># Regressors</span></span>
<span id="cb15-7"><a href="logit-model.html#cb15-7"></a>XB &lt;-<span class="st"> </span>X<span class="op">%*%</span>B</span>
<span id="cb15-8"><a href="logit-model.html#cb15-8"></a>PY &lt;-<span class="st"> </span><span class="kw">exp</span>(XB)<span class="op">/</span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span><span class="kw">exp</span>(XB)) <span class="co"># Probability of Y = 1</span></span>
<span id="cb15-9"><a href="logit-model.html#cb15-9"></a>Y &lt;-<span class="st"> </span><span class="kw">rbinom</span>(N, <span class="dv">1</span>, PY) <span class="co"># Draw Y&#39;s</span></span>
<span id="cb15-10"><a href="logit-model.html#cb15-10"></a><span class="kw">table</span>(Y) <span class="co"># Frequency</span></span></code></pre></div>
<pre><code>## Y
##    0    1 
## 4115 5885</code></pre>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="logit-model.html#cb17-1"></a><span class="kw">write.csv</span>(<span class="kw">cbind</span>(Y, x2, x3), <span class="dt">file =</span> <span class="st">&quot;DataSimulations/LogitSim.csv&quot;</span>) <span class="co"># Export data</span></span>
<span id="cb17-2"><a href="logit-model.html#cb17-2"></a></span>
<span id="cb17-3"><a href="logit-model.html#cb17-3"></a><span class="co">###### 1. Programming the M-H sampler #######</span></span>
<span id="cb17-4"><a href="logit-model.html#cb17-4"></a><span class="co"># This function sets the M-H sampler using as default a hyperparameter mean equal to 0</span></span>
<span id="cb17-5"><a href="logit-model.html#cb17-5"></a><span class="co"># and a covariance equal to 1000 times a identity matrix, a tunning parameter equal to 1,</span></span>
<span id="cb17-6"><a href="logit-model.html#cb17-6"></a><span class="co"># 1000 post burn-in iterations, and the latter is equal to 500.</span></span>
<span id="cb17-7"><a href="logit-model.html#cb17-7"></a>MHfunc &lt;-<span class="st"> </span><span class="cf">function</span>(y, X, <span class="dt">b0 =</span> <span class="kw">rep</span>(<span class="dv">0</span>, <span class="kw">dim</span>(X)[<span class="dv">2</span>] <span class="op">+</span><span class="st"> </span><span class="dv">1</span>), <span class="dt">B0 =</span> <span class="dv">1000</span><span class="op">*</span><span class="kw">diag</span>(<span class="kw">dim</span>(X)[<span class="dv">2</span>] <span class="op">+</span><span class="st"> </span><span class="dv">1</span>), <span class="dt">tau =</span> <span class="dv">1</span>, </span>
<span id="cb17-8"><a href="logit-model.html#cb17-8"></a>                   <span class="dt">iter =</span> <span class="dv">1000</span>, <span class="dt">burnin =</span> <span class="dv">500</span>){</span>
<span id="cb17-9"><a href="logit-model.html#cb17-9"></a>  Xm &lt;-<span class="st"> </span><span class="kw">cbind</span>(<span class="dv">1</span>, X) <span class="co"># Regressors</span></span>
<span id="cb17-10"><a href="logit-model.html#cb17-10"></a>  K &lt;-<span class="st"> </span><span class="kw">dim</span>(Xm)[<span class="dv">2</span>] <span class="co"># Number of location parameters</span></span>
<span id="cb17-11"><a href="logit-model.html#cb17-11"></a>  BETAS &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dv">0</span>, iter <span class="op">+</span><span class="st"> </span>burnin, K) <span class="co"># Space for posterior chains</span></span>
<span id="cb17-12"><a href="logit-model.html#cb17-12"></a>  Reg &lt;-<span class="st"> </span><span class="kw">glm</span>(y <span class="op">~</span><span class="st"> </span>Xm <span class="op">-</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link =</span> <span class="st">&quot;logit&quot;</span>)) <span class="co"># Maximum likelihood estimation</span></span>
<span id="cb17-13"><a href="logit-model.html#cb17-13"></a>  BETA &lt;-<span class="st"> </span>Reg<span class="op">$</span>coefficients <span class="co"># Maximum likelihood parameter estimates </span></span>
<span id="cb17-14"><a href="logit-model.html#cb17-14"></a>  tot &lt;-<span class="st"> </span>iter <span class="op">+</span><span class="st"> </span>burnin <span class="co"># Total iterations M-H algorithm</span></span>
<span id="cb17-15"><a href="logit-model.html#cb17-15"></a>  COV &lt;-<span class="st"> </span><span class="kw">vcov</span>(Reg) <span class="co"># Maximum likelihood covariance matrix</span></span>
<span id="cb17-16"><a href="logit-model.html#cb17-16"></a>  COVt &lt;-<span class="st"> </span>tau<span class="op">^</span><span class="dv">2</span><span class="op">*</span><span class="kw">solve</span>(<span class="kw">solve</span>(B0) <span class="op">+</span><span class="st"> </span><span class="kw">solve</span>(COV)) <span class="co"># Covariance matrix for the proposal distribution</span></span>
<span id="cb17-17"><a href="logit-model.html#cb17-17"></a>  Accep &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>, tot) <span class="co"># Space for calculating the acceptance rate</span></span>
<span id="cb17-18"><a href="logit-model.html#cb17-18"></a>  <span class="co"># create progress bar in case that you want to see iterations progress</span></span>
<span id="cb17-19"><a href="logit-model.html#cb17-19"></a>  <span class="co"># pb &lt;- winProgressBar(title = &quot;progress bar&quot;, min = 0,</span></span>
<span id="cb17-20"><a href="logit-model.html#cb17-20"></a>  <span class="co">#                      max = tot, width = 300)</span></span>
<span id="cb17-21"><a href="logit-model.html#cb17-21"></a>  <span class="cf">for</span>(it <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>tot){</span>
<span id="cb17-22"><a href="logit-model.html#cb17-22"></a>    BETAc &lt;-<span class="st"> </span>BETA <span class="op">+</span><span class="st"> </span>MASS<span class="op">::</span><span class="kw">mvrnorm</span>(<span class="dt">n =</span> <span class="dv">1</span>, <span class="dt">mu =</span> <span class="kw">rep</span>(<span class="dv">0</span>, K), <span class="dt">Sigma =</span> COVt) <span class="co"># Candidate location parameter</span></span>
<span id="cb17-23"><a href="logit-model.html#cb17-23"></a>    likecand &lt;-<span class="st"> </span><span class="kw">sum</span>((Xm<span class="op">%*%</span>BETAc) <span class="op">*</span><span class="st"> </span>Y <span class="op">-</span><span class="st"> </span><span class="kw">apply</span>(Xm<span class="op">%*%</span>BETAc, <span class="dv">1</span>, <span class="cf">function</span>(x) <span class="kw">log</span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span><span class="kw">exp</span>(x)))) <span class="co"># Log likelihood for the candidate</span></span>
<span id="cb17-24"><a href="logit-model.html#cb17-24"></a>    likepast &lt;-<span class="st"> </span><span class="kw">sum</span>((Xm<span class="op">%*%</span>BETA) <span class="op">*</span><span class="st"> </span>Y <span class="op">-</span><span class="st"> </span><span class="kw">apply</span>((Xm<span class="op">%*%</span>BETA), <span class="dv">1</span>, <span class="cf">function</span>(x) <span class="kw">log</span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span><span class="kw">exp</span>(x)))) <span class="co"># Log lkelihood for the actual draw</span></span>
<span id="cb17-25"><a href="logit-model.html#cb17-25"></a>    priorcand &lt;-<span class="st"> </span>(<span class="op">-</span><span class="dv">1</span><span class="op">/</span><span class="dv">2</span>)<span class="op">*</span><span class="kw">crossprod</span>((BETAc <span class="op">-</span><span class="st"> </span>b0), <span class="kw">solve</span>(B0))<span class="op">%*%</span>(BETAc <span class="op">-</span><span class="st"> </span>b0) <span class="co"># Log prior for candidate</span></span>
<span id="cb17-26"><a href="logit-model.html#cb17-26"></a>    priorpast &lt;-<span class="st"> </span>(<span class="op">-</span><span class="dv">1</span><span class="op">/</span><span class="dv">2</span>)<span class="op">*</span><span class="kw">crossprod</span>((BETA <span class="op">-</span><span class="st"> </span>b0), <span class="kw">solve</span>(B0))<span class="op">%*%</span>(BETA <span class="op">-</span><span class="st"> </span>b0) <span class="co"># Log prior for actual draw</span></span>
<span id="cb17-27"><a href="logit-model.html#cb17-27"></a>    alpha &lt;-<span class="st"> </span><span class="kw">min</span>(<span class="dv">1</span>, <span class="kw">exp</span>(likecand <span class="op">+</span><span class="st"> </span>priorcand <span class="op">-</span><span class="st"> </span>likepast <span class="op">-</span><span class="st"> </span>priorpast)) <span class="co">#Probability of selecting candidate</span></span>
<span id="cb17-28"><a href="logit-model.html#cb17-28"></a>    u &lt;-<span class="st"> </span><span class="kw">runif</span>(<span class="dv">1</span>) <span class="co"># Decision rule for selecting candidate</span></span>
<span id="cb17-29"><a href="logit-model.html#cb17-29"></a>    <span class="cf">if</span>(u <span class="op">&lt;</span><span class="st"> </span>alpha){</span>
<span id="cb17-30"><a href="logit-model.html#cb17-30"></a>      BETA &lt;-<span class="st"> </span>BETAc <span class="co"># Changing reference for candidate if selected</span></span>
<span id="cb17-31"><a href="logit-model.html#cb17-31"></a>      Accep[it] &lt;-<span class="st"> </span><span class="dv">1</span> <span class="co"># Indicator if the candidate is accepted</span></span>
<span id="cb17-32"><a href="logit-model.html#cb17-32"></a>    } </span>
<span id="cb17-33"><a href="logit-model.html#cb17-33"></a>    BETAS[it, ] &lt;-<span class="st"> </span>BETA <span class="co"># Saving draws</span></span>
<span id="cb17-34"><a href="logit-model.html#cb17-34"></a>    <span class="co"># setWinProgressBar(pb, it, title=paste( round(it/tot*100, 0),</span></span>
<span id="cb17-35"><a href="logit-model.html#cb17-35"></a>    <span class="co">#                                       &quot;% done&quot;))</span></span>
<span id="cb17-36"><a href="logit-model.html#cb17-36"></a>  }</span>
<span id="cb17-37"><a href="logit-model.html#cb17-37"></a>  <span class="co"># close(pb)</span></span>
<span id="cb17-38"><a href="logit-model.html#cb17-38"></a>  <span class="kw">return</span>(<span class="kw">list</span>(<span class="dt">Bs =</span> BETAS[<span class="op">-</span><span class="kw">c</span>(<span class="dv">1</span><span class="op">:</span>burnin), ], <span class="dt">AceptRate =</span> <span class="kw">mean</span>(Accep)))</span>
<span id="cb17-39"><a href="logit-model.html#cb17-39"></a>}</span>
<span id="cb17-40"><a href="logit-model.html#cb17-40"></a>Posterior &lt;-<span class="st"> </span><span class="kw">MHfunc</span>(<span class="dt">y =</span> Y, <span class="dt">X =</span> <span class="kw">cbind</span>(x2, x3), <span class="dt">iter =</span> <span class="dv">100</span>, <span class="dt">burnin =</span> <span class="dv">5</span>) <span class="co"># Runing our M-H function changing some default parameters.</span></span>
<span id="cb17-41"><a href="logit-model.html#cb17-41"></a><span class="kw">paste</span>(<span class="st">&quot;Acceptance rate equal to&quot;</span>, <span class="kw">round</span>(Posterior<span class="op">$</span>AceptRate, <span class="dv">2</span>), <span class="dt">sep =</span> <span class="st">&quot; &quot;</span>)</span></code></pre></div>
<pre><code>## [1] &quot;Acceptance rate equal to 0.49&quot;</code></pre>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="logit-model.html#cb19-1"></a>PostPar &lt;-<span class="st"> </span>coda<span class="op">::</span><span class="kw">mcmc</span>(Posterior<span class="op">$</span>Bs)</span>
<span id="cb19-2"><a href="logit-model.html#cb19-2"></a><span class="co"># Names</span></span>
<span id="cb19-3"><a href="logit-model.html#cb19-3"></a><span class="kw">colnames</span>(PostPar) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Cte&quot;</span>, <span class="st">&quot;x1&quot;</span>, <span class="st">&quot;x2&quot;</span>)</span>
<span id="cb19-4"><a href="logit-model.html#cb19-4"></a><span class="co"># Summary posterior draws</span></span>
<span id="cb19-5"><a href="logit-model.html#cb19-5"></a><span class="kw">summary</span>(PostPar)</span></code></pre></div>
<pre><code>## 
## Iterations = 1:100
## Thinning interval = 1 
## Number of chains = 1 
## Sample size per chain = 100 
## 
## 1. Empirical mean and standard deviation for each variable,
##    plus standard error of the mean:
## 
##        Mean      SD Naive SE Time-series SE
## Cte  0.5000 0.02025 0.002025       0.005291
## x1   0.8366 0.02057 0.002057       0.005556
## x2  -1.1969 0.02811 0.002811       0.008643
## 
## 2. Quantiles for each variable:
## 
##        2.5%     25%     50%     75%   97.5%
## Cte  0.4688  0.4872  0.4989  0.5119  0.5397
## x1   0.8092  0.8195  0.8357  0.8512  0.8809
## x2  -1.2475 -1.2190 -1.1906 -1.1807 -1.1396</code></pre>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="logit-model.html#cb21-1"></a><span class="co"># Trace and density plots</span></span>
<span id="cb21-2"><a href="logit-model.html#cb21-2"></a><span class="kw">plot</span>(PostPar)</span></code></pre></div>
<p><img src="BayesianEconometrics_files/figure-html/unnamed-chunk-2-1..svg" width="672" /></p>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="logit-model.html#cb22-1"></a><span class="co"># Autocorrelation plots</span></span>
<span id="cb22-2"><a href="logit-model.html#cb22-2"></a>coda<span class="op">::</span><span class="kw">autocorr.plot</span>(PostPar)</span></code></pre></div>
<p><img src="BayesianEconometrics_files/figure-html/unnamed-chunk-2-2..svg" width="672" /></p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="logit-model.html#cb23-1"></a><span class="co"># Convergence diagnostics</span></span>
<span id="cb23-2"><a href="logit-model.html#cb23-2"></a>coda<span class="op">::</span><span class="kw">geweke.diag</span>(PostPar)</span></code></pre></div>
<pre><code>## 
## Fraction in 1st window = 0.1
## Fraction in 2nd window = 0.5 
## 
##     Cte      x1      x2 
##  1.4567 -1.4614 -0.8573</code></pre>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="logit-model.html#cb25-1"></a>coda<span class="op">::</span><span class="kw">raftery.diag</span>(PostPar,<span class="dt">q=</span><span class="fl">0.5</span>,<span class="dt">r=</span><span class="fl">0.025</span>,<span class="dt">s =</span> <span class="fl">0.95</span>)</span></code></pre></div>
<pre><code>## 
## Quantile (q) = 0.5
## Accuracy (r) = +/- 0.025
## Probability (s) = 0.95 
## 
## You need a sample size of at least 1537 with these values of q, r and s</code></pre>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="logit-model.html#cb27-1"></a>coda<span class="op">::</span><span class="kw">heidel.diag</span>(PostPar)</span></code></pre></div>
<pre><code>##                                   
##     Stationarity start     p-value
##     test         iteration        
## Cte passed        1        0.0799 
## x1  failed       NA        0.0350 
## x2  passed        1        0.6687 
##                             
##     Halfwidth Mean Halfwidth
##     test                    
## Cte passed     0.5 0.0104   
## x1  &lt;NA&gt;        NA     NA   
## x2  passed    -1.2 0.0169</code></pre>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb29-1"><a href="logit-model.html#cb29-1"></a><span class="co">###### 2. Using a library: MCMCpack #######</span></span>
<span id="cb29-2"><a href="logit-model.html#cb29-2"></a>RegLog &lt;-<span class="st"> </span>MCMCpack<span class="op">::</span><span class="kw">MCMClogit</span>(Y<span class="op">~</span>X<span class="dv">-1</span>, <span class="dt">burnin =</span> <span class="dv">1000</span>, <span class="dt">mcmc =</span> <span class="dv">10000</span>, <span class="dt">b0 =</span> <span class="kw">rep</span>(<span class="dv">0</span>, <span class="dv">3</span>), <span class="dt">B0 =</span> <span class="dv">1000</span><span class="op">^</span>(<span class="op">-</span><span class="dv">1</span>)<span class="op">*</span><span class="kw">diag</span>(<span class="dv">3</span>), <span class="dt">tune =</span> <span class="dv">1</span>, <span class="dt">thin =</span> <span class="dv">1</span>)</span>
<span id="cb29-3"><a href="logit-model.html#cb29-3"></a><span class="kw">summary</span>(RegLog)</span></code></pre></div>
<pre><code>## 
## Iterations = 1001:11000
## Thinning interval = 1 
## Number of chains = 1 
## Sample size per chain = 10000 
## 
## 1. Empirical mean and standard deviation for each variable,
##    plus standard error of the mean:
## 
##        Mean      SD  Naive SE Time-series SE
## X    0.4888 0.02499 0.0002499      0.0008527
## Xx2  0.8325 0.02711 0.0002711      0.0009338
## Xx3 -1.2112 0.03027 0.0003027      0.0010453
## 
## 2. Quantiles for each variable:
## 
##        2.5%     25%     50%     75%   97.5%
## X    0.4395  0.4726  0.4891  0.5051  0.5385
## Xx2  0.7787  0.8145  0.8326  0.8499  0.8877
## Xx3 -1.2734 -1.2312 -1.2105 -1.1906 -1.1515</code></pre>
<p>When using our GUI to estimate this model, we should follow these steps:</p>
<ol style="list-style-type: decimal">
<li>Select univariate models on the top panel</li>
<li>Select logit models using the left radio button</li>
<li>Upload the data set (we save this in folder <em>DataSimulations</em> in file <em>LogitSim.csv</em>)</li>
<li>Select MCMC iterations, burn-in and thinning parameters</li>
<li>Select dependent and independent variables (see Figure <a href="logit-model.html#fig:Fig4">6.5</a>)</li>
<li>Click the <em>Build formula</em> button</li>
<li>Set the hyperparameters and the tunning parameter</li>
<li>Click the <em>Go!</em> button</li>
<li>Analyze results (see Figure <a href="logit-model.html#fig:Fig5">6.6</a>)</li>
<li>Download posterior chains and diagnostic plots</li>
</ol>

<div class="figure" style="text-align: center"><span id="fig:Fig4"></span>
<img src="images/Figure4.png" alt="Univariate models: Logit/normal model" width="80%" />
<p class="caption">
Figure 6.5: Univariate models: Logit/normal model
</p>
</div>
<p>We observe from our results that all 95% credible intervals embrace the population parameters. We also observe that there is a high level of autocorrelation (see autocorrelation plots) that potentially increases the dependence factor in the Raftery test (dependence factors higher than 5 are worrisome). Dependence factors are the proportional increase in the number of iterations attributable to serial dependence. Although, other diagnostics seem to be right (see Chapter <a href="diag.html#diag">10</a> for details). We can potentially mitigate convergence issues running longer chains or multiple chains, using a thinning parameter greater than 1, picking a better tunning parameter or improving the mixing properties of the model using better priors or performing better math.</p>

<div class="figure" style="text-align: center"><span id="fig:Fig5"></span>
<img src="images/Figure5.png" alt="Logit/normal model: Results." width="80%" />
<p class="caption">
Figure 6.6: Logit/normal model: Results.
</p>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-Martin2011">
<p>Martin, Andrew D., Kevin M. Quinn, and Jong Hee Park. 2011. “MCMCpack: Markov Chain Monte Carlo in R.” <em>Journal of Statistical Software</em> 42 (9): 1–21.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="3">
<li id="fn3"><p>Tuning parameters should be set in a way such that one obtains reasonable diagnostic criteria and aceptation rates.<a href="logit-model.html#fnref3" class="footnote-back">↩︎</a></p></li>
<li id="fn4"><p>Formulating the acceptance rate using <span class="math inline">\(\log\)</span> helps to mitigate computational problems.<a href="logit-model.html#fnref4" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="normal-model.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="probit-model.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/aramir21/IntroductionBayesianEconometricsBook/06-Univariatereg.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
