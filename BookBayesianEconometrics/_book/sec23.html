<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>2.3 Estimation, hypothesis testing and prediction | Introduction to Bayesian Econometrics</title>
  <meta name="description" content="The subject of this textbook is Bayesian regression analysis, and its main aim is to provide introductory level theory foundation, and facilitate applicability of Bayesian inference." />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="2.3 Estimation, hypothesis testing and prediction | Introduction to Bayesian Econometrics" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="The subject of this textbook is Bayesian regression analysis, and its main aim is to provide introductory level theory foundation, and facilitate applicability of Bayesian inference." />
  <meta name="github-repo" content="https://github.com/aramir21/IntroductionBayesianEconometricsBook" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="2.3 Estimation, hypothesis testing and prediction | Introduction to Bayesian Econometrics" />
  
  <meta name="twitter:description" content="The subject of this textbook is Bayesian regression analysis, and its main aim is to provide introductory level theory foundation, and facilitate applicability of Bayesian inference." />
  

<meta name="author" content="Andrés Ramírez-Hassan" />


<meta name="date" content="2021-01-12" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="sec22.html"/>
<link rel="next" href="sec24.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>



<link rel="stylesheet" href="css\style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Introduction to Bayesian Econometrics: A GUIded tour</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction</a><ul>
<li class="chapter" data-level="" data-path="to-instructors-and-students.html"><a href="to-instructors-and-students.html"><i class="fa fa-check"></i>To instructors and students</a></li>
<li class="chapter" data-level="" data-path="acknowledgments.html"><a href="acknowledgments.html"><i class="fa fa-check"></i>Acknowledgments</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="basics.html"><a href="basics.html"><i class="fa fa-check"></i><b>1</b> Basic formal concepts</a><ul>
<li class="chapter" data-level="1.1" data-path="sec11.html"><a href="sec11.html"><i class="fa fa-check"></i><b>1.1</b> The Bayes’ rule</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="bayfre.html"><a href="bayfre.html"><i class="fa fa-check"></i><b>2</b> Conceptual differences between the Bayesian and the frequentist statistical approaches</a><ul>
<li class="chapter" data-level="2.1" data-path="sec21.html"><a href="sec21.html"><i class="fa fa-check"></i><b>2.1</b> The concept of probability</a></li>
<li class="chapter" data-level="2.2" data-path="sec22.html"><a href="sec22.html"><i class="fa fa-check"></i><b>2.2</b> Subjectivity is not the key</a></li>
<li class="chapter" data-level="2.3" data-path="sec23.html"><a href="sec23.html"><i class="fa fa-check"></i><b>2.3</b> Estimation, hypothesis testing and prediction</a></li>
<li class="chapter" data-level="2.4" data-path="sec24.html"><a href="sec24.html"><i class="fa fa-check"></i><b>2.4</b> The likelihood principle</a></li>
<li class="chapter" data-level="2.5" data-path="sec25.html"><a href="sec25.html"><i class="fa fa-check"></i><b>2.5</b> Logic of argumentation</a></li>
<li class="chapter" data-level="2.6" data-path="sec26.html"><a href="sec26.html"><i class="fa fa-check"></i><b>2.6</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="objsub.html"><a href="objsub.html"><i class="fa fa-check"></i><b>3</b> Objective and subjective Bayesian approaches</a><ul>
<li class="chapter" data-level="3.1" data-path="sec31.html"><a href="sec31.html"><i class="fa fa-check"></i><b>3.1</b> Objective Bayesians</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="conjfam.html"><a href="conjfam.html"><i class="fa fa-check"></i><b>4</b> Basic statistical models: Conjugate families</a></li>
<li class="chapter" data-level="5" data-path="sim.html"><a href="sim.html"><i class="fa fa-check"></i><b>5</b> Simulation methods</a></li>
<li class="chapter" data-level="6" data-path="unireg.html"><a href="unireg.html"><i class="fa fa-check"></i><b>6</b> Univariate regression</a></li>
<li class="chapter" data-level="7" data-path="multi.html"><a href="multi.html"><i class="fa fa-check"></i><b>7</b> Multivariate regression</a></li>
<li class="chapter" data-level="8" data-path="time.html"><a href="time.html"><i class="fa fa-check"></i><b>8</b> Time series</a></li>
<li class="chapter" data-level="9" data-path="longi.html"><a href="longi.html"><i class="fa fa-check"></i><b>9</b> Longitudinal regression</a></li>
<li class="chapter" data-level="10" data-path="diag.html"><a href="diag.html"><i class="fa fa-check"></i><b>10</b> Convergence diagnostics</a></li>
<li class="chapter" data-level="11" data-path="bma.html"><a href="bma.html"><i class="fa fa-check"></i><b>11</b> Bayesian model averaging</a></li>
<li class="chapter" data-level="12" data-path="nonpara.html"><a href="nonpara.html"><i class="fa fa-check"></i><b>12</b> Nonparametric regression</a></li>
<li class="chapter" data-level="13" data-path="recent.html"><a href="recent.html"><i class="fa fa-check"></i><b>13</b> Recent developments</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i>Appendix</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to Bayesian Econometrics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="sec23" class="section level2">
<h2><span class="header-section-number">2.3</span> Estimation, hypothesis testing and prediction</h2>
<p>All what is required to perform estimation, hypothesis testing and prediction in the Bayesian approach is to apply the Bayes’ rule. This means coherence under a probabilistic view. But, there is no free lunch, coherence reduces flexibility. On the other hand, the frequestist approach is not coherent from a probabilistic point of view, but it is very flexible. This approach can be seen as a tool kit that offers inferential solutions under the umbrella of understanding probability as relative frequency.</p>
<p>The Bayesian approach allows to obtain the posterior distribution of any unknown object such as parameters, latent variables and future or unobserved variables. A nice advantage is that prediction can take into account estimation error, and predictive distribution (probabilistic forecasts) can be easily recovered. Hypothesis testing (model selection) is based on <em>inductive</em> logic reasoning (<em>Inverse probability</em>); on the basis of what we see, we evaluate what hypothesis is most tenable, and is performed using posterior odds, which in turn are based on Bayes factors that evaluate evidence in favor of a null hypothesis taking explicitly the alternative <span class="citation">(Kass and Raftery <a href="#ref-Kass1995" role="doc-biblioref">1995</a>)</span>, following the rules of probability <span class="citation">(Lindley <a href="#ref-Lindley2000" role="doc-biblioref">2000</a>)</span> comparing how well the hypothesis predicts data <span class="citation">(Goodman <a href="#ref-Goodman1999" role="doc-biblioref">1999</a>)</span>, minimizing the weighted sum of type I and type II error probabilities (<span class="citation">(DeGroot <a href="#ref-DeGroot1975" role="doc-biblioref">1975</a>)</span>, <span class="citation">(Pericchi and Pereira <a href="#ref-Pericchip" role="doc-biblioref">2015</a>)</span>), and taking the implicit balance of losses (<span class="citation">(Jeffreys <a href="#ref-Jeffreys1961" role="doc-biblioref">1961</a>)</span>, <span class="citation">(Bernardo and Smith <a href="#ref-Bernardo1994" role="doc-biblioref">1994</a>)</span>) into account. Posterior odds allows to use the same framework to analyze nested and non-nested models and perform model average. However, Bayes factors cannot be based on improper or vague priors <span class="citation">(Koop <a href="#ref-koop2003bayesian" role="doc-biblioref">2003</a>)</span>, the practical interplay between model selection and posterior distributions is not as easy as the frequentist approach, and the computational burden can be more demanding due to solving potentially difficult integrals.</p>
<p>On the other hand, the frequentist approach establishes most of its estimators as the solution of a system of equations. Observe that optimization problems reduce to solve systems. We can potentially get the distribution of these estimators, but most of the time it is needed asymptotic arguments or resampling techniques. Hypothesis testing requires pivotal quantities<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a> and/or also resampling, and prediction most of the time is based on a <em>plug-in</em> approach, which means not taking estimation error into account. In addition, ancillary statistics can be used to build prediction intervals.<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a> Comparing models depends on their structure, for instance, there are different frequentist statistical approaches to compare nested and non-nested models. A nice feature in some situations is that there is a practical interplay between hypothesis testing and confidence intervals, where you cannot reject at <span class="math inline">\(\alpha\)</span> significance level (Type I error) any null hypothesis <span class="math inline">\(H_0. \  \beta_k=\beta_k^0\)</span> if <span class="math inline">\(\beta_k^0\)</span> is in the <span class="math inline">\(1-\alpha\)</span> confidence interval <span class="math inline">\(P(\beta_k\in[\hat{\beta_k}-|t_{N-K}^{\alpha/2}|\times\hat \sigma_{\hat{\beta_k}},\hat{\beta_k}+|t_{N-k}|^{\alpha/2}\times \hat\sigma_{\hat{\beta_k}}])=1-\alpha\)</span> in a linear model, <span class="math inline">\(\hat{\beta_k}\)</span> and <span class="math inline">\(\hat\sigma_{\hat{\beta_k}}\)</span> are the least squares estimators of <span class="math inline">\(\beta_k\)</span> and its standard error, and <span class="math inline">\(t_{N-K}^{\alpha/2}\)</span> is the quantile value of the Student’s t distribution at <span class="math inline">\(\alpha/2\)</span> probability and <span class="math inline">\(N-K\)</span> degrees of freedom, <span class="math inline">\(N\)</span> is the sample size, and <span class="math inline">\(K\)</span> the number of location parameters.</p>
<p>A remarkable difference between the Bayesian and the frequentist inferential frameworks is the interpretation of credible/confidence intervals. Observe that once we have estimates, such that for example the previous interval is <span class="math inline">\([0.2, 0.4]\)</span> given a 95% confidence level, we cannot say that <span class="math inline">\(P(\beta_k\in [0.2, 0.4])=0.95\)</span> in the frequentist framework. In fact, this probability is 0 or 1 under this approach, as <span class="math inline">\(\beta_k\)</span> can be there or not, the problem is that we will never know in applied settings. This due to that <span class="math inline">\(P(\beta_k\in[\hat{\beta_k}-|t_{N-K}^{0.025}|\hat\times \sigma_{\hat{\beta_k}},\hat{\beta_k}+|t_{N-k}^{0.025}|\times \hat\sigma_{\hat{\beta_k}}])=0.95\)</span> being in the sense of repeated sampling. On the other hand, once we have the posterior distribution, we can say that <span class="math inline">\(P(\beta_k\in [0.2, 0.4])=0.95\)</span> under the Bayesian framework.</p>
<p>Following common practice, most of researchers and practitioners do hypothesis testing based on the <em>p</em>-value in the frequentist framework. But, <strong>what is a <em>p</em>–value?</strong> Most of the users do not know the answer due to many times statistical inference is not performed by statisticians <span class="citation">(Berger <a href="#ref-Berger2006" role="doc-biblioref">2006</a>)</span>.<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a> A <em>p</em>–value is the probability of obtaining a statistical summary of the data equal to or “more extreme” than what was actually observed, assuming that the null hypothesis is true.</p>
<p>Therefore, <em>p</em>–value calculations involve not just the observed data, but also more “extreme” hypothetical observations. So,</p>
<p>“What the use of p implies, therefore, is that a hypothesis that may be true may be rejected because it has not predicted observable results that have not occurred.”<span class="citation">(Jeffreys <a href="#ref-Jeffreys1961" role="doc-biblioref">1961</a>)</span></p>
<p>It seems that common frequentist inferential practice intertwined two different logic reasoning arguments: the <em>p</em>–value <span class="citation">(Fisher <a href="#ref-Fisher1958" role="doc-biblioref">1958</a>)</span> and <em>significance level</em> <span class="citation">(Neyman and Pearson <a href="#ref-Neyman1933" role="doc-biblioref">1933</a>)</span>. The former is an informal short–run criterion, whose philosophical foundation is <em>reduction to absurdity</em>, which measures the discrepancy between the data and the null hypothesis. So, the <em>p</em>–value is not a direct measure of the probability that the null hypothesis is false. The latter, whose philosophical foundations is <em>deduction</em>, is based on a long–run performance such that controls the overall number of incorrect inferences in the repeated sampling without care of individual cases. The <em>p</em>–value fallacy consists in interpreting the <em>p</em>–value as the strength of evidence against the null hypothesis, and using it simultaneously with the frequency of type I error under the null hypothesis <span class="citation">(Goodman <a href="#ref-Goodman1999" role="doc-biblioref">1999</a>)</span>.</p>
<p>The American Statistical Association has several concerns regarding the use of the <em>p</em>–value as a cornerstone to perform hypothesis testing in science. This concern motivates the ASA’s statement on p–values <span class="citation">(Wasserstein and Lazar <a href="#ref-Wasserstein2016" role="doc-biblioref">2016</a>)</span>, which can be summarized in the following principles:</p>
<ul>
<li><p>“P–values can indicate how incompatible the data are with a specified statistical model.”</p></li>
<li><p>“P–values do not measure the probability that the studied hypothesis is true, or the probability that the data were produced by random chance alone.”</p></li>
<li><p>“Scientific conclusions and business or policy decisions should not be based only on whether a p–value passes a specific threshold.”</p></li>
<li><p>“Proper inference requires full reporting and transparency.”</p></li>
<li><p>“A p–value, or statistical significance, does not measure the size of an effect or the importance of a result.”</p></li>
<li><p>“By itself, a p–value does not provide a good measure of evidence regarding a model or hypothesis.”</p></li>
</ul>
<p>Another difference between the frequentists and the Bayesians is the way how scientific hypothesis are tested. The former use the <em>p</em>-value, whereas the latter use the Bayes factor. Observe that the <em>p</em>–value is associated with the probability of the data given the hypothesis, whereas the Bayes factor is associated with the probability of the hypothesis given the data. However, there is an approximate link between the <span class="math inline">\(t\)</span> statistic and the Bayes factor for regression coefficients <span class="citation">(Raftery <a href="#ref-Raftery1995" role="doc-biblioref">1995</a>)</span>. In particular, <span class="math inline">\(|t|&gt;(log(N)+6)^{1/2}\)</span>, corresponds to strong evidence in favor of rejecting the not relevance of a control in a regression. Observe that in this setting the threshold of the <span class="math inline">\(t\)</span> statistic, and as a consequence the significant level, depends on the sample size. Observe that this setting agrees with the idea in experimental designs of selecting the sample size such that we control Type I and Type II errors. In observational studies we cannot control the sample size, but we can select the significance level.</p>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-Berger2006">
<p>Berger, J. 2006. “The Case for Objective Bayesian Analysis.” <em>Bayesian Analysis</em> 1 (3): 385–402.</p>
</div>
<div id="ref-Bernardo1994">
<p>Bernardo, J., and A. Smith. 1994. <em>Bayesian Theory</em>. Chichester: Wiley.</p>
</div>
<div id="ref-DeGroot1975">
<p>DeGroot, M. H. 1975. <em>Probability and Statistics</em>. London: Addison-Wesley Publishing Co.</p>
</div>
<div id="ref-Fisher1958">
<p>Fisher, R. 1958. <em>Statistical Methods for Research Workers</em>. 13th ed. New York: Hafner.</p>
</div>
<div id="ref-Goodman1999">
<p>Goodman, S. N. 1999. “Toward Evidence-Based Medical Statistics. 1: The P Value Fallacy.” <em>Annals of Internal Medicine</em> 130 (12): 995–1004.</p>
</div>
<div id="ref-Jeffreys1961">
<p>Jeffreys, H. 1961. <em>Theory of Probability</em>. London: Oxford University Press.</p>
</div>
<div id="ref-Kass1995">
<p>Kass, Robert E., and Adrian E. Raftery. 1995. “Bayes Factorss.” <em>Journal of American Statistical Association</em> 90 (430): 773–95.</p>
</div>
<div id="ref-koop2003bayesian">
<p>Koop, Gary M. 2003. <em>Bayesian Econometrics</em>. John Wiley &amp; Sons Inc.</p>
</div>
<div id="ref-Lindley2000">
<p>Lindley, D. V. 2000. “The Philosophy of Statistics.” <em>The Statistician</em> 49 (3): 293–337.</p>
</div>
<div id="ref-Neyman1933">
<p>Neyman, J., and E. Pearson. 1933. “On the Problem of the Most Efficient Tests of Statistical Hypotheses.” <em>Philosophical Transactions of the Royal Society, Series A</em> 231: 289–337.</p>
</div>
<div id="ref-Pericchip">
<p>Pericchi, Luis, and Carlos Pereira. 2015. “Adaptative significance levels using optimal decision rules: Balancing by weighting the error probabilities.” <em>Brazilian Journal of Probability and Statistics</em>.</p>
</div>
<div id="ref-Raftery1995">
<p>Raftery, A. 1995. “Bayesian Model Selection in Social Research.” <em>Sociological Methodology</em> 25: 111–63.</p>
</div>
<div id="ref-Wasserstein2016">
<p>Wasserstein, Ronald L., and Nicole A. Lazar. 2016. “The ASA’s Statement on P–Values: Context, Process and Purpose.” <em>The American Statistician</em>.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="2">
<li id="fn2"><p>A pivot quantity is a function of unobserved parameters and observations whose probability distribution does not depend on the unknown parameters.<a href="sec23.html#fnref2" class="footnote-back">↩︎</a></p></li>
<li id="fn3"><p>An ancillary statistic is a pivotal quantity that is also a statistic.<a href="sec23.html#fnref3" class="footnote-back">↩︎</a></p></li>
<li id="fn4"><p><a href="https://fivethirtyeight.com/features/not-even-scientists-can-easily-explain-p-values/" class="uri">https://fivethirtyeight.com/features/not-even-scientists-can-easily-explain-p-values/</a><a href="sec23.html#fnref4" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="sec22.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="sec24.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/aramir21/IntroductionBayesianEconometricsBook/02-BayFreq.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
