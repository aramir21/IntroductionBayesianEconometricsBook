<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>1.1 The Bayes’ rule | Introduction to Bayesian Econometrics</title>
  <meta name="description" content="The subject of this textbook is Bayesian regression analysis, and its main aim is to provide introductory level theory foundation, and facilitate applicability of Bayesian inference." />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="1.1 The Bayes’ rule | Introduction to Bayesian Econometrics" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="The subject of this textbook is Bayesian regression analysis, and its main aim is to provide introductory level theory foundation, and facilitate applicability of Bayesian inference." />
  <meta name="github-repo" content="https://github.com/aramir21/IntroductionBayesianEconometricsBook" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="1.1 The Bayes’ rule | Introduction to Bayesian Econometrics" />
  
  <meta name="twitter:description" content="The subject of this textbook is Bayesian regression analysis, and its main aim is to provide introductory level theory foundation, and facilitate applicability of Bayesian inference." />
  

<meta name="author" content="Andrés Ramírez-Hassan" />


<meta name="date" content="2021-05-23" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="basics.html"/>
<link rel="next" href="sec12.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Introduction to Bayesian Econometrics: A GUIded tour</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction</a><ul>
<li class="chapter" data-level="" data-path="to-instructors-and-students.html"><a href="to-instructors-and-students.html"><i class="fa fa-check"></i>To instructors and students</a></li>
<li class="chapter" data-level="" data-path="a-brief-presentation-of-r-software.html"><a href="a-brief-presentation-of-r-software.html"><i class="fa fa-check"></i>A brief presentation of R software</a></li>
<li class="chapter" data-level="" data-path="acknowledgments.html"><a href="acknowledgments.html"><i class="fa fa-check"></i>Acknowledgments</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="basics.html"><a href="basics.html"><i class="fa fa-check"></i><b>1</b> Basic formal concepts</a><ul>
<li class="chapter" data-level="1.1" data-path="sec11.html"><a href="sec11.html"><i class="fa fa-check"></i><b>1.1</b> The Bayes’ rule</a></li>
<li class="chapter" data-level="1.2" data-path="sec12.html"><a href="sec12.html"><i class="fa fa-check"></i><b>1.2</b> Bayesian framework: A brief summary of theory</a></li>
<li class="chapter" data-level="1.3" data-path="sec13.html"><a href="sec13.html"><i class="fa fa-check"></i><b>1.3</b> Bayesian reports: Decision theory under uncertainty</a></li>
<li class="chapter" data-level="1.4" data-path="summary-chapter-1.html"><a href="summary-chapter-1.html"><i class="fa fa-check"></i><b>1.4</b> Summary: Chapter 1</a></li>
<li class="chapter" data-level="1.5" data-path="exercises-chapter-1.html"><a href="exercises-chapter-1.html"><i class="fa fa-check"></i><b>1.5</b> Exercises: Chapter 1</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="bayfre.html"><a href="bayfre.html"><i class="fa fa-check"></i><b>2</b> Conceptual differences between the Bayesian and the Frequentist statistical approaches</a><ul>
<li class="chapter" data-level="2.1" data-path="sec21.html"><a href="sec21.html"><i class="fa fa-check"></i><b>2.1</b> The concept of probability</a></li>
<li class="chapter" data-level="2.2" data-path="sec22.html"><a href="sec22.html"><i class="fa fa-check"></i><b>2.2</b> Subjectivity is not the key</a></li>
<li class="chapter" data-level="2.3" data-path="sec23.html"><a href="sec23.html"><i class="fa fa-check"></i><b>2.3</b> Estimation, hypothesis testing and prediction</a></li>
<li class="chapter" data-level="2.4" data-path="sec24.html"><a href="sec24.html"><i class="fa fa-check"></i><b>2.4</b> The likelihood principle</a></li>
<li class="chapter" data-level="2.5" data-path="sec25.html"><a href="sec25.html"><i class="fa fa-check"></i><b>2.5</b> Logic of argumentation</a></li>
<li class="chapter" data-level="2.6" data-path="sec25A.html"><a href="sec25A.html"><i class="fa fa-check"></i><b>2.6</b> Why is not the Bayesian approach that popular?</a></li>
<li class="chapter" data-level="2.7" data-path="sec26.html"><a href="sec26.html"><i class="fa fa-check"></i><b>2.7</b> A simple working example</a></li>
<li class="chapter" data-level="2.8" data-path="sec27.html"><a href="sec27.html"><i class="fa fa-check"></i><b>2.8</b> Summary: Chapter 2</a></li>
<li class="chapter" data-level="2.9" data-path="exercises-chapter-2.html"><a href="exercises-chapter-2.html"><i class="fa fa-check"></i><b>2.9</b> Exercises: Chapter 2</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="objsub.html"><a href="objsub.html"><i class="fa fa-check"></i><b>3</b> Objective and subjective Bayesian approaches</a><ul>
<li class="chapter" data-level="3.1" data-path="sec31.html"><a href="sec31.html"><i class="fa fa-check"></i><b>3.1</b> Objective Bayesian priors</a><ul>
<li class="chapter" data-level="3.1.1" data-path="sec31.html"><a href="sec31.html#empirical-bayes"><i class="fa fa-check"></i><b>3.1.1</b> Empirical Bayes</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="sec32.html"><a href="sec32.html"><i class="fa fa-check"></i><b>3.2</b> Subjective Bayesian priors</a><ul>
<li class="chapter" data-level="3.2.1" data-path="sec32.html"><a href="sec32.html#human-heuristics"><i class="fa fa-check"></i><b>3.2.1</b> Human heuristics</a></li>
<li class="chapter" data-level="3.2.2" data-path="sec32.html"><a href="sec32.html#elicitation"><i class="fa fa-check"></i><b>3.2.2</b> Elicitation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="conjfam.html"><a href="conjfam.html"><i class="fa fa-check"></i><b>4</b> Basic statistical models: Conjugate families</a><ul>
<li class="chapter" data-level="4.1" data-path="sec41.html"><a href="sec41.html"><i class="fa fa-check"></i><b>4.1</b> Motivation of conjugate families</a></li>
<li class="chapter" data-level="4.2" data-path="sec42.html"><a href="sec42.html"><i class="fa fa-check"></i><b>4.2</b> Conjugate prior to exponential family</a></li>
<li class="chapter" data-level="4.3" data-path="linear-regression-the-conjugate-normal-normalinverse-gamma-model.html"><a href="linear-regression-the-conjugate-normal-normalinverse-gamma-model.html"><i class="fa fa-check"></i><b>4.3</b> Linear regression: The conjugate normal-normal/inverse gamma model</a></li>
<li class="chapter" data-level="4.4" data-path="multivariate-linear-regression-the-conjugate-normal-normalinverse-wishart-model.html"><a href="multivariate-linear-regression-the-conjugate-normal-normalinverse-wishart-model.html"><i class="fa fa-check"></i><b>4.4</b> Multivariate linear regression: The conjugate normal-normal/inverse Wishart model</a></li>
<li class="chapter" data-level="4.5" data-path="computational-examples.html"><a href="computational-examples.html"><i class="fa fa-check"></i><b>4.5</b> Computational examples</a></li>
<li class="chapter" data-level="4.6" data-path="summary-chapter-4.html"><a href="summary-chapter-4.html"><i class="fa fa-check"></i><b>4.6</b> Summary: Chapter 4</a></li>
<li class="chapter" data-level="4.7" data-path="exercises-chapter-4.html"><a href="exercises-chapter-4.html"><i class="fa fa-check"></i><b>4.7</b> Exercises: Chapter 4</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="sim.html"><a href="sim.html"><i class="fa fa-check"></i><b>5</b> Simulation methods</a></li>
<li class="chapter" data-level="6" data-path="unireg.html"><a href="unireg.html"><i class="fa fa-check"></i><b>6</b> Univariate regression</a><ul>
<li class="chapter" data-level="6.1" data-path="normal-model.html"><a href="normal-model.html"><i class="fa fa-check"></i><b>6.1</b> Normal model</a></li>
<li class="chapter" data-level="6.2" data-path="logit-model.html"><a href="logit-model.html"><i class="fa fa-check"></i><b>6.2</b> Logit model</a></li>
<li class="chapter" data-level="6.3" data-path="probit-model.html"><a href="probit-model.html"><i class="fa fa-check"></i><b>6.3</b> Probit model</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="multi.html"><a href="multi.html"><i class="fa fa-check"></i><b>7</b> Multivariate regression</a></li>
<li class="chapter" data-level="8" data-path="time.html"><a href="time.html"><i class="fa fa-check"></i><b>8</b> Time series</a></li>
<li class="chapter" data-level="9" data-path="longi.html"><a href="longi.html"><i class="fa fa-check"></i><b>9</b> Longitudinal regression</a></li>
<li class="chapter" data-level="10" data-path="diag.html"><a href="diag.html"><i class="fa fa-check"></i><b>10</b> Convergence diagnostics</a></li>
<li class="chapter" data-level="11" data-path="bma.html"><a href="bma.html"><i class="fa fa-check"></i><b>11</b> Bayesian model averaging in variable selection</a></li>
<li class="chapter" data-level="12" data-path="nonpara.html"><a href="nonpara.html"><i class="fa fa-check"></i><b>12</b> Nonparametric regression</a></li>
<li class="chapter" data-level="13" data-path="recent.html"><a href="recent.html"><i class="fa fa-check"></i><b>13</b> Recent developments</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i>Appendix</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to Bayesian Econometrics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="sec11" class="section level2">
<h2><span class="header-section-number">1.1</span> The Bayes’ rule</h2>
<p>As expected the point of departure to perform Bayesian inference is the Bayes’ rule,<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a> that is, the conditional probability of <span class="math inline">\(A_i\)</span> given <span class="math inline">\(B\)</span> is equal to the conditional probability of <span class="math inline">\(B\)</span> given <span class="math inline">\(A_i\)</span> times the marginal probability of <span class="math inline">\(A_i\)</span> over the marginal probability of <span class="math inline">\(B\)</span>,</p>
<p><span class="math display" id="eq:111">\[\begin{align}
  P(A_i|B)&amp;=\frac{P(A_i,B)}{P(B)}\\
        &amp;=\frac{P(B|A_i) \times P(A_i)}{P(B)},
  \tag{1.1}
\end{align}\]</span></p>
<p>where by the law of total probability <span class="math inline">\(P(B)=\sum_i P(B|A_i)P(A_i)\neq 0\)</span>, <span class="math inline">\(\left\{A_i, i=1,2,\dots\right\}\)</span> is a finite or countably infinite partition of a sample space.</p>
<p>In the Bayesian framework, <span class="math inline">\(B\)</span> is sample information that updates a probabilistic statement about an unknown object <span class="math inline">\(A_i\)</span> following probability rules. This is done by means of the Bayes’ rule using prior “beliefs” about <span class="math inline">\(A_i\)</span>, that is, <span class="math inline">\(P(A_i)\)</span>, sample information relating <span class="math inline">\(B\)</span> to the particular state of the nature <span class="math inline">\(A_i\)</span> through a probabilistic statment, <span class="math inline">\(P(B|A_i)\)</span>, and the probability of observing that specific sample information <span class="math inline">\(P(B)\)</span>.</p>
<p>Let’s see a simple example, <em>the base rate fallacy</em>:</p>
<p>Assume that the sample information comes from a positive result from a test whose true positive rate (sensitivity) is 98%, <span class="math inline">\(P(+|\text{disease})=0.98\)</span>. On the other hand, the prior information regarding being infected with this disease comes from a base incidence rate that is equal to 0.002, that is <span class="math inline">\(P(\text{disease})=0.002\)</span>. Then, <strong>what is the probability of being actually infected?</strong></p>
<p>This is an example of <em>the base rate fallacy</em>, where having a positive test result from a disease whose base incidence rate is tiny gives a low probability of actually having the disease.</p>
<p>The key to answer the question is based on understanding the difference between the probability of having the disease given a positive result, <span class="math inline">\(P(\text{disease}|+)\)</span>, versus the probability of a positive result given the disease, <span class="math inline">\(P(+|\text{disease})\)</span>. The former is the important result, and the Bayes’ rule helps us to get the answer. Using the Bayes’ rule (equation <a href="sec11.html#eq:111">(1.1)</a>):</p>
<p><span class="math display">\[\begin{equation}
  P(\text{disease}|+) = \frac{P(+|\text{disease})\times P(\text{disease})}{P(+)},
\end{equation}\]</span></p>
<p>where <span class="math inline">\(P(+)=P(+|\text{disease})\times P(\text{disease})+P(+|\lnot\text{disease})\times P( \lnot\text{disease})\)</span>,<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a></p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="sec11.html#cb1-1"></a>PD &lt;-<span class="st"> </span><span class="fl">0.002</span> <span class="co"># Probability of disease</span></span>
<span id="cb1-2"><a href="sec11.html#cb1-2"></a>PPD &lt;-<span class="st"> </span><span class="fl">0.98</span> <span class="co"># True positive (Sensitivity)</span></span>
<span id="cb1-3"><a href="sec11.html#cb1-3"></a>PDP &lt;-<span class="st"> </span>PD <span class="op">*</span><span class="st"> </span>PPD <span class="op">/</span><span class="st"> </span>(PD <span class="op">*</span><span class="st"> </span>PPD <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>PD) <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>PPD)) <span class="co"># Probability of disease given positive</span></span>
<span id="cb1-4"><a href="sec11.html#cb1-4"></a><span class="kw">paste</span>(<span class="st">&quot;Probability of disease given a positive test is&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot; &quot;</span>, <span class="kw">round</span>(PDP, <span class="dv">2</span>))</span></code></pre></div>
<pre><code>## [1] &quot;Probability of disease given a positive test is 0.09&quot;</code></pre>
<p>We observe that despite of having a positive result, the probability of having the disease is low. This due to the base rate being tiny.</p>
<p>Another interesting example, which is at the heart of the origin of the Bayes’ theorem <span class="citation">(Bayes <a href="#ref-bayes1763lii" role="doc-biblioref">1763</a>)</span>, is related to the existence of God <span class="citation">(Stigler <a href="#ref-stigler2018richard" role="doc-biblioref">2018</a>)</span>. The Section X of David Hume’s “An Enquiry concerning Human Understanding, 1748” is named <em>Of Miracles</em>. There, Hume argues that when someone claims to have seen a miracle, this is poor evidence it actually happened, since it goes against what we see every day. Then, Richard Price, who actually finished and published “An essay towards solving a problem in the doctrine of chances” in 1763 after Bayes died in 1761, argues against Hume saying that there is a huge difference between <em>impossibility</em> as used commonly in conversation and <em>physical impossibility</em>. Price used an example of a die with a million sides, where the former is getting a particular side when throwing this die, and the latter is getting a side that does not exist. In millions throws, the latter case never would occur, but the former eventually would.</p>
<p>Let’s say that there are two cases of resurrection (Res), Jesus Christ and Elvis, and the total number of people who have ever lived is 108.5 trillion,<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a> then the prior base rate is 2/108,500,000,000. On the other hand, the sample information comes from a very reliable witness whose true positive rate is 0.9999999. Then, <strong>what is the probability of this miracle?</strong><a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a></p>
<p>Using the Bayes’ rule:</p>
<p><span class="math display">\[\begin{equation}
  P(\text{Res}|\text{Witness}) = \frac{P(\text{Witness}|\text{Res})\times P(\text{Res})}{P(\text{Witness})},
\end{equation}\]</span></p>
<p>where <span class="math inline">\(P(\text{Witness})=P(\text{Witness}|\text{Res})\times P(\text{Res})+(1-P(\text{Witness}|\text{Res}))\times (1-P(\text{Res}))\)</span>,</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="sec11.html#cb3-1"></a>PR &lt;-<span class="st"> </span><span class="dv">2</span><span class="op">/</span><span class="dv">108500000000</span> <span class="co"># Probability of resurrection</span></span>
<span id="cb3-2"><a href="sec11.html#cb3-2"></a>PWR &lt;-<span class="st"> </span><span class="fl">0.9999999</span> <span class="co"># Very reliable witness (true positive rate)</span></span>
<span id="cb3-3"><a href="sec11.html#cb3-3"></a>PRW &lt;-<span class="st"> </span>PR <span class="op">*</span><span class="st"> </span>PWR <span class="op">/</span><span class="st"> </span>(PR <span class="op">*</span><span class="st"> </span>PWR <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>PR) <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>PWR)) <span class="co"># Probability of resurrection given witness</span></span>
<span id="cb3-4"><a href="sec11.html#cb3-4"></a><span class="kw">paste</span>(<span class="st">&quot;Probability of resurrection given witness is&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot; &quot;</span>, PRW)</span></code></pre></div>
<pre><code>## [1] &quot;Probability of resurrection given witness is 0.000184297806959661&quot;</code></pre>
<p>Observe that we can get a conditional version of the Bayes’ rule. Let’s have two conditioning events <span class="math inline">\(B\)</span> and <span class="math inline">\(C\)</span>, then equation <a href="sec11.html#eq:111">(1.1)</a> becomes</p>
<p><span class="math display" id="eq:112">\[\begin{align}
  P(A_i|B,C)&amp;=\frac{P(A_i,B,C)}{P(B,C)}\\
        &amp;=\frac{P(B|A_i,C) \times P(A_i|C) \times P(C)}{P(B|C)P(C)},
  \tag{1.2}
\end{align}\]</span></p>
<p>Let’s use one of the most intriguing statistical puzzles, <strong>the Monty Hall problem</strong>, to illustrate how to use equation <a href="sec11.html#eq:112">(1.2)</a>(<span class="citation">(Selvin <a href="#ref-selvin1975problem" role="doc-biblioref">1975</a><a href="#ref-selvin1975problem" role="doc-biblioref">a</a>)</span>, <span class="citation">(Selvin <a href="#ref-selvin1975bproblem" role="doc-biblioref">1975</a><a href="#ref-selvin1975bproblem" role="doc-biblioref">b</a>)</span>). This was the situation faced by a contestant in the American television game show <em>Let’s Make a Deal</em>. There, the contestant was asked to choose a door where behind one door there is a car, and behind the others, goats. Let’s say that the contestant picks door No. 1, and the host (Monty Hall), who knows what is behind each door, opens door No. 3, where there is a goat. Then, the host asks the tricky question to the contestant, <strong>do you want to pick door No. 2?</strong></p>
<p>Let’s name <span class="math inline">\(P_i\)</span> the event <em>contestant picks door No. <span class="math inline">\(i\)</span></em>, <span class="math inline">\(H_i\)</span> the event <em>host picks door No. <span class="math inline">\(i\)</span></em>, and <span class="math inline">\(C_i\)</span> the event <em>car is behind door No. <span class="math inline">\(i\)</span></em>. In this particular setting, the contestant is interested in the probability of the event <span class="math inline">\(P(C_2|H_3,P_1)\)</span>. A naive answer would be that it is irrelevant as initially <span class="math inline">\(P(C_i)=1/3, \ i=1,2,3\)</span>, and now <span class="math inline">\(P(C_i|H_3)=1/2, \ i=1,2\)</span> as the host opened door No. 3. So, why bothering changing the initial guess if the odds are the same? The important point here is that the host knows what is behind each door and randomly picks a door given contestant choice. That is, <span class="math inline">\(P(H_3|C_3,P_1)=0\)</span>, <span class="math inline">\(P(H_3|C_2,P_1)=1\)</span> and <span class="math inline">\(P(H_3|C_1,P_1)=1/2\)</span>. Then, using equation <a href="sec11.html#eq:112">(1.2)</a></p>
<p><span class="math display">\[\begin{align}
  P(C_2|H_3,P_1)&amp;= \frac{P(C_2,H_3,P_1)}{P(H_3,P_1)}\\
                &amp;= \frac{P(H_3|C_2,P_1)P(C_2|P_1)P(P_1)}{P(H_3|P_1)\times P(P_1)}\\
                &amp;= \frac{P(H_3|C_2,P_1)P(C_2)}{P(H_3|P_1)}\\
                &amp;=\frac{1\times 1/3}{1/2}\\
                &amp;=\frac{2}{3},
\end{align}\]</span>
where the third equation uses the fact that <span class="math inline">\(C_i\)</span> and <span class="math inline">\(P_i\)</span> are independent events, and <span class="math inline">\(P(H_3|P_1)=1/2\)</span> due to this depending just on <span class="math inline">\(P_1\)</span> (not on <span class="math inline">\(C_2\)</span>).</p>
<p>Therefore, changing the initial decision increases the probability of getting the car from 1/3 to 2/3!</p>
<p>Let’s see a simulation exercise to check this answer:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="sec11.html#cb5-1"></a><span class="kw">set.seed</span>(<span class="dv">0101</span>) <span class="co"># Set simulation seed</span></span>
<span id="cb5-2"><a href="sec11.html#cb5-2"></a>S &lt;-<span class="st"> </span><span class="dv">100000</span> <span class="co"># Simulations</span></span>
<span id="cb5-3"><a href="sec11.html#cb5-3"></a>Game &lt;-<span class="st"> </span><span class="cf">function</span>(<span class="dt">switch =</span> <span class="dv">0</span>){</span>
<span id="cb5-4"><a href="sec11.html#cb5-4"></a>  <span class="co"># switch = 0 is not change, and switch = 1 is to change</span></span>
<span id="cb5-5"><a href="sec11.html#cb5-5"></a>  opts &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">:</span><span class="dv">3</span> </span>
<span id="cb5-6"><a href="sec11.html#cb5-6"></a>  car &lt;-<span class="st"> </span><span class="kw">sample</span>(opts, <span class="dv">1</span>) <span class="co"># car location</span></span>
<span id="cb5-7"><a href="sec11.html#cb5-7"></a>  guess1 &lt;-<span class="st"> </span><span class="kw">sample</span>(opts, <span class="dv">1</span>) <span class="co"># Initial guess pick</span></span>
<span id="cb5-8"><a href="sec11.html#cb5-8"></a>  </span>
<span id="cb5-9"><a href="sec11.html#cb5-9"></a>  <span class="cf">if</span>(car <span class="op">!=</span><span class="st"> </span>guess1) {</span>
<span id="cb5-10"><a href="sec11.html#cb5-10"></a>    host &lt;-<span class="st"> </span>opts[<span class="op">-</span><span class="kw">c</span>(car, guess1)]</span>
<span id="cb5-11"><a href="sec11.html#cb5-11"></a>    } <span class="cf">else</span> {</span>
<span id="cb5-12"><a href="sec11.html#cb5-12"></a>    host &lt;-<span class="st"> </span><span class="kw">sample</span>(opts[<span class="op">-</span><span class="kw">c</span>(car, guess1)], <span class="dv">1</span>)</span>
<span id="cb5-13"><a href="sec11.html#cb5-13"></a>    }</span>
<span id="cb5-14"><a href="sec11.html#cb5-14"></a>  </span>
<span id="cb5-15"><a href="sec11.html#cb5-15"></a>  win1 &lt;-<span class="st"> </span>guess1 <span class="op">==</span><span class="st"> </span>car <span class="co"># Win given no change</span></span>
<span id="cb5-16"><a href="sec11.html#cb5-16"></a>  </span>
<span id="cb5-17"><a href="sec11.html#cb5-17"></a>  guess2 &lt;-<span class="st"> </span>opts[<span class="op">-</span><span class="kw">c</span>(host, guess1)]</span>
<span id="cb5-18"><a href="sec11.html#cb5-18"></a>  </span>
<span id="cb5-19"><a href="sec11.html#cb5-19"></a>  win2 &lt;-<span class="st"> </span>guess2 <span class="op">==</span><span class="st"> </span>car <span class="co"># Win given change</span></span>
<span id="cb5-20"><a href="sec11.html#cb5-20"></a>  </span>
<span id="cb5-21"><a href="sec11.html#cb5-21"></a>  <span class="cf">if</span>(<span class="cf">switch</span> <span class="op">==</span><span class="st"> </span><span class="dv">0</span>){</span>
<span id="cb5-22"><a href="sec11.html#cb5-22"></a>    win &lt;-<span class="st"> </span>win1</span>
<span id="cb5-23"><a href="sec11.html#cb5-23"></a>  } <span class="cf">else</span> {</span>
<span id="cb5-24"><a href="sec11.html#cb5-24"></a>      win &lt;-<span class="st"> </span>win2</span>
<span id="cb5-25"><a href="sec11.html#cb5-25"></a>    }</span>
<span id="cb5-26"><a href="sec11.html#cb5-26"></a>  </span>
<span id="cb5-27"><a href="sec11.html#cb5-27"></a>  <span class="kw">return</span>(win)</span>
<span id="cb5-28"><a href="sec11.html#cb5-28"></a>}</span>
<span id="cb5-29"><a href="sec11.html#cb5-29"></a></span>
<span id="cb5-30"><a href="sec11.html#cb5-30"></a>Prob &lt;-<span class="st"> </span><span class="kw">mean</span>(<span class="kw">replicate</span>(S, <span class="kw">Game</span>(<span class="dt">switch =</span> <span class="dv">0</span>))) <span class="co">#Win probabilities not changing</span></span>
<span id="cb5-31"><a href="sec11.html#cb5-31"></a><span class="kw">paste</span>(<span class="st">&quot;Winning probabilities no changing door is&quot;</span>, Prob, <span class="dt">sep =</span> <span class="st">&quot; &quot;</span>)</span></code></pre></div>
<pre><code>## [1] &quot;Winning probabilities no changing door is 0.3334&quot;</code></pre>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="sec11.html#cb7-1"></a>Prob &lt;-<span class="st"> </span><span class="kw">mean</span>(<span class="kw">replicate</span>(S, <span class="kw">Game</span>(<span class="dt">switch =</span> <span class="dv">1</span>))) <span class="co">#Win probabilities changing</span></span>
<span id="cb7-2"><a href="sec11.html#cb7-2"></a><span class="kw">paste</span>(<span class="st">&quot;Winning probabilities changing door is&quot;</span>, Prob, <span class="dt">sep =</span> <span class="st">&quot; &quot;</span>)</span></code></pre></div>
<pre><code>## [1] &quot;Winning probabilities changing door is 0.6654&quot;</code></pre>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-bayes1763lii">
<p>Bayes, Thomas. 1763. “LII. An Essay Towards Solving a Problem in the Doctrine of Chances. By the Late Rev. Mr. Bayes, Frs Communicated by Mr. Price, in a Letter to John Canton, Amfr S.” <em>Philosophical Transactions of the Royal Society of London</em>, no. 53: 370–418.</p>
</div>
<div id="ref-selvin1975problem">
<p>Selvin, Steve. 1975a. “A Problem in Probability (Letter to the Editor).” <em>The American Statistician</em> 11 (1): 67–71.</p>
</div>
<div id="ref-selvin1975bproblem">
<p>Selvin, Steve. 1975b. “A Problem in Probability (Letter to the Editor).” <em>The American Statistician</em> 11 (3): 131–34.</p>
</div>
<div id="ref-stigler2018richard">
<p>Stigler, Stephen. 2018. “Richard Price, the First Bayesian.” <em>Statistical Science</em> 33 (1): 117–25.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p>Observe that I use the term “Bayes’ rule” rather than "Bayes’ theorem. It was Laplace <span class="citation">(Laplace <a href="#ref-laplace1774memoire" role="doc-biblioref">1774</a>)</span> who actually generalized the Bayes’ theorem <span class="citation">(Bayes <a href="#ref-bayes1763lii" role="doc-biblioref">1763</a>)</span>. His generalization is named the Bayes’ rule.<a href="sec11.html#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p><span class="math inline">\(\lnot\)</span> is the negation symbol.<a href="sec11.html#fnref2" class="footnote-back">↩︎</a></p></li>
<li id="fn3"><p><a href="https://www.wolframalpha.com/input/?i=number+of+people+who+have+ever+lived+on+Earth" class="uri">https://www.wolframalpha.com/input/?i=number+of+people+who+have+ever+lived+on+Earth</a><a href="sec11.html#fnref3" class="footnote-back">↩︎</a></p></li>
<li id="fn4"><p><a href="https://www.r-bloggers.com/2019/04/base-rate-fallacy-or-why-no-one-is-justified-to-believe-that-jesus-rose/" class="uri">https://www.r-bloggers.com/2019/04/base-rate-fallacy-or-why-no-one-is-justified-to-believe-that-jesus-rose/</a><a href="sec11.html#fnref4" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="basics.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="sec12.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/aramir21/IntroductionBayesianEconometricsBook/01-Basics.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
