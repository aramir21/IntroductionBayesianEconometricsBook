<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>4.1 Motivation of conjugate families | Introduction to Bayesian Econometrics</title>
  <meta name="description" content="The subject of this textbook is Bayesian regression analysis, and its main aim is to provide introductory level theory foundation, and facilitate applicability of Bayesian inference." />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="4.1 Motivation of conjugate families | Introduction to Bayesian Econometrics" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="The subject of this textbook is Bayesian regression analysis, and its main aim is to provide introductory level theory foundation, and facilitate applicability of Bayesian inference." />
  <meta name="github-repo" content="https://github.com/aramir21/IntroductionBayesianEconometricsBook" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="4.1 Motivation of conjugate families | Introduction to Bayesian Econometrics" />
  
  <meta name="twitter:description" content="The subject of this textbook is Bayesian regression analysis, and its main aim is to provide introductory level theory foundation, and facilitate applicability of Bayesian inference." />
  

<meta name="author" content="Andrés Ramírez-Hassan" />


<meta name="date" content="2021-03-10" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="conjfam.html"/>
<link rel="next" href="sec41.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>



<link rel="stylesheet" href="css\style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Introduction to Bayesian Econometrics: A GUIded tour</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction</a><ul>
<li class="chapter" data-level="" data-path="to-instructors-and-students.html"><a href="to-instructors-and-students.html"><i class="fa fa-check"></i>To instructors and students</a></li>
<li class="chapter" data-level="" data-path="a-brief-presentation-of-r-software.html"><a href="a-brief-presentation-of-r-software.html"><i class="fa fa-check"></i>A brief presentation of R software</a></li>
<li class="chapter" data-level="" data-path="acknowledgments.html"><a href="acknowledgments.html"><i class="fa fa-check"></i>Acknowledgments</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="basics.html"><a href="basics.html"><i class="fa fa-check"></i><b>1</b> Basic formal concepts</a><ul>
<li class="chapter" data-level="1.1" data-path="sec11.html"><a href="sec11.html"><i class="fa fa-check"></i><b>1.1</b> The Bayes’ rule</a></li>
<li class="chapter" data-level="1.2" data-path="sec12.html"><a href="sec12.html"><i class="fa fa-check"></i><b>1.2</b> Bayesian framework: A brief summary of theory</a></li>
<li class="chapter" data-level="1.3" data-path="sec13.html"><a href="sec13.html"><i class="fa fa-check"></i><b>1.3</b> Bayesian reports: Decision theory under uncertainty</a></li>
<li class="chapter" data-level="1.4" data-path="summary.html"><a href="summary.html"><i class="fa fa-check"></i><b>1.4</b> Summary</a></li>
<li class="chapter" data-level="1.5" data-path="exercises-chapter-1.html"><a href="exercises-chapter-1.html"><i class="fa fa-check"></i><b>1.5</b> Exercises: Chapter 1</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="bayfre.html"><a href="bayfre.html"><i class="fa fa-check"></i><b>2</b> Conceptual differences between the Bayesian and the Frequentist statistical approaches</a><ul>
<li class="chapter" data-level="2.1" data-path="sec21.html"><a href="sec21.html"><i class="fa fa-check"></i><b>2.1</b> The concept of probability</a></li>
<li class="chapter" data-level="2.2" data-path="sec22.html"><a href="sec22.html"><i class="fa fa-check"></i><b>2.2</b> Subjectivity is not the key</a></li>
<li class="chapter" data-level="2.3" data-path="sec23.html"><a href="sec23.html"><i class="fa fa-check"></i><b>2.3</b> Estimation, hypothesis testing and prediction</a></li>
<li class="chapter" data-level="2.4" data-path="sec24.html"><a href="sec24.html"><i class="fa fa-check"></i><b>2.4</b> The likelihood principle</a></li>
<li class="chapter" data-level="2.5" data-path="sec25.html"><a href="sec25.html"><i class="fa fa-check"></i><b>2.5</b> Logic of argumentation</a></li>
<li class="chapter" data-level="2.6" data-path="sec26.html"><a href="sec26.html"><i class="fa fa-check"></i><b>2.6</b> Summary</a></li>
<li class="chapter" data-level="2.7" data-path="exercises-chapter-2.html"><a href="exercises-chapter-2.html"><i class="fa fa-check"></i><b>2.7</b> Exercises: Chapter 2</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="objsub.html"><a href="objsub.html"><i class="fa fa-check"></i><b>3</b> Objective and subjective Bayesian approaches</a><ul>
<li class="chapter" data-level="3.1" data-path="sec31.html"><a href="sec31.html"><i class="fa fa-check"></i><b>3.1</b> Objective Bayesians</a></li>
<li class="chapter" data-level="3.2" data-path="empirical-bayes.html"><a href="empirical-bayes.html"><i class="fa fa-check"></i><b>3.2</b> Empirical Bayes</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="conjfam.html"><a href="conjfam.html"><i class="fa fa-check"></i><b>4</b> Basic statistical models: Conjugate families</a><ul>
<li class="chapter" data-level="4.1" data-path="motivation-of-conjugate-families.html"><a href="motivation-of-conjugate-families.html"><i class="fa fa-check"></i><b>4.1</b> Motivation of conjugate families</a></li>
<li class="chapter" data-level="4.2" data-path="sec41.html"><a href="sec41.html"><i class="fa fa-check"></i><b>4.2</b> Beta-Bernoulli family</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="sim.html"><a href="sim.html"><i class="fa fa-check"></i><b>5</b> Simulation methods</a></li>
<li class="chapter" data-level="6" data-path="unireg.html"><a href="unireg.html"><i class="fa fa-check"></i><b>6</b> Univariate regression</a></li>
<li class="chapter" data-level="7" data-path="multi.html"><a href="multi.html"><i class="fa fa-check"></i><b>7</b> Multivariate regression</a></li>
<li class="chapter" data-level="8" data-path="time.html"><a href="time.html"><i class="fa fa-check"></i><b>8</b> Time series</a></li>
<li class="chapter" data-level="9" data-path="longi.html"><a href="longi.html"><i class="fa fa-check"></i><b>9</b> Longitudinal regression</a></li>
<li class="chapter" data-level="10" data-path="diag.html"><a href="diag.html"><i class="fa fa-check"></i><b>10</b> Convergence diagnostics</a></li>
<li class="chapter" data-level="11" data-path="bma.html"><a href="bma.html"><i class="fa fa-check"></i><b>11</b> Bayesian model averaging</a></li>
<li class="chapter" data-level="12" data-path="nonpara.html"><a href="nonpara.html"><i class="fa fa-check"></i><b>12</b> Nonparametric regression</a></li>
<li class="chapter" data-level="13" data-path="recent.html"><a href="recent.html"><i class="fa fa-check"></i><b>13</b> Recent developments</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i>Appendix</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to Bayesian Econometrics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="motivation-of-conjugate-families" class="section level2">
<h2><span class="header-section-number">4.1</span> Motivation of conjugate families</h2>
<p>Observing three fundamental pieces of Bayesian analysis: the posterior distribution (parameter inference), the marginal likelihood (hypothesis testing), and the predictive distribution (prediction), equations <a href="motivation-of-conjugate-families.html#eq:411">(4.1)</a>, <a href="motivation-of-conjugate-families.html#eq:412">(4.2)</a> and <a href="motivation-of-conjugate-families.html#eq:413">(4.3)</a>, respectively,</p>
<p><span class="math display" id="eq:411">\[\begin{align}
  \pi(\mathbf{\theta}|\mathbf{y})&amp;=\frac{p(\mathbf{y}|\mathbf{\theta}) \times \pi(\mathbf{\theta})}{p(\mathbf{y})},
  \tag{4.1}
\end{align}\]</span></p>
<p><span class="math display" id="eq:412">\[\begin{equation}
p(\mathbf{y})=\int_{\mathbf{\Theta}}p(\mathbf{y}|\mathbf{\theta})\pi(\mathbf{\theta})d\mathbf{\theta},
\tag{4.2}
\end{equation}\]</span></p>
<p>and</p>
<p><span class="math display" id="eq:413">\[\begin{equation}
p(\mathbf{Y}_0|\mathbf{y})=\int_{\mathbf{\Theta}}p(\mathbf{Y}_0|\mathbf{\theta})\pi(\mathbf{\theta}|\mathbf{y})d\mathbf{\theta},
\tag{4.3}
\end{equation}\]</span></p>
<p>we can understand that some of the initial limitations of the application of the Bayesian analysis were associated with the ausence of algorithms to draw from non-standard posterior distributions (equation <a href="motivation-of-conjugate-families.html#eq:411">(4.1)</a>), and the lack of analytical solutions of the marginal likelihood (equation <a href="motivation-of-conjugate-families.html#eq:412">(4.2)</a>) and the predictive distribution (equation <a href="motivation-of-conjugate-families.html#eq:413">(4.3)</a>). Both issues requiring computational power.</p>
<p>Although there were algorithms to sample from non-standard posterior distributions since the second half of the last century <span class="citation">(Metropolis et al. <a href="#ref-metropolis53" role="doc-biblioref">1953</a>)</span><span class="citation">(Hastings <a href="#ref-hastings70" role="doc-biblioref">1970</a>)</span>,<span class="citation">(Geman and Geman <a href="#ref-Geman1984" role="doc-biblioref">1984</a>)</span>, their particular application in the Bayesian framework emerged later <span class="citation">(Gelfand and Smith <a href="#ref-Gelfand1990" role="doc-biblioref">1990</a>)</span>,<span class="citation">(Tierney <a href="#ref-tierney1994markov" role="doc-biblioref">1994</a>)</span>, maybe until increasing computational power of desktop computers. However, it is also common practice nowadays to use models that have standard conditional posterior distributions to mitigate computational requirements. In addition, nice mathematical tricks plus computational algorithms <span class="citation">(Gelfand and Dey <a href="#ref-gelfand1994bayesian" role="doc-biblioref">1994</a>)</span>, <span class="citation">(Chib <a href="#ref-chib1995marginal" role="doc-biblioref">1995</a>)</span>,<span class="citation">(Chib and Jeliazkov <a href="#ref-chib2001marginal" role="doc-biblioref">2001</a>)</span> and approximations <span class="citation">(Tierney and Kadane <a href="#ref-Tierney1986" role="doc-biblioref">1986</a>)</span><span class="citation">(Jordan and Saul <a href="#ref-Jordan1999" role="doc-biblioref">1999</a>)</span> are used to obtain the marginal likelihood (prior predictive).</p>
<p>Despite these advances, there are two potentially conflicting desirable model specification features that we can see from equations <a href="motivation-of-conjugate-families.html#eq:411">(4.1)</a>, <a href="motivation-of-conjugate-families.html#eq:412">(4.2)</a> and <a href="motivation-of-conjugate-families.html#eq:413">(4.3)</a>: analytical solutions and the posterior distribution in the same family as the prior distribution for a given likelihood. The latter is called <em>conjugate priors</em>, a family of priors that is closed under sampling <span class="citation">(Schlaifer and Raiffa <a href="#ref-schlaifer1961applied" role="doc-biblioref">1961</a>, 43–57)</span>.</p>
<p>These features are desirable as the former implies facility to perform hypothesis testing and predictive analysis, and the latter means invariance of the prior-to-posterior updating. Both feautures imply less computational burden.</p>
<p>We can easily achieve each of these features independenly, for instance using improper priors for analytical tractability, and defining in a broad sense the family of prior distributions for prior conjugacy. However, these are in conflict.</p>
<p>Fortunately, we can achieve these two nice features if we assume that the data generating process is given by a distribution function in the <em>exponential family</em>. That is, given a random sample <span class="math inline">\(\mathbf{y}=[y_1,y_2,\dots,y_N]^{\top}\)</span>, a probability density function <span class="math inline">\(p(\mathbf{y}|\mathbf{\theta})\)</span> belongs to the exponential family if it has the form</p>
<p><span class="math display">\[\begin{equation}
  p(\mathbf{y}|\mathbf{\theta})=h(\mathbf{y})\exp\left\{\eta(\mathbf{\theta})^{\top}\mathbf{T}(\mathbf{y})-A(\mathbf{\theta})\right\},
\end{equation}\]</span></p>
<p>where <span class="math inline">\(A(\mathbf{\theta})=\log\left(\int_{\mathbf{Y}}h(\mathbf{y})\exp\left\{\eta(\mathbf{\theta})^{\top}\mathbf{T}(\mathbf{y}))d\mathbf{y}\right\}\right)\)</span> is a normalization factor that differenting helps to obtain the moments (mean, variance, etc.) of the sufficient statistic vector of the distribution (<span class="math inline">\(\mathbf{T}(\mathbf{y})\)</span>), <span class="math inline">\(h(\mathbf{y})\)</span> is a non-negative function, and <span class="math inline">\(\eta(\mathbf{\theta})\)</span> is known function of the parameters.</p>
<p>If we set <span class="math inline">\(\eta=\eta(\mathbf{\theta})\)</span>, then the exponential family is said to be in the <em>canonical form</em></p>
<p><span class="math display">\[\begin{equation}
  p(\mathbf{y}|\mathbf{\theta})=h(\mathbf{y})\exp\left\{\eta^{\top}\mathbf{T}(\mathbf{y})-B(\mathbf{\eta})\right\}.
\end{equation}\]</span></p>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-chib1995marginal">
<p>Chib, Siddhartha. 1995. “Marginal Likelihood from the Gibbs Output.” <em>Journal of the American Statistical Association</em> 90 (432): 1313–21.</p>
</div>
<div id="ref-chib2001marginal">
<p>Chib, Siddhartha, and Ivan Jeliazkov. 2001. “Marginal Likelihood from the Metropolis–Hastings Output.” <em>Journal of the American Statistical Association</em> 96 (453): 270–81.</p>
</div>
<div id="ref-Gelfand1990">
<p>Gelfand, A. E., and A. F. M. Smith. 1990. “Sampling-Based Approaches to Calculating Marginal Densities.” <em>Journal of the American Statistical Association</em> 85: 398–409.</p>
</div>
<div id="ref-gelfand1994bayesian">
<p>Gelfand, Alan E, and Dipak K Dey. 1994. “Bayesian Model Choice: Asymptotics and Exact Calculations.” <em>Journal of the Royal Statistical Society: Series B (Methodological)</em> 56 (3): 501–14.</p>
</div>
<div id="ref-Geman1984">
<p>Geman, S, and D. Geman. 1984. “Stochastic Relaxation, Gibbs Distributions and the Bayesian Restoration of Images.” <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em> 6: 721–41.</p>
</div>
<div id="ref-hastings70">
<p>Hastings, W. 1970. “Monte Carlo Sampling Methods Using Markov Chains and Their Application.” <em>Biometrika</em> 57: 97–109.</p>
</div>
<div id="ref-Jordan1999">
<p>Jordan, Ghahramani, M. I., and L. Saul. 1999. “Introduction to Variational Methods for Graphical Models.” <em>Machine Learning</em> 37: 183–233.</p>
</div>
<div id="ref-metropolis53">
<p>Metropolis, N., A. Rosenbluth, M. Rosenbluth, A. Teller, and E. Teller. 1953. “Equations of State Calculations by Fast Computing Machines.” <em>J. Chem. Phys</em> 21: 1087–92.</p>
</div>
<div id="ref-schlaifer1961applied">
<p>Schlaifer, Robert, and Howard Raiffa. 1961. <em>Applied Statistical Decision Theory</em>.</p>
</div>
<div id="ref-tierney1994markov">
<p>Tierney, Luke. 1994. “Markov Chains for Exploring Posterior Distributions.” <em>The Annals of Statistics</em>, 1701–28.</p>
</div>
<div id="ref-Tierney1986">
<p>Tierney, Luke, and Joseph B Kadane. 1986. “Accurate Approximations for Posterior Moments and Marginal Densities.” <em>Journal of the American Statistical Association</em> 81 (393): 82–86.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="conjfam.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="sec41.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/aramir21/IntroductionBayesianEconometricsBook/04-Conjugate.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
