<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>13.3 Conditional independence assumption (CIA) | Introduction to Bayesian Econometrics</title>
  <meta name="description" content="The subject of this textbook is Bayesian data modeling, with the primary aim of providing an introduction to its theoretical foundations and facilitating the application of Bayesian inference using a GUI." />
  <meta name="generator" content="bookdown 0.43 and GitBook 2.6.7" />

  <meta property="og:title" content="13.3 Conditional independence assumption (CIA) | Introduction to Bayesian Econometrics" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="The subject of this textbook is Bayesian data modeling, with the primary aim of providing an introduction to its theoretical foundations and facilitating the application of Bayesian inference using a GUI." />
  <meta name="github-repo" content="https://github.com/aramir21/IntroductionBayesianEconometricsBook" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="13.3 Conditional independence assumption (CIA) | Introduction to Bayesian Econometrics" />
  
  <meta name="twitter:description" content="The subject of this textbook is Bayesian data modeling, with the primary aim of providing an introduction to its theoretical foundations and facilitating the application of Bayesian inference using a GUI." />
  

<meta name="author" content="Andrés Ramírez-Hassan" />


<meta name="date" content="2025-09-18" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="sec13_2.html"/>
<link rel="next" href="sec13_4.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Introduction to Bayesian Econometrics: A GUIded tour using R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction</a>
<ul>
<li class="chapter" data-level="" data-path="to-instructors-and-students.html"><a href="to-instructors-and-students.html"><i class="fa fa-check"></i>To instructors and students</a></li>
<li class="chapter" data-level="" data-path="acknowledgments.html"><a href="acknowledgments.html"><i class="fa fa-check"></i>Acknowledgments</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="Chap1.html"><a href="Chap1.html"><i class="fa fa-check"></i><b>1</b> Basic formal concepts</a>
<ul>
<li class="chapter" data-level="1.1" data-path="sec11.html"><a href="sec11.html"><i class="fa fa-check"></i><b>1.1</b> The Bayes’ rule</a></li>
<li class="chapter" data-level="1.2" data-path="sec12.html"><a href="sec12.html"><i class="fa fa-check"></i><b>1.2</b> Bayesian framework: A brief summary of theory</a></li>
<li class="chapter" data-level="1.3" data-path="sec14.html"><a href="sec14.html"><i class="fa fa-check"></i><b>1.3</b> Bayesian reports: Decision theory under uncertainty</a></li>
<li class="chapter" data-level="1.4" data-path="summary.html"><a href="summary.html"><i class="fa fa-check"></i><b>1.4</b> Summary</a></li>
<li class="chapter" data-level="1.5" data-path="exercises.html"><a href="exercises.html"><i class="fa fa-check"></i><b>1.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="Chap2.html"><a href="Chap2.html"><i class="fa fa-check"></i><b>2</b> Conceptual differences between the Bayesian and Frequentist approaches</a>
<ul>
<li class="chapter" data-level="2.1" data-path="sec21.html"><a href="sec21.html"><i class="fa fa-check"></i><b>2.1</b> The concept of probability</a></li>
<li class="chapter" data-level="2.2" data-path="sec22.html"><a href="sec22.html"><i class="fa fa-check"></i><b>2.2</b> Subjectivity is not the key</a></li>
<li class="chapter" data-level="2.3" data-path="sec23.html"><a href="sec23.html"><i class="fa fa-check"></i><b>2.3</b> Estimation, hypothesis testing and prediction</a></li>
<li class="chapter" data-level="2.4" data-path="sec24.html"><a href="sec24.html"><i class="fa fa-check"></i><b>2.4</b> The likelihood principle</a></li>
<li class="chapter" data-level="2.5" data-path="sec25.html"><a href="sec25.html"><i class="fa fa-check"></i><b>2.5</b> Why is not the Bayesian approach that popular?</a></li>
<li class="chapter" data-level="2.6" data-path="sec26.html"><a href="sec26.html"><i class="fa fa-check"></i><b>2.6</b> A simple working example</a></li>
<li class="chapter" data-level="2.7" data-path="sec27.html"><a href="sec27.html"><i class="fa fa-check"></i><b>2.7</b> Summary</a></li>
<li class="chapter" data-level="2.8" data-path="sec28.html"><a href="sec28.html"><i class="fa fa-check"></i><b>2.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="Chap3.html"><a href="Chap3.html"><i class="fa fa-check"></i><b>3</b> Cornerstone models: Conjugate families</a>
<ul>
<li class="chapter" data-level="3.1" data-path="sec41.html"><a href="sec41.html"><i class="fa fa-check"></i><b>3.1</b> Motivation of conjugate families</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="sec41.html"><a href="sec41.html#examples-of-exponential-family-distributions"><i class="fa fa-check"></i><b>3.1.1</b> Examples of exponential family distributions</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="sec42.html"><a href="sec42.html"><i class="fa fa-check"></i><b>3.2</b> Conjugate prior to exponential family</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="sec42.html"><a href="sec42.html#sec421"><i class="fa fa-check"></i><b>3.2.1</b> Examples: Theorem 4.2.1</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="sec43.html"><a href="sec43.html"><i class="fa fa-check"></i><b>3.3</b> Linear regression: The conjugate normal-normal/inverse gamma model</a></li>
<li class="chapter" data-level="3.4" data-path="sec44.html"><a href="sec44.html"><i class="fa fa-check"></i><b>3.4</b> Multivariate linear regression: The conjugate normal-normal/inverse Wishart model</a></li>
<li class="chapter" data-level="3.5" data-path="sec45.html"><a href="sec45.html"><i class="fa fa-check"></i><b>3.5</b> Summary</a></li>
<li class="chapter" data-level="3.6" data-path="sec46.html"><a href="sec46.html"><i class="fa fa-check"></i><b>3.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="Chap4.html"><a href="Chap4.html"><i class="fa fa-check"></i><b>4</b> Simulation methods</a>
<ul>
<li class="chapter" data-level="4.1" data-path="sec51.html"><a href="sec51.html"><i class="fa fa-check"></i><b>4.1</b> Markov Chain Monte Carlo methods</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="sec51.html"><a href="sec51.html#sec511"><i class="fa fa-check"></i><b>4.1.1</b> Gibbs sampler</a></li>
<li class="chapter" data-level="4.1.2" data-path="sec51.html"><a href="sec51.html#sec512"><i class="fa fa-check"></i><b>4.1.2</b> Metropolis-Hastings</a></li>
<li class="chapter" data-level="4.1.3" data-path="sec51.html"><a href="sec51.html#sec513"><i class="fa fa-check"></i><b>4.1.3</b> Hamiltonian Monte Carlo</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="sec52.html"><a href="sec52.html"><i class="fa fa-check"></i><b>4.2</b> Importance sampling</a></li>
<li class="chapter" data-level="4.3" data-path="sec53.html"><a href="sec53.html"><i class="fa fa-check"></i><b>4.3</b> Particle filtering</a></li>
<li class="chapter" data-level="4.4" data-path="sec54.html"><a href="sec54.html"><i class="fa fa-check"></i><b>4.4</b> Convergence diagnostics</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="sec54.html"><a href="sec54.html#numerical-standard-error"><i class="fa fa-check"></i><b>4.4.1</b> Numerical standard error</a></li>
<li class="chapter" data-level="4.4.2" data-path="sec54.html"><a href="sec54.html#effective-number-of-simulation-draws"><i class="fa fa-check"></i><b>4.4.2</b> Effective number of simulation draws</a></li>
<li class="chapter" data-level="4.4.3" data-path="sec54.html"><a href="sec54.html#tests-of-convergence"><i class="fa fa-check"></i><b>4.4.3</b> Tests of convergence</a></li>
<li class="chapter" data-level="4.4.4" data-path="sec54.html"><a href="sec54.html#checking-for-errors-in-the-posterior-simulator"><i class="fa fa-check"></i><b>4.4.4</b> Checking for errors in the posterior simulator</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="sec55.html"><a href="sec55.html"><i class="fa fa-check"></i><b>4.5</b> Summary</a></li>
<li class="chapter" data-level="4.6" data-path="sec56.html"><a href="sec56.html"><i class="fa fa-check"></i><b>4.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="Chap5.html"><a href="Chap5.html"><i class="fa fa-check"></i><b>5</b> Graphical user interface</a>
<ul>
<li class="chapter" data-level="5.1" data-path="secGUI1.html"><a href="secGUI1.html"><i class="fa fa-check"></i><b>5.1</b> Introduction</a></li>
<li class="chapter" data-level="5.2" data-path="secGUI2.html"><a href="secGUI2.html"><i class="fa fa-check"></i><b>5.2</b> Univariate models</a></li>
<li class="chapter" data-level="5.3" data-path="secGUI3.html"><a href="secGUI3.html"><i class="fa fa-check"></i><b>5.3</b> Multivariate models</a></li>
<li class="chapter" data-level="5.4" data-path="secGUI4.html"><a href="secGUI4.html"><i class="fa fa-check"></i><b>5.4</b> Time series models</a></li>
<li class="chapter" data-level="5.5" data-path="secGUI5.html"><a href="secGUI5.html"><i class="fa fa-check"></i><b>5.5</b> Longitudinal/panel models</a></li>
<li class="chapter" data-level="5.6" data-path="secGUI6.html"><a href="secGUI6.html"><i class="fa fa-check"></i><b>5.6</b> Bayesian model average</a></li>
<li class="chapter" data-level="5.7" data-path="secGUI7.html"><a href="secGUI7.html"><i class="fa fa-check"></i><b>5.7</b> Help</a></li>
<li class="chapter" data-level="5.8" data-path="secGUI8.html"><a href="secGUI8.html"><i class="fa fa-check"></i><b>5.8</b> Warning</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="Chap6.html"><a href="Chap6.html"><i class="fa fa-check"></i><b>6</b> Univariate regression</a>
<ul>
<li class="chapter" data-level="6.1" data-path="sec61.html"><a href="sec61.html"><i class="fa fa-check"></i><b>6.1</b> The Gaussian linear model</a></li>
<li class="chapter" data-level="6.2" data-path="sec62.html"><a href="sec62.html"><i class="fa fa-check"></i><b>6.2</b> The logit model</a></li>
<li class="chapter" data-level="6.3" data-path="sec63.html"><a href="sec63.html"><i class="fa fa-check"></i><b>6.3</b> The probit model</a></li>
<li class="chapter" data-level="6.4" data-path="sec64.html"><a href="sec64.html"><i class="fa fa-check"></i><b>6.4</b> The multinomial probit model</a></li>
<li class="chapter" data-level="6.5" data-path="sec65.html"><a href="sec65.html"><i class="fa fa-check"></i><b>6.5</b> The multinomial logit model</a></li>
<li class="chapter" data-level="6.6" data-path="sec66.html"><a href="sec66.html"><i class="fa fa-check"></i><b>6.6</b> Ordered probit model</a></li>
<li class="chapter" data-level="6.7" data-path="negative-binomial-model.html"><a href="negative-binomial-model.html"><i class="fa fa-check"></i><b>6.7</b> Negative binomial model</a></li>
<li class="chapter" data-level="6.8" data-path="sec68.html"><a href="sec68.html"><i class="fa fa-check"></i><b>6.8</b> Tobit model</a></li>
<li class="chapter" data-level="6.9" data-path="sec69.html"><a href="sec69.html"><i class="fa fa-check"></i><b>6.9</b> Quantile regression</a></li>
<li class="chapter" data-level="6.10" data-path="sec610.html"><a href="sec610.html"><i class="fa fa-check"></i><b>6.10</b> Bayesian bootstrap regression</a></li>
<li class="chapter" data-level="6.11" data-path="sec611.html"><a href="sec611.html"><i class="fa fa-check"></i><b>6.11</b> Summary</a></li>
<li class="chapter" data-level="6.12" data-path="sec612.html"><a href="sec612.html"><i class="fa fa-check"></i><b>6.12</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="Chap7.html"><a href="Chap7.html"><i class="fa fa-check"></i><b>7</b> Multivariate regression</a>
<ul>
<li class="chapter" data-level="7.1" data-path="sec71.html"><a href="sec71.html"><i class="fa fa-check"></i><b>7.1</b> Multivariate regression</a></li>
<li class="chapter" data-level="7.2" data-path="sec72.html"><a href="sec72.html"><i class="fa fa-check"></i><b>7.2</b> Seemingly Unrelated Regression</a></li>
<li class="chapter" data-level="7.3" data-path="sec73.html"><a href="sec73.html"><i class="fa fa-check"></i><b>7.3</b> Instrumental variable</a></li>
<li class="chapter" data-level="7.4" data-path="sec74.html"><a href="sec74.html"><i class="fa fa-check"></i><b>7.4</b> Multivariate probit model</a></li>
<li class="chapter" data-level="7.5" data-path="sec75.html"><a href="sec75.html"><i class="fa fa-check"></i><b>7.5</b> Summary</a></li>
<li class="chapter" data-level="7.6" data-path="sec76.html"><a href="sec76.html"><i class="fa fa-check"></i><b>7.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="Chap8.html"><a href="Chap8.html"><i class="fa fa-check"></i><b>8</b> Time series</a>
<ul>
<li class="chapter" data-level="8.1" data-path="sec81.html"><a href="sec81.html"><i class="fa fa-check"></i><b>8.1</b> State-space representation</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="sec81.html"><a href="sec81.html#gaussian-linear-state-space-models"><i class="fa fa-check"></i><b>8.1.1</b> Gaussian linear state-space models</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="sec82.html"><a href="sec82.html"><i class="fa fa-check"></i><b>8.2</b> ARMA processes</a></li>
<li class="chapter" data-level="8.3" data-path="sec83.html"><a href="sec83.html"><i class="fa fa-check"></i><b>8.3</b> Stochastic volatility models</a></li>
<li class="chapter" data-level="8.4" data-path="sec84.html"><a href="sec84.html"><i class="fa fa-check"></i><b>8.4</b> Vector Autoregressive models</a></li>
<li class="chapter" data-level="8.5" data-path="sec85.html"><a href="sec85.html"><i class="fa fa-check"></i><b>8.5</b> Summary</a></li>
<li class="chapter" data-level="8.6" data-path="sec86.html"><a href="sec86.html"><i class="fa fa-check"></i><b>8.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="Chap9.html"><a href="Chap9.html"><i class="fa fa-check"></i><b>9</b> Longitudinal regression</a>
<ul>
<li class="chapter" data-level="9.1" data-path="sec91.html"><a href="sec91.html"><i class="fa fa-check"></i><b>9.1</b> Normal model</a></li>
<li class="chapter" data-level="9.2" data-path="sec92.html"><a href="sec92.html"><i class="fa fa-check"></i><b>9.2</b> Logit model</a></li>
<li class="chapter" data-level="9.3" data-path="sec93.html"><a href="sec93.html"><i class="fa fa-check"></i><b>9.3</b> Poisson model</a></li>
<li class="chapter" data-level="9.4" data-path="sec94.html"><a href="sec94.html"><i class="fa fa-check"></i><b>9.4</b> Summary</a></li>
<li class="chapter" data-level="9.5" data-path="sec95.html"><a href="sec95.html"><i class="fa fa-check"></i><b>9.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="Chap10.html"><a href="Chap10.html"><i class="fa fa-check"></i><b>10</b> Bayesian model averaging in variable selection</a>
<ul>
<li class="chapter" data-level="10.1" data-path="sec10_1.html"><a href="sec10_1.html"><i class="fa fa-check"></i><b>10.1</b> Foundation</a></li>
<li class="chapter" data-level="10.2" data-path="sec102.html"><a href="sec102.html"><i class="fa fa-check"></i><b>10.2</b> The Gaussian linear model</a></li>
<li class="chapter" data-level="10.3" data-path="sec103.html"><a href="sec103.html"><i class="fa fa-check"></i><b>10.3</b> Generalized linear models</a></li>
<li class="chapter" data-level="10.4" data-path="sec10_4.html"><a href="sec10_4.html"><i class="fa fa-check"></i><b>10.4</b> Calculating the marginal likelihood</a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="sec10_4.html"><a href="sec10_4.html#sec10_4_1"><i class="fa fa-check"></i><b>10.4.1</b> Savage-Dickey density ratio</a></li>
<li class="chapter" data-level="10.4.2" data-path="sec10_4.html"><a href="sec10_4.html#sec10_4_2"><i class="fa fa-check"></i><b>10.4.2</b> Chib’s methods</a></li>
<li class="chapter" data-level="10.4.3" data-path="sec10_4.html"><a href="sec10_4.html#sec10_4_3"><i class="fa fa-check"></i><b>10.4.3</b> Gelfand-Dey method</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="sec10_5.html"><a href="sec10_5.html"><i class="fa fa-check"></i><b>10.5</b> Summary</a></li>
<li class="chapter" data-level="10.6" data-path="sec10_6.html"><a href="sec10_6.html"><i class="fa fa-check"></i><b>10.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="Chap11.html"><a href="Chap11.html"><i class="fa fa-check"></i><b>11</b> Semi-parametric and non-parametric models</a>
<ul>
<li class="chapter" data-level="11.1" data-path="sec11_1.html"><a href="sec11_1.html"><i class="fa fa-check"></i><b>11.1</b> Mixture models</a>
<ul>
<li class="chapter" data-level="11.1.1" data-path="sec11_1.html"><a href="sec11_1.html#sec11_11"><i class="fa fa-check"></i><b>11.1.1</b> Finite Gaussian mixtures</a></li>
<li class="chapter" data-level="11.1.2" data-path="sec11_1.html"><a href="sec11_1.html#sec11_12"><i class="fa fa-check"></i><b>11.1.2</b> Direchlet processes</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="sec11_2.html"><a href="sec11_2.html"><i class="fa fa-check"></i><b>11.2</b> Splines</a></li>
<li class="chapter" data-level="11.3" data-path="sec11_3.html"><a href="sec11_3.html"><i class="fa fa-check"></i><b>11.3</b> Summary</a></li>
<li class="chapter" data-level="11.4" data-path="sec11_4.html"><a href="sec11_4.html"><i class="fa fa-check"></i><b>11.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="Chap12.html"><a href="Chap12.html"><i class="fa fa-check"></i><b>12</b> Bayesian machine learning</a>
<ul>
<li class="chapter" data-level="12.1" data-path="sec12_1.html"><a href="sec12_1.html"><i class="fa fa-check"></i><b>12.1</b> Cross-validation and Bayes factors</a></li>
<li class="chapter" data-level="12.2" data-path="sec12_2.html"><a href="sec12_2.html"><i class="fa fa-check"></i><b>12.2</b> Regularization</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="sec12_2.html"><a href="sec12_2.html#sec12_21"><i class="fa fa-check"></i><b>12.2.1</b> Bayesian LASSO</a></li>
<li class="chapter" data-level="12.2.2" data-path="sec12_2.html"><a href="sec12_2.html#sec12_22"><i class="fa fa-check"></i><b>12.2.2</b> Stochastic search variable selection</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="sec12_3.html"><a href="sec12_3.html"><i class="fa fa-check"></i><b>12.3</b> Bayesian additive regression trees</a></li>
<li class="chapter" data-level="12.4" data-path="sec12_4.html"><a href="sec12_4.html"><i class="fa fa-check"></i><b>12.4</b> Gaussian processes</a></li>
<li class="chapter" data-level="12.5" data-path="sec12_5.html"><a href="sec12_5.html"><i class="fa fa-check"></i><b>12.5</b> Tall data problems</a>
<ul>
<li class="chapter" data-level="12.5.1" data-path="sec12_5.html"><a href="sec12_5.html#sec12_51"><i class="fa fa-check"></i><b>12.5.1</b> Divide-and-conquer methods</a></li>
<li class="chapter" data-level="12.5.2" data-path="sec12_5.html"><a href="sec12_5.html#sec12_52"><i class="fa fa-check"></i><b>12.5.2</b> Subsampling-based algorithms</a></li>
</ul></li>
<li class="chapter" data-level="12.6" data-path="id_13_6.html"><a href="id_13_6.html"><i class="fa fa-check"></i><b>12.6</b> Summary</a></li>
<li class="chapter" data-level="12.7" data-path="id_13_7.html"><a href="id_13_7.html"><i class="fa fa-check"></i><b>12.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="Chap13.html"><a href="Chap13.html"><i class="fa fa-check"></i><b>13</b> Causal inference</a>
<ul>
<li class="chapter" data-level="13.1" data-path="sec13_1.html"><a href="sec13_1.html"><i class="fa fa-check"></i><b>13.1</b> Identification setting</a></li>
<li class="chapter" data-level="13.2" data-path="sec13_2.html"><a href="sec13_2.html"><i class="fa fa-check"></i><b>13.2</b> Randomized controlled trial (RCT)</a></li>
<li class="chapter" data-level="13.3" data-path="sec13_3.html"><a href="sec13_3.html"><i class="fa fa-check"></i><b>13.3</b> Conditional independence assumption (CIA)</a></li>
<li class="chapter" data-level="13.4" data-path="sec13_4.html"><a href="sec13_4.html"><i class="fa fa-check"></i><b>13.4</b> Instrumental variables (IV)</a></li>
<li class="chapter" data-level="13.5" data-path="sec13_5.html"><a href="sec13_5.html"><i class="fa fa-check"></i><b>13.5</b> Difference-in-differences design (DiD)</a>
<ul>
<li class="chapter" data-level="13.5.1" data-path="sec13_5.html"><a href="sec13_5.html#sec13_51"><i class="fa fa-check"></i><b>13.5.1</b> Classic DiD: two-group and two-period (<span class="math inline">\(2\times2\)</span>) setup</a></li>
<li class="chapter" data-level="13.5.2" data-path="sec13_5.html"><a href="sec13_5.html#sec13_52"><i class="fa fa-check"></i><b>13.5.2</b> Staggered (SDiD): G-group and T-period (<span class="math inline">\(G\times T\)</span>) setup</a></li>
</ul></li>
<li class="chapter" data-level="13.6" data-path="sec13_6.html"><a href="sec13_6.html"><i class="fa fa-check"></i><b>13.6</b> Regression discontinuity design (RD)</a>
<ul>
<li class="chapter" data-level="13.6.1" data-path="sec13_6.html"><a href="sec13_6.html#sec13_61"><i class="fa fa-check"></i><b>13.6.1</b> Sharp regression discontinuity design (SRD)</a></li>
<li class="chapter" data-level="13.6.2" data-path="sec13_6.html"><a href="sec13_6.html#sec13_62"><i class="fa fa-check"></i><b>13.6.2</b> Fuzzy regression discontinuity design (FRD)</a></li>
</ul></li>
<li class="chapter" data-level="13.7" data-path="sec13_7.html"><a href="sec13_7.html"><i class="fa fa-check"></i><b>13.7</b> Sample selection</a></li>
<li class="chapter" data-level="13.8" data-path="sec13_8.html"><a href="sec13_8.html"><i class="fa fa-check"></i><b>13.8</b> Bayesian exponentially tilted empirical likelihood</a></li>
<li class="chapter" data-level="13.9" data-path="sec13_10.html"><a href="sec13_10.html"><i class="fa fa-check"></i><b>13.9</b> Doubly robust Bayesian inferential framework (DRB)</a></li>
<li class="chapter" data-level="13.10" data-path="sec13_11.html"><a href="sec13_11.html"><i class="fa fa-check"></i><b>13.10</b> Summary</a></li>
<li class="chapter" data-level="13.11" data-path="sec13_12.html"><a href="sec13_12.html"><i class="fa fa-check"></i><b>13.11</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="Chap14.html"><a href="Chap14.html"><i class="fa fa-check"></i><b>14</b> Approximate Bayesian methods</a>
<ul>
<li class="chapter" data-level="14.1" data-path="sec14_1.html"><a href="sec14_1.html"><i class="fa fa-check"></i><b>14.1</b> Simulation-based approaches</a>
<ul>
<li class="chapter" data-level="14.1.1" data-path="sec14_1.html"><a href="sec14_1.html#sec14_11"><i class="fa fa-check"></i><b>14.1.1</b> Approximate Bayesian computation</a></li>
<li class="chapter" data-level="14.1.2" data-path="sec14_1.html"><a href="sec14_1.html#sec14_12"><i class="fa fa-check"></i><b>14.1.2</b> Bayesian synthetic likelihood</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="sec14_2.html"><a href="sec14_2.html"><i class="fa fa-check"></i><b>14.2</b> Optimization approaches</a>
<ul>
<li class="chapter" data-level="14.2.1" data-path="sec14_2.html"><a href="sec14_2.html#sec14_21"><i class="fa fa-check"></i><b>14.2.1</b> Integrated nested Laplace approximations</a></li>
<li class="chapter" data-level="14.2.2" data-path="sec14_2.html"><a href="sec14_2.html#sec14_22"><i class="fa fa-check"></i><b>14.2.2</b> Variational Bayes</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="summary-1.html"><a href="summary-1.html"><i class="fa fa-check"></i><b>14.3</b> Summary</a></li>
<li class="chapter" data-level="14.4" data-path="sec14_4.html"><a href="sec14_4.html"><i class="fa fa-check"></i><b>14.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i>Appendix</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to Bayesian Econometrics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="sec13_3" class="section level2 hasAnchor" number="13.3">
<h2><span class="header-section-number">13.3</span> Conditional independence assumption (CIA)<a href="sec13_3.html#sec13_3" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In practice, researchers often work with <em>observational data</em>, where the treatment status is not randomly assigned because units actively choose the treatment they receive. In an RCT, the assignment mechanism is determined by chance, whereas in observational studies it is driven by choice. In these situations, we can identify the causal effect if the <em>conditional independence assumption</em> (CIA) holds. This assumption states that the potential outcomes are independent of the treatment status, conditional on a set of observed <em>pre-treatment variables</em>:
<span class="math display">\[
\{ Y_i(1), Y_i(0) \} \perp D_i \mid \mathbf{X}_i.
\]</span></p>
<p>This means that, conditional on the <em>pre-treatment variables</em> <span class="math inline">\(\mathbf{X}_i\)</span>, treatment assignment is as good as random. This property is known as <em>unconfoundedness given</em> <span class="math inline">\(\mathbf{X}_i\)</span>, or equivalently, the <em>no unmeasured confounders</em> assumption. When this condition is combined with the requirement that, for all possible values of <span class="math inline">\(\mathbf{X}_i\)</span>, there is a positive probability of receiving each treatment level (<span class="math inline">\(0 &lt; P(D_i = 1 \mid \mathbf{X}_i) &lt; 1\)</span>), the joint condition is referred to as <em>strong ignorability</em>. Identification of average causal effects in this setting also requires the SUTVA.</p>
<p>Note that under the CIA,
<span class="math display" id="eq:CIA-ate">\[\begin{align}
\text{ATE} &amp;= \mathbb{E}[Y_i(1)] - \mathbb{E}[Y_i(0)] \\
&amp;= \mathbb{E}_{\mathbf{X}}\left\{ \mathbb{E}[Y_i(1)\mid \mathbf{X}_i] - \mathbb{E}[Y_i(0)\mid \mathbf{X}_i] \right\} \\
&amp;= \mathbb{E}_{\mathbf{X}}\left\{ \mathbb{E}[Y_i(1)\mid \mathbf{X}_i, D_i=1] - \mathbb{E}[Y_i(0)\mid \mathbf{X}_i, D_i=0] \right\} \\
&amp;= \mathbb{E}_{\mathbf{X}}\left\{ \mathbb{E}[Y_i\mid \mathbf{X}_i, D_i=1] - \mathbb{E}[Y_i\mid \mathbf{X}_i, D_i=0] \right\} \\
&amp;= \mathbb{E}_{\mathbf{X}}\left\{ \tau(\mathbf{X}_i) \right\},
\tag{13.1}
\end{align}\]</span></p>
<p>where the second equality follows from the law of iterated expectations, the third uses CIA, and
<span class="math display">\[
\tau(\mathbf{X}_i) = \mathbb{E}[Y_i \mid \mathbf{X}_i, D_i=1] - \mathbb{E}[Y_i \mid \mathbf{X}_i, D_i=0]
\]</span>
is the <em>conditional average treatment effect</em> (CATE) at covariate value <span class="math inline">\(\mathbf{X}_i\)</span>, which captures treatment effect heterogeneity across different values of <span class="math inline">\(\mathbf{X}\)</span>. Therefore, the ATE is the expectation of the CATE over the distribution of <span class="math inline">\(\mathbf{X}\)</span>.</p>
<p>The foolowing figure illustrates the causal structure underlying the CIA. We follow the convention that time flows from left to right. Here, <span class="math inline">\(\mathbf{X}\)</span> —a vector of pre-treatment variables or <em>confounders</em>— influences both the treatment (<span class="math inline">\(D\)</span>) and the outcome (<span class="math inline">\(Y\)</span>). Under the CIA, we can identify the causal effect of <span class="math inline">\(D\)</span> on <span class="math inline">\(Y\)</span> by adjusting for <span class="math inline">\(\mathbf{X}\)</span> because this causal structure satisfies the <em>back-door criterion</em>. This criterion states that a set of variables <span class="math inline">\(\mathbf{X}\)</span> satisfies the condition for identifying the effect of <span class="math inline">\(D\)</span> on <span class="math inline">\(Y\)</span> if no variable in <span class="math inline">\(\mathbf{X}\)</span> is a descendant of <span class="math inline">\(D\)</span> and <span class="math inline">\(\mathbf{X}\)</span> blocks every back-door path from <span class="math inline">\(D\)</span> to <span class="math inline">\(Y\)</span>. A <em>back-door path</em> is any path from <span class="math inline">\(D\)</span> to <span class="math inline">\(Y\)</span> that begins with an arrow pointing into <span class="math inline">\(D\)</span>.</p>
<p>In Exercise 3, we ask to construct the DAG of the following figure, verify that it is acyclic, and check whether the causal effect of <span class="math inline">\(D\)</span> on <span class="math inline">\(Y\)</span> is identifiable by controlling for <span class="math inline">\(\mathbf{X}\)</span> using the package <em>dagitty</em>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:unnamed-chunk-4"></span>
<img src="figures/FigChap13_3.png" alt="Directed Acyclic Graph (DAG) implied by the Conditional Independence Assumption (CIA)." width="300px" />
<p class="caption">
Figure 13.3: Directed Acyclic Graph (DAG) implied by the Conditional Independence Assumption (CIA).
</p>
</div>
<p>This figure displays the SWIG.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:unnamed-chunk-5"></span>
<img src="figures/FigChap13_4.png" alt="*Single-World Intervention Graph (SWIG) for $do(D=d)$*: The treatment $D$ is split into the fixed intervention $D=d$ and its natural value. The outcome is replaced by $Y(d)$. $X$ still influences $Y(d)$, so adjustment for $X$ is needed for identification." width="300px" />
<p class="caption">
Figure 13.4: <em>Single-World Intervention Graph (SWIG) for <span class="math inline">\(do(D=d)\)</span></em>: The treatment <span class="math inline">\(D\)</span> is split into the fixed intervention <span class="math inline">\(D=d\)</span> and its natural value. The outcome is replaced by <span class="math inline">\(Y(d)\)</span>. <span class="math inline">\(X\)</span> still influences <span class="math inline">\(Y(d)\)</span>, so adjustment for <span class="math inline">\(X\)</span> is needed for identification.
</p>
</div>
<p>The simple regression framework of the previous section can be extended to a multiple linear regression model by including the <em>pre-treatment variables</em>; therefore, the CEF is linear in the treatment and pre-treatment variables:
<span class="math display">\[
Y_i = \beta_0 + \tau D_i + \mathbf{X}_i^{\top}\boldsymbol{\beta} + \mu_i.
\]</span></p>
<p>Note that, by assumption in RCTs, <span class="math inline">\(D_i\)</span> and <span class="math inline">\(\mathbf{X}_i\)</span> are independent. Thus, the identification of <span class="math inline">\(\tau\)</span> is not affected under random assignment; however, including <span class="math inline">\(\mathbf{X}_i\)</span> helps explain part of the variability in <span class="math inline">\(Y_i\)</span>, thereby improving the precision of the estimates.</p>
<p>On the other hand, if the CIA is satisfied, the error term in the linear regression is defined as
<span class="math display">\[
\mu_i = Y_i(0) - \mathbb{E}[Y_i(0) \mid \mathbf{X}_i].
\]</span></p>
<p>Thus,
<span class="math display">\[
\mathbb{E}[\mu_i \mid D_i, \mathbf{X}_i]
= \mathbb{E}[Y_i(0) - \mathbb{E}[Y_i(0) \mid \mathbf{X}_i] \mid D_i, \mathbf{X}_i]
= \mathbb{E}[Y_i(0) \mid D_i, \mathbf{X}_i] - \mathbb{E}[Y_i(0) \mid \mathbf{X}_i].
\]</span></p>
<p>By the CIA, <span class="math inline">\(Y_i(0) \perp D_i \mid \mathbf{X}_i\)</span>, so:
<span class="math display">\[
\mathbb{E}[Y_i(0) \mid D_i, \mathbf{X}_i] = \mathbb{E}[Y_i(0) \mid \mathbf{X}_i].
\]</span></p>
<p>Therefore:
<span class="math display">\[\begin{equation*}
\mathbb{E}[\mu_i \mid D_i, \mathbf{X}_i] = 0
\end{equation*}\]</span></p>
<p>This condition is known as <em>conditional mean independence</em>: after controlling for <span class="math inline">\(\mathbf{X}_i\)</span>, treatment assignment is independent of unobserved determinants of the outcome. It justifies unbiased estimation of <span class="math inline">\(\tau\)</span> by regression adjustment in observational studies.</p>
<p><strong>Example: Treatment effect of 401(k) eligibility on net financial assets</strong></p>
<p>We study the average treatment effect of eligibility (<em>e401</em>) for participation in the 401(k) retirement savings plan in the United States on net financial assets (<em>net_tfa</em>) using the dataset <em>401k.csv</em>. The rationale for the exogeneity of 401(k) eligibility is that it becomes exogenous after conditioning on observable characteristics related to job choice, which may correlate with whether a firm offers this retirement plan <span class="citation">(<a href="#ref-chernozhukov2024applied">Chernozhukov et al. 2024</a>)</span>.</p>
<p>Accordingly, we control for the following covariates: age (<em>age</em>), income (<em>inc</em>), family size (<em>fsize</em>), years of education (<em>educ</em>), a marital status indicator (<em>marr</em>), a two-earner status indicator (<em>twoearn</em>), a defined benefit pension status indicator (<em>db</em>), an IRA participation indicator (<em>pira</em>), and a home ownership indicator (<em>hown</em>). Under this specification, the key assumption is that eligibility is conditionally independent of net financial assets given these covariates <span class="citation">(<a href="#ref-chernozhukov2024applied">Chernozhukov et al. 2024</a>)</span>.</p>
<p>We can use the framework in Section <a href="sec61.html#sec61">6.1</a> to estimate the average treatment effect of 401(k) eligibility on net financial assets. The following code shows how to obtain the posterior distribution of this effect. The figure displays the posterior distribution of the treatment effect: the 95% credible interval is (USD 3,473, USD 8,371), and the posterior mean is USD 5,903.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="sec13_3.html#cb2-1" tabindex="-1"></a><span class="co"># 401k: Treatment effects</span></span>
<span id="cb2-2"><a href="sec13_3.html#cb2-2" tabindex="-1"></a><span class="fu">rm</span>(<span class="at">list =</span> <span class="fu">ls</span>())</span>
<span id="cb2-3"><a href="sec13_3.html#cb2-3" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">10101</span>)</span>
<span id="cb2-4"><a href="sec13_3.html#cb2-4" tabindex="-1"></a></span>
<span id="cb2-5"><a href="sec13_3.html#cb2-5" tabindex="-1"></a><span class="fu">library</span>(MCMCpack)</span>
<span id="cb2-6"><a href="sec13_3.html#cb2-6" tabindex="-1"></a><span class="fu">library</span>(coda)</span>
<span id="cb2-7"><a href="sec13_3.html#cb2-7" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb2-8"><a href="sec13_3.html#cb2-8" tabindex="-1"></a></span>
<span id="cb2-9"><a href="sec13_3.html#cb2-9" tabindex="-1"></a>mydata <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">&quot;https://raw.githubusercontent.com/BEsmarter-consultancy/BSTApp/refs/heads/master/DataApp/401k.csv&quot;</span>, <span class="at">sep =</span> <span class="st">&quot;,&quot;</span>, <span class="at">header =</span> <span class="cn">TRUE</span>, <span class="at">quote =</span> <span class="st">&quot;&quot;</span>)</span>
<span id="cb2-10"><a href="sec13_3.html#cb2-10" tabindex="-1"></a><span class="fu">attach</span>(mydata )</span>
<span id="cb2-11"><a href="sec13_3.html#cb2-11" tabindex="-1"></a>y <span class="ot">&lt;-</span> net_tfa </span>
<span id="cb2-12"><a href="sec13_3.html#cb2-12" tabindex="-1"></a><span class="co"># net_tfa: net financial assets</span></span>
<span id="cb2-13"><a href="sec13_3.html#cb2-13" tabindex="-1"></a><span class="co"># Regressors quantity including intercept</span></span>
<span id="cb2-14"><a href="sec13_3.html#cb2-14" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">cbind</span>(e401, age, inc, fsize, educ, marr, twoearn, db, pira, hown, <span class="dv">1</span>)</span>
<span id="cb2-15"><a href="sec13_3.html#cb2-15" tabindex="-1"></a><span class="co"># e401: 401k eligibility </span></span>
<span id="cb2-16"><a href="sec13_3.html#cb2-16" tabindex="-1"></a><span class="co"># age, income, family size, years of education, marital status indicator, two-earner status indicator, defined benefit pension status indicator, IRA participation indicator, and home ownership indicator.</span></span>
<span id="cb2-17"><a href="sec13_3.html#cb2-17" tabindex="-1"></a></span>
<span id="cb2-18"><a href="sec13_3.html#cb2-18" tabindex="-1"></a><span class="co"># Posterior distributions using packages: MCMCpack sets the model in terms of the precision matrix. We use default parameters</span></span>
<span id="cb2-19"><a href="sec13_3.html#cb2-19" tabindex="-1"></a>posterior  <span class="ot">&lt;-</span> MCMCpack<span class="sc">::</span><span class="fu">MCMCregress</span>(y<span class="sc">~</span>X<span class="dv">-1</span>)</span>
<span id="cb2-20"><a href="sec13_3.html#cb2-20" tabindex="-1"></a><span class="fu">summary</span>(coda<span class="sc">::</span><span class="fu">mcmc</span>(posterior))</span>
<span id="cb2-21"><a href="sec13_3.html#cb2-21" tabindex="-1"></a></span>
<span id="cb2-22"><a href="sec13_3.html#cb2-22" tabindex="-1"></a><span class="co"># Extract posterior samples for e401 (first coefficient)</span></span>
<span id="cb2-23"><a href="sec13_3.html#cb2-23" tabindex="-1"></a>beta_e401 <span class="ot">&lt;-</span> posterior[, <span class="dv">1</span>]</span>
<span id="cb2-24"><a href="sec13_3.html#cb2-24" tabindex="-1"></a></span>
<span id="cb2-25"><a href="sec13_3.html#cb2-25" tabindex="-1"></a><span class="co"># Convert to data frame for ggplot</span></span>
<span id="cb2-26"><a href="sec13_3.html#cb2-26" tabindex="-1"></a>df_posterior <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(beta_e401)</span>
<span id="cb2-27"><a href="sec13_3.html#cb2-27" tabindex="-1"></a></span>
<span id="cb2-28"><a href="sec13_3.html#cb2-28" tabindex="-1"></a><span class="co"># Plot with ggplot</span></span>
<span id="cb2-29"><a href="sec13_3.html#cb2-29" tabindex="-1"></a><span class="fu">ggplot</span>(df_posterior, <span class="fu">aes</span>(<span class="at">x =</span> beta_e401)) <span class="sc">+</span></span>
<span id="cb2-30"><a href="sec13_3.html#cb2-30" tabindex="-1"></a><span class="fu">geom_density</span>(<span class="at">fill =</span> <span class="st">&quot;steelblue&quot;</span>, <span class="at">alpha =</span> <span class="fl">0.6</span>) <span class="sc">+</span></span>
<span id="cb2-31"><a href="sec13_3.html#cb2-31" tabindex="-1"></a><span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="fu">mean</span>(beta_e401), <span class="at">color =</span> <span class="st">&quot;red&quot;</span>, <span class="at">linetype =</span> <span class="st">&quot;dashed&quot;</span>) <span class="sc">+</span></span>
<span id="cb2-32"><a href="sec13_3.html#cb2-32" tabindex="-1"></a><span class="fu">labs</span>(</span>
<span id="cb2-33"><a href="sec13_3.html#cb2-33" tabindex="-1"></a><span class="at">title =</span> <span class="st">&quot;Posterior Distribution of Treatment Effect (e401)&quot;</span>,</span>
<span id="cb2-34"><a href="sec13_3.html#cb2-34" tabindex="-1"></a><span class="at">x =</span> <span class="fu">expression</span>(beta[e401]),</span>
<span id="cb2-35"><a href="sec13_3.html#cb2-35" tabindex="-1"></a><span class="at">y =</span> <span class="st">&quot;Density&quot;</span></span>
<span id="cb2-36"><a href="sec13_3.html#cb2-36" tabindex="-1"></a>) <span class="sc">+</span></span>
<span id="cb2-37"><a href="sec13_3.html#cb2-37" tabindex="-1"></a><span class="fu">theme_minimal</span>(<span class="at">base_size =</span> <span class="dv">14</span>)</span></code></pre></div>
<p>Observe that the identification strategy relies on conditioning on <span class="math inline">\(\mathbf{X}\)</span>. However, adding more controls is not always safe because some variables, known as <em>bad controls</em>, can introduce bias if included in the adjustment set <span class="citation">(<a href="#ref-angrist2009mostly">Angrist and Pischke 2009</a>)</span>. One important type of bad control is a <em>collider</em>, a variable that is caused by (or is a common effect of) two or more other variables in a DAG. Colliders play a critical role because conditioning on them can create spurious associations between their causes, leading to what is known as <em>collider bias</em> (or selection bias).</p>
<p>The following figure illustrates this situation. Here, <span class="math inline">\(C\)</span> is a common effect of <span class="math inline">\(D\)</span> and <span class="math inline">\(\mathbf{X}\)</span>. Conditioning on <span class="math inline">\(C\)</span> opens an additional path between <span class="math inline">\(D\)</span> and <span class="math inline">\(Y\)</span>, creating a spurious association that violates the back-door criterion. In particular, the variable <span class="math inline">\(C\)</span> is a collider on the path <span class="math inline">\(D \to C \leftarrow \mathbf{X}\)</span>. By default, a collider <em>blocks</em> the flow of association along the path on which it lies, so this path is closed when <span class="math inline">\(C\)</span> is not conditioned on. However, conditioning on <span class="math inline">\(C\)</span> (or on any descendant of <span class="math inline">\(C\)</span>) opens this path, creating a spurious association between <span class="math inline">\(D\)</span> and <span class="math inline">\(\mathbf{X}\)</span>. Since <span class="math inline">\(\mathbf{X}\)</span> also affects <span class="math inline">\(Y\)</span>, this induces bias in estimating the causal effect of <span class="math inline">\(D\)</span> on <span class="math inline">\(Y\)</span>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:unnamed-chunk-7"></span>
<img src="figures/FigChap13_5.png" alt="Directed Acyclic Graph (DAG): The additional collider $C$ caused by both $D$ and $X$ would open a path between $D$ and $X$, inducing bias." width="300px" />
<p class="caption">
Figure 13.5: Directed Acyclic Graph (DAG): The additional collider <span class="math inline">\(C\)</span> caused by both <span class="math inline">\(D\)</span> and <span class="math inline">\(X\)</span> would open a path between <span class="math inline">\(D\)</span> and <span class="math inline">\(X\)</span>, inducing bias.
</p>
</div>
<p><strong>Example: Birth-weight “paradox”, collider bias</strong></p>
<p>The collider bias illustrated in the following DAG, based on <span class="citation">Chernozhukov et al. (<a href="#ref-chernozhukov2024applied">2024</a>)</span>, reflects the well-known Birth-weight “paradox”. This phenomenon arises when conditioning on an intermediate variable (birth weight, <span class="math inline">\(B\)</span>) induces a spurious association between the binary indicator of smoking (<span class="math inline">\(S\)</span>) and infant mortality (<span class="math inline">\(Y\)</span>). In this setting, <span class="math inline">\(U\)</span> represents unobserved factors that affect both birth weight and infant mortality. Conditioning on <span class="math inline">\(B\)</span> creates collider bias because it opens a back-door path through the unobserved factors <span class="math inline">\(U\)</span> (dashed).</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:unnamed-chunk-8"></span>
<img src="figures/FigChap13_6.png" alt="DAG illustrating the birth-weight paradox: $S$ (smoking), $B$ (birth weight), $Y$ (infant mortality), $U$ (other unobserved health factors)." width="250px" />
<p class="caption">
Figure 13.6: DAG illustrating the birth-weight paradox: <span class="math inline">\(S\)</span> (smoking), <span class="math inline">\(B\)</span> (birth weight), <span class="math inline">\(Y\)</span> (infant mortality), <span class="math inline">\(U\)</span> (other unobserved health factors).
</p>
</div>
<p>The following code illustrates the bias by performing 100 replications, and the figure shows the distribution of posterior means across these replications. In this setting, the total effect of smoking on infant mortality is 2, consisting of a direct effect of 1 and an indirect effect through birth weight, also equal to 1.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="sec13_3.html#cb3-1" tabindex="-1"></a><span class="fu">rm</span>(<span class="at">list =</span> <span class="fu">ls</span>()); <span class="fu">set.seed</span>(<span class="dv">10101</span>)</span>
<span id="cb3-2"><a href="sec13_3.html#cb3-2" tabindex="-1"></a><span class="fu">library</span>(MCMCpack); <span class="fu">library</span>(dplyr); <span class="fu">library</span>(ggplot2)</span>
<span id="cb3-3"><a href="sec13_3.html#cb3-3" tabindex="-1"></a><span class="co"># Parameters</span></span>
<span id="cb3-4"><a href="sec13_3.html#cb3-4" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">1000</span>; true_effect <span class="ot">&lt;-</span> <span class="dv">2</span>; replications <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb3-5"><a href="sec13_3.html#cb3-5" tabindex="-1"></a><span class="co"># Store results</span></span>
<span id="cb3-6"><a href="sec13_3.html#cb3-6" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">rep =</span> <span class="dv">1</span><span class="sc">:</span>replications, <span class="at">correct =</span> <span class="fu">numeric</span>(replications), <span class="at">biased =</span> <span class="fu">numeric</span>(replications))</span>
<span id="cb3-7"><a href="sec13_3.html#cb3-7" tabindex="-1"></a></span>
<span id="cb3-8"><a href="sec13_3.html#cb3-8" tabindex="-1"></a><span class="cf">for</span> (r <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>replications) {</span>
<span id="cb3-9"><a href="sec13_3.html#cb3-9" tabindex="-1"></a>    <span class="co"># Simulate data under DAG: S -&gt; B -&gt; Y, S -&gt; Y, U -&gt; B, U -&gt; Y</span></span>
<span id="cb3-10"><a href="sec13_3.html#cb3-10" tabindex="-1"></a>    U <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n, <span class="dv">0</span>, <span class="dv">1</span>); S <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(n, <span class="at">prob =</span> <span class="fl">0.7</span>, <span class="at">size =</span> <span class="dv">1</span>)</span>
<span id="cb3-11"><a href="sec13_3.html#cb3-11" tabindex="-1"></a>    B <span class="ot">&lt;-</span> S <span class="sc">+</span> U <span class="sc">+</span> <span class="fu">rnorm</span>(n)</span>
<span id="cb3-12"><a href="sec13_3.html#cb3-12" tabindex="-1"></a>    Y <span class="ot">&lt;-</span> S <span class="sc">+</span> B <span class="sc">+</span> <span class="fl">1.5</span><span class="sc">*</span>U <span class="sc">+</span> <span class="fu">rnorm</span>(n)</span>
<span id="cb3-13"><a href="sec13_3.html#cb3-13" tabindex="-1"></a>    <span class="co"># Correct model: does NOT condition on collider B</span></span>
<span id="cb3-14"><a href="sec13_3.html#cb3-14" tabindex="-1"></a>    model_correct <span class="ot">&lt;-</span> <span class="fu">MCMCregress</span>(Y <span class="sc">~</span> S, <span class="at">burnin =</span> <span class="dv">1000</span>, <span class="at">mcmc =</span> <span class="dv">3000</span>, <span class="at">verbose =</span> <span class="cn">FALSE</span>)</span>
<span id="cb3-15"><a href="sec13_3.html#cb3-15" tabindex="-1"></a>    <span class="co"># Biased model: conditions on collider B</span></span>
<span id="cb3-16"><a href="sec13_3.html#cb3-16" tabindex="-1"></a>    model_biased <span class="ot">&lt;-</span> <span class="fu">MCMCregress</span>(Y <span class="sc">~</span> S <span class="sc">+</span> B, <span class="at">burnin =</span> <span class="dv">1000</span>, <span class="at">mcmc =</span> <span class="dv">3000</span>, <span class="at">verbose =</span> <span class="cn">FALSE</span>)</span>
<span id="cb3-17"><a href="sec13_3.html#cb3-17" tabindex="-1"></a>    <span class="co"># Posterior means for S</span></span>
<span id="cb3-18"><a href="sec13_3.html#cb3-18" tabindex="-1"></a>    results<span class="sc">$</span>correct[r] <span class="ot">&lt;-</span> <span class="fu">mean</span>(<span class="fu">as.matrix</span>(model_correct)[, <span class="st">&quot;S&quot;</span>])</span>
<span id="cb3-19"><a href="sec13_3.html#cb3-19" tabindex="-1"></a>    results<span class="sc">$</span>biased[r] <span class="ot">&lt;-</span> <span class="fu">mean</span>(<span class="fu">as.matrix</span>(model_biased)[, <span class="st">&quot;S&quot;</span>])</span>
<span id="cb3-20"><a href="sec13_3.html#cb3-20" tabindex="-1"></a>}</span>
<span id="cb3-21"><a href="sec13_3.html#cb3-21" tabindex="-1"></a><span class="co"># Compute bias</span></span>
<span id="cb3-22"><a href="sec13_3.html#cb3-22" tabindex="-1"></a>results <span class="ot">&lt;-</span> results <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(</span>
<span id="cb3-23"><a href="sec13_3.html#cb3-23" tabindex="-1"></a><span class="at">bias_correct =</span> correct <span class="sc">-</span> true_effect,</span>
<span id="cb3-24"><a href="sec13_3.html#cb3-24" tabindex="-1"></a><span class="at">bias_biased =</span> biased <span class="sc">-</span> true_effect</span>
<span id="cb3-25"><a href="sec13_3.html#cb3-25" tabindex="-1"></a>)</span>
<span id="cb3-26"><a href="sec13_3.html#cb3-26" tabindex="-1"></a><span class="co"># Average bias and SD</span></span>
<span id="cb3-27"><a href="sec13_3.html#cb3-27" tabindex="-1"></a>avg_bias <span class="ot">&lt;-</span> results <span class="sc">%&gt;%</span></span>
<span id="cb3-28"><a href="sec13_3.html#cb3-28" tabindex="-1"></a><span class="fu">summarise</span>(</span>
<span id="cb3-29"><a href="sec13_3.html#cb3-29" tabindex="-1"></a><span class="at">mean_correct =</span> <span class="fu">mean</span>(bias_correct),</span>
<span id="cb3-30"><a href="sec13_3.html#cb3-30" tabindex="-1"></a><span class="at">mean_biased =</span> <span class="fu">mean</span>(bias_biased),</span>
<span id="cb3-31"><a href="sec13_3.html#cb3-31" tabindex="-1"></a><span class="at">sd_correct =</span> <span class="fu">sd</span>(bias_correct),</span>
<span id="cb3-32"><a href="sec13_3.html#cb3-32" tabindex="-1"></a><span class="at">sd_biased =</span> <span class="fu">sd</span>(bias_biased)</span>
<span id="cb3-33"><a href="sec13_3.html#cb3-33" tabindex="-1"></a>)</span>
<span id="cb3-34"><a href="sec13_3.html#cb3-34" tabindex="-1"></a><span class="fu">print</span>(avg_bias)</span>
<span id="cb3-35"><a href="sec13_3.html#cb3-35" tabindex="-1"></a><span class="co"># Visualization: distribution of posterior means across 100 simulations</span></span>
<span id="cb3-36"><a href="sec13_3.html#cb3-36" tabindex="-1"></a>df_long <span class="ot">&lt;-</span> results <span class="sc">%&gt;%</span></span>
<span id="cb3-37"><a href="sec13_3.html#cb3-37" tabindex="-1"></a><span class="fu">select</span>(rep, correct, biased) <span class="sc">%&gt;%</span></span>
<span id="cb3-38"><a href="sec13_3.html#cb3-38" tabindex="-1"></a>tidyr<span class="sc">::</span><span class="fu">pivot_longer</span>(<span class="at">cols =</span> <span class="fu">c</span>(correct, biased), <span class="at">names_to =</span> <span class="st">&quot;model&quot;</span>, <span class="at">values_to =</span> <span class="st">&quot;estimate&quot;</span>)</span>
<span id="cb3-39"><a href="sec13_3.html#cb3-39" tabindex="-1"></a></span>
<span id="cb3-40"><a href="sec13_3.html#cb3-40" tabindex="-1"></a><span class="fu">ggplot</span>(df_long, <span class="fu">aes</span>(<span class="at">x =</span> estimate, <span class="at">fill =</span> model)) <span class="sc">+</span> <span class="fu">geom_density</span>(<span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span> <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> true_effect, <span class="at">color =</span> <span class="st">&quot;black&quot;</span>, <span class="at">linetype =</span> <span class="st">&quot;dashed&quot;</span>, <span class="at">linewidth =</span> <span class="dv">1</span>) <span class="sc">+</span> <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Posterior Means Across 100 Simulations&quot;</span>, <span class="at">x =</span> <span class="fu">expression</span>(<span class="fu">paste</span>(<span class="st">&quot;Posterior Mean of &quot;</span>, beta[S])), <span class="at">y =</span> <span class="st">&quot;Density&quot;</span>) <span class="sc">+</span> <span class="fu">theme_minimal</span>(<span class="at">base_size =</span> <span class="dv">14</span>)</span></code></pre></div>
<p>Collider (selection) bias is one possible source of bias in the identification of causal effects. The well-known Heckman’s sample selection problem in econometrics <span class="citation">(<a href="#ref-heckman1979sample">Heckman 1979</a>)</span> can be interpreted as a form of collider bias because restricting the analysis to selected observations (e.g., those with positive wages) conditions on a variable that is a common effect of observed and unobserved factors, thereby opening a non-causal path and creating bias. In other words, the sample is no longer representative of the population, which undermines the identification of the causal effect.</p>
<p>Other well-known sources of bias in econometrics include the omission of common causes affecting both the treatment and the outcome, that is, <em>omission of correlated relevant regressors</em>, measurement error in regressors leading to <em>attenuation bias</em> (where the estimated causal effect is biased toward zero), and <em>simultaneous causality</em>, which often arises in systems of equations (see <span class="citation">Wooldridge (<a href="#ref-wooldridge2010econometric">2010</a>)</span> for details). We will discuss these additional sources of bias later.</p>
</div>
<h3>References<a href="references.html#references" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-angrist2009mostly" class="csl-entry">
Angrist, Joshua D., and Jörn-Steffen Pischke. 2009. <em>Mostly Harmless Econometrics: An Empiricist’s Companion</em>. Princeton, NJ: Princeton University Press.
</div>
<div id="ref-chernozhukov2024applied" class="csl-entry">
Chernozhukov, Victor, Christian Hansen, Nathan Kallus, Martin Spindler, and Vasilis Syrgkanis. 2024. <span>“Applied Causal Inference Powered by ML and AI.”</span> arXiv preprint 2403.02467. arXiv.
</div>
<div id="ref-heckman1979sample" class="csl-entry">
Heckman, James J. 1979. <span>“Sample Selection Bias as a Specification Error.”</span> <em>Econometrica</em> 47 (1): 153–61. <a href="https://doi.org/10.2307/1912352">https://doi.org/10.2307/1912352</a>.
</div>
<div id="ref-wooldridge2010econometric" class="csl-entry">
Wooldridge, Jeffrey M. 2010. <em>Econometric Analysis of Cross Section and Panel Data</em>. MIT press.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="sec13_2.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="sec13_4.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": true,
    "facebook": true,
    "twitter": true,
    "linkedin": false,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": false,
    "all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
  },
  "fontsettings": {
    "theme": "white",
    "family": "sans",
    "size": 2
  },
  "edit": {
    "link": "https://github.com/aramir21/IntroductionBayesianEconometricsBook/10-Diagnostics.Rmd",
    "text": "Edit"
  },
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": null,
    "text": null
  },
  "download": null,
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "subsection"
  }
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
