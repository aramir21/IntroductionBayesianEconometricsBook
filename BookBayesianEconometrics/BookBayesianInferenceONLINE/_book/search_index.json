[["index.html", "Introduction to Bayesian Data Modeling A GUIded toolkit using R Introduction", " Introduction to Bayesian Data Modeling A GUIded toolkit using R Andrés Ramírez-Hassan 2025-02-22 Introduction Since the late 90s, Bayesian inference has gained significant popularity among researchers due to the computational revolution and the availability of algorithms to solve complex integrals. However, many researchers, students, and practitioners still lack a deep understanding and practical application of this inferential approach. The primary reason for this is the requirement for strong programming skills. Introduction to Bayesian Data Modeling: A GUIded Toolkit using R mainly targets those who want to apply Bayesian inference with a solid conceptual and formal understanding but may not have the time to develop programming skills. Thus, this book provides a graphical user interface (GUI) for performing Bayesian regression in a user-friendly environment. It also offers the basic theory and its code implementation using R software (R Core Team, 2021), along with applications that highlight the potential of Bayesian inference. Additionally, the book includes theoretical and computational exercises for those interested in developing more complex models. In particular, the first part presents step-by-step mathematical proofs of basic models, serving as the foundation for deriving key mathematical results in the more complex models covered in the second and third parts. Our GUI is based on an interactive web application using shiny (Chang et al., 2018), along with several packages in R. Users can estimate univariate, multivariate, time series, longitudinal/panel data, and Bayesian model averaging models using our GUI. In addition, it provides basic summaries, as well as formal and graphical diagnostics of the posterior chains. Our GUI can be run on any operating system and is freely available at GitHub. Users can access simulated and real datasets in the folders DataSim and DataApp, respectively. The DataSim folder also includes the files used to simulate different processes, providing access to population parameters. As a result, these files serve as a pedagogical tool for demonstrating various statistical properties. The DataApp folder contains the datasets used in our applications, which users are encouraged to use as templates for structuring their own datasets. This book is divided into three parts: Part One (Chapters 1–4) covers theoretical concepts, mathematical foundations, programming, and simulation. Part Two (Chapters 5–10) focuses on regression applications, with an emphasis on computational methods for obtaining posterior draws at three levels of programming skills: No programming skills required (using our GUI). Intermediate skills (using specialized R packages for Bayesian inference). Advanced skills (coding posterior draws from scratch). Part Three (Chapters 11–14) introduces advanced methods in Bayesian inference. Some mathematical derivations are presented in detail in the first part of the book, while most proofs are omitted in the second and third parts. However, the mathematical steps covered in Part One can be applied to derive results in Parts Two and Three. In the first part, Chapter 1 introduces fundamental concepts in Bayesian inference, starting with Bayes’ rule, its components, formal definitions, and basic examples. It then presents the basics of Bayesian inference within a decision-theoretic framework under uncertainty. Chapter 2 discusses the conceptual differences between Bayesian and Frequentist statistical approaches, providing both a historical and philosophical perspective on Bayesian statistics and econometrics while highlighting contrasts with the Frequentist approach. Chapter 3 introduces conjugate families in basic statistical models, solving them both analytically and computationally. Chapter 4 presents simulation-based methods, which are essential in modern Bayesian inference since most realistic models lack standard forms or analytical solutions. In the second part, Chapter 5 introduces our graphical user interface (GUI). Univariate and multivariate regression models are covered in Chapters 6 and 7. Chapter 8 focuses on univariate and multivariate time series models, while Chapter 9 covers Bayesian longitudinal/panel data models. Chapter 10 introduces Bayesian model averaging. The third part covers advanced topics: - Chapter 11 explores semi-parametric and non-parametric models. - Chapter 12 discusses causal inference. - Chapter 13 covers Bayesian methods in machine learning. - Chapter 14 describes approximation methods. About Me My name is Andrés Ramírez-Hassan, and I am an applied and theoretical econometrician working as a Distinguished Professor in the School of Finance, Economics, and Government at Universidad EAFIT (Medellín, Colombia). I hold a PhD in Statistical Science, a Master’s degree in Finance, a Master’s degree in Economics, and a Bachelor’s degree in Economics. I have been a research fellow at the Department of Econometrics and Business Statistics at Monash University and a visiting professor in the Department of Economics at the University of Melbourne and the University of Glasgow. Since completing my PhD, my research has primarily focused on Bayesian econometrics, with applications in crime, finance, health, sports, and utilities. My work has been published (or is forthcoming) in highly regarded journals, including: International Journal of Forecasting, Journal of Applied Econometrics, Econometric Reviews, Journal of Computational and Graphical Statistics, The R Journal, Economic Modelling, Spatial Economic Analysis, Economic Inquiry, World Development, Journal of Sport Economics, Empirical Economics, Australian and New Zealand Journal of Statistics, Brazilian Journal of Probability and Statistics, among other prestigious international research outlets. I founded BEsmarter — Bayesian Econometrics: simulations, models, and applications to research, teaching, and encoding with responsibility. This research group’s mission is to lead and excel in generating and disseminating Bayesian econometric knowledge through research, teaching, and software. Our vision is to advance worldwide econometric research, teaching, and applications based on the Bayesian framework, aiming to: Inspire new econometric ideas Create a user-friendly environment for Bayesian econometrics applications Transform classical econometric research, teaching, and applications Address critical social problems through scientific advancements Contact Email: aramir21@gmail.com / aramir21@eafit.edu.co Website: http://www.besmarter-team.org License This book is licensed under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. This book is licensed under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. "],["preface.html", "Preface", " Preface The main goal of this book is to make the Bayesian inferential framework more approachable to students, researchers, and practitioners who wish to understand and apply this statistical/econometric approach but do not have the time to develop programming skills. I have aimed to strike a balance between applicability and theory. This book provides a very user-friendly graphical user interface (GUI) to implement the most common regression models, while also covering the basic mathematical developments and their code implementation for those interested in advancing to more complex models. "],["to-instructors-and-students.html", "To instructors and students", " To instructors and students This book is divided into three parts: foundations (chapters 1 to 4), regression analysis (chapters 5 to 10), and Advanced methods (chapters 11 to 14). Our graphical user interface (GUI) is designed for the second part. The source code can be found at https://github.com/besmarter/BSTApp. Instructors and students can access all the code, along with simulated and real datasets. There are three ways to install our GUI: Type shiny::runGitHub(\"besmarter/BSTApp\", launch.browser=T) in the R console or any R code editor and execute it. Visit https://posit.cloud/content/4328505, log in or sign up for Posit Cloud, navigate to the BSTApp-master folder in the Files tab of the right-bottom window, then click on the app.R file and select Run App. Use a Docker image by typing in the Command Prompt: docker pull magralo95/besmartergui:latest docker run --rm -p 3838:3838 magralo95/besmartergui Then users can access our GUI by going to http://localhost:3838/. See Chapter 5 for details. Students should have a basic understanding of probability theory and statistics, as well as some background in econometrics and time series, particularly regression analysis. Familiarity with standard univariate and multivariate probability distributions is strongly recommended. See a nice summary of useful probability distributions in (Greenberg 2012). Additionally, students who wish to master the material in this book should have programming skills in R software. An excellent starting point for R programming is the R Introduction Manual. I have included both formal and computational exercises at the end of each chapter to help students gain a better understanding of the material presented. A solutions manual for these exercises accompanies this book. Instructors can use this book as a textbook for a course on introductory Bayesian Econometrics/Statistics, with a strong emphasis on implementation and applications. This book is intended to be complementary, rather than a substitute, for excellent resources on the topic, such as Andrew Gelman et al. (2021), Chan et al. (2019), P. E. Rossi, Allenby, and McCulloch (2012), Greenberg (2012), John Geweke (2005), Lancaster (2004), and G. M. Koop (2003). References "],["acknowledgments.html", "Acknowledgments", " Acknowledgments I began developing our graphical user interface (GUI) in 2016, after being diagnosed with cervical dystonia. I worked on this side project during weekends, which I called ``nerd weekends,’’ and it served as a form of release from my health condition. Once I began to recover, I invited Mateo Graciano, my former student, business partner, and friend, to join the project. He has been instrumental in developing our GUI, and I am enormously grateful to him. I would also like to thank the members of the BEsmarter research group at Universidad EAFIT, as well as the NUMBATs members at Monash University, for their valuable feedback and recommendations to improve our GUI. This book is an extension of the paper (Ramírez-Hassan and Graciano-Londoño 2020), which serves as a brief user guide for our GUI. I decided to write this book to explain the underlying theory and code in our GUI, and to use it as a textbook in my course on Bayesian econometrics/statistics. I am grateful to my students in this course; their insights and thoughtful questions have deepened my understanding of the material. I also thank Chris Parmeter for his suggestions on how to present our user guide, Professor Raul Pericchi and Juan Carlos Correa for introducing me to Bayesian statistics, and Liana Jacobi and Chun Fung Kwok (Jackson) from the University of Melbourne, as well as David Frazier from Monash University, for engaging talks and amazing collaborations in Bayesian econometrics/statistics. My sincere gratitude goes to Professor Peter Diggle for his unwavering support of my career, and especially to Professor Gael Martin, who gave me the opportunity to work with her, she is a constant source of intellectual inspiration. Finally, I would like to express my thanks to my colleagues and staff at Universidad EAFIT for their continuous support. To my parents, Orlando and Nancy, who have always been there for me with their unconditional support. They have taught me that the primary aspect of human spiritual evolution is humility, a lesson I am still learning every day. To my fiancée, Estephania, for her unwavering love and support. References "],["Chap1.html", "Chapter 1 Basic formal concepts", " Chapter 1 Basic formal concepts We introduce formal concepts in Bayesian inference, beginning with Bayes’ rule and its components, along with their formal definitions and basic examples. In addition, we present key features of Bayesian inference, such as Bayesian updating and asymptotic sampling properties. We also cover the basics of Bayesian inference from a decision-theoretic perspective under uncertainty, introducing important concepts like loss functions, risk functions, and optimal decision rules. "],["sec11.html", "1.1 The Bayes’ rule", " 1.1 The Bayes’ rule As expected, the starting point for performing Bayesian inference is Bayes’ rule, which provides the solution to the inverse problem of determining causes from observed effects. This rule combines prior beliefs with objective probabilities based on repeatable experiments, allowing us to move from observations to probable causes.1 Formally, the conditional probability of \\(A_i\\) given \\(B\\) is equal to the conditional probability of \\(B\\) given \\(A_i\\), multiplied by the marginal probability of \\(A_i\\), divided by the marginal probability of \\(B\\): \\[\\begin{align} P(A_i|B)&amp;=\\frac{P(A_i,B)}{P(B)}\\\\ &amp;=\\frac{P(B|A_i) \\times P(A_i)}{P(B)}, \\tag{1.1} \\end{align}\\] where equation (1.1) is Bayes’ rule. By the law of total probability, \\(P(B) = \\sum_i P(B \\mid A_i) P(A_i) \\neq 0\\), and \\(\\{ A_i, i = 1, 2, \\dots \\}\\) is a finite or countably infinite partition of the sample space. In the Bayesian framework, \\(B\\) represents sample information that updates a probabilistic statement about an unknown object \\(A_i\\) according to probability rules. This is done using Bayes’ rule, which incorporates prior “beliefs” about \\(A_i\\), i.e., \\(P(A_i)\\), sample information relating \\(B\\) to the particular state of nature \\(A_i\\) through a probabilistic statement, \\(P(B \\mid A_i)\\), and the probability of observing that specific sample information, \\(P(B)\\). Let’s consider a simple example, the base rate fallacy: Assume that the sample information comes from a positive result from a test whose true positive rate (sensitivity) is 98%, i.e., \\(P(+ \\mid \\text{disease}) = 0.98\\). On the other hand, the prior information regarding being infected with this disease comes from a base incidence rate of 0.002, i.e., \\(P(\\text{disease}) = 0.002\\). The question is: What is the probability of actually being infected, given a positive test result? This is an example of the base rate fallacy, where a positive test result for a disease with a very low base incidence rate still gives a low probability of actually having the disease. The key to answering this question lies in understanding the difference between the probability of having the disease given a positive test result, \\(P(\\text{disease} \\mid +)\\), and the probability of a positive result given the disease, \\(P(+ \\mid \\text{disease})\\). The former is the crucial result, and Bayes’ rule helps us to compute it. Using Bayes’ rule (equation (1.1)): \\[ P(\\text{disease} \\mid +) = \\frac{P(+ \\mid \\text{disease}) \\times P(\\text{disease})}{P(+)} = \\frac{0.98 \\times 0.002}{0.98 \\times 0.002 + (1-0.98) \\times (1-0.002)} = 0.09 \\] where \\(P(+) = P(+ \\mid \\text{disease}) \\times P(\\text{disease}) + P(+ \\mid \\lnot \\text{disease}) \\times P(\\lnot \\text{disease})\\).2 The following code shows how to perform this exercise in R. PD &lt;- 0.002 # Probability of disease PPD &lt;- 0.98 # True positive (Sensitivity) PDP &lt;- PD * PPD / (PD * PPD + (1 - PD)*(1 - PPD)) paste(&quot;Probability of disease given a positive test is&quot;, sep = &quot; &quot;, round(PDP, 2)) ## [1] &quot;Probability of disease given a positive test is 0.09&quot; We observe that despite having a positive result, the probability of actually having the disease remains low. This is due to the base rate being so small. Another interesting example, which lies at the heart of the origin of Bayes’ theorem (Thomas Bayes 1763), is related to the existence of God (Stigler 2018). In Section X of David Hume’s “An Inquiry concerning Human Understanding” (1748), titled Of Miracles, Hume argues that when someone claims to have seen a miracle, this provides poor evidence that the event actually occurred, as it contradicts our everyday observations. In response, Richard Price, who finished and published “An Essay Towards Solving a Problem in the Doctrine of Chances” in 1763 (after Bayes’ death in 1761), argues against Hume by highlighting the difference between impossibility in casual conversation and physical impossibility. Price used an example of a die with a million sides, where impossibility refers to rolling a specific side, and physical impossibility refers to rolling a side that does not exist. In millions of throws, the latter would never happen, while the former would eventually occur. Now, let’s consider a scenario involving two cases of resurrection (Res): Jesus Christ and Elvis. The total number of people who have ever lived is approximately 108.5 billion,3 so the prior base rate is given by \\(\\frac{2}{108.5 \\times 10^9}\\). On the other hand, suppose the sample information comes from a highly reliable witness with a true positive rate of 0.9999999. The question then is: What is the probability of this miracle occurring?4 Using Bayes’ rule: \\[\\begin{align*} P(\\text{Res}\\mid \\text{Witness}) &amp; = \\frac{P(\\text{Witness}\\mid \\text{Res})\\times P(\\text{Res})}{P(\\text{Witness})}\\\\ &amp; =\\frac{2/(108.5 * 10^9) \\times 0.9999999}{2/(108.5 * 10^9) \\times 0.9999999 + (1-2/(108.5 * 10^9)) \\times (1-0.9999999)}\\\\ &amp; = 0.000184297806959661 \\end{align*}\\] where \\(P(\\text{Witness}) = P(\\text{Witness} \\mid \\text{Res}) \\times P(\\text{Res}) + (1 - P(\\text{Witness} \\mid \\text{Res})) \\times (1 - P(\\text{Res}))\\). Thus, the probability of a resurrection, given a very reliable witness, is approximately \\(1.843 \\times 10^{-4}\\). The following code shows how to perform this exercise in R. # Probability of resurrection PR &lt;- 2/(108.5 * 10^9) PWR &lt;- 0.9999999 # True positive rate PRW &lt;- PR * PWR / (PR * PWR + (1 - PR)*(1 - PWR)) paste(&quot;Probability of resurrection given witness is&quot;, sep = &quot; &quot;, PRW) ## [1] &quot;Probability of resurrection given witness is 0.000184297806959661&quot; Observe that we can condition on multiple events in Bayes’ rule. Let’s consider two conditioning events, \\(B\\) and \\(C\\). Then, equation (1.1) becomes \\[\\begin{align} P(A_i\\mid B,C)&amp;=\\frac{P(A_i,B,C)}{P(B,C)}\\nonumber\\\\ &amp;=\\frac{P(B\\mid A_i,C) \\times P(A_i\\mid C) \\times P(C)}{P(B\\mid C)P(C)}. \\tag{1.2} \\end{align}\\] Let’s use this rule in one of the most intriguing statistical puzzles, the Monty Hall problem, to illustrate how to use equation (1.2) (Selvin 1975; Morgan et al. 1991). This was the situation faced by a contestant in the American television game show Let’s Make a Deal. In this game, the contestant was asked to choose a door, behind one of which there is a car, and behind the others, goats. Let’s say the contestant picks door No. 1, and the host (Monty Hall), who knows what is behind each door, opens door No. 3, revealing a goat. Then, the host asks the tricky question: Do you want to pick door No. 2? Let’s define the following events: \\(P_i\\): the event contestant picks door No. \\(i\\), which stays closed, \\(H_i\\): the event host picks door No. \\(i\\), which is open and contains a goat, \\(C_i\\): the event car is behind door No. \\(i\\). In this particular setting, the contestant is interested in the probability of the event \\(P(C_2 \\mid H_3, P_1)\\). A naive answer would be that it is irrelevant, as initially, \\(P(C_i) = \\frac{1}{3}, \\ i = 1, 2, 3\\), and now \\(P(C_i \\mid H_3) = \\frac{1}{2}, \\ i = 1, 2\\), since the host opened door No. 3. So, why bother changing the initial guess if the odds are the same (1:1)? The important point here is that the host knows what is behind each door and always picks a door where there is a goat, given the contestant’s choice. In this particular setting: \\[ P(H_3 \\mid C_3, P_1) = 0, \\quad P(H_3 \\mid C_2, P_1) = 1, \\quad P(H_3 \\mid C_1, P_1) = \\frac{1}{2}. \\] Then, using equation (1.2), we can calculate the posterior probability. \\[\\begin{align*} P(C_2\\mid H_3,P_1)&amp;= \\frac{P(C_2,H_3,P_1)}{P(H_3,P_1)}\\\\ &amp;= \\frac{P(H_3\\mid C_2,P_1)P(C_2\\mid P_1)P(P_1)}{P(H_3\\mid P_1)\\times P(P_1)}\\\\ &amp;= \\frac{P(H_3\\mid C_2,P_1)P(C_2)}{P(H_3\\mid P_1)}\\\\ &amp;=\\frac{1\\times 1/3}{1/2}, \\end{align*}\\] Where the third equation uses the fact that \\(C_i\\) and \\(P_i\\) are independent events, and \\(P(H_3 \\mid P_1) = \\frac{1}{2}\\) because this depends only on \\(P_1\\) (not on \\(C_2\\)). Therefore, changing the initial decision increases the probability of getting the car from \\(\\frac{1}{3}\\) to \\(\\frac{2}{3}\\)! Thus, it is always a good idea to change the door. Let’s see a simulation exercise in R to check this answer: set.seed(0101) # Set simulation seed S &lt;- 100000 # Simulations Game &lt;- function(switch = 0){ # switch = 0 is not change # switch = 1 is to change opts &lt;- 1:3 car &lt;- sample(opts, 1) # car location guess1 &lt;- sample(opts, 1) # Initial guess if(car != guess1) { host &lt;- opts[-c(car, guess1)] } else { host &lt;- sample(opts[-c(car, guess1)], 1) } win1 &lt;- guess1 == car # Win no change guess2 &lt;- opts[-c(host, guess1)] win2 &lt;- guess2 == car # Win change if(switch == 0){ win &lt;- win1 } else { win &lt;- win2 } return(win) } #Win probabilities not changing Prob &lt;- mean(replicate(S, Game(switch = 0))) paste(&quot;Winning probabilities no changing door is&quot;, Prob, sep = &quot; &quot;) ## [1] &quot;Winning probabilities no changing door is 0.3334&quot; #Win probabilities changing Prob &lt;- mean(replicate(S, Game(switch = 1))) paste(&quot;Winning probabilities changing door is&quot;, Prob, sep = &quot; &quot;) ## [1] &quot;Winning probabilities changing door is 0.6654&quot; References "],["sec12.html", "1.2 Bayesian framework: A brief summary of theory", " 1.2 Bayesian framework: A brief summary of theory Given an unknown parameter set \\(\\boldsymbol{\\theta}\\), and a particular realization of the data \\(\\mathbf{y}\\), Bayes’ rule may be applied analogously,5 \\[\\begin{align} \\pi(\\boldsymbol{\\theta}\\mid \\mathbf{y})&amp;=\\frac{p(\\mathbf{y}\\mid \\boldsymbol{\\theta}) \\times \\pi(\\boldsymbol{\\theta})}{p(\\mathbf{y})}, \\tag{1.3} \\end{align}\\] where \\(\\pi(\\boldsymbol{\\theta}\\mid \\mathbf{y})\\) is the posterior density function, \\(\\pi(\\boldsymbol{\\theta})\\) is the prior density, \\(p(\\mathbf{y}\\mid \\boldsymbol{\\theta})\\) is the likelihood (statistical model), and \\[\\begin{equation} p(\\mathbf{y})=\\int_{\\mathbf{\\Theta}}p(\\mathbf{y}\\mid \\boldsymbol{\\theta})\\pi(\\boldsymbol{\\theta})d\\boldsymbol{\\theta}=\\mathbb{E}\\left[p(\\mathbf{y}\\mid \\boldsymbol{\\theta})\\right] \\tag{1.4} \\end{equation}\\] is the marginal likelihood or prior predictive. Observe that for this expected value to be meaningful, the prior should be a proper density, that is, it must integrate to one; otherwise, it does not make sense. Observe that \\(p(\\mathbf{y} \\mid \\boldsymbol{\\theta})\\) is not a density in \\(\\boldsymbol{\\theta}\\). In addition, \\(\\pi(\\boldsymbol{\\theta})\\) does not have to integrate to 1, that is, \\(\\pi(\\boldsymbol{\\theta})\\) can be an improper density function, \\(\\int_{\\mathbf{\\Theta}} \\pi(\\boldsymbol{\\theta}) d\\boldsymbol{\\theta} = \\infty\\). However, \\(\\pi(\\boldsymbol{\\theta} \\mid \\mathbf{y})\\) is a proper density function, that is, \\(\\int_{\\mathbf{\\Theta}} \\pi(\\boldsymbol{\\theta} \\mid \\mathbf{y}) d\\boldsymbol{\\theta} = 1\\). For instance, set \\(\\pi(\\boldsymbol{\\theta}) = c\\), where \\(c\\) is a constant, then \\(\\int_{\\mathbf{\\Theta}} c d\\boldsymbol{\\theta} = \\infty\\). However, \\[ \\int_{\\mathbf{\\Theta}} \\pi(\\boldsymbol{\\theta} \\mid \\mathbf{y}) d\\boldsymbol{\\theta} = \\int_{\\mathbf{\\Theta}} \\frac{p(\\mathbf{y} \\mid \\boldsymbol{\\theta}) \\times c}{\\int_{\\mathbf{\\Theta}} p(\\mathbf{y} \\mid \\boldsymbol{\\theta}) \\times c \\, d\\boldsymbol{\\theta}} d\\boldsymbol{\\theta} = 1 \\] where \\(c\\) cancels out. \\(\\pi(\\boldsymbol{\\theta} \\mid \\mathbf{y})\\) is a sample updated ``probabilistic belief” version of \\(\\pi(\\boldsymbol{\\theta})\\), where \\(\\pi(\\boldsymbol{\\theta})\\) is a prior probabilistic belief which can be constructed from previous empirical work, theoretical foundations, expert knowledge, and/or mathematical convenience. This prior usually depends on parameters, which are named . In addition, the Bayesian approach implies using a probabilistic model about \\(\\mathbf{Y}\\) given \\(\\boldsymbol{\\theta}\\), that is, \\(p(\\mathbf{y} \\mid \\boldsymbol{\\theta})\\), where its integral over \\(\\mathbf{\\Theta}\\), \\(p(\\mathbf{y})\\), is named due to being a measure of model fit to the data. Observe that the Bayesian inferential approach is conditional, that is, what can we learn about an unknown object \\(\\boldsymbol{\\theta}\\) given that we already observed \\(\\mathbf{ Y} =\\mathbf{y}\\)? The answer is also conditional on the probabilistic model, that is, \\(p(\\mathbf{y} \\mid \\boldsymbol{\\theta})\\). So, what if we want to compare different models, say \\(\\mathcal{M}_m\\), \\(m = \\{1,2,\\dots,M\\}\\)? Then, we should make explicit this in the Bayes’ rule formulation: \\[\\begin{align} \\pi(\\boldsymbol{\\theta}\\mid \\mathbf{y},\\mathcal{M}_m)&amp;=\\frac{p(\\mathbf{y}\\mid \\boldsymbol{\\theta},\\mathcal{M}_m) \\times \\pi(\\boldsymbol{\\theta}\\mid \\mathcal{M}_m)}{p(\\mathbf{y}\\mid \\mathcal{M}_m)}. \\tag{1.5} \\end{align}\\] The posterior model probability is \\[\\begin{align} \\pi(\\mathcal{M}_m\\mid \\mathbf{y})&amp;=\\frac{p(\\mathbf{y}\\mid \\mathcal{M}_m) \\times \\pi(\\mathcal{M}_m)}{p(\\mathbf{y})}, \\tag{1.6} \\end{align}\\] where \\(p(\\mathbf{y}\\mid \\mathcal{M}_m)=\\int_{\\mathbf{\\Theta}}p(\\mathbf{y}\\mid \\boldsymbol{\\theta},\\mathcal{M}_m) \\times \\pi(\\boldsymbol{\\theta}\\mid \\mathcal{M}_m)d\\boldsymbol{\\theta}\\) due to equation (1.5), and \\(\\pi(\\mathcal{M}_m)\\) is the prior model probability. Calculating \\(p(\\mathbf{y})\\) in equations (1.3) and (1.6) is very demanding in most of the realistic cases. Fortunately, it is not required when performing inference about \\(\\boldsymbol{\\theta}\\) as this is integrated out from it. Then, all you need to know about the shape of \\(\\boldsymbol{\\theta}\\) is in \\(p(\\mathbf{y} \\mid \\boldsymbol{\\theta}, \\mathcal{M}_m) \\times \\pi(\\boldsymbol{\\theta} \\mid \\mathcal{M}_m)\\), or without explicitly conditioning on \\(\\mathcal{M}_m\\), \\[\\begin{align} \\pi(\\boldsymbol{\\theta}\\mid \\mathbf{y})&amp; \\propto p(\\mathbf{y}\\mid \\boldsymbol{\\theta}) \\times \\pi(\\boldsymbol{\\theta}). \\tag{1.7} \\end{align}\\] Equation (1.7) is a very good shortcut to perform Bayesian inference about \\(\\boldsymbol{\\theta}\\). We can also avoid calculating \\(p(\\mathbf{y})\\) when performing model selection (hypothesis testing) using the posterior odds ratio, that is, comparing models \\(\\mathcal{M}_1\\) and \\(\\mathcal{M}_2\\), \\[\\begin{align} PO_{12}&amp;=\\frac{\\pi(\\mathcal{M}_1\\mid \\mathbf{y})}{\\pi(\\mathcal{M}_2\\mid \\mathbf{y})} \\nonumber \\\\ &amp;=\\frac{p(\\mathbf{y}\\mid \\mathcal{M}_1)}{p(\\mathbf{y}\\mid \\mathcal{M}_2)}\\times\\frac{\\pi(\\mathcal{M}_1)}{\\pi(\\mathcal{M}_2)}, \\tag{1.8} \\end{align}\\] where the first term in equation (1.8) is named the Bayes factor, and the second term is the prior odds. Observe that the Bayes factor is a ratio of ordinates for \\(\\mathbf{y}\\) under different models. Then, the Bayes factor is a measure of relative sample evidence in favor of model 1 compared to model 2. However, we still need to calculate \\(p(\\mathbf{y}\\mid \\mathcal{M}_m) = \\int_{\\mathbf{\\Theta}} p(\\mathbf{y}\\mid \\boldsymbol{\\theta}, \\mathcal{M}_m) \\pi(\\boldsymbol{\\theta}\\mid \\mathcal{M}_m) d\\boldsymbol{\\theta} = \\mathbb{E}\\left[ p(\\mathbf{y}\\mid \\boldsymbol{\\theta}, \\mathcal{M}_m) \\right]\\). For this integral to be meaningful, the prior must be proper. Using an improper prior has unintended consequences when comparing models; for instance, parsimonious models are favored by posterior odds or Bayes factors, and these values may depend on units of measure (see Chapter 3). A nice feature of comparing models using posterior odds is that if we have an exhaustive set of competing models such that \\(\\sum_{m=1}^M \\pi(\\mathcal{M}_m \\mid \\mathbf{y}) = 1\\), then we can recover \\(\\pi(\\mathcal{M}_m \\mid \\mathbf{y})\\) without calculating \\(p(\\mathbf{y})\\). In particular, given two models \\(\\mathcal{M}_1\\) and \\(\\mathcal{M}_2\\) such that \\(\\pi(\\mathcal{M}_1 \\mid \\mathbf{y}) + \\pi(\\mathcal{M}_2 \\mid \\mathbf{y}) = 1\\), we have: \\[ \\pi(\\mathcal{M}_1 \\mid \\mathbf{y}) = \\frac{PO_{12}}{1 + PO_{12}} \\quad \\text{and} \\quad \\pi(\\mathcal{M}_2 \\mid \\mathbf{y}) = 1 - \\pi(\\mathcal{M}_1 \\mid \\mathbf{y}). \\] In general, \\[ \\pi(\\mathcal{M}_m \\mid \\mathbf{y}) = \\frac{p(\\mathbf{y} \\mid \\mathcal{M}_m) \\times \\pi(\\mathcal{M}_m)}{\\sum_{l=1}^M p(\\mathbf{y} \\mid \\mathcal{M}_l) \\times \\pi(\\mathcal{M}_l)}. \\] These posterior model probabilities can be used to perform Bayesian model averaging. Table 1.1 shows guidelines for the interpretation of \\(2\\log(PO_{12})\\) (R. E. Kass and Raftery 1995). This transformation is done to replicate the structure of the likelihood ratio test statistic. However, posterior odds do not require nested models as the likelihood ratio test does. Table 1.1: Kass and Raftery guidelines \\(2\\log(PO_{12})\\) \\(PO_{12}\\) Evidence against \\(\\mathcal{M}_{2}\\) 0 to 2 1 to 3 Not worth more than a bare mention 2 to 6 3 to 20 Positive 6 to 10 20 to 150 Strong &gt; 10 &gt; 150 Very strong Observe that the posterior odds ratio is a relative criterion, that is, we specify an exhaustive set of competing models and compare them. However, we may want to check the performance of a model on its own or use a non-informative prior. In this case, we can use the posterior predictive p-value (A. Gelman and Meng 1996; A. Gelman, Meng, and Stern 1996).6 The intuition behind the predictive p-value is simple: analyze the discrepancy between the model’s assumptions and the data by checking a potential extreme tail-area probability. Observe that this approach does not check if a model is true; its focus is on potential discrepancies between the model and the data at hand. This is done by simulating pseudo-data from our sampling model (\\(\\mathbf{y}^{(s)}, s=1,2,\\dots,S\\)) using draws from the posterior distribution, and then calculating a discrepancy measure, \\(D(\\mathbf{y}^{(s)},\\boldsymbol{\\theta})\\), to estimate the posterior predictive p-value, \\[ p_D(\\mathbf{y}) = P[D(\\mathbf{y}^{(s)},\\boldsymbol{\\theta}) \\geq D(\\mathbf{y},\\boldsymbol{\\theta})], \\] using the proportion of the \\(S\\) draws for which \\(D(\\mathbf{y}^{(s)},\\boldsymbol{\\theta}^{(s)}) \\geq D(\\mathbf{y},\\boldsymbol{\\theta}^{(s)})\\). Extreme tail probabilities (\\(p_D(\\mathbf{y}) \\leq 0.05\\) or \\(p_D(\\mathbf{y}) \\geq 0.95\\)) suggest potential discrepancies between the data and the model. A. Gelman, Meng, and Stern (1996) also suggest the posterior predictive p-value based on the minimum discrepancy, \\[ D_{\\min}(\\mathbf{y}) = \\min_{\\boldsymbol{\\theta}} D(\\mathbf{y}, \\boldsymbol{\\theta}), \\] and the average discrepancy statistic \\[ D(\\mathbf{y}) = \\mathbb{E}[D(\\mathbf{y}, \\boldsymbol{\\theta})] = \\int_{\\mathbf{\\Theta}} D(\\mathbf{y}, \\boldsymbol{\\theta}) \\pi(\\boldsymbol{\\theta} \\mid \\mathbf{y}) d\\boldsymbol{\\theta}. \\] These alternatives can be more computationally demanding. The Bayesian approach is also suitable to get probabilistic predictions, that is, we can obtain a posterior predictive density \\[\\begin{align} \\pi(\\mathbf{y}_0\\mid \\mathbf{y},\\mathcal{M}_m) &amp; =\\int_{\\mathbf{\\Theta}}\\pi(\\mathbf{y}_0,\\boldsymbol{\\theta}\\mid \\mathbf{y},\\mathcal{M}_m)d\\boldsymbol{\\theta}\\nonumber\\\\ &amp;=\\int_{\\mathbf{\\Theta}}\\pi(\\mathbf{y}_0\\mid \\boldsymbol{\\theta},\\mathbf{y},\\mathcal{M}_m)\\pi(\\boldsymbol{\\theta}\\mid \\mathbf{y},\\mathcal{M}_m)d\\boldsymbol{\\theta}. \\tag{1.9} \\end{align}\\] Observe that equation (1.9) is again an expectation \\(\\mathbb{E}[\\pi(\\mathbf{y}_0 \\mid \\boldsymbol{\\theta}, \\mathbf{y}, \\mathcal{M}_m)]\\), this time using the posterior distribution. Therefore, the Bayesian approach takes estimation error into account when performing prediction. As we have shown many times, expectation (integration) is a common feature in Bayesian inference. That is why the remarkable relevance of computation based on Monte Carlo integration in the Bayesian framework. Bayesian model averaging (BMA) allows for considering model uncertainty in prediction or any unknown probabilistic object. In the case of the predictive density, \\[\\begin{align} \\pi(\\mathbf{y}_0\\mid \\mathbf{y})&amp;=\\sum_{m=1}^M \\pi(\\mathcal{M}_m\\mid \\mathbf{y})\\pi(\\mathbf{y}_0\\mid \\mathbf{y},\\mathcal{M}_m). \\end{align}\\] In the case of the posterior density of the parameters, \\[\\begin{align} \\pi(\\boldsymbol{\\theta}\\mid \\mathbf{y})&amp;=\\sum_{m=1}^M \\pi(\\mathcal{M}_m\\mid \\mathbf{y})\\pi(\\boldsymbol{\\theta}\\mid \\mathbf{y},\\mathcal{M}_m), \\end{align}\\] where \\[\\begin{align} \\mathbb{E}(\\boldsymbol{\\theta}\\mid \\mathbf{y})=\\sum_{m=1}^{M}\\hat{\\boldsymbol{\\theta}}_m \\pi(\\mathcal{M}_m\\mid \\mathbf{y}), \\tag{1.10} \\end{align}\\] and \\[\\begin{align} Var({\\theta}_k\\mid \\mathbf{y})= \\sum_{m=1}^{M}\\pi(\\mathcal{M}_m\\mid \\mathbf{y}) \\widehat{Var} ({\\theta}_{km}\\mid \\mathbf{y},\\mathcal{M}_m)+\\sum_{m=1}^{M} \\pi(\\mathcal{M}_m\\mid \\mathbf{y}) (\\hat{{\\theta}}_{km}-\\mathbb{E}[{\\theta}_{km}\\mid \\mathbf{y}])^2, \\tag{1.11} \\end{align}\\] \\(\\hat{\\boldsymbol{\\theta}}_m\\) is the posterior mean and \\(\\widehat{Var}({\\theta}_{km}\\mid \\mathbf{y},\\mathcal{M}_m)\\) is the posterior variance of the \\(k\\)-th element of \\(\\boldsymbol{\\theta}\\) under model \\(\\mathcal{M}_m\\). Observe how the variance in equation (1.11) captures the extra variability due to potential differences between the mean posterior estimates associated with each model, and the posterior mean that incorporates model uncertainty in equation (1.10). A significant advantage of the Bayesian approach, which is particularly useful in (see Chapter 8), is the way the posterior distribution updates with new sample information. Given \\(\\mathbf{y} = \\mathbf{y}_{1:t+1}\\) as a sequence of observations from 1 to \\(t+1\\), then \\[\\begin{align} \\pi(\\boldsymbol{\\theta}\\mid \\mathbf{y}_{1:t+1})&amp;\\propto p(\\mathbf{y}_{1:t+1}\\mid \\boldsymbol{\\theta})\\times \\pi(\\boldsymbol{\\theta})\\nonumber\\\\ &amp;= p(y_{t+1}\\mid \\mathbf{y}_{1:t},\\boldsymbol{\\theta})\\times p(\\mathbf{y}_{1:t}\\mid \\boldsymbol{\\theta})\\times \\pi(\\boldsymbol{\\theta})\\nonumber\\\\ &amp;\\propto p(y_{t+1}\\mid \\mathbf{y}_{1:t},\\boldsymbol{\\theta})\\times \\pi(\\boldsymbol{\\theta}\\mid \\mathbf{y}_{1:t}). \\tag{1.12} \\end{align}\\] We observe in Equation (1.12) that the new prior is simply the posterior distribution based on the previous observations. This is particularly useful under the assumption of conditional independence, that is, \\(Y_{t+1} \\perp \\mathbf{Y}_{1:t} \\mid \\boldsymbol{\\theta}\\), so that \\(p(y_{t+1} \\mid \\mathbf{y}_{1:t}, \\boldsymbol{\\theta}) = p(y_{t+1} \\mid \\boldsymbol{\\theta})\\), allowing the posterior to be recovered recursively (Petris, Petrone, and Campagnoli 2009). This facilitates online updating because all information up to time \\(t\\) is captured in \\(\\boldsymbol{\\theta}\\). Therefore, \\(\\pi(\\boldsymbol{\\theta} \\mid \\mathbf{y}_{1:t+1}) \\propto p(y_{t+1} \\mid \\boldsymbol{\\theta}) \\times \\pi(\\boldsymbol{\\theta} \\mid \\mathbf{y}_{1:t}) \\propto \\prod_{h=1}^{t+1} p(y_h \\mid \\boldsymbol{\\theta}) \\times \\pi(\\boldsymbol{\\theta})\\). This recursive expression can be computed more efficiently at any specific point in time \\(t\\), compared to a batch-mode algorithm, which requires processing all information up to time \\(t\\) simultaneously. It is also important to consider the sampling properties of “Bayesian estimators”. This topic has attracted the attention of statisticians and econometricians for a long time. For instance, asymptotic posterior concentration on the population parameter vector is discussed by Bickel and Yahav (1969). The convergence of posterior distributions is stated by the Bernstein-von Mises theorem (Lehmann and Casella 2003; Van der Vaart 2000), which establishes a link between credible intervals (sets) and confidence intervals (sets), where a credible interval is an interval in the domain of the posterior distribution within which an unknown parameter falls with a particular probability. Credible intervals treat bounds as fixed and parameters as random, whereas confidence intervals reverse this. There are many settings in parametric models where Bayesian credible intervals with an \\(\\alpha\\) level converge asymptotically to confidence intervals at the \\(\\alpha\\) level. This suggests that Bayesian inference is asymptotically correct from a sampling perspective in these settings. A heuristic approach to demonstrate this in the simplest case, where we assume random sampling and \\(\\theta \\in \\mathcal{R}\\), is the following: \\(p(\\mathbf{y} \\mid \\theta) = \\prod_{i=1}^N p(y_i \\mid \\theta)\\), so the log likelihood is \\(l(\\mathbf{y} \\mid \\theta) \\equiv \\log p(\\mathbf{y} \\mid \\theta) = \\sum_{i=1}^N \\log p(y_i \\mid \\theta) = N \\times \\bar{l}(\\mathbf{y} \\mid \\theta)\\), where \\(\\bar{l} \\equiv \\frac{1}{N} \\sum_{i=1}^N \\log p(y_i \\mid \\theta)\\) is the mean likelihood.7 Then, the posterior distribution is proportional to \\[\\begin{align} \\pi(\\theta\\mid \\mathbf{y})&amp;\\propto p(\\mathbf{y}\\mid \\theta) \\times \\pi(\\theta)\\nonumber\\\\ &amp;=\\exp\\left\\{N\\times \\bar{l}(\\mathbf{y}\\mid \\theta)\\right\\} \\times \\pi(\\theta). \\end{align}\\] Observe that as the sample size increases, that is, as \\(N \\to \\infty\\), the exponential term should dominate the prior distribution as long as the prior does not depend on \\(N\\), such that the likelihood determines the posterior distribution asymptotically. Maximum likelihood theory shows that \\(\\lim_{N \\to \\infty} \\bar{l}(\\mathbf{y} \\mid \\theta) \\to \\bar{l}(\\mathbf{y} \\mid \\theta_0)\\), where \\(\\theta_0\\) is the population parameter of the data-generating process. In addition, performing a second-order Taylor expansion of the log likelihood at the maximum likelihood estimator, \\[\\begin{align*} l(\\mathbf{y}\\mid \\theta)&amp;\\approx l(\\mathbf{y}\\mid \\hat{\\theta})+\\left.\\frac{dl(\\mathbf{y}\\mid {\\theta})}{d\\theta}\\right\\vert_{\\hat{\\theta}}(\\theta-\\hat{\\theta})+\\frac{1}{2}\\left.\\frac{d^2l(\\mathbf{y}\\mid {\\theta})}{d\\theta^2}\\right\\vert_{\\hat{\\theta}}(\\theta-\\hat{\\theta})^2\\\\ &amp;= l(\\mathbf{y}\\mid \\hat{\\theta})+\\frac{1}{2}\\left.\\sum_{i=1}^N\\frac{d^2l(y_i\\mid {\\theta})}{d\\theta^2}\\right\\vert_{\\hat{\\theta}}(\\theta-\\hat{\\theta})^2\\\\ &amp;= l(\\mathbf{y}\\mid \\hat{\\theta})-\\frac{1}{2}\\left.N\\left[-\\bar{l}&#39;&#39;\\right\\vert_{\\hat{\\theta}}\\right](\\theta-\\hat{\\theta})^2\\\\ &amp;= l(\\mathbf{y}\\mid \\hat{\\theta})-\\frac{N}{2\\sigma^2}(\\theta-\\hat{\\theta})^2 \\end{align*}\\] where \\(\\left.\\frac{dl(\\mathbf{y}\\mid \\theta)}{d\\theta}\\right\\vert_{\\hat{\\theta}}=0\\), \\(\\bar{l}&#39;&#39;\\equiv\\frac{1}{N}\\left.\\sum_{i=1}^N\\frac{d^2l(y_i\\mid {\\theta})}{d\\theta^2}\\right\\vert_{\\hat{\\theta}}\\) and \\(\\sigma^2:=\\left[\\left.-\\bar{l}&#39;&#39;\\right\\vert_{\\hat{\\theta}}\\right]^{-1}\\).8 Then, \\[\\begin{align*} \\pi(\\theta\\mid \\mathbf{y})&amp;\\propto \\exp\\left\\{{l}(\\mathbf{y}\\mid \\theta)\\right\\} \\times \\pi(\\theta)\\\\ &amp;\\approx \\exp\\left\\{l(\\mathbf{y}\\mid \\hat{\\theta})-\\frac{N}{2\\sigma^2}(\\theta-\\hat{\\theta})^2\\right\\} \\times \\pi(\\theta)\\\\ &amp;\\propto \\exp\\left\\{-\\frac{N}{2\\sigma^2}(\\theta-\\hat{\\theta})^2\\right\\} \\times \\pi(\\theta)\\\\ \\end{align*}\\] Observe that the posterior density is proportional to the kernel of a normal density with mean \\(\\hat{\\theta}\\) and variance \\(\\sigma^2 / N\\), as long as \\(\\pi(\\hat{\\theta}) \\neq 0\\). This kernel dominates as the sample size increases due to the \\(N\\) in the exponential term. It is also important to note that the prior should not exclude values of \\(\\theta\\) that are logically possible, such as \\(\\hat{\\theta}\\). Example: Health insurance Suppose that you are analyzing whether to buy health insurance next year. To make a better decision, you want to know what the probability is that you will visit your doctor at least once next year? To answer this question, you have records of the number of times you have visited your doctor over the last 5 years, \\(\\mathbf{y} = \\{0, 3, 2, 1, 0\\}\\). How should you proceed? Assuming that this is a random sample9 from a data-generating process (statistical model) that is Poisson, i.e., \\(Y_i \\sim P(\\lambda)\\), and your probabilistic prior beliefs about \\(\\lambda\\) are well described by a Gamma distribution with shape and scale parameters \\(\\alpha_0\\) and \\(\\beta_0\\), i.e., \\(\\lambda \\sim G(\\alpha_0, \\beta_0)\\), then you are interested in calculating the probability \\(P(Y_0 &gt; 0 \\mid \\mathbf{y})\\). To answer this, you need to calculate the posterior predictive density \\(\\pi(y_0 \\mid \\mathbf{y})\\) in a Bayesian way. In this example, \\(p(\\mathbf{y} \\mid \\lambda)\\) is Poisson, and \\(\\pi(\\lambda)\\) is Gamma. Therefore, using Equation (1.9). \\[\\begin{align*} \\pi(y_0\\mid \\mathbf{y})=&amp;\\int_{0}^{\\infty}\\frac{\\lambda^{y_0}\\exp\\left\\{-\\lambda\\right\\}}{y_0!}\\times \\pi(\\lambda\\mid \\mathbf{y})d\\lambda,\\\\ \\end{align*}\\] where the posterior distribution is \\[ \\pi(\\lambda\\mid \\mathbf{y})\\propto \\lambda^{\\sum_{i=1}^N y_i + \\alpha_0 - 1}\\exp\\left\\{-\\lambda\\left(\\frac{\\beta_0 N+1}{\\beta_0}\\right)\\right\\} \\] by Equation (1.3). Observe that the last expression is the kernel of a Gamma distribution with parameters \\(\\alpha_n = \\sum_{i=1}^N y_i + \\alpha_0\\) and \\(\\beta_n = \\frac{\\beta_0}{\\beta_0 N + 1}\\). Given that \\(\\int_0^{\\infty} \\pi(\\lambda \\mid \\mathbf{y}) d\\lambda = 1\\), the constant of proportionality in the last expression is \\(\\Gamma(\\alpha_n) \\beta_n^{\\alpha_n}\\), where \\(\\Gamma(\\cdot)\\) is the Gamma function. Thus, the posterior density function \\(\\pi(\\lambda \\mid \\mathbf{y})\\) is \\(G(\\alpha_n, \\beta_n)\\). Observe that \\[\\begin{align*} \\mathbb{E}[\\lambda\\mid \\mathbf{y}]&amp;=\\alpha_n\\beta_n\\\\ &amp;=\\left(\\sum_{i=1}^N y_i + \\alpha_0\\right)\\left(\\frac{\\beta_0}{\\beta_0 N + 1}\\right)\\\\ &amp;=\\bar{y}\\left(\\frac{N\\beta_0}{N\\beta_0+1}\\right)+\\alpha_0\\beta_0\\left(\\frac{1}{N\\beta_0+1}\\right)\\\\ &amp;=w\\bar{y}+(1-w)\\mathbb{E}[\\lambda], \\end{align*}\\] where \\(\\bar{y}\\) is the sample mean estimate, which is the maximum likelihood estimate of \\(\\lambda\\) in this example, \\(w = \\left(\\frac{N\\beta_0}{N\\beta_0 + 1}\\right)\\), and \\(\\mathbb{E}[\\lambda] = \\alpha_0 \\beta_0\\) is the prior mean. The posterior mean is a weighted average of the maximum likelihood estimator (sample information) and the prior mean. Observe that \\(\\lim_{N \\to \\infty} w = 1\\), that is, the sample information asymptotically dominates. The predictive distribution is \\[\\begin{align*} \\pi(y_0\\mid \\mathbf{y})=&amp;\\int_{0}^{\\infty}\\frac{\\lambda^{y_0}\\exp\\left\\{-\\lambda\\right\\}}{y_0!}\\times \\frac{1}{\\Gamma(\\alpha_n)\\beta_n^{\\alpha_n}}\\lambda^{\\alpha_n-1}\\exp\\left\\{-\\lambda/\\beta_n\\right\\} d\\lambda\\\\ =&amp;\\frac{1}{y_0!\\Gamma(\\alpha_n)\\beta_n^{\\alpha_n}}\\int_{0}^{\\infty}\\lambda^{y_0+\\alpha_n-1}\\exp\\left\\{-\\lambda\\left(\\frac{1+\\beta_n}{\\beta_n}\\right)\\right\\}d\\lambda\\\\ =&amp;\\frac{\\Gamma(y_0+\\alpha_n)\\left(\\frac{\\beta_n}{\\beta_n+1}\\right)^{y_0+\\alpha_n}}{y_0!\\Gamma(\\alpha_n)\\beta_n^{\\alpha_n}}\\\\ =&amp;{y_0+\\alpha_n-1 \\choose y_0}\\left(\\frac{\\beta_n}{\\beta_n+1}\\right)^{y_0}\\left(\\frac{1}{\\beta_n+1}\\right)^{\\alpha_n}. \\end{align*}\\] The third equality follows from the kernel of a Gamma density, and the fourth from \\[ {y_0 + \\alpha_n - 1 \\choose y_0} = \\frac{(y_0 + \\alpha_n - 1)(y_0 + \\alpha_n - 2)\\dots\\alpha_n}{y_0!} = \\frac{\\Gamma(y_0 + \\alpha_n)}{\\Gamma(\\alpha_n) y_0!} \\] using a property of the Gamma function. Observe that this is a Negative Binomial density, that is, \\(Y_0 \\mid \\mathbf{y} \\sim \\text{NB}(\\alpha_n, p_n)\\) where \\(p_n = \\frac{\\beta_n}{\\beta_n + 1}\\). Up to this point, we have said nothing about the hyperparameters, which are required to give a concrete response to this exercise. Thus, we show two approaches to set them. First, we set \\(\\alpha_0 = 0.001\\) and \\(\\beta_0 = \\frac{1}{0.001}\\), which imply vague prior information about \\(\\lambda\\) due to having a large degree of variability compared to the mean information.10 In particular, \\(\\mathbb{E}[\\lambda] = 1\\) and \\(\\mathbb{V}ar[\\lambda] = 1000\\). In this setting, \\(P(Y_0 &gt; 0 \\mid \\mathbf{y}) = 1 - P(Y_0 = 0 \\mid \\mathbf{y}) \\approx 0.67\\). That is, the probability of visiting the doctor at least once next year is approximately 0.67. Another approach is using Empirical Bayes, where we set the hyperparameters maximizing the logarithm of the marginal likelihood,11 that is, \\[ \\left[\\hat{\\alpha}_0 \\ \\hat{\\beta}_0\\right]^{\\top} = \\underset{\\alpha_0, \\beta_0}{\\mathrm{argmax}} \\ \\ln p(\\mathbf{y}) \\] where \\[ \\begin{align} p(\\mathbf{y}) &amp;= \\int_0^{\\infty} \\left\\{ \\frac{1}{\\Gamma(\\alpha_0)\\beta_0^{\\alpha_0}} \\lambda^{\\alpha_0 - 1} \\exp\\left\\{-\\lambda / \\beta_0\\right\\} \\prod_{i=1}^N \\frac{\\lambda^{y_i} \\exp\\left\\{-\\lambda\\right\\}}{ y_i!} \\right\\} d\\lambda \\\\ &amp;= \\frac{\\int_0^{\\infty} \\lambda^{\\sum_{i=1}^N y_i + \\alpha_0 - 1} \\exp\\left\\{-\\lambda \\left( \\frac{\\beta_0 N + 1}{\\beta_0} \\right) \\right\\} d\\lambda}{ \\Gamma(\\alpha_0) \\beta_0^{\\alpha_0} \\prod_{i=1}^N y_i! } \\\\ &amp;= \\frac{\\Gamma\\left(\\sum_{i=1}^N y_i + \\alpha_0\\right) \\left( \\frac{\\beta_0}{N\\beta_0 + 1} \\right)^{\\sum_{i=1}^N y_i} \\left( \\frac{1}{N\\beta_0 + 1} \\right)^{\\alpha_0}}{ \\Gamma(\\alpha_0) \\prod_{i=1}^N y_i } \\end{align} \\] Using the empirical Bayes approach, we get \\(\\hat{\\alpha}_0 = 51.8\\) and \\(\\hat{\\beta}_0 = 0.023\\), then \\(P(Y_0 &gt; 0 \\mid \\mathbf{y}) = 1 - P(Y_0 = 0 \\mid \\mathbf{y}) \\approx 0.70\\). Observe that we can calculate the posterior odds comparing the model using an Empirical Bayes prior (model 1) versus the vague prior (model 2). We assume that \\(\\pi(\\mathcal{M}_1) = \\pi(\\mathcal{M}_2) = 0.5\\), then \\[ \\begin{align} PO_{12} &amp;= \\frac{p(\\mathbf{y} \\mid \\text{Empirical Bayes})}{ p(\\mathbf{y} \\mid \\text{Vague prior}) } \\\\ &amp;= \\frac{\\frac{\\Gamma\\left(\\sum_{i=1}^N y_i + 51.807\\right) \\left( \\frac{0.023}{N \\times 0.023 + 1} \\right)^{\\sum_{i=1}^N y_i} \\left( \\frac{1}{N \\times 0.023 + 1} \\right)^{51.807}}{\\Gamma(51.807)}}{\\frac{\\Gamma\\left(\\sum_{i=1}^N y_i + 0.001\\right) \\left( \\frac{1/0.001}{N/0.001 + 1} \\right)^{\\sum_{i=1}^N y_i} \\left( \\frac{1}{N/0.001 + 1} \\right)^{0.001}}{\\Gamma(0.001)}} \\\\ &amp;\\approx 919 \\end{align} \\] Then, \\(2 \\times \\log(PO_{12}) = 13.64\\), which provides very strong evidence against the vague prior model (see Table 1.1). In particular, \\(\\pi(\\text{Empirical Bayes} \\mid \\mathbf{y}) = \\frac{919}{1 + 919} = 0.999\\) and \\(\\pi(\\text{Vague prior} \\mid \\mathbf{y}) = 1 - 0.999 = 0.001\\). These probabilities can be used to perform Bayesian model averaging (BMA). In particular, \\[ \\begin{align} \\mathbb{E}(\\lambda \\mid \\mathbf{y}) &amp;= 1.2 \\times 0.999 + 1.2 \\times 0.001 = 1.2 \\\\ \\text{Var}(\\lambda \\mid \\mathbf{y}) &amp;= 0.025 \\times 0.999 + 0.24 \\times 0.001 \\\\ &amp;+ (1.2 - 1.2)^2 \\times 0.999 + (1.2 - 1.2)^2 \\times 0.001 = 0.025 \\end{align} \\] The BMA predictive distribution is a mix of negative binomial distributions, that is, \\[ Y_0 \\mid \\mathbf{y} \\sim 0.999 \\times \\text{NB}(57.8, 0.02) + 0.001 \\times \\text{NB}(6.001, 0.17) \\] The following code shows how to perform this exercise in R. set.seed(010101) y &lt;- c(0, 3, 2, 1, 0) # Data N &lt;- length(y) ProbBo &lt;- function(y, a0, b0){ N &lt;- length(y) #sample size an &lt;- a0 + sum(y) # Posterior shape parameter bn &lt;- b0 / ((b0 * N) + 1) # Posterior scale parameter p &lt;- bn / (bn + 1) # Probability negative binomial density Pr &lt;- 1 - pnbinom(0, size=an,prob=(1 - p)) # Probability of visiting the Doctor at least once next year # Observe that in R there is a slightly different parametrization. return(Pr) } # Using a vague prior: a0 &lt;- 0.001 # Prior shape parameter b0 &lt;- 1 / 0.001 # Prior scale parameter PriMeanV &lt;- a0 * b0 # Prior mean PriVarV &lt;- a0 * b0^2 # Prior variance Pp &lt;- ProbBo(y, a0 = 0.001, b0 = 1 / 0.001) # This setting is vague prior information. Pp ## [1] 0.6650961 # Using Empirical Bayes LogMgLik &lt;- function(theta, y){ N &lt;- length(y) #sample size a0 &lt;- theta[1] # prior shape hyperparameter b0 &lt;- theta[2] # prior scale hyperparameter an &lt;- sum(y) + a0 # posterior shape parameter if(a0 &lt;= 0 || b0 &lt;= 0){ #Avoiding negative values lnp &lt;- -Inf }else{ lnp &lt;- lgamma(an) + sum(y)*log(b0/(N*b0+1)) - a0*log(N*b0+1) - lgamma(a0) } # log marginal likelihood return(-lnp) } theta0 &lt;- c(0.01, 1/0.1) # Initial values control &lt;- list(maxit = 1000) # Number of iterations in optimization EmpBay &lt;- optim(theta0, LogMgLik, method = &quot;BFGS&quot;, control = control, hessian = TRUE, y = y) # Optimization EmpBay$convergence ## [1] 0 a0EB &lt;- EmpBay$par[1] # Prior shape using empirical Bayes a0EB ## [1] 51.80696 b0EB &lt;- EmpBay$par[2] # Prior scale using empirical Bayes b0EB ## [1] 0.02318341 PriMeanEB &lt;- a0EB * b0EB # Prior mean PriVarEB &lt;- a0EB * b0EB^2 # Prior variance PpEB &lt;- ProbBo(y, a0 = a0EB, b0 = b0EB) # This setting is using emprical Bayes. PpEB ## [1] 0.6953668 # Density figures: # This code helps plotting densities lambda &lt;- seq(0.01, 10, 0.01) # Values of lambda VaguePrior &lt;- dgamma(lambda,shape=a0,scale = b0) EBPrior &lt;- dgamma(lambda,shape=a0EB,scale = b0EB) PosteriorV &lt;- dgamma(lambda, shape = a0 + sum(y), scale = b0 / ((b0 * N) + 1)) PosteriorEB &lt;- dgamma(lambda, shape = a0EB+sum(y), scale = b0EB / ((b0EB * N) + 1)) # Likelihood function Likelihood &lt;- function(theta, y){ LogL &lt;- dpois(y, theta, log = TRUE) Lik &lt;- prod(exp(LogL)) return(Lik) } Liks &lt;- sapply(lambda, function(par) {Likelihood(par, y = y)}) Sc &lt;- max(PosteriorEB)/max(Liks) #Scale for displaying in figure LiksScale &lt;- Liks * Sc data &lt;- data.frame(cbind(lambda, VaguePrior, EBPrior, PosteriorV, PosteriorEB, LiksScale)) #Data frame require(ggplot2) # Cool figures ## Loading required package: ggplot2 ## Warning: package &#39;ggplot2&#39; was built under R version 4.3.3 require(latex2exp) # LaTeX equations in figures ## Loading required package: latex2exp require(ggpubr) # Multiple figures in one page ## Loading required package: ggpubr fig1 &lt;- ggplot(data = data, aes(lambda, VaguePrior)) + geom_line() + xlab(TeX(&quot;$\\\\lambda$&quot;)) + ylab(&quot;Density&quot;) + ggtitle(&quot;Prior: Vague Gamma&quot;) fig2 &lt;- ggplot(data = data, aes(lambda, EBPrior)) + geom_line() + xlab(TeX(&quot;$\\\\lambda$&quot;)) + ylab(&quot;Density&quot;) + ggtitle(&quot;Prior: Empirical Bayes Gamma&quot;) fig3 &lt;- ggplot(data = data, aes(lambda, PosteriorV)) + geom_line() + xlab(TeX(&quot;$\\\\lambda$&quot;)) + ylab(&quot;Density&quot;) + ggtitle(&quot;Posterior: Vague Gamma&quot;) fig4 &lt;- ggplot(data = data, aes(lambda, PosteriorEB)) + geom_line() + xlab(TeX(&quot;$\\\\lambda$&quot;)) + ylab(&quot;Density&quot;) + ggtitle(&quot;Posterior: Empirical Bayes Gamma&quot;) FIGcap1 &lt;- ggarrange(fig1, fig2, fig3, fig4, ncol = 2, nrow = 2) annotate_figure(FIGcap1, top = text_grob(&quot;Vague versus Empirical Bayes: Poisson-Gamma model&quot;, color = &quot;black&quot;, face = &quot;bold&quot;, size = 14)) dataNew &lt;- data.frame(cbind(rep(lambda, 3), c(EBPrior, PosteriorEB, LiksScale), rep(1:3, each = 1000))) #Data frame colnames(dataNew) &lt;- c(&quot;Lambda&quot;, &quot;Density&quot;, &quot;Factor&quot;) dataNew$Factor &lt;- factor(dataNew$Factor, levels=c(&quot;1&quot;, &quot;3&quot;, &quot;2&quot;), labels=c(&quot;Prior&quot;, &quot;Likelihood&quot;, &quot;Posterior&quot;)) # ggplot(data = dataNew, aes_string(x = &quot;Lambda&quot;, y = &quot;Density&quot;, group = &quot;Factor&quot;)) + geom_line(aes(color = Factor)) + xlab(TeX(&quot;$\\\\lambda$&quot;)) + ylab(&quot;Density&quot;) + ggtitle(&quot;Prior, likelihood and posterior: Empirical Bayes Poisson-Gamma model&quot;) + guides(color=guide_legend(title=&quot;Information&quot;)) + scale_color_manual(values = c(&quot;red&quot;, &quot;yellow&quot;, &quot;blue&quot;)) p1 &lt;- ggplot(data = dataNew, aes(x = Lambda, y = Density, group = Factor, color = Factor)) + geom_line() + xlab(TeX(&quot;$\\\\lambda$&quot;)) + ylab(&quot;Density&quot;) + ggtitle(&quot;Prior, likelihood and posterior: Empirical Bayes Poisson-Gamma model&quot;) + guides(color = guide_legend(title = &quot;Information&quot;)) + scale_color_manual(values = c(&quot;red&quot;, &quot;yellow&quot;, &quot;blue&quot;)) p1 The first figure displays the prior and posterior densities based on vague and Empirical Bayes hyperparameters. We observe that the prior and posterior densities using the latter are more informative, as expected. The second figure shows the prior, scaled likelihood, and posterior densities of \\(\\lambda\\) based on the hyperparameters from the Empirical Bayes approach. The posterior density is a compromise between prior and sample information. # Predictive distributions PredDen &lt;- function(y, y0, a0, b0){ N &lt;- length(y) #sample size an &lt;- a0 + sum(y) # Posterior shape parameter bn &lt;- b0 / ((b0 * N) + 1) # Posterior scale parameter p &lt;- bn / (bn + 1) # Probability negative binomial density Pr &lt;- dnbinom(y0, size=an, prob=(1 - p)) # Predictive density # Observe that in R there is a slightly different parametrization. return(Pr) } y0 &lt;- 0:10 PredVague &lt;- PredDen(y=y, y0=y0, a0=a0, b0=b0) PredEB &lt;- PredDen(y=y, y0=y0, a0=a0EB, b0=b0EB) dataPred &lt;- as.data.frame(cbind(y0, PredVague, PredEB)) colnames(dataPred) &lt;- c(&quot;y0&quot;, &quot;PredictiveVague&quot;, &quot;PredictiveEB&quot;) FIGchappred &lt;- ggplot(data = dataPred) + geom_point(aes(y0, PredictiveVague, color = &quot;red&quot;)) + xlab(TeX(&quot;$y_0$&quot;)) + ylab(&quot;Density&quot;) + ggtitle(&quot;Predictive density: Vague and Empirical Bayes priors&quot;) + geom_point(aes(y0, PredictiveEB, color = &quot;yellow&quot;)) + guides(color = guide_legend(title=&quot;Prior&quot;)) + scale_color_manual(labels = c(&quot;Vague&quot;, &quot;Empirical Bayes&quot;), values = c(&quot;red&quot;, &quot;yellow&quot;)) + scale_x_continuous(breaks=seq(0,10,by=1)) FIGchappred This figure displays the predictive probability mass of not having any visits to a physician next year, as well as having one, two, and so on, using Empirical Bayes and vague hyperparameters. The predictive probabilities of not having any visits are approximately 30% and 33% based on the Empirical Bayes and vague hyperparameters, respectively. # Posterior odds: Vague vs Empirical Bayes PO12 &lt;- exp(-LogMgLik(c(a0EB, b0EB), y = y))/exp(-LogMgLik(c(a0, b0), y = y)) PO12 ## [1] 919.0069 PostProMEM &lt;- PO12/(1 + PO12) PostProMEM ## [1] 0.9989131 # Posterior model probability Empirical Bayes PostProbMV &lt;- 1 - PostProMEM PostProbMV ## [1] 0.001086948 # Posterior model probability vague prior # Bayesian model average (BMA) PostMeanEB &lt;- (a0EB + sum(y)) * (b0EB / (b0EB * N + 1)) # Posterior mean Empirical Bayes PostMeanV &lt;- (a0 + sum(y)) * (b0 / (b0 * N + 1)) # Posterior mean vague priors BMAmean &lt;- PostProMEM * PostMeanEB + PostProbMV * PostMeanV BMAmean ## [1] 1.200951 # BMA posterior mean PostVarEB &lt;- (a0EB + sum(y)) * (b0EB/(b0EB * N + 1))^2 # Posterior variance Empirical Bayes PostVarV &lt;- (a0 + sum(y)) * (b0 / (b0 * N + 1))^2 # Posterior variance vague prior BMAVar &lt;- PostProMEM * PostVarEB + PostProbMV*PostVarV + PostProMEM * (PostMeanEB - BMAmean)^2 + PostProbMV * (PostMeanV - BMAmean)^2 # BMA posterior variance BMAVar ## [1] 0.02518372 # BMA: Predictive BMAPred &lt;- PostProMEM * PredEB+PostProbMV * PredVague dataPredBMA &lt;- as.data.frame(cbind(y0, BMAPred)) colnames(dataPredBMA) &lt;- c(&quot;y0&quot;, &quot;PredictiveBMA&quot;) FIGchappred1 &lt;- ggplot(data = dataPredBMA) + geom_point(aes(y0, PredictiveBMA, color = &quot;red&quot;)) + xlab(TeX(&quot;$y_0$&quot;)) + ylab(&quot;Density&quot;) + ggtitle(&quot;Predictive density: BMA&quot;) + guides(color = guide_legend(title=&quot;BMA&quot;)) + scale_color_manual(labels = c(&quot;Probability&quot;), values = c(&quot;red&quot;)) + scale_x_continuous(breaks=seq(0,10,by=1)) FIGchappred1 The first figure displays the predictive density using Bayesian model averaging based on the vague and Empirical Bayes hyperparameters. This figure closely resembles the predictive probability mass function based on the Empirical Bayes framework, as the posterior model probability for that setting is nearly one. The second figure shows how the posterior distribution updates with new sample information, starting from an initial non-informative prior (iteration 1). We observe that iteration 5 incorporates all the sample information in our example. As a result, the posterior density in iteration 5 is identical to the posterior density. References "],["sec14.html", "1.3 Bayesian reports: Decision theory under uncertainty", " 1.3 Bayesian reports: Decision theory under uncertainty The Bayesian framework allows reporting the full posterior distributions. However, some situations require reporting a specific value of the posterior distribution (point estimate), an informative interval (set), point or interval predictions, and/or selecting a specific model. Decision theory offers an elegant framework to make decisions regarding the optimal posterior values to report (J. O. Berger 2013). The starting point is a loss function, which is a non-negative real-valued function whose arguments are the unknown state of nature (\\(\\mathbf{\\Theta}\\)), and a set of actions to be taken (\\(\\mathcal{A}\\)), that is, \\[\\begin{equation*} L(\\mathbf{\\theta}, a):\\mathbf{\\Theta}\\times \\mathcal{A}\\rightarrow \\mathcal{R}^+. \\end{equation*}\\] This function is a mathematical representation of the loss incurred from making mistakes. In particular, selecting action \\(a\\in\\mathcal{A}\\) when \\(\\mathbf{\\theta}\\in\\mathbf{\\Theta}\\) is the true state. In our case, the unknown state of nature can refer to parameters, functions of them, future or unknown realizations, models, etc. From a Bayesian perspective, we should choose the action that minimizes the posterior expected loss (\\(a^*(\\mathbf{y})\\)), that is, the posterior risk function (\\(\\mathbb{E}[L(\\mathbf{\\theta}, a)\\mid \\mathbf{y}]\\)), \\[\\begin{equation*} a^*(\\mathbf{y})=\\underset{a \\in \\mathcal{A}}{\\mathrm{argmin}} \\ \\mathbb{E}[L(\\mathbf{\\theta}, a)\\mid \\mathbf{y}], \\end{equation*}\\] where \\(\\mathbb{E}[L(\\mathbf{\\theta}, a)\\mid \\mathbf{y}] = \\int_{\\mathbf{\\Theta}} L(\\mathbf{\\theta}, a)\\pi(\\mathbf{\\theta}\\mid \\mathbf{y})d\\mathbf{\\theta}\\).12 Different loss functions imply different optimal decisions. We illustrate this assuming \\(\\theta \\in \\mathcal{R}\\). The quadratic loss function, \\(L(\\theta,a)=[\\theta-a]^2\\), gives as the optimal decision the posterior mean, \\(a^*(\\mathbf{y})=\\mathbb{E}[\\theta \\mid \\mathbf{y}]\\), that is: \\[\\begin{equation*} \\mathbb{E}[\\theta \\mid \\mathbf{y}] = \\underset{a \\in \\mathcal{A}}{\\mathrm{argmin}} \\ \\int_{\\Theta} [\\theta - a]^2 \\pi(\\theta \\mid \\mathbf{y}) \\, d\\theta. \\end{equation*}\\] To obtain this result, let’s use the first-order condition, differentiate the risk function with respect to \\(a\\), interchange the differential and integral order, and set the result equal to zero: \\[ -2 \\int_{\\Theta} [\\theta - a^*] \\pi(\\theta \\mid \\mathbf{y}) \\, d\\theta = 0. \\] This implies that \\[ a^* \\int_{\\Theta} \\pi(\\theta \\mid \\mathbf{y}) \\, d\\theta = a^*(\\mathbf{y}) = \\int_{\\Theta} \\theta \\pi(\\theta \\mid \\mathbf{y}) \\, d\\theta = \\mathbb{E}[\\theta \\mid \\mathbf{y}], \\] that is, the posterior mean is the Bayesian optimal action. This means that we should report the posterior mean as a point estimate of \\(\\theta\\) when facing the quadratic loss function. The generalized quadratic loss function, \\(L(\\theta,a) = w(\\theta) [\\theta - a]^2\\), where \\(w(\\theta) &gt; 0\\) is a weighting function, gives as the optimal decision rule the weighted mean. We should follow the same steps as the previous result to obtain \\[ a^*(\\mathbf{y}) = \\frac{\\mathbb{E}[w(\\theta) \\times \\theta \\mid \\mathbf{y}]}{\\mathbb{E}[w(\\theta) \\mid \\mathbf{y}]}. \\] Observe that the weighted average is driven by the weighting function \\(w(\\theta)\\). The absolute error loss function, \\(L(\\theta,a) = |\\theta - a|\\), gives as the optimal action the posterior median (Exercise 5). The generalized absolute error function, \\[ L(\\theta,a) = \\begin{cases} K_0 (\\theta - a), &amp; \\text{if } \\theta - a \\geq 0, \\\\ K_1 (a - \\theta), &amp; \\text{if } \\theta - a &lt; 0, \\end{cases} \\quad K_0, K_1 &gt; 0, \\] implies the following risk function: \\[\\begin{align*} \\mathbb{E}[L(\\theta, a) \\mid \\mathbf{y}] &amp;= \\int_{-\\infty}^{a} K_1(a - \\theta) \\pi(\\theta \\mid \\mathbf{y}) \\, d\\theta + \\int_{a}^{\\infty} K_0 (\\theta - a) \\pi(\\theta \\mid \\mathbf{y}) \\, d\\theta. \\end{align*}\\] Differentiating with respect to \\(a\\), interchanging differentials and integrals, and equating to zero, we get: \\[\\begin{align*} K_1 \\int_{-\\infty}^{a^*} \\pi(\\theta \\mid \\mathbf{y}) \\, d\\theta - K_0 \\int_{a^*}^{\\infty} \\pi(\\theta \\mid \\mathbf{y}) \\, d\\theta &amp;= 0. \\end{align*}\\] Thus, we have \\[ \\int_{-\\infty}^{a^*} \\pi(\\theta \\mid \\mathbf{y}) \\, d\\theta = \\frac{K_0}{K_0 + K_1}, \\] that is, any \\(\\frac{K_0}{K_0 + K_1}\\)-percentile of \\(\\pi(\\theta \\mid \\mathbf{y})\\) is an optimal Bayesian estimate of \\(\\theta\\). We can also use decision theory under uncertainty in hypothesis testing. In particular, testing \\(H_0: \\theta \\in \\Theta_0\\) versus \\(H_1: \\theta \\in \\Theta_1\\), where \\(\\Theta = \\Theta_0 \\cup \\Theta_1\\) and \\(\\emptyset = \\Theta_0 \\cap \\Theta_1\\), there are two actions of interest, \\(a_0\\) and \\(a_1\\), where \\(a_j\\) denotes not rejecting \\(H_j\\), for \\(j = \\{0,1\\}\\). Given the \\(0-K_j\\) loss function: \\[\\begin{equation*} L(\\theta,a_j) = \\begin{cases} 0, &amp; \\text{if } \\theta \\in \\Theta_j, \\\\ K_j, &amp; \\text{if } \\theta \\in \\Theta_i, j \\neq i, \\end{cases} \\end{equation*}\\] where there is no loss if the right decision is made, for instance, not rejecting \\(H_0\\) when \\(\\theta \\in \\Theta_0\\), and the loss is \\(K_j\\) when an error is made. For example, a type I error occurs when rejecting the null hypothesis (\\(H_0\\)) when it is true (\\(\\theta \\in \\Theta_0\\)), which results in a loss of \\(K_1\\) due to choosing action \\(a_1\\), not rejecting \\(H_1\\). The posterior expected loss associated with decision \\(a_j\\), i.e., not rejecting \\(H_j\\), is: \\[ \\mathbb{E}[L(\\theta,a_j) \\mid \\mathbf{y}] = 0 \\times P(\\Theta_j \\mid \\mathbf{y}) + K_j P(\\Theta_i \\mid \\mathbf{y}) = K_j P(\\Theta_i \\mid \\mathbf{y}), \\quad j \\neq i. \\] Therefore, the Bayes optimal decision is the one that minimizes the posterior expected loss. That is, the null hypothesis is rejected (\\(a_1\\) is not rejected) when \\[ K_0 P(\\Theta_1 \\mid \\mathbf{y}) &gt; K_1 P(\\Theta_0 \\mid \\mathbf{y}). \\] Given our framework, \\(\\Theta = \\Theta_0 \\cup \\Theta_1\\) and \\(\\emptyset = \\Theta_0 \\cap \\Theta_1\\), we have \\(P(\\Theta_0 \\mid \\mathbf{y}) = 1 - P(\\Theta_1 \\mid \\mathbf{y})\\). As a result, the rejection region of the Bayesian test is: \\[ R = \\left\\{ \\mathbf{y} : P(\\Theta_1 \\mid \\mathbf{y}) &gt; \\frac{K_1}{K_1 + K_0} \\right\\}. \\] Decision theory also helps to construct interval (region) estimates. Let \\(\\Theta_{C(\\mathbf{y})} \\subset \\Theta\\) be a credible set for \\(\\theta\\), and let the loss function be defined as: \\[ L(\\theta, \\Theta_{C(\\mathbf{y})}) = 1 - \\mathbf{1}\\left\\{\\theta \\in \\Theta_{C(\\mathbf{y})}\\right\\}, \\] where \\[ \\mathbf{1}\\left\\{\\theta \\in \\Theta_{C(\\mathbf{y})}\\right\\} = \\begin{cases} 1, &amp; \\text{if } \\theta \\in \\Theta_{C(\\mathbf{y})}, \\\\ 0, &amp; \\text{if } \\theta \\notin \\Theta_{C(\\mathbf{y})}. \\end{cases} \\] Thus, the loss function becomes: \\[ L(\\theta, \\Theta_{C(\\mathbf{y})}) = \\begin{cases} 0, &amp; \\text{if } \\theta \\in \\Theta_{C(\\mathbf{y})}, \\\\ 1, &amp; \\text{if } \\theta \\notin \\Theta_{C(\\mathbf{y})}. \\end{cases} \\] This is a 0-1 loss function, which equals zero when \\(\\theta \\in \\Theta_{C(\\mathbf{y})}\\) and equals one when \\(\\theta \\notin \\Theta_{C(\\mathbf{y})}\\). Consequently, the risk function is: \\[ 1 - P(\\theta \\in \\Theta_{C(\\mathbf{y})}). \\] Given a measure of credibility \\(\\alpha(\\mathbf{y})\\) that defines the level of trust that \\(\\theta \\in \\Theta_{C(\\mathbf{y})}\\), we can measure the accuracy of the report by the loss function: \\[ L(\\theta, \\alpha(\\mathbf{y})) = \\left[\\mathbf{1}\\left\\{\\theta \\in \\Theta_{C(\\mathbf{y})}\\right\\} - \\alpha(\\mathbf{y})\\right]^2. \\] This loss function could be used to suggest a choice of the report \\(\\alpha(\\mathbf{y})\\). Given that this is a quadratic loss function, the optimal action is the posterior mean, that is, \\[ \\mathbb{E}[\\mathbf{1}\\left\\{\\theta \\in \\Theta_{C(\\mathbf{y})}\\right\\} \\mid \\mathbf{y}] = P(\\theta \\in \\Theta_{C(\\mathbf{y})} \\mid \\mathbf{y}). \\] This probability can be calculated given the posterior distribution as \\[ P(\\theta \\in \\Theta_{C(\\mathbf{y})} \\mid \\mathbf{y}) = \\int_{\\Theta_{C(\\mathbf{y})}} \\pi(\\theta \\mid \\mathbf{y}) \\, d\\theta. \\] This represents a measure of the belief that \\(\\theta \\in \\Theta_{C(\\mathbf{y})}\\) given the prior beliefs and sample information. The set \\(\\Theta_{C(\\mathbf{y})} \\subset \\Theta\\) is a \\(100(1 - \\alpha)\\%\\) credible set with respect to \\(\\pi(\\theta \\mid \\mathbf{y})\\) if \\[ P(\\theta \\in \\Theta_{C(\\mathbf{y})} \\mid \\mathbf{y}) = \\int_{\\Theta_{C(\\mathbf{y})}} \\pi(\\theta \\mid \\mathbf{y}) \\, d\\theta = 1 - \\alpha. \\] Two alternatives for reporting credible sets are the symmetric credible set and the highest posterior density set (HPD). The former is based on the \\(\\frac{\\alpha}{2}\\%\\) and \\((1 - \\frac{\\alpha}{2})\\%\\) percentiles of the posterior distribution, and the latter is a \\(100(1 - \\alpha)\\%\\) credible interval for \\(\\theta\\) with the property that it has the smallest distance compared to any other \\(100(1 - \\alpha)\\%\\) credible interval for \\(\\theta\\) based on the posterior distribution. Specifically, \\[ C(\\mathbf{y}) = \\left\\{ \\theta : \\pi(\\theta \\mid \\mathbf{y}) \\geq k(\\alpha) \\right\\}, \\] where \\(k(\\alpha)\\) is the largest number such that \\[ \\int_{\\theta : \\pi(\\theta \\mid \\mathbf{y}) \\geq k(\\alpha)} \\pi(\\theta \\mid \\mathbf{y}) d\\theta = 1 - \\alpha. \\] The HPD set can be a collection of disjoint intervals when working with multimodal posterior densities. Additionally, HPD sets have the limitation of not necessarily being invariant under transformations. Decision theory can also be used to perform prediction (point, sets, or probabilistic). Suppose that there is a loss function \\(L(Y_0, a)\\) involving the prediction of \\(Y_0\\). Then, the expected loss is \\[ \\mathbb{E}_{Y_0}[L(Y_0, a)] = \\int_{\\mathcal{Y}_0} L(y_0, a) \\pi(y_0 \\mid \\mathbf{y}) \\, dy_0, \\] where \\(\\pi(y_0 \\mid \\mathbf{y})\\) is the predictive density function. Thus, we make an optimal choice for prediction that minimizes the risk function given a specific loss function. Although Bayesian Model Averaging (BMA) allows for incorporating model uncertainty in a regression framework, sometimes it is desirable to select just one model. A compelling alternative is to choose the model with the highest posterior model probability. This model is the best alternative for prediction in the case of a 0-1 loss function (Clyde and George 2004). Example: Health insurance continues We show some optimal rules in the health insurance example, specifically the best point estimates of \\(\\lambda\\) under the quadratic, absolute, and generalized absolute loss functions. For the generalized absolute loss function, we assume that underestimating \\(\\lambda\\) is twice as costly as overestimating it, i.e., \\(K_0 = 2\\) and \\(K_1 = 1\\). Given that the posterior distribution of \\(\\lambda\\) is \\(G(\\alpha_0 + \\sum_{i=1}^N y_i, \\frac{\\beta_0}{\\beta_0 N + 1})\\), and using the hyperparameters from empirical Bayes, we obtain the following optimal point estimates: The posterior mean: \\(\\mathbb{E}[\\lambda \\mid \\mathbf{y}] = \\alpha_n \\beta_n = 1.2\\), The posterior median: 1.19, The 2/3-th quantile: 1.26. These are the optimal point estimates for the quadratic, absolute, and generalized absolute loss functions, respectively. In addition, we test the null hypothesis \\(H_0: \\lambda \\in [0, 1)\\) versus the alternative hypothesis \\(H_1: \\lambda \\in [1, \\infty)\\), setting \\(K_0 = K_1 = 1\\). We should reject the null hypothesis since \\(P(\\lambda \\in [0, 1)) = 0.9 &gt; \\frac{K_1}{K_0 + K_1} = 0.5\\). The 95% symmetric credible interval is \\((0.91, 1.53)\\), and the highest posterior density (HPD) interval is \\((0.90, 1.51)\\). Finally, the optimal point prediction under the quadratic loss function is 1.2, which is the mean value of the posterior predictive distribution. The optimal model, assuming a 0-1 loss function, is the model using the hyperparameters from the empirical Bayes procedure, since the posterior model probability of this model is approximately 1, whereas the posterior model probability of the model using vague hyperparameters is approximately 0. an &lt;- sum(y) + a0EB # Posterior shape parameter bn &lt;- b0EB / (N*b0EB + 1) # Posterior scale parameter S &lt;- 1000000 # Number of posterior draws Draws &lt;- rgamma(1000000, shape = an, scale = bn) # Posterior draws ###### Point estimation ######## OptQua &lt;- an*bn # Mean: Optimal choice quadratic loss function OptQua ## [1] 1.200952 OptAbs &lt;- qgamma(0.5, shape = an, scale = bn) # Median: Optimal choice absolute loss function OptAbs ## [1] 1.194034 # Setting K0 = 2 and K1 = 1, that is, to underestimate lambda is twice as costly as to overestimate it. K0 &lt;- 2; K1 &lt;- 1 OptGenAbs &lt;- quantile(Draws, K0/(K0 + K1)) # Median: Optimal choice generalized absolute loss function OptGenAbs ## 66.66667% ## 1.263182 ###### Hypothesis test ######## # H0: lambda in [0,1) vs H1: lambda in [1, Inf] K0 &lt;- 1; K1 &lt;- 1 ProbH0 &lt;- pgamma(1, shape = an, scale = bn) ProbH0 # Posterior probability H0 ## [1] 0.09569011 ProbH1 &lt;- 1 -ProbH0 ProbH1 # Posterior probability H1 ## [1] 0.9043099 # We should reject H0 given ProbH1 &gt; K1 / (K0 + K1) ###### Credible intervals ######## LimInf &lt;- qgamma(0.025, shape = an, scale = bn) # Lower bound LimInf ## [1] 0.9114851 LimSup &lt;- qgamma(0.975, shape = an, scale = bn) # Upper bound LimSup ## [1] 1.529724 HDI &lt;- HDInterval::hdi(Draws, credMass = 0.95) # Highest posterior density credible interval HDI ## lower upper ## 0.9007934 1.5163109 ## attr(,&quot;credMass&quot;) ## [1] 0.95 ###### Predictive optimal choices ######## p &lt;- bn / (bn + 1) # Probability negative binomial density OptPred &lt;- p/(1-p)*an # Optimal point prediction given a quadratic loss function in prediction OptPred ## [1] 1.200952 References "],["summary.html", "1.4 Summary", " 1.4 Summary We introduce Bayes’ rule to update probabilistic statements using humorous examples. We then study the three key probabilistic objects in Bayesian inference: the posterior distribution, the marginal likelihood, and the predictive density. The posterior distribution allows for inference regarding parameters, the marginal likelihood is required for hypothesis testing and model selection using the Bayes factor, and the predictive density enables probabilistic predictions. We also review some sampling properties of Bayesian estimators and the process of Bayes updating. All of these concepts were illustrated using a simple example in R software. Finally, we introduce decision theory concepts that can be applied to report summary statistics while minimizing posterior expected losses. "],["exercises.html", "1.5 Exercises", " 1.5 Exercises The Court Case: The Blue or Green Cab A cab was involved in a hit-and-run accident at night. There are two cab companies in the town: Blue and Green. The former has 150 cabs, and the latter has 850 cabs. A witness stated that a blue cab was involved in the accident; the court tested the reliability of the witness under similar circumstances and found that 80% of the time the witness correctly identified the color of the cab. What is the probability that the color of the cab involved in the accident was blue, given that the witness said it was blue? The Monty Hall Problem What is the probability of winning a car in the Monty Hall problem if you switch your decision, when there are four doors, three goats, and one car? Solve this problem both analytically and computationally. What if there are \\(n\\) doors, \\(n-1\\) goats, and one car? Solve the health insurance example using a Gamma prior in the rate parametrization, that is, \\(\\pi(\\lambda) = \\frac{\\beta_0^{\\alpha_0}}{\\Gamma(\\alpha_0)} \\lambda^{\\alpha_0 - 1} \\exp\\left\\{-\\lambda \\beta_0\\right\\}\\). Suppose you are analyzing the decision to buy car insurance for the next year. To make a better decision, you want to know: What is the probability that you will have a car claim next year? You have the records of your car claims over the last 15 years, \\(\\mathbf{y} = \\left\\{ 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0 \\right\\}\\). Assume that this is a random sample from a data-generating process (statistical model) that is Bernoulli, \\(Y_i \\sim \\text{Ber}(p)\\). Your prior beliefs about \\(p\\) are well described by a Beta distribution with parameters \\(\\alpha_0\\) and \\(\\beta_0\\), i.e., \\(p \\sim B(\\alpha_0, \\beta_0)\\). You are interested in calculating the probability of a claim the next year, \\(P(Y_0 = 1 \\mid \\mathbf{y})\\). Solve this using both an empirical Bayes approach and a non-informative approach where \\(\\alpha_0 = \\beta_0 = 1\\) (uniform distribution). Show that, given the loss function \\(L(\\theta, a) = |\\theta - a|\\), the optimal decision rule minimizing the risk function, \\(a^*(\\mathbf{y})\\), is the median. "],["Chap2.html", "Chapter 2 Conceptual differences between the Bayesian and Frequentist approaches", " Chapter 2 Conceptual differences between the Bayesian and Frequentist approaches We outline some of the conceptual differences between the Bayesian and Frequentist inferential approaches. We emphasize Bayesian concepts, as most readers may already be familiar with the Frequentist statistical framework. We illustrate the differences between these two inferential approaches using a simple example. In addition, we provide some potential explanations for why the Bayesian inferential framework is not well known at the introductory level among practitioners and applied researchers. "],["sec21.html", "2.1 The concept of probability", " 2.1 The concept of probability Let’s begin with the following thought experiment: Assume that you are watching the international game show “Who Wants to Be a Millionaire?”. The contestant is asked to answer a very simple question: What is the last name of the brothers who are credited with inventing the world’s first successful motor-operated airplane? What is the probability that the contestant answers this question correctly? Unless you have: watched this particular contestant participate in this show many times, seen him asked this same question each time, and computed the relative frequency with which he gives the correct answer, you need to answer this question as a Bayesian! Uncertainty about the event answering this question needs to be expressed as a “degree of belief,” informed by both data on the skill of the particular participant and how much he knows about inventors, as well as possibly prior knowledge of his performance in other game shows. Of course, your prior knowledge of the contestant may be minimal, or it may be well-informed. Either way, your final answer remains a degree of belief about an uncertain, and inherently unrepeatable, state of nature. The point of this hypothetical, light-hearted scenario is simply to highlight that a key distinction between the Frequentist and Bayesian approaches to inference is not the use (or nature) of prior information, but the manner in which probability is used. To the Bayesian, probability is the mathematical construct used to quantify uncertainty about an unknown state of nature, conditional on observed data and prior knowledge about the context in which that state occurs. To the Frequentist, probability is intrinsically linked to the concept of a repeated experiment, and the relative frequency with which a particular outcome occurs, conditional on that unknown state. This distinction remains key whether the Bayesian chooses to be informative or subjective in the specification of prior information, or chooses to be non-informative or objective. Frequentists consider probability to be a physical phenomenon, like mass or wavelength, whereas Bayesians stipulate that probability exists in the mind of scientists, as any scientific construct (Parmigiani and Inoue 2008). It seems that the understanding of the concept of probability for the common human being is more associated with “degrees of belief” rather than relative frequency. Peter Diggle, President of The Royal Statistical Society between 2014 and 2016, was asked in an interview, “A different trend which has surged upwards in statistics during Peter’s career is the popularity of Bayesian statistics. Does Peter consider himself a Bayesian?” He replied, “… you can’t not believe in Bayes’ theorem because it’s true. But that doesn’t make you a Bayesian in the philosophical sense. When people are making personal decisions – even if they don’t formally process Bayes’ theorem in their mind – they are adapting what they think they should believe in response to new evidence as it comes in. Bayes’ theorem is just the formal mathematical machinery for doing that.” However, we should mention that psychological experiments suggest that human beings suffer from anchoring, a cognitive bias that causes us to rely too heavily on previous information (the prior), so that the updating process (posterior) due to new information (likelihood) is not as strong as Bayes’ rule would suggest (Kahneman 2011). References "],["sec22.html", "2.2 Subjectivity is not the key", " 2.2 Subjectivity is not the key The concepts of subjectivity and objectivity indeed characterize both statistical paradigms in differing ways. Among Bayesians, there are those who are immersed in subjective rationality (Ramsey 1926; Finetti 1937; Savage 1954; D. V. Lindley 2000), but others who adopt objective prior distributions such as Jeffreys’, reference, empirical, or robust priors (T. Bayes 1763; P. Laplace 1812; H. Jeffreys 1961; J. Berger 2006) to operationalize Bayes’ rule and thereby weight quantitative (data-based) evidence. Among Frequentists, there are choices made about significance levels which, if not explicitly subjective, are typically not grounded in any objective and documented assessment of the relative losses of Type I and Type II errors.13 In addition, both Frequentist and Bayesian statisticians make decisions about the form of the data generating process, or “model”, which – if not subject to rigorous diagnostic assessment – retains a subjective element that potentially influences the final inferential outcome. Although we all know that by definition, a model is a schematic and simplified approximation to reality, “Since all models are wrong, the scientist cannot obtain a correct one by excessive elaboration. On the contrary, following William of Occam, he should seek an economical description of natural phenomena.” (G. E. P. Box 1976). We also know that “All models are wrong, but some are useful” (G. E. Box 1979), which is why model diagnostics are important. This task can be performed in both approaches. Particularly, the Bayesian framework can use predictive p-values for absolute testing (A. Gelman and Meng 1996; M. Bayarri and Berger 2000) or posterior odds ratios for relative statements (H. Jeffreys 1935; R. E. Kass and Raftery 1995). This is because the marginal likelihood, conditional on data, is interpreted as the evidence for the prior distribution (J. Berger 1993). In addition, what does objectivity mean in a Frequentist approach? For example, why should we use a 5% or 1% significance level rather than any other value? As someone said, the apparent objectivity is really a consensus (D. V. Lindley 2000). In fact, “Student” (William Gosset) saw statistical significance at any level as being “nearly valueless” in itself (Ziliak 2008). But, this is not just a situation in the Frequentist approach. The cut-offs used to “establish” scientific evidence against a null hypothesis, in terms of \\(log_{10}\\) scale (H. Jeffreys 1961) or \\(log_{e}\\) scale (R. E. Kass and Raftery 1995) as shown in Table 1.1, are also ad hoc. Although the true state of nature in Bayesian inference is expressed in “degrees of belief”, the distinction between the two paradigms does not reside in one being more, or less, subjective than the other. Rather, the differences are philosophical, pedagogical, and methodological. References "],["sec23.html", "2.3 Estimation, hypothesis testing and prediction", " 2.3 Estimation, hypothesis testing and prediction All that is required to perform estimation, hypothesis testing (model selection), and prediction in the Bayesian approach is to apply Bayes’ rule. This ensures coherence under a probabilistic view. However, there is no free lunch: coherence reduces flexibility. On the other hand, the Frequentist approach may not be coherent from a probabilistic point of view, but it is highly flexible. This approach can be seen as a toolkit that offers inferential solutions under the umbrella of understanding probability as relative frequency. For instance, a point estimator in a Frequentist approach is found such that it satisfies good sampling properties like unbiasedness, efficiency, or a large sample property such as consistency. A notable difference is that optimal Bayesian decisions are calculated by minimizing the expected value of the loss function with respect to the posterior distribution, i.e., conditional on observed data. In contrast, Frequentist “optimal” actions are based on the expected values over the distribution of the estimator (a function of data), conditional on the unknown parameters. This involves considering sampling variability. The Bayesian approach allows for the derivation of the posterior distribution of any unknown object, such as parameters, latent variables, future or unobserved variables, or models. A major advantage is that predictions can account for estimation error, and predictive distributions (probabilistic forecasts) can be easily derived. Hypothesis testing (model selection) in the Bayesian framework is based on inductive logic reasoning (inverse probability). Based on observed data, we evaluate which hypothesis is most tenable, performing this evaluation using posterior odds. These odds are in turn based on Bayes factors, which assess the evidence in favor of a null hypothesis while explicitly considering the alternative (R. E. Kass and Raftery 1995), following the rules of probability (D. V. Lindley 2000). This approach compares how well hypotheses predict data (Goodman 1999), minimizes the weighted sum of type I and type II error probabilities (DeGroot 1975; Pericchi and Pereira 2015), and takes into account the implicit balance of losses (H. Jeffreys 1961; J. Bernardo and Smith 1994). Posterior odds allow for the use of the same framework to analyze nested and non-nested models and perform model averaging. However, Bayes factors cannot be based on improper or vague priors (G. M. Koop 2003), the practical interplay between model selection and posterior distributions is not as straightforward as it may be in the Frequentist approach, and the computational burden can be more demanding due to the need to solve potentially difficult integrals. On the other hand, the Frequentist approach establishes most of its estimators as the solution to a system of equations. Observe that optimization problems often reduce to solving systems. We can potentially obtain the distribution of these estimators, but most of the time, asymptotic arguments or resampling techniques are required. Hypothesis testing relies on pivotal quantities and/or resampling, and prediction is typically based on a plug-in approach, which means that estimation error is not taken into account.14 In addition, ancillary statistics can be used to build prediction intervals.15 Comparing models depends on their structure. For instance, there are different Frequentist statistical approaches to compare nested and non-nested models. A nice feature in some situations is that there is a practical interplay between hypothesis testing and confidence intervals. For example, in the normal population mean hypothesis framework, you cannot reject a null hypothesis \\(H_0: \\mu = \\mu^0\\) at the \\(\\alpha\\) significance level (Type I error) if \\(\\mu^0\\) is in the \\(1-\\alpha\\) confidence interval. Specifically, \\[ P\\left( \\mu \\in \\left[\\hat{\\mu} - |t_{N-1}^{\\alpha/2}| \\times \\hat{\\sigma}_{\\hat{\\mu}}, \\hat{\\mu} + |t_{N-1}^{\\alpha/2}| \\times \\hat{\\sigma}_{\\hat{\\mu}}\\right] \\right) = 1 - \\alpha, \\] where \\(\\hat{\\mu}\\) and \\(\\hat{\\sigma}_{\\hat{\\mu}}\\) are the maximum likelihood estimators of the mean and standard error, \\(t_{N-1}^{\\alpha/2}\\) is the quantile value of the Student’s \\(t\\)-distribution at the \\(\\alpha/2\\) probability level with \\(N-1\\) degrees of freedom, and \\(N\\) is the sample size. A remarkable difference between the Bayesian and Frequentist inferential frameworks is the interpretation of credible/confidence intervals. Observe that once we have estimates, such that, for example, the previous interval is \\([0.2, 0.4]\\) given a 95% confidence level, we cannot say that \\(P(\\mu \\in [0.2, 0.4]) = 0.95\\) in the Frequentist framework. In fact, this probability is either 0 or 1 in this approach, as \\(\\mu\\) is either in the interval or it is not. The problem is that we will never know for certain in applied settings. This is because \\[ P(\\mu \\in [\\hat{\\mu} - |t_{N-1}^{0.025}| \\times \\hat{\\sigma}_{\\hat{\\mu}}, \\hat{\\mu} + |t_{N-1}^{0.025}| \\times \\hat{\\sigma}_{\\hat{\\mu}}]) = 0.95 \\] is interpreted in the context of repeated sampling. On the other hand, once we have the posterior distribution in the Bayesian framework, we can say that \\(P(\\mu \\in [0.2, 0.4]) = 0.95\\). Following common practice, most researchers and practitioners conduct hypothesis testing based on the p-value in the Frequentist framework. But what is a p-value? Most users do not know the answer, as statistical inference is often not performed by statisticians (J. Berger 2006).16 A p-value is the probability of obtaining a statistical summary of the data equal to or more extreme than what was actually observed, assuming that the null hypothesis is true. Therefore, p-value calculations involve not just the observed data, but also more extreme hypothetical observations. Thus, “What the use of p implies, therefore, is that a hypothesis that may be true may be rejected because it has not predicted observable results that have not occurred.” (H. Jeffreys 1961) It seems that common Frequentist inferential practice intertwines two different logical reasoning arguments: the p-value (Fisher 1958) and the significance level (Neyman and Pearson 1933). The former is an informal short-run criterion, whose philosophical foundation is reduction to absurdity, which measures the discrepancy between the data and the null hypothesis. Therefore, the p-value is not a direct measure of the probability that the null hypothesis is false. The latter, whose philosophical foundation is deduction, is based on long-run performance and controls the overall number of incorrect inferences in repeated sampling, without regard to individual cases. The p-value fallacy consists of interpreting the p-value as the strength of evidence against the null hypothesis and using it simultaneously with the frequency of Type I error under the null hypothesis (Goodman 1999). The American Statistical Association has several concerns regarding the use of the p-value as a cornerstone for hypothesis testing in science. This concern motivates the ASA’s statement on p-values (Wasserstein and Lazar 2016), which can be summarized in the following principles: “P-values can indicate how incompatible the data are with a specified statistical model.” “P-values do not measure the probability that the studied hypothesis is true, or the probability that the data were produced by random chance alone.” “Scientific conclusions and business or policy decisions should not be based solely on whether a p-value passes a specific threshold.” “Proper inference requires full reporting and transparency.” “A p-value, or statistical significance, does not measure the size of an effect or the importance of a result.” “By itself, a p-value does not provide a good measure of evidence regarding a model or hypothesis.” To sum up, Fisher proposed the p-value as a witness rather than a judge. So, a p-value lower than the significance level means more inspection of the null hypothesis, but it is not a final conclusion about it. Another difference between the Frequentists and the Bayesians is the way in which scientific hypotheses are tested. The former use the p-value, whereas the latter use the Bayes factor. Observe that the p-value is associated with the probability of the data given the hypothesis, whereas the Bayes factor is associated with the probability of the hypothesis given the data. However, there is an approximate link between the \\(t\\) statistic and the Bayes factor for regression coefficients (A. Raftery 1995). In particular, \\[ |t|&gt;(\\log(N)+6)^{1/2} \\] corresponds to strong evidence in favor of rejecting the null hypothesis of no relevance of a control in a regression. Observe that, in this setting, the threshold of the \\(t\\) statistic, and as a consequence the significance level, depends on the sample size. This setting agrees with the idea in experimental designs of selecting the sample size such that we control Type I and Type II errors. In observational studies, we cannot control the sample size, but we can select the significance level. See also Sellke, Bayarri, and Berger (2001) and Benjamin et al. (2018) for exercises that reveal potential flaws of the p-value (\\(p\\)) due to \\(p \\sim U[0,1]\\) under the null hypothesis,17 and calibrations of the p-value to interpret it as the odds ratio and the error probability. In particular, \\[ B(p)=-e \\times p \\times \\log(p) \\quad \\text{when} \\quad p &lt; e^{-1} \\] and interpret this as the Bayes factor of \\(H_0\\) to \\(H_1\\), where \\(H_1\\) denotes the unspecified alternative to \\(H_0\\), and \\[ \\alpha(p) = \\left(1 + \\left[-e \\times p \\times \\log(p)\\right]^{-1}\\right)^{-1} \\] as the error probability \\(\\alpha\\) in rejecting \\(H_0\\). Take into account that \\(B(p)\\) and \\(\\alpha(p)\\) are lower bounds. The logic of argumentation in the Frequentist approach is based on deductive logic, which means that it starts from a statement about the true state of nature (null hypothesis) and predicts what should be observed if this statement were true. On the other hand, the Bayesian approach is based on inductive logic, which means that it defines which hypothesis is more consistent with what is observed. The former inferential approach establishes that the truth of the premises implies the truth of the conclusion, which is why we reject or fail to reject hypotheses. The latter establishes that the premises supply some evidence, but not full assurance, of the truth of the conclusion, which is why we get probabilistic statements. Here, there is a distinction between the effects of causes (forward causal inference) and the causes of effects (reverse causal inference) (Andrew Gelman and Imbens 2013; Dawid, Musio, and Fienberg 2016). To illustrate this point, imagine that a firm increases the price of a specific good. Economic theory would suggest that, as a result, demand for the good decreases. In this case, the premise (null hypothesis) is the price increase, and the consequence is the decrease in the firm’s demand. Alternatively, one could observe a reduction in a firm’s demand and attempt to identify the cause behind it. For example, a reduction in quantity could be due to a negative supply shock. The Frequentist approach typically follows the first view (effects of causes), while Bayesian reasoning focuses on determining the probability of potential causes (causes of effects). References "],["sec24.html", "2.4 The likelihood principle", " 2.4 The likelihood principle The likelihood principle states that in making inferences or decisions about the state of nature, all the relevant experimental information is given by the likelihood function. The Bayesian framework follows this statement, i.e., it is conditional on observed data. We follow J. Berger (1993), who in turn followed D. V. Lindley and Phillips (1976), to illustrate the likelihood principle. We are given a coin and are interested in the probability, \\(\\theta\\), of it landing heads when flipped. We wish to test \\(H_0: \\theta = 1/2\\) versus \\(H_1: \\theta &gt; 1/2\\). An experiment is conducted by flipping the coin (independently) in a series of trials, with the result being the observation of 9 heads and 3 tails. This is not yet enough information to specify \\(p(y|\\theta)\\), since the series of trials has not been explained. Two possibilities arise: The experiment consisted of a predetermined 12 flips, so that \\(Y = [ \\text{Heads} ]\\) follows a \\(B(12, \\theta)\\) distribution. In this case, \\[ p_1(y|\\theta) = \\binom{12}{y} \\theta^y (1 - \\theta)^{12 - y} = 220 \\times \\theta^9 (1 - \\theta)^3. \\] The experiment consisted of flipping the coin until 3 tails were observed (\\(r = 3\\)). In this case, \\(Y\\), the number of heads (failures) before obtaining 3 tails, follows a \\(NB(3, 1 - \\theta)\\) distribution. Here, \\[ p_2(y|\\theta) = \\binom{y + r - 1}{r - 1} (1 - (1 - \\theta)^y)(1 - \\theta)^r = 55 \\times \\theta^9 (1 - \\theta)^3. \\] Using a Frequentist approach, the significance level of \\(y=9\\) using the Binomial model against \\(\\theta=1/2\\) would be: \\[ \\alpha_1=P_{1/2}(Y\\geq 9)=p_1(9|1/2)+p_1(10|1/2)+p_1(11|1/2)+p_1(12|1/2)=0.073. \\] success &lt;- 9 # Number of observed success in n trials n &lt;- 12 # Number of trials siglevel &lt;- sum(sapply(9:n,function(y)dbinom(y,n,0.5))) siglevel ## [1] 0.07299805 For the Negative Binomial model, the significance level would be: \\[ \\alpha_2=P_{1/2}(Y\\geq 9)=p_2(9|1/2)+p_2(10|1/2)+\\ldots=0.0327. \\] success &lt;- 3 # Number of target success (tails) failures &lt;- 9 # Number of failures siglevel &lt;- 1 - pnbinom((failures - 1),success,0.5) siglevel ## [1] 0.03271484 We arrive at different conclusions using a significance level of 5%, whereas we obtain the same outcomes using a Bayesian approach because the kernels of both distributions are identical (\\(\\theta^9 \\times (1 - \\theta)^3\\)). References "],["sec25.html", "2.5 Why is not the Bayesian approach that popular?", " 2.5 Why is not the Bayesian approach that popular? At this stage, one might wonder why the Bayesian statistical framework is not the dominant inferential approach, despite its historical origin in 1763 (Thomas Bayes 1763), whereas the Frequentist statistical framework was largely developed in the early 20th century. The scientific debate over the Bayesian inferential approach lasted for 150 years, and this may be explained by some of the following factors. One issue is the apparent subjectivity of the Bayesian approach, which runs counter to the strong conviction that science demands objectivity. Bayesian probability is considered a measure of degrees of belief, where the initial prior may be just a guess. This was not accepted as objective and rigorous science. Initial critics argued that Bayes was quantifying ignorance by assigning equal probabilities to all potential outcomes. As a consequence, prior distributions were dismissed (McGrayne 2011). Bayes himself seemed not to have believed in his idea. Although it seems that Bayes made his breakthrough in the late 1740s, he did not submit it for publication to the Royal Society. It was his friend, Richard Price, another Presbyterian minister, who rediscovered Bayes’ idea, polished it, and published it. However, it was Laplace who independently generalized Bayes’ theorem in 1781. Initially, he applied it to gambling problems and soon thereafter to astronomy, combining various sources of information to advance research in situations where data was scarce. He later sought to apply his discovery to finding the probability of causes, which he thought required large datasets, thus turning to demography. In this field, he had to perform large-scale calculations, leading to the development of Laplace’s approximation and the central limit theorem (P. Laplace 1812). Unfortunately, this came at the cost of abandoning his research on Bayesian inference. Once Laplace passed away in 1827, Bayes’ rule disappeared from the scientific discourse for almost a century. In part, personal attacks against Laplace led to the rule being forgotten. Moreover, there was a prevailing belief that statistics should not address causation, and that the prior was too subjective to be compatible with science. Nonetheless, practitioners continued to use Bayes’ rule to solve problems in astronomy, communication, medicine, military affairs, and social issues with remarkable results. Thus, the concept of degrees of belief to operationalize probability was abandoned in favor of scientific objectivity. Probability was then defined as the frequency with which an event occurs in many repeatable trials, which became the accepted norm. Critics of Laplace argued that these two concepts were diametrically opposed, although Laplace considered them to be basically equivalent when large sample sizes are involved (McGrayne 2011). The era of Frequentists, or sampling theorists, began, led by Karl Pearson and his nemesis, Ronald Fisher. Both were brilliant and persuasive characters, opposing the inverse probability approach and making it nearly impossible to argue against their ideas. Pearson’s legacy was carried on by his son, Egon, and Egon’s friend, Jerzy Neyman. Both inherited the anti-Bayesian and anti-Fisher sentiments. Despite the anti-Bayesian campaign among statisticians, some independent thinkers continued to develop Bayesian ideas, including Borel, Ramsey, and de Finetti, who were isolated in different countries: France, England, and Italy. However, the anti-Bayesian trio of Fisher, Neyman, and Egon Pearson dominated the spotlight in the 1920s and 1930s. Only a geophysicist, Harold Jeffreys, kept Bayesian inference alive during the 1930s and 1940s. Jeffreys was a quiet, reserved gentleman working in the astronomy department at Cambridge. He was Fisher’s friend due to their shared character, although they were intellectual opposites when it came to Bayesian inference, leading to intense intellectual battles. Unfortunately for the Bayesian approach, Jeffreys lost. His work was highly technical, using confusing high-level mathematics. He focused on inference from scientific evidence, rather than guiding future actions based on decision theory, which was crucial in that era for mathematical statistics, especially during the Second World War. In contrast, Fisher was a dominant figure, persuasive in public and a master of practical applications, with his techniques written in a popular style with minimal mathematics. Nevertheless, Bayes’ rule achieved remarkable results in applied settings such as at AT&amp;T and the U.S. Social Security system. Bayesian inference also played a significant role during the Second World War and the Cold War. Alan Turing used inverse probability at Bletchley Park to crack German messages encoded using the Enigma machine, which was employed by U-boats. Andrei Kolmogorov used Bayesian methods to improve firing tables for Russian artillery. Bernard Koopman applied it for searching targets at sea, and the RAND Corporation used it during the Cold War. Unfortunately, these Bayesian developments remained top secret for almost 40 years, keeping the contribution of inverse probability hidden from modern history. In the 1950s and 1960s, three mathematicians led the resurgence of the Bayesian approach: Good, Savage, and Lindley. However, it seems that they were reluctant to apply their theories to real-world problems. Despite the fact that the Bayesian approach proved its worth in various areas such as business decisions, naval searches, and lung cancer detection, it was largely applied to simple models due to its mathematical complexity and requirement for large computations. However, some breakthroughs changed this. First, hierarchical models were introduced by Lindley and Smith, where a complex model is decomposed into many smaller, easier-to-solve models. Second, Markov chain Monte Carlo (MCMC) methods were developed by Hastings in the 1970s (Hastings 1970) and the Geman brothers in the 1980s (Geman and Geman 1984). These methods were incorporated into the Bayesian inferential framework in the 1990s by Gelfand and Smith (A. E. Gelfand and Smith 1990), and Tierney (Tierney 1994), when desktop computers gained sufficient computational power to solve complex models. Since then, the Bayesian inferential framework has gained increasing popularity among both practitioners and scientists. References "],["sec26.html", "2.6 A simple working example", " 2.6 A simple working example We will illustrate some conceptual differences between the Bayesian and Frequentist statistical approaches by performing inference on a random sample \\(\\mathbf{Y} = [Y_1, Y_2, \\dots, Y_N]\\), where \\(Y_i \\stackrel{iid}{\\sim} N(\\mu, \\sigma^2)\\) for \\(i = 1, 2, \\dots, N\\). In particular, we set \\(\\pi(\\mu, \\sigma) = \\pi(\\mu) \\pi(\\sigma) \\propto \\frac{1}{\\sigma}\\). This is a standard non-informative improper prior (Jeffreys prior, see Chapter 3). That is, this prior is perfectly compatible with the sample information. Additionally, we assume independent priors for \\(\\mu\\) and \\(\\sigma\\). \\[ \\begin{aligned} \\pi(\\mu,\\sigma|\\mathbf{y}) &amp;\\propto \\frac{1}{\\sigma}\\times (\\sigma^2)^{-N/2}\\exp\\left\\{-\\frac{1}{2\\sigma^2}\\sum_{i=1}^N (y_i-\\mu)^2\\right\\} \\\\ &amp;= \\frac{1}{\\sigma}\\times (\\sigma^2)^{-N/2}\\exp\\left\\{-\\frac{1}{2\\sigma^2}\\sum_{i=1}^N \\left((y_i-\\bar{y}) - (\\mu-\\bar{y})\\right)^2\\right\\} \\\\ &amp;= \\frac{1}{\\sigma}\\exp\\left\\{-\\frac{N}{2\\sigma^2}(\\mu-\\bar{y})^2\\right\\}\\times (\\sigma)^{-N}\\exp\\left\\{-\\frac{1}{2\\sigma^2}\\sum_{i=1}^N (y_i-\\bar{y})^2\\right\\} \\\\ &amp;= \\frac{1}{\\sigma}\\exp\\left\\{-\\frac{N}{2\\sigma^2}(\\mu-\\bar{y})^2\\right\\}\\times (\\sigma)^{-(\\alpha_n+1)}\\exp\\left\\{-\\frac{\\alpha_n\\hat{\\sigma}^2}{2\\sigma^2}\\right\\}, \\end{aligned} \\] where \\(\\bar{y} = \\frac{\\sum_{i=1}^N y_i}{N}\\), \\(\\alpha_n = N-1\\), and \\(\\hat{\\sigma}^2 = \\frac{\\sum_{i=1}^N (y_i-\\bar{y})^2}{N-1}\\). The first term in the last expression is the kernel of a normal density, \\(\\mu|\\sigma,\\mathbf{y} \\sim N(\\bar{y}, \\sigma^2 / N)\\). The second term is the kernel of an inverted gamma density (Zellner 1996), \\(\\sigma|\\mathbf{y} \\sim IG(\\alpha_n, \\hat{\\sigma}^2)\\). Therefore, \\[ \\pi(\\mu|\\sigma,\\mathbf{y}) = \\frac{1}{\\sqrt{2\\pi \\sigma^2 / N}} \\exp\\left\\{-\\frac{N}{2\\sigma^2}(\\mu-\\bar{y})^2\\right\\}, \\] and \\[ \\pi(\\sigma|\\mathbf{y}) = \\frac{2}{\\Gamma(\\alpha_n / 2)} \\left(\\frac{\\alpha_n \\hat{\\sigma}^2}{2}\\right)^{\\alpha_n / 2} \\frac{1}{\\sigma^{\\alpha_n+1}} \\exp\\left\\{-\\frac{\\alpha_n \\hat{\\sigma}^2}{2 \\sigma^2}\\right\\}. \\] Observe that \\(\\mathbb{E}[\\mu | \\sigma, \\mathbf{y}] = \\bar{y}\\); this is also the maximum likelihood (Frequentist) point estimate of \\(\\mu\\) in this setting. In addition, the Frequentist \\((1-\\alpha)\\%\\) confidence interval and the Bayesian \\((1-\\alpha)\\%\\) credible interval have exactly the same form, \\(\\bar{y} \\pm |z_{\\alpha/2}| \\frac{\\sigma}{\\sqrt{N}}\\), where \\(z_{\\alpha/2}\\) is the \\(\\alpha/2\\) percentile of a standard normal distribution. However, the interpretations are entirely different. The confidence interval has a probabilistic interpretation under sampling variability of \\(\\bar{Y}\\): in repeated sampling, \\((1-\\alpha)\\%\\) of the intervals \\(\\bar{Y} \\pm |z_{\\alpha/2}| \\frac{\\sigma}{\\sqrt{N}}\\) would include \\(\\mu\\). However, given an observed realization of \\(\\bar{Y}\\), say \\(\\bar{y}\\), the probability of \\(\\bar{y} \\pm |z_{\\alpha/2}| \\frac{\\sigma}{\\sqrt{N}}\\) including \\(\\mu\\) is either 1 or 0. This is why we refer to it as a \\((1-\\alpha)\\%\\) confidence interval. On the other hand, \\(\\bar{y} \\pm |z_{\\alpha/2}| \\frac{\\sigma}{\\sqrt{N}}\\) has a straightforward probabilistic interpretation in the Bayesian framework: there is a \\((1-\\alpha)\\%\\) probability that \\(\\mu\\) lies within this interval. If we want to get the marginal posterior density of \\(\\mu\\), \\[\\begin{align*} \\pi(\\mu|\\mathbf{y})&amp;=\\int_{0}^{\\infty} \\pi(\\mu,\\sigma|\\mathbf{y}) d\\sigma\\\\ &amp;\\propto \\int_{0}^{\\infty} \\frac{1}{\\sigma}\\times (\\sigma^2)^{-N/2}\\exp\\left\\{-\\frac{1}{2\\sigma^2}\\sum_{i=1}^N (y_i-\\mu)^2\\right\\} d\\sigma\\\\ &amp;= \\int_{0}^{\\infty} \\left(\\frac{1}{\\sigma}\\right)^{N+1} \\exp\\left\\{-\\frac{N}{2\\sigma^2}\\frac{\\sum_{i=1}^N (y_i-\\mu)^2}{N}\\right\\} d\\sigma\\\\ &amp;=\\left[\\frac{2}{\\Gamma(N/2)}\\left(\\frac{N\\sum_{i=1}^N (y_i-\\mu)^2}{2N}\\right)^{N/2}\\right]^{-1}\\\\ &amp;\\propto \\left[\\sum_{i=1}^N (y_i-\\mu)^2\\right]^{-N/2}\\\\ &amp;=\\left[\\sum_{i=1}^N ((y_i-\\bar{y})-(\\mu-\\bar{y}))^2\\right]^{-N/2}\\\\ &amp;=[\\alpha_n\\hat{\\sigma}^2+N(\\mu-\\bar{y})^2]^{-N/2}\\\\ &amp;\\propto \\left[1+\\frac{1}{\\alpha_n}\\left(\\frac{\\mu-\\bar{y}}{\\hat{\\sigma}/\\sqrt{N}}\\right)^2\\right]^{-(\\alpha_n+1)/2}. \\end{align*}\\] The fourth line arises from the kernel of an inverted gamma density with \\(N\\) degrees of freedom in the integral (Zellner 1996). The last expression represents the kernel of a Student’s \\(t\\)-distribution with \\(\\alpha_n = N - 1\\) degrees of freedom, expected value equal to \\(\\bar{y}\\), and variance \\(\\frac{\\hat{\\sigma}^2}{N} \\left( \\frac{\\alpha_n}{\\alpha_n - 2} \\right)\\). Therefore, \\(\\mu | \\mathbf{y} \\sim t \\left( \\bar{y}, \\frac{\\hat{\\sigma}^2}{N} \\left( \\frac{\\alpha_n}{\\alpha_n - 2} \\right), \\alpha_n \\right)\\). Observe that a \\((1-\\alpha)\\%\\) confidence interval and a \\((1-\\alpha)\\%\\) credible interval have exactly the same form, \\(\\bar{y} \\pm |t_{\\alpha/2}^{\\alpha_n}| \\frac{\\hat{\\sigma}}{\\sqrt{N}}\\), where \\(t_{\\alpha/2}^{\\alpha_n}\\) is the \\(\\alpha/2\\) percentile of a Student’s \\(t\\)-distribution. However, the interpretations are entirely different. The mathematical similarity between the Frequentist and Bayesian expressions in this example arises from the use of an improper prior. Example: Math test You have a random sample of math scores of size \\(N = 50\\) from a normal distribution, \\(Y_i \\sim N(\\mu, \\sigma^2)\\). The sample mean and variance are equal to 102 and 10, respectively. Assuming an improper prior equal to \\(\\frac{1}{\\sigma}\\), we proceed with the following tasks: Compute the 95% confidence and credible intervals for \\(\\mu\\). Determine the posterior probability that \\(\\mu &gt; 103\\). Using the fact that \\(\\mu | \\mathbf{y} \\sim t\\left(\\bar{y}, \\frac{\\hat{\\sigma}^2}{N} \\left( \\frac{\\alpha_n}{\\alpha_n - 2} \\right), \\alpha_n \\right)\\), which implies that the confidence and credible intervals for \\(\\mu\\) are given by: \\[ \\begin{aligned} \\bar{y} \\pm |t_{\\alpha/2}^{\\alpha_n}| \\frac{\\hat{\\sigma}}{\\sqrt{N}}, \\end{aligned} \\] where \\(\\bar{y} = 102\\), \\(\\hat{\\sigma}^2 = 10\\), and \\(\\alpha_n = 49\\). Thus, the 95% confidence and credible intervals for \\(\\mu\\) are the same, namely \\((101.1, 102.9)\\), and the posterior probability that \\(\\mu &gt; 103\\) is 1.49% given the sample information. N &lt;- 50 # Sample size y_bar &lt;- 102 # Sample mean s2 &lt;- 10 # Sample variance alpha &lt;- N - 1 serror &lt;- (s2/N)^0.5 LimInf &lt;- y_bar - abs(qt(0.025, alpha)) * serror LimInf ## [1] 101.1013 # Lower bound LimSup &lt;- y_bar + abs(qt(0.025, alpha)) * serror LimSup ## [1] 102.8987 # Upper bound y.cut &lt;- 103 P &lt;- 1-metRology::pt.scaled(y.cut, df = alpha, mean = y_bar, sd = serror) P ## [1] 0.01496694 # Probability of mu greater than y.cut References "],["sec27.html", "2.7 Summary", " 2.7 Summary The differences between the Bayesian and Frequentist inferential approaches are philosophical, particularly with regard to the role of probability; pedagogical, especially in relation to the use of inference for decision-making; and methodological, due to differences in their mathematical and computational frameworks. Although, at the methodological level, the debate has become considerably muted —except for certain aspects of inference— there is widespread recognition that each approach has much to contribute to statistical practice (Good (1992), M. J. Bayarri and Berger (2004), R. Kass (2011)). As Bradley Efron stated, “Computer-age statistical inference at its most successful combines elements of the two philosophies” (Bradley Efron and Hastie (2016)). References "],["sec28.html", "2.8 Exercises", " 2.8 Exercises Jeffreys-Lindley’s Paradox The Jeffreys-Lindley’s paradox (H. Jeffreys 1961; Dennis V. Lindley 1957) represents an apparent disagreement between the Bayesian and Frequentist frameworks in a hypothesis testing scenario. In particular, assume that in a city, 49,581 boys and 48,870 girls have been born over 20 years. Assume that the male births follow a Binomial distribution with probability \\(\\theta\\). We wish to test the null hypothesis \\(H_0: \\ \\theta = 0.5\\) versus the alternative hypothesis \\(H_1: \\ \\theta \\neq 0.5\\). Show that the posterior model probability for the null model is approximately 0.95. Assume \\(\\pi(H_0) = \\pi(H_1) = 0.5\\), and that \\(\\pi(\\theta)\\) follows a uniform distribution, i.e., \\({U}(0,1)\\), under \\(H_1\\). Show that the p-value for this hypothesis test is 0.0235 using the normal approximation, \\(Y \\sim N(N \\times \\theta, N \\times \\theta \\times (1 - \\theta))\\). We want to test \\(H_0: \\ \\mu = \\mu_0\\) versus \\(H_1: \\ \\mu \\neq \\mu_0\\) given \\(Y_i \\stackrel{iid}{\\sim} N(\\mu, \\sigma^2)\\). Assume \\(\\pi(H_0) = \\pi(H_1) = 0.5\\), and that \\(\\pi(\\mu, \\sigma) \\propto 1/\\sigma\\) under the alternative hypothesis. Show that \\[ p(\\mathbf{y}|\\mathcal{M}_1) = \\frac{\\pi^{-N/2}}{2} \\Gamma(N/2) 2^{N/2} \\left( \\frac{1}{\\alpha_n \\hat{\\sigma}^2} \\right)^{N/2} \\left( \\frac{N}{\\alpha_n \\hat{\\sigma}^2} \\right)^{-1/2} \\frac{\\Gamma(1/2) \\Gamma(\\alpha_n/2)}{\\Gamma((\\alpha_n+1)/2)} \\] and \\[ p(\\mathbf{y}|\\mathcal{M}_0) = (2\\pi)^{-N/2} \\left[ \\frac{2}{\\Gamma(N/2)} \\left( \\frac{N}{2} \\frac{\\sum_{i=1}^N (y_i - \\mu_0)^2}{N} \\right)^{N/2} \\right]^{-1}. \\] Then, the posterior odds ratio is: \\[ PO_{01} = \\frac{p(\\mathbf{y}|\\mathcal{M}_0)}{p(\\mathbf{y}|\\mathcal{M}_1)} = \\frac{\\Gamma((\\alpha_n+1)/2)}{\\Gamma(1/2)\\Gamma(\\alpha_n/2)} (\\alpha_n \\hat{\\sigma}^2 / N)^{-1/2} \\left[ 1 + \\frac{(\\mu_0 - \\bar{y})^2}{\\alpha_n \\hat{\\sigma}^2 / N} \\right]^{-\\left(\\frac{\\alpha_n + 1}{2}\\right)}, \\] where \\(\\alpha_n = N - 1\\) and \\(\\hat{\\sigma}^2 = \\frac{\\sum_{i=1}^N (y_i - \\bar{y})^2}{N-1}\\). Find the relationship between the posterior odds ratio and the classical test statistic for the null hypothesis. Math Test Continues Using the setting of the Example: Math Test in Subsection 2.6, test \\(H_0: \\ \\mu = \\mu_0\\) versus \\(H_1: \\ \\mu \\neq \\mu_0\\) where \\(\\mu_0 = \\{ 100, 100.5, 101, 101.5, 102 \\}\\). What is the p-value for these hypothesis tests? Find the posterior model probability of the null model for each \\(\\mu_0\\). References "],["Chap3.html", "Chapter 3 Cornerstone models: Conjugate families", " Chapter 3 Cornerstone models: Conjugate families We will introduce conjugate families, which are distributions for which the posterior distribution belongs to the same family as the prior distribution, given the likelihood. We provide some examples and solve them both analytically and computationally. We begin with simple examples of discrete and continuous distributions and then study the linear model in detail, both univariate and multivariate, deriving the posterior distributions, the marginal likelihood, and the predictive distribution analytically. Additionally, we will include mathematical and computational exercises in R. "],["sec41.html", "3.1 Motivation of conjugate families", " 3.1 Motivation of conjugate families By observing the three fundamental pieces of Bayesian analysis –the posterior distribution (parameter inference), the marginal likelihood (hypothesis testing), and the predictive distribution (prediction)– as given in equations (3.1), (3.2), and (3.3), respectively, we can understand that some of the initial limitations of Bayesian analysis were due to the absence of algorithms for sampling from non-standard posterior distributions (equation (3.1)), and the lack of analytical solutions for the marginal likelihood (equation (3.2)) and the predictive distribution (equation (3.3)), both of which require significant computational power. \\[\\begin{align} \\pi(\\boldsymbol{\\theta}\\mid \\boldsymbol{y})&amp;=\\frac{p(\\boldsymbol{y}\\mid \\boldsymbol{\\theta}) \\times \\pi(\\boldsymbol{\\theta})}{p(\\boldsymbol{y})}, \\tag{3.1} \\end{align}\\] \\[\\begin{equation} p(\\boldsymbol{y})=\\int_{\\boldsymbol{\\Theta}}p(\\boldsymbol{y}\\mid \\boldsymbol{\\theta})\\pi(\\boldsymbol{\\theta})d\\boldsymbol{\\theta}, \\tag{3.2} \\end{equation}\\] and \\[\\begin{equation} p(\\boldsymbol{y}_0\\mid \\boldsymbol{y})=\\int_{\\boldsymbol{\\Theta}}p(\\boldsymbol{y}_0\\mid \\boldsymbol{\\theta})\\pi(\\boldsymbol{\\theta}\\mid \\boldsymbol{y})d\\boldsymbol{\\theta}, \\tag{3.3} \\end{equation}\\] Although algorithms for sampling from non-standard posterior distributions have existed since the second half of the last century (Metropolis et al. 1953; Hastings 1970; Geman and Geman 1984), their application within the Bayesian framework emerged later (A. E. Gelfand and Smith 1990; Tierney 1994), likely coinciding with the rise in computational power of desktop computers. However, it is still common practice today to use models with standard conditional posterior distributions in order to reduce computational requirements. In addition, mathematical techniques coupled with computational algorithms (Alan E. Gelfand and Dey 1994; Siddhartha Chib 1995; Siddhartha Chib and Jeliazkov 2001) and approximations (Tierney and Kadane 1986, Jordan1999) are employed to obtain the marginal likelihood (prior predictive). Despite these advances, two potentially conflicting desirable model specification features are evident from equations (3.1), (3.2), and (3.3): (1) analytical solutions and (2) the posterior distribution belonging to the same family as the prior distribution for a given likelihood. The latter is known as conjugate priors, a family of priors that is closed under sampling (Schlaifer and Raiffa 1961). These features are desirable because the former facilitates hypothesis testing and predictive analysis, while the latter ensures invariance in the prior-to-posterior updating process. Both features reduce computational burden. Although each of these features can be achieved independently –such as using improper priors for analytical tractability and broadly defining the family of priors for conjugacy– these features are in conflict. Fortunately, we can achieve both characteristics if we assume that the data-generating process follows a distribution function in the exponential family. That is, given a random sample \\(\\boldsymbol{Y}=[Y_1 \\ Y_2 \\ \\dots \\ Y_N]^{\\top}\\), a probability density function \\(p(\\boldsymbol{y}\\mid \\boldsymbol{\\theta})\\) belongs to the exponential family if it has the form: \\[\\begin{align} p(\\boldsymbol{y}\\mid \\boldsymbol{\\theta})&amp;=\\prod_{i=1}^N h(y_i) C(\\boldsymbol{\\theta}) \\exp\\left\\{\\eta(\\boldsymbol{\\theta})^{\\top}\\boldsymbol{T}(y_i)\\right\\}\\tag{3.4}\\\\ &amp;=h(\\boldsymbol{y}) C(\\boldsymbol{\\theta})^N\\exp\\left\\{\\eta(\\boldsymbol{\\theta})^{\\top}\\boldsymbol{T}(\\boldsymbol{y})\\right\\}\\nonumber \\\\ &amp;=h(\\boldsymbol{y})\\exp\\left\\{\\eta(\\boldsymbol{\\theta})^{\\top}\\boldsymbol{T}(\\boldsymbol{y})-A(\\boldsymbol{\\theta})\\right\\}\\nonumber, \\end{align}\\] Where \\(h(\\boldsymbol{y}) = \\prod_{i=1}^N h(y_i)\\) is a non-negative function, \\(\\eta(\\boldsymbol{\\theta})\\) is a known function of the parameters, and \\(A(\\boldsymbol{\\theta}) = \\log\\left\\{ \\int_{\\boldsymbol{Y}} h(\\boldsymbol{y}) \\exp\\left\\{ \\eta(\\boldsymbol{\\theta})^{\\top} \\boldsymbol{T}(\\boldsymbol{y}) \\right\\} d\\boldsymbol{y} \\right\\} = -N \\log\\left(C(\\boldsymbol{\\theta})\\right)\\) is the normalization factor. Additionally, \\(\\boldsymbol{T}(\\boldsymbol{y}) = \\sum_{i=1}^N \\boldsymbol{T}(y_i)\\) is the vector of sufficient statistics for the distribution (by the factorization theorem). If the support of \\(\\boldsymbol{Y}\\) is independent of \\(\\boldsymbol{\\theta}\\), the family is said to be ; otherwise, it is . Furthermore, if we set \\(\\eta = \\eta(\\boldsymbol{\\theta})\\), the exponential family is said to be in the . \\[\\begin{align} p(\\boldsymbol{y}\\mid \\boldsymbol{\\eta})&amp;=h(\\boldsymbol{y})D(\\boldsymbol{\\eta})^N\\exp\\left\\{\\eta^{\\top}\\boldsymbol{T}(\\boldsymbol{y})\\right\\}\\nonumber\\\\ &amp;=h(\\boldsymbol{y})\\exp\\left\\{\\eta^{\\top}\\boldsymbol{T}(\\boldsymbol{y})-B(\\boldsymbol{\\eta})\\right\\}.\\nonumber \\end{align}\\] A nice feature of this representation is that \\(\\mathbb{E}[\\boldsymbol{T}(\\boldsymbol{y})\\mid \\boldsymbol{\\eta}]=\\nabla B(\\boldsymbol{\\eta})\\) and \\(Var[\\boldsymbol{T}(\\boldsymbol{y})\\mid \\boldsymbol{\\eta}]=\\nabla^2 B(\\boldsymbol{\\eta})\\). 3.1.1 Examples of exponential family distributions Discrete distributions Let’s show that some of the most common distributions for random variables, which can take values on a finite or countably infinite set, are part of the exponential family. Poisson distribution Given a random sample \\(\\boldsymbol{Y}=[Y_1 \\ Y_2 \\ \\dots \\ Y_N]^{\\top}\\) from a Poisson distribution let’s show that \\(p(\\boldsymbol{y}\\mid \\lambda)\\) is in the exponential family. \\[\\begin{align} p(\\boldsymbol{y}\\mid \\lambda)&amp;=\\prod_{i=1}^N \\frac{\\lambda^{y_i} \\exp(-\\lambda)}{y_i!}\\nonumber\\\\ &amp;=\\frac{\\lambda^{\\sum_{i=1}^N y_i}\\exp(-N\\lambda)}{\\prod_{i=1}^N y_i!}\\nonumber\\\\ &amp;=\\frac{\\exp(-N\\lambda)\\exp(\\sum_{i=1}^Ny_i\\log(\\lambda))}{\\prod_{i=1}^N y_i!}\\nonumber, \\end{align}\\] then \\(h(\\boldsymbol{y})=\\left[\\prod_{i=1}^N y_i!\\right]^{-1}\\), \\(\\eta(\\lambda)=\\log(\\lambda)\\), \\(T(\\boldsymbol{y})=\\sum_{i=1}^N y_i\\) (sufficient statistic) and \\(C(\\lambda)=\\exp(-\\lambda)\\). If we set \\(\\eta=\\log(\\lambda)\\), then \\[\\begin{align} p(\\boldsymbol{y}\\mid \\eta)&amp;=\\frac{\\exp(\\eta\\sum_{i=1}^Ny_i-N\\exp(\\eta))}{\\prod_{i=1}^N y_i!},\\nonumber \\end{align}\\] such that \\(B(\\eta)=N\\exp(\\eta)\\), then \\(\\nabla(B(\\eta))=N\\exp(\\eta)=N\\lambda=\\mathbb{E}\\left[\\sum_{i=1}^N y_i\\biggr\\rvert\\lambda\\right]\\), that is, \\(\\mathbb{E}\\left[\\frac{\\sum_{i=1}^N y_i}{N}\\biggr\\rvert\\lambda\\right]=\\mathbb{E}[\\bar{y}\\mid \\lambda]=\\lambda\\), and \\(\\nabla^2(B(\\eta))=N\\exp(\\eta)=N\\lambda=Var\\left[\\sum_{i=1}^N y_i\\biggr\\rvert\\lambda\\right]=N^2 \\times Var\\left[\\bar{y}\\rvert\\lambda\\right]\\), then \\(Var\\left[\\bar{y}\\rvert\\lambda\\right]=\\frac{\\lambda}{N}\\). Bernoulli distribution Given a random sample \\(\\boldsymbol{Y}=[Y_1 \\ Y_2 \\ \\dots \\ Y_N]^{\\top}\\) from a Bernoulli distribution let’s show that \\(p(\\boldsymbol{y}\\mid \\theta)\\) is in the exponential family. \\[\\begin{align} p(\\boldsymbol{y}\\mid \\theta)&amp;=\\prod_{i=1}^N \\theta^{y_i}(1-\\theta)^{1-y_i}\\nonumber\\\\ &amp;=\\theta^{\\sum_{i=1}^N y_i}(1-\\theta)^{N-\\sum_{i=1}^N y_i}\\nonumber\\\\ &amp;=(1-\\theta)^N\\exp\\left\\{\\sum_{i=1}^N y_i\\log\\left(\\frac{\\theta}{1-\\theta}\\right)\\right\\}\\nonumber, \\end{align}\\] then \\(h(\\boldsymbol{y})=\\mathbb{1}[y_i\\in\\left\\{0,1\\right\\}]\\) (indicator function), \\(\\eta(\\theta)=\\log\\left(\\frac{\\theta}{1-\\theta}\\right)\\), \\(T(\\boldsymbol{y})=\\sum_{i=1}^N y_i\\) and \\(C(\\theta)=1-\\theta\\). Write this distribution in the canonical form, and find the mean and variance of the sufficient statistic (Exercise 1). Multinomial distribution Given a random sample \\(\\boldsymbol{Y}=[\\boldsymbol{Y}_1 \\ \\boldsymbol{Y}_2 \\ \\dots \\ \\boldsymbol{Y}_N]\\) from a m-dimensional multinomial distribution, where \\(\\boldsymbol{Y}_i=\\left[Y_{i1} \\ Y_{i2} \\ \\dots \\ Y_{im}\\right]\\), \\(\\sum_{l=1}^m Y_{il}=n\\), \\(n\\) independent trials each of which leads to a success for exactly one of \\(m\\) categories with probabilities \\(\\boldsymbol{\\theta}=[\\theta_1 \\ \\theta_2 \\ \\dots \\ \\theta_m]\\), \\(\\sum_{l=1}^m \\theta_l=1\\). Let’s show that \\(p(\\boldsymbol{y}\\mid \\boldsymbol{\\theta})\\) is in the exponential family. \\[\\begin{align} p(\\boldsymbol{y}\\mid \\boldsymbol{\\theta})&amp;=\\prod_{i=1}^N \\frac{n!}{\\prod_{l=1}^m y_{il}!} \\prod_{l=1}^m\\theta_l^{y_{il}}\\nonumber\\\\ &amp;=\\frac{(n!)^N}{\\prod_{i=1}^N\\prod_{l=1}^m y_{il}!}\\exp\\left\\{\\sum_{i=1}^N\\sum_{l=1}^m y_{il}\\log(\\theta_l)\\right\\}\\nonumber\\\\ &amp;=\\frac{(n!)^N}{\\prod_{i=1}^N\\prod_{l=1}^m y_{il}!}\\exp\\left\\{\\left(N\\times n-\\sum_{i=1}^N\\sum_{l=1}^{m-1}y_{il}\\right)\\log(\\theta_m)\\nonumber\\right. \\\\ &amp;\\left.+\\sum_{i=1}^N\\sum_{l=1}^{m-1}y_{il}\\log(\\theta_l)\\right\\}\\nonumber\\\\ &amp;=\\frac{(n!)^N}{\\prod_{i=1}^N\\prod_{l=1}^m y_{il}!}\\theta_m^{N\\times n}\\exp\\left\\{\\sum_{i=1}^N\\sum_{l=1}^{m-1}y_{il}\\log(\\theta_l/\\theta_m)\\right\\}\\nonumber, \\end{align}\\] then \\(h(\\boldsymbol{y})=\\frac{(n!)^N}{\\prod_{i=1}^N\\prod_{l=1}^m y_{il}!}\\), \\(\\eta(\\boldsymbol{\\theta})=\\left[\\log\\left(\\frac{\\theta_1}{\\theta_m}\\right)\\dots \\log\\left(\\frac{\\theta_{m-1}}{\\theta_m}\\right)\\right]\\), \\(T(\\boldsymbol{y})=\\left[\\sum_{i=1}^N y_{i1}\\dots \\sum_{i=1}^N y_{im-1}\\right]\\) and \\(C(\\boldsymbol{\\theta})=\\theta_m^n\\). Continuous distributions Let’s show that some of the most common distributions for random variables, which can take any value within a certain range or interval –often an infinite number of possible values– are part of the exponential family. Normal distribution Given a random sample \\(\\boldsymbol{Y}=[Y_1 \\ Y_2 \\ \\dots \\ Y_N]^{\\top}\\) from a normal distribution let’s show that \\(p(\\boldsymbol{y}\\mid \\mu,\\sigma^2)\\) is in the exponential family. \\[\\begin{align} p(\\boldsymbol{y}\\mid \\mu,\\sigma^2)&amp;=\\prod_{i=1}^N \\frac{1}{2\\pi\\sigma^2}\\exp\\left\\{-\\frac{1}{2\\sigma^2}\\left(y_i-\\mu\\right)^2\\right\\}\\nonumber\\\\ &amp;= (2\\pi)^{-N/2}(\\sigma^2)^{-N/2}\\exp\\left\\{-\\frac{1}{2\\sigma^2}\\sum_{i=1}^N\\left(y_i-\\mu\\right)^2\\right\\}\\nonumber\\\\ &amp;= (2\\pi)^{-N/2}\\exp\\left\\{-\\frac{1}{2\\sigma^2}\\sum_{i=1}^Ny_i^2+\\frac{\\mu}{\\sigma^2}\\sum_{i=1}^N y_i\\right.\\nonumber\\\\ &amp;-\\left.N\\frac{\\mu^2}{2\\sigma^2}-\\frac{N}{2}\\log(\\sigma^2)\\right\\}\\nonumber, \\end{align}\\] then \\(h(\\boldsymbol{y})=(2\\pi)^{-N/2}\\), \\(\\eta(\\mu,\\sigma^2)=\\left[\\frac{\\mu}{\\sigma^2} \\ \\frac{-1}{2\\sigma^2}\\right]\\), \\(T(\\boldsymbol{y})=\\left[\\sum_{i=1}^N y_i \\ \\sum_{i=1}^N y_i^2\\right]\\) and \\(C(\\mu,\\sigma^2)=\\exp\\left\\{-\\frac{\\mu^2}{2\\sigma^2}-\\frac{\\log(\\sigma^2)}{2}\\right\\}\\). Observe that \\[\\begin{align} p(\\boldsymbol{y}\\mid \\mu,\\sigma^2)&amp;= (2\\pi)^{-N/2}\\exp\\left\\{\\eta_1\\sum_{i=1}^N y_i+\\eta_2\\sum_{i=1}^Ny_i^2-\\frac{N}{2}\\log(-2\\eta_2)+\\frac{N}{4}\\frac{\\eta_1^2}{\\eta_2}\\right\\}\\nonumber, \\end{align}\\] where \\(B(\\boldsymbol{\\eta})=\\frac{N}{2}\\log(-2\\eta_2)-\\frac{N}{4}\\frac{\\eta_1^2}{\\eta_2}\\). Then, \\[\\begin{align*} \\nabla B(\\boldsymbol{\\eta}) &amp; = \\begin{bmatrix} -\\frac{N}{2}\\frac{\\eta_1}{\\eta_2}\\\\ -\\frac{N}{2}\\frac{1}{\\eta_2}+\\frac{N}{4}\\frac{\\eta_1^2}{\\eta_2^2} \\end{bmatrix} = \\begin{bmatrix} N\\times\\mu\\\\ N\\times(\\mu^2+\\sigma^2) \\end{bmatrix} = \\begin{bmatrix} \\mathbb{E}\\left[\\sum_{i=1}^N y_i\\bigr\\rvert \\mu,\\sigma^2\\right]\\\\ \\mathbb{E}\\left[\\sum_{i=1}^N y_i^2\\bigr\\rvert \\mu,\\sigma^2\\right] \\end{bmatrix}. \\end{align*}\\] Multivariate normal distribution Given \\(\\boldsymbol{Y}=[\\boldsymbol{Y}_1 \\ \\boldsymbol{Y}_2 \\ \\dots \\ \\boldsymbol{Y}_p]\\) a \\(N\\times p\\) matrix such that \\(\\boldsymbol{Y}_i\\sim N_p(\\boldsymbol{\\mu},\\boldsymbol{\\Sigma})\\), \\(i=1,2,\\dots,N\\), that is, each \\(i\\)-th row of \\(\\boldsymbol{Y}\\) follows a multivariate normal distribution. Then, assuming independence between rows, let’s show that \\(p(\\boldsymbol{y}_1,\\boldsymbol{y}_2,\\dots,\\boldsymbol{y}_N\\mid \\boldsymbol{\\mu},\\boldsymbol{\\Sigma})\\) is in the exponential family. \\[\\begin{align} p(\\boldsymbol{y}_1,\\dots,\\boldsymbol{y}_N\\mid \\boldsymbol{\\mu},\\boldsymbol{\\Sigma})&amp;=\\prod_{i=1}^N (2\\pi)^{-p/2}| \\Sigma|^{-1/2}\\exp\\left\\{-\\frac{1}{2}\\left(\\boldsymbol{y}_i-\\boldsymbol{\\mu}\\right)^{\\top}\\boldsymbol{\\Sigma}^{-1}\\left(\\boldsymbol{y}_i-\\boldsymbol{\\mu}\\right)\\right\\}\\nonumber\\\\ &amp;= (2\\pi)^{-pN/2}|\\Sigma|^{-N/2}\\exp\\left\\{-\\frac{1}{2}tr\\left[\\sum_{i=1}^N\\left(\\boldsymbol{y}_i-\\boldsymbol{\\mu}\\right)^{\\top}\\boldsymbol{\\Sigma}^{-1}\\left(\\boldsymbol{y}_i-\\boldsymbol{\\mu}\\right)\\right]\\right\\}\\nonumber\\\\ &amp;= (2\\pi)^{-p N/2}|\\Sigma|^{-N/2}\\exp\\left\\{-\\frac{1}{2}tr\\left[\\left(\\boldsymbol{S}+N\\left(\\boldsymbol{\\mu}-\\hat{\\boldsymbol{\\mu}}\\right)\\left(\\boldsymbol{\\mu}-\\hat{\\boldsymbol{\\mu}}\\right)^{\\top}\\right)\\boldsymbol{\\Sigma}^{-1}\\right]\\right\\}\\nonumber\\\\ &amp;= (2\\pi)^{-p N/2}\\exp\\left\\{-\\frac{1}{2}\\left[\\left(vec\\left(\\boldsymbol{S}\\right)^{\\top}+N vec\\left(\\hat{\\boldsymbol{\\mu}}\\hat{\\boldsymbol{\\mu}}^{\\top}\\right)^{\\top}\\right)vec \\left(\\boldsymbol{\\Sigma}^{-1}\\right)\\right.\\right.\\nonumber\\\\ &amp;\\left.\\left.-2N\\hat{\\boldsymbol{\\mu}}^{\\top}vec\\left(\\boldsymbol{\\mu}^{\\top}\\boldsymbol{\\Sigma}^{-1}\\right)+N tr\\left(\\boldsymbol{\\mu}\\boldsymbol{\\mu}^{\\top}\\boldsymbol{\\Sigma}^{-1}\\right)+N\\log (|\\boldsymbol{\\Sigma}|)\\right]\\right\\}\\nonumber, \\end{align}\\] where the second line uses the trace operator (\\(\\text{tr}\\)), and its invariance under cyclic permutation is applied in the third line. Additionally, we add and subtract \\(\\hat{\\boldsymbol{\\mu}} = \\frac{1}{N}\\sum_{i=1}^N \\boldsymbol{y}_i\\) inside each parenthesis, resulting in \\(\\boldsymbol{S} = \\sum_{i=1}^N \\left(\\boldsymbol{y}_i - \\hat{\\boldsymbol{\\mu}}\\right) \\left(\\boldsymbol{y}_i - \\hat{\\boldsymbol{\\mu}}\\right)^{\\top}\\). The fourth line is obtained after collecting terms and using properties of the trace operator to introduce the vectorization operator (\\(\\text{vec}\\)), specifically, $ () = ({}){} ()$, and $ ( + ) = () + ()$. Then \\(h(\\boldsymbol{y})=(2\\pi)^{-pN/2}\\), \\(\\eta(\\boldsymbol{\\mu},\\boldsymbol{\\Sigma})^{\\top}=\\left[\\left(vec\\left(\\boldsymbol{\\Sigma}^{-1}\\right)\\right)^{\\top} \\ \\ \\left(vec\\left(\\boldsymbol{\\mu}^{\\top}\\boldsymbol{\\Sigma}^{-1}\\right)\\right)^{\\top}\\right]\\), \\(T(\\boldsymbol{y})=\\left[-\\frac{1}{2}\\left(vec\\left(\\boldsymbol{S}\\right)^{\\top}+N vec\\left(\\hat{\\boldsymbol{\\mu}}\\hat{\\boldsymbol{\\mu}}^{\\top}\\right)^{\\top}\\right) \\ \\ -N\\hat{\\boldsymbol{\\mu}}^{\\top}\\right]^{\\top}\\) and \\(C(\\boldsymbol{\\mu},\\boldsymbol{\\Sigma})=\\exp\\left\\{-\\frac{1}{2}\\left(tr\\left(\\boldsymbol{\\mu}\\boldsymbol{\\mu}^{\\top}\\boldsymbol{\\Sigma}^{-1}\\right)+\\log(|\\Sigma|)\\right)\\right\\}\\). References "],["sec42.html", "3.2 Conjugate prior to exponential family", " 3.2 Conjugate prior to exponential family Theorem 4.2.1 The prior distribution \\(\\pi(\\boldsymbol{\\theta})\\propto C(\\boldsymbol{\\theta})^{b_0}\\exp\\left\\{\\eta(\\boldsymbol{\\theta})^{\\top}\\boldsymbol{a}_0\\right\\}\\) is conjugate to the exponential family (equation (3.4)). Proof \\[\\begin{align} \\pi(\\boldsymbol{\\theta}\\mid \\boldsymbol{y})&amp; \\propto C(\\boldsymbol{\\theta})^{b_0}\\exp\\left\\{\\eta(\\boldsymbol{\\theta})^{\\top}\\boldsymbol{a}_0\\right\\} \\times h(\\boldsymbol{y}) C(\\boldsymbol{\\theta})^N\\exp\\left\\{\\eta(\\boldsymbol{\\theta})^{\\top}\\boldsymbol{T}(\\boldsymbol{y})\\right\\}\\nonumber\\\\ &amp; \\propto C(\\boldsymbol{\\theta})^{N+b_0} \\exp\\left\\{\\eta(\\boldsymbol{\\theta})^{\\top}(\\boldsymbol{T}(\\boldsymbol{y})+\\boldsymbol{a}_0)\\right\\}.\\nonumber \\end{align}\\] Observe that the posterior is in the exponential family, \\(\\pi(\\boldsymbol{\\theta}\\mid \\boldsymbol{y})\\propto C(\\boldsymbol{\\theta})^{\\beta_n} \\exp\\left\\{\\eta(\\boldsymbol{\\theta})^{\\top}\\boldsymbol{\\alpha}_n\\right\\}\\), \\(\\beta_n=N+b_0\\) and \\(\\boldsymbol{\\alpha}_n=\\boldsymbol{T}(\\boldsymbol{y})+\\boldsymbol{a}_0\\). Remarks We observe, by comparing the prior and the likelihood, that \\(b_0\\) plays the role of a hypothetical sample size, and \\(\\boldsymbol{a}_0\\) plays the role of hypothetical sufficient statistics. This perspective aids the elicitation process, that is, integrating non-sample information into the prior distribution. We established this result in the standard form of the exponential family. We can also establish it in the canonical form of the exponential family. Observe that, given \\(\\boldsymbol{\\eta} = \\boldsymbol{\\eta}(\\boldsymbol{\\theta})\\), another way to derive a prior for \\(\\boldsymbol{\\eta}\\) is to use the change of variable theorem, given a bijective function. In the case where there is a regular conjugate prior, Diaconis, Ylvisaker, et al. (1979) show that the posterior expectation of the sufficient statistics is a weighted average between the prior expectation and the likelihood estimate. 3.2.1 Examples: Theorem 4.2.1 Likelihood functions from discrete distributions The Poisson-gamma model Given a random sample \\(\\boldsymbol{Y}=[Y_1 \\ Y_2 \\ \\dots \\ Y_N]^{\\top}\\) from a Poisson distribution then a conjugate prior density for \\(\\lambda\\) has the form \\[\\begin{align} \\pi(\\lambda)&amp;\\propto \\left(\\exp(-\\lambda)\\right)^{b_0} \\exp\\left\\{a_0\\log(\\lambda)\\right\\}\\nonumber\\\\ &amp; = \\exp(-\\lambda b_0) \\lambda^{a_0}\\nonumber\\\\ &amp; = \\exp(-\\lambda \\beta_0) \\lambda^{\\alpha_0-1}.\\nonumber \\end{align}\\] This is the kernel of a gamma density in the rate parametrization, \\(G(\\alpha_0, \\beta_0)\\), where \\(\\alpha_0 = a_0 + 1\\) and \\(\\beta_0 = b_0\\).18 Thus, a prior conjugate distribution for the Poisson likelihood is a gamma distribution. Since \\(\\sum_{i=1}^N Y_i\\) is a sufficient statistic for the Poisson distribution, we can interpret \\(a_0\\) as the number of occurrences in \\(b_0\\) experiments. Observe that \\[\\begin{align} \\pi(\\lambda\\mid \\boldsymbol{y})&amp;\\propto \\exp(-\\lambda \\beta_0) \\lambda^{\\alpha_0-1} \\times \\exp(-N\\lambda)\\lambda^{\\sum_{i=1}^Ny_i}\\nonumber\\\\ &amp;= \\exp(-\\lambda(N+\\beta_0)) \\lambda^{\\sum_{i=1}^Ny_i+\\alpha_0-1}.\\nonumber \\end{align}\\] As expected, this is the kernel of a gamma distribution, which means \\(\\lambda\\mid \\boldsymbol{y}\\sim G(\\alpha_n,\\beta_n)\\), \\(\\alpha_n=\\sum_{i=1}^Ny_i+\\alpha_0\\) and \\(\\beta_n=N+\\beta_0\\). Observe that \\(\\alpha_0/\\beta_0\\) is the prior mean, and \\(\\alpha_0/\\beta_0^2\\) is the prior variance. Then, \\(\\alpha_0\\rightarrow 0\\) and \\(\\beta_0\\rightarrow 0\\) imply a non-informative prior such that the posterior mean converges to the maximum likelihood estimate \\(\\bar{y}=\\frac{\\sum_{i=1}^N y_i}{N}\\), \\[\\begin{align} \\mathbb{E}\\left[\\lambda\\mid \\boldsymbol{y}\\right]&amp;=\\frac{\\alpha_n}{\\beta_n}\\nonumber\\\\ &amp;=\\frac{\\sum_{i=1}^Ny_i+\\alpha_0}{N+\\beta_0}\\nonumber\\\\ &amp;=\\frac{N\\bar{y}}{N+\\beta_0}+\\frac{\\alpha_0}{N+\\beta_0}.\\nonumber \\end{align}\\] The posterior mean is a weighted average of the sample and prior information. This is a general result for regular conjugate priors (Diaconis, Ylvisaker, et al. 1979). Note that \\(\\mathbb{E}[\\lambda \\mid \\boldsymbol{y}] = \\bar{y}, \\quad \\lim_{N \\to \\infty}\\). Additionally, \\(\\alpha_0 \\to 0\\) and \\(\\beta_0 \\to 0\\) corresponds to \\(\\pi(\\lambda) \\propto \\frac{1}{\\lambda}\\), which is an improper prior. Improper priors may have undesirable consequences for Bayes factors (hypothesis testing); see below for a discussion of this in the linear regression framework. In this example, we can obtain analytical solutions for the marginal likelihood and the predictive distribution (see the health insurance example and Exercise 3 in Chapter 1). The Bernoulli-beta model Given a random sample \\(\\boldsymbol{Y}=[Y_1 \\ Y_2 \\ \\dots \\ Y_N]^{\\top}\\) from a Bernoulli distribution then a conjugate prior density for \\(\\theta\\) has the form \\[\\begin{align} \\pi(\\theta)&amp;\\propto (1-\\theta)^{b_0} \\exp\\left\\{a_0\\log\\left(\\frac{\\theta}{1-\\theta}\\right)\\right\\}\\nonumber\\\\ &amp; = (1-\\theta)^{b_0-a_0}\\theta^{a_0}\\nonumber\\\\ &amp; = \\theta^{\\alpha_0-1}(1-\\theta)^{\\beta_0-1}.\\nonumber \\end{align}\\] This is the kernel of a beta density, \\(B(\\alpha_0, \\beta_0)\\), where \\(\\alpha_0 = a_0 + 1\\) and \\(\\beta_0 = b_0 - a_0 + 1\\). A prior conjugate distribution for the Bernoulli likelihood is a beta distribution. Given that \\(b_0\\) is the hypothetical sample size and \\(a_0\\) is the hypothetical sufficient statistic (the number of successes), \\(b_0 - a_0\\) represents the number of failures. This implies that \\(\\alpha_0\\) is the number of prior successes plus one, and \\(\\beta_0\\) is the number of prior failures plus one. Since the mode of a beta-distributed random variable is given by \\(\\frac{\\alpha_0 - 1}{\\alpha_0 + \\beta_0 - 2} = \\frac{a_0}{b_0}\\), we can interpret this as the prior probability of success. Setting \\(\\alpha_0 = 1\\) and \\(\\beta_0 = 1\\), which corresponds to a uniform distribution on the interval [0, 1], represents a setting with 0 successes (and 0 failures) in 0 experiments. Observe that \\[\\begin{align} \\pi(\\theta\\mid \\boldsymbol{y})&amp;\\propto \\theta^{\\alpha_0-1}(1-\\theta)^{\\beta_0-1} \\times \\theta^{\\sum_{i=1}^N y_i}(1-\\theta)^{N-\\sum_{i=1}^Ny_i}\\nonumber\\\\ &amp;= \\theta^{\\alpha_0+\\sum_{i=1}^N y_i-1}(1-\\theta)^{\\beta_0+N-\\sum_{i=1}^Ny_i-1}.\\nonumber \\end{align}\\] The posterior distribution is beta, \\(\\theta\\mid \\boldsymbol{y}\\sim B(\\alpha_n,\\beta_n)\\), \\(\\alpha_n=\\alpha_0+\\sum_{i=1}^N y_i\\) and \\(\\beta_n=\\beta_0+N-\\sum_{i=1}^Ny_i\\), where the posterior mean \\(\\mathbb{E}[\\theta\\mid \\boldsymbol{y}]=\\frac{\\alpha_n}{\\alpha_n+\\beta_n}=\\frac{\\alpha_0+N\\bar{y}}{\\alpha_0+\\beta_0+N}=\\frac{\\alpha_0+\\beta_0}{\\alpha_0+\\beta_0+N}\\frac{\\alpha_0}{\\alpha_0+\\beta_0}+\\frac{N}{\\alpha_0+\\beta_0+N}\\bar{y}\\). The posterior mean is a weighted average between the prior mean and the maximum likelihood estimate. El marginal likelihood in this setting is \\[\\begin{align} p(\\boldsymbol{y})=&amp;\\int_{0}^1 \\frac{\\theta^{\\alpha_0-1}(1-\\theta)^{\\beta_0-1}}{B(\\alpha_0,\\beta_0)}\\times \\theta^{\\sum_{i=1}^N y_i}(1-\\theta)^{N-\\sum_{i=1}^N y_i}d\\theta\\nonumber\\\\ =&amp; \\frac{B(\\alpha_n,\\beta_n)}{B(\\alpha_0,\\beta_0)},\\nonumber \\end{align}\\] where \\(B(\\cdot ,\\cdot)\\) is the beta function. In addition, the predictive density is \\[\\begin{align} p(y_0\\mid \\boldsymbol{y})&amp;=\\int_0^1 \\theta^{y_0}(1-\\theta)^{1-y_0}\\times \\frac{\\theta^{\\alpha_n-1}(1-\\theta)^{\\beta_n-1}}{B(\\alpha_n,\\beta_n)}d\\theta\\nonumber\\\\ &amp;=\\frac{B(\\alpha_n+y_0,\\beta_n+1-y_0)}{B(\\alpha_n,\\beta_n)}\\nonumber\\\\ &amp;=\\frac{\\Gamma(\\alpha_n+\\beta_n)\\Gamma(\\alpha_n+y_0)\\Gamma(\\beta_n+1-y_0)}{\\Gamma(\\alpha_n+\\beta_n+1)\\Gamma(\\alpha_n)\\Gamma(\\beta_n)}\\nonumber\\\\ &amp;=\\begin{Bmatrix} \\frac{\\alpha_n}{\\alpha_n+\\beta_n}, &amp; y_0=1\\\\ \\frac{\\beta_n}{\\alpha_n+\\beta_n}, &amp; y_0=0\\\\ \\end{Bmatrix}.\\nonumber \\end{align}\\] This is a Bernoulli distribution with probability of success equal to \\(\\frac{\\alpha_n}{\\alpha_n+\\beta_n}\\). The multinomial-Dirichlet model Given a random sample \\(\\boldsymbol{Y}=[Y_1 \\ Y_2 \\ \\dots \\ Y_N]^{\\top}\\) from a multinomial distribution then a conjugate prior density for \\(\\boldsymbol{\\theta}=\\left[\\theta_1 \\ \\theta_2 \\ \\dots \\ \\theta_m\\right]\\) has the form \\[\\begin{align} \\pi(\\boldsymbol{\\theta})&amp;\\propto \\theta_m^{b_0} \\exp\\left\\{\\boldsymbol{\\eta}(\\boldsymbol{\\theta})^{\\top}\\boldsymbol{a}_0\\right\\}\\nonumber\\\\ &amp; = \\prod_{l=1}^{m-1}\\theta_l^{a_{0l}}\\theta_m^{b_0-\\sum_{l=1}^{m-1}a_{0l}}\\nonumber\\\\ &amp; = \\prod_{l=1}^{m}\\theta_l^{\\alpha_{0l}-1},\\nonumber \\end{align}\\] where \\(\\boldsymbol{\\eta}(\\boldsymbol{\\theta})=\\left[\\log\\left(\\frac{\\theta_1}{\\theta_m}\\right) \\ \\dots \\ \\log\\left(\\frac{\\theta_{m-1}}{\\theta_m}\\right)\\right]\\), \\(\\boldsymbol{a}_0=\\left[a_{01} \\ \\dots \\ a_{0m-1}\\right]^{\\top}\\), \\(\\boldsymbol{\\alpha}_0=\\left[\\alpha_{01} \\ \\alpha_{02} \\ \\dots \\ \\alpha_{0m}\\right]\\), \\(\\alpha_{0l}=a_{0l}+1\\), \\(l=1,2,\\dots,m-1\\) and \\(\\alpha_{0m}=b_0-\\sum_{l=1}^{m-1} a_{0l}+1\\). This is the kernel of a Dirichlet distribution, that is, the prior distribution is \\(D(\\boldsymbol{\\alpha}_0)\\). Observe that \\(a_{0l}\\) is the hypothetical number of times outcome \\(l\\) is observed over the hypothetical \\(b_0\\) trials. Setting \\(\\alpha_{0l} = 1\\), which corresponds to a uniform distribution over the open standard simplex, implicitly sets \\(a_{0l} = 0\\), meaning that there are 0 occurrences of category \\(l\\) in \\(b_0 = 0\\) experiments. The posterior distribution of the multinomial-Dirichlet model is given by \\[\\begin{align} \\pi(\\boldsymbol{\\theta}\\mid \\boldsymbol{y})&amp;\\propto \\prod_{l=1}^m \\theta_l^{\\alpha_{0l}-1}\\times\\prod_{l=1}^m \\theta_l^{\\sum_{i=1}^{N} y_{il}}\\nonumber\\\\ &amp;=\\prod_{l=1}^m \\theta_l^{\\alpha_{0l}+\\sum_{i=1}^{N} y_{il}-1}\\nonumber. \\end{align}\\] This is the kernel of a Dirichlet distribution \\(D(\\boldsymbol{\\alpha}_n)\\), \\(\\boldsymbol{\\alpha}_n=\\left[\\alpha_{n1} \\ \\alpha_{n2} \\ \\dots \\ \\alpha_{nm}\\right]\\), \\(\\alpha_{nl}=\\alpha_{0l}+\\sum_{i=1}^{N}y_{il}\\), \\(l=1,2,\\dots,m\\). Observe that \\[\\begin{align} \\mathbb{E}[\\theta_{j}\\mid \\boldsymbol{y}]&amp;=\\frac{\\alpha_{nj}}{\\sum_{l=1}^m \\left[\\alpha_{0l}+\\sum_{i=1}^N y_{il}\\right]}\\nonumber\\\\ &amp;=\\frac{\\sum_{l=1}^m \\alpha_{0l}}{\\sum_{l=1}^m \\left[\\alpha_{0l}+\\sum_{i=1}^N y_{il}\\right]}\\frac{\\alpha_{0j}}{\\sum_{l=1}^m \\alpha_{0l}}\\nonumber\\\\ &amp;+\\frac{\\sum_{l=1}^m\\sum_{i=1}^N y_{il}}{\\sum_{l=1}^m \\left[\\alpha_{0l}+\\sum_{i=1}^N y_{il}\\right]}\\frac{\\sum_{i=1}^N y_{ij}}{\\sum_{l=1}^m\\sum_{i=1}^N y_{il}}.\\nonumber \\end{align}\\] We have again that the posterior mean is a weighted average between the prior mean and the maximum likelihood estimate. The marginal likelihood is \\[\\begin{align} p(\\boldsymbol{y})&amp;=\\int_{\\boldsymbol{\\Theta}}\\frac{\\prod_{l=1}^m \\theta_l^{\\alpha_{0l}-1}}{B(\\boldsymbol{\\alpha}_0)}\\times \\prod_{i=1}^N\\frac{n!}{\\prod_{l=1}^m y_{il}}\\prod_{l=1}^m \\theta_{l}^{y_{il}}d\\boldsymbol{\\theta}\\nonumber\\\\ &amp;=\\frac{N\\times n!}{B(\\boldsymbol{\\alpha}_0)\\prod_{i=1}^N\\prod_{l=1}^m y_{il}!}\\int_{\\boldsymbol{\\Theta}} \\prod_{l=1}^m \\theta_l^{\\alpha_{0l}+\\sum_{i=1}^N y_{il}-1} d\\boldsymbol{\\theta}\\nonumber\\\\ &amp;=\\frac{N\\times n!}{B(\\boldsymbol{\\alpha}_0)\\prod_{i=1}^N\\prod_{l=1}^m y_{il}!}B(\\boldsymbol{\\alpha}_n)\\nonumber\\\\ &amp;=\\frac{N\\times n! \\Gamma\\left(\\sum_{l=1}^m\\nonumber \\alpha_{0l}\\right)}{\\Gamma\\left(\\sum_{l=1}^m \\alpha_{0l}+N\\times n\\right)}\\prod_{l=1}^m \\frac{\\Gamma\\left( \\alpha_{nl}\\right)}{\\Gamma\\left(\\alpha_{0l}\\right)\\prod_{i=1}^N y_{il}!},\\nonumber \\end{align}\\] where \\(B(\\boldsymbol{\\alpha})=\\frac{\\prod_{l=1}^m\\Gamma(\\alpha_l)}{\\Gamma\\left(\\sum_{l=1}^m \\alpha_l\\right)}\\). Following similar steps we get the predictive density \\[\\begin{align} p(y_0\\mid \\boldsymbol{y})&amp;=\\frac{ n! \\Gamma\\left(\\sum_{l=1}^m \\alpha_{nl}\\right)}{\\Gamma\\left(\\sum_{l=1}^m \\alpha_{nl}+ n\\right)}\\prod_{l=1}^m \\frac{\\Gamma\\left( \\alpha_{nl}+y_{0l}\\right)}{\\Gamma\\left(\\alpha_{nl}\\right) y_{0l}!}.\\nonumber \\end{align}\\] This is a Dirichlet-multinomial distribution with parameters \\(\\boldsymbol{\\alpha}_n\\). Example: English premier league, Liverpool vs Manchester city Let’s consider an example using data from the English Premier League. In particular, we want to calculate the probability that, in the next five matches between Liverpool and Manchester City, Liverpool wins two games and Manchester City wins three. This calculation is based on historical data from the last five matches where Liverpool played at home between January 14th, 2018, and April 10th, 2022. In those matches, Liverpool secured two wins, there were two draws, and Manchester City won one match. 19 We use two strategies to estimate the hyperparameters. First, we estimate the hyperparameters of the Dirichlet distribution using betting odds from bookmakers at 19:05 on October 6th, 2022 (Colombia time). We obtained data from 24 bookmakers (see file DataOddsLIVvsMAN.csv)20, and we transform these odds into probabilities using a simple standardization approach. Then, we apply maximum likelihood estimation to estimate the hyperparameters. Second, we use empirical Bayes, where we estimate the hyperparameters by optimizing the marginal likelihood. # Multinomial-Dirichlet example: Liverpool vs Manchester city Data &lt;- read.csv(&quot;https://raw.githubusercontent.com/besmarter/BSTApp/refs/heads/master/DataApp/DataOddsLIVvsMAN.csv&quot;, sep = &quot;,&quot;, header = TRUE, quote = &quot;&quot;) attach(Data) library(dplyr) ## ## Attaching package: &#39;dplyr&#39; ## The following objects are masked from &#39;package:stats&#39;: ## ## filter, lag ## The following objects are masked from &#39;package:base&#39;: ## ## intersect, setdiff, setequal, union Probs &lt;- Data %&gt;% mutate(pns1 = 1/home, pns2 = 1/draw, pns3 = 1/away)%&gt;% mutate(SumInvOdds = pns1 + pns2 + pns3) %&gt;% mutate(p1 = pns1/SumInvOdds, p2 = pns2/SumInvOdds, p3 = pns3/SumInvOdds) %&gt;% select(p1, p2, p3) # We get probabilities using simple standardization. There are more technical approaches to do this. See for instance Shin (1993) and Strumbelj (2014). DirMLE &lt;- sirt::dirichlet.mle(Probs) # Use maximum likelihood to estimate parameters of the # Dirichlet distribution alpha0odds &lt;- DirMLE$alpha alpha0odds ## p1 p2 p3 ## 1599.122 1342.703 2483.129 y &lt;- c(2, 2, 1) # Historical records last five mathces # Liverpool wins (2), draws (2) and Manchester # city wins (1) # Marginal likelihood MarLik &lt;- function(a0){ n &lt;- sum(y) Res1 &lt;- sum(sapply(1:length(y), function(l){lgamma(a0[l]+y[l])-lgamma(a0[l])})) Res &lt;- lgamma(sum(a0))-lgamma(sum(a0)+n)+Res1 return(-Res) } EmpBay &lt;- optim(alpha0odds, MarLik, method = &quot;BFGS&quot;) alpha0EB &lt;- EmpBay$par alpha0EB ## p1 p2 p3 ## 2362.622 2660.153 1279.510 # Bayes factor empirical Bayes vs betting odds. # This is greather than 1 by construction BF &lt;- exp(-MarLik(alpha0EB))/exp(-MarLik(alpha0odds)) BF ## [1] 2.085819 # Posterior distribution based on empirical Bayes alphan &lt;- alpha0EB + y # Posterior parameters S &lt;- 100000 # Simulation draws from the Dirichlet distribution thetas &lt;- MCMCpack::rdirichlet(S, alphan) colnames(thetas) &lt;- c(&quot;Liverpool&quot;,&quot;Draw&quot;,&quot;Manchester&quot;) # Predictive distribution based on simulations y0 &lt;- c(2, 0, 3) # Liverpool two wins and Manchester city three wins in next five matches Pred &lt;- apply(thetas, 1, function(p) {rmultinom(1, size = sum(y0), prob = p)}) ProY0 &lt;- sum(sapply(1:S,function(s){sum(Pred[,s]==y0)==3}))/S ProY0 # Probability of y0 ## [1] 0.01224 # Predictive distribution using analytical expression PredY0 &lt;- function(y0){ n &lt;- sum(y0) Res1 &lt;- sum(sapply(1:length(y), function(l){lgamma(alphan[l]+y0[l]) - lgamma(alphan[l])-lfactorial(y0[l])})) Res &lt;- lfactorial(n) + lgamma(sum(alphan)) - lgamma(sum(alphan)+n) + Res1 return(exp(Res)) } PredY0(y0) ## [1] 0.01177531 We observe that the Bayes factor provides evidence in favor of the hyperparameters estimated via empirical Bayes, as these hyperparameters are specifically chosen to maximize the marginal likelihood. Using the hyperparameters obtained from empirical Bayes, we calculate that the probability of Liverpool winning two out of the next five games, while Manchester City wins three, is 1.2%. The result obtained from the predictive distribution via simulations is similar to the probability derived using the exact predictive distribution. Likelihood functions from continuous distributions The normal-normal/inverse-gamma model Given a random sample \\(\\boldsymbol{Y}=[Y_1 \\ Y_2 \\ \\dots \\ Y_N]^{\\top}\\) from a normal distribution, then the conjugate prior density has the form \\[\\begin{align} \\pi(\\mu,\\sigma^2)&amp;\\propto \\exp\\left\\{b_0\\left(-\\frac{\\mu^2}{2\\sigma^2}-\\frac{\\log \\sigma^2}{2}\\right)\\right\\}\\exp\\left\\{a_{01}\\frac{\\mu}{\\sigma^2}-a_{02}\\frac{1}{\\sigma^2}\\right\\}\\nonumber\\\\ &amp;=\\exp\\left\\{b_0\\left(-\\frac{\\mu^2}{2\\sigma^2}-\\frac{\\log \\sigma^2}{2}\\right)\\right\\}\\exp\\left\\{a_{01}\\frac{\\mu}{\\sigma^2}-a_{02}\\frac{1}{\\sigma^2}\\right\\}\\nonumber\\\\ &amp;\\times \\exp\\left\\{-\\frac{a_{01}^2}{2\\sigma^2b_0}\\right\\}\\exp\\left\\{\\frac{a_{01}^2}{2\\sigma^2b_0}\\right\\}\\nonumber\\\\ &amp;=\\exp\\left\\{-\\frac{b_0}{2\\sigma^2}\\left(\\mu-\\frac{a_{01}}{b_0}\\right)^2\\right\\}\\left(\\frac{1}{\\sigma^2}\\right)^{\\frac{b_0+1-1}{2}}\\nonumber\\\\ &amp;\\times \\exp\\left\\{\\frac{1}{\\sigma^2}\\frac{-2b_0a_{02}+a_{01}^2}{2b_0}\\right\\}\\nonumber\\\\ &amp;=\\underbrace{\\left(\\frac{1}{\\sigma^2}\\right)^{\\frac{1}{2}}\\exp\\left\\{-\\frac{b_0}{2\\sigma^2}\\left(\\mu-\\frac{a_{01}}{b_0}\\right)^2\\right\\}}_{1}\\nonumber\\\\ &amp;\\times\\underbrace{\\left(\\frac{1}{\\sigma^2}\\right)^{\\frac{b_0-1}{2}}\\exp\\left\\{-\\frac{1}{\\sigma^2}\\frac{2b_0a_{02}-a_{01}^2}{2b_0}\\right\\}}_{2}.\\nonumber \\end{align}\\] The first part is the kernel of a normal density with mean \\(\\mu_0 = \\frac{a_{01}}{\\beta_0}\\) and variance \\(\\frac{\\sigma^2}{\\beta_0}\\), where \\(\\beta_0 = b_0\\). That is, \\(\\mu \\mid \\sigma^2 \\sim N\\left(\\mu_0, \\frac{\\sigma^2}{\\beta_0}\\right)\\). The second part is the kernel of an inverse gamma density with shape parameter \\(\\frac{\\alpha_0}{2} = \\frac{\\beta_0 - 3}{2}\\) and scale parameter \\(\\frac{\\delta_0}{2} = \\frac{2\\beta_0 a_{02} - a_{01}^2}{2\\beta_0}\\), so \\(\\sigma^2 \\sim IG\\left(\\frac{\\alpha_0}{2}, \\frac{\\delta_0}{2}\\right)\\). Observe that \\(b_0 = \\beta_0\\) represents the hypothetical sample size, and \\(a_{01}\\) is the hypothetical sum of prior observations. Therefore, it makes sense that \\(\\frac{a_{01}}{\\beta_0}\\) and \\(\\frac{\\sigma^2}{\\beta_0}\\) represent the prior mean and variance, respectively. Therefore, the posterior distribution is also a normal-inverse gamma distribution, \\[\\begin{align} \\pi(\\mu,\\sigma^2\\mid \\boldsymbol{y})&amp;\\propto \\left(\\frac{1}{\\sigma^2}\\right)^{1/2}\\exp\\left\\{-\\frac{\\beta_0}{2\\sigma^2}(\\mu-\\mu_0)^2\\right\\}\\left(\\frac{1}{\\sigma^2}\\right)^{\\alpha_0/2+1}\\exp\\left\\{-\\frac{\\delta_0}{2\\sigma^2}\\right\\}\\nonumber\\\\ &amp;\\times(\\sigma^2)^{-N/2}\\exp\\left\\{-\\frac{1}{2\\sigma^2}\\sum_{i=1}^N (y_i-\\mu)^2\\right\\}\\nonumber\\\\ &amp; = \\left(\\frac{1}{\\sigma^2}\\right)^{1/2}\\exp\\left\\{-\\frac{1}{2\\sigma^2}\\left(\\beta_0(\\mu-\\mu_0)^2+\\sum_{i=1}^N (y_i-\\bar{y})^2+N(\\mu-\\bar{y})^2+\\delta_0\\right)\\right\\}\\nonumber\\\\ &amp; \\times\\left(\\frac{1}{\\sigma^2}\\right)^{\\frac{\\alpha_0+N}{2}+1} + \\frac{(\\beta_0\\mu_0+N\\bar{y})^2}{\\beta_0+N} - \\frac{(\\beta_0\\mu_0+N\\bar{y})^2}{\\beta_0+N}\\nonumber\\\\ &amp; = \\underbrace{\\left(\\frac{1}{\\sigma^2}\\right)^{1/2}\\exp\\left\\{-\\frac{1}{2\\sigma^2}\\left((\\beta_0+N)\\left(\\mu-\\left(\\frac{\\beta_0\\mu_0+N\\bar{y}}{\\beta_0+N}\\right)\\right)^2\\right)\\right\\}}_{1}\\nonumber\\\\ &amp; \\times \\underbrace{\\left(\\frac{1}{\\sigma^2}\\right)^{\\frac{\\alpha_0+N}{2}+1}\\exp\\left\\{-\\frac{1}{2\\sigma^2}\\left(\\sum_{i=1}^N (y_i-\\bar{y})^2+\\delta_0+\\frac{\\beta_0N}{\\beta_0+N}(\\bar{y}-\\mu_0)^2\\right)\\right\\}}_{2}.\\nonumber \\end{align}\\] The first term is the kernel of a normal density, \\(\\mu\\mid \\sigma^2,\\boldsymbol{y}\\sim N \\left(\\mu_n, \\sigma_n^2\\right)\\), where \\(\\mu_n=\\frac{\\beta_0\\mu_0+N\\bar{y}}{\\beta_0+N}\\) and \\(\\sigma_n^2=\\frac{\\sigma^2}{\\beta_n}\\), \\(\\beta_n=\\beta_0+N\\). The second term is the kernel of an inverse gamma density, \\(\\sigma^2\\mid \\boldsymbol{y}\\sim IG(\\alpha_n/2,\\delta_n/2)\\) where \\(\\alpha_n=\\alpha_0+N\\) and \\(\\delta_n=\\sum_{i=1}^N (y_i-\\bar{y})^2+\\delta_0+\\frac{\\beta_0N}{\\beta_0+N}(\\bar{y}-\\mu_0)^2\\). Observe that the posterior mean is a weighted average between prior and sample information. The weights depends on the sample sizes (\\(\\beta_0\\) and \\(N\\)). The marginal posterior for \\(\\sigma^2\\) is inverse gamma with shape and scale parameters \\(\\alpha_n/2\\) and \\(\\delta_n/2\\), respectively. The marginal posterior of \\(\\mu\\) is \\[\\begin{align} \\pi(\\mu\\mid \\boldsymbol{y})&amp;\\propto \\int_{0}^{\\infty}\\left\\{ \\left(\\frac{1}{\\sigma^2}\\right)^{\\frac{\\alpha_n+1}{2}+1}\\exp\\left\\{-\\frac{1}{2\\sigma^2}(\\beta_n(\\mu-\\mu_n)^2+\\delta_n)\\right\\}\\right\\}d\\sigma^2\\nonumber\\\\ &amp;=\\frac{\\Gamma\\left(\\frac{\\alpha_n+1}{2}\\right)}{\\left[\\frac{\\beta_n(\\mu-\\mu_n)^2+\\delta_n}{2}\\right]^{\\frac{\\alpha_n+1}{2}}}\\nonumber\\\\ &amp;\\propto \\left[\\frac{\\beta_n(\\mu-\\mu_n)^2+\\delta_n}{2}\\right]^{-\\frac{\\alpha_n+1}{2}}\\left(\\frac{\\delta_n}{\\delta_n}\\right)^{-\\frac{\\alpha_n+1}{2}}\\nonumber\\\\ &amp;\\propto \\left[\\frac{\\alpha_n\\beta_n(\\mu-\\mu_n)^2}{\\alpha_n\\delta_n}+1\\right]^{-\\frac{\\alpha_n+1}{2}},\\nonumber \\end{align}\\] The second line follows from having the kernel of an inverse gamma density with parameters \\(\\frac{\\alpha_n + 1}{2}\\) and \\(\\frac{1}{2} \\left( \\beta_n (\\mu - \\mu_n)^2 + \\delta_n \\right)\\). This corresponds to the kernel of a Student’s \\(t\\)-distribution: \\[ \\mu \\mid \\boldsymbol{y} \\sim t\\left(\\mu_n, \\frac{\\delta_n}{\\beta_n \\alpha_n}, \\alpha_n\\right), \\] where \\(\\mathbb{E}[\\mu \\mid \\boldsymbol{y}] = \\mu_n\\) and \\[ \\text{Var}[\\mu \\mid \\boldsymbol{y}] = \\frac{\\alpha_n}{\\alpha_n - 2} \\left( \\frac{\\delta_n}{\\beta_n \\alpha_n} \\right) = \\frac{\\delta_n}{(\\alpha_n - 2) \\beta_n}, \\quad \\alpha_n &gt; 2. \\] Observe that the marginal posterior distribution for \\(\\mu\\) has heavier tails than the conditional posterior distribution due to the incorporation of uncertainty regarding \\(\\sigma^2\\). The marginal likelihood is \\[\\begin{align} p(\\boldsymbol{y})&amp;=\\int_{-\\infty}^{\\infty}\\int_{0}^{\\infty}\\left\\{ (2\\pi\\sigma^2/\\beta_0)^{-1/2}\\exp\\left\\{-\\frac{1}{2\\sigma^2/\\beta_0}(\\mu-\\mu_0)^2\\right\\}\\frac{(\\delta_0/2)^{\\alpha_0/2}}{\\Gamma(\\alpha_0/2)}\\left(\\frac{1}{\\sigma^2}\\right)^{\\alpha_0/2+1}\\right.\\nonumber\\\\ &amp;\\times\\left.\\exp\\left\\{-\\frac{\\delta_0}{2\\sigma^2}\\right\\}(2\\pi\\sigma^2)^{-N/2}\\exp\\left\\{-\\frac{1}{2\\sigma^2}\\sum_{i=1}^N(y_i-\\mu)^2\\right\\}\\right\\}d\\sigma^2d\\mu\\nonumber\\\\ &amp;=\\frac{(\\delta_0/2)^{\\alpha_0/2}}{\\Gamma(\\alpha_0/2)}(2\\pi)^{-\\left(\\frac{N+1}{2}\\right)}\\beta_0^{1/2}\\int_{-\\infty}^{\\infty}\\int_{0}^{\\infty}\\left\\{\\left(\\frac{1}{\\sigma^2}\\right)^{\\frac{\\alpha_0+N+1}{2}+1}\\right.\\nonumber\\\\ &amp;\\times\\left.\\exp\\left\\{-\\frac{1}{2\\sigma^2}(\\beta_0(\\mu-\\mu_0)^2+\\sum_{i=1}^N (y_i-\\mu)^2+\\delta_0)\\right\\}\\right\\}d\\sigma^2d\\mu\\nonumber\\\\ &amp;=\\frac{(\\delta_0/2)^{\\alpha_0/2}}{\\Gamma(\\alpha_0/2)}(2\\pi)^{-\\left(\\frac{N+1}{2}\\right)}\\beta_0^{1/2}\\Gamma\\left(\\frac{N+1+\\alpha_0}{2}\\right)\\nonumber\\\\ &amp;\\times \\int_{-\\infty}^{\\infty} \\left[\\frac{\\beta_0(\\mu-\\mu_0)^2+\\sum_{i=1}^N(y_i-\\mu)^2+\\delta_0}{2}\\right]^{-\\frac{\\alpha_0+N+1}{2}}d\\mu\\nonumber\\\\ &amp;=\\frac{(\\delta_0/2)^{\\alpha_0/2}}{\\Gamma(\\alpha_0/2)}(2\\pi)^{-\\left(\\frac{N+1}{2}\\right)}\\beta_0^{1/2}\\Gamma\\left(\\frac{N+1+\\alpha_0}{2}\\right)\\nonumber\\\\ &amp;\\times \\int_{-\\infty}^{\\infty} \\left[\\frac{\\beta_n(\\mu-\\mu_n)^2+\\delta_n}{2}\\right]^{-\\frac{\\alpha_n+1}{2}}d\\mu\\left(\\frac{\\delta_n/2}{\\delta_n/2}\\right)^{-\\frac{\\alpha_n+1}{2}}\\nonumber\\\\ &amp;=\\frac{(\\delta_0/2)^{\\alpha_0/2}}{\\Gamma(\\alpha_0/2)}(2\\pi)^{-\\left(\\frac{N+1}{2}\\right)}\\beta_0^{1/2}\\Gamma\\left(\\frac{\\alpha_n+1}{2}\\right)\\left(\\frac{\\delta_n}{2}\\right)^{-\\frac{\\alpha_n+1}{2}}\\frac{\\left(\\frac{\\delta_n\\pi}{\\beta_n}\\right)^{1/2}\\Gamma\\left(\\frac{\\alpha_n}{2}\\right)}{\\Gamma\\left(\\frac{\\alpha_n+1}{2}\\right)}\\nonumber\\\\ &amp;=\\frac{\\Gamma\\left(\\frac{\\alpha_n}{2}\\right)}{\\Gamma\\left(\\frac{\\alpha_0}{2}\\right)}\\frac{(\\delta_0/2)^{\\alpha_0/2}}{(\\delta_n/2)^{\\alpha_n/2}}\\left(\\frac{\\beta_0}{\\beta_n}\\right)^{1/2}(\\pi)^{-N/2},\\nonumber \\end{align}\\] where we take into account that \\(\\int_{-\\infty}^{\\infty} \\left[\\frac{\\beta_n(\\mu-\\mu_n)^2+\\delta_n}{2}\\right]^{-\\frac{\\alpha_n+1}{2}}d\\mu\\left(\\frac{\\delta_n/2}{\\delta_n/2}\\right)^{-\\frac{\\alpha_n+1}{2}}=\\int_{-\\infty}^{\\infty} \\left[\\frac{\\beta_n\\alpha_n(\\mu-\\mu_n)^2}{\\delta_n\\alpha_n}+1\\right]^{-\\frac{\\alpha_n+1}{2}}d\\mu\\left(\\frac{\\delta_n}{2}\\right)^{-\\frac{\\alpha_n+1}{2}}\\). The term in the integral is the kernel of a Student’s t density, this means that the integral is equal to \\(\\frac{\\left(\\frac{\\delta_n\\pi}{\\beta_n}\\right)^{1/2}\\Gamma\\left(\\frac{\\alpha_n}{2}\\right)}{\\Gamma\\left(\\frac{\\alpha_n+1}{2}\\right)}\\). The predictive density is \\[\\begin{align} \\pi(y_0\\mid \\boldsymbol{y})&amp;\\propto\\int_{-\\infty}^{\\infty}\\int_0^{\\infty}\\left\\{ \\left(\\frac{1}{\\sigma^2}\\right)^{1/2}\\exp\\left\\{-\\frac{1}{2\\sigma^2}(y_0-\\mu)^2\\right\\}\\left(\\frac{1}{\\sigma^2}\\right)^{1/2}\\exp\\left\\{-\\frac{\\beta_n}{2\\sigma^2}(\\mu-\\mu_n)^2\\right\\}\\right.\\nonumber\\\\ &amp;\\times \\left.\\left(\\frac{1}{\\sigma^2}\\right)^{\\alpha_n/2+1}\\exp\\left\\{-\\frac{\\delta_n}{2\\sigma^2}\\right\\}\\right\\}d\\sigma^2d\\mu\\nonumber\\\\ &amp;=\\int_{-\\infty}^{\\infty}\\int_0^{\\infty}\\left\\{ \\left(\\frac{1}{\\sigma^2}\\right)^{\\frac{\\alpha_n+2}{2}+1}\\exp\\left\\{-\\frac{1}{2\\sigma^2}((y_0-\\mu)^2+\\beta_n(\\mu-\\mu_n)^2+\\delta_n)\\right\\}\\right\\}d\\sigma^2d\\mu\\nonumber\\\\ &amp;\\propto\\int_{-\\infty}^{\\infty}\\left[\\beta_n(\\mu-\\mu_n)^2+(y_0-\\mu)^2+\\delta_n\\right]^{-\\left(\\frac{\\alpha_n}{2}+1\\right)}d\\mu\\nonumber\\\\ &amp;=\\int_{-\\infty}^{\\infty}\\left[(\\beta_n+1)\\left(\\mu-\\left(\\frac{\\beta_n\\mu_n+y_0}{\\beta_n+1}\\right)\\right)^2+\\frac{\\beta_n(y_0-\\mu_n)^2}{\\beta_n+1}+\\delta_n\\right]^{-\\left(\\frac{\\alpha_n}{2}+1\\right)}d\\mu\\nonumber\\\\ &amp;=\\int_{-\\infty}^{\\infty}\\left[1+\\frac{(\\beta_n+1)^2\\left(\\mu-\\left(\\frac{\\beta_n\\mu_n+y_0}{\\beta_n+1}\\right)\\right)^2}{\\beta_n(y_0-\\mu_n)^2+(\\beta_n+1)\\delta_n}\\right]^{-\\left(\\frac{\\alpha_n}{2}+1\\right)}d\\mu\\nonumber\\\\ &amp;\\times\\left(\\frac{\\beta_n(y_0-\\mu_n)^2+(\\beta_n+1)\\delta_n}{\\beta_n+1}\\right)^{-\\left(\\frac{\\alpha_n}{2}+1\\right)}\\nonumber\\\\ &amp;\\propto\\left(\\frac{\\beta_n(y_0-\\mu_n)^2+(\\beta_n+1)\\delta_n}{(\\beta_n+1)^2(\\alpha_n+1)}\\right)^{\\frac{1}{2}}\\left(\\frac{\\beta_n(y_0-\\mu_n)^2+(\\beta_n+1)\\delta_n}{\\beta_n+1}\\right)^{-\\left(\\frac{\\alpha_n}{2}+1\\right)}\\nonumber\\\\ &amp;\\propto (\\beta_n(y_0-\\mu_n)^2+(\\beta_n+1)\\delta_n)^{\\left(\\frac{\\alpha_n+1}{2}\\right)}\\nonumber\\\\ &amp;\\propto\\left[1+\\frac{\\beta_n\\alpha_n}{(\\beta_n+1)\\delta_n\\alpha_n}(y_0-\\mu_n)^2\\right]^{-\\left(\\frac{\\alpha_n+1}{2}\\right)},\\nonumber \\end{align}\\] where we have that \\(\\left[1+\\frac{(\\beta_n+1)^2\\left(\\mu-\\left(\\frac{\\beta_n\\mu_n+y_0}{\\beta_n+1}\\right)\\right)^2}{\\beta_n(y_0-\\mu_n)^2+(\\beta_n+1)\\delta_n}\\right]^{-\\left(\\frac{\\alpha_n}{2}+1\\right)}\\) is the kernel of a Student’s t density with degrees of freedom \\(\\alpha_n+1\\) and scale \\(\\frac{\\beta_n(y_0-\\mu_n)^2+(\\beta_n+1)\\delta_n}{(\\beta_n+1)^2(\\alpha_n+1)}\\). The last expression is the kernel of a Student’s t density, that is, \\(Y_0\\mid \\boldsymbol{y}\\sim t\\left(\\mu_n,\\frac{(\\beta_n+1)\\delta_n}{\\beta_n\\alpha_n},\\alpha_n\\right)\\). The multivariate normal-normal/inverse-Wishart model We show in subsection 3.1 that the multivariate normal distribution is in the exponential family where \\[\\begin{equation*} C(\\boldsymbol{\\mu},\\boldsymbol{\\Sigma})=\\exp\\left\\{-\\frac{1}{2}\\left(tr\\left(\\boldsymbol{\\mu}\\boldsymbol{\\mu}^{\\top}\\boldsymbol{\\Sigma}^{-1}\\right)+\\log(|\\Sigma|)\\right)\\right\\}, \\end{equation*}\\] \\[\\begin{equation*} \\eta(\\boldsymbol{\\mu},\\boldsymbol{\\Sigma})^{\\top}=\\left[\\left(vec\\left(\\boldsymbol{\\Sigma}^{-1}\\right)\\right)^{\\top} \\ \\ \\left(vec\\left(\\boldsymbol{\\mu}^{\\top}\\boldsymbol{\\Sigma}^{-1}\\right)\\right)^{\\top}\\right], \\end{equation*}\\] \\[\\begin{equation*} T(\\boldsymbol{y})=\\left[-\\frac{1}{2}\\left(vec\\left(\\boldsymbol{S}\\right)^{\\top}+N vec\\left(\\hat{\\boldsymbol{\\mu}}\\hat{\\boldsymbol{\\mu}}^{\\top}\\right)^{\\top}\\right) \\ \\ -N\\hat{\\boldsymbol{\\mu}}^{\\top}\\right]^{\\top} \\end{equation*}\\] and \\[\\begin{equation*} h(\\boldsymbol{y})=(2\\pi)^{-pN/2}. \\end{equation*}\\] Then, its conjugate prior distribution should have the form \\[\\begin{align} \\pi(\\boldsymbol{\\mu},\\boldsymbol{\\Sigma})&amp;\\propto \\exp\\left\\{-\\frac{b_0}{2}\\left(tr\\left(\\boldsymbol{\\mu}\\boldsymbol{\\mu}^{\\top}\\boldsymbol{\\Sigma}^{-1}\\right)+\\log(|\\Sigma|)\\right)\\right\\}\\nonumber\\\\ &amp;\\times \\exp\\left\\{\\boldsymbol{a}_{01}^{\\top} vec\\left(\\boldsymbol{\\Sigma}^{-1}\\right)+\\boldsymbol{a}_{02}^{\\top}vec\\left(\\boldsymbol{\\mu}^{\\top}\\boldsymbol{\\Sigma}^{-1}\\right)\\right\\}\\nonumber\\\\ &amp;=|\\Sigma|^{-b_0/2}\\exp\\left\\{-\\frac{b_0}{2}\\left(tr\\left(\\boldsymbol{\\mu}^{\\top}\\boldsymbol{\\Sigma}^{-1}\\boldsymbol{\\mu}\\right)\\right)+tr\\left(\\boldsymbol{a}_{02}^{\\top}\\boldsymbol{\\Sigma}^{-1}\\boldsymbol{\\mu}\\right)\\right\\}\\nonumber\\\\ &amp;\\times \\exp\\left\\{\\boldsymbol{a}_{01}^{\\top} vec\\left(\\boldsymbol{\\Sigma}^{-1}\\right)+\\frac{\\boldsymbol{a}_{02}^{\\top}\\boldsymbol{\\Sigma}^{-1}\\boldsymbol{a}_{02}}{2b_0}-\\frac{\\boldsymbol{a}_{02}^{\\top}\\boldsymbol{\\Sigma}^{-1}\\boldsymbol{a}_{02}}{2b_0}\\right\\}\\nonumber\\\\ &amp;=|\\Sigma|^{-b_0/2}\\exp\\left\\{-\\frac{b_0}{2}\\left(\\boldsymbol{\\mu}-\\frac{\\boldsymbol{a}_{02}}{b_0}\\right)^{\\top}\\boldsymbol{\\Sigma}^{-1}\\left(\\boldsymbol{\\mu}-\\frac{\\boldsymbol{a}_{02}}{b_0}\\right)\\right\\}\\nonumber\\\\ &amp;\\times \\exp\\left\\{-\\frac{1}{2}tr\\left(\\left(\\boldsymbol{A}_{01}-\\frac{\\boldsymbol{a}_{02}\\boldsymbol{a}_{02}^{\\top}}{b_0}\\right)\\boldsymbol{\\Sigma}^{-1}\\right)\\right\\}\\nonumber\\\\ &amp;=\\underbrace{|\\Sigma|^{-1/2}\\exp\\left\\{-\\frac{b_0}{2}\\left(\\boldsymbol{\\mu}-\\frac{\\boldsymbol{a}_{02}}{b_0}\\right)^{\\top}\\boldsymbol{\\Sigma}^{-1}\\left(\\boldsymbol{\\mu}-\\frac{\\boldsymbol{a}_{02}}{b_0}\\right)\\right\\}}_1\\nonumber\\\\ &amp;\\times \\underbrace{|\\Sigma|^{-(\\alpha_0+p+1)/2}\\exp\\left\\{-\\frac{1}{2}tr\\left(\\left(\\boldsymbol{A}_{01}-\\frac{\\boldsymbol{a}_{02}\\boldsymbol{a}_{02}^{\\top}}{b_0}\\right)\\boldsymbol{\\Sigma}^{-1}\\right)\\right\\}}_2,\\nonumber \\end{align}\\] Here, \\(b_0\\) represents the hypothetical sample size, and \\(\\boldsymbol{a}_{01}\\) and \\(\\boldsymbol{a}_{02}\\) are \\(p^2\\)-dimensional and \\(p\\)-dimensional vectors of prior sufficient statistics, respectively. Specifically, \\(\\boldsymbol{a}_{01} = -\\frac{1}{2} \\text{vec}(\\boldsymbol{A}_{01})\\), where \\(\\boldsymbol{A}_{01}\\) is a \\(p \\times p\\) positive semi-definite matrix. Setting \\(b_0 = 1 + \\alpha_0 + p + 1\\), we observe that the first part of the last expression is the kernel of a multivariate normal density with mean \\(\\boldsymbol{\\mu}_0 = \\frac{\\boldsymbol{a}_{02}}{b_0}\\) and covariance \\(\\frac{\\boldsymbol{\\Sigma}}{b_0}\\), i.e., \\[ \\boldsymbol{\\mu} \\mid \\boldsymbol{\\Sigma} \\sim N_p \\left( \\boldsymbol{\\mu}_0, \\frac{\\boldsymbol{\\Sigma}}{b_0} \\right), \\] where \\(b_0 = \\beta_0\\). This choice of hyperparameters is intuitive because \\(\\boldsymbol{a}_{02}\\) represents the hypothetical sum of prior observations, and \\(b_0\\) represents the hypothetical prior sample size. Additionally, the second part of the last expression corresponds to the kernel of an inverse Wishart distribution with scale matrix \\(\\boldsymbol{\\Psi}_0 = \\left( \\boldsymbol{A}_{01} - \\frac{\\boldsymbol{a}_{02} \\boldsymbol{a}_{02}^{\\top}}{b_0} \\right)\\) and \\(\\alpha_0\\) degrees of freedom, i.e., \\[ \\boldsymbol{\\Sigma} \\sim IW_p (\\boldsymbol{\\Psi}_0, \\alpha_0). \\] Observe that \\(\\boldsymbol{\\Psi}_0\\) has the same structure as the first part of the sufficient statistics in \\(T(\\boldsymbol{y})\\), except that it should be understood as arising from prior hypothetical observations. Therefore, the prior distribution in this setting is normal/inverse-Wishart, and, due to conjugacy, the posterior distribution belongs to the same family. \\[\\begin{align} \\pi(\\boldsymbol{\\mu},\\boldsymbol{\\Sigma}\\mid \\boldsymbol{y})&amp;\\propto (2\\pi)^{-p N/2}|\\boldsymbol{\\Sigma}|^{-N/2}\\exp\\left\\{-\\frac{1}{2}tr\\left[\\left(\\boldsymbol{S}+N\\left(\\boldsymbol{\\mu}-\\hat{\\boldsymbol{\\mu}}\\right)\\left(\\boldsymbol{\\mu}-\\hat{\\boldsymbol{\\mu}}\\right)^{\\top}\\right)\\boldsymbol{\\Sigma}^{-1}\\right]\\right\\}\\nonumber\\\\ &amp;\\times |\\boldsymbol{\\Sigma}|^{-1/2}\\exp\\left\\{-\\frac{\\beta_0}{2}tr\\left[(\\boldsymbol{\\mu}-\\boldsymbol{\\mu}_0)(\\boldsymbol{\\mu}-\\boldsymbol{\\mu}_0)^{\\top}\\boldsymbol{\\Sigma}^{-1}\\right]\\right\\}|\\boldsymbol{\\Sigma}|^{-(\\alpha_0+p+1)/2}\\nonumber\\\\ &amp;\\times\\exp\\left\\{-\\frac{1}{2}tr(\\boldsymbol{\\Psi}_0\\boldsymbol{\\Sigma}^{-1})\\right\\}\\nonumber. \\end{align}\\] Taking into account that \\[\\begin{align} N\\left(\\boldsymbol{\\mu}-\\hat{\\boldsymbol{\\mu}}\\right)\\left(\\boldsymbol{\\mu}-\\hat{\\boldsymbol{\\mu}}\\right)^{\\top}+\\beta_0\\left(\\boldsymbol{\\mu}-\\boldsymbol{\\mu}_0\\right)\\left(\\boldsymbol{\\mu}-\\boldsymbol{\\mu}_0\\right)^{\\top}&amp;=(N+\\beta_0)\\left(\\boldsymbol{\\mu}-\\boldsymbol{\\mu}_n\\right)\\left(\\boldsymbol{\\mu}-\\boldsymbol{\\mu}_n\\right)^{\\top}\\nonumber\\\\ &amp;+\\frac{N\\beta_0}{N+\\beta_0}\\left(\\hat{\\boldsymbol{\\mu}}-\\boldsymbol{\\mu}_0\\right)\\left(\\hat{\\boldsymbol{\\mu}}-\\boldsymbol{\\mu}_0\\right)^{\\top},\\nonumber \\end{align}\\] where \\(\\boldsymbol{\\mu}_n=\\frac{N}{N+\\beta_0}\\hat{\\boldsymbol{\\mu}}+\\frac{\\beta_0}{N+\\beta_0}\\boldsymbol{\\mu}_0\\) is the posterior mean. We have \\[\\begin{align} \\pi(\\boldsymbol{\\mu},\\boldsymbol{\\Sigma}\\mid \\boldsymbol{y})&amp;\\propto |\\boldsymbol\\Sigma|^{-1/2}\\exp\\left\\{-\\frac{N+\\beta_0}{2}tr\\left[\\left(\\left(\\boldsymbol{\\mu}-\\boldsymbol{\\mu}_n\\right)\\left(\\boldsymbol{\\mu}-\\boldsymbol{\\mu}_n\\right)^{\\top}\\right)\\boldsymbol{\\Sigma}^{-1}\\right]\\right\\}\\nonumber\\\\ &amp;\\times |\\boldsymbol{\\Sigma}|^{-(N+\\alpha_0+p+1)/2}\\nonumber\\\\ &amp;\\times\\exp\\left\\{-\\frac{1}{2}tr\\left[\\left(\\boldsymbol{\\Psi}_0+\\boldsymbol{S}+\\frac{N\\beta_0}{N+\\beta_0}(\\hat{\\boldsymbol{\\mu}}-\\boldsymbol{\\mu}_0)(\\hat{\\boldsymbol{\\mu}}-\\boldsymbol{\\mu}_0)^{\\top}\\right)\\boldsymbol{\\Sigma}^{-1}\\right]\\right\\}.\\nonumber \\end{align}\\] Then, \\(\\boldsymbol{\\mu}\\mid \\boldsymbol{\\Sigma},\\boldsymbol{y}\\sim N_p\\left(\\boldsymbol{\\mu}_n,\\frac{1}{\\beta_n}\\boldsymbol{\\Sigma}\\right)\\), and \\(\\boldsymbol{\\Sigma}\\mid \\boldsymbol{y}\\sim IW\\left(\\boldsymbol{\\Psi}_n,\\alpha_n\\right)\\) where \\(\\beta_n=N+\\beta_0\\), \\(\\alpha_n=N+\\alpha_0\\) and \\(\\boldsymbol{\\Psi}_n=\\boldsymbol{\\Psi}_0+\\boldsymbol{S}+\\frac{N\\beta_0}{N+\\beta_0}(\\hat{\\boldsymbol{\\mu}}-\\boldsymbol{\\mu}_0)(\\hat{\\boldsymbol{\\mu}}-\\boldsymbol{\\mu}_0)^{\\top}\\). The marginal posterior of \\(\\boldsymbol{\\mu}\\) is given by \\(\\int_{\\mathcal{S}} \\pi(\\boldsymbol{\\mu},\\boldsymbol{\\Sigma})d\\boldsymbol{\\Sigma}\\) where \\(\\mathcal{S}\\) is the space of positive semi-definite matrices. Then, \\[\\begin{align} \\pi(\\boldsymbol{\\mu}\\mid \\boldsymbol{y})&amp;\\propto\\int_{\\mathcal{S}}\\left\\{|\\boldsymbol{\\Sigma}|^{-(\\alpha_n+p+2)/2}\\right.\\nonumber\\\\ &amp;\\left. \\exp\\left\\{-\\frac{1}{2}tr\\left[\\left(\\beta_n\\left(\\boldsymbol{\\mu}-\\boldsymbol{\\mu}_n\\right)\\left(\\boldsymbol{\\mu}-\\boldsymbol{\\mu}_n\\right)^{\\top}+\\boldsymbol{\\Psi}_n\\right)\\boldsymbol{\\Sigma}^{-1}\\right]\\right\\} \\right\\}d\\boldsymbol{\\Sigma}\\nonumber\\\\ &amp;\\propto \\big\\lvert\\left(\\beta_n\\left(\\boldsymbol{\\mu}-\\boldsymbol{\\mu}_n\\right)\\left(\\boldsymbol{\\mu}-\\boldsymbol{\\mu}_n\\right)^{\\top}+\\boldsymbol{\\Psi}_n\\right)\\big\\lvert^{-(\\alpha_n+1)/2}\\nonumber\\\\ &amp;=\\left[\\big\\lvert\\boldsymbol{\\Psi}_n\\big\\lvert\\times \\big\\lvert1+\\beta_n\\left(\\boldsymbol{\\mu}-\\boldsymbol{\\mu}_n\\right)^{\\top}\\boldsymbol{\\Psi}_n^{-1}\\left(\\boldsymbol{\\mu}-\\boldsymbol{\\mu}_n\\right)\\big\\lvert\\right]^{-(\\alpha_n+1)/2}\\nonumber\\\\ &amp;\\propto \\left(1+\\frac{1}{\\alpha_n+1-p}\\left(\\boldsymbol{\\mu}-\\boldsymbol{\\mu}_n\\right)^{\\top}\\left(\\frac{\\boldsymbol{\\Psi}_n}{(\\alpha_n+1-p)\\beta_n}\\right)^{-1}\\left(\\boldsymbol{\\mu}-\\boldsymbol{\\mu}_n\\right)\\right)^{-(\\alpha_n+1-p+p)/2},\\nonumber \\end{align}\\] where the second line uses properties of the inverse Wishart distribution, and the third line uses a particular case of the Sylvester’s determinant theorem. We observe that the last line is the kernel of a multivariate t distribution, that is, \\(\\boldsymbol{\\mu}\\mid \\boldsymbol{y}\\sim t_p(v_n,\\boldsymbol{\\mu}_n,\\boldsymbol{\\Sigma}_n)\\) where \\(v_n=\\alpha_n+1-p\\) and \\(\\boldsymbol{\\Sigma}_n=\\frac{\\boldsymbol{\\Psi}_n}{(\\alpha_n+1-p)\\beta_n}\\). The marginal likelihood is given by \\[\\begin{align} p(\\boldsymbol{y})=\\frac{\\Gamma_p\\left(\\frac{v_n}{2}\\right)}{\\Gamma_p\\left(\\frac{\\alpha_0}{2}\\right)}\\frac{|\\boldsymbol{\\Psi}_0|^{\\alpha_0/2}}{|\\boldsymbol{\\Psi}_n|^{\\alpha_n/2}}\\left(\\frac{\\beta_0}{\\beta_n}\\right)^{p/2}(2\\pi)^{-Np/2},\\nonumber \\end{align}\\] where \\(\\Gamma_p\\) is the multivariate gamma function (see Exercise 5). The posterior predictive distribution is \\(\\boldsymbol{Y}_0\\mid \\boldsymbol{y}\\sim t_p(v_n,\\boldsymbol{\\mu}_n,(\\beta_n+1)\\boldsymbol{\\Sigma}_n)\\) (see Exercise 6). Example: Tangency portfolio of US tech stocks The tangency portfolio is the portfolio that maximizes the Sharpe ratio, which is defined as the excess return of a portfolio standardized by its risk. We aim to find the portfolio weights \\(\\boldsymbol{w}\\) that maximize the Sharpe ratio, where \\(\\mu_{i,T+\\kappa} = \\mathbb{E}\\left( R_{i,T+\\kappa} - R_{f,T+\\kappa} \\mid \\mathcal{I}_T \\right)\\), with \\(R_{i,T+\\kappa}\\) and \\(R_{f,T+\\kappa}\\) representing the returns of stock \\(i\\) and the risk-free asset, respectively. Here, \\(\\mu_{i,T+\\kappa}\\) is the expected value of the excess return at period \\(T+\\kappa\\), conditional on information available up to time \\(T\\) (\\(\\mathcal{I}_T\\)), and \\(\\boldsymbol{\\Sigma}_{T+\\kappa}\\) is the covariance matrix of the excess returns, which quantifies the risk. \\[\\begin{equation*} \\text{argmax}_{{\\boldsymbol w}\\in \\mathbb{R}^{p}} \\frac{{\\boldsymbol w}^{\\top}\\boldsymbol{\\mu}_{T+\\kappa}}{\\sqrt{{\\boldsymbol w}^{\\top}{\\boldsymbol{\\Sigma}}_{T+\\kappa} {\\boldsymbol w}}}; \\hspace{1cm} \\text{s.t}\\hspace{.5cm} {\\boldsymbol w}^{\\top}{\\boldsymbol{1}}=1, \\end{equation*}\\] where the solution is \\[\\begin{equation*} {\\boldsymbol w}^*=\\frac{{\\boldsymbol{\\Sigma}}^{-1}_{T+\\kappa}\\boldsymbol{\\mu}_{T+\\kappa}}{{\\boldsymbol{1}}^{\\top}{\\boldsymbol \\Sigma}^{-1}_{T+\\kappa}\\boldsymbol{\\mu}_{T+\\kappa}}. \\end{equation*}\\] If we want to find the optimal portfolio for the next period under the assumption that the excess returns follow a multivariate normal distribution –a common assumption in these applications– we can set \\(\\kappa = 1\\) and use the predictive distribution of the excess returns. In this case, \\(\\boldsymbol{\\mu}_{T+1} = \\boldsymbol{\\mu}_n\\) and \\(\\boldsymbol{\\Sigma}_{T+1} = \\frac{v_n}{v_n - 2} (\\beta_n + 1) \\boldsymbol{\\Sigma}_n\\), based on the previous predictive result. We apply this framework to ten tech stocks of the US market between January first, 2021, and September ninth, 2022. In particular, we use information from Yahoo Finance for Apple (AAPL), Netflix (NFLX), Amazon (AMZN), Microsoft (MSFT), Google (GOOG), Meta (META), Tesla (TSLA), NVIDIA Corporation (NVDA), Intel (INTC), and PayPal (PYPL). library(quantmod) ## Loading required package: xts ## Loading required package: zoo ## ## Attaching package: &#39;zoo&#39; ## The following objects are masked from &#39;package:base&#39;: ## ## as.Date, as.Date.numeric ## ## ######################### Warning from &#39;xts&#39; package ########################## ## # # ## # The dplyr lag() function breaks how base R&#39;s lag() function is supposed to # ## # work, which breaks lag(my_xts). Calls to lag(my_xts) that you type or # ## # source() into this session won&#39;t work correctly. # ## # # ## # Use stats::lag() to make sure you&#39;re not using dplyr::lag(), or you can add # ## # conflictRules(&#39;dplyr&#39;, exclude = &#39;lag&#39;) to your .Rprofile to stop # ## # dplyr from breaking base R&#39;s lag() function. # ## # # ## # Code in packages is not affected. It&#39;s protected by R&#39;s namespace mechanism # ## # Set `options(xts.warn_dplyr_breaks_lag = FALSE)` to suppress this warning. # ## # # ## ############################################################################### ## ## Attaching package: &#39;xts&#39; ## The following objects are masked from &#39;package:dplyr&#39;: ## ## first, last ## Loading required package: TTR ## Registered S3 method overwritten by &#39;quantmod&#39;: ## method from ## as.zoo.data.frame zoo library(xts) library(ggplot2) library(gridExtra) ## ## Attaching package: &#39;gridExtra&#39; ## The following object is masked from &#39;package:dplyr&#39;: ## ## combine # grid.arrange graphics.off() rm(list=ls()) # Data Range sdate &lt;- as.Date(&quot;2021-01-01&quot;) edate &lt;- as.Date(&quot;2022-09-30&quot;) Date &lt;- seq(sdate, edate, by = &quot;day&quot;) tickers &lt;- c(&quot;AAPL&quot;, &quot;NFLX&quot;, &quot;AMZN&quot;, &quot;GOOG&quot;, &quot;INTC&quot;,&quot;META&quot;, &quot;MSFT&quot;, &quot;TSLA&quot;, &quot;NVDA&quot;, &quot;PYPL&quot;) p &lt;- length(tickers) # AAPL: Apple, NFLX: Netflix, AMZN: Amazon, # MSFT: Microsoft, GOOG: Google, META: Meta, # TSLA: Tesla, NVDA: NVIDIA Corporation # INTC: Intel, PYPL: PayPal ss_stock &lt;- getSymbols(tickers, from=sdate, to=edate, auto.assign = T) ss_stock &lt;- purrr::map(tickers,function(x) Ad(get(x))) ss_stock &lt;- as.data.frame(purrr::reduce(ss_stock, merge)) colnames(ss_stock) &lt;- tickers # This is to get stock prices ss_rtn &lt;- as.data.frame(apply(ss_stock, 2, function(x) {diff(log(x), 1)})) # Daily returns t10yr &lt;- getSymbols(Symbols = &quot;DGS10&quot;, src = &quot;FRED&quot;, from=sdate, to=edate, auto.assign = F) # To get 10-Year US Treasury yield data from the Federal Reserve Electronic Database (FRED) t10yrd &lt;- (1 + t10yr/100)^(1/365)-1 # Daily returns t10yrd &lt;- t10yrd[row.names(ss_rtn)] Exc_rtn &lt;- as.matrix(ss_rtn) - kronecker(t(rep(1, p)), as.matrix(t10yrd)) # Excesses of return df &lt;- as.data.frame(Exc_rtn) df$Date &lt;- as.Date(rownames(df)) # Get months df$Month &lt;- months(df$Date) # Get years df$Year &lt;- format(df$Date, format=&quot;%y&quot;) # Aggregate on months and year and get mean Data &lt;- sapply(1:p, function(i) { aggregate(df[, i] ~ Month + Year, df, mean)}) DataExcRtn &lt;- matrix(0, length(Data[, 1]$Month), p) for(i in 1:p){ DataExcRtn[, i] &lt;- as.numeric(Data[, i]$`df[, i]`) } colnames(DataExcRtn) &lt;- tickers head(DataExcRtn) ## AAPL NFLX AMZN GOOG INTC ## [1,] 0.003453436 -0.0007978684 0.0053804495 0.0072313890 -0.0051193877 ## [2,] 0.001856496 0.0042864089 0.0018802467 0.0032834533 0.0005462708 ## [3,] 0.003214835 -0.0029236867 -0.0023355829 0.0006654206 0.0020368917 ## [4,] 0.001054383 0.0009737922 0.0003104527 0.0033227708 0.0061459733 ## [5,] -0.004406269 0.0006005357 -0.0019272761 0.0054374191 0.0050578243 ## [6,] 0.002962127 -0.0010048976 -0.0016201572 0.0035865836 -0.0021341328 ## META MSFT TSLA NVDA PYPL ## [1,] 0.0046552164 0.0031597866 0.002826751 0.0055412954 0.0036246294 ## [2,] 0.0028180326 0.0026818375 0.003066171 0.0062470706 0.0020811144 ## [3,] 0.0015960684 0.0007412593 -0.003674775 -0.0048193681 0.0008583936 ## [4,] -0.0022658207 0.0034977089 0.004623756 -0.0005564295 0.0005398989 ## [5,] -0.0001791074 0.0001820381 -0.008509941 0.0028232820 0.0054109929 ## [6,] 0.0011262192 0.0023652517 0.000486675 -0.0012498933 -0.0027156472 # Hyperparameters # N &lt;- dim(DataExcRtn)[1] mu0 &lt;- rep(0, p) beta0 &lt;- 1 Psi0 &lt;- 100 * diag(p) alpha0 &lt;- p + 2 # Posterior parameters # alphan &lt;- N + alpha0 vn &lt;- alphan + 1 - p muhat &lt;- colMeans(DataExcRtn) mun &lt;- N/(N + beta0) * muhat + beta0/(N + beta0) * mu0 S &lt;- t(DataExcRtn - rep(1, N)%*%t(muhat))%*%(DataExcRtn - rep(1, N) %*%t(muhat)) Psin &lt;- Psi0 + S + N*beta0/(N + beta0)*(muhat - mu0)%*%t(muhat - mu0) betan &lt;- N + beta0 Sigman &lt;- Psin/((alphan + 1 - p)*betan) Covarn &lt;- (Sigman * (1 + betan)) * vn / (vn - 2) Covari &lt;- solve(Covarn) OptShare &lt;- t(Covari%*%mun/as.numeric((t(rep(1, p))%*%Covari%*%mun))) colnames(OptShare) &lt;- tickers OptShare ## AAPL NFLX AMZN GOOG INTC META MSFT ## [1,] -0.01871449 0.248481 0.1028211 -0.03408626 0.1733602 0.2299969 -0.0222197 ## TSLA NVDA PYPL ## [1,] -0.01591862 0.03534303 0.3009368 We find that the optimal tangency portfolio is composed by 24.8%, 10.2%, 17.3%, 23%, 3.5% and 30.1% weights of Netflix, Amazon, Intel, Meta, NVIDIA and PayPal, and -1.9%, -3.4%, -2.2% and -1.6% weights of Apple, Google, Microsoft and Tesla. A negative weight means being short in financial jargon, that is, borrowing a stock to sell it. References "],["sec43.html", "3.3 Linear regression: The conjugate normal-normal/inverse gamma model", " 3.3 Linear regression: The conjugate normal-normal/inverse gamma model In this setting, we analyze the conjugate normal-normal/inverse gamma model, which is a cornerstone in econometrics. In this model, the dependent variable \\(y_i\\) is related to a set of regressors \\(\\boldsymbol{x}_i = [x_{i1} \\ x_{i2} \\ \\dots \\ x_{iK}]^{\\top}\\) in a linear way, that is: \\[ y_i = \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\dots + \\beta_K x_{iK} + \\mu_i = \\boldsymbol{x}_i^{\\top} \\boldsymbol{\\beta} + \\mu_i, \\] where \\(\\boldsymbol{\\beta} = [\\beta_1 \\ \\beta_2 \\ \\dots \\ \\beta_K]^{\\top}\\) and \\(\\mu_i \\stackrel{iid}{\\sim} N(0, \\sigma^2)\\) is a stochastic error such that \\(\\mathbb{E}[\\mu_i \\mid \\boldsymbol{x}_i] = 0\\). Defining the vectors and matrices: \\[ \\boldsymbol{y} = \\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_N \\end{bmatrix}, \\quad \\boldsymbol{X} = \\begin{bmatrix} x_{11} &amp; x_{12} &amp; \\dots &amp; x_{1K} \\\\ x_{21} &amp; x_{22} &amp; \\dots &amp; x_{2K} \\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots \\\\ x_{N1} &amp; x_{N2} &amp; \\dots &amp; x_{NK} \\end{bmatrix}, \\quad \\boldsymbol{\\mu} = \\begin{bmatrix} \\mu_1 \\\\ \\mu_2 \\\\ \\vdots \\\\ \\mu_N \\end{bmatrix}, \\] we can write the model in matrix form as: \\[ \\boldsymbol{y} = \\boldsymbol{X} \\boldsymbol{\\beta} + \\boldsymbol{\\mu}, \\] where \\(\\boldsymbol{\\mu} \\sim N(\\boldsymbol{0}, \\sigma^2 \\boldsymbol{I})\\). This implies that: \\[ \\boldsymbol{y} \\sim N(\\boldsymbol{X} \\boldsymbol{\\beta}, \\sigma^2 \\boldsymbol{I}).\\] In regression analysis, to simplify notation, we depart from the conventional statistical notation, which defines lowercase letters as realizations of random variables, typically denoted by uppercase letters. We hope it is clear from the context when we refer to random vectors and matrices, and their realizations. Thus, we use bold lowercase letters for vectors and bold uppercase letters for matrices. This applies to the rest of the book. Thus, the likelihood function is: \\[\\begin{align*} p({\\boldsymbol{y}}\\mid \\boldsymbol{\\beta}, \\sigma^2, {{\\boldsymbol{X}}}) &amp; = (2\\pi\\sigma^2)^{-\\frac{N}{2}} \\exp \\left\\{-\\frac{1}{2\\sigma^2} ({\\boldsymbol{y}} - {\\boldsymbol{X}}\\boldsymbol{\\beta})^{\\top}({\\boldsymbol{y}} - {\\boldsymbol{X}}\\boldsymbol{\\beta}) \\right\\} \\\\ &amp; \\propto (\\sigma^2)^{-\\frac{N}{2}} \\exp \\left\\{-\\frac{1}{2\\sigma^2} ({\\boldsymbol{y}} - {\\boldsymbol{X}}\\boldsymbol{\\beta})^{\\top}({\\boldsymbol{y}} - {\\boldsymbol{X}}\\boldsymbol{\\beta}) \\right\\}. \\end{align*}\\] The conjugate priors for the parameters are \\[\\begin{align*} \\boldsymbol{\\beta}\\mid \\sigma^2 &amp; \\sim N(\\boldsymbol{\\beta}_0, \\sigma^2 {\\boldsymbol{B}}_0),\\\\ \\sigma^2 &amp; \\sim IG(\\alpha_0/2, \\delta_0/2). \\end{align*}\\] Then, the posterior distribution is \\[\\begin{align*} \\pi(\\boldsymbol{\\beta},\\sigma^2\\mid \\boldsymbol{y},\\boldsymbol{X})&amp;\\propto (\\sigma^2)^{-\\frac{N}{2}} \\exp \\left\\{-\\frac{1}{2\\sigma^2} ({\\boldsymbol{y}} - {\\boldsymbol{X}}\\boldsymbol{\\beta})^{\\top}({\\boldsymbol{y}} - {\\boldsymbol{X}}\\boldsymbol{\\beta}) \\right\\} \\\\ &amp; \\times (\\sigma^2)^{-\\frac{K}{2}} \\exp \\left\\{-\\frac{1}{2\\sigma^2} (\\boldsymbol{\\beta} - \\boldsymbol{\\beta}_0)^{\\top}{\\boldsymbol{B}}_0^{-1}(\\boldsymbol{\\beta} - \\boldsymbol{\\beta}_0)\\right\\} \\\\ &amp; \\times \\frac{(\\delta_0/2)^{\\alpha_0/2}}{\\Gamma(\\alpha_0/2)}\\left(\\frac{1}{\\sigma^2}\\right)^{\\alpha_0/2+1}\\exp \\left\\{-\\frac{\\delta_0}{2\\sigma^2} \\right\\} \\\\ &amp; \\propto (\\sigma^2)^{-\\frac{K}{2}} \\exp \\left\\{-\\frac{1}{2\\sigma^2} [\\boldsymbol{\\beta}^{\\top}({\\boldsymbol{B}}_0^{-1} + {\\boldsymbol{X}}^{\\top}{\\boldsymbol{X}})\\boldsymbol{\\beta} - 2\\boldsymbol{\\beta}^{\\top}({\\boldsymbol{B}}_0^{-1}\\boldsymbol{\\beta}_0 + {\\boldsymbol{X}}^{\\top}{\\boldsymbol{X}}\\hat{\\boldsymbol{\\beta}})] \\right\\} \\\\ &amp; \\times \\left(\\frac{1}{\\sigma^2}\\right)^{(\\alpha_0+N)/2+1}\\exp \\left\\{-\\frac{\\delta_0+ {\\boldsymbol{y}}^{\\top}{\\boldsymbol{y}} + \\boldsymbol{\\beta}_0^{\\top}{\\boldsymbol{B}}_0^{-1}\\boldsymbol{\\beta}_0}{2\\sigma^2} \\right\\}, \\end{align*}\\] where \\(\\hat{\\boldsymbol{\\beta}}=({\\boldsymbol{X}}^{\\top}{\\boldsymbol{X}})^{-1}{\\boldsymbol{X}}^{\\top}{\\boldsymbol{y}}\\) is the maximum likelihood estimator. Adding and subtracting \\(\\boldsymbol{\\beta}_n^{\\top}{{\\boldsymbol{B}}}_n^{-1} \\boldsymbol{\\beta}_n\\) to complete the square, where \\(\\boldsymbol{B}_n = (\\boldsymbol{B}_0^{-1} + \\boldsymbol{X}^{\\top}\\boldsymbol{X})^{-1}\\) and \\(\\boldsymbol{\\beta}_n = \\boldsymbol{B}_n(\\boldsymbol{B}_0^{-1}\\boldsymbol{\\beta}_0 + \\boldsymbol{X}^{\\top}\\boldsymbol{X}\\hat{\\boldsymbol{\\beta}})\\), \\[\\begin{align*} \\pi(\\boldsymbol{\\beta},\\sigma^2\\mid \\boldsymbol{y},\\boldsymbol{X})&amp;\\propto \\underbrace{(\\sigma^2)^{-\\frac{K}{2}} \\exp \\left\\{-\\frac{1}{2\\sigma^2} (\\boldsymbol{\\beta}-\\boldsymbol{\\beta}_n)^{\\top}{\\boldsymbol{B}}^{-1}_n(\\boldsymbol{\\beta}-\\boldsymbol{\\beta}_n) \\right\\}}_1 \\\\ &amp; \\times \\underbrace{(\\sigma^2)^{-\\left(\\frac{\\alpha_n}{2}+1 \\right)} \\exp \\left\\{-\\frac{\\delta_n}{2\\sigma^2} \\right\\}}_2. \\end{align*}\\] The first expression is the kernel of a normal density function, \\(\\boldsymbol{\\beta}\\mid \\sigma^2, \\boldsymbol{y}, \\boldsymbol{X} \\sim N(\\boldsymbol{\\beta}_n, \\sigma^2\\boldsymbol{B}_n)\\). The second expression is the kernel of a inverse gamma density, \\(\\sigma^2\\mid \\boldsymbol{y}, \\boldsymbol{X}\\sim IG(\\alpha_n/2, \\delta_n/2)\\), where \\(\\alpha_n = \\alpha_0 + N\\) and \\(\\delta_n = \\delta_0 + \\boldsymbol{y}^{\\top}\\boldsymbol{y} + \\boldsymbol{\\beta}_0^{\\top}\\boldsymbol{B}_0^{-1}\\boldsymbol{\\beta}_0 - \\boldsymbol{\\beta}_n^{\\top}\\boldsymbol{B}_n^{-1}\\boldsymbol{\\beta}_n\\). Taking into account that \\[\\begin{align*}\\boldsymbol{\\beta}_n &amp; = (\\boldsymbol{B}_0^{-1} + \\boldsymbol{X}^{\\top}\\boldsymbol{X})^{-1}(\\boldsymbol{B}_0^{-1}\\boldsymbol{\\beta}_0 + \\boldsymbol{X}^{\\top}\\boldsymbol{X}\\hat{\\boldsymbol{\\beta}})\\\\ &amp; = (\\boldsymbol{B}_0^{-1} + \\boldsymbol{X}^{\\top}\\boldsymbol{X})^{-1}\\boldsymbol{B}_0^{-1}\\boldsymbol{\\beta}_0 + (\\boldsymbol{B}_0^{-1} + \\boldsymbol{X}^{\\top}\\boldsymbol{X})^{-1} \\boldsymbol{X}^{\\top}\\boldsymbol{X}\\hat{\\boldsymbol{\\beta}}, \\end{align*}\\] where \\(({\\boldsymbol{B}}_0^{-1} + {\\boldsymbol{X}}^{\\top}{\\boldsymbol{X}})^{-1}{\\boldsymbol{B}}_0^{-1}=\\boldsymbol{I}_K-({\\boldsymbol{B}}_0^{-1} + {\\boldsymbol{X}}^{\\top}{\\boldsymbol{X}})^{-1}{\\boldsymbol{X}}^{\\top}{\\boldsymbol{X}}\\) (A. F. M. Smith 1973). Setting \\({\\boldsymbol{W}}=({\\boldsymbol{B}}_0^{-1} + {\\boldsymbol{X}}^{\\top}{\\boldsymbol{X}})^{-1}{\\boldsymbol{X}}^{\\top}{\\boldsymbol{X}}\\) we have \\(\\boldsymbol{\\beta}_n=(\\boldsymbol{I}_K-{\\boldsymbol{W}})\\boldsymbol{\\beta}_0+{\\boldsymbol{W}}\\hat{\\boldsymbol{\\beta}}\\), that is, the posterior mean of \\(\\boldsymbol{\\beta}\\) is a weighted average between the sample and prior information, where the weights depend on the precision of each piece of information. Observe that when the prior covariance matrix is highly vague (non–informative), such that \\({\\boldsymbol{B}}_0^{-1}\\rightarrow \\boldsymbol{0}_K\\), we obtain \\({\\boldsymbol{W}} \\rightarrow I_K\\), such that \\(\\boldsymbol{\\beta}_n \\rightarrow \\hat{\\boldsymbol{\\beta}}\\), that is, the posterior mean location parameter converges to the maximum likelihood estimator. In addition, we know that the posterior conditional covariance matrix of the location parameters \\(\\sigma^2({\\boldsymbol{B}}_0^{-1} + {\\boldsymbol{X}}^{\\top}{\\boldsymbol{X}})^{-1}=\\sigma^2({\\boldsymbol{X}}^{\\top}{\\boldsymbol{X}})^{-1}-\\sigma^2\\left(({\\boldsymbol{X}}^{\\top}{\\boldsymbol{X}})^{-1}({\\boldsymbol{B}}_0 + ({\\boldsymbol{X}}^{\\top}{\\boldsymbol{X}})^{-1})^{-1}({\\boldsymbol{X}}^{\\top}{\\boldsymbol{X}})^{-1}\\right)\\) is positive semi-definite.21 Given that \\(\\sigma^2({\\boldsymbol{X}}^{\\top}{\\boldsymbol{X}})^{-1}\\) is the covariance matrix of the maximum likelihood estimator, we observe that prior information reduces estimation uncertainty. Another way to see this model is by considering that both \\(\\boldsymbol{y}\\) and \\(\\boldsymbol{\\beta}\\) are treated as random variables under the Bayesian framework. Thus, we can express the joint distribution of these two vectors as follows: \\[\\begin{align*} \\begin{bmatrix} \\boldsymbol{\\beta}\\\\ \\boldsymbol{y} \\end{bmatrix}\\sim N\\left [ \\begin{pmatrix} \\boldsymbol{\\beta}_{0} \\\\ \\boldsymbol{X}\\boldsymbol{\\beta}_{0} \\end{pmatrix} , \\sigma^2\\begin{pmatrix} \\boldsymbol{B}_{0} &amp; \\boldsymbol{B}_{0} \\boldsymbol{X}^{\\top} \\\\ \\boldsymbol{X}\\boldsymbol{B}_{0}^{\\top} &amp; \\boldsymbol{X}\\boldsymbol{B}_{0}\\boldsymbol{X}^{\\top}+\\boldsymbol{I}_N \\end{pmatrix}\\right ], \\end{align*}\\] where we use that \\(Cov[\\boldsymbol{\\beta},\\boldsymbol{y}]=\\mathbb{E}[\\boldsymbol{\\beta}\\boldsymbol{y}^{\\top}]-\\mathbb{E}[\\boldsymbol{\\beta}]\\mathbb{E}[\\boldsymbol{y}^{\\top}]=\\mathbb{E}[\\boldsymbol{\\beta}(\\boldsymbol{X}\\boldsymbol{\\beta}+\\boldsymbol{\\mu})^{\\top}]-\\mathbb{E}[\\boldsymbol{\\beta}]\\mathbb{E}[\\boldsymbol{y}^{\\top}]=[Var[\\boldsymbol{\\beta}]+\\mathbb{E}[\\boldsymbol{\\beta}]\\mathbb{E}[\\boldsymbol{\\beta}^{\\top}]]\\boldsymbol{X}^{\\top}-\\mathbb{E}[\\boldsymbol{\\beta}]\\mathbb{E}[\\boldsymbol{y}^{\\top}]=\\sigma^2\\boldsymbol{B}_0\\boldsymbol{X}^{\\top}+\\boldsymbol{\\beta}_0\\boldsymbol{\\beta}_0^{\\top}\\boldsymbol{X}^{\\top}-\\boldsymbol{\\beta}_0\\boldsymbol{\\beta}_0^{\\top}\\boldsymbol{X}^{\\top}=\\sigma^2\\boldsymbol{B}_0\\boldsymbol{X}^{\\top}\\). Then, we can obtain the conditional distribution of \\(\\boldsymbol{\\beta} \\mid \\boldsymbol{y}\\) using the properties of the multivariate normal distribution. This distribution is normal with mean equal to \\[ \\boldsymbol{\\beta}_{0} + \\boldsymbol{B}_{0} \\boldsymbol{X}^{\\top} \\left( \\boldsymbol{X} \\boldsymbol{B}_{0} \\boldsymbol{X}^{\\top} + \\boldsymbol{I}_N \\right)^{-1} (\\boldsymbol{y} - \\boldsymbol{X} \\boldsymbol{\\beta}_{0}), \\] and covariance matrix \\[ \\sigma^2 \\left( \\boldsymbol{B}_{0} - \\boldsymbol{B}_{0} \\boldsymbol{X}^{\\top} \\left( \\boldsymbol{X} \\boldsymbol{B}_{0} \\boldsymbol{X}^{\\top} + \\boldsymbol{I}_N \\right)^{-1} \\boldsymbol{X} \\boldsymbol{B}_{0}^{\\top} \\right). \\] Observe that in this representation, the posterior mean is equal to the prior mean plus a correction term that takes into account the deviation between the observations and the prior expected value (\\(\\boldsymbol{X} \\boldsymbol{\\beta}_{0}\\)). The weight of this correction is given by the matrix \\(\\boldsymbol{B}_{0} \\boldsymbol{X}^{\\top} \\left( \\boldsymbol{X} \\boldsymbol{B}_{0} \\boldsymbol{X}^{\\top} + \\boldsymbol{I}_N \\right)^{-1}\\). This form of expressing the posterior distribution is relevant for gaining some intuition on Bayesian inference in time series models within the Gaussian linear state-space representation in Chapter @ref{Chap8}, also known as the Kalman filter in time series literature. We can show that both conditional posterior distributions are the same. In particular, the posterior mean in this representation is \\([\\boldsymbol{I}_K-\\boldsymbol{B}_{0}\\boldsymbol{X}^{\\top}(\\boldsymbol{X}\\boldsymbol{B}_{0}\\boldsymbol{X}^{\\top}+ \\boldsymbol{I}_N)^{-1}\\boldsymbol{X}]\\boldsymbol{\\beta}_{0}+\\boldsymbol{B}_{0}\\boldsymbol{X}^{\\top}(\\boldsymbol{X}\\boldsymbol{B}_{0}\\boldsymbol{X}^{\\top}+ \\boldsymbol{I}_N)^{-1}\\boldsymbol{y}\\), where \\[\\begin{align*} \\boldsymbol{B}_{0}\\boldsymbol{X}^{\\top}(\\boldsymbol{X}\\boldsymbol{B}_{0}\\boldsymbol{X}^{\\top}+ \\boldsymbol{I}_N)^{-1} &amp;=\\boldsymbol{B}_{0}\\boldsymbol{X}^{\\top}[\\boldsymbol{I}_N-\\boldsymbol{I}_N\\boldsymbol{X}(\\boldsymbol{B}_0^{-1}+\\boldsymbol{X}^{\\top}\\boldsymbol{I}_N\\boldsymbol{X})^{-1}\\boldsymbol{X}^{\\top}\\boldsymbol{I}_N]\\\\ &amp;=\\boldsymbol{B}_{0}[\\boldsymbol{I}_K-\\boldsymbol{X}^{\\top}\\boldsymbol{I}_N\\boldsymbol{X}(\\boldsymbol{B}_0^{-1}+\\boldsymbol{X}^{\\top}\\boldsymbol{I}_N\\boldsymbol{X})^{-1}]\\boldsymbol{X}^{\\top}\\\\ &amp;=\\boldsymbol{B}_{0}[\\boldsymbol{I}_K-[\\boldsymbol{I}_K-\\boldsymbol{B}_0^{-1}(\\boldsymbol{B}_0^{-1}+\\boldsymbol{X}^{\\top}\\boldsymbol{I}_N\\boldsymbol{X})^{-1}]]\\boldsymbol{X}^{\\top}\\\\ &amp;=(\\boldsymbol{B}_0^{-1}+\\boldsymbol{X}^{\\top}\\boldsymbol{X})^{-1}\\boldsymbol{X}^{\\top}, \\end{align*}\\] where the first equality uses the Woodbury matrix identity (matrix inversion lemma), and the third equality uses \\(\\boldsymbol{D}(\\boldsymbol{D}+\\boldsymbol{E})^{-1}=\\boldsymbol{I}-\\boldsymbol{E}(\\boldsymbol{D}+\\boldsymbol{E})^{-1}\\). Thus, \\([\\boldsymbol{I}_K-\\boldsymbol{B}_{0}\\boldsymbol{X}^{\\top}(\\boldsymbol{X}\\boldsymbol{B}_{0}\\boldsymbol{X}^{\\top}+ \\boldsymbol{I}_N)^{-1}\\boldsymbol{X}]\\boldsymbol{\\beta}_{0}+\\boldsymbol{B}_{0}\\boldsymbol{X}^{\\top}(\\boldsymbol{X}\\boldsymbol{B}_{0}\\boldsymbol{X}^{\\top}+ \\boldsymbol{I}_N)^{-1}\\boldsymbol{y}=[\\boldsymbol{I}_K-(\\boldsymbol{B}_0^{-1}+\\boldsymbol{X}^{\\top}\\boldsymbol{X})^{-1}\\boldsymbol{X}^{\\top}\\boldsymbol{X}]\\boldsymbol{\\beta}_{0}+(\\boldsymbol{B}_0^{-1}+\\boldsymbol{X}^{\\top}\\boldsymbol{X})^{-1}\\boldsymbol{X}^{\\top}\\boldsymbol{y}=[\\boldsymbol{I}_K-(\\boldsymbol{B}_0^{-1}+\\boldsymbol{X}^{\\top}\\boldsymbol{X})^{-1}\\boldsymbol{X}^{\\top}\\boldsymbol{X}]\\boldsymbol{\\beta}_{0}+(\\boldsymbol{B}_0^{-1}+\\boldsymbol{X}^{\\top}\\boldsymbol{X})^{-1}\\boldsymbol{X}^{\\top}\\boldsymbol{X}\\hat{\\boldsymbol{\\beta}}\\). Again, we see that the posterior mean is a weighted average between the prior mean, and the maximum likelihood estimator. The equality of variances of both approaches is as follows: \\[\\begin{align*} Var[\\boldsymbol{\\beta}\\mid \\boldsymbol{y}]&amp; = \\sigma^2(\\boldsymbol{B}_{0}-\\boldsymbol{B}_{0}\\boldsymbol{X}^{\\top}(\\boldsymbol{X}\\boldsymbol{B}_{0}\\boldsymbol{X}^\\top+\\boldsymbol{I}_N)^{-1} \\boldsymbol{X}\\boldsymbol{B}_{0})\\\\ &amp;=\\sigma^2(\\boldsymbol{B}_{0}-\\boldsymbol{B}_{0}\\boldsymbol{X}^{\\top}(\\boldsymbol{I}_N- \\boldsymbol{I}_N\\boldsymbol{X}(\\boldsymbol{B}_{0}^{-1}+\\boldsymbol{X}^{\\top}\\boldsymbol{I}_N\\boldsymbol{X})^{-1}\\boldsymbol{X}^{\\top}\\boldsymbol{I}_N)\\boldsymbol{X}\\boldsymbol{B}_{0})\\\\ &amp;=\\sigma^2(\\boldsymbol{B}_{0}-\\boldsymbol{B}_{0}\\boldsymbol{X}^{\\top}\\boldsymbol{X}\\boldsymbol{B}_{0}+ \\boldsymbol{B}_{0}\\boldsymbol{X}^{\\top}\\boldsymbol{X}(\\boldsymbol{B}_{0}^{-1}+\\boldsymbol{X}^{\\top}\\boldsymbol{X})^{-1}\\boldsymbol{X}^{\\top}\\boldsymbol{X}\\boldsymbol{B}_{0})\\\\ &amp;=\\sigma^2(\\boldsymbol{B}_{0}-\\boldsymbol{B}_{0}\\boldsymbol{X}^{\\top}\\boldsymbol{X}\\boldsymbol{B}_{0}+ \\boldsymbol{B}_{0}\\boldsymbol{X}^{\\top}\\boldsymbol{X}[\\boldsymbol{I}_K-(\\boldsymbol{B}_{0}^{-1}+\\boldsymbol{X}^{\\top}\\boldsymbol{X})^{-1}\\boldsymbol{B}_{0}^{-1}]\\boldsymbol{B}_{0})\\\\ &amp;=\\sigma^2(\\boldsymbol{B}_{0}-\\boldsymbol{B}_{0}\\boldsymbol{X}^{\\top}\\boldsymbol{X}(\\boldsymbol{B}_{0}^{-1}+\\boldsymbol{X}^{\\top}\\boldsymbol{X})^{-1})\\\\ &amp;=\\sigma^2(\\boldsymbol{B}_{0}[\\boldsymbol{I}_K-\\boldsymbol{X}^{\\top}\\boldsymbol{X}(\\boldsymbol{B}_{0}^{-1}+\\boldsymbol{X}^{\\top}\\boldsymbol{X})^{-1}])\\\\ &amp;=\\sigma^2(\\boldsymbol{B}_{0}[\\boldsymbol{I}_K-(\\boldsymbol{I}_K-\\boldsymbol{B}_{0}^{-1}(\\boldsymbol{B}_{0}^{-1}+\\boldsymbol{X}^{\\top}\\boldsymbol{X})^{-1})])\\\\ &amp;=\\sigma^2(\\boldsymbol{B}_{0}^{-1}+\\boldsymbol{X}^{\\top}\\boldsymbol{X})^{-1}, \\end{align*}\\] where the second equality uses the Woodbury matrix identity, the fourth equality uses \\((\\boldsymbol{D}+\\boldsymbol{E})^{-1}\\boldsymbol{D}=\\boldsymbol{I}-(\\boldsymbol{D}+\\boldsymbol{E})^{-1}\\boldsymbol{E}\\), and the seventh equality uses \\(\\boldsymbol{D}(\\boldsymbol{D}+\\boldsymbol{E})^{-1}=\\boldsymbol{I}-\\boldsymbol{E}(\\boldsymbol{D}+\\boldsymbol{E})^{-1}\\). Now, we calculate the posterior marginal distribution of \\(\\boldsymbol{\\beta}\\) following the standard approach, \\[\\begin{align*} \\pi(\\boldsymbol{\\beta}\\mid {\\boldsymbol{y}},{\\boldsymbol{X}}) &amp; = \\int_0^{\\infty} \\pi(\\boldsymbol{\\beta}, \\sigma^2\\mid {\\boldsymbol{y}},{\\boldsymbol{X}}) d\\sigma^2 \\\\ &amp; = \\int_0^{\\infty} \\left(\\frac{1}{\\sigma^2}\\right)^{\\frac{\\alpha_n+K}{2} + 1} \\exp \\left\\{-\\frac{s}{2\\sigma^2}\\right\\} d\\sigma^2, \\end{align*}\\] where \\(s = \\delta_n + (\\boldsymbol{\\beta} - \\boldsymbol{\\beta}_n)^{\\top}{{\\boldsymbol{B}}}_n^{-1}(\\boldsymbol{\\beta} - \\boldsymbol{\\beta}_n)\\). Then we can write \\[\\begin{align*} \\pi(\\boldsymbol{\\beta}\\mid {\\boldsymbol{y}},{\\boldsymbol{X}}) &amp; = \\int_0^{\\infty} \\left(\\frac{1}{\\sigma^2}\\right)^{\\frac{\\alpha_n+K}{2} + 1} \\exp \\left\\{-\\frac{s}{2\\sigma^2}\\right\\} d\\sigma^2 \\\\ &amp; = \\frac{\\Gamma((\\alpha_n+K)/2)}{(s/2)^{(\\alpha_n+K)/2}} \\int_0^{\\infty} \\frac{(s/2)^{(\\alpha_n+K)/2}}{\\Gamma((\\alpha_n+K)/2)} (\\sigma^2)^{-(\\alpha_n+K)/2 - 1} \\exp \\left\\{-\\frac{s}{2\\sigma^2}\\right\\} d\\sigma^2. \\end{align*}\\] The right term is the integral of the probability density function of an inverse gamma distribution with parameters \\(\\nu = (\\alpha_n+K)/2\\) and \\(\\tau = s/2\\). Since we are integrating over the whole support of \\(\\sigma^2\\), the integral is equal to 1, and therefore \\[\\begin{align*} \\pi(\\boldsymbol{\\beta}\\mid {\\boldsymbol{y}},{\\boldsymbol{X}}) &amp; = \\frac{\\Gamma((\\alpha_n+K)/2)}{(s/2)^{(\\alpha_n+K)/2}} \\\\ &amp; \\propto s^{-(\\alpha_n+K)/2} \\\\ &amp; = [\\delta_n + (\\boldsymbol{\\beta} - \\boldsymbol{\\beta}_n)^{\\top}{{\\boldsymbol{B}}}_n^{-1}(\\boldsymbol{\\beta} - \\boldsymbol{\\beta}_n)]^{-(\\alpha_n+K)/2} \\\\ &amp; = \\left[1 + \\frac{(\\boldsymbol{\\beta} - \\boldsymbol{\\beta}_n)^{\\top}\\left(\\frac{\\delta_n}{\\alpha_n}{{\\boldsymbol{B}}}_n\\right)^{-1}(\\boldsymbol{\\beta} - \\boldsymbol{\\beta}_n)}{\\alpha_n}\\right]^{-(\\alpha_n+K)/2}(\\delta_n)^{-(\\alpha_N+K)/2} \\\\ &amp; \\propto \\left[1 + \\frac{(\\boldsymbol{\\beta} - \\boldsymbol{\\beta}_n)^{\\top}{\\boldsymbol{H}}_n^{-1}(\\boldsymbol{\\beta} - \\boldsymbol{\\beta}_n)}{\\alpha_n}\\right]^{-(\\alpha_n+K)/2}, \\end{align*}\\] where \\({\\boldsymbol{H}}_n = \\frac{\\delta_n}{\\alpha_n}{\\boldsymbol{B}}_n\\). This last expression is a multivariate t distribution for \\(\\boldsymbol{\\beta}\\), \\(\\boldsymbol{\\beta}\\mid {\\boldsymbol{y}},{\\boldsymbol{X}} \\sim t_K(\\alpha_n, \\boldsymbol{\\beta}_n, {\\boldsymbol{H}}_n)\\). Observe that as we have incorporated the uncertainty of the variance, the posterior for \\(\\boldsymbol{\\beta}\\) changes from a normal to a t distribution, which has heavier tails, indicating more uncertainty. The marginal likelihood of this model is \\[\\begin{align*} p({\\boldsymbol{y}})=\\int_0^{\\infty}\\int_{R^K}\\pi (\\boldsymbol{\\beta} \\mid \\sigma^2,{\\boldsymbol{B}}_0,\\boldsymbol{\\beta}_0 )\\pi(\\sigma^2\\mid \\alpha_0/2, \\delta_0/2)p({\\boldsymbol{y}}\\mid \\boldsymbol{\\beta}, \\sigma^2, {\\boldsymbol{X}})d\\sigma^2 d\\boldsymbol{\\beta}. \\end{align*}\\] Taking into account that \\(({\\boldsymbol{y}}-{\\boldsymbol{X}}\\boldsymbol{\\beta})^{\\top}({\\boldsymbol{y}}-{\\boldsymbol{X}}\\boldsymbol{\\beta})+(\\boldsymbol{\\beta}-\\boldsymbol{\\beta}_0)^{\\top}{\\boldsymbol{B}}_0^{-1}(\\boldsymbol{\\beta}-\\boldsymbol{\\beta}_0)=(\\boldsymbol{\\beta}-\\boldsymbol{\\beta}_n)^{\\top}{\\boldsymbol{B}}_n^{-1}(\\boldsymbol{\\beta}-\\boldsymbol{\\beta}_n)+m\\), where \\(m={\\boldsymbol{y}}^{\\top}{\\boldsymbol{y}}+\\boldsymbol{\\beta}_0^{\\top}{\\boldsymbol{B}}_0^{-1}\\boldsymbol{\\beta}_0-\\boldsymbol{\\beta}_n^{\\top}{\\boldsymbol{B}}_n^{-1}\\boldsymbol{\\beta}_n\\), we have that \\[\\begin{align*} p({\\boldsymbol{y}})&amp;=\\int_0^{\\infty}\\int_{R^K}\\pi (\\boldsymbol{\\beta} \\mid \\sigma^2)\\pi(\\sigma^2)p({\\boldsymbol{y}}\\mid \\boldsymbol{\\beta}, \\sigma^2, {\\boldsymbol{X}})d\\sigma^2 d\\boldsymbol{\\beta}\\\\ &amp;=\\int_0^{\\infty}\\pi(\\sigma^2) \\frac{1}{(2\\pi\\sigma^2)^{N/2}}\\exp\\left\\{-\\frac{1}{2\\sigma^2}m \\right\\} \\frac{1}{(2\\pi\\sigma^2)^{K/2}|{\\boldsymbol{B}}_0|^{1/2}}\\\\ &amp;\\times\\int_{R^K}\\exp\\left\\{-\\frac{1}{2\\sigma^2}(\\boldsymbol{\\beta}-\\boldsymbol{\\beta}_n)^{\\top}{\\boldsymbol{B}}_n^{-1}(\\boldsymbol{\\beta}-\\boldsymbol{\\beta}_n)\\right\\}d\\sigma^2 d\\boldsymbol{\\beta}\\\\ &amp;=\\int_0^{\\infty}\\pi(\\sigma^2) \\frac{1}{(2\\pi\\sigma^2)^{N/2}}\\exp\\left\\{-\\frac{1}{2\\sigma^2}m \\right\\} \\frac{|{\\boldsymbol{B}}_n|^{1/2}}{|{\\boldsymbol{B}}_0|^{1/2}}d\\sigma^2\\\\ &amp;=\\int_{0}^{\\infty} \\frac{(\\delta_0/2)^{\\alpha_0/2}}{\\Gamma(\\alpha_0/2)}\\left(\\frac{1}{\\sigma^2}\\right)^{\\alpha_0/2+1}\\exp\\left\\{\\left(-\\frac{\\delta_0}{2\\sigma^2}\\right)\\right\\} \\frac{1}{(2\\pi\\sigma^2)^{N/2}}\\exp\\left\\{-\\frac{1}{2\\sigma^2}m \\right\\} \\frac{|{\\boldsymbol{B}}_n|^{1/2}}{|{\\boldsymbol{B}}_0|^{1/2}} d\\sigma^2\\\\ &amp;= \\frac{1}{(2\\pi)^{N/2}}\\frac{(\\delta_0/2)^{\\alpha_0/2}}{\\Gamma(\\alpha_0/2)}\\frac{|{\\boldsymbol{B}}_n|^{1/2}}{|{\\boldsymbol{B}}_0|^{1/2}}\\int_{0}^{\\infty}\\left(\\frac{1}{\\sigma^2}\\right)^{\\frac{\\alpha_0+N}{2}+1}\\exp\\left\\{\\left(-\\frac{\\delta_0+m}{2\\sigma^2}\\right)\\right\\}d\\sigma^2\\\\ &amp;= \\frac{1}{\\pi^{N/2}}\\frac{\\delta_0^{\\alpha_0/2}}{\\delta_n^{\\alpha_n/2}}\\frac{|{\\boldsymbol{B}}_n|^{1/2}}{|{\\boldsymbol{B}}_0|^{1/2}}\\frac{\\Gamma(\\alpha_n/2)}{\\Gamma(\\alpha_0/2)}. \\end{align*}\\] We can show that \\(\\delta_n=\\delta_0 + {\\boldsymbol{y}}^{\\top}{\\boldsymbol{y}} + \\boldsymbol{\\beta}_0^{\\top}{\\boldsymbol{B}}_0^{-1}\\boldsymbol{\\beta}_0 - \\boldsymbol{\\beta}_n^{\\top}{\\boldsymbol{B}}_n^{-1}\\boldsymbol{\\beta}_n=\\delta_0+({\\boldsymbol{y}}-{\\boldsymbol{X}}\\hat{\\boldsymbol{\\beta}})^{\\top}({\\boldsymbol{y}}-{\\boldsymbol{X}}\\hat{\\boldsymbol{\\beta}})+(\\hat{\\boldsymbol{\\beta}}-\\boldsymbol{\\beta}_0)^{\\top}(({\\boldsymbol{X}}^{\\top}{\\boldsymbol{X}})^{-1}+{\\boldsymbol{B}}_0)^{-1}(\\hat{\\boldsymbol{\\beta}}-\\boldsymbol{\\beta}_0)\\) (see Exercise 7). Therefore, if we want to compare two models under this setting, the Bayes factor is \\[\\begin{align*} BF_{12}&amp;=\\frac{p(\\boldsymbol{y}\\mid \\mathcal{M}_1)}{p(\\boldsymbol{y}\\mid \\mathcal{M}_2)}\\\\ &amp;=\\frac{\\frac{\\delta_{10}^{\\alpha_{10}/2}}{\\delta_{1n}^{\\alpha_{1n}/2}}\\frac{|{\\boldsymbol{B}}_{1n}|^{1/2}}{|{\\boldsymbol{B}}_{10}|^{1/2}}\\frac{\\Gamma(\\alpha_{1n}/2)}{\\Gamma(\\alpha_{10}/2)}}{\\frac{\\delta_{20}^{\\alpha_{20}/2}}{\\delta_{2n}^{\\alpha_{2n}/2}}\\frac{|{\\boldsymbol{B}}_{2n}|^{1/2}}{|{\\boldsymbol{B}}_{20}|^{1/2}}\\frac{\\Gamma(\\alpha_{2n}/2)}{\\Gamma(\\alpha_{20}/2)}}, \\end{align*}\\] where subscripts 1 and 2 refer to each model. Observe that, ceteris paribus, the model with better fit, coherence between sample and prior information regarding location parameters, higher prior to posterior precision, and fewer parameters is favored by the Bayes factor. The Bayes factor rewards model fit, as the sum of squared errors appears in \\(\\delta_n\\); the better the fit (i.e., the lower the sum of squared errors), the better the Bayes factor. In addition, a weighted distance between sample and prior location parameters also appears in \\(\\delta_n\\). The greater this distance, the worse the model support. The ratio of determinants between posterior and prior covariance matrices is also present; the higher this ratio, the better the Bayes factor supports a model due to information gains. To see the effect of a model’s parsimony, let’s consider the common situation in applications where \\(\\boldsymbol{B}_{j0} = c \\boldsymbol{I}_{K_j}\\), then \\(| \\boldsymbol{B}_{j0} | = c^{K_j}\\). Hence, \\[ \\left( \\frac{| \\boldsymbol{B}_{20} |}{| \\boldsymbol{B}_{10} |} \\right)^{1/2} = \\left( \\frac{c^{K_2/2}}{c^{K_1/2}} \\right), \\] if \\(\\frac{K_2}{K_1} &gt; 1\\) and \\(c \\to \\infty\\) (the latter implying a non-informative prior), then \\(BF_{12} \\to \\infty\\). This means infinite evidence supporting the parsimonious model, no matter what the sample information says. Comparing models having the same number of regressors (\\(K_1 = K_2\\)) is not a safe ground, as \\(| \\boldsymbol{B}_0 |\\) depends on the measurement units of the regressors. Conclusions regarding model selection depend on this, which is not a nice property. This prevents using non-informative priors when performing model selection in the Bayesian framework. However, this is not the case when \\(\\alpha_0 \\to 0\\) and \\(\\delta_0 \\to 0\\), which implies a non-informative prior for the variance parameter.22 We observe that \\(\\Gamma(\\alpha_{j0})\\) cancels out, \\(\\alpha_{jn} \\to N\\), and \\[ \\delta_{jn} \\to ({\\boldsymbol{y}} - {\\boldsymbol{X}}_j \\hat{\\boldsymbol{\\beta}}_j)^{\\top} ({\\boldsymbol{y}} - {\\boldsymbol{X}}_j \\hat{\\boldsymbol{\\beta}}_j) + (\\hat{\\boldsymbol{\\beta}}_j - \\boldsymbol{\\beta}_{j0})^{\\top} \\left( ({\\boldsymbol{X}}_j^{\\top} {\\boldsymbol{X}}_j)^{-1} + \\boldsymbol{B}_{j0} \\right)^{-1} (\\hat{\\boldsymbol{\\beta}}_j - \\boldsymbol{\\beta}_{j0}), \\] therefore, there is no effect. This is due to \\(\\sigma^2\\) being a common parameter in both models. In general, we can use non-informative priors for common parameters across all models, but we cannot use non-informative priors for non-common parameters when performing model selection using the Bayes factor. This issue raises the question of how to set informative priors. On one hand, we have those who advocate for subjective priors (Ramsey 1926; Finetti 1937; Savage 1954; D. V. Lindley 2000); on the other hand, those who prefer objective priors (T. Bayes 1763; P. Laplace 1812; H. Jeffreys 1961; J. Berger 2006). Regarding the former, eliciting subjective priors, i.e., “formulating a person’s knowledge and beliefs about one or more uncertain quantities into a (joint) probability distribution for those quantities” (Garthwaite, Kadane, and O’Hagan 2005), is a very difficult task due to human beings’ heuristics and biases associated with representativeness, information availability, conservatism, overconfidence, and anchoring-and-adjustment issues (Tversky and Kahneman 1974). However, there have been good efforts using predictive and structural elicitation procedures (J. B. Kadane 1980; J. Kadane and Wolfson 1998). Regarding the latter, there are reference priors that are designed to have minimal impact on the posterior distribution and to be invariant to different parametrizations of the model (J. M. Bernardo and Smith 2009). A remarkable example of reference priors is the Jeffreys’ prior (Harold Jeffreys 1946), which originated from the critique of non-informative priors that were not invariant to transformations of the parameter space. In particular, the Jeffreys’ prior is given by: \\[ \\pi(\\boldsymbol{\\theta}) \\propto |I(\\boldsymbol{\\theta})|^{1/2}, \\] where \\(I(\\boldsymbol{\\theta}) = \\mathbb{E}\\left(-\\frac{\\partial^2 \\log p(\\boldsymbol{y} \\mid \\boldsymbol{\\theta})}{\\partial \\boldsymbol{\\theta} \\partial \\boldsymbol{\\theta}^{\\top}}\\right)\\), i.e., \\(I(\\boldsymbol{\\theta})\\) is the Fisher information matrix. However, the Jeffreys’ prior is often improper, meaning it does not work well for model selection. Thus, a standard objective approach is to use intrinsic priors (J. O. Berger and Pericchi 1996), where a minimal training dataset is used with a reference prior to obtain a proper posterior distribution. This proper distribution is then used as a prior, and the standard Bayesian procedures are followed using the remaining dataset. In this way, we end up with meaningful Bayes factors for model selection. Regardless of using a subjective or objective approach to define a prior distribution, it is always a good idea to assess the sensitivity of the posterior results to the prior assumptions. This is commonly done using local or pointwise assessments, such as partial derivatives (Giordano et al. 2022; Jacobi, Zhu, and Joshi 2022; Gustafson 2000) or, more often, in terms of multiple evaluations (scenario analysis) (Richardson and Green 1997; Kim and Nelson 1999; An and Schorfheide 2007). Recently, Jacobi et al. (2024) extend these approaches to perform sensitivity analysis in high-dimensional hyperparameter settings. Returning to the linear model, the posterior predictive is equal to \\[\\begin{align*} \\pi({\\boldsymbol{y}}_0\\mid {\\boldsymbol{y}})&amp;=\\int_{0}^{\\infty}\\int_{R^K}p({\\boldsymbol{Y}}_0\\mid \\boldsymbol{\\beta},\\sigma^2,{\\boldsymbol{y}})\\pi(\\boldsymbol{\\beta}\\mid \\sigma^2,{\\boldsymbol{y}})\\pi(\\sigma^2\\mid {\\boldsymbol{y}})d\\boldsymbol{\\beta} d\\sigma^2\\\\ &amp;=\\int_{0}^{\\infty}\\int_{R^K}p({\\boldsymbol{Y}}_0\\mid \\boldsymbol{\\beta},\\sigma^2)\\pi(\\boldsymbol{\\beta}\\mid \\sigma^2,{\\boldsymbol{y}})\\pi(\\sigma^2\\mid {\\boldsymbol{y}})d\\boldsymbol{\\beta} d\\sigma^2, \\end{align*}\\] where we take into account independence between \\({\\boldsymbol{y}}_0\\) and \\({\\boldsymbol{y}}\\). Given \\({\\boldsymbol{X}}_0\\), which is the \\(N_0\\times K\\) matrix of regressors associated with \\({\\boldsymbol{y}}_0\\), Then, \\[\\begin{align*} \\pi({\\boldsymbol{y}}_0\\mid {\\boldsymbol{y}})&amp;=\\int_{0}^{\\infty}\\int_{R^K}\\left\\{ (2\\pi\\sigma^2)^{-\\frac{N_0}{2}} \\exp \\left\\{-\\frac{1}{2\\sigma^2} ({\\boldsymbol{y}}_0 - {\\boldsymbol{X}}_0\\boldsymbol{\\beta})^{\\top}({\\boldsymbol{y}}_0 - {\\boldsymbol{X}}_0\\boldsymbol{\\beta})^{\\top} \\right\\}\\right. \\\\ &amp; \\times (2\\pi\\sigma^2)^{-\\frac{K}{2}} |{\\boldsymbol{B}}_n|^{-1/2} \\exp \\left\\{-\\frac{1}{2\\sigma^2} (\\boldsymbol{\\beta} - \\boldsymbol{\\beta}_n)^{\\top}{\\boldsymbol{B}}_n^{-1}(\\boldsymbol{\\beta} - \\boldsymbol{\\beta}_n)\\right\\} \\\\ &amp; \\left. \\times \\frac{(\\delta_n/2)^{\\alpha_n/2}}{\\Gamma(\\alpha_n/2)}\\left(\\frac{1}{\\sigma^2}\\right)^{\\alpha_n/2+1}\\exp \\left\\{-\\frac{\\delta_n}{2\\sigma^2} \\right\\}\\right\\}d\\boldsymbol{\\beta} d\\sigma^2. \\\\ \\end{align*}\\] Setting \\({\\boldsymbol{M}}=({\\boldsymbol{X}}_0^{\\top}{\\boldsymbol{X}}_0+{\\boldsymbol{B}}_n^{-1})\\) and \\(\\boldsymbol{\\beta}_*={\\boldsymbol{M}}^{-1}({\\boldsymbol{B}}_n^{-1}\\boldsymbol{\\beta}_n+{\\boldsymbol{X}}_0^{\\top}{\\boldsymbol{y}}_0)\\), we have \\(({\\boldsymbol{y}}_0 - {\\boldsymbol{X}}_0\\boldsymbol{\\beta})^{\\top}({\\boldsymbol{y}}_0 - {\\boldsymbol{X}}_0\\boldsymbol{\\beta})^{\\top}+(\\boldsymbol{\\beta} - \\boldsymbol{\\beta}_n)^{\\top}{\\boldsymbol{B}}_n^{-1}(\\boldsymbol{\\beta} - \\boldsymbol{\\beta}_n)=(\\boldsymbol{\\beta} - \\boldsymbol{\\beta}_*)^{\\top}{\\boldsymbol{M}}(\\boldsymbol{\\beta} - \\boldsymbol{\\beta}_*)+\\boldsymbol{\\beta}_n^{\\top}{\\boldsymbol{B}}_n^{-1}\\boldsymbol{\\beta}_n+{\\boldsymbol{y}}_0^{\\top}{\\boldsymbol{y}}_0-\\boldsymbol{\\beta}_*^{\\top}{\\boldsymbol{M}}\\boldsymbol{\\beta}_*\\). Thus, \\[\\begin{align*} \\pi({\\boldsymbol{y}}_0\\mid {\\boldsymbol{y}})&amp;\\propto\\int_{0}^{\\infty}\\left\\{\\left(\\frac{1}{\\sigma^2}\\right)^{-\\frac{K+N_0+\\alpha_n}{2}+1}\\exp\\left\\{-\\frac{1}{2\\sigma^2}(\\boldsymbol{\\beta}_n^{\\top}{\\boldsymbol{B}}_n^{-1}\\boldsymbol{\\beta}_n+{\\boldsymbol{y}}_0^{\\top}{\\boldsymbol{y}}_0-\\boldsymbol{\\beta}_*^{\\top}{\\boldsymbol{M}}\\boldsymbol{\\beta}_*+\\delta_n)\\right\\}\\right.\\\\ &amp;\\times\\left.\\int_{R^K}\\exp\\left\\{-\\frac{1}{2\\sigma^2}(\\boldsymbol{\\beta} - \\boldsymbol{\\beta}_*)^{\\top}{\\boldsymbol{M}}(\\boldsymbol{\\beta} - \\boldsymbol{\\beta}_*)\\right\\}d\\boldsymbol{\\beta}\\right\\} d\\sigma^2,\\\\ \\end{align*}\\] where the term in the second integral is the kernel of a multivariate normal density with mean \\(\\boldsymbol{\\beta}_*\\) and covariance matrix \\(\\sigma^2{\\boldsymbol{M}}^{-1}\\). Then, \\[\\begin{align*} \\pi({\\boldsymbol{y}}_0\\mid {\\boldsymbol{y}})&amp;\\propto\\int_{0}^{\\infty}\\left(\\frac{1}{\\sigma^2}\\right)^{\\frac{N_0+\\alpha_n}{2}+1}\\exp\\left\\{-\\frac{1}{2\\sigma^2}(\\boldsymbol{\\beta}_n^{\\top}{\\boldsymbol{B}}_n^{-1}\\boldsymbol{\\beta}_n+{\\boldsymbol{y}}_0^{\\top}{\\boldsymbol{y}}_0-\\boldsymbol{\\beta}_*^{\\top}{\\boldsymbol{M}}\\boldsymbol{\\beta}_*+\\delta_n)\\right\\}d\\sigma^2,\\\\ \\end{align*}\\] which is the kernel of an inverse gamma density. Thus, \\[\\begin{align*} \\pi({\\boldsymbol{y}}_0\\mid {\\boldsymbol{y}})&amp;\\propto \\left[\\frac{\\boldsymbol{\\beta}_n^{\\top}{\\boldsymbol{B}}_n^{-1}\\boldsymbol{\\beta}_n+{\\boldsymbol{y}}_0^{\\top}{\\boldsymbol{y}}_0-\\boldsymbol{\\beta}_*^{\\top}{\\boldsymbol{M}}\\boldsymbol{\\beta}_*+\\delta_n}{2}\\right]^{-\\frac{\\alpha_n+N_0}{2}}. \\end{align*}\\] Setting \\({\\boldsymbol{C}}^{-1}={\\boldsymbol{I}}_{N_0}+{\\boldsymbol{X}}_0{\\boldsymbol{B}}_n{\\boldsymbol{X}}_0^{\\top}\\) such that \\({\\boldsymbol{C}}={\\boldsymbol{I}}_{N_0}-{\\boldsymbol{X}}_0({\\boldsymbol{B}}_n^{-1}+{\\boldsymbol{X}}_0^{\\top}{\\boldsymbol{X}}_0)^{-1}{\\boldsymbol{X}}_0^{\\top}={\\boldsymbol{I}}_{N_0}-{\\boldsymbol{X}}_0{\\boldsymbol{M}}^{-1}{\\boldsymbol{X}}_0^{\\top}\\), and \\({\\boldsymbol{\\boldsymbol{\\beta}}}_{**}={\\boldsymbol{C}}^{-1}{\\boldsymbol{X}}_0{\\boldsymbol{M}}^{-1}{\\boldsymbol{B}}_n^{-1}\\boldsymbol{\\beta}_n\\), then \\[\\begin{align*} \\boldsymbol{\\beta}_n^{\\top}{\\boldsymbol{B}}_n^{-1}\\boldsymbol{\\beta}_n+{\\boldsymbol{y}}_0^{\\top}{\\boldsymbol{y}}_0-\\boldsymbol{\\beta}_*^{\\top}{\\boldsymbol{M}}\\boldsymbol{\\beta}_*&amp;= \\boldsymbol{\\beta}_n^{\\top}{\\boldsymbol{B}}_n^{-1}\\boldsymbol{\\beta}_n+{\\boldsymbol{y}}_0^{\\top}{\\boldsymbol{y}}_0-(\\boldsymbol{\\beta}_n^{\\top}{\\boldsymbol{B}}_n^{-1}+{\\boldsymbol{y}}_0^{\\top}{\\boldsymbol{X}}_0){\\boldsymbol{M}}^{-1}({\\boldsymbol{B}}_n^{-1}\\boldsymbol{\\beta}_n+{\\boldsymbol{X}}_0^{\\top}{\\boldsymbol{y}}_0)\\\\ &amp;=\\boldsymbol{\\beta}_n^{\\top}({\\boldsymbol{B}}_n^{-1}-{\\boldsymbol{B}}_n^{-1}{\\boldsymbol{M}}^{-1}{\\boldsymbol{B}}_n^{-1})\\boldsymbol{\\beta}_n+{\\boldsymbol{y}}_0^{\\top}{\\boldsymbol{C}}{\\boldsymbol{y}}_0\\\\ &amp;-2{\\boldsymbol{y}}_0^{\\top}{\\boldsymbol{C}}{\\boldsymbol{C}}^{-1}{\\boldsymbol{X}}_0{\\boldsymbol{M}}^{-1}{\\boldsymbol{B}}_n^{-1}\\boldsymbol{\\beta}_n+{\\boldsymbol{\\boldsymbol{\\beta}}}_{**}^{\\top}{\\boldsymbol{C}}{\\boldsymbol{\\boldsymbol{\\beta}}}_{**}-{\\boldsymbol{\\boldsymbol{\\beta}}}_{**}^{\\top}{\\boldsymbol{C}}{\\boldsymbol{\\boldsymbol{\\beta}}}_{**}\\\\ &amp;=\\boldsymbol{\\beta}_n^{\\top}({\\boldsymbol{B}}_n^{-1}-{\\boldsymbol{B}}_n^{-1}{\\boldsymbol{M}}^{-1}{\\boldsymbol{B}}_n^{-1})\\boldsymbol{\\beta}_n+({\\boldsymbol{y}}_0-{\\boldsymbol{\\boldsymbol{\\beta}}}_{**})^{\\top}{\\boldsymbol{C}}({\\boldsymbol{y}}_0-{\\boldsymbol{\\boldsymbol{\\beta}}}_{**})\\\\ &amp;-{\\boldsymbol{\\boldsymbol{\\beta}}}_{**}^{\\top}{\\boldsymbol{C}}{\\boldsymbol{\\boldsymbol{\\beta}}}_{**}, \\end{align*}\\] where \\(\\boldsymbol{\\beta}_n^{\\top}({\\boldsymbol{B}}_n^{-1}-{\\boldsymbol{B}}_n^{-1}{\\boldsymbol{M}}^{-1}{\\boldsymbol{B}}_n^{-1})\\boldsymbol{\\beta}_n={\\boldsymbol{\\boldsymbol{\\beta}}}_{**}^{\\top}{\\boldsymbol{C}}{\\boldsymbol{\\boldsymbol{\\beta}}}_{**}\\) and \\(\\boldsymbol{\\beta}_{**}={\\boldsymbol{X}}_0\\boldsymbol{\\beta}_n\\) (see Exercise 8). Then, \\[\\begin{align*} \\pi({\\boldsymbol{y}}_0\\mid {\\boldsymbol{y}})&amp;\\propto\\left[\\frac{({\\boldsymbol{y}}_0-{\\boldsymbol{X}}_0\\boldsymbol{\\beta}_n)^{\\top}{\\boldsymbol{C}}({\\boldsymbol{y}}_0-{\\boldsymbol{X}}_0\\boldsymbol{\\beta}_n)+\\delta_n}{2}\\right]^{-\\frac{\\alpha_n+N_0}{2}}\\\\ &amp;\\propto\\left[\\frac{({\\boldsymbol{y}}_0-{\\boldsymbol{X}}_0\\boldsymbol{\\beta}_n)^{\\top}\\left(\\frac{{\\boldsymbol{C}}\\alpha_n}{\\delta_n}\\right)({\\boldsymbol{y}}_0-{\\boldsymbol{X}}_0\\boldsymbol{\\beta}_n)}{\\alpha_n}+1\\right]^{-\\frac{\\alpha_n+N_0}{2}}. \\end{align*}\\] The posterior predictive is a multivariate t distribution, \\({\\boldsymbol{y}}_0\\mid {\\boldsymbol{y}}\\sim t\\left({\\boldsymbol{X}}_0\\boldsymbol{\\beta}_n,\\frac{\\delta_n({\\boldsymbol{I}}_{N_0}+{\\boldsymbol{X}}_0{\\boldsymbol{B}}_n{\\boldsymbol{X}}_0^{\\top})}{\\alpha_n},\\alpha_n\\right)\\) centered at \\({\\boldsymbol{X}}_0\\boldsymbol{\\beta}_n\\). Example: Demand of electricity We study in this example the determinants of the monthly demand for electricity by Colombian households. The data consists of information from 2103 households, including the following variables: the average price (USD/kWh), indicators of the socioeconomic conditions of the neighborhood where the household is located (with IndSocio1 being the lowest and IndSocio3 being the highest), an indicator for whether the household is located in a municipality that is above 1000 meters above sea level, the number of rooms in the house, the number of members in the household, the presence of children in the household (where 1 indicates yes), and the monthly income (USD). The specification is as follows: \\[\\begin{align*} \\log(\\text{Electricity}_i) &amp; = \\beta_1\\log(\\text{price}_i) + \\beta_2\\text{IndSocio1}_i + \\beta_3\\text{IndSocio2}_i + \\beta_4\\text{Altitude}_i \\\\ &amp; + \\beta_5\\text{Nrooms}_i + \\beta_6\\text{HouseholdMem}_i + \\beta_7\\text{Children}_i\\\\ &amp; + \\beta_8\\log(\\text{Income}_i) + \\beta_9 + \\mu. \\end{align*}\\] We use a non-informative vague prior setting such that \\(\\alpha_0=\\delta_0=0.001\\), \\(\\boldsymbol{\\beta}_0=\\boldsymbol{0}\\) and \\(\\boldsymbol{B}_0=c_0\\boldsymbol{I}_k\\), where \\(c_0=1000\\) and \\(k\\) is the number of regressors. The results from the R code (see below) indicate that the posterior mean of the own-price elasticity of electricity demand is -1.09, and the 95% symmetric credible interval is (-1.47, -0.71). Households in neighborhoods with low socioeconomic conditions and those located in municipalities situated more than 1000 meters above sea level consume less electricity, with reductions of 32.7% and 19.7% on average, respectively. An additional room leads to an 8.7% increase in electricity consumption, and each additional household member increases consumption by 5.9% on average. The mean estimate for income elasticity is 0.074, meaning that a 10% increase in income results in a 0.74% increase in electricity demand. We want to check the results of the Bayes factor comparing the previous specification (model 1) with other specification without considering the price of electricity (model 2), that is, \\[\\begin{align*} \\log(\\text{Electricity}_i) &amp; = \\beta_1\\text{IndSocio1}_i + \\beta_2\\text{IndSocio2}_i + \\beta_3\\text{Altitude}_i + \\beta_4\\text{Nrooms}_i\\\\ &amp; + \\beta_5\\text{HouseholdMem}_i + \\beta_6\\text{Children}_i + \\beta_7\\log(\\text{Income}_i)\\\\ &amp; + \\beta_8 + \\mu. \\end{align*}\\] In particular, we examine what happens as \\(c_0\\) increases from \\(10^{0}\\) to \\(10^{20}\\). We observe that when \\(c_0 = 1\\), \\(BF_{12} = 8.68 \\times 10^{+16}\\), which indicates very strong evidence in favor of the model including the price of electricity. However, as \\(c_0\\) increases, the Bayes factor decreases, which suggests evidence supporting model 2. For instance, when \\(c_0 = 10^{20}\\), \\(BF_{12} = 3.11 \\times 10^{-4}\\). This is an example of the issue with using non-informative priors to calculate the Bayes factor: there is very strong evidence supporting the parsimonious model as \\(c_0 \\rightarrow \\infty\\). We can obtain the posterior predictive distribution of the monthly electricity demand for a household located in the lowest socioeconomic condition in a municipality situated below 1000 meters above sea level, with 2 rooms, 3 members (with children), a monthly income of USD 500, and an electricity price of USD 0.15/kWh. The next Figure shows the histogram of the predictive posterior distribution. The highest posterior density credible interval at 95% is between 44.4 kWh and 373.9 kWh, and the posterior mean is 169.4 kWh. rm(list = ls()) set.seed(010101) # Electricity demand DataUt &lt;- read.csv(&quot;https://raw.githubusercontent.com/besmarter/BSTApp/refs/heads/master/DataApp/Utilities.csv&quot;, sep = &quot;,&quot;, header = TRUE, quote = &quot;&quot;) library(dplyr) DataUtEst &lt;- DataUt %&gt;% filter(Electricity != 0) attach(DataUtEst) # Dependent variable: Monthly consumption (kWh) in log Y &lt;- log(Electricity) # Regressors quantity including intercept X &lt;- cbind(LnPriceElect, IndSocio1, IndSocio2, Altitude, Nrooms, HouseholdMem, Children, Lnincome, 1) # LnPriceElect: Price per kWh (USD) in log # IndSocio1, IndSocio2, IndSocio3: Indicators socio-economic condition (1) is the lowest and (3) the highest # Altitude: Indicator of household location (1 is more than 1000 meters above sea level) # Nrooms: Number of rooms in house # HouseholdMem: Number of household members # Children: Indicator por presence of children in household (1) # Lnincome: Monthly income (USD) in log k &lt;- dim(X)[2] N &lt;- dim(X)[1] # Hyperparameters d0 &lt;- 0.001 a0 &lt;- 0.001 b0 &lt;- rep(0, k) B0 &lt;- 1000*diag(k) # Posterior parameters bhat &lt;- solve(t(X)%*%X)%*%t(X)%*%Y Bn &lt;- as.matrix(Matrix::forceSymmetric(solve(solve(B0) + t(X)%*%X))) # Force this matrix to be symmetric bn &lt;- Bn%*%(solve(B0)%*%b0 + t(X)%*%X%*%bhat) dn &lt;- as.numeric(d0 + t(Y)%*%Y+t(b0)%*%solve(B0)%*%b0-t(bn)%*%solve(Bn)%*%bn) an &lt;- a0 + N Hn &lt;- Bn*dn/an # Posterior draws S &lt;- 10000 # Number of draws from posterior distributions sig2 &lt;- MCMCpack::rinvgamma(S,an/2,dn/2) summary(coda::mcmc(sig2)) ## ## Iterations = 1:10000 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 10000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## 2.361e-01 7.617e-03 7.617e-05 7.617e-05 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## 0.2217 0.2309 0.2360 0.2412 0.2513 Betas &lt;- LaplacesDemon::rmvt(S, bn, Hn, an) summary(coda::mcmc(Betas)) ## ## Iterations = 1:10000 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 10000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## LnPriceElect -1.09043 0.19459 0.0019459 0.0019459 ## IndSocio1 -0.32783 0.05294 0.0005294 0.0005294 ## IndSocio2 -0.05737 0.04557 0.0004557 0.0004557 ## Altitude -0.19780 0.02386 0.0002386 0.0002429 ## Nrooms 0.08731 0.01094 0.0001094 0.0001119 ## HouseholdMem 0.05987 0.01334 0.0001334 0.0001334 ## Children 0.05696 0.03043 0.0003043 0.0003043 ## Lnincome 0.07447 0.01223 0.0001223 0.0001223 ## 2.52296 0.35077 0.0035077 0.0035077 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## LnPriceElect -1.472069 -1.22432 -1.08961 -0.95703 -0.71429 ## IndSocio1 -0.435957 -0.36228 -0.32731 -0.29133 -0.22588 ## IndSocio2 -0.147252 -0.08744 -0.05757 -0.02650 0.03254 ## Altitude -0.244759 -0.21372 -0.19783 -0.18164 -0.15094 ## Nrooms 0.066432 0.07985 0.08709 0.09480 0.10864 ## HouseholdMem 0.033623 0.05089 0.05975 0.06889 0.08596 ## Children -0.002259 0.03637 0.05698 0.07736 0.11681 ## Lnincome 0.050536 0.06614 0.07449 0.08283 0.09852 ## 1.835506 2.28703 2.52165 2.76364 3.21199 # Log marginal function (multiply by -1 due to minimization) LogMarLikLM &lt;- function(X, c0){ k &lt;- dim(X)[2] N &lt;- dim(X)[1] # Hyperparameters B0 &lt;- c0*diag(k) b0 &lt;- rep(0, k) # Posterior parameters bhat &lt;- solve(t(X)%*%X)%*%t(X)%*%Y # Force this matrix to be symmetric Bn &lt;- as.matrix(Matrix::forceSymmetric(solve(solve(B0) + t(X)%*%X))) bn &lt;- Bn%*%(solve(B0)%*%b0 + t(X)%*%X%*%bhat) dn &lt;- as.numeric(d0 + t(Y)%*%Y+t(b0)%*%solve(B0)%*%b0-t(bn)%*%solve(Bn)%*%bn) an &lt;- a0 + N # Log marginal likelihood logpy &lt;- (N/2)*log(1/pi)+(a0/2)*log(d0)-(an/2)*log(dn) + 0.5*log(det(Bn)/det(B0)) + lgamma(an/2)-lgamma(a0/2) return(-logpy) } cs &lt;- c(10^0, 10^3, 10^6, 10^10, 10^12, 10^15, 10^20) # Observe -1 to recover the right sign LogML &lt;- sapply(cs, function(c) {-LogMarLikLM(c0=c, X = X)}) # Regressor without price Xnew &lt;- cbind(IndSocio1, IndSocio2, Altitude, Nrooms, HouseholdMem, Children, Lnincome, 1) # Observe -1 to recover the right sign LogMLnew &lt;- sapply(cs, function(c) {-LogMarLikLM(c0=c,X = Xnew)}) # Bayes factor BF &lt;- exp(LogML - LogMLnew) BF ## [1] 8.687289e+16 1.006665e+05 3.108374e+03 3.108299e+01 3.108303e+00 ## [6] 9.829315e-02 3.108302e-04 # Predictive distribution Xpred &lt;- c(log(0.15), 1, 0, 0, 2, 3, 1, log(500), 1) Mean &lt;- Xpred%*%bn Hn &lt;- dn*(1+t(Xpred)%*%Bn%*%Xpred)/an ExpKwH &lt;- exp(LaplacesDemon::rmvt(S, Mean, Hn, an)) summary(ExpKwH) ## V1 ## Min. : 27.32 ## 1st Qu.: 119.94 ## Median : 168.74 ## Mean : 190.18 ## 3rd Qu.: 236.20 ## Max. :1032.62 HDI &lt;- HDInterval::hdi(ExpKwH, credMass = 0.95) # Highest posterior density credible interval HDI ## [,1] ## lower 47.94745 ## upper 387.64843 ## attr(,&quot;credMass&quot;) ## [1] 0.95 hist(ExpKwH, main = &quot;Histogram: Monthly demand of electricity&quot;, xlab = &quot;Monthly kWh&quot;, col = &quot;blue&quot;, breaks = 50) References "],["sec44.html", "3.4 Multivariate linear regression: The conjugate normal-normal/inverse Wishart model", " 3.4 Multivariate linear regression: The conjugate normal-normal/inverse Wishart model Let’s study the multivariate regression setting where there are \\(N\\)-dimensional vectors \\({\\boldsymbol{y}}_m\\), for \\(m = 1, 2, \\dots, M\\), such that \\({\\boldsymbol{y}}_m = {\\boldsymbol{X}} \\boldsymbol{\\beta}_m + \\mu_m\\). Here, \\({\\boldsymbol{X}}\\) represents the set of common regressors, and \\(\\mu_m\\) is the \\(N\\)-dimensional vector of stochastic errors for each equation. We assume that \\({\\boldsymbol{U}} = [\\mu_1 \\ \\mu_2 \\ \\dots \\ \\mu_M] \\sim MN_{N,M}({\\boldsymbol{0}}, {\\boldsymbol{I}}_N, {\\boldsymbol{\\Sigma}})\\), which is a matrix variate normal distribution where \\(\\boldsymbol{\\Sigma}\\) is the covariance matrix of each \\(i\\)-th row of \\({\\boldsymbol{U}}\\), for \\(i = 1, 2, \\dots, N\\), and we assume independence between the rows. Consequently, we have that \\(vec({\\boldsymbol{U}}) \\sim N_{N \\times M}({\\boldsymbol{0}}, \\boldsymbol{\\Sigma} \\otimes {\\boldsymbol{I}}_N)\\).23 This framework can be written in matrix form \\[\\begin{align*} \\underbrace{ \\begin{bmatrix} y_{11} &amp; y_{12} &amp; \\dots &amp; y_{1M}\\\\ y_{21} &amp; y_{22} &amp; \\dots &amp; y_{2M}\\\\ \\vdots &amp; \\vdots &amp; \\dots &amp; \\vdots\\\\ y_{N1} &amp; y_{N2} &amp; \\dots &amp; y_{NM}\\\\ \\end{bmatrix}}_{\\boldsymbol{Y}} &amp;= \\underbrace{\\begin{bmatrix} x_{11} &amp; x_{12} &amp; \\dots &amp; x_{1K}\\\\ x_{21} &amp; x_{22} &amp; \\dots &amp; x_{2K}\\\\ \\vdots &amp; \\vdots &amp; \\dots &amp; \\vdots\\\\ x_{N1} &amp; x_{N2} &amp; \\dots &amp; x_{NK}\\\\ \\end{bmatrix}}_{\\boldsymbol{X}} \\underbrace{ \\begin{bmatrix} \\beta_{11} &amp; \\beta_{12} &amp; \\dots &amp; \\beta_{1M}\\\\ \\beta_{21} &amp; \\beta_{22} &amp; \\dots &amp; \\beta_{2M}\\\\ \\vdots &amp; \\vdots &amp; \\dots &amp; \\vdots\\\\ \\beta_{K1} &amp; \\beta_{K2} &amp; \\dots &amp; \\beta_{KM}\\\\ \\end{bmatrix}}_{\\boldsymbol{B}}\\\\ &amp;+ \\underbrace{\\begin{bmatrix} \\mu_{11} &amp; \\mu_{12} &amp; \\dots &amp; \\mu_{1M}\\\\ \\mu_{21} &amp; \\mu_{22} &amp; \\dots &amp; \\mu_{2M}\\\\ \\vdots &amp; \\vdots &amp; \\dots &amp; \\vdots\\\\ \\mu_{N1} &amp; \\mu_{N2} &amp; \\dots &amp; \\mu_{NM}\\\\ \\end{bmatrix}}_{\\boldsymbol{U}}. \\end{align*}\\] Therefore, \\({\\boldsymbol{Y}}\\sim N_{N\\times M}({\\boldsymbol{X}}{\\boldsymbol{B}},\\boldsymbol{\\Sigma}\\otimes {\\boldsymbol{I}}_N)\\), \\[\\begin{align*} p({\\boldsymbol{Y}}\\mid {\\boldsymbol{B}},{\\boldsymbol{\\Sigma}}, {\\boldsymbol{X}})&amp;\\propto |{{\\boldsymbol \\Sigma}}|^{-N/2}\\exp\\left\\lbrace -\\frac{1}{2}tr\\left[({\\boldsymbol{Y}}-{\\boldsymbol{X}}{\\boldsymbol{B}})^{\\top}({\\boldsymbol{Y}}-{\\boldsymbol{X}}{\\boldsymbol{B}}){{\\boldsymbol \\Sigma}}^{-1}\\right]\\right\\rbrace \\\\ &amp;=|{{\\boldsymbol \\Sigma}}|^{-N/2}\\exp\\left\\lbrace -\\frac{1}{2}tr\\left[\\left({\\boldsymbol{S}}+({\\boldsymbol{B}}-\\widehat{\\boldsymbol{B}})^{\\top}{\\boldsymbol{X}}^{\\top}{\\boldsymbol{X}}({\\boldsymbol{B}}-\\widehat{\\boldsymbol{B}})\\right){{\\boldsymbol \\Sigma}}^{-1}\\right]\\right\\rbrace, \\end{align*}\\] where \\({\\boldsymbol{S}}= ({\\boldsymbol{Y}}-{\\boldsymbol{X}}\\widehat{\\boldsymbol{B}})^{\\top}({\\boldsymbol{Y}}-{\\boldsymbol{X}}\\widehat{\\boldsymbol{B}})\\), \\(\\widehat{\\boldsymbol{B}}= ({\\boldsymbol{X}}^{\\top}{\\boldsymbol{X}})^{-1}{\\boldsymbol{X}}^{\\top}{\\boldsymbol{Y}}\\) (see Exercise 9). The conjugate prior for this models is \\(\\pi({\\boldsymbol{B}},{\\boldsymbol{\\Sigma}})=\\pi({\\boldsymbol{B}}\\mid {\\boldsymbol{\\Sigma}})\\pi({\\boldsymbol{\\Sigma}})\\) where \\({\\boldsymbol{B}}\\mid {\\boldsymbol \\Sigma}\\sim N_{K\\times M}({\\boldsymbol{B}}_{0},{\\boldsymbol{V}}_{0},{\\boldsymbol{\\Sigma}})\\) and \\({\\boldsymbol{\\Sigma}}\\sim IW({\\boldsymbol{\\Psi}}_{0},\\alpha_{0})\\), that is, \\[\\begin{align*} \\pi ({\\boldsymbol{B}},{\\boldsymbol{\\Sigma}})\\propto &amp;\\left|{\\boldsymbol{\\Sigma}} \\right|^{-K/2}\\exp\\left\\lbrace -\\frac{1}{2}tr\\left[({\\boldsymbol{B}}-{\\boldsymbol{B}}_{0})^{\\top}{\\boldsymbol{V}}_{0}^{-1}({\\boldsymbol{B}}-{\\boldsymbol{B}}_{0}){\\boldsymbol \\Sigma}^{-1}\\right]\\right\\rbrace \\\\ &amp; \\times \\left|{\\boldsymbol \\Sigma} \\right|^{-(\\alpha_{0}+M+1)/2}\\exp\\left\\lbrace -\\frac{1}{2}tr \\left[ {\\boldsymbol{\\Psi}}_{0} {\\boldsymbol \\Sigma}^{-1}\\right] \\right\\rbrace. \\end{align*}\\] The posterior distribution is given by \\[\\begin{align*} \\pi({\\boldsymbol{B}},{\\boldsymbol{\\Sigma}}\\mid {\\boldsymbol{Y}},{\\boldsymbol{X}})&amp;\\propto p({\\boldsymbol{Y}}\\mid {\\boldsymbol{B}},{\\boldsymbol{\\Sigma}},{\\boldsymbol{X}}) \\pi({\\boldsymbol{B}}\\mid {\\boldsymbol \\Sigma})\\pi({\\boldsymbol{\\Sigma}})\\\\ &amp;\\propto \\left|{\\boldsymbol{\\Sigma}} \\right|^{-\\frac{N+K+\\alpha_{0}+M+1}{2}}\\\\ &amp;\\times\\exp\\left\\lbrace -\\frac{1}{2}tr\\left[(\\boldsymbol{\\Psi}_{0}+{\\boldsymbol{S}} +({\\boldsymbol{B}}-{\\boldsymbol{B}}_{0})^{\\top}{\\boldsymbol{V}}_{0}^{-1}({\\boldsymbol{B}}-{\\boldsymbol{B}}_{0})\\right.\\right.\\\\ &amp;\\left.\\left. +({\\boldsymbol{B}}-\\widehat{\\boldsymbol{B}})^{\\top}{\\boldsymbol{X}}^{\\top}{\\boldsymbol{X}}({\\boldsymbol{B}}-\\widehat{\\boldsymbol{B}}))\\boldsymbol{\\Sigma}^{-1}\\right]\\right\\rbrace . \\end{align*}\\] Completing the squares on \\({\\boldsymbol{B}}\\) and collecting the remaining terms in the bracket yields \\[\\begin{align*} {\\boldsymbol{\\Psi}}_{0}+{\\boldsymbol{S}} +({\\boldsymbol{B}}-{\\boldsymbol{B}}_{0})^{\\top}{\\boldsymbol{V}}_{0}^{-1}({\\boldsymbol{B}}-{\\boldsymbol{B}}_{0})+({\\boldsymbol{B}}-\\widehat{\\boldsymbol{B}})^{\\top}{\\boldsymbol{X}}^{\\top}{\\boldsymbol{X}}({\\boldsymbol{B}}-\\widehat{\\boldsymbol{B}}) &amp; = ({\\boldsymbol{B}}-{\\boldsymbol{B}}_n)^{\\top}{\\boldsymbol{V}}_n^{-1}({\\boldsymbol{B}}-{\\boldsymbol{B}}_n)+{\\boldsymbol{\\Psi}}_n, \\end{align*}\\] where \\[\\begin{align*} {\\boldsymbol{B}}_n = &amp;({\\boldsymbol{V}}_{0}^{-1}+{\\boldsymbol{X}}^{\\top}{\\boldsymbol{X}})^{-1}({\\boldsymbol{V}}_{0}^{-1}{\\boldsymbol{B}}_{0}+{\\boldsymbol{X}}^{\\top}{\\boldsymbol{Y}})=({\\boldsymbol{V}}_{0}^{-1}+{\\boldsymbol{X}}^{\\top}{\\boldsymbol{X}})^{-1}({\\boldsymbol{V}}_{0}^{-1}{\\boldsymbol{B}}_{0}+{\\boldsymbol{X}}^{\\top}{\\boldsymbol{X}}\\widehat{\\boldsymbol{B}}),\\\\ {\\boldsymbol{V}}_n = &amp;({\\boldsymbol{V}}_{0}^{-1}+{\\boldsymbol{X}}^{\\top}{\\boldsymbol{X}})^{-1},\\\\ {\\boldsymbol{\\Psi}}_n= &amp;{\\boldsymbol{\\Psi}}_{0}+{\\boldsymbol{S}}+{\\boldsymbol{B}}_{0}^{\\top}{\\boldsymbol{V}}_{0}^{-1}{\\boldsymbol{B}}_{0}+\\widehat{\\boldsymbol{B}}^{\\top}{\\boldsymbol{X}}^{\\top}{\\boldsymbol{X}}\\widehat{\\boldsymbol{B}}-{\\boldsymbol{B}}_n^{\\top}{\\boldsymbol{V}}_n^{-1}{\\boldsymbol{B}}_n. \\end{align*}\\] Thus, the posterior distribution can be written as \\[\\begin{align*} \\pi({\\boldsymbol{B}},{\\boldsymbol \\Sigma}\\mid {\\boldsymbol{Y}}, {\\boldsymbol{X}})\\propto &amp;\\left|{\\boldsymbol \\Sigma} \\right|^{-K/2}\\exp\\left\\lbrace -\\frac{1}{2} tr\\left[({\\boldsymbol{B}}-{\\boldsymbol{B}}_n)^{\\top}{\\boldsymbol{V}}_n^{-1}({\\boldsymbol{B}}-{\\boldsymbol{B}}_n) {\\boldsymbol \\Sigma}^{-1}\\right]\\right\\rbrace \\\\ \\times &amp; \\left|{\\boldsymbol \\Sigma} \\right|^{-\\frac{N+\\alpha_{0}+M+1}{2}}\\exp\\left\\lbrace -\\frac{1}{2} tr \\left[ {\\boldsymbol{\\Psi}}_n{\\boldsymbol \\Sigma}^{-1}\\right] \\right\\rbrace . \\end{align*}\\] That is \\(\\pi({\\boldsymbol{B}},{\\boldsymbol \\Sigma}\\mid {\\boldsymbol{Y}}, {\\boldsymbol{X}})=\\pi ({\\boldsymbol{B}}\\mid {\\boldsymbol \\Sigma},{\\boldsymbol{Y}},{\\boldsymbol{X}})\\pi({\\boldsymbol \\Sigma}\\mid {\\boldsymbol{Y}},{\\boldsymbol{X}})\\) where \\({\\boldsymbol{B}}\\mid {\\boldsymbol \\Sigma},{\\boldsymbol{Y}}, {\\boldsymbol{X}} \\sim N_{K\\times M}({\\boldsymbol{B}}_n,{\\boldsymbol{V}}_n,{\\boldsymbol \\Sigma})\\) and \\({\\boldsymbol \\Sigma}\\mid {\\boldsymbol{Y}},{\\boldsymbol{X}} \\sim IW({\\boldsymbol{\\Psi}}_n,{\\alpha}_n)\\), \\(\\alpha_n= N+\\alpha_{0}\\). Observe again that we can write down the posterior mean as a weighted average between prior and sample information such that \\({\\boldsymbol{V}}_0\\rightarrow\\infty\\) implies \\({\\boldsymbol{B}}_n\\rightarrow\\hat{{\\boldsymbol{B}}}\\), as we show in the univariate linear model. The marginal posterior for \\({\\boldsymbol{B}}\\) is given by \\[\\begin{align*} \\pi({\\boldsymbol{B}}\\mid {\\boldsymbol{Y}},{\\boldsymbol{X}})&amp;\\propto \\int_{\\boldsymbol{\\mathcal{S}}} \\left|{\\boldsymbol \\Sigma} \\right|^{-(\\alpha_n+K+M+1)/2}\\\\ &amp;\\times\\exp\\left\\lbrace -\\frac{1}{2} tr\\left\\{\\left[({\\boldsymbol{B}}-{\\boldsymbol{B}}_n)^{\\top}{\\boldsymbol{V}}_n^{-1}({\\boldsymbol{B}}-{\\boldsymbol{B}}_n)+{\\boldsymbol{\\Psi}}_n \\right] {\\boldsymbol \\Sigma}^{-1}\\right\\}\\right\\rbrace d{\\boldsymbol{\\Sigma}} \\\\ &amp;\\propto|({\\boldsymbol{B}}-{\\boldsymbol{B}}_n)^{\\top}{\\boldsymbol{V}}_n^{-1}({\\boldsymbol{B}}-{\\boldsymbol{B}}_n)+{\\boldsymbol{\\Psi}}_n|^{-(K+\\alpha_n)/2}\\\\ &amp;=\\left[|{\\boldsymbol{\\Psi}}_n|\\times|{\\boldsymbol{I}}_K+{\\boldsymbol{V}}_n^{-1}({\\boldsymbol{B}}-{\\boldsymbol{B}}_n){\\boldsymbol{\\Psi}}_n^{-1}({\\boldsymbol{B}}-{\\boldsymbol{B}}_n)^{\\top}|\\right]^{-(\\alpha_n+1-M+K+M-1)/2}\\\\ &amp;\\propto|{\\boldsymbol{I}}_K+{\\boldsymbol{V}}_n^{-1}({\\boldsymbol{B}}-{\\boldsymbol{B}}_n){\\boldsymbol{\\Psi}}_n^{-1}({\\boldsymbol{B}}-{\\boldsymbol{B}}_n)^{\\top}|^{-(\\alpha_n+1-M+K+M-1)/2}. \\end{align*}\\] The second line uses the inverse Wishart distribution, the third line the Sylverter’s theorem, and the last line is the kernel of a matrix \\(t\\)-distribution, that is, \\({\\boldsymbol{B}}\\mid {\\boldsymbol{Y}},{\\boldsymbol{X}}\\sim T_{K\\times M}({\\boldsymbol{B}}_n,{\\boldsymbol{V}}_n,{\\boldsymbol{\\Psi}}_n)\\) with \\(\\alpha_n+1-M\\) degrees of freedom. Observe that \\(vec({\\boldsymbol{B}})\\) has mean \\(vec({\\boldsymbol{B}}_n)\\) and variance \\(({\\boldsymbol{V}}_n\\otimes{\\boldsymbol{\\Psi}}_n)/(\\alpha_n-M-1)\\) based on its marginal distribution. On the other hand, the variance based on the conditional distribution is \\({\\boldsymbol{V}}_n\\otimes{\\boldsymbol{\\Sigma}}\\), where the mean of \\({\\boldsymbol{\\Sigma}}\\) is \\({\\boldsymbol{\\Psi}}_n/(\\alpha_n-M-1)\\). The marginal likelihood is the following, \\[\\begin{align*} p({\\boldsymbol{Y}})&amp;=\\int_{\\mathcal{B}}\\int_{\\mathcal{S}}\\left\\{ (2\\pi)^{-NM/2} |{{\\boldsymbol \\Sigma}}|^{-N/2}\\exp\\left\\lbrace -\\frac{1}{2}tr\\left[{\\boldsymbol{S}}+({\\boldsymbol{B}}-\\widehat{\\boldsymbol{B}})^{\\top}{\\boldsymbol{X}}^{\\top}{\\boldsymbol{X}}({\\boldsymbol{B}}-\\widehat{\\boldsymbol{B}})\\right]{{\\boldsymbol \\Sigma}}^{-1}\\right\\rbrace\\right.\\\\ &amp;\\times (2\\pi)^{-KM/2}\\left|{\\boldsymbol V}_0 \\right|^{-M/2} \\left|{\\boldsymbol{\\Sigma}} \\right|^{-K/2}\\exp\\left\\lbrace -\\frac{1}{2}tr\\left[({\\boldsymbol{B}}-{\\boldsymbol{B}}_{0})^{\\top}{\\boldsymbol{V}}_{0}^{-1}({\\boldsymbol{B}}-{\\boldsymbol{B}}_{0}){\\boldsymbol \\Sigma}^{-1}\\right]\\right\\rbrace \\\\ &amp;\\left. \\times \\frac{|\\Psi_0|^{\\alpha_0/2}}{2^{\\alpha_0M/2}\\Gamma_M(\\alpha_0/2)} \\left|{\\boldsymbol \\Sigma} \\right|^{-(\\alpha_{0}+M+1)/2}\\exp\\left\\lbrace -\\frac{1}{2}tr \\left[ {\\boldsymbol{\\Psi}}_{0} {\\boldsymbol \\Sigma}^{-1}\\right] \\right\\rbrace \\right\\} d{\\boldsymbol{\\Sigma}} d{\\boldsymbol B}\\\\ &amp;=(2\\pi)^{-M(N+K)/2}\\left|{\\boldsymbol V}_0\\right|^{-M/2}\\frac{|\\Psi_0|^{\\alpha_0/2}}{2^{\\alpha_0M/2}\\Gamma_M(\\alpha_0/2)}\\\\ &amp;\\times\\int_{\\mathcal{B}}\\int_{\\mathcal{S}} \\left\\{ \\left|{\\boldsymbol \\Sigma} \\right|^{-(\\alpha_{0}+N+K+M+1)/2}\\right.\\\\ &amp;\\left. \\exp\\left\\lbrace -\\frac{1}{2}tr\\left[{\\boldsymbol{S}}+({\\boldsymbol{B}}-\\widehat{\\boldsymbol{B}})^{\\top}{\\boldsymbol{X}}^{\\top}{\\boldsymbol{X}}({\\boldsymbol{B}}-\\widehat{\\boldsymbol{B}})+({\\boldsymbol{B}}-{\\boldsymbol{B}}_{0})^{\\top}{\\boldsymbol{V}}_{0}^{-1}({\\boldsymbol{B}}-{\\boldsymbol{B}}_{0})+{\\boldsymbol{\\Psi}}_0\\right]{{\\boldsymbol \\Sigma}}^{-1}\\right\\rbrace\\right\\}d{\\boldsymbol{\\Sigma}} d{\\boldsymbol B}\\\\ &amp;=(2\\pi)^{-M(N+K)/2}\\left|{\\boldsymbol V}_0\\right|^{-M/2}\\frac{|\\Psi_0|^{\\alpha_0/2}}{2^{\\alpha_0M/2}\\Gamma_M(\\alpha_0/2)}2^{M(\\alpha_n+K)/2}\\Gamma_M((\\alpha_n+K)/2)\\\\ &amp;\\times \\int_{\\mathcal{B}}\\left|{\\boldsymbol{S}}+({\\boldsymbol{B}}-\\widehat{\\boldsymbol{B}})^{\\top}{\\boldsymbol{X}}^{\\top}{\\boldsymbol{X}}({\\boldsymbol{B}}-\\widehat{\\boldsymbol{B}})+({\\boldsymbol{B}}-{\\boldsymbol{B}}_{0})^{\\top}{\\boldsymbol{V}}_{0}^{-1}({\\boldsymbol{B}}-{\\boldsymbol{B}}_{0})+{\\boldsymbol{\\Psi}}_0\\right|^{-(\\alpha_n+K)/2}d{\\boldsymbol{B}}\\\\ &amp;=(2\\pi)^{-M(N+K)/2}\\left|{\\boldsymbol V}_0\\right|^{-M/2}\\frac{|\\Psi_0|^{\\alpha_0/2}}{2^{\\alpha_0M/2}\\Gamma_M(\\alpha_0/2)}2^{M(\\alpha_n+K)/2}\\Gamma_M((\\alpha_n+K)/2)\\\\ &amp;\\times \\int_{\\mathcal{B}}\\left|({\\boldsymbol{B}}-\\widehat{\\boldsymbol{B}}_n)^{\\top}{\\boldsymbol{V}}_n^{-1}({\\boldsymbol{B}}-\\widehat{\\boldsymbol{B}}_n)+{\\boldsymbol{\\Psi}}_n\\right|^{-(\\alpha_n+K)/2}d{\\boldsymbol{B}}\\\\ &amp;=(2\\pi)^{-M(N+K)/2}\\left|{\\boldsymbol V}_0\\right|^{-M/2}\\frac{|\\Psi_0|^{\\alpha_0/2}}{2^{\\alpha_0M/2}\\Gamma_M(\\alpha_0/2)}2^{M(\\alpha_n+K)/2}\\Gamma_M((\\alpha_n+K)/2)\\\\ &amp;\\times \\int_{\\mathcal{B}}\\left[|{\\boldsymbol{\\Psi}}_n|\\times |{\\boldsymbol{I}}_{K}+{\\boldsymbol{V}}_n^{-1}({\\boldsymbol{B}}-\\widehat{\\boldsymbol{B}}_n){\\boldsymbol{\\Psi}}_n^{-1}({\\boldsymbol{B}}-\\widehat{\\boldsymbol{B}}_n)^{\\top}|\\right]^{-(\\alpha_n+K)/2}d{\\boldsymbol{B}}\\\\ &amp;=|{\\boldsymbol{\\Psi}}_n|^{-(\\alpha_n+K)/2}(2\\pi)^{-M(N+K)/2}\\left|{\\boldsymbol V}_0\\right|^{-M/2}\\frac{|\\Psi_0|^{\\alpha_0/2}2^{M(\\alpha_n+K)/2}\\Gamma_M((\\alpha_n+K)/2)}{2^{\\alpha_0M/2}\\Gamma_M(\\alpha_0/2)}\\\\ &amp;\\times \\int_{\\mathcal{{\\boldsymbol{B}}}}\\left| {\\boldsymbol{I}}_{K}+{\\boldsymbol{V}}_n^{-1}({\\boldsymbol{B}}-\\widehat{\\boldsymbol{B}}_n){\\boldsymbol{\\Psi}}_n^{-1}({\\boldsymbol{B}}-\\widehat{\\boldsymbol{B}}_n)^{\\top}\\right|^{-(\\alpha_n+1-M+K+M-1)/2}d{\\boldsymbol{B}}\\\\ &amp;=|{\\boldsymbol{\\Psi}}_n|^{-(\\alpha_n+K)/2}(2\\pi)^{-M(N+K)/2}\\left|{\\boldsymbol V}_0\\right|^{-M/2}\\frac{|\\Psi_0|^{\\alpha_0/2}2^{M(\\alpha_n+K)/2}\\Gamma_M((\\alpha_n+K)/2)}{2^{\\alpha_0M/2}\\Gamma_M(\\alpha_0/2)}\\\\ &amp;\\times \\pi^{MK/2}\\frac{\\Gamma_M((\\alpha_n+1-M+M-1)/2)}{\\Gamma_M((\\alpha_n+1-M+K+M-1)/2)}|{\\boldsymbol{\\Psi}}_n|^{K/2}|{\\boldsymbol{V}}_n|^{M/2}\\\\ &amp;=\\frac{|{\\boldsymbol{V}}_n|^{M/2}}{|{\\boldsymbol{V}}_0|^{M/2}}\\frac{|{\\boldsymbol{\\Psi}}_0|^{\\alpha_0/2}}{|{\\boldsymbol{\\Psi}}_n|^{\\alpha_n/2}}\\frac{\\Gamma_M(\\alpha_n/2)}{\\Gamma_M(\\alpha_0/2)}\\pi^{-MN/2}. \\end{align*}\\] The third equality follows from the kernel of an inverse Wishart distribution, the fifth from Sylvester’s theorem, and the seventh from the kernel of a matrix \\(t\\)-distribution. Observe that this last expression is the multivariate case of the marginal likelihood of the univariate regression model. Taking into account that \\[\\begin{align*} ({\\boldsymbol{A}}+{\\boldsymbol{B}})^{-1}&amp;={\\boldsymbol{A}}^{-1}-({\\boldsymbol{A}}^{-1}+{\\boldsymbol{B}}^{-1})^{-1}{\\boldsymbol{A}}^{-1}\\\\ &amp;={\\boldsymbol{B}}^{-1}-({\\boldsymbol{A}}^{-1}+{\\boldsymbol{B}}^{-1})^{-1}{\\boldsymbol{B}}^{-1}\\\\ &amp;={\\boldsymbol{A}}^{-1}({\\boldsymbol{A}}^{-1}+{\\boldsymbol{B}}^{-1}){\\boldsymbol{B}}^{-1}, \\end{align*}\\] we can show that \\({\\boldsymbol{\\Psi}}_{n}={\\boldsymbol{\\Psi}}_{0}+{\\boldsymbol{S}}+(\\hat{\\boldsymbol{B}}-{\\boldsymbol{B}}_{0})^{\\top}{\\boldsymbol{V}}_{n}(\\hat{\\boldsymbol{B}}-{\\boldsymbol{B}}_{0})\\) (see Exercise 7). Therefore, the marginal likelihood rewards fit (smaller sum of squares, \\({\\boldsymbol{S}}\\)), similarity between prior and sample information regarding location parameters, and information gains in variability from \\({\\boldsymbol{V}}_0\\) to \\({\\boldsymbol{V}}_n\\). Given a matrix of regressors \\({\\boldsymbol{X}}_0\\) for \\(N_0\\) unobserved units, the predictive density of \\({\\boldsymbol{Y}}_0\\) given \\({\\boldsymbol{Y}}\\), \\(\\pi({\\boldsymbol{Y}}_0\\mid {\\boldsymbol{Y}})\\) is a matrix t distribution \\(T_{N_0,M}(\\alpha_n-M+1,{\\boldsymbol{X}}_0{\\boldsymbol{B}}_n,{\\boldsymbol{I}}_{N_0}+{\\boldsymbol{X}}_0{\\boldsymbol{V}}_n{\\boldsymbol{X}}_0^{\\top},{\\boldsymbol{\\Psi}}_n)\\) (see Exercise 6). Observe that the prediction is centered at \\({\\boldsymbol{X}}_0{\\boldsymbol{B}}_n\\), and the covariance matrix of \\(vec({\\boldsymbol{Y}}_0)\\) is \\(\\frac{({\\boldsymbol{I}}_{N_0}+{\\boldsymbol{X}}_0{\\boldsymbol{V}}_n{\\boldsymbol{X}}_0^{\\top})\\otimes{\\boldsymbol{\\Psi}}_n}{\\alpha_n-M-1}\\). \\(vec\\) denotes the vectorization operation, and \\(\\otimes\\) denotes the Kronecker product.↩︎ "],["sec45.html", "3.5 Summary", " 3.5 Summary We introduce conjugate family models for both discrete and continuous data. These models form the foundation of the Bayesian framework due to their mathematical tractability, as they provide closed-form expressions for the posterior distributions, marginal likelihood, and predictive distribution. Additionally, we present the Bayesian linear regression frameworks for both univariate and multivariate cases under conjugate families. These frameworks are fundamental for performing regression analysis in the Bayesian setting. "],["sec46.html", "3.6 Exercises", " 3.6 Exercises Write the distribution of the Bernoulli example in canonical form, and find the mean and variance of the sufficient statistic. Given a random sample \\(\\boldsymbol{Y} = [Y_1 \\ Y_2 \\ \\dots \\ Y_N]^{\\top}\\) from \\(N\\) binomial experiments, each with known size \\(n_i\\) and the same unknown probability \\(\\theta\\), show that \\(p(\\boldsymbol{y} \\mid \\theta)\\) is in the exponential family. Then, find the posterior distribution, the marginal likelihood, and the predictive distribution of the binomial-Beta model assuming the number of trials is known. Given a random sample \\(\\boldsymbol{Y} = [Y_1 \\ Y_2 \\ \\dots \\ Y_N]^{\\top}\\) from an exponential distribution, show that \\(p(\\boldsymbol{y} \\mid \\lambda)\\) is in the exponential family. Additionally, find the posterior distribution, the marginal likelihood, and the predictive distribution of the exponential-Gamma model. Given that \\(\\boldsymbol{Y} \\sim N_N(\\boldsymbol{\\mu}, \\boldsymbol{\\Sigma})\\), that is, a multivariate normal distribution, show that \\(p(\\boldsymbol{y} \\mid \\boldsymbol{\\mu}, \\boldsymbol{\\Sigma})\\) is in the exponential family. Find the marginal likelihood in the normal/inverse-Wishart model. Find the posterior predictive distribution in the normal/inverse-Wishart model, and show that \\({\\boldsymbol{Y}}_0\\mid {\\boldsymbol{Y}}\\sim T_{N_0,M}(\\alpha_n-M+1,{\\boldsymbol{X}}_0{\\boldsymbol{B}}_n,{\\boldsymbol{I}}_{N_0}+{\\boldsymbol{X}}_0{\\boldsymbol{V}}_n{\\boldsymbol{X}}_0^{\\top},{\\boldsymbol{\\Psi}}_n)\\). Show that \\(\\delta_n=\\delta_0+({\\boldsymbol{y}}-{\\boldsymbol{X}}\\hat{\\boldsymbol{\\beta}})^{\\top}({\\boldsymbol{y}}-{\\boldsymbol{X}}\\hat{\\boldsymbol{\\beta}})+(\\hat{\\boldsymbol{\\beta}}-\\boldsymbol{\\beta}_0)^{\\top}(({\\boldsymbol{X}}^{\\top}{\\boldsymbol{X}})^{-1}+{\\boldsymbol{B}}_0)^{-1}(\\hat{\\boldsymbol{\\beta}}-\\boldsymbol{\\beta}_0)\\) in the linear regression model, and that \\({\\boldsymbol{\\Psi}}_{n}={\\boldsymbol{\\Psi}}_{0}+{\\boldsymbol{S}}+(\\hat{\\boldsymbol{B}}-{\\boldsymbol{B}}_{0})^{\\top}{\\boldsymbol{V}}_{n}(\\hat{\\boldsymbol{B}}-{\\boldsymbol{B}}_{0})\\) in the linear multivariate regression model. Show that in the linear regression model \\(\\boldsymbol{\\beta}_n^{\\top}({\\boldsymbol{B}}_n^{-1}-{\\boldsymbol{B}}_n^{-1}{\\boldsymbol{M}}^{-1}{\\boldsymbol{B}}_n^{-1})\\boldsymbol{\\beta}_n={\\boldsymbol{\\boldsymbol{\\beta}}}_{**}^{\\top}{\\boldsymbol{C}}{\\boldsymbol{\\boldsymbol{\\beta}}}_{**}\\) and \\(\\boldsymbol{\\beta}_{**}={\\boldsymbol{X}}_0\\boldsymbol{\\beta}_n\\). Show that \\(({\\boldsymbol{Y}}-{\\boldsymbol{X}}{\\boldsymbol{B}})^{\\top}({\\boldsymbol{Y}}-{\\boldsymbol{X}}{\\boldsymbol{B}})={\\boldsymbol{S}}+({\\boldsymbol{B}}-\\widehat{\\boldsymbol{B}})^{\\top}{\\boldsymbol{X}}^{\\top}{\\boldsymbol{X}}({\\boldsymbol{B}}-\\widehat{\\boldsymbol{B}})\\) where \\({\\boldsymbol{S}}= ({\\boldsymbol{Y}}-{\\boldsymbol{X}}\\widehat{\\boldsymbol{B}})^{\\top}({\\boldsymbol{Y}}-{\\boldsymbol{X}}\\widehat{\\boldsymbol{B}})\\), \\(\\widehat{\\boldsymbol{B}}= ({\\boldsymbol{X}}^{\\top}{\\boldsymbol{X}})^{-1}{\\boldsymbol{X}}^{\\top}{\\boldsymbol{Y}}\\) in the multivariate regression model. What is the probability that the Sun will rise tomorrow? This is the most famous example by Richard Price, developed in the Appendix of Bayes’ theorem paper (Thomas Bayes 1763). Here, we implicitly use Laplace’s Rule of Succession to solve this problem. In particular, if we were a priori uncertain about the probability that the Sun will rise on a specified day, we can assume a uniform prior distribution over \\((0,1)\\), that is, a Beta(1,1) distribution. Then, what is the probability that the Sun will rise? Using information from Public Policy Polling in September 27th-28th for the 2016 presidential five-way race in USA, there are 411, 373 and 149 sampled people supporting Hillary Clinton, Donald Trump and other, respectively. Find the posterior probability of the percentage difference of people supporting Hillary versus Trump according to this data using a non-informative prior, that is, \\(\\alpha_0=[1 \\ 1 \\ 1]\\) in the multinomial-Dirichlet model. What is the probability of having more supports of Hillary vs Trump? What is the probability that sampling one hundred independent individuals 44, 40 and 16 support Hillary, Trump and other, respectively? Math test example continues You have a random sample of math scores of size \\(N=50\\) from a normal distribution, \\(Y_i\\sim {N}(\\mu, \\sigma^2)\\). The sample mean and variance are equal to \\(102\\) and \\(10\\), respectively. Using the normal-normal/inverse-gamma model where \\(\\mu_0=100\\), \\(\\beta_0=1\\), \\(\\alpha_0=\\delta_0=0.001\\) Get a 95% confidence and credible interval for \\(\\mu\\). What is the posterior probability that \\(\\mu &gt; 103\\)? Demand of electricity example continues Set \\(c_0\\) such that maximizes the marginal likelihood in the specifications with and without electricity price in the example of demand of electricity (empirical Bayes). Then, calculate the Bayes factor, and conclude if there is evidence supporting the inclusion of the price of electricity in the demand equation. Utility demand Use the file Utilities.csv to estimate a multivariate linear regression model where \\(\\boldsymbol{Y}_i=\\left[\\log(\\text{electricity}_i) \\ \\log(\\text{water}_i) \\ \\log(\\text{gas}_i)\\right]\\) as function of \\(\\log(\\text{electricity price}_i)\\), \\(\\log(\\text{water price}_i)\\), \\(\\log(\\text{gas price}_i)\\), \\(\\text{IndSocio1}_i\\), \\(\\text{IndSocio2}_i\\), \\(\\text{Altitude}_i\\), \\(\\text{Nrooms}_i\\), \\(\\text{HouseholdMem}_i\\), \\(\\text{Children}_i\\), and \\(\\log(\\text{Income}_i)\\), where electricity, water and gas are monthly consumption of electricity (kWh), water (m\\(^3\\)) and gas (m\\(^3\\)), and other definitions are given in the Example of Section 3.3. Omit households that do not consume any of the utilities in this exercise. Set a non-informative prior framework, \\(\\boldsymbol{B}_0=\\left[0\\right]_{11\\times 3}\\), \\(\\boldsymbol{V}_0=1000 \\boldsymbol{I}_{11}\\), \\(\\boldsymbol{\\Psi}_0=1000 \\boldsymbol{I}_{3}\\) and \\(\\alpha_0=3\\), where we have \\(K=11\\) (regressors plus intercept) and \\(M=3\\) (equations) in this exercise. Find the posterior mean estimates and the highest posterior density intervals at 95% of \\(\\boldsymbol{B}\\) and \\(\\boldsymbol{\\Sigma}\\). Use the marginal distribution and the conditional distribution to obtain the posterior estimates of \\(\\boldsymbol{B}\\), and compare the results. Find the Bayes factor comparing the baseline model in this exercise with the same specification but using the income in dollars. Now, calculate the Bayes factor using the income in thousand dollars. Is there any difference? Find the predictive distribution for the monthly demand of electricity, water and gas in the baseline specification of a household located in the lowest socioeconomic condition in a municipality located below 1000 meters above the sea level, 2 rooms, 3 members with children, a monthly income equal to USD 500, an electricity price equal to USD/kWh 0.15, a water price equal to USD/M\\(^3\\) 0.70, and a gas price equal to USD/M\\(^3\\) 0.75. 15 Ph.D. students sleeping hours (J. Albert 2009) We are interested in learning about the proportion of Ph.D. students who sleep at least 6 hours per day. We have a sample of 52 students, where 15 report sleeping at least 6 hours, and the remaining 37 report not sleeping at least 6 hours. The prior distribution is a Beta distribution, with hyperparameters calibrated so that the prior probabilities of the proportion of students who sleep least than 6 hours being less than 0.4 and 0.75 are 0.6 and 0.95, respectively. Estimate the 95% posterior credible interval for the proportion of Ph.D. students who sleep at least 6 hours per day. Then, assume there is a group of experts whose beliefs about the proportion of Ph.D. students sleeping at least 6 hours are represented in the following table: Table 3.1: Probability distribution: Ph.D students that sleep at least 6 hours per day. \\(h\\) 0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40 0.45 0.50 0.15 \\(P(p=h)\\) 0.05 0.07 0.10 0.12 0.15 0.17 0.15 0.11 0.06 0.01 0.01 Use this Table as prior information, and find the posterior distribution of the proportion of students that sleep at least 6 hours. References "],["Chap4.html", "Chapter 4 Simulation methods", " Chapter 4 Simulation methods In the previous chapters, we focused on conjugate families, where the posterior and predictive distributions have standard analytical forms (e.g., normal, Student’s t, gamma, binomial, Poisson, etc.) and where the marginal likelihood has a closed-form analytical solution. However, realistic models are often more complex and lack such closed-form solutions. To address this complexity, we rely on simulation (stochastic) methods to draw samples from posterior and predictive distributions. This chapter introduces posterior simulation, a cornerstone of Bayesian inference. We discuss Markov Chain Monte Carlo (MCMC) methods, including Gibbs sampling, Metropolis-Hastings, and Hamiltonian Monte Carlo, as well as other techniques like importance sampling and particle filtering (sequential Monte Carlo). The simulation methods discussed in this chapter are specifically applied throughout this book. However, we do not delve into deterministic methods, such as numerical integration (quadrature), or other simulation methods, including discrete approximation, the probability integral transform, the method of composition, accept-reject sampling, and slice sampling algorithms. While these methods are also widely used, they are not as common as the approaches explicitly employed in this book. For readers interested in these alternative methods, we recommend exploring Christian P. Robert, Casella, and Casella (2010), Christian P. Robert and Casella (2011), Greenberg (2012), and Andrew Gelman et al. (2021). References "],["sec51.html", "4.1 Markov Chain Monte Carlo methods", " 4.1 Markov Chain Monte Carlo methods Markov Chain Monte Carlo (MCMC) methods are algorithms used to approximate complex probability distributions by constructing a Markov chain. This chain is a sequence of random samples where each sample depends only on the previous one. The goal of MCMC methods is to obtain draws from the posterior distribution as the equilibrium distribution. The key point in MCMC methods is the transition kernel or density, \\(q(\\boldsymbol{\\theta}^{(s)}\\mid \\boldsymbol{\\theta}^{(s-1)})\\), which generates a draw \\(\\boldsymbol{\\theta}^{(s)}\\) at stage \\(s\\) that depends solely on \\(\\boldsymbol{\\theta}^{(s-1)}\\). This transition distribution must be designed such that the Markov chain converges to a unique stationary distribution, which, in our case, is the posterior distribution, that is, \\[ \\pi(\\boldsymbol{\\theta}^{(s)}\\mid \\boldsymbol{y})=\\int_{\\boldsymbol{\\Theta}}q(\\boldsymbol{\\theta}^{(s)}\\mid \\boldsymbol{\\theta}^{(s-1)})\\pi(\\boldsymbol{\\theta}^{(s-1)}\\mid \\boldsymbol{y})d\\boldsymbol{\\theta}^{(s-1)}. \\] Given that we start at an arbitrary point, \\(\\boldsymbol{\\theta}^{(0)}\\), the algorithm requires that the Markov chain be irreducible, meaning that the process can reach any other state with positive probability. Additionally, the process must be aperiodic, meaning that for each state, the greatest common divisor of the number of steps it takes to return to the state is 1, ensuring that there are no cycles forcing the system to return to a state only after a fixed number of steps. Furthermore, the process must be recurrent, meaning that it will return to any state an infinite number of times with probability one. However, to ensure convergence to the stationary distribution, a stronger condition is required: the process must be positive recurrent, meaning that the expected return time to a state is finite. Given an irreducible, aperiodic, and positive recurrent transition density, the Markov chain algorithm will asymptotically converge to the stationary posterior distribution we are seeking. For more details, see Christian P. Robert and Casella (2011). 4.1.1 Gibbs sampler The Gibbs sampler algorithm is one of the most widely used MCMC methods for sampling from non-standard distributions in Bayesian analysis. While it is a special case of the Metropolis-Hastings (MH) algorithm, it originated from a different theoretical background (Geman and Geman 1984; A. E. Gelfand and Smith 1990). The key requirement for implementing the Gibbs sampling algorithm is the availability of conditional posterior distributions. The algorithm works by cycling through the conditional posterior distributions corresponding to different blocks of the parameter space under inference. To simplify concepts, let’s focus on a parameter space composed of two blocks, \\(\\boldsymbol{\\theta} = [\\boldsymbol{\\theta}_1 \\ \\boldsymbol{\\theta}_2]^{\\top}\\). The Gibbs sampling algorithm uses the transition kernel \\[ q(\\boldsymbol{\\theta}_1^{(s)},\\boldsymbol{\\theta}_2^{(s)}\\mid \\boldsymbol{\\theta}_1^{(s-1)},\\boldsymbol{\\theta}_2^{(s-1)})=\\pi(\\boldsymbol{\\theta}_1^{(s)}\\mid \\boldsymbol{\\theta}_2^{(s-1)},\\boldsymbol{y})\\pi(\\boldsymbol{\\theta}_2^{(s)}\\mid \\boldsymbol{\\theta}_1^{(s)},\\boldsymbol{y}). \\] Thus, \\[ \\begin{aligned} \\int_{\\boldsymbol{\\Theta}}q(\\boldsymbol{\\theta}^{(s)}\\mid \\boldsymbol{\\theta}^{(s-1)})\\pi(\\boldsymbol{\\theta}^{(s-1)}\\mid \\boldsymbol{y})d\\boldsymbol{\\theta}^{(s-1)} &amp;=\\int_{\\boldsymbol{\\Theta}_2}\\int_{\\boldsymbol{\\Theta}_1}\\pi(\\boldsymbol{\\theta}_1^{(s)}\\mid \\boldsymbol{\\theta}_2^{(s-1)},\\boldsymbol{y})\\pi(\\boldsymbol{\\theta}_2^{(s)}\\mid \\boldsymbol{\\theta}_1^{(s)},\\boldsymbol{y})\\pi(\\boldsymbol{\\theta}^{(s-1)}_1,\\boldsymbol{\\theta}^{(s-1)}_2\\mid \\boldsymbol{y})d\\boldsymbol{\\theta}^{(s-1)}_1d\\boldsymbol{\\theta}^{(s-1)}_2\\\\ &amp;=\\pi(\\boldsymbol{\\theta}_2^{(s)}\\mid \\boldsymbol{\\theta}_1^{(s)},\\boldsymbol{y})\\int_{\\boldsymbol{\\Theta}_2}\\int_{\\boldsymbol{\\Theta}_1}\\pi(\\boldsymbol{\\theta}_1^{(s)}\\mid \\boldsymbol{\\theta}_2^{(s-1)},\\boldsymbol{y})\\pi(\\boldsymbol{\\theta}^{(s-1)}_1,\\boldsymbol{\\theta}^{(s-1)}_2\\mid \\boldsymbol{y})d\\boldsymbol{\\theta}^{(s-1)}_1d\\boldsymbol{\\theta}^{(s-1)}_2\\\\ &amp;=\\pi(\\boldsymbol{\\theta}_2^{(s)}\\mid \\boldsymbol{\\theta}_1^{(s)},\\boldsymbol{y})\\int_{\\boldsymbol{\\Theta}_2}\\pi(\\boldsymbol{\\theta}_1^{(s)}\\mid \\boldsymbol{\\theta}_2^{(s-1)},\\boldsymbol{y})\\pi(\\boldsymbol{\\theta}^{(s-1)}_2\\mid \\boldsymbol{y})d\\boldsymbol{\\theta}^{(s-1)}_2\\\\ &amp;=\\pi(\\boldsymbol{\\theta}_2^{(s)}\\mid \\boldsymbol{\\theta}_1^{(s)},\\boldsymbol{y})\\int_{\\boldsymbol{\\Theta}_2}\\pi(\\boldsymbol{\\theta}_1^{(s)},\\boldsymbol{\\theta}_2^{(s-1)}\\mid \\boldsymbol{y})d\\boldsymbol{\\theta}^{(s-1)}_2\\\\ &amp;=\\pi(\\boldsymbol{\\theta}_2^{(s)}\\mid \\boldsymbol{\\theta}_1^{(s)},\\boldsymbol{y})\\pi(\\boldsymbol{\\theta}_1^{(s)}\\mid \\boldsymbol{y})\\\\ &amp;=\\pi(\\boldsymbol{\\theta}_1^{(s)},\\boldsymbol{\\theta}_2^{(s)}\\mid \\boldsymbol{y}). \\end{aligned} \\] Then, \\(\\pi(\\boldsymbol{\\theta}\\mid \\boldsymbol{y})\\) is the stationary distribution for the Gibbs transition kernel. A word of caution! Even if we have well-defined conditional posterior distributions \\(\\pi(\\boldsymbol{\\theta}_1^{(s)} \\mid \\boldsymbol{\\theta}_2^{(s-1)}, \\boldsymbol{y})\\) and \\(\\pi(\\boldsymbol{\\theta}_2^{(s)} \\mid \\boldsymbol{\\theta}_1^{(s)}, \\boldsymbol{y})\\), and we can simulate from them, the joint posterior distribution \\(\\pi(\\boldsymbol{\\theta}_1^{(s)}, \\boldsymbol{\\theta}_2^{(s)} \\mid \\boldsymbol{y})\\) may not correspond to any proper distribution. We should be mindful of this situation, especially when dealing with improper prior distributions (see Christian P. Robert and Casella (2011) for details). Algorithm 1 demonstrates the implementation of a Gibbs sampler with \\(d\\) blocks. The number of iterations (\\(S\\)) is chosen to ensure convergence to the stationary distribution. In Section 4.4, we review several convergence diagnostics to assess whether the posterior draws have reached convergence. Algorithm: Gibbs sampling Set θ2(0), θ3(0), ..., θd(0), For s=1,2,...,S do Draw θ1(s) from π(θ1(s)|θ2(s-1),...,θd(s-1),y) Draw θ2(s) from π(θ2(s)|θ1(s),...,θd(s-1),y) ... Draw θd(s) from π(θd(s)|θ1(s),...,θd-1(s),y) End for Example: Mining disaster change point Let’s use the dataset Mining.csv provided by Carlin, Gelfand, and Smith (1992). This dataset records the number of mining disasters per year from 1851 to 1962 in British coal mines. We assume there is an unknown structural change point in the number of mining disasters, where the parameters of the Poisson distributions change. In particular: \\[ \\begin{align*} p(y_t) = \\begin{cases} \\frac{\\exp(-\\lambda_1) \\lambda_1^{y_t}}{y_t!}, &amp; t = 1, 2, \\dots, H \\\\ \\frac{\\exp(-\\lambda_2) \\lambda_2^{y_t}}{y_t!}, &amp; t = H+1, \\dots, T \\end{cases} \\end{align*} \\] where \\(H\\) is the changing point. We use conjugate families for \\(\\lambda_l\\), \\(l = 1, 2\\), where \\(\\lambda_l \\sim G(\\alpha_{l0}, \\beta_{l0})\\), and set \\(\\pi(H) = 1 / T\\), which corresponds to a discrete uniform distribution for the change point. This implies that, a priori, we assume equal probability for any time to be the change point. The posterior distribution is: \\[ \\begin{align*} \\pi(\\lambda_1, \\lambda_2, H \\mid \\mathbf{y}) &amp;\\propto \\prod_{t=1}^{H} \\frac{\\exp(-\\lambda_1) \\lambda_1^{y_t}}{y_t!} \\prod_{t=H+1}^{T} \\frac{\\exp(-\\lambda_2) \\lambda_2^{y_t}}{y_t!} \\\\ &amp;\\times \\exp(-\\beta_{10} \\lambda_1) \\lambda_1^{\\alpha_{10}-1} \\exp(-\\beta_{20} \\lambda_2) \\lambda_2^{\\alpha_{20}-1} \\frac{1}{T} \\\\ &amp;\\propto \\exp(-H \\lambda_1) \\lambda_1^{\\sum_{t=1}^{H} y_t} \\exp(-(T-H) \\lambda_2) \\lambda_2^{\\sum_{t=H+1}^{T} y_t} \\\\ &amp;\\times \\exp(-\\beta_{10} \\lambda_1) \\lambda_1^{\\alpha_{10}-1} \\exp(-\\beta_{20} \\lambda_2) \\lambda_2^{\\alpha_{20}-1} \\end{align*} \\] Then, the conditional posterior distribution of \\(\\lambda_1 \\mid \\lambda_2, H, \\mathbf{y}\\) is: \\[ \\begin{align*} \\pi(\\lambda_1 \\mid \\lambda_2, H, \\mathbf{y}) &amp;\\propto \\exp(-(H + \\beta_{10}) \\lambda_1) \\lambda_1^{\\sum_{t=1}^{H} y_t + \\alpha_{10} - 1} \\end{align*} \\] That is, \\(\\lambda_1 \\mid \\lambda_2, H, \\mathbf{y} \\sim G(\\alpha_{1n}, \\beta_{1n})\\), \\(\\beta_{1n} = H + \\beta_{10}\\) and \\(\\alpha_{1n} = \\sum_{t=1}^{H} y_t + \\alpha_{10}\\). The conditional posterior distribution of \\(\\lambda_2\\mid \\lambda_1,H,y\\) is \\[\\begin{align*} \\pi(\\lambda_2\\mid \\lambda_1,H,y)&amp;\\propto\\exp(-((T-H)+\\beta_{20})\\lambda_2)\\lambda_2^{\\sum_{t=H+1}^T y_t+\\alpha_{20}-1}, \\end{align*}\\] that is, \\(\\lambda_2\\mid \\lambda_1,H,y\\sim G(\\alpha_{2n},\\beta_{2n})\\), \\(\\beta_{2n}=(T-H)+\\beta_{20}\\) and \\(\\alpha_{2n}=\\sum_{t=H+1}^T y_t+\\alpha_{20}\\). The conditional posterior distribution of the change point is \\[\\begin{align*} \\pi(H\\mid \\lambda_1,\\lambda_2,y)&amp;\\propto\\exp(-H\\lambda_1)\\lambda_1^{\\sum_{t=1}^H y_t}\\exp(-(T-H)\\lambda_2)\\lambda_2^{\\sum_{t=H+1}^T y_t}\\\\ &amp;\\propto \\exp(-H(\\lambda_1-\\lambda_2))\\lambda_1^{\\sum_{t=1}^H y_t}\\lambda_2^{\\sum_{t=H+1}^T y_t} \\exp(-T\\lambda_2) \\frac{\\lambda_2^{\\sum_{t=1}^H}}{\\lambda_2^{\\sum_{t=1}^H} y_t}\\\\ &amp;\\propto \\exp(-H(\\lambda_1-\\lambda_2))\\left(\\frac{\\lambda_1}{\\lambda_2}\\right)^{\\sum_{t=1}^H y_t}. \\end{align*}\\] Thus, the conditional posterior distribution of \\(H\\) is \\[\\begin{align*} \\pi(H\\mid \\lambda_1,\\lambda_2,y)=&amp; \\frac{\\exp(-H(\\lambda_1-\\lambda_2))\\left(\\frac{\\lambda_1}{\\lambda_2}\\right)^{\\sum_{t=1}^H y_t}}{\\sum_{H=1}^T \\exp(-H(\\lambda_1-\\lambda_2))\\left(\\frac{\\lambda_1}{\\lambda_2}\\right)^{\\sum_{t=1}^H y_t}}, &amp; H=1,2,\\dots,T. \\end{align*}\\] The following code shows how to do a Gibbs sampling algorithm to perform inference of this model using the hyperparameters suggested by Greenberg (2012), \\(\\alpha_{l0}=0.5\\) and \\(\\beta_{l0}=1\\), \\(l=1,2\\). rm(list = ls()); set.seed(010101) dataset&lt;-read.csv(&quot;https://raw.githubusercontent.com/besmarter/BSTApp/refs/heads/master/DataApp/MiningDataCarlin.csv&quot;,header=T) attach(dataset); str(dataset) ## &#39;data.frame&#39;: 112 obs. of 2 variables: ## $ year : int 1851 1852 1853 1854 1855 1856 1857 1858 1859 1860 ... ## $ Count: int 4 5 4 1 0 4 3 4 0 6 ... a10&lt;-0.5; a20&lt;-0.5 b10&lt;-1; b20&lt;-1 y&lt;-Count sumy&lt;-sum(Count); N&lt;-length(Count) theta1&lt;-NULL; theta2&lt;-NULL kk&lt;-NULL; k&lt;-60; S&lt;-10000 for(i in 1:S){ a1&lt;-a10+sum(y[1:k]); b1&lt;-b10+k theta11&lt;-rgamma(1,a1,b1) theta1&lt;-c(theta1,theta11) a2&lt;-a20+sum(y[(1+k):N]); b2&lt;-b20+N-k theta22&lt;-rgamma(1,a2,b2) theta2&lt;-c(theta2,theta22) pp&lt;-NULL for(l in 1:N){ p&lt;-exp(l*(theta22-theta11))*(theta11/theta22)^(sum(y[1:l])) pp&lt;-c(pp,p) } prob&lt;-pp/sum(pp); k&lt;-sample(1:N,1,prob=prob) kk&lt;-c(kk,k) } library(coda); summary(mcmc(theta1)); summary(mcmc(theta2)) ## ## Iterations = 1:10000 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 10000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## 3.051805 0.283456 0.002835 0.003054 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## 2.513 2.856 3.046 3.237 3.632 ## ## Iterations = 1:10000 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 10000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## 0.915383 0.117658 0.001177 0.001268 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## 0.6996 0.8341 0.9117 0.9932 1.1570 summary(mcmc(kk)) ## ## Iterations = 1:10000 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 10000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## 40.15020 2.48875 0.02489 0.02903 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## 36 39 40 41 46 hist(kk, main = &quot;Histogram: Posterior mean change point&quot;, xlab = &quot;Posterior mean&quot;, col = &quot;blue&quot;, breaks = 25) The posterior results indicate that the rate of disasters decrease from 3.1 to 0.92 per year in 1890. The figure shows the histogram of the posterior draws of the change point in mining disasters. 4.1.2 Metropolis-Hastings The Metropolis-Hastings (M-H) algorithm (Metropolis et al. 1953; Hastings 1970) is a general MCMC method that does not require standard closed-form solutions for the conditional posterior distributions. The key idea is to use a transition kernel whose unique invariant distribution is \\(\\pi(\\boldsymbol{\\theta} \\mid \\mathbf{y})\\). This kernel must satisfy the balancing condition, meaning that, given a realization \\(\\boldsymbol{\\theta}^{(s-1)}\\) at stage \\(s-1\\) from the stationary distribution \\(\\pi(\\boldsymbol{\\theta} \\mid \\mathbf{y})\\), we generate a candidate draw \\(\\boldsymbol{\\theta}^{c}\\) from the proposal distribution \\(q(\\boldsymbol{\\theta}^{c} \\mid \\boldsymbol{\\theta}^{(s-1)})\\) at stage \\(s\\) such that: \\[ q(\\boldsymbol{\\theta}^{c} \\mid \\boldsymbol{\\theta}^{(s-1)}) \\pi(\\boldsymbol{\\theta}^{(s-1)} \\mid \\mathbf{y}) = q(\\boldsymbol{\\theta}^{(s-1)} \\mid \\boldsymbol{\\theta}^{c}) \\pi(\\boldsymbol{\\theta}^{c} \\mid \\mathbf{y}), \\] which implies that the probability of moving from \\(\\boldsymbol{\\theta}^{(s-1)}\\) to \\(\\boldsymbol{\\theta}^{c}\\) is equal to the probability of moving from \\(\\boldsymbol{\\theta}^{c}\\) to \\(\\boldsymbol{\\theta}^{(s-1)}\\). In general, the balancing condition is not automatically satisfied, and we must introduce an acceptance probability \\(\\alpha(\\boldsymbol{\\theta}^{(s-1)}, \\boldsymbol{\\theta}^{c})\\) to ensure that the condition holds: \\[ q(\\boldsymbol{\\theta}^{c} \\mid \\boldsymbol{\\theta}^{(s-1)}) \\pi(\\boldsymbol{\\theta}^{(s-1)} \\mid \\mathbf{y}) \\alpha(\\boldsymbol{\\theta}^{(s-1)}, \\boldsymbol{\\theta}^{c}) = q(\\boldsymbol{\\theta}^{(s-1)} \\mid \\boldsymbol{\\theta}^{c}) \\pi(\\boldsymbol{\\theta}^{c} \\mid \\mathbf{y}). \\] Thus, the acceptance probability is given by: \\[ \\alpha(\\boldsymbol{\\theta}^{(s-1)}, \\boldsymbol{\\theta}^{c}) = \\min\\left\\{\\frac{q(\\boldsymbol{\\theta}^{(s-1)} \\mid \\boldsymbol{\\theta}^{c}) \\pi(\\boldsymbol{\\theta}^{c} \\mid \\mathbf{y})}{q(\\boldsymbol{\\theta}^{c} \\mid \\boldsymbol{\\theta}^{(s-1)}) \\pi(\\boldsymbol{\\theta}^{(s-1)} \\mid \\mathbf{y})}, 1\\right\\}, \\] where \\(q(\\boldsymbol{\\theta}^{c} \\mid \\boldsymbol{\\theta}^{(s-1)})\\) and \\(\\pi(\\boldsymbol{\\theta}^{(s-1)} \\mid \\mathbf{y})\\) must be nonzero, as transitioning from \\(\\boldsymbol{\\theta}^{(s-1)}\\) to \\(\\boldsymbol{\\theta}^{c}\\) is only possible under these conditions. Algorithm 2 shows how to implement a Metropolis-Hastings algorithm. The number of iterations (\\(S\\)) is chosen to ensure convergence to the stationary distribution. Algorithm: Metropolis-Hastings Set θ(0) in the support of π(θ|y) For s=1,2,...,S do Draw θc from q(θc|θ(s-1)) Calculate α(θ(s-1),θc)=min((q(θ(s-1)|θc)π(θc|y))/(q(θc|θ(s-1))π(θ(s-1)|y)),1) Draw U from U(0,1) θ(s)= θc if U (s-1),θc) θ(s)= θ(s-1) otherwise End for Some remarks: First, we do not need to know the marginal likelihood to implement the M-H algorithm, as it cancels out when calculating the acceptance probability. Specifically, given that \\(\\pi(\\boldsymbol{\\theta} \\mid \\boldsymbol{y}) \\propto \\pi(\\boldsymbol{\\theta}) \\times p(\\boldsymbol{y} \\mid \\boldsymbol{\\theta})\\), we can use the right-hand side expression to compute the acceptance probability. Second, the Gibbs sampling algorithm is a particular case of the M-H algorithm where the acceptance probability is equal to 1 (Andrew Gelman and Rubin (1992) and Christian P. Robert and Casella (2011), see Exercise 2). Third, we can combine the M-H and Gibbs sampling algorithms when dealing with relatively complex posterior distributions. Specifically, the Gibbs sampling algorithm can be used for blocks with conditional posterior distributions in standard closed forms, while the M-H algorithm is applied to sample from conditional posterior distributions that do not have standard forms. This approach is known as the M-H within Gibbs sampling algorithm. Fourth, we can note that the transition kernel in the M-H algorithm is a mixture of a continuous density (\\(q(\\boldsymbol{\\theta}^c \\mid \\boldsymbol{\\theta}^{(s-1)})\\)) and a probability mass function (\\(\\alpha(\\boldsymbol{\\theta}^{(s-1)}, \\boldsymbol{\\theta}^c)\\)) Siddhartha Chib and Greenberg (1995). Fifth, a crucial point associated with the proposal densities is the acceptance probability. Low or high acceptance probabilities are not ideal. A low rate implies poor mixing, meaning the chain does not move effectively through the support of the posterior distribution. Conversely, a high acceptance rate implies that the chain will converge too slowly. A sensible value depends on the dimension of the parameter space. A rule of thumb is that if the dimension is less than or equal to 2, the acceptance rate should be around 0.50. If the dimension is greater than 2, the acceptance rate should be approximately 0.25 Roberts, Gelman, and Gilks (1997). For technical details of the Metropolis-Hastings algorithm, see Christian P. Robert and Casella (2011), Chap. 7. Regarding the proposal density, it must be positive everywhere the posterior distribution is positive. This ensures that the Markov chain can explore the entire support of the posterior distribution. Additionally, the proposal density must allow the Markov chain to reach any region of the posterior distribution’s support. There are three standard approaches for choosing the proposal density: the independent proposal, the random walk proposal, and the tailored proposal. In the independent proposal, \\(q(\\boldsymbol{\\theta}^c \\mid \\boldsymbol{\\theta}^{(s-1)}) = q(\\boldsymbol{\\theta}^c)\\), which implies that \\[ \\alpha(\\boldsymbol{\\theta}^{(s-1)}, \\boldsymbol{\\theta}^c) = \\min\\left\\{\\frac{q(\\boldsymbol{\\theta}^{(s-1)}) \\pi(\\boldsymbol{\\theta}^c \\mid \\boldsymbol{y})}{q(\\boldsymbol{\\theta}^c) \\pi(\\boldsymbol{\\theta}^{(s-1)} \\mid \\boldsymbol{y})}, 1\\right\\}. \\] In this case, a move from \\(\\boldsymbol{\\theta}^{(s-1)}\\) to \\(\\boldsymbol{\\theta}^c\\) is always accepted if \\(q(\\boldsymbol{\\theta}^{(s-1)}) \\pi(\\boldsymbol{\\theta}^c \\mid \\boldsymbol{y}) \\geq q(\\boldsymbol{\\theta}^c) \\pi(\\boldsymbol{\\theta}^{(s-1)} \\mid \\boldsymbol{y})\\). In the random walk proposal, \\(\\boldsymbol{\\theta}^c = \\boldsymbol{\\theta}^{(s-1)} + \\boldsymbol{\\epsilon}\\), where \\(\\boldsymbol{\\epsilon}\\) is a random perturbation. If \\(p(\\boldsymbol{\\epsilon}) = p(-\\boldsymbol{\\epsilon})\\), meaning the distribution \\(p(\\boldsymbol{\\epsilon})\\) is symmetric around zero, then \\(q(\\boldsymbol{\\theta}^c \\mid \\boldsymbol{\\theta}^{(s-1)}) = q(\\boldsymbol{\\theta}^{(s-1)} \\mid \\boldsymbol{\\theta}^c)\\). This was the original Metropolis algorithm Metropolis et al. (1953). Thus, the acceptance rate is \\[ \\alpha(\\boldsymbol{\\theta}^{(s-1)}, \\boldsymbol{\\theta}^c) = \\min\\left\\{\\frac{\\pi(\\boldsymbol{\\theta}^c \\mid \\boldsymbol{y})}{\\pi(\\boldsymbol{\\theta}^{(s-1)} \\mid \\boldsymbol{y})}, 1\\right\\}. \\] In this case, a move from \\(\\boldsymbol{\\theta}^{(s-1)}\\) to \\(\\boldsymbol{\\theta}^c\\) is always accepted if \\(\\pi(\\boldsymbol{\\theta}^c \\mid \\boldsymbol{y}) \\geq \\pi(\\boldsymbol{\\theta}^{(s-1)} \\mid \\boldsymbol{y})\\). In the tailored proposal, the density is designed to have fat tails, is centered at the mode of the posterior distribution, and its scale matrix is given by the negative inverse Hessian matrix evaluated at the mode. Specifically, for two blocks, the log posterior distribution is maximized with respect to \\(\\boldsymbol{\\theta}_1\\) given \\(\\boldsymbol{\\theta}_2\\). This process is repeated at each iteration of the algorithm because \\(\\boldsymbol{\\theta}_2\\) changes at different stages. As a result, the algorithm can be slow since the optimization process is computationally demanding (see Greenberg (2012), Chaps. 7 and 9 for examples). A sensible recommendation when performing the M-H algorithm is to use a random walk proposal such that \\(\\boldsymbol{\\epsilon} \\sim N(\\boldsymbol{0}, c^2 \\boldsymbol{\\Sigma})\\), where \\(\\boldsymbol{\\Sigma}\\) is the negative inverse Hessian matrix evaluated at the mode, that is, maximize with respect to all parameters, and set \\(c \\approx 2.4 / \\sqrt{\\text{dim}(\\boldsymbol{\\theta})}\\), which is the most efficient scale compared to independent sampling Andrew Gelman et al. (2021), Chap. 12. After some iterations of the algorithm, adjust the scale matrix \\(\\boldsymbol{\\Sigma}\\) as before, and increase or decrease \\(c\\) if the acceptance rate of the simulations is too high or low, respectively. The objective is to bring the acceptance rate to the stated rule of thumb: if the dimension is less than or equal to 2, the acceptance rate should be around 0.50, and if the dimension is greater than 2, the acceptance rate should be around 0.25. Once this is achieved, we should run the algorithm without modifications and use this part of the algorithm to perform inference. Example: Ph.D. students sleeping hours continues In the Ph.D. students sleeping hours exercise of Chapter 3 we get a posterior distribution that is Beta with parameters 16.55 and 39.57. We can sample from this posterior distribution using the function rbeta from R. However, we want to compare the performance of a M-H algorithm using as proposal density a \\(U(0,1)\\) distribution. The following code shows how to do a M-H algorithm to sample from the beta distribution using the uniform distribution. rm(list = ls()); set.seed(010101) an &lt;- 16.55; bn &lt;- 39.57 S &lt;- 100000; p &lt;- runif(S); accept &lt;- rep(0, S) for (s in 2:S){ pc &lt;- runif(1) # Candidate a &lt;- dbeta(pc, an, bn)/dbeta(p[s-1], an, bn) # Acceptance rate U &lt;- runif(1) if(U &lt;= a){ p[s] &lt;- pc accept[s] &lt;- 1 }else{ p[s] &lt;- p[s-1] accept[s] &lt;- 0 } } mean(accept); mean(p); sd(p) ## [1] 0.19378 ## [1] 0.2949128 ## [1] 0.06087849 an/(an + bn); (an*bn/((an+bn)^2*(an+bn+1)))^0.5 # Population values ## [1] 0.2949038 ## [1] 0.06033513 h &lt;- hist(p, breaks=50, col=&quot;blue&quot;, xlab=&quot;Proportion Ph.D. students sleeping at least 6 hours&quot;, main=&quot;Beta draws from a Metropolis-Hastings algorithm&quot;) pfit &lt;- seq(min(p),max(p),length=50) yfit&lt;-dbeta(pfit, an, bn) yfit &lt;- yfit*diff(h$mids[1:2])*length(p) lines(pfit, yfit, col=&quot;red&quot;, lwd=2) The results indicate that the mean and standard deviation obtained from the posterior draws are similar to the population values. Furthermore, this figure presents the histogram of the posterior draws alongside the density of the beta distribution, demonstrating a good match between them. 4.1.3 Hamiltonian Monte Carlo Hamiltonian Monte Carlo (HMC) was proposed by Duane et al. (1987) and later introduced to the statistical community by Neal (1996). HMC extends the Metropolis algorithm to efficiently explore the parameter space by introducing momentum variables, which help overcome the random walk behavior of Gibbs sampling and the Metropolis-Hastings algorithm. Known also as hybrid Monte Carlo, HMC is particularly advantageous for high-dimensional posterior distributions, as it reduces the risk of getting stuck in local modes and significantly improves mixing (Neal 2011). However, HMC is designed to work with strictly positive target densities. Therefore, transformations are required to handle bounded parameters, such as variances and proportions. For example, logarithmic and logit transformations can be applied. These transformations necessitate the use of the change-of-variable theorem to compute the log posterior density and its gradient, which are essential for implementing the HMC algorithm. HMC leverages concepts from physics, specifically Hamiltonian mechanics, to propose transitions in the Markov chain. In Hamiltonian mechanics, two key variables define the total energy of the system: the position (\\(\\boldsymbol{\\theta}\\)) and the momentum (\\(\\boldsymbol{\\delta}\\)). The Hamiltonian represents the total energy of the system, consisting of potential energy (energy due to position) and kinetic energy (energy associated with motion). The objective is to identify trajectories that preserve the system’s total energy, meaning the Hamiltonian remains invariant, while avoiding trajectories that do not. This approach enhances the acceptance rate of proposed transitions. To implement HMC, we solve the differential equations derived from the Hamiltonian, which involve derivatives with respect to position and momentum. However, these equations rarely have analytical solutions, requiring numerical methods for approximation. This necessitates discretizing Hamilton’s equations, which introduces errors. To mitigate these errors, HMC uses the leapfrog integrator, a numerical method with smaller errors compared to simpler approaches like the Euler method. HMC uses a momentum variable (\\(\\delta_k\\)) for each \\(\\theta_k\\), so that the transition kernel of \\(\\boldsymbol{\\theta}\\) is determined by \\(\\boldsymbol{\\delta}\\). Both vectors are updated using a Metropolis algorithm at each stage such that the distribution of \\(\\boldsymbol{\\theta}\\) remains invariant (Neal 2011). The joint density in HMC is given by \\(p(\\boldsymbol{\\theta}, \\boldsymbol{\\delta} \\mid \\boldsymbol{y}) = \\pi(\\boldsymbol{\\theta} \\mid \\boldsymbol{y}) \\times p(\\boldsymbol{\\delta})\\), where \\(\\boldsymbol{\\delta} \\sim N(\\boldsymbol{0}, \\boldsymbol{M})\\), and \\(\\boldsymbol{M}\\) is a diagonal matrix such that \\(\\delta_k \\sim N(0, M_{kk})\\). Algorithm 3 outlines the HMC implementation. The gradient vector \\(\\frac{d \\log(\\pi(\\boldsymbol{\\theta} \\mid \\boldsymbol{y}))}{d \\boldsymbol{\\theta}}\\) must be computed analytically, as using finite differences can be computationally expensive. However, it is advisable to verify the analytical calculations by evaluating the gradient at the maximum posterior estimate, where the function should return values close to 0, or by comparing results with finite differences at a few points. Algorithm: Hamiltonian Monte Carlo Set θ(0) in the support of π(θ|y), and set step size ε, number of leapfrog steps L, and total iterations S Draw δ(0) from N(0, M) For s=1,2,...,S do For l=1,2,...,L do if l=1 then δc ← δ(s-1) + 0.5 ε dlog(π(θ|y))/dθ θc ← θ(s-1) + ε M-1 δc else if l=2,...,L-1 then δc ← δc + ε dlog(π(θ|y))/dθ θc ← θc + ε M-1 δc else δc ← δc + 0.5 ε dlog(π(θ|y))/dθ θc ← θc + ε M-1 δc End if End if End for Calculate α([θ, δ](s-1),[θ, δ]c)=min((p(δc)π(θc|y))/(p(δ(s-1))π(θ(s-1)|y)),1) Draw U from U(0,1) θ(s)= θc if U (s-1),[θ, δ]c) θ(s)= θ(s-1) otherwise End for Note that HMC does not require the marginal likelihood, as neither the gradient vector \\(\\frac{d \\log(\\pi(\\boldsymbol{\\theta} \\mid \\boldsymbol{y}))}{d \\boldsymbol{\\theta}}\\) nor the acceptance rate depend on it. That is, we can use only \\(\\pi(\\boldsymbol{\\theta}) \\times p(\\boldsymbol{y} \\mid \\boldsymbol{\\theta})\\) to implement HMC. In addition, we do not retain \\(\\boldsymbol{\\delta}\\) after it is updated at the beginning of each iteration, as it is not required subsequently. To begin, the step size (\\(\\epsilon\\)) can be drawn randomly from a uniform distribution between 0 and \\(2\\epsilon_0\\), and the number of leapfrog steps (\\(L\\)) is set as the largest integer near \\(1/\\epsilon\\), ensuring \\(\\epsilon \\times L \\approx 1\\). We need to set \\(\\boldsymbol{M}\\) to be the inverse of the posterior covariance matrix evaluated at the maximum a posteriori estimate under this setting. The acceptance rate should be checked, with the optimal rate around 65% (Andrew Gelman et al. 2021). If the acceptance rate is much higher than 65%, increase \\(\\epsilon_0\\); if it is much lower, decrease it. This strategy may not always work, and alternative strategies can be tested, such as setting \\(\\boldsymbol{M} = \\boldsymbol{I}\\) and fine-tuning \\(\\epsilon\\) and \\(L\\) to achieve an acceptance rate near 65%. Finally, the number of iterations (\\(S\\)) is chosen to ensure convergence to the stationary distribution. Example: Sampling from a bi-variate Gaussian distribution As a toy example, let’s compare the Gibbs sampling, M-H, and HMC algorithms when the posterior distribution is a bi-variate Gaussian distribution with mean \\(\\boldsymbol{0}\\) and covariance matrix \\(\\boldsymbol{\\Sigma} = \\begin{bmatrix} 1 &amp; \\rho \\\\ \\rho &amp; 1 \\end{bmatrix}\\). Let’s set \\(\\rho = 0.98\\). The Gibbs sampler requires the conditional posterior distributions, which in this case are \\(\\theta_1 \\mid \\theta_2 \\sim N(\\rho \\theta_2, 1 - \\rho^2)\\) and \\(\\theta_2 \\mid \\theta_1 \\sim N(\\rho \\theta_1, 1 - \\rho^2)\\). We use the random walk proposal distribution for the M-H algorithm, where \\(\\boldsymbol{\\theta}^c \\sim N(\\boldsymbol{\\theta}^{(s-1)}, \\text{diag}\\left\\{0.18^2\\right\\})\\). We set \\(\\epsilon = 0.05\\), \\(L = 20\\), and \\(\\boldsymbol{M} = \\boldsymbol{I}_2\\) for the HMC algorithm, and given that \\(\\pi(\\boldsymbol{\\theta} \\mid \\boldsymbol{y}) \\propto \\exp\\left\\{-\\frac{1}{2} \\boldsymbol{\\theta}^{\\top} \\boldsymbol{\\Sigma}^{-1} \\boldsymbol{\\theta}\\right\\}\\), then \\(\\frac{d \\log(\\pi(\\boldsymbol{\\theta} \\mid \\boldsymbol{y}))}{d \\boldsymbol{\\theta}} = -\\boldsymbol{\\Sigma}^{-1} \\boldsymbol{\\theta}\\). The following code shows how to implement the Gibbs sampler, the random walk M-H algorithm, and the HMC in this example such that the effective number of posterior draws is 400. rm(list = ls()); set.seed(010101) # Gibbs sampler Gibbs &lt;- function(theta, rho){ thetal &lt;- rnorm(1, mean = rho*theta, sd = (1- rho^2)^0.5) return(thetal) } # Metropolis-Hastings MH &lt;- function(theta, rho, sig2){ SIGMA &lt;- matrix(c(1, rho, rho, 1), 2, 2) SIGMAc &lt;- matrix(c(1, sig2, sig2, 1), 2, 2) thetac &lt;- MASS::mvrnorm(1, mu = theta, Sigma = SIGMAc) a &lt;- mvtnorm::dmvnorm(thetac, c(0, 0), SIGMA)/mvtnorm::dmvnorm(theta, c(0, 0), SIGMA) U &lt;- runif(1) if(U &lt;= a){ theta &lt;- thetac accept &lt;- 1 }else{ theta &lt;- theta accept &lt;- 0 } return(list(theta = theta, accept = accept)) } # Hamiltonian Monte Carlo HMC &lt;- function(theta, rho, epsilon, M){ SIGMA &lt;- matrix(c(1, rho, rho, 1), 2, 2) L &lt;- ceiling(1/epsilon) Minv &lt;- solve(M); thetat &lt;- theta K &lt;- length(thetat) mom &lt;- t(mvtnorm::rmvnorm(1, rep(0, K), M)) logPost_Mom_t &lt;- mvtnorm::dmvnorm(t(theta), rep(0, K), SIGMA, log = TRUE) + mvtnorm::dmvnorm(t(mom), rep(0, K), M, log = TRUE) for(l in 1:L){ if(l == 1 | l == L){ mom &lt;- mom + 0.5*epsilon*(-solve(SIGMA)%*%theta) theta &lt;- theta + epsilon*Minv%*%mom }else{ mom &lt;- mom + epsilon*(-solve(SIGMA)%*%theta) theta &lt;- theta + epsilon*Minv%*%mom } } logPost_Mom_star &lt;- mvtnorm::dmvnorm(t(theta), rep(0, K), SIGMA, log = TRUE) + mvtnorm::dmvnorm(t(mom), rep(0, K), M, log = TRUE) alpha &lt;- min(1, exp(logPost_Mom_star-logPost_Mom_t)) u &lt;- runif(1) if(u &lt;= alpha){ thetaNew &lt;- c(theta) }else{ thetaNew &lt;- thetat } rest &lt;- list(theta = thetaNew, Prob = alpha) return(rest) } # Hyperparameters rho &lt;- 0.98; sig2 &lt;- 0.18^2 # Posterior draws Gibbs and M-H S &lt;- 8000; thin &lt;- 20; K &lt;- 2 thetaPostGibbs &lt;- matrix(NA, S, K) thetaPostMH &lt;- matrix(NA, S, K) AcceptMH &lt;- rep(NA, S) thetaGibbs &lt;- c(-2, 3); thetaMH &lt;- c(-2, 3) for(s in 1:S){ theta1 &lt;- Gibbs(thetaGibbs[2], rho) theta2 &lt;- Gibbs(theta1, rho) thetaGibbs &lt;- c(theta1, theta2) ResMH &lt;- MH(thetaMH, rho, sig2) thetaMH &lt;- ResMH$theta thetaPostGibbs[s,] &lt;- thetaGibbs thetaPostMH[s,] &lt;- thetaMH AcceptMH[s] &lt;- ResMH$accept } keep &lt;- seq(0, S, thin) mean(AcceptMH[keep[-1]]) ## [1] 0.165 thetaPostGibbsMCMC &lt;- coda::mcmc(thetaPostGibbs[keep[-1],]) summary(thetaPostGibbsMCMC) ## ## Iterations = 1:400 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 400 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## [1,] 0.09561 0.9230 0.04615 0.06976 ## [2,] 0.09338 0.9258 0.04629 0.07029 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## var1 -1.748 -0.4606 0.07596 0.6520 1.937 ## var2 -1.652 -0.5319 0.10553 0.6702 1.881 coda::autocorr.plot(thetaPostGibbsMCMC) thetaPostMHMCMC &lt;- coda::mcmc(thetaPostMH[keep[-1],]) plot(thetaPostMHMCMC) coda::autocorr.plot(thetaPostMHMCMC) # Posterior draws HMC S &lt;- 400;epsilon &lt;- 0.05; L &lt;- ceiling(1/epsilon); M &lt;- diag(2) thetaPostHMC &lt;- matrix(NA, S, K) ProbAcceptHMC &lt;- rep(NA, S) thetaHMC &lt;- c(-2, 3) for(s in 1:S){ ResHMC &lt;- HMC(theta = thetaHMC, rho, epsilon, M) thetaHMC &lt;- ResHMC$theta thetaPostHMC[s,] &lt;- thetaHMC ProbAcceptHMC[s] &lt;- ResHMC$Prob } thetaPostHMCMCMC &lt;- coda::mcmc(thetaPostHMC) plot(thetaPostHMCMCMC); coda::autocorr.plot(thetaPostHMCMCMC) summary(ProbAcceptHMC) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.2422 0.8005 0.9705 0.8747 1.0000 1.0000 #Figure df &lt;- as.data.frame(cbind(1:S, thetaPostHMC[,1], thetaPostMH[keep[-1],1], thetaPostGibbs[keep[-1],1])) colnames(df) &lt;- c(&quot;Iter&quot;, &quot;HMC&quot;, &quot;MH&quot;, &quot;Gibbs&quot;) library(latex2exp); library(ggpubr) g1 &lt;- ggplot(df, aes(x= Iter)) + geom_point(aes(y=HMC), colour=&quot;black&quot;) + labs(x = &quot;Iteration&quot;, y = TeX(&quot;$\\\\theta_{1}$&quot;), title = &quot;HMC algorithm&quot;) g2 &lt;- ggplot(df, aes(x= Iter)) + geom_point(aes(y=MH), colour=&quot;black&quot;) + labs(x = &quot;Iteration&quot;, y = TeX(&quot;$\\\\theta_{1}$&quot;), title = &quot;M-H algorithm&quot;) g3 &lt;- ggplot(df, aes(x= Iter)) + geom_point(aes(y=Gibbs), colour=&quot;black&quot;) + labs(x = &quot;Iteration&quot;, y = TeX(&quot;$\\\\theta_{1}$&quot;), title = &quot;Gibbs sampling&quot;) ggarrange(g3, g2, g1, labels = c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;), ncol = 3, nrow = 1) The figure shows the posterior draws of \\(\\theta_1\\) using the Gibbs sampler (Panel A, left), the Metropolis-Hastings algorithm (Panel B, middle), and the Hamiltonian Monte Carlo (Panel C, right). The convergence diagnostic plots (no shown) suggests that the three algorithms perform a good job. Although, the acceptance rate in HMC is higher than the M-H due to the HMC producing larger changes in \\(\\boldsymbol{\\theta}\\) than a corresponding number of random-walk M-H iterations (Neal 2011). References "],["sec52.html", "4.2 Importance sampling", " 4.2 Importance sampling Up to this section, we have introduced MCMC methods for sampling from the posterior distribution when it does not have a standard closed form. However, MCMC methods have some limitations. First, the samples are generated sequentially, which complicates parallel computing. Although multiple MCMC chains can be run simultaneously, this approach—often referred to as brute-force parallelization—does not fully address the sequential nature of individual chains. Second, consecutive samples are correlated, which reduces the effective sample size and complicates convergence diagnostics. Thus, in this section, we introduce importance sampling (IS), a simulation method for drawing samples from the posterior distribution that avoids these limitations. Unlike MCMC, IS does not require satisfying the balancing condition, making it conceptually and mathematically simpler to implement in certain situations. Moreover, importance weights can be reused to analyze posterior quantities, compute marginal likelihoods, compare models, approximate new target distributions, and allow for straightforward parallelization in large-scale problems. However, the critical challenge in IS lies in selecting an appropriate proposal distribution. This involves satisfying both support and stability conditions, which can be difficult to achieve, particularly in high-dimensional problems. In such cases, MCMC methods may be more suitable. The starting point is evaluating the integral: \\[\\begin{align} \\mathbb{E}_{\\pi}[h(\\boldsymbol{\\theta})] &amp;= \\int_{\\Theta} h(\\boldsymbol{\\theta}) \\pi(\\boldsymbol{\\theta} \\mid y) d\\boldsymbol{\\theta}, \\tag{4.1} \\end{align}\\] where \\(\\mathbb{E}_{\\pi}\\) denotes expected value under the posterior distribution. Thus, we can approximate Equation (4.1) by \\[\\begin{align} \\bar{h}(\\boldsymbol{\\theta})_S &amp;= \\frac{1}{S} \\sum_{s=1}^S h(\\boldsymbol{\\theta}^{(s)}), \\tag{4.2} \\end{align}\\] where \\(\\boldsymbol{\\theta}^{(s)}\\) are draws from \\(\\pi(\\boldsymbol{\\theta} \\mid y)\\). The strong law of large numbers shows that \\(\\bar{h}(\\boldsymbol{\\theta})_S\\) converges (almost surely) to \\(\\mathbb{E}_{\\pi}[h(\\boldsymbol{\\theta})]\\) as \\(S \\to \\infty\\). The challenge arises when we do not know how to obtain samples from \\(\\pi(\\boldsymbol{\\theta}\\mid \\boldsymbol{y})\\). The ingenious idea is to express Equation (4.1) in a different way using the importance sampling fundamental identity (Christian P. Robert and Casella 2011): \\[\\begin{align} \\mathbb{E}_{\\pi}[h(\\boldsymbol{\\theta})] &amp;= \\int_{\\boldsymbol{\\Theta}} h(\\boldsymbol{\\theta}) \\pi(\\boldsymbol{\\theta}\\mid \\boldsymbol{y})\\frac{q(\\boldsymbol{\\theta})}{q(\\boldsymbol{\\theta})}d\\boldsymbol{\\theta} \\nonumber \\\\ &amp;= \\mathbb{E}_{q}\\left[\\frac{h(\\boldsymbol{\\theta})\\pi(\\boldsymbol{\\theta}\\mid \\boldsymbol{y})}{q(\\boldsymbol{\\theta})}\\right], \\tag{4.3} \\end{align}\\] where \\(q(\\boldsymbol{\\theta})\\) is the proposal distribution. Thus, we have \\[\\begin{align} \\frac{1}{S}\\sum_{s=1}^S \\left[\\frac{h(\\boldsymbol{\\theta}^{(s)})\\pi(\\boldsymbol{\\theta}^{(s)}\\mid \\boldsymbol{y})}{q(\\boldsymbol{\\theta}^{(s)})}\\right] &amp;= \\frac{1}{S}\\sum_{s=1}^S h(\\boldsymbol{\\theta}^{(s)})w(\\boldsymbol{\\theta}^{(s)}), \\end{align}\\] where \\(w(\\boldsymbol{\\theta}^{(s)})= \\left[\\frac{\\pi(\\boldsymbol{\\theta}^{(s)}\\mid \\boldsymbol{y})}{q(\\boldsymbol{\\theta}^{(s)})}\\right]\\) are called the importance weights, and \\(\\boldsymbol{\\theta}^{(s)}\\) are samples from the proposal distribution. This expression converges to \\(\\mathbb{E}_{\\pi}[h(\\boldsymbol{\\theta})]\\) given that the support of \\(q(\\boldsymbol{\\theta})\\) includes the support of \\(\\pi(\\boldsymbol{\\theta}\\mid \\boldsymbol{y})\\). There are many proposal distributions that satisfy the support condition. However, the stability of the method depends heavily on the variability of the importance weights. In particular, the variance of \\[\\begin{align} \\frac{1}{S}\\sum_{s=1}^S h(\\boldsymbol{\\theta}^{(s)})w(\\boldsymbol{\\theta}^{(s)}) \\end{align}\\] can be large if the proposal distribution has lighter tails than the posterior distribution. In this case, the weights \\(w(\\boldsymbol{\\theta}^{(s)})\\) will vary widely, assigning too much importance to a few values of \\(\\boldsymbol{\\theta}^{(s)}\\). Thus, it is important to use proposals that have thicker tails than the posterior distribution. In any case, we should check the adequacy of the proposal distribution by analyzing the behavior of the importance weights. If they are distributed more or less uniformly over the support, it is a good sign. Consider, for instance, the extreme case where \\(q(\\boldsymbol{\\theta}) = \\pi(\\boldsymbol{\\theta}\\mid \\boldsymbol{y})\\), then \\(w(\\boldsymbol{\\theta}^{(s)}) = 1\\) everywhere. A natural choice in Bayesian inference is to use the prior distribution as the proposal, given that it is a proper density function. The prior distribution typically has heavier tails than the posterior by construction, and it is usually a distribution that allows for easy sampling. The most relevant point for us is that importance sampling provides a way to simulate from the posterior distribution when there is no closed-form solution. The method generates samples \\(\\boldsymbol{\\theta}^{(s)}\\) from \\(q(\\boldsymbol{\\theta})\\) and computes the importance weights \\(w(\\boldsymbol{\\theta}^{(s)})\\). Thus, if we resample with replacement from \\(\\boldsymbol{\\theta}^{(1)},\\boldsymbol{\\theta}^{(2)},\\dots,\\boldsymbol{\\theta}^{(S)}\\), selecting \\(\\boldsymbol{\\theta}^{(s)}\\) with probability proportional to \\(w(\\boldsymbol{\\theta}^{(s)})\\), we would get a sample \\(\\boldsymbol{\\theta}^{*(1)},\\boldsymbol{\\theta}^{*(2)},\\dots,\\boldsymbol{\\theta}^{*(L)}\\) of size \\(L\\) from \\(\\pi(\\boldsymbol{\\theta}\\mid \\boldsymbol{y})\\) (A. F. Smith and Gelfand 1992; Donald B. Rubin 1988). This is named sampling/importance resampling (SIR) algorithm. Observe that the number of times \\(L^{(s)}\\) each particular point \\(\\boldsymbol{\\theta}^{(s)}\\) is selected follows a binomial distribution with size \\(L\\), and probabilities proportional to \\(w^{(s)}\\). Consequently, the vector \\(L_{\\boldsymbol{\\theta}} = \\left\\{L_{\\boldsymbol{\\theta}^1}, L_{\\boldsymbol{\\theta}^2}, \\dots, L_{\\boldsymbol{\\theta}^S}\\right\\}\\) follows a multinomial distribution with \\(L\\) trials and probabilities proportional to \\(w(\\boldsymbol{\\theta}^{(s)})\\), \\(s = 1, 2, \\dots, S\\) (Olivier Cappé, Godsill, and Moulines 2007). Therefore, the resampling step ensures that points in the first-stage sample with small importance weights are more likely to be discarded, while points with high weights are replicated in proportion to their importance weights. In most applications, it is typical to have \\(S \\gg L\\). The intuition is that importance weights are scaling factors that correct for the bias introduced by drawing from \\(q(\\boldsymbol{\\theta}^{(s)})\\) instead of \\(\\pi(\\boldsymbol{\\theta}^{(s)}\\mid \\boldsymbol{y})\\); thus, when combined, the samples and weights effectively recreate the posterior distribution, ensuring the resampled data set reflects the posterior. Let’s prove this: \\[\\begin{align*} P(\\boldsymbol{\\theta}^*\\in A) &amp;=\\frac{1}{S}\\sum_{s=1}^S{w}^{(s)}\\mathbb{1}_{A}(\\boldsymbol{\\theta}^{(s)})\\\\ &amp;\\rightarrow \\mathbb{E}_q\\left[\\mathbb{1}_{\\in A}(\\boldsymbol{\\theta})\\frac{\\pi(\\boldsymbol{\\theta}\\mid \\boldsymbol{y})}{q(\\boldsymbol{\\theta})}\\right]\\\\ &amp;=\\int_{A}\\left[\\frac{\\pi(\\boldsymbol{\\theta}\\mid \\boldsymbol{y})}{q(\\boldsymbol{\\theta})}\\right]q(\\boldsymbol{\\theta})d\\boldsymbol{\\theta}\\\\ &amp;=\\int_{A}\\pi(\\boldsymbol{\\theta}\\mid \\boldsymbol{y})d\\boldsymbol{\\theta}. \\end{align*}\\] Thus, \\(\\boldsymbol{\\theta}^*\\) is approximately distributed as an observation from \\(\\pi(\\boldsymbol{\\theta}\\mid \\boldsymbol{y})\\). However, the weights \\(\\pi(\\boldsymbol{\\theta}^{(s)}\\mid \\boldsymbol{y})/(S q(\\boldsymbol{\\theta}^{(s)}))\\) do not sum up to 1, and we need to standardize them: \\[ w^*(\\boldsymbol{\\theta}^{(s)})=\\frac{\\frac{1}{S} w(\\boldsymbol{\\theta}^{(s)})}{\\frac{1}{S}\\sum_{s=1}^S w(\\boldsymbol{\\theta}^{(s)})}. \\] Note that we could alternatively arrive at these weights as follows: \\[\\begin{align*} \\mathbb{E}_{\\pi}[h(\\boldsymbol{\\theta})]&amp;=\\int_{\\boldsymbol{\\Theta}} \\left[\\frac{h(\\boldsymbol{\\theta}) \\pi(\\boldsymbol{\\theta}\\mid \\boldsymbol{y})}{q(\\boldsymbol{\\theta})}\\right]q(\\boldsymbol{\\theta})d\\boldsymbol{\\theta}\\\\ &amp;=\\frac{\\int_{\\boldsymbol{\\Theta}}\\left[\\frac{h(\\boldsymbol{\\theta}) \\pi(\\boldsymbol{\\theta}\\mid \\boldsymbol{y})}{q(\\boldsymbol{\\theta})}\\right] q(\\boldsymbol{\\theta})d\\boldsymbol{\\theta}}{\\int_{\\boldsymbol{\\Theta}}\\left[\\frac{ \\pi(\\boldsymbol{\\theta}\\mid \\boldsymbol{y})}{q(\\boldsymbol{\\theta})}\\right] q(\\boldsymbol{\\theta})d\\boldsymbol{\\theta}}. \\end{align*}\\] Then, \\[ \\frac{\\frac{1}{S}\\sum_{s=1}^S h(\\boldsymbol{\\theta}^{(s)})w(\\boldsymbol{\\theta}^{(s)})}{\\frac{1}{S}\\sum_{s=1}^S w(\\boldsymbol{\\theta}^{(s)})}= \\sum_{s=1}^S h(\\boldsymbol{\\theta}^{(s)})w^*(\\boldsymbol{\\theta}^{(s)}). \\] This alternative expression also converges (almost surely) to \\(\\mathbb{E}_{\\pi}[h(\\boldsymbol{\\theta})]\\). In addition, this expression is very useful because if we do not have the marginal likelihood in the posterior distribution, this constant cancels out in \\(w^*(\\boldsymbol{\\theta}^{(s)})\\). Although this estimator is biased, the bias is small and provides good gains in variance reduction compared with the non-standardized option (Christian P. Robert and Casella 2011). A nice by-product of implementing IS is that it easily allows the calculation of the marginal likelihood. In particular, we know from Bayes’ rule that \\[ p(\\boldsymbol{y})^{-1}=\\frac{\\pi(\\boldsymbol{\\theta}\\mid \\boldsymbol{y})}{p(\\boldsymbol{y}\\mid \\boldsymbol{\\theta})\\times \\pi(\\boldsymbol{\\theta})}, \\] then, \\[\\begin{align*} \\int_{\\boldsymbol{\\Theta}}p(\\boldsymbol{y})^{-1}q(\\boldsymbol{\\theta})d\\boldsymbol{\\theta} &amp;=\\int_{{\\Theta}}\\frac{q(\\boldsymbol{\\theta})}{p(\\boldsymbol{y}\\mid \\boldsymbol{\\theta})\\times \\pi(\\boldsymbol{\\theta})}\\pi(\\boldsymbol{\\theta}\\mid \\boldsymbol{y})d\\boldsymbol{\\theta}\\\\ &amp;=\\mathbb{E}_{\\pi}\\left[\\frac{q(\\boldsymbol{\\theta})}{p(\\boldsymbol{y}\\mid \\boldsymbol{\\theta})\\times \\pi(\\boldsymbol{\\theta})}\\right]. \\end{align*}\\] Thus, an estimate of the marginal likelihood is \\[ \\left[\\frac{1}{S}\\sum_{s=1}^S\\frac{q(\\boldsymbol{\\theta}^{*(s)})}{p(\\boldsymbol{y}\\mid \\boldsymbol{\\theta}^{*(s)})\\times\\pi(\\boldsymbol{\\theta}^{*(s)})}\\right]^{-1}. \\] This is the Gelfand-Dey method to calculate the marginal likelihood (Alan E. Gelfand and Dey 1994). Example: Cauchy distribution Let’s assume that the posterior distribution is Cauchy with parameters 0 and 1. We perform an importance sampling algorithm using as proposals a standard normal distribution and a Student’s t distribution with 3 degrees of freedom. The following code shows how to do this. rm(list = ls()); set.seed(010101) S &lt;- 20000 # Size proposal # Importance sampling from standard normal proposal thetaNs &lt;- rnorm(S) wNs &lt;- dcauchy(thetaNs)/dnorm(thetaNs) wNstars &lt;- wNs/sum(wNs) L &lt;- 10000 # Size posterior thetaCauchyN &lt;- sample(thetaNs, L, replace = TRUE, prob = wNstars) h &lt;- hist(thetaCauchyN, breaks=50, col=&quot;blue&quot;, xlab=&quot;x&quot;, main=&quot;Cauchy draws from importance sampling: Normal standard proposal&quot;) pfit &lt;- seq(min(thetaCauchyN),max(thetaCauchyN),length=50) yfit&lt;-dcauchy(pfit) yfit &lt;- yfit*diff(h$mids[1:2])*length(thetaCauchyN) lines(pfit, yfit, col=&quot;red&quot;, lwd=2) # Importance sampling from Student&#39;s t proposal df &lt;- 3 thetaTs &lt;- rt(S, df = df) wTs &lt;- dcauchy(thetaTs)/dt(thetaTs, df = df) wTstars &lt;- wTs/sum(wTs) thetaCauchyT &lt;- sample(thetaTs, L, replace = TRUE, prob = wTstars) h &lt;- hist(thetaCauchyT, breaks=50, col=&quot;blue&quot;, xlab=&quot;x&quot;, main=&quot;Cauchy draws from importance sampling: Student&#39;s t proposal&quot;) pfit &lt;- seq(min(thetaCauchyT),max(thetaCauchyT),length=50) yfit&lt;-dcauchy(pfit) yfit &lt;- yfit*diff(h$mids[1:2])*length(thetaCauchyT) lines(pfit, yfit, col=&quot;red&quot;, lwd=2) plot(wNstars, main = &quot;Importance sampling: Cauchy distribution&quot;, ylab = &quot;Weights&quot;, xlab = &quot;Iterations&quot;) points(wTstars, col = &quot;blue&quot;) legend(&quot;topright&quot;, legend = c(&quot;Normal&quot;, &quot;Student&#39;s t&quot;), col = c(&quot;black&quot;, &quot;blue&quot;), pch = c(1, 1)) The first and second figures show the histograms of the posterior draws using the normal and Student’s t-distributions, respectively, along with the density of the Cauchy distribution. The spike in the posterior draws from the standard normal proposal arises due to the lighter tails of the standard normal compared to the Cauchy distribution, consequently assigning too much weight to a specific draw from the normal distribution. The third figure shows the weights using the standard normal distribution (black dots) and the Student’s t-distribution with 3 degrees of freedom (blue dots) as proposals. We observe that a few draws carry too much weight when using the normal proposal; this occurs because the normal distribution has much lighter tails compared to the Cauchy distribution. In contrast, using the Student’s t-distribution with 3 degrees of freedom improves this situation. References "],["sec53.html", "4.3 Particle filtering", " 4.3 Particle filtering Now, we consider the scenario where we need to sample from a posterior distribution whose dimension increases over time, \\(\\pi(\\boldsymbol{\\theta}_{0:t}\\mid \\boldsymbol{y}_{0:t})\\), for \\(t = 0, 1, \\dots\\). The challenge arises from the fact that, even if this posterior distribution is known, the computational complexity of implementing a sampling scheme in this context increases linearly with \\(t\\). This makes MCMC methods, which operate in batch mode and require a complete re-run whenever new information becomes available, less optimal. Consequently, we present sequential algorithms, which operate incrementally as new data becomes available, and are often a better alternative. These algorithms are typically faster and are well-suited for scenarios requiring real-time updates, commonly referred to as online mode. Specifically, we consider the dynamic system in the state-space representation. This is a system where there is an unobservable state vector \\(\\boldsymbol{\\theta}_t\\in\\mathbb{R}^K\\), and an observed variable \\(\\boldsymbol{Y}_t\\), \\(t=0,1,\\dots\\) such that: \\(\\boldsymbol{\\theta}_t\\) is a Markov process, that is, \\[ \\pi(\\boldsymbol{\\theta}_{t}\\mid \\boldsymbol{\\theta}_{1:t-1})=\\pi(\\boldsymbol{\\theta}_{t}\\mid \\boldsymbol{\\theta}_{t-1}), \\] for \\(t=1,2,\\dots\\). All the relevant information to define \\(\\boldsymbol{\\theta}_{t}\\) is in \\(\\boldsymbol{\\theta}_{t-1}\\).24 \\(\\boldsymbol{Y}_t\\perp \\boldsymbol{Y}_s\\mid \\boldsymbol{\\theta}_{t}\\), for \\(s&lt;t\\). That is, there is independence between observable variables regarding their history conditional on the actual state vector. We can see in the next figure a graphical representation of the dynamic system. Formally, \\[ \\begin{aligned} \\boldsymbol{\\theta}_t &amp;= h(\\boldsymbol{\\theta}_{t-1}, \\boldsymbol{w}_t) &amp; \\text{(State equations)}\\\\ Y_t &amp; = f(\\boldsymbol{\\theta}_t, \\mu_t)&amp; \\text{(Observation equation)}, \\end{aligned} \\] where \\(\\boldsymbol{w}_t\\) and \\(\\mu_t\\) are stochastic errors such that their probability distributions define the transition density \\(\\pi(\\boldsymbol{\\theta}_t\\mid \\boldsymbol{\\theta}_{t-1})\\) and observation density \\(p(Y_t\\mid \\boldsymbol{\\theta}_t)\\). We present particle filtering, a specific case of sequential Monte Carlo (SMC), which is one of the most commonly used algorithms for scenarios requiring sequential updates of the posterior distribution as described by the state-space model. The starting point is sequential importance sampling (SIS), originally proposed by Handschin and Mayne (1969), which is a modification of IS to compute an estimate of \\(\\pi(\\boldsymbol{\\theta}_{0:t}\\mid \\boldsymbol{y}_{0:t})\\) without altering the past trajectories \\(\\left\\{\\boldsymbol{\\theta}^{(s)}_{1:t-1}, s=1,2,\\dots,S\\right\\}\\). The key idea is to use a proposal density that takes the form \\[ \\begin{aligned} q(\\boldsymbol{\\theta}_{0:t}\\mid \\boldsymbol{y}_{0:t}) &amp;= q(\\boldsymbol{\\theta}_{0:t-1}\\mid \\boldsymbol{y}_{1:t-1})q(\\boldsymbol{\\theta}_t\\mid \\boldsymbol{\\theta}_{t-1},\\boldsymbol{y}_{t}) \\\\ &amp;= q(\\boldsymbol{\\theta}_0)\\prod_{h=1}^{t}q(\\boldsymbol{\\theta}_h\\mid \\boldsymbol{\\theta}_{h-1},\\boldsymbol{y}_{h}). \\end{aligned} \\] This proposal density allows calculating the weights sequentially, \\[ \\begin{aligned} w_{t}(\\boldsymbol{\\theta}^{(s)}_{0:t})&amp;=\\frac{\\pi(\\boldsymbol{\\theta}_{0:t}^{(s)}\\mid \\boldsymbol{y}_{0:t})}{q(\\boldsymbol{\\theta}_{0:t}^{(s)}\\mid \\boldsymbol{y}_{0:t})}\\\\ &amp;=\\frac{p(\\boldsymbol{y}_{0:t}\\mid \\boldsymbol{\\theta}_{0:t}^{(s)})\\pi(\\boldsymbol{\\theta}_{0:t}^{(s)})}{p(\\boldsymbol{y}_{0:t})q(\\boldsymbol{\\theta}_{0:t}^{(s)}\\mid \\boldsymbol{y}_{0:t})}\\\\ &amp;=\\frac{p(\\boldsymbol{y}_{t}\\mid \\boldsymbol{\\theta}_{t}^{(s)})p(\\boldsymbol{y}_{1:t-1}\\mid \\boldsymbol{\\theta}_{0:t-1}^{(s)})\\pi(\\boldsymbol{\\theta}_{t}^{(s)}\\mid \\boldsymbol{\\theta}_{t-1}^{(s)})\\pi(\\boldsymbol{\\theta}_{0:t-1}^{(s)})}{p(\\boldsymbol{y}_{0:t})q(\\boldsymbol{\\theta}_{t}^{(s)}\\mid \\boldsymbol{\\theta}_{t-1},\\boldsymbol{y}_{t}^{(s)})q(\\boldsymbol{\\theta}_{0:t-1}^{(s)}\\mid \\boldsymbol{y}_{1:t-1})}\\\\ &amp;\\propto w_{t-1}^*(\\boldsymbol{\\theta}^{(s)}_{0:t-1})\\frac{p(\\boldsymbol{y}_{t}\\mid \\boldsymbol{\\theta}_{t}^{(s)})\\pi(\\boldsymbol{\\theta}_{t}\\mid \\boldsymbol{\\theta}_{t-1}^{(s)})}{q(\\boldsymbol{\\theta}_t^{(s)}\\mid \\boldsymbol{\\theta}_{t-1}^{(s)},\\boldsymbol{y}_{t})}. \\end{aligned} \\] Take into account that \\(p(\\boldsymbol{y}_{0:t})\\) does not depend on \\(\\boldsymbol{\\theta}^{(s)}_{0:t}\\). The term \\(\\alpha_t(\\boldsymbol{\\theta}_{0:t}^{(s)})=\\frac{p(\\boldsymbol{y}_{t}\\mid \\boldsymbol{\\theta}_{t}^{(s)})\\pi(\\boldsymbol{\\theta}_{t}\\mid \\boldsymbol{\\theta}_{t-1}^{(s)})}{q(\\boldsymbol{\\theta}_t^{(s)}\\mid \\boldsymbol{\\theta}_{t-1}^{(s)},\\boldsymbol{y}_{t})}\\) is called the incremental importance weight, and implies that \\[ w_t(\\boldsymbol{\\theta}^{s}_{0:t})=w_0(\\boldsymbol{\\theta}^{s}_{0})\\prod_{h=1}^{t}\\alpha_h(\\boldsymbol{\\theta}_{1:h}^{(s)}). \\] This algorithm possesses the desirable property of maintaining fixed computational complexity. Consequently, we sequentially obtain draws \\(\\boldsymbol{\\theta}_t^{(s)}\\), referred to as particles: \\(\\boldsymbol{\\theta}_0^{(s)}\\) is drawn from \\(q(\\boldsymbol{\\theta}_0)\\) at \\(t=0\\), and subsequently, \\(\\boldsymbol{\\theta}_h^{(s)}\\) is drawn from \\(q(\\boldsymbol{\\theta}_h\\mid \\boldsymbol{\\theta}_{h-1},\\boldsymbol{y}_{h})\\) at \\(t=h\\) (Doucet, De Freitas, and Gordon 2001; Olivier Cappé, Godsill, and Moulines 2007). A relevant case is when the proposal distribution takes the form of the prior distribution, that is, \\[ q(\\boldsymbol{\\theta}_{0:t}\\mid \\boldsymbol{y}_{0:t}) = \\pi(\\boldsymbol{\\theta}_{0:t}) = \\pi(\\boldsymbol{\\theta}_0)\\prod_{h=1}^{t}\\pi(\\boldsymbol{\\theta}_h\\mid \\boldsymbol{\\theta}_{h-1}). \\] This implies that \\[ w_{t}(\\boldsymbol{\\theta}^{(s)}_{0:t})\\propto w_{t-1}^*(\\boldsymbol{\\theta}^{(s)}_{0:t-1})p(\\boldsymbol{y}_{t}\\mid \\boldsymbol{\\theta}_{t}^{(s)}), \\] which means that the incremental importance weight is given by \\(p(\\boldsymbol{y}_{t}\\mid \\boldsymbol{\\theta}_{t}^{(s)})\\). Algorithm 4 shows how to perform SIS (Olivier Cappé, Godsill, and Moulines 2007). We set \\(w_t^{(s)}:=w_t(\\boldsymbol{\\theta}_{0:t}^{(s)})\\) to simplify notation. Algorithm: Sequential importance sampling For s=1,2,...,S do Sample θ0(s) from q(θ0|y0) Calculate the importance weights w0(s) ∝(p(y0|θ0(s))π(θ0(s)))/q(θ0(s)|y0) End for for t=1,2,...,T do for s=1,2,...,S do Draw particles θt(s) from qt(θt|θt-1,y0) Compute the weights wt(s) ∝ wt-1*(s) (p(yt|θt(s))π(θt(s)|θt-1(s)))/q(θt(s)|θt-1(s),yt) End for Standardize the weights wt*(s) = wt(s)/(∑hwt(h)), s=1,2,...,S End for Example: Dynamic linear model Let’s assume that the state-space representation is \\[ \\theta_t = \\theta_{t-1} + w_t \\quad \\text{(State equation)} \\\\ Y_t = \\phi \\theta_t + \\mu_t \\quad \\text{(Observation equation)}, \\] where \\(w_t \\sim N(0, \\sigma_w^2)\\) and \\(\\mu_t \\sim N(0, \\sigma_{\\mu}^2)\\), \\(t = 1, 2, \\dots, 50\\). In addition, we use the proposal distribution \\(q(\\theta_t \\mid y_t) = \\pi(\\theta_t)\\), which is normal with mean \\(\\theta_{t-1}\\) and variance \\(\\sigma_w^2\\). Then, the weights are given by the recursion \\[ w_t^{(s)} \\propto w_{t-1}^{*(s)} p(y_t \\mid \\theta_t, \\sigma_{\\mu}^2), \\] where \\(p(y_t \\mid \\theta_t, \\sigma_{\\mu}^2)\\) is \\(N(\\phi \\theta_t, \\sigma_{\\mu}^2)\\). We can compute the mean and standard deviation of the state at each \\(t\\) using \\[ \\hat{\\theta}_t = \\sum_{s=1}^S w_t^{*(s)} \\theta_t^{(s)} \\] and \\[ \\hat{\\sigma}_{\\theta} = \\left(\\sum_{s=1}^S w_t^{*(s)} \\theta_t^{2(s)} - \\hat{\\theta}_t^2\\right)^{1/2}. \\] The following code demonstrates the implementation of this algorithm, setting \\(\\sigma_w^2 = \\sigma_{\\mu}^2 = 1\\) and \\(\\phi = 0.5\\). First, we simulate the process, and then we implement the SIS algorithm. rm(list = ls()); set.seed(010101) S &lt;- 50000 # Number of particles sigma_w &lt;- 1 # State noise sigma_mu &lt;- 1 # Observation noise phi &lt;- 0.5 # Coefficient in observation equation T &lt;- 50 # Sample size # Simulate true states and observations theta_true &lt;- numeric(T); y_obs &lt;- numeric(T) theta_true[1] &lt;- rnorm(1, mean = 0, sd = sigma_w) # Initial state for (t in 2:T) { theta_true[t] &lt;- rnorm(1, mean = theta_true[t-1], sd = sigma_w) } y_obs &lt;- rnorm(T, mean = phi*theta_true, sd = sigma_mu) # Sequential Importance Sampling (SIS) particles &lt;- matrix(0, nrow = S, ncol = T) weights &lt;- matrix(0, nrow = S, ncol = T) weightsSt &lt;- matrix(0, nrow = S, ncol = T) # Initialization particles[, 1] &lt;- rnorm(S, mean = 0, sd = sigma_w) # Sample initial particles weights[, 1] &lt;- dnorm(y_obs[1], mean = phi*particles[, 1], sd = sigma_mu) # Importance weights weightsSt[, 1] &lt;- weights[, 1] / sum(weights[, 1]) # Standardized weights # Sequential updating for (t in 2:T) { # Propagate particles particles[, t] &lt;- rnorm(S, mean = particles[, t-1], sd = sigma_w) # Compute weights weights[, t] &lt;- weightsSt[, t-1] * dnorm(y_obs[t], mean = phi*particles[, t], sd = sigma_mu) # Recursive weight update weightsSt[, t] &lt;- weights[, t] / sum(weights[, t]) # Normalize weights } # Estimate the states (weighted mean) FilterDist &lt;- colSums(particles * weightsSt) SDFilterDist &lt;- (colSums(particles^2 * weightsSt) - FilterDist^2)^0.5 library(dplyr); library(ggplot2); library(latex2exp) ggplot2::theme_set(theme_bw()) df &lt;- tibble(t = 1:T, mean = FilterDist, lower = FilterDist - 2*SDFilterDist, upper = FilterDist + 2*SDFilterDist, theta_true = theta_true) # Function to plot plot_filtering_estimates &lt;- function(df) { p &lt;- ggplot(data = df, aes(x = t)) + geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 1, fill = &quot;lightblue&quot;) + geom_line(aes(y = theta_true), colour = &quot;black&quot;, alpha = 1, linewidth = 0.5) + geom_line(aes(y = mean), colour = &quot;blue&quot;, linewidth = 0.5) + ylab(TeX(&quot;$\\\\theta_{t}$&quot;)) + xlab(&quot;Time&quot;) print(p) } plot_filtering_estimates(df) The figure shows the trajectory of the true state vector (black line), the posterior mean (blue line), and the area defined by \\(\\pm2\\hat{\\sigma}_{\\theta}\\) (light blue shaded area). Sequential importance sampling is effective for sampling from the posterior distribution in the short term. However, it is important to note that SIS is a particular case of IS and, consequently, inherits the drawbacks of importance sampling. In particular, the variance of the weights increases exponentially with \\(t\\) (Kong, Liu, and Wong 1994). This implies that, as \\(t\\) increases, the importance weights tend to degenerate in the long run; that is, all probability mass concentrates on a few weights, a phenomenon known as sample impoverishment or weight degeneracy. This is because it is impossible to accurately represent a distribution on a space of arbitrarily high dimension with a sample of fixed, finite size. This phenomenon can be observed, for instance, in the dynamic linear model example, where the highest standardized weight at \\(t = 50\\) is 53%, and 7 out of 50,000 particles account for 87% of the total probability. Given that, in practice, we are often interested in lower-dimensional marginal distributions, ideas from sampling/importance resampling can be employed. This strategy avoids the accumulation of errors due to resetting the system, although resampling introduces some additional Monte Carlo variation. Gordon, Salmond, and Smith (1993) proposed the Bootstrap filter, where, at each time step, resampling is performed by drawing \\(S\\) particles from the current set using the standardized weights as probabilities of selection. This ensures that particles with small weights have a low probability of being selected. After resampling, the standardized weights are set equal to \\(1/S\\). Note that the Bootstrap filter involves multiple iterations of the SIR algorithm, which implies that the resampled trajectories are no longer independent. This multinomial resampling provides an unbiased approximation to the posterior distribution obtained by SIS (Doucet, Johansen, et al. 2009). Algorithm 5 shows how to perform the particle filter. We set \\(w_t^{(s)} := w_t(\\boldsymbol{\\theta}_{0:t}^{(s)})\\) to simplify notation (Doucet, Johansen, et al. 2009). Algorithm: Particle filter For s=1,2,...,S do Sample θ0(s) from q(θ0|y0) Calculate the importance weights w0(s) ∝(p(y0|θ0(s))π(θ0(s)))/q(θ0(s)|y0) End for Standardize the weights w0*(s) = w0(s)/(∑hw0(h)), s=1,2,...,S Select S particle from {θ0(s),w0*(s)} to obtain {θ0r(s),1/S} for t=1,2,...,T do for s=1,2,...,S do Draw particles θt(s) from qt(θt|θt-1,y0) Set θ1:t(s) ← (θ1:t-1r(s), θt(s)) Compute the weights αt(s) = (p(yt|θt(s))π(θt(s)|θt-1(s)))/q(θt(s)|θt-1(s),yt) End for Standardize the weights wt*(s) = wt(s)/(∑hwt(h)), s=1,2,...,S Select S particle from {θ1:t(s),wt*(s)} to obtain {θ1:tr(s),1/S} End for Example: Dynamic linear model continues If we apply the SIS algorithm to the dynamic linear model with a sample size of 200, the algorithm’s performance deteriorates as \\(t\\) increases. This is due to particle degeneration; at \\(t=200\\), a single particle holds a weight close to 100%. Let’s perform particle filtering in this example. The following code illustrate the procedure. The figure shows the performance of particle filtering in this example. There is the true state vector (black line), the means based on \\(\\left\\{\\boldsymbol{\\theta}_{1:t}^{(s)},w_t^{*(s)}\\right\\}\\) (blue line) and \\(\\left\\{\\boldsymbol{\\theta}_{1:t}^{r(s)},1/S\\right\\}\\) (purple line), and the area defined by \\(\\pm2\\hat{\\sigma}_{\\theta}\\) based on the former (light blue shaded area). Note that the particle filtering algorithm has better performance than the SIS algorithm. rm(list = ls()); set.seed(010101) S &lt;- 50000 # Number of particles sigma_w &lt;- 1; sigma_mu &lt;- 1 # # State and observation noises phi &lt;- 0.5 # Coefficient in observation equation T &lt;- 200 # Sample size # Simulate true states and observations theta_true &lt;- numeric(T); y_obs &lt;- numeric(T) theta_true[1] &lt;- rnorm(1, mean = 0, sd = sigma_w) for (t in 2:T) { theta_true[t] &lt;- rnorm(1, mean = theta_true[t-1], sd = sigma_w) } y_obs &lt;- rnorm(T, mean = phi*theta_true, sd = sigma_mu) # Particle filtering particles &lt;- matrix(0, nrow = S, ncol = T) # Store particles particlesT &lt;- matrix(0, nrow = S, ncol = T) # Store resampling particles weights &lt;- matrix(0, nrow = S, ncol = T) # Store weights weightsSt &lt;- matrix(0, nrow = S, ncol = T) # Store standardized weights weightsSTT &lt;- matrix(1/S, nrow = S, ncol = T) # Store standardized weights logalphas &lt;- matrix(0, nrow = S, ncol = T) # Store log incremental weights particles[, 1] &lt;- rnorm(S, mean = 0, sd = sigma_w) weights[, 1] &lt;- dnorm(y_obs[1], mean = phi*particles[, 1], sd = sigma_mu) # Importance weights weightsSt[, 1] &lt;- weights[, 1] / sum(weights[, 1]) # Normalize weights ind &lt;- sample(1:S, size = S, replace = TRUE, prob = weightsSt[, 1]) # Resample particles[, 1] &lt;- particles[ind, 1] # Resampled particles particlesT[, 1] &lt;- particles[, 1] # Resampled particles # Sequential updating pb &lt;- winProgressBar(title = &quot;progress bar&quot;, min = 0, max = T, width = 300) for (t in 2:T) { particles[, t] &lt;- rnorm(S, mean = particles[, t-1], sd = sigma_w) logalphas[, t] &lt;- dnorm(y_obs[t], mean = phi*particles[, t], sd = sigma_mu, log = TRUE) weights[, t] &lt;- exp(logalphas[, t]) weightsSt[, t] &lt;- weights[, t] / sum(weights[, t]) if(t &lt; T){ ind &lt;- sample(1:S, size = S, replace = TRUE, prob = weightsSt[, t]) particles[, 1:t] &lt;- particles[ind, 1:t] }else{ ind &lt;- sample(1:S, size = S, replace = TRUE, prob = weightsSt[, t]) particlesT[, 1:t] &lt;- particles[ind, 1:t] } setWinProgressBar(pb, t, title=paste( round(t/T*100, 0), &quot;% done&quot;)) } close(pb) ## NULL FilterDist &lt;- colSums(particles * weightsSt) SDFilterDist &lt;- (colSums(particles^2 * weightsSt) - FilterDist^2)^0.5 FilterDistT &lt;- colSums(particlesT * weightsSTT) SDFilterDistT &lt;- (colSums(particlesT^2 * weightsSTT) - FilterDistT^2)^0.5 MargLik &lt;- colMeans(weights) plot(MargLik, type = &quot;l&quot;) library(dplyr) library(ggplot2) require(latex2exp) ggplot2::theme_set(theme_bw()) df &lt;- tibble(t = 1:T, mean = FilterDist, lower = FilterDist - 2*SDFilterDist, upper = FilterDist+ 2*SDFilterDist, meanT = FilterDistT, lowerT = FilterDistT - 2*SDFilterDistT, upperT = FilterDistT + 2*SDFilterDistT, x_true = theta_true) plot_filtering_estimates &lt;- function(df) { p &lt;- ggplot(data = df, aes(x = t)) + geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 1, fill = &quot;lightblue&quot;) + geom_line(aes(y = x_true), colour = &quot;black&quot;, alpha = 1, linewidth = 0.5) + geom_line(aes(y = mean), colour = &quot;blue&quot;, linewidth = 0.5) + geom_line(aes(y = meanT), colour = &quot;purple&quot;, linewidth = 0.5) + ylab(TeX(&quot;$\\\\theta_{t}$&quot;)) + xlab(&quot;Time&quot;) print(p) } plot_filtering_estimates(df) Algorithm 5 performs resampling at every time step. However, it is common to perform resampling only when the effective sample size of the particles (\\(ESS = (\\sum_{s=1}^S (w_t^{*(s)})^{2})^{-1}\\)) falls below a specific threshold, such as 50% of the initial number of particles. Note that when \\(w_t^{*(s)} = 1/S\\), the effective sample size is \\(S\\), the total number of particles. Additionally, we should use \\(\\left\\{\\boldsymbol{\\theta}_{1:t}^{(s)}, w_t^{*(s)}\\right\\}\\) to estimate the posterior distribution, as it results in lower Monte Carlo error compared to calculations based on \\(\\left\\{\\boldsymbol{\\theta}_{1:t}^{r(s)}, 1/S\\right\\}\\) (Olivier Cappé, Godsill, and Moulines 2007). Finally, an estimate of the marginal likelihood can be obtained using \\[ \\hat{p}(y_t) = \\frac{1}{S}\\sum_{s=1}^S w_t^{(s)}. \\] Particle filtering offers several advantages, such as being quick and easy to implement, its modularity—allowing one to simply adjust the expressions for the importance distribution and weights when changing the problem—and its suitability for parallel algorithms. Moreover, it enables straightforward sequential inference for very complex models. However, there are also disadvantages. The resampling step introduces extra Monte Carlo variability. Using the state transition (prior) density as the importance distribution often leads to poor performance, manifested in a lack of robustness with respect to the observed sequence. For instance, performance deteriorates when outliers occur in the data or when the variance of the observation noise is small. Furthermore, the procedure is not well suited for sampling from \\(\\pi(\\boldsymbol{\\theta}_{0:t} \\mid y_{1:t})\\) because most particles originate from the same ancestor. Alternative resampling approaches, such as residual resampling (Liu and Chen 1995) and systematic resampling (J. Carpenter, Clifford, and Fearnhead 1999), preserve unbiasedness while reducing variance. Additionally, auxiliary particle filtering (O. Cappé, Godsill, and Moulines 2007) can help decrease Monte Carlo variability. Lastly, estimating fixed parameters such as \\(\\sigma_w^2\\), \\(\\sigma_{\\mu}^2\\), and \\(\\phi\\) in the dynamic linear model poses a challenge. Various methods exist to address this issue; see N. Kantas et al. (2009), Nikolas Kantas et al. (2015) for a comprehensive review and C. Andrieu, Doucet, and Holenstein (2010) for a seminal work in particle MCMC methods. References "],["sec54.html", "4.4 Convergence diagnostics", " 4.4 Convergence diagnostics MCMC methods rely on irreducibility, positive recurrence, and aperiodicity, ensuring that, after a sufficient burn-in (warm-up) period, the posterior draws are sampled from the invariant stationary posterior distribution. This can be achieved by running multiple chains initiated at different points and then mixing them, or by running a single longer chain. In this book, we follow the latter approach, as suggested by Geyer (1992). In this section, we present diagnostics to assess whether the sample draws come from the stationary posterior distribution. First, we calculate the numerical standard error associated with the MCMC algorithm. Next, we review the effective number of simulation draws and various convergence tests. Finally, we examine potential errors in the posterior simulator. 4.4.1 Numerical standard error Many times, the goal in Bayesian inference is to obtain a set of independent draws \\(\\boldsymbol{\\theta}^{(s)}\\), \\(s = 1, 2, \\dots, S\\), from the posterior distribution, such that a measure of interest can be estimated with reasonable precision. In particular, we approximate Equation (4.1) using Equation (4.2). By the central limit theorem, we know that \\[ \\begin{equation} \\frac{\\bar{h}(\\boldsymbol{\\theta})_S - \\mathbb{E}_{\\pi}[h(\\boldsymbol{\\theta})]}{\\sigma_h(\\boldsymbol{\\theta})/\\sqrt{S}} \\stackrel{d}{\\rightarrow} N(0, 1), \\tag{4.4} \\end{equation} \\] where \\(\\sigma^2_h(\\boldsymbol{\\theta})\\) is the variance of \\(h(\\boldsymbol{\\theta})\\). If we have independent draws, we can estimate \\(\\sigma^2_h(\\boldsymbol{\\theta})\\) using the posterior draws as follows: \\[ \\hat{\\sigma}^2_{Sh}(\\boldsymbol{\\theta}) = \\frac{1}{S} \\sum_{s=1}^S \\left[h(\\boldsymbol{\\theta}^{(s)})\\right]^2 - \\left[\\bar{h}(\\boldsymbol{\\theta})_S\\right]^2. \\] However, if there are dependent draws, we have \\[ \\hat{\\sigma}^{2*}_{Sh}(\\boldsymbol{\\theta}) = \\frac{1}{S} \\left\\{\\sum_{s=1}^S \\left[h(\\boldsymbol{\\theta}^{(s)})-\\bar{h}(\\boldsymbol{\\theta})_S\\right]^2 + 2\\sum_{l=k+1}^K \\big(h(\\boldsymbol{\\theta}^{(l)}) - \\bar{h}(\\boldsymbol{\\theta})\\big)\\big(h(\\boldsymbol{\\theta}^{(l-k)}) - \\bar{h}(\\boldsymbol{\\theta})\\big)\\right\\}. \\] The numerical standard error is given by \\(\\sigma_h(\\boldsymbol{\\theta})/\\sqrt{S}\\) and serves as a measure of the approximation error in the Monte Carlo integration. Note that this error can be decreased by increasing \\(S\\). For instance, \\(S = 1000\\) implies an error proportional to 3.2%, while \\(S = 10000\\) reduces the error to approximately 1%. 4.4.2 Effective number of simulation draws MCMC posterior draws are not independent; therefore, the effective sample size of the posterior chains is not equal to \\(S\\). To assess the effective sample size of the posterior draws, we use the following measure: \\[ S_{\\text{ef}} = \\frac{S}{1 + 2\\sum_{k=1}^{\\infty} \\rho_k(h)}, \\] where \\(\\rho_k(h)\\) is the autocorrelation of the sequence \\(h(\\boldsymbol{\\theta})\\) at lag \\(k\\). The sample counterpart of this expression is: \\[ \\hat{S}_{\\text{ef}} = \\frac{S}{1 + 2\\sum_{k=1}^{K} \\hat{\\rho}_k(h)}, \\] where \\[ \\hat{\\rho}_k(h) = \\frac{\\sum_{l=k+1}^K \\big(h(\\boldsymbol{\\theta}^{(l)}) - \\bar{h}(\\boldsymbol{\\theta})\\big)\\big(h(\\boldsymbol{\\theta}^{(l-k)}) - \\bar{h}(\\boldsymbol{\\theta})\\big)}{\\sum_{s=1}^K \\big(h(\\boldsymbol{\\theta}^{(s)}) - \\bar{h}(\\boldsymbol{\\theta})\\big)^2}. \\] If \\(\\hat{\\rho}_k(h)\\) declines to zero slowly as \\(k\\) increases, it indicates significant memory in the draws. Consequently, the effective sample size of the posterior draws is small, and it becomes necessary to either decrease the autocorrelation or increase the number of posterior draws. Note that \\[ \\hat{\\sigma}^{2*}_{Sh}(\\boldsymbol{\\theta}) = \\hat{\\sigma}^2_{Sh}\\left(\\boldsymbol{\\theta}\\right) (1+2\\sum_{k=1}^K \\hat{\\rho}_k(h)), \\] where \\(\\hat{\\sigma}^{2*}_{Sh}(\\boldsymbol{\\theta})\\) and \\(\\hat{\\sigma}^2_{Sh}\\) are the simulation variances using dependent and independent draws, and \\(\\hat{\\kappa}(h) = (1+2\\sum_{k=1}^K \\hat{\\rho}_k(h))\\) is called the inefficiency factor, which represents the inflation of the simulation variance due to autocorrelation in the draws. Values near one indicate draws with little correlation. 4.4.3 Tests of convergence Regarding convergence issues, there are several diagnostics to assess the adequacy of the posterior chains. In particular, graphical approaches such as trace plots and autocorrelation plots are widely used. Trace plots display the sampled values of a parameter (or multiple parameters) as a function of the iteration number, while autocorrelation plots graphically represent \\(\\hat{\\rho}_k\\). The latter shows how correlated the values of \\(\\boldsymbol{\\theta}\\), or functions of \\(\\boldsymbol{\\theta}\\), are at different lags. Trace plots should fluctuate around a stable mean, exploring the entire parameter space without becoming stuck in any particular region. Autocorrelation plots, on the other hand, should exhibit values close to zero or diminish quickly as the lag increases. Additionally, Geweke’s test (J. Geweke 1992) provides a simple two-sample test of means. If the mean of the first window (10% of the chain) is not significantly different from the mean of the second window (50% of the chain), we do not reject the null hypothesis that the two segments of the chain are drawn from the same stationary distribution. The Raftery and Lewis test (A. E. Raftery and Lewis 1992) is designed to calculate the approximate number of iterations (\\(S\\)), burn-in (\\(b\\)), and thinning parameter (\\(d\\)) required to estimate \\(p\\left[H(\\boldsymbol{\\theta}) \\leq h\\right]\\), where \\(H(\\boldsymbol{\\theta}): \\mathcal{R}^K \\rightarrow \\mathcal{R}\\). This calculation is based on a specific quantile of interest (\\(q\\)), precision (\\(r\\)), and probability (\\(p\\)). The diagnostic is based on the dependence factor, \\(I = \\frac{S + b}{S_{\\text{Min}}}\\), where \\(S_{\\text{Min}} = \\Phi^{-1}\\left(\\frac{1}{2}(p+1)\\right)^2 q(1-q) / r^2\\), and \\(\\Phi(\\cdot)\\) is the standard normal cumulative distribution function. Values of \\(I\\) much greater than 5 indicate a high level of dependence. Heidelberger and Welch’s test (Heidelberger and Welch 1983) uses a Cramér-von Mises statistic to test the null hypothesis that the sampled values, \\(\\boldsymbol{\\theta}^{(s)}\\), are drawn from a stationary distribution. The statistic is given by: \\[ \\text{CVM}(B_S) = \\int_0^1 B_S(t)^2 \\, dt, \\] where \\(B_S(t) = \\frac{S_{\\left[St\\right]} - \\left[St\\right] \\bar{\\boldsymbol{\\theta}}^S}{\\sqrt{S p(0)}}\\), \\(S_S = \\sum_{s=1}^S \\boldsymbol{\\theta}^{(s)}\\), \\(\\bar{\\boldsymbol{\\theta}}^S = S_S / S\\), and \\(p(0)\\) is the spectral density at 0, with \\(0 \\leq t \\leq 1\\). Under the null hypothesis, \\(B_S(t)\\) converges in distribution to a Brownian bridge. This test is recursively applied until either the null hypothesis is not rejected, or \\(s = 50\\%\\) of the chain has been discarded. Subsequently, the half-width test calculates a 95% confidence interval for the mean using the portion of the chain that passed the stationarity test. If the ratio of the half-width of this interval to the mean is less than 0.1, the test is considered passed. This indicates no evidence to reject the null hypothesis that the estimated mean is accurate and stable. There are other diagnostics in Bayesian inference that we do not mention here, such as the Gelman and Rubin test (Andrew Gelman and Rubin 1992). This is because we focus on the available diagnostics in our Graphical User Interface (GUI). 4.4.4 Checking for errors in the posterior simulator In this book, we provide basic code templates to get posterior draws for performing inference under the Bayesian framework when there is no closed-form solution. We are prone to making mistakes and greatly appreciate your feedback to help improve our code and identify any other potential issues. One way to check if our code works correctly is to perform simulations where the population parameters are known. If the code is functioning properly, the posterior estimates should converge to these values as the sample size increases due to the Bayesian consistency. This is an informal approach to identifying potential mistakes. John Geweke (2004) offers a more formal method for code validation. The starting point is the joint density \\(p(\\boldsymbol{y}, \\boldsymbol{\\theta}) = p(\\boldsymbol{y} \\mid \\boldsymbol{\\theta}) \\pi(\\boldsymbol{\\theta})\\) and a test function \\(h(\\boldsymbol{y}, \\boldsymbol{\\theta})\\) such that \\(\\sigma_h^2 = \\text{Var}[h(\\boldsymbol{y}, \\boldsymbol{\\theta})] &lt; \\infty\\). Assume that there is a marginal-conditional simulator for the joint distribution of \\(\\boldsymbol{y}\\) and \\(\\boldsymbol{\\theta}\\): \\[\\begin{align} \\boldsymbol{\\theta}^{(s)} &amp;\\sim \\pi(\\boldsymbol{\\theta}) \\\\ \\boldsymbol{y}^{(s)} &amp;\\sim p(\\boldsymbol{y} \\mid \\boldsymbol{\\theta}^{(s)}) \\\\ h^{(s)} &amp;= h(\\boldsymbol{y}^{(s)}, \\boldsymbol{\\theta}^{(s)}). \\end{align}\\] The sequence \\(\\left\\{\\boldsymbol{y}^{(s)}, \\boldsymbol{\\theta}^{(s)}\\right\\}\\) is i.i.d., \\(\\bar{h}_S\\) converges almost surely to \\(\\mathbb{E}[h(\\boldsymbol{y}, \\boldsymbol{\\theta})]\\), and there is convergence in distribution when \\(\\bar{h}_S\\) is well standardized (see Equation (4.4)) and \\(\\hat{\\sigma}^2_{Sh}(\\boldsymbol{\\theta})\\) converges to \\({\\sigma}^2_h(\\boldsymbol{\\theta})\\) almost surely. A posterior simulator produces draws \\(\\boldsymbol{\\theta}^{(s)}\\) given a particular realization \\(\\boldsymbol{y}_{\\text{Obs}}\\), using the transition density \\(q(\\boldsymbol{\\theta} \\mid \\boldsymbol{\\theta}^{(s-1)}, \\boldsymbol{y}_{\\text{Obs}})\\). Thus, a successive-conditional simulator consists of an initial draw \\(\\boldsymbol{\\theta}^{(0)}\\) from \\(\\pi(\\boldsymbol{\\theta})\\) followed by: \\[\\begin{align} \\boldsymbol{y}^{(l)} &amp;\\sim p(\\boldsymbol{y} \\mid \\boldsymbol{\\theta}^{(l-1)}) \\\\ \\boldsymbol{\\theta}^{(l)} &amp;\\sim q(\\boldsymbol{\\theta} \\mid \\boldsymbol{y}^{(l)}, \\boldsymbol{\\theta}^{(l-1)}) \\\\ h^{(l)} &amp;= h(\\boldsymbol{y}^{(l)}, \\boldsymbol{\\theta}^{(l)}), \\end{align}\\] where \\(\\bar{h}_L = L^{-1} \\sum_{l=1}^L h(\\boldsymbol{y}^{(l)}, \\boldsymbol{\\theta}^{(l)})\\) converges almost surely to \\(\\mathbb{E}[h(\\boldsymbol{y}, \\boldsymbol{\\theta})]\\), and there is convergence in distribution when \\(\\bar{h}_L\\) is well standardized, and \\(\\hat{\\sigma}^{*2}_{Lh}(\\boldsymbol{\\theta})\\) converges to \\({\\sigma}^2_h(\\boldsymbol{\\theta})\\) almost surely, for \\(l = 1, 2, \\dots, L\\). Thus, \\[\\begin{align} \\frac{\\bar{h}_S - \\bar{h}_L}{\\left( S^{-1} \\hat{\\sigma}^2_{Sh}(\\boldsymbol{\\theta}) + L^{-1} \\hat{\\sigma}^{*2}_{Lh}(\\boldsymbol{\\theta}) \\right)^{1/2}} &amp;\\stackrel{d}{\\rightarrow} N(0, 1). \\end{align}\\] Thus, we can test \\(H_0. \\ \\bar{h}_S - \\bar{h}_L = 0\\) versus \\(H_1. \\ \\bar{h}_S - \\bar{h}_L \\neq 0\\). Rejection of the null indicates potential errors in implementing the posterior simulator. Example: Mining disaster change point continues Let’s revisit the mining disaster change point example from subsection 4.1.1 and examine some convergence diagnostics for the posterior draws of the rate of disasters after the change point (\\(\\lambda_2\\)). The following code demonstrates how to perform these diagnostics using the R package coda. For clarity and replicability of the results, we present the Gibbs sampler again. The following two figures show the trace and autocorrelation plots. We observe that the posterior draws of \\(\\lambda_2\\) appear stationary around their mean, and the autocorrelation decreases rapidly to zero. The mean and standard deviation of the rate after the change point are 0.92 and 0.12, respectively. The naive and time series standard errors are 0.0008245 and 0.0008945, respectively. The naive standard error assumes iid posterior draws, whereas the time series standard error accounts for autocorrelation. Both standard errors are very similar, indicating a low level of autocorrelation, which is consistent with the results shown in the second figure. The effective sample size of the posterior draws is 16,991, while the total number of posterior draws is 20,000 after a burn-in period of 1,000. The Geweke test statistic is 1.43, which implies no statistical evidence to reject the null hypothesis of equal means in the two segments of the posterior draws. The Raftery and Lewis test yields a dependence factor near 1, indicating a low level of dependence. The Heidelberger and Welch test does not reject the null hypothesis of stationarity for the posterior draws and also confirms that the mean is accurate and stable. In summary, all posterior diagnostics indicate that the posterior draws originate from an invariant stationary distribution. The second part of the code implements the proposal by John Geweke (2004) to assess the reliability of the posterior simulator. The parameter vector is defined as \\(\\boldsymbol{\\theta} = [\\lambda_1 \\ \\lambda_2 \\ H]\\), and the first moments of these parameters are used as test functions. We do not reject the null hypothesis of equal means across the three test functions, indicating that the posterior simulator is functioning correctly. To evaluate the effectiveness of the test, we run the marginal-conditional simulator with prior parameters \\(\\alpha_{l0} = 0.5\\) and \\(\\beta_{l0} = 1\\), \\(l = 1, 2\\). In contrast, for the successive-conditional simulator, we use prior parameters \\(\\alpha_{l0} = 1\\) and \\(\\beta_{l0} = 0.5\\), \\(l = 1, 2\\). In this case, we reject the null hypothesis in two out of three test functions, suggesting that the test performs well in this example. rm(list = ls()) set.seed(010101) dataset&lt;-read.csv(&quot;https://raw.githubusercontent.com/besmarter/BSTApp/refs/heads/master/DataApp/MiningDataCarlin.csv&quot;,header=T) attach(dataset) ## The following objects are masked from dataset (pos = 4): ## ## Count, year str(dataset) ## &#39;data.frame&#39;: 112 obs. of 2 variables: ## $ year : int 1851 1852 1853 1854 1855 1856 1857 1858 1859 1860 ... ## $ Count: int 4 5 4 1 0 4 3 4 0 6 ... a10 &lt;- 0.5; a20 &lt;- 0.5 b10 &lt;- 1; b20 &lt;- 1 y &lt;- Count sumy &lt;- sum(Count); T &lt;- length(Count) theta1 &lt;- NULL; theta2 &lt;- NULL kk &lt;- NULL; H &lt;- 60 MCMC &lt;- 20000; burnin &lt;- 1000; S &lt;- MCMC + burnin; keep &lt;- (burnin+1):S pb &lt;- winProgressBar(title = &quot;progress bar&quot;, min = 0, max = S, width = 300) for(s in 1:S){ a1 &lt;- a10 + sum(y[1:H]) b1 &lt;- b10+H theta11 &lt;- rgamma(1,a1,b1) theta1 &lt;- c(theta1,theta11) a2 &lt;- a20 + sum(y[(1+H):T]) b2 &lt;- b20 + T-H theta22 &lt;- rgamma(1,a2,b2) theta2 &lt;- c(theta2,theta22) pp&lt;-NULL for(l in 1:T){ p &lt;- exp(l*(theta22-theta11))*(theta11/theta22)^(sum(y[1:l])) pp &lt;- c(pp,p) } prob &lt;- pp/sum(pp) H &lt;- sample(1:T,1,prob=prob) kk &lt;- c(kk,H) setWinProgressBar(pb, s, title=paste( round(s/S*100, 0),&quot;% done&quot;)) } close(pb) ## NULL library(coda); library(latex2exp) theta1Post &lt;- mcmc(theta1[keep]); summary(theta1Post) ## ## Iterations = 1:20000 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 20000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## 3.049150 0.282297 0.001996 0.002155 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## 2.517 2.855 3.042 3.235 3.625 HPost &lt;- mcmc(kk); summary(HPost) ## ## Iterations = 1:21000 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 21000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## 40.15843 2.48171 0.01713 0.01973 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## 36 39 40 41 46 theta2Post &lt;- mcmc(theta2[keep]); summary(theta2Post) ## ## Iterations = 1:20000 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 20000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## 0.9151697 0.1165952 0.0008245 0.0008945 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## 0.7010 0.8343 0.9104 0.9914 1.1564 plot(theta2Post, density = FALSE, main = &quot;Trace plot&quot;, ylab = TeX(&quot;$\\\\theta_{2}$&quot;)) autocorr.plot(theta2Post, main = &quot;Autocorrelation plot&quot;) raftery.diag(theta2Post, q = 0.025, r = 0.005, s = 0.95) ## ## Quantile (q) = 0.025 ## Accuracy (r) = +/- 0.005 ## Probability (s) = 0.95 ## ## Burn-in Total Lower bound Dependence ## (M) (N) (Nmin) factor (I) ## 2 3865 3746 1.03 geweke.diag(theta2Post, frac1 = 0.1, frac2 = 0.5) ## ## Fraction in 1st window = 0.1 ## Fraction in 2nd window = 0.5 ## ## var1 ## 1.431 heidel.diag(theta2Post, eps = 0.1, pvalue = 0.05) ## ## Stationarity start p-value ## test iteration ## var1 passed 1 0.196 ## ## Halfwidth Mean Halfwidth ## test ## var1 passed 0.915 0.00175 effectiveSize(theta2Post) ## var1 ## 16990.59 # Marginal-conditional simulator Theta1Prior &lt;- rgamma(MCMC,a10,b10); Theta2Prior &lt;- rgamma(MCMC,a20,b20) kPrior &lt;- sample(1:T, MCMC, replace = TRUE, prob = rep(1/T,T)) ytPrior &lt;- function(par){ y1t &lt;- rpois(par[3], par[1]) if(par[3] == T){y2t &lt;- NULL }else{y2t &lt;- rpois(T-par[3], par[2]) } yt &lt;- c(y1t, y2t) return(yt) } pars1 &lt;- cbind(Theta1Prior, Theta2Prior, kPrior); Yt &lt;- apply(pars1, 1, ytPrior) parsmcmc1 &lt;- coda::mcmc(pars1); Summ1 &lt;- summary(parsmcmc1) # Successive-conditional simulator SucConSim &lt;- function(a10, b10, a20, b20, par){ y &lt;- ytPrior(par) theta1 &lt;- par[1]; theta2 &lt;- par[2]; H &lt;- par[3] a1 &lt;- a10 + sum(y[1:H]); b1 &lt;- b10+H theta11 &lt;- rgamma(1,a1,b1) if(H == T){ a2 &lt;- a20 }else{ a2 &lt;- a20 + sum(y[(1+H):T]) } b2 &lt;- b20 + T-H; theta22 &lt;- rgamma(1,a2,b2); pp&lt;-NULL for(l in 1:T){ p &lt;- l*(theta22-theta11) + (sum(y[1:l]))*log(theta11/theta22) pp &lt;- c(pp,p) } pps &lt;- exp(pp - max(pp)); prob &lt;- pps/sum(pps) H &lt;- sample(1:T, 1, prob=prob) parNew &lt;- list(y = y, pars = c(theta11, theta22, H)) return(parNew) } a10 &lt;- 0.5; b10 &lt;- 1; a20 &lt;- 0.5; b20 &lt;- 1 # a10 &lt;- 1; b10 &lt;- 0.5; a20 &lt;- 1; b20 &lt;- 0.5 par1 &lt;- rgamma(1,a10,b10); par2 &lt;- rgamma(1,a20,b20) par3 &lt;- sample(1:T, 1, replace = TRUE, prob = rep(1/T,T)) pars2 &lt;- matrix(NA, MCMC, 3); pars2[1,] &lt;- c(par1, par2, par3) for(s in 2:MCMC){ Res &lt;- SucConSim(a10 = a10, b10 = b10, a20 = a20, b20 = b20, par = pars2[s-1,]) pars2[s, ] &lt;- Res$pars } parsmcmc2 &lt;- coda::mcmc(pars2); Summ2 &lt;- summary(parsmcmc2) TestGeweke &lt;- function(j){ Test &lt;- (Summ1[[&quot;statistics&quot;]][j,1] - Summ2[[&quot;statistics&quot;]][j,1])/(Summ1[[&quot;statistics&quot;]][j,4]+Summ2[[&quot;statistics&quot;]][j,4])^0.5 Reject &lt;- abs(Test) &gt; qnorm(0.975) return(list(Test = Test, Reject = Reject)) } TestGeweke(1); TestGeweke(2); TestGeweke(3) ## $Test ## Mean ## -0.0966628 ## ## $Reject ## Mean ## FALSE ## $Test ## Mean ## -0.2038595 ## ## $Reject ## Mean ## FALSE ## $Test ## Mean ## 0.7029845 ## ## $Reject ## Mean ## FALSE References "],["sec55.html", "4.5 Summary", " 4.5 Summary In this chapter, we present the most popular methods for obtaining posterior draws when the posterior distribution does not have a standard closed-form solution. In particular, Markov chain Monte Carlo (MCMC) methods, such as Gibbs sampling and the Metropolis-Hastings algorithm, are the most commonly used approaches in this book. However, Hamiltonian Monte Carlo is gaining particular relevance in high-dimensional problems, while particle filtering (Sequential Monte Carlo) is widely applied in time series models. Each problem requires careful consideration to determine the most appropriate method, and in many cases, a combination of methods is necessary. For instance, estimating fixed parameters in state-space models typically requires MCMC methods, while recursion of the state vector requires particle filtering. Additionally, convergence diagnostics are crucial because MCMC methods rely on technical assumptions that must be verified. "],["sec56.html", "4.6 Exercises", " 4.6 Exercises Example: The normal model with independent priors Let’s recap the math test exercise in Chapter 3, this time assuming independent priors. Specifically, let \\(Y_i \\sim N(\\mu, \\sigma^2)\\), where \\(\\mu \\sim N(\\mu_0, \\sigma_0^2)\\) and \\(\\sigma^2 \\sim IG(\\alpha_0 / 2, \\delta_0 / 2)\\). The sample size is 50, and the mean and standard deviation of the math scores are 102 and 10, respectively. We set \\(\\mu_0 = 100\\), \\(\\sigma_0^2 = 100\\), and \\(\\alpha_0 = \\delta_0 = 0.001\\). Find the posterior distribution of \\(\\mu\\) and \\(\\sigma^2\\). Program a Gibbs sampler algorithm and plot the histogram of the posterior draws of \\(\\mu\\). Show that the Gibbs sampler is a particular case of the Metropolis-Hastings where the acceptance probability is equal to 1. Implement a Metropolis-Hastings to sample from the Cauchy distribution, \\(C(0,1)\\), using as proposals a standard normal distribution and a Student’s t distribution with 5 degrees of freedom. This exercise was proposed by Professor Hedibert Freitas Lopes, who cites Thomas and Tu (2021) as a useful reference for an introduction to Hamiltonian Monte Carlo in R and the hmclearn package. The task is to obtain posterior draws using the Metropolis-Hastings and Hamiltonian Monte Carlo algorithms for the posterior distribution given by \\[ \\pi(\\theta_1,\\theta_2\\mid \\mathbf{y}) \\propto \\exp\\left\\{-\\frac{1}{2}(\\theta_1^2\\theta_2^2 + \\theta_1^2 + \\theta_2^2 - 8\\theta_1 - 8\\theta_2)\\right\\}. \\] Ph.D. students sleeping hours continues Use importance sampling based on a \\(U(0,1)\\) proposal to obtain draws of \\(\\boldsymbol{\\theta}\\mid \\mathbf{y} \\sim B(16.55,39.57)\\) in the Ph.D. students’ sleeping hours example in Chapter 3. Note that, based on Exercise 15 in Chapter 3, \\(\\alpha_0 = 1.44\\) and \\(\\beta_0 = 2.57\\). Compute the marginal likelihood in this context (Bernoulli-Beta model) and compare it to the result obtained using the Gelfand-Dey method. Example 4.1 in Gordon, Salmond, and Smith (1993) is \\[\\begin{align*} \\theta_t &amp;= 0.5\\theta_{t-1} + 25\\frac{\\theta_{t-1}}{1+\\theta_{t-1}^2} + 8 \\cos(1.2t) + w_t \\\\ y_t &amp;= \\frac{\\theta_{t}^2}{20} + \\mu_t, \\end{align*}\\] where \\(\\theta_0 \\sim N(0, \\sqrt{10})\\), \\(w_t \\sim \\mathcal{N}(0, \\sqrt{10})\\) and \\(\\mu_t \\sim N(0, \\sqrt{1})\\). Perform sequential importance sampling in this example. Perform particle (Bootstrap) filtering in this example. Estimate the marginal likelihood in this example. Ph.D. students sleeping hours continues Perform the diagnostics of Section 4.4 in this example. Check if there are errors in the posterior simulator of the Metropolis-Hastings algorithm in this example using the Geweke approach using as test functions the first moments of \\(p\\) and \\(p^2\\). Remember from Exercise 15 in Chapter 3 that the sample size is 52, and \\(\\alpha_0 = 1.22\\) and \\(\\beta_0 = 2.57\\). Run the Geweke test using \\(\\alpha_0 = 2.57\\) and \\(\\beta_0 = 1.22\\), and check the results. References "],["Chap5.html", "Chapter 5 Graphical user interface", " Chapter 5 Graphical user interface This chapter introduces our graphical user interface (GUI) for conducting Bayesian regression analysis in a user-friendly environment, requiring no programming skills (drag and drop). Our GUI is built as an interactive web application using shiny (Chang 2018) and incorporates packages such as MCMCpack (Martin, Quinn, and Park 2018) and bayesm (P. Rossi 2017) from the R software (R Core Team 2023). It is designed for teaching and applied purposes at an introductory level. In the following chapters of the second part of this book, we present several applications that demonstrate the potential of our GUI for applied researchers and practitioners. References "],["secGUI1.html", "5.1 Introduction", " 5.1 Introduction Our GUI enables users to perform inference using Bayesian regression analysis without requiring programming skills. The latter is often a significant impediment to the widespread adoption of the Bayesian framework (Woodward 2005; Karabatsos 2016). Several other graphical user interfaces are available for Bayesian regression analysis. ShinyStan (Stan Development Team 2017) is a highly flexible, open-source program; however, users must have some programming skills. It is based on the Stan software for Bayesian data analysis (B. Carpenter et al. 2017). BugsXLA (Woodward 2005) is also open source but less flexible, though it does not require programming skills. Bayesian Regression: Nonparametric and Parametric Models (Karabatsos 2016) is a user-friendly and flexible GUI based on the MATLAB Compiler for 64-bit Windows systems. It primarily focuses on Bayesian nonparametric regression and is designed for users already familiar with basic parametric models, such as those implemented in our GUI. Additionally, there are tools such as the MATLAB Toolkit, Stata, and BayES, but these are not open source. We developed our GUI as an interactive web application using shiny (Chang 2018) and various libraries in R (R Core Team 2023). The specific libraries and commands used in our GUI are listed in the Appendix. It includes ten univariate models, four multivariate models, four time series models, three hierarchical longitudinal models, and seven Bayesian model averaging frameworks. Additionally, it provides basic summaries and diagnostics of the posterior chains, as well as visualizations such as trace plots, autocorrelation plots, and density plots. In terms of flexibility and functionality, our GUI falls between ShinyStan and BugsXLA: users do not need programming skills, but it is not as advanced as the software in Karabatsos (2016). However, our GUI runs on any operating system. We call our GUI BEsmarter,25 and it is freely available at https://github.com/besmarter/BSTApp, where users can access all source code and datasets. Simulated and applied datasets are stored in the DataSim and DataApp folders of our GitHub repository (see the Appendix for details). The DataSim folder includes the files used to simulate different processes, providing access to population parameters. As a result, these files serve as a valuable pedagogical tool for illustrating statistical properties of the inferential frameworks available in our GUI. The DataApp folder contains the datasets used in this book, which users can use as templates for structuring their own datasets. There are three ways to install our GUI. The easiest method, which requires installing R and potentially an R code editor, is to type: There are three ways to install our GUI. The easiest way, but that requires installation of R and potentially a R code editor, is to type shiny::runGitHub(\"besmarter/BSTApp\", launch.browser=T) in the R console or any R code editor and execute it. The second option is to visit https://posit.cloud/content/4328505: log in or sign up for Posit Cloud, and access the project titled GUIded Bayesian Regression App BSTApp In the bottom-right window, navigate to the BSTApp-master folder under Files, open the app.R file, and click the Run App button. However, prolonged inactivity may cause the session to close. The third approach, and our recommendation, is using a Docker image by running: docker pull magralo95/besmartergui:latest docker run --rm -p 3838:3838 magralo95/besmartergui in your Command Prompt, this command creates an isolated environment for our GUI, ensuring consistent performance across different systems. Note that Docker must be installed to deploy our GUI using this method. Users can then access the app by navigating to 127.0.0.1:3838 or http://localhost:3838/. After using any of the three methods to run our GUI, users will see a new window displaying a presentation of our research team (see Figure 5.1). Additionally, the top panel in Figure 5.1 shows the categories of models that can be estimated in our GUI. Figure 5.1: Display of graphical user interface. References "],["secGUI2.html", "5.2 Univariate models", " 5.2 Univariate models After deploying our GUI (see Figure 5.1), the user should select Univariate Models from the top panel. Then, Figure 5.2 is displayed, showing a radio button on the left-hand side that lists the specific models within this category. In particular, users can see that the normal model is selected from the univariate models class. Figure 5.2: Univariate models: Specification. Then, the right-hand panel displays a widget for uploading the input dataset, which must be a csv file with headers in the first row. Users must also select the separator type used in the input file: comma, semicolon, or tab (use the DataSim and DataApp folders for input file templates). Once the dataset is uploaded, users can preview the data. Range sliders allow users to set the number of iterations for the Markov Chain Monte Carlo algorithm, specify the burn-in period, and adjust the thinning parameter (see the following chapters in this section for technical details). Next, users must specify the equation. This can be done using the formula builder, where they select the dependent variable and independent variables, then click on the Build Formula tab. The equation appears in the Main Equation space, formatted according to R syntax (see the main equation box in Figure 5.2, e.g., \\(y \\sim x1 + x2 + x3\\)). Users can modify this as needed, including higher-order terms, interaction effects, or other transformations. These modifications must follow the standard formula syntax.26 By default, univariate models include an intercept, except for ordered probit models, where the specification must explicitly exclude it due to identification constraints (see details below).27 Thus, users should specify this explicitly as follows: \\(y \\sim x1 + x2 + x3 - 1\\). Finally, users must define the prior hyperparameters. For example, in the normal-inverse gamma model, these include the mean vector, covariance matrix, shape parameter, and scale parameter (see Figure 5.3). However, our GUI uses non-informative hyperparameters by default across all modeling frameworks, so this step is optional. Figure 5.3: Univariate models: Results. After completing the specification process, users should click the Go! button to initiate the estimation. Once the process is finished, our GUI displays the summary statistics and convergence diagnostics (see Figure 5.3). Additionally, widgets allow users to download the posterior chains (csv file) and graphs (pdf and eps files). Note that in the results—summary, posterior chains, and graphs—the coefficients are ordered with location parameters appearing first, followed by scale parameters. For multinomial models (probit and logit), the dataset must be structured as follows: the first column should contain the dependent variable, followed by alternative-specific regressors (e.g., alternatives’ prices), and finally, non-alternative-specific regressors (e.g., income). The formula builder allows users to specify the dependent variable as well as both types of independent variables (see technical details in the next chapter). Additionally, users must define the base category, the number of alternatives (which is also required for ordered probit), the number of alternative-specific regressors, and the number of non-alternative-specific regressors (see Figure 5.4). For multinomial logit models, users can also specify a tuning parameter—the degrees of freedom for the Metropolis–Hastings algorithm (see technical details in the next chapter). This tuning option is available in our GUI when estimation relies on the Metropolis–Hastings algorithm. In the results of these models, coefficients are ordered as follows: Figure 5.4: Univariate models: Multinomial. Note that the non-alternative-specific regressors associated with the base category are set to zero and do not appear in the results. Additionally, due to identification constraints in multinomial and multivariate probit models, some coefficients in the main diagonal of the covariance matrix remain constant. Figure 5.5: Univariate models: Bootstrap. For the negative binomial model, users must specify a dispersion parameter (see the next chapter for details). Similarly, for Tobit and quantile models, users need to define the censorship points and quantiles, respectively. The Bayesian bootstrap method only requires uploading a dataset, specifying the number of MCMC iterations, setting the resampling size, and defining the equation (see Figure 5.5). The input file should follow the same structure as the one used for the univariate normal model. See https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/formula↩︎ An identification issue arises when multiple sets of model parameters yield the same likelihood function value.↩︎ "],["secGUI3.html", "5.3 Multivariate models", " 5.3 Multivariate models After our GUI is deployed (see Figure 5.1), the user should select Multivariate Models from the top panel. Figure 5.6 will then be displayed, showing a radio button on the left-hand side that lists the specific models within this category. Figure 5.6 illustrates the multivariate regression setup. The input file should first contain the dependent variables, followed by the regressors. If each equation includes an intercept, a column of 1s should be added after the dependent variables in the input file. Users can preview the data after uploading the file. The user must specify the number of dependent variables and regressors, indicate whether an intercept should be included, and define the hyperparameter values (see Figure 5.6). Figure 5.6: Multivariate models: Simple multivariate. In seemingly unrelated regressions, the input file should first contain the dependent variables, followed by the regressors for each equation, including the intercept (a column of 1s) if necessary. Users must define the number of dependent variables (equations), the total number of regressors (the sum of all regressors associated with the equations), and the number of regressors per equation (including the intercept if necessary). Users can also specify the values of the hyperparameters if prior information is available. The results of the simple multivariate and seemingly unrelated regressions first display the posterior location parameters by equation, followed by the posterior covariance matrix. In the instrumental variable setting, users should specify the main equation and the instrumental equation. This setting includes intercepts by default. The first variable on the right-hand side of the main equation must be the variable with endogeneity issues. In the instrumental equation, the dependent variable is the one with endogeneity issues, modeled as a function of the instruments. Users can also specify the values of the hyperparameters if they have prior information. The input file should include the dependent variable, the endogenous regressor, the instruments, and the exogenous regressors. The results first list the posterior estimates of the endogenous regressor, followed by the location parameters of the auxiliary regression (instrumental equation), the location parameters of the exogenous regressors, and finally, the posterior covariance matrix. Figure 5.7: Multivariate models: Multivariate probit. The multivariate probit model requires the input dataset to be ordered by unit. For example, three choices imply repeating each unit three times. The first column must contain the identification for each unit, using ordered integers. Next, the dependent variable should be a single vector of 0s and 1s, followed by the regressors, which must include a column of 1s for the intercepts. Users should specify the number of units, the number of regressors, and the number of choices (see Figure 5.7). The results first display the posterior location parameters by equation, followed by the posterior covariance matrix. "],["secGUI4.html", "5.4 Time series models", " 5.4 Time series models After our GUI is deployed (see Figure 5.1), the user should select Time Series Models from the top panel. Then, Figure 5.8 will be displayed, and the user will see the radio button on the left-hand side, which shows the specific models within this general class. Figure 5.8: Time series models. Users can perform inference using dynamic linear models (DLM), autoregressive moving average (ARMA) models, stochastic volatility models (SVM), and vector autoregressive (VAR) models. Users should upload a dataset, which must be a csv file with headers in the first row. The files for DLMs and SVMs have the same structure: the first column contains the dependent variable, followed by the independent variables. For ARMA models, there is only one column with the modeled variable, while VAR models have each modeled variable in a separate column. Note that this version of the GUI does not allow for exogenous variables in VAR models. Users should specify the separator used in the input file: comma, semicolon, or tab. A dataset preview is displayed once the file is uploaded. Dataset templates can be found in the folders DataSim and DataApp (see the Appendix for details) in our GitHub repository. Next, users should set the MCMC and burn-in iterations using the range sliders and the thinning parameter using the input box. To estimate DLMs, users should set the hyperparameters for the precision of the observation equation and the state equations (means and variances) if prior information is available. Otherwise, users can click the Pre Calculate Prior button, where these hyperparameters are estimated based on a recursive model estimation using ordinary least squares (OLS). The sample size is progressively increased, and the location parameters are saved. The GUI then computes the covariance matrix of this sequence and uses it to set the prior mean for the precision of the state vector, which is equal to the inverse of the maximum element on the main diagonal of the covariance matrix (\\(a.theta\\)). The prior variance is set to ten times this value (\\(b.theta\\)). For the observation equation, the prior mean of the precision is set to the inverse of the OLS variance estimate (\\(a.y\\)), and the prior variance is set to ten times this value (\\(b.y\\)). This is a rudimentary approach to setting these hyperparameters, and users are encouraged to use a more thoughtful process. Next, users should click the Go! button to start estimating the model. This may take a few minutes, as DLMs are complex to estimate. Users should be patient. Once the estimation is complete, the GUI will display graphs of the states (mean and 95% credible intervals), summary statistics of the posterior chains for the observation and state variances, and convergence diagnostics. Users can download the mean and the lower and upper limits of the 95% credible intervals of the states, as well as the posterior chains for the variances. For ARMA models, users need to set the frequency (annual -1-, quarterly -4-, and monthly -12-), as well as the AR and MA orders (see Figure 5.9). Then, users should set the location and scale hyperparameters for the intercept, autoregressive (AR), moving average (MA), and standard deviation terms. Note that there is only one set of hyperparameters for the AR and MA coefficients. This step is optional, as the GUI uses non-informative priors by default. Figure 5.9: Time series models: ARMA specification. Then, users should click the Go! button, and the GUI will start estimating the model. The GUI will display the summary statistics of the posterior draws and the convergence diagnostics. The order is AR coefficients (if any), MA coefficients (if any), intercept, and standard deviation. Users can download the posterior chains and figures (density, autocorrelation, and trace plots). Estimation of the SVMs requires setting the coefficients of the mean and standard deviation of the Gaussian prior for the regression parameters, the mean and standard deviation for the Gaussian prior distribution of the level of the log-volatility, shape parameters for the Beta prior distribution of the transformed persistence parameter, and a positive real number representing the scaling of the transformed volatility of log-volatility. However, this step is not necessary, as by default our GUI uses the default values in the stochvol package. Then, click the Go! button, wait for the estimation to be completed, and the GUI will display the stochastic volatility plot (mean and 95% credible interval). Users can also view the summary and diagnostics of the posterior chains (see Figure 5.10). In addition, users can download the mean and the lower and upper limits of the 95% credible intervals of the stochastic volatility, as well as the posterior chains of the variances. Figure 5.10: Time series models: Stochastic volatility. To estimate VAR models, users should set the number of lags, the impulse response and forecast periods, the three coefficients of the Minnesota prior, and the type of impulse response (forecast error impulse response -feir- or orthogonalized impulse response -other-, both cumulative or non-cumulative). See Chapter 8 for details, Section 8.4. Click the Go! button, and after a few minutes, users will be able to see the plots of the impulse responses and forecasts (means and 95% credible intervals). Click the Download Results button, and a zip file with .csv files containing the impulse responses and forecasts, along with their plots, will be downloaded. "],["secGUI5.html", "5.5 Longitudinal/panel models", " 5.5 Longitudinal/panel models After our GUI is deployed (see Figure 5.1), the user should select Hierarchical Longitudinal Models in the top panel. Then, Figure 5.11 will be displayed, and the user can see the radio button on the left-hand side that shows the specific models inside this generic class. The hierarchical longitudinal models tab allows for estimating models that account for within-subject correlation when the dependent variable is continuous (Normal), binary (Logit), or a count (Poisson). The input files for hierarchical longitudinal models should first include the dependent variable, followed by the regressors and a cross-sectional identifier (\\(i=1,2,\\dots,N\\)). It is not a requirement to have a balanced dataset: \\(T_i\\) can be different for each \\(i\\) (see Chapter 9 for technical details). Users can see templates of datasets in the folders DataSim and DataApp (see the Appendix for details) in our GitHub repository. When the dataset is uploaded, users will have a preview of it. Users should also specify the fixed part equation and the random part equation, both in R format. If only random intercepts are required, do not enter anything in the latter part (see Figure 5.11). Users should also type the name of the cross-sectional identifier variable. The results displayed and the posterior graphs are associated with the fixed effects and covariance matrix. However, users can download the posterior chains of all posterior estimates: fixed and random effects, and the covariance matrix. Figure 5.11: Hierarchical longitudinal models: Specification. "],["secGUI6.html", "5.6 Bayesian model average", " 5.6 Bayesian model average After our GUI is deployed (see Figure 5.1), the user should select Bayesian Model Averaging in the top panel. Then, Figure 5.12 will be displayed, and the user can see the radio button on the left-hand side that shows the specific models inside this generic class. Bayesian model averaging (BMA) based on a Gaussian distribution can be carried out using the Bayesian information criterion (BIC) approximation, Markov chain Monte Carlo model composition (MC3), instrumental variables (see Figure 5.12), and dynamic BMA. The first two approaches require an input dataset where the first column is the dependent variable, followed by the potentially important regressors. Users should set the bandwidth model selection parameter (\\(O_R\\)) and the number of iterations for BIC and MC3, respectively (see Chapter 10 for technical details). The results include the posterior inclusion probability (\\(p \\neq 0\\)), expected value (EV), and standard deviation (SD) of the coefficients associated with each regressor. The BIC framework also displays the most relevant models with their posterior model probabilities (PMP). Users can download two csv files: Best models and Descriptive statistics coefficients. The former is a 0-1 matrix such that the columns are the regressors and the rows are the models; a 1 indicates the presence of a specific regressor in a specific model, and 0 indicates its absence. Note that the last column of this file is the posterior model probability for each model (row). The latter file shows the posterior inclusion probabilities, expected values, and standard deviations associated with each regressor, taking into account the BMA procedure based on the best models. Figure 5.12: Bayesian model averaging: Specification. Bayesian model averaging with endogeneity issues requires two input files. The first file should have the dependent variable in the first column, followed by the regressors with endogeneity issues, and then the exogenous regressors. The user should include a column of 1’s if an intercept is required. The second input file contains all the instruments. Users should also specify the number of regressors with endogeneity issues (see Figure 5.13). Figure 5.13: Bayesian model averaging: Instrumental variable specification. The results include the posterior inclusion probabilities and expected values for each regressor. The user can find the results of the main equation, and then of the auxiliary equations. Users can download csv files of BMA results for both the second stage (main equation) and the first stage (auxiliary equations). In addition, users can download the posterior chains of the location parameters of the main equation, \\(\\beta_{l}\\), \\(l=1,2,\\dots,dim\\left\\{\\boldsymbol{\\beta}\\right\\}\\), the location parameters of the auxiliary equations, \\(\\gamma_{j,i}\\), \\(j=1,2,\\dots,dim\\left\\{\\boldsymbol{\\beta}_s\\right\\}\\) where \\(dim\\left\\{\\boldsymbol{\\beta}_s\\right\\}\\) is the number of regressors with endogeneity issues, \\(i=1,2,\\dots,dim\\left\\{\\boldsymbol{\\gamma}\\right\\}\\), where \\(dim\\left\\{\\boldsymbol{\\gamma}\\right\\}\\) is the number of regressors in the auxiliary regressors (exogenous regressors + instruments), and the elements of the covariance matrix \\(\\sigma_{j,k}\\) (see Chapter 10 for technical details). Dynamic BMA also requires two files. The first is the dataset with the dependent variable and potential regressors, and the second file describes the competing models. There is one column for each regressor and one row for each competing model; 0 indicates that the regressor is not in the model, and 1 indicates that it is in the model. Users can see templates of this file in the folders DataSim and DataApp (see the Appendix for details) of our GitHub repository. Then, the users should set the forgetting parameters of the covariance and transition matrices and click the Go! button. A plot of the PMPs of the competing models is displayed, and users can click the Download the results for DBMA. Two files are downloaded: the first contains the dynamic Bayesian average filtering recursions for each state, and the second contains the PMP of each model and the dynamic Bayesian model averaging prediction. Bayesian model averaging based on BIC approximation for non-linear models (Logit, Gamma, and Poisson) requires an input dataset where the first column is the dependent variable, and the other columns are the potentially relevant regressors. Users should specify the bandwidth model selection parameters, also referred to as Occam’s window parameters (\\(O_R\\) and \\(O_L\\)). Our GUI displays the posterior inclusion probabilities (\\(p \\neq 0\\)), the expected value of the posterior coefficients (EV), and the standard deviation (SD). In addition, users can view the results associated with the models with the highest posterior model probabilities and download csv files with the results of specifications of the best models and descriptive statistics of the posterior coefficients from the BMA procedure. These files are similar to the results of the BIC approximation for the Gaussian model. "],["secGUI7.html", "5.7 Help", " 5.7 Help The last tab in our GUI is Help. There, you can find the PDF version of this book and the link to the HTML online version. Users can also send me an email at aramir21@gmail.com for any questions, comments, or suggestions. "],["secGUI8.html", "5.8 Warning", " 5.8 Warning Users should also note that sometimes our GUI shuts down. In our experience, this is due to computational issues arising from the implicit commands we call when estimating certain models. These issues may include computationally singular systems, missing values where TRUE/FALSE are needed, L-BFGS-B requiring finite values for “fn”, NA/NaN/Inf values, or errors in backsolve. These issues can sometimes be resolved by adjusting the dataset, such as avoiding high levels of multicollinearity. It should also be noted that when warning messages are displayed in our GUI, there is a high likelihood of convergence issues with the posterior chains. Therefore, the results may not be trustworthy. Users can identify these problems by checking the console in their RStudio sections, where the specific folder/file where the issue occurred will be specified. In any case, we would appreciate your feedback to improve and enhance our GUI. We should also mention that there are many ways to improve the codes presented in this book, and particularly, the following five chapters. For instance, the MCMCpack and bayesm packages perform most of the matrix operations in C++ using the Rcpp package. This substantially speeds up the algorithms compared to the codes presented in the next chapters when we program from scratch the samplers. We could further improve the computational times of our codes using parallel computing and the Rcpp package, but this requires more advanced skills that are not covered in this book. "],["Chap6.html", "Chapter 6 Univariate regression", " Chapter 6 Univariate regression We describe how to perform Bayesian inference in some of the most common univariate models: normal-inverse gamma, logit, probit, multinomial probit and logit, ordered probit, negative binomial, tobit, quantile regression, and Bayesian bootstrap in linear models. The point of departure is assuming a random sample of cross-sectional units. We then show the posterior distributions of the parameters and some applications. In addition, we show how to perform inference in various models using three levels of programming skills: our graphical user interface (GUI), packages from R, and programming the posterior distributions. The first requires no programming skills, the second requires an intermediate level, and the third demands more advanced skills. We also include mathematical and computational exercises. We can run our GUI typingshiny::runGitHub(\"besmarter/BSTApp\", launch.browser=T) in the R console or any R code editor and execute it. However, users should see Chapter 5 for details. "],["sec61.html", "6.1 The Gaussian linear model", " 6.1 The Gaussian linear model The Gaussian linear model specifies \\[ \\mathbf{y} = \\mathbf{X} \\boldsymbol{\\beta} + \\mu \\] such that \\(\\mu \\sim N(\\mathbf{0}, \\sigma^2 \\mathbf{I}_N)\\) is a stochastic error, \\(\\mathbf{X}\\) is an \\(N \\times K\\) matrix of regressors, \\(\\boldsymbol{\\beta}\\) is a \\(K\\)-dimensional vector of location coefficients, \\(\\sigma^2\\) is the variance of the model (scale parameter), \\(\\mathbf{y}\\) is an \\(N\\)-dimensional vector of a dependent variable, and \\(N\\) is the sample size. We describe this model using the conjugate family in 3.3, that is, \\[ \\pi(\\boldsymbol{\\beta},\\sigma^2) = \\pi(\\boldsymbol{\\beta} \\mid \\sigma^2) \\times \\pi(\\sigma^2), \\] which allows obtaining the posterior marginal distribution for \\(\\boldsymbol{\\beta}\\) and \\(\\sigma^2\\). We assume independent priors in this section, that is, \\[ \\pi(\\boldsymbol{\\beta},\\sigma^2) = \\pi(\\boldsymbol{\\beta}) \\times \\pi(\\sigma^2), \\] where \\(\\boldsymbol{\\beta} \\sim N(\\boldsymbol{\\beta}_0, \\mathbf{B}_0)\\) and \\(\\sigma^2 \\sim IG(\\alpha_0/2, \\delta_0/2)\\), with \\(\\alpha_0/2\\) and \\(\\delta_0/2\\) as the shape and rate parameters. This setting allows deriving the posterior conditional distributions, \\[ \\pi(\\boldsymbol{\\beta} \\mid \\sigma^2, \\mathbf{y}, \\mathbf{X}) \\] and \\[ \\pi(\\sigma^2 \\mid \\boldsymbol{\\beta}, \\mathbf{y}, \\mathbf{X}), \\] which in turn enables the use of the Gibbs sampler algorithm to perform posterior inference on \\(\\boldsymbol{\\beta}\\) and \\(\\sigma^2\\). The likelihood function in this model is \\[\\begin{align} p(\\mathbf{y} \\mid \\boldsymbol{\\beta}, \\sigma^2, \\mathbf{X}) = (2\\pi\\sigma^2)^{-\\frac{N}{2}} \\exp \\left\\{-\\frac{1}{2\\sigma^2} (\\mathbf{y} - \\mathbf{X} \\boldsymbol{\\beta})^{\\top}(\\mathbf{y} - \\mathbf{X} \\boldsymbol{\\beta}) \\right\\}. \\end{align}\\] Then, the conditional posterior distributions are \\[\\begin{align} \\boldsymbol{\\beta} \\mid \\sigma^2, \\mathbf{y}, \\mathbf{X} \\sim N(\\boldsymbol{\\beta}_n, \\mathbf{B}_n), \\end{align}\\] and \\[\\begin{align} \\sigma^2 \\mid \\boldsymbol{\\beta}, \\mathbf{y}, \\mathbf{X} \\sim IG(\\alpha_n/2, \\delta_n/2), \\end{align}\\] where \\[ \\mathbf{B}_n = (\\mathbf{B}_0^{-1} + \\sigma^{-2} \\mathbf{X}^{\\top} \\mathbf{X})^{-1}, \\] \\[ \\boldsymbol{\\beta}_n= \\mathbf{B}_n (\\mathbf{B}_0^{-1} \\boldsymbol{\\beta}_0 + \\sigma^{-2} \\mathbf{X}^{\\top} \\mathbf{y}), \\] \\[ \\alpha_n = \\alpha_0 + N, \\] \\[ \\delta_n = \\delta_0 + (\\mathbf{y} - \\mathbf{X} \\boldsymbol{\\beta})^{\\top} (\\mathbf{y} - \\mathbf{X} \\boldsymbol{\\beta}). \\] This model can be extended to consider heteroskedasticity such that \\(y_i \\sim N(\\mathbf{x}_i^{\\top} \\boldsymbol{\\beta}, \\sigma^2/\\tau_i)\\), where \\(\\tau_i \\sim G(v/2,v/2)\\). See Exercise 2 for details. Example: The market value of soccer players in Europe Let’s analyze the determinants of the market value of soccer players in Europe. In particular, we use the dataset 1ValueFootballPlayers.csv, which is in the folder DataApp in our GitHub repository: https://github.com/besmarter/BSTApp. This dataset was used by Serna Rodríguez, Ramírez Hassan, and Coad (2019) to find the determinants of high-performance soccer players in the five most important national leagues in Europe. The specification of the model is \\[\\begin{align} \\log(\\text{Value}_i) &amp;= \\beta_1 + \\beta_2 \\text{Perf}_i + \\beta_3 \\text{Age}_i + \\beta_4 \\text{Age}^2_i + \\beta_5 \\text{NatTeam}_i \\\\ &amp;\\quad + \\beta_6 \\text{Goals}_i + \\beta_7 \\text{Exp}_i + \\beta_8 \\text{Exp}^2_i + \\mu_i, \\end{align}\\] where Value is the market value in Euros (2017), Perf is a measure of performance, Age is the player’s age in years, NatTeam is an indicator variable that takes the value of 1 if the player has been on the national team, Goals is the number of goals scored by the player during his career, and Exp is his experience in years. We assume that the dependent variable follows a normal distribution, so we use a normal-inverse gamma model with vague conjugate priors where \\[ \\mathbf{B}_0 = 1000 \\mathbf{I}_{8}, \\quad \\boldsymbol{\\beta}_0 = \\mathbf{0}_{8}, \\quad \\alpha_0 = 0.001, \\quad \\delta_0 = 0.001. \\] We perform a Gibbs sampler with 5,000 MCMC iterations, plus a burn-in of 5,000, and a thinning parameter equal to 1. Once our GUI is displayed (see the beginning of this chapter), we should follow the next Algorithm to run linear Gaussian models in our GUI (see Chapter 5 for details). Algorithm: Gaussian linear model Select Univariate Models on the top panel Choose the Normal model using the left radio button Upload the dataset by selecting if there is a header and specifying the separator (comma, semicolon, or tab) Use the Browse button to select the file and preview the dataset Adjust MCMC iterations, burn-in, and thinning using the Range sliders Specify dependent and independent variables using the Formula builder Click the Build formula button to generate the model formula in R Modify the formula in the Main equation box if necessary Set hyperparameters (mean vector, covariance matrix, shape, and scale parameters) if needed Click the Go! button Analyze results Download posterior chains and diagnostic plots using the Download Posterior Chains and Download Posterior Graphs buttons We can see in the following R code examples how to perform the linear Gaussian model using the MCMCregress command from the MCMCpack package, as well as how to program the Gibbs sampler ourselves. We should obtain similar results using all three approaches: GUI, package, and our function. In fact, our GUI relies on the MCMCregress command. For instance, the value of a top soccer player in Europe increases by 134% (\\(\\exp(0.85)-1\\)) on average when he has played for the national team, with a 95% credible interval of (86%, 197%). rm(list = ls()) set.seed(010101) ########################## Linear regression: Value of soccer players ########################## Data &lt;- read.csv(&quot;https://raw.githubusercontent.com/besmarter/BSTApp/refs/heads/master/DataApp/1ValueFootballPlayers.csv&quot;, sep = &quot;,&quot;, header = TRUE, quote = &quot;&quot;) attach(Data) y &lt;- log(Value) # Value: Market value in Euros (2017) of soccer players # Regressors quantity including intercept X &lt;- cbind(1, Perf, Age, Age2, NatTeam, Goals, Exp, Exp2) # Perf: Performance. Perf2: Performance squared. Age: Age; Age: Age squared. # NatTeam: Indicator of national team. Goals: Scored goals. Goals2: Scored goals squared # Exp: Years of experience. Exp2: Years of experience squared. Assists: Number of assists k &lt;- dim(X)[2] N &lt;- dim(X)[1] # Hyperparameters d0 &lt;- 0.001/2 a0 &lt;- 0.001/2 b0 &lt;- rep(0, k) c0 &lt;- 1000 B0 &lt;- c0*diag(k) B0i &lt;- solve(B0) # MCMC parameters mcmc &lt;- 5000 burnin &lt;- 5000 tot &lt;- mcmc + burnin thin &lt;- 1 # Posterior distributions using packages: MCMCpack sets the model in terms of the precision matrix posterior &lt;- MCMCpack::MCMCregress(y~X-1, b0=b0, B0 = B0i, c0 = a0, d0 = d0, burnin = burnin, mcmc = mcmc, thin = thin) summary(coda::mcmc(posterior)) ## ## Iterations = 1:5000 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 5000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## X 3.695499 2.228060 3.151e-02 3.151e-02 ## XPerf 0.035445 0.004299 6.079e-05 6.079e-05 ## XAge 0.778410 0.181362 2.565e-03 2.565e-03 ## XAge2 -0.016617 0.003380 4.781e-05 4.781e-05 ## XNatTeam 0.850362 0.116861 1.653e-03 1.689e-03 ## XGoals 0.009097 0.001603 2.266e-05 2.266e-05 ## XExp 0.206208 0.062713 8.869e-04 8.428e-04 ## XExp2 -0.006992 0.002718 3.844e-05 3.719e-05 ## sigma2 0.969590 0.076091 1.076e-03 1.076e-03 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## X -0.545746 2.174460 3.653373 5.171463 8.177948 ## XPerf 0.026933 0.032570 0.035421 0.038368 0.043817 ## XAge 0.419057 0.656975 0.779534 0.902753 1.125442 ## XAge2 -0.022967 -0.018928 -0.016651 -0.014366 -0.009919 ## XNatTeam 0.627228 0.771339 0.852420 0.928765 1.075360 ## XGoals 0.005914 0.007984 0.009108 0.010180 0.012272 ## XExp 0.082206 0.164290 0.206742 0.248716 0.329809 ## XExp2 -0.012290 -0.008829 -0.007002 -0.005188 -0.001762 ## sigma2 0.832320 0.915580 0.965122 1.018776 1.127566 # Posterior distributions programming the Gibbs sampling # Auxiliary parameters XtX &lt;- t(X)%*%X bhat &lt;- solve(XtX)%*%t(X)%*%y an &lt;- a0 + N # Gibbs sampling functions PostSig2 &lt;- function(Beta){ dn &lt;- d0 + t(y - X%*%Beta)%*%(y - X%*%Beta) sig2 &lt;- invgamma::rinvgamma(1, shape = an/2, rate = dn/2) return(sig2) } PostBeta &lt;- function(sig2){ Bn &lt;- solve(B0i + sig2^(-1)*XtX) bn &lt;- Bn%*%(B0i%*%b0 + sig2^(-1)*XtX%*%bhat) Beta &lt;- MASS::mvrnorm(1, bn, Bn) return(Beta) } PostBetas &lt;- matrix(0, mcmc+burnin, k) PostSigma2 &lt;- rep(0, mcmc+burnin) Beta &lt;- rep(0, k) for(s in 1:tot){ sig2 &lt;- PostSig2(Beta = Beta) PostSigma2[s] &lt;- sig2 Beta &lt;- PostBeta(sig2 = sig2) PostBetas[s,] &lt;- Beta } keep &lt;- seq((burnin+1), tot, thin) PosteriorBetas &lt;- PostBetas[keep,] colnames(PosteriorBetas) &lt;- c(&quot;Intercept&quot;, &quot;Perf&quot;, &quot;Age&quot;, &quot;Age2&quot;, &quot;NatTeam&quot;, &quot;Goals&quot;, &quot;Exp&quot;, &quot;Exp2&quot;) summary(coda::mcmc(PosteriorBetas)) ## ## Iterations = 1:5000 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 5000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## Intercept 3.663230 2.194363 3.103e-02 3.103e-02 ## Perf 0.035361 0.004315 6.102e-05 6.102e-05 ## Age 0.780374 0.178530 2.525e-03 2.525e-03 ## Age2 -0.016641 0.003332 4.713e-05 4.713e-05 ## NatTeam 0.850094 0.119093 1.684e-03 1.684e-03 ## Goals 0.009164 0.001605 2.270e-05 2.270e-05 ## Exp 0.205965 0.062985 8.907e-04 8.596e-04 ## Exp2 -0.007006 0.002731 3.862e-05 3.701e-05 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## Intercept -0.579087 2.169333 3.651261 5.108860 8.023949 ## Perf 0.027018 0.032474 0.035346 0.038165 0.044079 ## Age 0.429084 0.662879 0.781856 0.901172 1.126256 ## Age2 -0.023079 -0.018883 -0.016662 -0.014410 -0.010018 ## NatTeam 0.621226 0.769287 0.848137 0.930096 1.088729 ## Goals 0.006026 0.008065 0.009176 0.010249 0.012240 ## Exp 0.080559 0.163623 0.206094 0.248598 0.327669 ## Exp2 -0.012354 -0.008885 -0.007009 -0.005166 -0.001629 PosteriorSigma2 &lt;- PostSigma2[keep] summary(coda::mcmc(PosteriorSigma2)) ## ## Iterations = 1:5000 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 5000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## 0.973309 0.077316 0.001093 0.001116 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## 0.8361 0.9189 0.9685 1.0228 1.1421 References "],["sec62.html", "6.2 The logit model", " 6.2 The logit model In the logit model, the dependent variable is binary, \\(y_i=\\left\\{1,0\\right\\}\\), which follows a Bernoulli distribution, \\(y_i \\stackrel{ind}{\\sim} B(\\pi_i)\\), such that \\(p(y_i=1)=\\pi_i\\), where \\(\\pi_i = \\frac{\\exp\\left\\{{\\mathbf{x}}_i^{\\top}\\boldsymbol{\\beta}\\right\\}}{1 + \\exp\\left\\{{\\mathbf{x}}_i^{\\top}\\boldsymbol{\\beta}\\right\\}}\\), and \\(\\mathbf{x}_i\\) is a \\(K\\)-dimensional vector of regressors. The likelihood function of the logit model is: \\[ p({\\mathbf{y}} \\mid \\boldsymbol{\\beta}, {\\mathbf{X}}) = \\prod_{i=1}^N \\pi_i^{y_i}(1 - \\pi_i)^{1 - y_i} \\] \\[ = \\prod_{i=1}^N \\left( \\frac{\\exp\\left\\{{\\mathbf{x}}_i^{\\top}\\boldsymbol{\\beta}\\right\\}}{1 + \\exp\\left\\{{\\mathbf{x}}_i^{\\top}\\boldsymbol{\\beta}\\right\\}} \\right)^{y_i} \\left( \\frac{1}{1 + \\exp\\left\\{{\\mathbf{x}}_i^{\\top}\\boldsymbol{\\beta}\\right\\}} \\right)^{1 - y_i}. \\] We can specify a Normal distribution as a prior, \\(\\boldsymbol{\\beta} \\sim N({\\boldsymbol{\\beta}}_0, {\\mathbf{B}}_0)\\). Then, the posterior distribution is: \\[ \\pi(\\boldsymbol{\\beta} \\mid {\\mathbf{y}}, {\\mathbf{X}}) \\propto \\prod_{i=1}^N \\left( \\frac{\\exp\\left\\{{\\mathbf{x}}_i^{\\top}\\boldsymbol{\\beta}\\right\\}}{1 + \\exp\\left\\{{\\mathbf{x}}_i^{\\top}\\boldsymbol{\\beta}\\right\\}} \\right)^{y_i} \\left( \\frac{1}{1 + \\exp\\left\\{{\\mathbf{x}}_i^{\\top}\\boldsymbol{\\beta}\\right\\}} \\right)^{1 - y_i} \\] \\[ \\times \\exp\\left\\{-\\frac{1}{2}(\\boldsymbol{\\beta} - \\boldsymbol{\\beta}_0)^{\\top} {\\mathbf{B}}_0^{-1} (\\boldsymbol{\\beta} - \\boldsymbol{\\beta}_0)\\right\\}. \\] The logit model does not have a standard posterior distribution. Therefore, a random walk Metropolis–Hastings algorithm can be used to obtain draws from the posterior distribution. A potential proposal distribution is a multivariate normal, centered at the current value, with covariance matrix \\(\\tau^2({\\mathbf{B}}_0^{-1} + \\widehat{{\\mathbf{\\Sigma}}}^{-1})^{-1}\\), where \\(\\tau &gt; 0\\) is a tuning parameter and \\(\\widehat{\\mathbf{\\Sigma}}\\) is the sample covariance matrix obtained from the maximum likelihood estimation (Martin, Quinn, and Park 2011). Tuning parameters should be set in a way that ensures reasonable diagnostic criteria and acceptance rates. Observe that: \\[ \\log(p({\\mathbf{y}} \\mid \\boldsymbol{\\beta}, {\\mathbf{X}})) = \\sum_{i=1}^N y_i {\\mathbf{x}}_i^{\\top} \\boldsymbol{\\beta} - \\log(1 + \\exp({\\mathbf{x}}_i^{\\top} \\boldsymbol{\\beta})). \\] This expression can be used when calculating the acceptance parameter in the computational implementation of the Metropolis-Hastings algorithm. In particular, the acceptance parameter is: \\[ \\alpha = \\min\\left\\{1, \\exp\\left(\\log(p({\\mathbf{y}} \\mid \\boldsymbol{\\beta}^{c}, {\\mathbf{X}})) + \\log(\\pi(\\boldsymbol{\\beta}^c)) - \\left(\\log(p({\\mathbf{y}} \\mid \\boldsymbol{\\beta}^{(s-1)}, {\\mathbf{X}})) + \\log(\\pi(\\boldsymbol{\\beta}^{(s-1)}))\\right)\\right)\\right\\}, \\] where \\(\\boldsymbol{\\beta}^c\\) and \\(\\boldsymbol{\\beta}^{(s-1)}\\) are the draws from the proposal distribution and the previous iteration of the Markov chain, respectively. Formulating the acceptance rate using \\(\\log\\) helps mitigate computational problems. Example: Simulation exercise Let’s do a simulation exercise to check the performance of the algorithm. Set \\(\\boldsymbol{\\beta} = \\begin{bmatrix}0.5 &amp; 0.8 &amp; -1.2\\end{bmatrix}^{\\top}\\), \\(x_{ik} \\sim N(0,1)\\), \\(k=2,3\\) and \\(i=1,2,\\dots,10000\\). We set as hyperparameters \\(\\boldsymbol{\\beta}_0 = [0 \\ 0 \\ 0]^{\\top}\\) and \\({\\mathbf{B}}_0 = 1000 {\\mathbf{I}}_3\\). The tuning parameter for the Metropolis-Hastings algorithm is equal to 1. Once our GUI is displayed (see beginning of this chapter), we should follow the next Algorithm to run logit models in our GUI (see Chapter 5 for details): Algorithm: Logit model Select Univariate Models on the top panel Select Logit model using the left radio button Upload the dataset by first selecting whether there is a header in the file, and the kind of separator in the csv file of the dataset (comma, semicolon, or tab). Then, use the Browse button under the Choose File legend. You should see a preview of the dataset Select MCMC iterations, burn-in, and thinning parameters using the Range sliders Select dependent and independent variables using the Formula builder table Click the Build formula button to generate the formula in R syntax. You can modify the formula in the Main equation box using valid arguments of the formula command structure in R Set the hyperparameters: mean vector and covariance matrix. This step is not necessary as by default our GUI uses non-informative priors Select the tuning parameter for the Metropolis-Hastings algorithm. This step is not necessary as by default our GUI sets the tuning parameter at 1.1 Click the Go! button Analyze results Download posterior chains and diagnostic plots using the Download Posterior Chains and Download Posterior Graphs buttons We can see in the following R code how to perform the logit model using the MCMClogit command from the MCMCpack package, as well as by programming the Metropolis-Hastings algorithm ourselves. We should obtain similar results using the three approaches: GUI, package, and our function. Our GUI relies on the MCMClogit command. In particular, we achieve an acceptance rate of 0.46, and the diagnostics suggest that the posterior chains behave well. In general, the 95% credible intervals encompass the population values, and both the mean and median are very close to these values. ########################## Logit: Simulation ########################## # Simulate data rm(list = ls()) set.seed(010101) N &lt;- 10000 # Sample size B &lt;- c(0.5, 0.8, -1.2) # Population location parameters x2 &lt;- rnorm(N) # Regressor x3 &lt;- rnorm(N) # Regressor X &lt;- cbind(1, x2, x3) # Regressors XB &lt;- X%*%B PY &lt;- exp(XB)/(1 + exp(XB)) # Probability of Y = 1 Y &lt;- rbinom(N, 1, PY) # Draw Y&#39;s table(Y) # Frequency ## Y ## 0 1 ## 4115 5885 # write.csv(cbind(Y, x2, x3), file = &quot;DataSimulations/LogitSim.csv&quot;) # Export data # MCMC parameters iter &lt;- 5000; burnin &lt;- 1000; thin &lt;- 5; tune &lt;- 1 # Hyperparameters K &lt;- dim(X)[2] b0 &lt;- rep(0, K) c0 &lt;- 1000 B0 &lt;- c0*diag(K) B0i &lt;- solve(B0) # Posterior distributions using packages: MCMCpack sets the model in terms of the precision matrix RegLog &lt;- MCMCpack::MCMClogit(Y~X-1, mcmc = iter, burnin = burnin, thin = thin, b0 = b0, B0 = B0i, tune = tune) summary(RegLog) ## ## Iterations = 1001:5996 ## Thinning interval = 5 ## Number of chains = 1 ## Sample size per chain = 1000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## X 0.4896 0.02550 0.0008064 0.001246 ## Xx2 0.8330 0.02730 0.0008632 0.001406 ## Xx3 -1.2104 0.03049 0.0009643 0.001536 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## X 0.4424 0.4728 0.4894 0.5072 0.5405 ## Xx2 0.7787 0.8159 0.8327 0.8505 0.8852 ## Xx3 -1.2758 -1.2296 -1.2088 -1.1902 -1.1513 # Posterior distributions programming the Metropolis-Hastings algorithm MHfunc &lt;- function(y, X, b0 = rep(0, dim(X)[2] + 1), B0 = 1000*diag(dim(X)[2] + 1), tau = 1, iter = 6000, burnin = 1000, thin = 5){ Xm &lt;- cbind(1, X) # Regressors K &lt;- dim(Xm)[2] # Number of location parameters BETAS &lt;- matrix(0, iter + burnin, K) # Space for posterior chains Reg &lt;- glm(y ~ Xm - 1, family = binomial(link = &quot;logit&quot;)) # Maximum likelihood estimation BETA &lt;- Reg$coefficients # Maximum likelihood parameter estimates tot &lt;- iter + burnin # Total iterations M-H algorithm COV &lt;- vcov(Reg) # Maximum likelihood covariance matrix COVt &lt;- tau^2*solve(solve(B0) + solve(COV)) # Covariance matrix for the proposal distribution Accep &lt;- rep(0, tot) # Space for calculating the acceptance rate # Create progress bar in case that you want to see iterations progress pb &lt;- winProgressBar(title = &quot;progress bar&quot;, min = 0, max = tot, width = 300) for(it in 1:tot){ BETAc &lt;- BETA + MASS::mvrnorm(n = 1, mu = rep(0, K), Sigma = COVt) # Candidate location parameter likecand &lt;- sum((Xm%*%BETAc) * Y - apply(Xm%*%BETAc, 1, function(x) log(1 + exp(x)))) # Log likelihood for the candidate likepast &lt;- sum((Xm%*%BETA) * Y - apply((Xm%*%BETA), 1, function(x) log(1 + exp(x)))) # Log likelihood for the actual draw priorcand &lt;- (-1/2)*crossprod((BETAc - b0), solve(B0))%*%(BETAc - b0) # Log prior for candidate priorpast &lt;- (-1/2)*crossprod((BETA - b0), solve(B0))%*%(BETA - b0) # Log prior for actual draw alpha &lt;- min(1, exp((likecand + priorcand) - (likepast + priorpast))) #Probability of selecting candidate u &lt;- runif(1) # Decision rule for selecting candidate if(u &lt; alpha){ BETA &lt;- BETAc # Changing reference for candidate if selected Accep[it] &lt;- 1 # Indicator if the candidate is accepted } BETAS[it, ] &lt;- BETA # Saving draws setWinProgressBar(pb, it, title=paste( round(it/tot*100, 0), &quot;% done&quot;)) } close(pb) keep &lt;- seq(burnin, tot, thin) return(list(Bs = BETAS[keep[-1], ], AceptRate = mean(Accep[keep[-1]]))) } Posterior &lt;- MHfunc(y = Y, X = cbind(x2, x3), iter = iter, burnin = burnin, thin = thin) # Running our M-H function changing some default parameters. paste(&quot;Acceptance rate equal to&quot;, round(Posterior$AceptRate, 2), sep = &quot; &quot;) ## [1] &quot;Acceptance rate equal to 0.46&quot; &quot;Acceptance rate equal to 0.46&quot; ## [1] &quot;Acceptance rate equal to 0.46&quot; PostPar &lt;- coda::mcmc(Posterior$Bs) # Names colnames(PostPar) &lt;- c(&quot;Cte&quot;, &quot;x1&quot;, &quot;x2&quot;) # Summary posterior draws summary(PostPar) ## ## Iterations = 1:1000 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 1000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## Cte 0.4893 0.02427 0.0007674 0.001223 ## x1 0.8309 0.02699 0.0008536 0.001440 ## x2 -1.2107 0.02943 0.0009308 0.001423 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## Cte 0.4431 0.4721 0.4899 0.5059 0.5344 ## x1 0.7817 0.8123 0.8305 0.8505 0.8833 ## x2 -1.2665 -1.2309 -1.2107 -1.1911 -1.1538 # Trace and density plots plot(PostPar) # Autocorrelation plots coda::autocorr.plot(PostPar) # Convergence diagnostics coda::geweke.diag(PostPar) ## ## Fraction in 1st window = 0.1 ## Fraction in 2nd window = 0.5 ## ## Cte x1 x2 ## -0.975 -3.112 1.326 coda::raftery.diag(PostPar,q=0.5,r=0.05,s = 0.95) ## ## Quantile (q) = 0.5 ## Accuracy (r) = +/- 0.05 ## Probability (s) = 0.95 ## ## Burn-in Total Lower bound Dependence ## (M) (N) (Nmin) factor (I) ## Cte 6 731 385 1.90 ## x1 6 703 385 1.83 ## x2 6 725 385 1.88 coda::heidel.diag(PostPar) ## ## Stationarity start p-value ## test iteration ## Cte passed 1 0.4436 ## x1 passed 101 0.3470 ## x2 passed 1 0.0872 ## ## Halfwidth Mean Halfwidth ## test ## Cte passed 0.489 0.00240 ## x1 passed 0.832 0.00268 ## x2 passed -1.211 0.00279 References "],["sec63.html", "6.3 The probit model", " 6.3 The probit model The probit model also has a binary dependent variable. In this case, there is a latent variable (\\(y_i^*\\), which is unobserved) that defines the structure of the estimation problem. In particular, \\[ y_i = \\begin{cases} 0, &amp; \\text{if } y_i^* \\leq 0, \\\\ 1, &amp; \\text{if } y_i^* &gt; 0. \\end{cases} \\] such that \\(y_i^* = \\mathbf{x}_i^{\\top}\\boldsymbol{\\beta} + \\mu_i\\), where \\(\\mu_i \\stackrel{i.i.d.}{\\sim} N(0,1)\\).28 This implies \\(P(y_i = 1) = \\pi_i = \\Phi(\\mathbf{x}_i^{\\top} \\boldsymbol{\\beta})\\), where \\(\\mathbf{x}_i\\) is a \\(K\\)-dimensional vector of regressors. J. H. Albert and Chib (1993) implemented data augmentation (Tanner and Wong 1987) to apply a Gibbs sampling algorithm to this model. Augmenting this model with \\(y_i^*\\), we can express the likelihood contribution from observation \\(i\\) as: \\[ p(y_i \\mid y_i^*) = \\mathbb{1}({y_i = 0}) \\mathbb{1}({y_i^* \\leq 0}) + \\mathbb{1}({y_i = 1}) \\mathbb{1}({y_i^* &gt; 0}), \\] where \\(\\mathbb{1}(A)\\) is an indicator function that takes the value of 1 when the condition \\(A\\) is satisfied. The posterior distribution is: \\[ \\pi(\\boldsymbol{\\beta}, \\mathbf{y^*} \\mid \\mathbf{y}, \\mathbf{X}) \\propto \\prod_{i=1}^N \\left[\\mathbb{1}({y_i = 0}) \\mathbb{1}({y_i^* \\leq 0}) + \\mathbb{1}({y_i = 1}) \\mathbb{1}({y_i^* &gt; 0}) \\right] \\] \\[ \\times N_N(\\mathbf{y^*} \\mid \\mathbf{X\\boldsymbol{\\beta}}, \\mathbf{I}_n) \\times N_K(\\boldsymbol{\\beta} \\mid \\boldsymbol{\\beta}_0, \\mathbf{B}_0), \\] where we assume a Gaussian prior for \\(\\boldsymbol{\\beta}\\): \\(\\boldsymbol{\\beta} \\sim N_K(\\boldsymbol{\\beta}_0, \\mathbf{B}_0)\\). This implies \\[ y_i^* \\mid \\boldsymbol{\\beta}, \\mathbf{y}, \\mathbf{X} \\sim \\begin{cases} TN_{(-\\infty,0]}(\\mathbf{x}_i^{\\top} \\boldsymbol{\\beta}, 1) &amp; \\text{if } y_i = 0, \\\\ TN_{(0,\\infty)}(\\mathbf{x}_i^{\\top} \\boldsymbol{\\beta}, 1) &amp; \\text{if } y_i = 1, \\end{cases}, \\] where \\(TN\\) denotes a truncated normal density. \\[ \\boldsymbol{\\beta} \\mid \\mathbf{y}^*, \\mathbf{X} \\sim N(\\boldsymbol{\\beta}_n, \\mathbf{B}_n), \\] where \\(\\mathbf{B}_n = (\\mathbf{B}_0^{-1} + \\mathbf{X}^{\\top} \\mathbf{X})^{-1}\\), and \\(\\boldsymbol{\\beta}_n = \\mathbf{B}_n (\\mathbf{B}_0^{-1} \\boldsymbol{\\beta}_0 + \\mathbf{X}^{\\top} \\mathbf{y}^*)\\). Example: Determinants of hospitalization We use the dataset named 2HealthMed.csv, which is located in the DataApp folder of our GitHub repository (https://github.com/besmarter/BSTApp), and was used by Ramírez Hassan, Cardona Jiménez, and Cadavid Montoya (2013). The dependent variable is a binary indicator, taking the value 1 if an individual was hospitalized in 2007, and 0 otherwise. The specification of the model is \\[ \\text{Hosp}_i = \\boldsymbol{\\beta}_1 + \\boldsymbol{\\beta}_2 \\text{SHI}_i + \\boldsymbol{\\beta}_3 \\text{Female}_i + \\boldsymbol{\\beta}_4 \\text{Age}_i + \\boldsymbol{\\beta}_5 \\text{Age}_i^2 + \\boldsymbol{\\beta}_6 \\text{Est2}_i + \\boldsymbol{\\beta}_7 \\text{Est3}_i + \\boldsymbol{\\beta}_8 \\text{Fair}_i + \\boldsymbol{\\beta}_9 \\text{Good}_i + \\boldsymbol{\\beta}_{10} \\text{Excellent}_i, \\] where SHI is a binary variable equal to 1 if the individual is enrolled in a subsidized health care program and 0 otherwise, Female is an indicator of gender, Age is in years, Est2 and Est3 are indicators of socioeconomic status, with Est1 being the reference category (the lowest status), and HealthStatus is a self-perception of health status, where bad is the reference category. We set \\(\\boldsymbol{\\beta}_0 = {\\boldsymbol{0}}_{10}\\), \\({\\boldsymbol{B}}_0 = {\\boldsymbol{I}}_{10}\\), with iterations, burn-in, and thinning parameters equal to 10000, 1000, and 1, respectively. We can use the next Algorithm to run the probit model in our GUI. Our GUI relies on the rbprobitGibbs command from the bayesm package to perform inference in the probit model. The following R code shows how to run this example using the rbprobitGibbs command. We also asked you to implement a Gibbs sampler algorithm to perform inference in the probit model in the exercises. Algorithm: Probit model Select Univariate Models on the top panel Select Probit model using the left radio button Upload the dataset by first selecting whether there is a header in the file, and the kind of separator in the csv file of the dataset (comma, semicolon, or tab). Then, use the Browse button under the Choose File legend. You should see a preview of the dataset Select MCMC iterations, burn-in, and thinning parameters using the Range sliders Select dependent and independent variables using the Formula builder table Click the Build formula button to generate the formula in R syntax. You can modify the formula in the Main equation box using valid arguments of the formula command structure in R Set the hyperparameters: mean vector and covariance matrix. This step is not necessary as by default our GUI uses non-informative priors Select the tuning parameter for the Metropolis-Hastings algorithm. This step is not necessary as by default our GUI sets the tuning parameter at 1.1 Click the Go! button Analyze results Download posterior chains and diagnostic plots using the Download Posterior Chains and Download Posterior Graphs buttons Our analysis finds evidence that gender and self-perceived health status significantly affect the probability of hospitalization. Women have a higher probability of being hospitalized than men, and individuals with a better perception of their health status have a lower probability of hospitalization. mydata &lt;- read.csv(&quot;https://raw.githubusercontent.com/besmarter/BSTApp/refs/heads/master/DataApp/2HealthMed.csv&quot;, sep = &quot;,&quot;, header = TRUE, quote = &quot;&quot;) attach(mydata) ## The following objects are masked from Data (pos = 3): ## ## Age, Age2 ## The following object is masked from DataUtEst: ## ## id str(mydata) ## &#39;data.frame&#39;: 12975 obs. of 22 variables: ## $ id : int 1 2 3 4 5 6 7 8 9 10 ... ## $ MedVisPrev : int 0 0 0 0 0 0 0 0 0 0 ... ## $ MedVisPrevOr: int 1 1 1 1 1 1 1 1 1 1 ... ## $ Hosp : int 0 0 0 0 0 0 0 0 0 0 ... ## $ SHI : int 1 1 1 1 0 0 1 1 0 0 ... ## $ Female : int 0 1 1 1 0 1 0 1 0 1 ... ## $ Age : int 7 39 23 15 8 54 64 40 6 7 ... ## $ Age2 : int 49 1521 529 225 64 2916 4096 1600 36 49 ... ## $ FemaleAge : int 0 39 23 15 0 54 0 40 0 7 ... ## $ Est1 : int 1 0 0 0 0 0 0 0 0 0 ... ## $ Est2 : int 0 1 1 1 0 1 1 1 0 0 ... ## $ Est3 : int 0 0 0 0 1 0 0 0 1 1 ... ## $ Bad : int 0 0 0 0 0 0 0 0 0 0 ... ## $ Fair : int 0 0 0 0 0 0 1 0 0 0 ... ## $ Good : int 1 1 1 1 0 0 0 1 1 1 ... ## $ Excellent : int 0 0 0 0 1 1 0 0 0 0 ... ## $ NoEd : int 1 0 0 0 1 0 0 0 1 1 ... ## $ PriEd : int 0 0 0 0 0 1 1 1 0 0 ... ## $ HighEd : int 0 1 1 1 0 0 0 0 0 0 ... ## $ VocEd : int 0 0 0 0 0 0 0 0 0 0 ... ## $ UnivEd : int 0 0 0 0 0 0 0 0 0 0 ... ## $ PTL : num 0.43 0 0 0 0 0.06 0 0.38 0 1 ... K &lt;- 10 # Number of regressors b0 &lt;- rep(0, K) # Prio mean B0i &lt;- diag(K) # Prior precision (inverse of covariance) Prior &lt;- list(betabar = b0, A = B0i) # Prior list y &lt;- Hosp # Dependent variables X &lt;- cbind(1, SHI, Female, Age, Age2, Est2, Est3, Fair, Good, Excellent) # Regressors Data &lt;- list(y = y, X = X) # Data list Mcmc &lt;- list(R = 10000, keep = 1, nprint = 0) # MCMC parameters RegProb &lt;- bayesm::rbprobitGibbs(Data = Data, Prior = Prior, Mcmc = Mcmc) # Inference using bayesm package ## ## Starting Gibbs Sampler for Binary Probit Model ## with 12975 observations ## Table of y Values ## y ## 0 1 ## 12571 404 ## ## Prior Parms: ## betabar ## [1] 0 0 0 0 0 0 0 0 0 0 ## A ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] ## [1,] 1 0 0 0 0 0 0 0 0 0 ## [2,] 0 1 0 0 0 0 0 0 0 0 ## [3,] 0 0 1 0 0 0 0 0 0 0 ## [4,] 0 0 0 1 0 0 0 0 0 0 ## [5,] 0 0 0 0 1 0 0 0 0 0 ## [6,] 0 0 0 0 0 1 0 0 0 0 ## [7,] 0 0 0 0 0 0 1 0 0 0 ## [8,] 0 0 0 0 0 0 0 1 0 0 ## [9,] 0 0 0 0 0 0 0 0 1 0 ## [10,] 0 0 0 0 0 0 0 0 0 1 ## ## MCMC parms: ## R= 10000 keep= 1 nprint= 0 ## PostPar &lt;- coda::mcmc(RegProb$betadraw) # Posterior draws colnames(PostPar) &lt;- c(&quot;Cte&quot;, &quot;SHI&quot;, &quot;Female&quot;, &quot;Age&quot;, &quot;Age2&quot;, &quot;Est2&quot;, &quot;Est3&quot;, &quot;Fair&quot;, &quot;Good&quot;, &quot;Excellent&quot;) # Names summary(PostPar) # Posterior summary ## ## Iterations = 1:10000 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 10000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## Cte -9.443e-01 1.347e-01 1.347e-03 3.413e-03 ## SHI -7.227e-03 5.934e-02 5.934e-04 2.229e-03 ## Female 1.260e-01 4.807e-02 4.807e-04 1.780e-03 ## Age 1.112e-04 3.551e-03 3.551e-05 1.164e-04 ## Age2 4.078e-05 4.222e-05 4.222e-07 1.249e-06 ## Est2 -8.658e-02 5.370e-02 5.370e-04 1.898e-03 ## Est3 -4.254e-02 8.112e-02 8.112e-04 2.774e-03 ## Fair -4.961e-01 1.119e-01 1.119e-03 2.013e-03 ## Good -1.204e+00 1.114e-01 1.114e-03 2.205e-03 ## Excellent -1.061e+00 1.316e-01 1.316e-03 3.136e-03 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## Cte -1.210e+00 -1.034e+00 -9.450e-01 -8.523e-01 -0.6839311 ## SHI -1.207e-01 -4.742e-02 -8.527e-03 3.225e-02 0.1125873 ## Female 3.273e-02 9.359e-02 1.261e-01 1.585e-01 0.2219169 ## Age -6.849e-03 -2.343e-03 6.224e-05 2.535e-03 0.0071123 ## Age2 -4.198e-05 1.215e-05 4.177e-05 6.976e-05 0.0001213 ## Est2 -1.911e-01 -1.235e-01 -8.634e-02 -4.971e-02 0.0168394 ## Est3 -2.018e-01 -9.709e-02 -4.153e-02 1.256e-02 0.1129273 ## Fair -7.141e-01 -5.704e-01 -4.971e-01 -4.218e-01 -0.2752697 ## Good -1.419e+00 -1.279e+00 -1.205e+00 -1.131e+00 -0.9832597 ## Excellent -1.323e+00 -1.147e+00 -1.062e+00 -9.730e-01 -0.8028882 References "],["sec64.html", "6.4 The multinomial probit model", " 6.4 The multinomial probit model The multinomial probit model is used to model the choice of the \\(l\\)-th alternative over a set of \\(L\\) mutually exclusive options. We observe the following: \\[ y_{il} = \\begin{cases} 1, &amp; \\text{if } y_{il}^* \\geq \\max\\left\\{\\boldsymbol{y}_i^*\\right\\}, \\\\ 0, &amp; \\text{otherwise,} \\end{cases} \\] where \\(\\boldsymbol{y}_i^* = \\boldsymbol{X}_{i} \\boldsymbol{\\delta} + \\boldsymbol{\\mu}_i\\), with \\(\\boldsymbol{\\mu}_i \\stackrel{i.i.d.}{\\sim} N(\\boldsymbol{0}, \\boldsymbol{\\Sigma})\\). The vector \\(\\boldsymbol{y}_i^*\\) is an unobserved latent vector of dimension \\(L\\). The matrix \\(\\boldsymbol{X}_i = \\left[(1 \\ \\boldsymbol{c}_i^{\\top}) \\otimes \\boldsymbol{I}_L \\ \\boldsymbol{A}_i\\right]\\) is an \\(L \\times j\\) matrix of regressors for each alternative, where \\(l = 1, 2, \\dots, L\\), and \\(j = L \\times (1 + \\text{dim}(\\boldsymbol{c}_i)) + a\\). Here, \\(\\boldsymbol{c}_i\\) is a vector of individual-specific characteristics, \\(\\boldsymbol{A}_i\\) is an \\(L \\times a\\) matrix of alternative-varying regressors, \\(a\\) is the number of alternative-varying regressors, and \\(\\boldsymbol{\\delta}\\) is a \\(j\\)-dimensional vector of parameters. We take into account simultaneously the alternative-varying regressors (alternative attributes) and alternative-invariant regressors (individual characteristics).29 The vector \\(\\boldsymbol{y}_i^*\\) can be stacked into a multiple regression model with correlated stochastic errors, i.e., \\(\\boldsymbol{y}^* = \\boldsymbol{X} \\boldsymbol{\\delta} + \\boldsymbol{\\mu}\\), where \\(\\boldsymbol{y}^* = \\left[\\boldsymbol{y}_1^{*\\top} \\ \\boldsymbol{y}_2^{*\\top} \\ \\dots \\ \\boldsymbol{y}_N^{*\\top}\\right]\\), \\(\\boldsymbol{X} = \\left[\\boldsymbol{X}_1^{\\top} \\ \\boldsymbol{X}_2^{\\top} \\ \\dots \\ \\boldsymbol{X}_N^{\\top}\\right]^{\\top}\\), and \\(\\boldsymbol{\\mu} = \\left[\\boldsymbol{\\mu}_1^{\\top} \\ \\boldsymbol{\\mu}_2^{\\top} \\ \\dots \\ \\boldsymbol{\\mu}_N^{\\top}\\right]^{\\top}\\). Following the practice of expressing \\(y_{il}^*\\) relative to \\(y_{iL}^*\\) by letting \\(\\boldsymbol{w}_i = \\left[w_{i1} \\ w_{i2} \\ \\dots \\ w_{iL-1}\\right]^{\\top}\\), where \\(w_{il} = y_{il}^* - y_{iL}^*\\), we can write \\(\\boldsymbol{w}_i = \\boldsymbol{R}_i \\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}_i\\), with \\(\\boldsymbol{\\epsilon}_i \\sim N(\\boldsymbol{0}, \\boldsymbol{\\Omega})\\), where \\(\\boldsymbol{R}_i = \\left[(1 \\ \\boldsymbol{c}_i^{\\top}) \\otimes \\boldsymbol{I}_{L-1} \\ \\boldsymbol{\\Delta A}_i\\right]\\) is an \\((L-1) \\times K\\) matrix, with \\(\\Delta \\boldsymbol{A}_i = \\boldsymbol{A}_{li} - \\boldsymbol{A}_{Li}\\), for \\(l = 1, 2, \\dots, L-1\\). That is, the last row of \\(\\boldsymbol{A}_i\\) is subtracted from each row of \\(\\boldsymbol{A}_i\\), and \\(\\boldsymbol{\\beta}\\) is a \\(K\\)-dimensional vector, where \\(K = (L-1) \\times (1 + \\text{dim}(\\boldsymbol{c}_i)) + a\\). Observe that \\(\\boldsymbol{\\beta}\\) contains the same last \\(a\\) elements as \\(\\boldsymbol{\\delta}\\), that is, the alternative-specific attribute coefficients. However, the first \\((L-1) \\times (1 + \\text{dim}(\\boldsymbol{c}_i))\\) elements of \\(\\boldsymbol{\\beta}\\) are the differences \\(\\delta_{jl} - \\delta_{jL}\\), for \\(j = 1, \\dots, \\text{dim}(\\boldsymbol{c}_i)\\) and \\(l = 1, 2, \\dots, L-1\\). That is, these elements represent the difference between the coefficients of each qualitative response and the \\(L\\)-th alternative for the individuals’ characteristics. This makes it difficult to interpret the multinomial probit coefficients. Note that in multinomial models, for each alternative-specific attribute, it is only necessary to estimate one coefficient for all alternatives. However, for individuals’ characteristics (non-alternative-specific regressors), it is required to estimate \\(L-1\\) coefficients, since the coefficient for the base alternative is set equal to 0. The likelihood function in this model is given by \\[ p(\\boldsymbol{\\beta}, \\boldsymbol{\\Omega} \\mid \\boldsymbol{y}, \\boldsymbol{R}) = \\prod_{i=1}^N \\prod_{l=1}^L p_{il}^{y_{il}}, \\] where \\(p_{il} = p(y_{il}^* \\geq \\max(\\boldsymbol{y}_i^*))\\). We assume independent priors for the parameters: \\[ \\boldsymbol{\\beta} \\sim N(\\boldsymbol{\\beta}_0, \\boldsymbol{B}_0) \\quad \\text{and} \\quad \\boldsymbol{\\Omega}^{-1} \\sim W(\\alpha_0, \\boldsymbol{\\Sigma}_0), \\] where \\(W\\) denotes the Wishart density. We can employ Gibbs sampling in this model, as it is a standard Bayesian linear regression model when data augmentation is used for \\(\\boldsymbol{w}\\). The posterior conditional distributions are given by \\[\\begin{equation*} \\boldsymbol{\\beta}\\mid \\boldsymbol{\\Omega},\\boldsymbol{w}\\sim{N}(\\boldsymbol{\\beta}_n,\\boldsymbol{B}_n), \\end{equation*}\\] \\[\\begin{equation*} \\boldsymbol{\\Omega}^{-1}\\mid \\boldsymbol{\\beta},\\boldsymbol{w}\\sim{W}(\\alpha_n,\\boldsymbol{\\Sigma}_n), \\end{equation*}\\] where \\(\\boldsymbol{B}_n=(\\boldsymbol{B}_0^{-1}+\\boldsymbol{X}^{*\\top}\\boldsymbol{X}^*)^{-1}\\), \\(\\boldsymbol{\\beta}_n=\\boldsymbol{B}_n(\\boldsymbol{B}_0^{-1}\\boldsymbol{\\beta}_0+\\boldsymbol{X}^{*\\top}\\boldsymbol{w}^*)\\), \\(\\boldsymbol{\\Omega}^{-1}=\\boldsymbol{C}^{\\top}\\boldsymbol{C}\\), \\(\\boldsymbol{X}_i^{*\\top}=\\boldsymbol{C}^{\\top}\\boldsymbol{R}_i\\), \\(\\boldsymbol{w}_i^*=\\boldsymbol{C}^{\\top}\\boldsymbol{w}_i\\), \\(\\boldsymbol{X}^*=\\begin{bmatrix}\\boldsymbol{X}_1^*\\\\ \\boldsymbol{X}_2^*\\\\ \\vdots\\\\ \\boldsymbol{X}_N^* \\end{bmatrix}\\), \\(\\alpha_n=\\alpha_0+N\\), \\(\\boldsymbol{\\Sigma}_n=(\\boldsymbol{\\Sigma}_0+\\sum_{i=1}^N (\\boldsymbol{w}_i-\\boldsymbol{R}_i\\boldsymbol{\\beta})^{\\top}(\\boldsymbol{w}_i-\\boldsymbol{R}_i\\boldsymbol{\\beta}))^{-1}\\). We can collapse the multinomial vector \\(\\boldsymbol{y}_i\\) into the indicator variable \\(d_i=\\sum_{l=1}^{L-1}l\\times \\mathbb{1}({\\max(\\boldsymbol{w}_{l})=w_{il}})\\).30 Then the distribution of \\(\\boldsymbol{w}_i\\mid \\boldsymbol{\\beta},\\boldsymbol{\\Omega}^{-1},d_i\\) is an \\(L-1\\) dimensional Gaussian distribution truncated over the appropriate cone in \\(\\mathcal{R}^{L-1}\\). R. McCulloch and Rossi (1994) propose drawing from the univariate conditional distributions \\(w_{il}\\mid \\boldsymbol{w}_{i,-l},\\boldsymbol{\\beta},\\boldsymbol{\\Omega}^{-1},d_i\\sim TN_{I_{il}}(m_{il},\\tau_{ll}^2)\\), where \\[\\begin{equation*} I_{il}=\\begin{Bmatrix} w_{il}&gt;\\max(\\boldsymbol{w}_{i,-l},0), &amp; d_i=l\\\\ w_{il}&lt;\\max(\\boldsymbol{w}_{i,-l},0), &amp; d_i\\neq l\\\\ \\end{Bmatrix}, \\end{equation*}\\] and permuting the columns and rows of \\(\\boldsymbol{\\Omega}^{-1}\\) so that the \\(l\\)-th column and row is the last, \\[\\begin{equation*} \\boldsymbol{\\Omega}^{-1}=\\begin{bmatrix} \\boldsymbol{\\Omega}_{-l,-l} &amp; \\boldsymbol\\omega_{-l,l}\\\\ \\boldsymbol\\omega_{l,-1} &amp; \\omega_{l,l}\\\\ \\end{bmatrix}^{-1} =\\begin{bmatrix} \\boldsymbol{\\Omega}_{-l,-l}^{-1}+{\\tau}^{-2}_{ll}\\boldsymbol{f}_l\\boldsymbol{f}_l^{\\top} &amp; -\\boldsymbol{f}_l\\tau^{-2}_{ll}\\\\ -{\\tau}^{-2}_{ll}\\boldsymbol{f}_l^{\\top} &amp; {\\tau}^{-2}_{ll}\\\\ \\end{bmatrix} \\end{equation*}\\] where \\(\\boldsymbol{f}_l=\\boldsymbol{\\Omega}_{-l,-l}^{-1}\\boldsymbol{\\omega}_{-l,l}\\), \\(\\tau_{ll}^2= \\omega_{ll}-\\boldsymbol{\\omega}_{l,-l}\\boldsymbol{\\Omega}^{-1}_{-l,-1}\\boldsymbol{\\omega}_{-l,l}\\), \\(m_{il}=\\boldsymbol{r}_{il}^{\\top}\\boldsymbol{\\beta}+\\boldsymbol{f}_l^{\\top}(\\boldsymbol{w}_{i,-l}-\\boldsymbol{R}_{i,-l}\\boldsymbol{\\beta})\\), \\(\\boldsymbol{w}_{i,-l}\\) is an \\(L-2\\) dimensional vector of all components of \\(\\boldsymbol{w}_i\\) excluding \\(w_{il}\\), \\(\\boldsymbol{r}_{il}\\) is the \\(l\\)-th row of \\(\\boldsymbol{R}_i\\), \\(l=1,2,\\dots,L-1\\). The identified parameters are obtained by normalizing with respect to one of the diagonal elements \\(\\frac{1}{\\omega_{1,1}^{0.5}}\\boldsymbol{\\beta}\\) and \\(\\frac{1}{\\omega_{1,1}}\\boldsymbol{\\Omega}\\).31 Warning: This model is an example where decisions must be made about setting the model in an identified parameter space versus an unidentified parameter space. The mixing properties of the posterior draws can be better in the latter case (R. E. McCulloch, Polson, and Rossi 2000), which typically results in less computational burden. However, it is important to recover the identified space in a final stage. Additionally, defining priors in the unidentified space may have unintended consequences on the posterior distributions in the identified space (Nobile 2000). The multinomial probit model presented in this section is set in the unidentified space (R. McCulloch and Rossi 1994), while a version of the multinomial probit in the identified space is presented by R. E. McCulloch, Polson, and Rossi (2000). Example: Choice of fishing mode We used in this application the dataset 3Fishing.csv from Cameron and Trivedi (2005). The dependent variable is mutually exclusive alternatives regarding fishing modes (mode), where beach is equal to 1, pier is equal to 2, private boat is equal to 3, and chartered boat (baseline alternative) is equal to 4. In this model, we have \\[ \\mathbf{X}_i = \\begin{bmatrix} 1 &amp; 0 &amp; 0 &amp; 0 &amp; \\text{Income}_i &amp; 0 &amp; 0 &amp; 0 &amp; \\text{Price}_{i,1} &amp; \\text{Catch rate}_{i,1}\\\\ 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; \\text{Income}_i &amp; 0 &amp; 0 &amp; \\text{Price}_{i,2} &amp; \\text{Catch rate}_{i,2}\\\\ 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; \\text{Income}_i &amp; 0 &amp; \\text{Price}_{i,3} &amp; \\text{Catch rate}_{i,3}\\\\ 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; \\text{Income}_i &amp; \\text{Price}_{i,4} &amp; \\text{Catch rate}_{i,4}\\\\ \\end{bmatrix} \\] In this example, chartered boat is the base category, the number of choice categories is four, there are two alternative-specific regressors (price and catch rate), and one non-alternative-specific regressor (income). This setting involves the estimation of eight location parameters (\\(\\boldsymbol{\\beta}\\)): three intercepts, three for income, one for price, and one for catch rate. This is the order of the posterior chains in our GUI. Note that the location coefficients are set equal to 0 for the baseline category. For multinomial models, we strongly recommend using the last category as the baseline. We also get posterior estimates for a \\(3\\times 3\\) covariance matrix (four alternatives minus one), where the element (1,1) is equal to 1 due to identification restrictions, and elements 2 and 4 are the same, as well as 3 and 7, and 6 and 8, due to symmetry. Observe that this identification restriction implies NaN values in J. Geweke (1992) and Heidelberger and Welch (1983) tests for element (1,1) of the covariance matrix, and just eight dependence factors associated with the remaining elements of the covariance matrix. Once our GUI is displayed (see beginning of this chapter), we should follow the next Algorithm to run multinomial probit models in our GUI (see Chapter 5 for details), which in turn uses the command rmnpGibbs from the bayesm package. Algorithm: Multinomial Probit model Select Univariate Models on the top panel Select Multinomial Probit model using the left radio button Upload the dataset by first selecting whether there is a header in the file, and the kind of separator in the csv file of the dataset (comma, semicolon, or tab). Then, use the Browse button under the Choose File legend. You should see a preview of the dataset Select MCMC iterations, burn-in, and thinning parameters using the Range sliders Select dependent and independent variables using the Formula builder table Select the number of the Base Alternative Select the Number of choice categorical alternatives Select the Number of alternative specific variables Select the Number of Non-alternative specific variables Click the Build formula button to generate the formula in R syntax Set the hyperparameters: mean vector, covariance matrix, scale matrix, and degrees of freedom. This step is not necessary as by default our GUI uses non-informative priors Click the Go! button Analyze results Download posterior chains and diagnostic plots using the Download Posterior Chains and Download Posterior Graphs buttons We ran 100,000 MCMC iterations plus 10,000 as burn-in with a thinning parameter equal to 5, where all priors use default values for the hyperparameters in our GUI. We found that the 95% credible intervals of the coefficient associated with income for beach and private boat alternatives are equal to (8.58e-06, 8.88e-05) and (3.36e-05, 1.45e-04). This suggests that the probability of choosing these alternatives increases compared to a chartered boat when income increases. In addition, an increase in the price or a decrease in the catch rate for specific fishing alternatives imply lower probabilities of choosing them as the 95% credible intervals are (-9.91e-03, -3.83e-03) and (1.40e-01, 4.62e-01), respectively. However, the posterior chain diagnostics suggest there are convergence issues with the posterior draws (see Exercise 5). References "],["sec65.html", "6.5 The multinomial logit model", " 6.5 The multinomial logit model The multinomial logit model is used to model mutually exclusive discrete outcomes or qualitative response variables. However, this model assumes the independence of irrelevant alternatives (IIA), meaning that the choice between two alternatives does not depend on a third alternative. We consider the multinomial mixed logit model (not to be confused with the random parameters logit model), which accounts for both alternative-varying regressors (conditional) and alternative-invariant regressors (multinomial) simultaneously.32 In this setting, there are \\(L\\) mutually exclusive alternatives, and the dependent variable \\(y_{il}\\) is equal to 1 if the \\(l\\)th alternative is chosen by individual \\(i\\), and 0 otherwise, where \\(l=\\left\\{1,2,\\dots,L\\right\\}\\). The likelihood function is \\[ p(\\boldsymbol{\\beta} \\mid \\boldsymbol{y}, \\boldsymbol{X}) = \\prod_{i=1}^{N} \\prod_{l=1}^{L} p_{il}^{y_{il}}, \\] where the probability that individual \\(i\\) chooses the alternative \\(l\\) is given by \\[ p_{il} := p(y_i = l \\mid \\boldsymbol{\\beta}, \\boldsymbol{X}) = \\frac{\\exp\\left\\{\\boldsymbol{x}_{il}^{\\top} \\boldsymbol{\\beta}_l\\right\\}}{\\sum_{j=1}^{L} \\exp\\left\\{\\boldsymbol{x}_{ij}^{\\top} \\boldsymbol{\\beta}_j\\right\\}}, \\] \\(\\boldsymbol{y}\\) and \\(\\boldsymbol{X}\\) are the vector and matrix of the dependent variable and regressors, respectively, and \\(\\boldsymbol{\\beta}\\) is the vector containing all the coefficients. Remember that coefficients associated with alternative-invariant regressors are set to 0 for the baseline category, and the coefficients associated with the alternative-varying regressors are the same for all the categories. In addition, we assume \\(\\boldsymbol{\\beta} \\sim N(\\boldsymbol{\\beta}_0, \\boldsymbol{B}_0)\\) as the prior distribution. Thus, the posterior distribution is \\[ \\pi(\\boldsymbol{\\beta} \\mid \\boldsymbol{y}, \\boldsymbol{X}) \\propto p(\\boldsymbol{\\beta} \\mid \\boldsymbol{y}, \\boldsymbol{X}) \\times \\pi(\\boldsymbol{\\beta}). \\] As the multinomial logit model does not have a standard posterior distribution, P. E. Rossi, Allenby, and McCulloch (2012) propose a “tailored” independent Metropolis-Hastings algorithm where the proposal distribution is a multivariate Student’s \\(t\\) distribution with \\(v\\) degrees of freedom (tuning parameter), mean equal to the maximum likelihood estimator, and scale equal to the inverse of the Hessian matrix. Example: Simulation exercise Let’s conduct a simulation exercise to evaluate the performance of the Metropolis-Hastings algorithm for inference in the multinomial logit model. We consider a scenario with three alternatives, one alternative-invariant regressor (plus the intercept), and three alternative-varying regressors. The population parameters are given by \\(\\boldsymbol{\\beta}_1 = [1 \\ -2.5 \\ 0.5 \\ 0.8 \\ -3]^{\\top}\\), \\(\\boldsymbol{\\beta}_2 = [1 \\ -3.5 \\ 0.5 \\ 0.8 \\ -3]^{\\top}\\), and \\(\\boldsymbol{\\beta}_3 = [0 \\ 0 \\ 0.5 \\ 0.8 \\ -3]^{\\top}\\), where the first two elements of each vector correspond to the intercept and the alternative-invariant regressor, while the last three elements correspond to the alternative-varying regressors. The sample size is 1000, and all regressors are simulated from standard normal distributions. We can deploy our GUI using the command line at the beginning of this chapter. We should follow the next Algorithm to run multinomial logit models in our GUI (see Chapter 5 for details). Algorithm: Multinomial logit models Select Univariate Models on the top panel Select Multinomial Logit model using the left radio button Upload the dataset by first selecting whether there is a header in the file, and the kind of separator in the csv file of the dataset (comma, semicolon, or tab). Then, use the Browse button under the Choose File legend. You should see a preview of the dataset Select MCMC iterations, burn-in, and thinning parameters using the Range sliders Select dependent and independent variables using the Formula builder table Select the Base Alternative Select the Number of choice categorical alternatives Select the Number of alternative specific variables Select the Number of Non-alternative specific variables Click the Build formula button to generate the formula in R syntax Set the hyperparameters: mean vector and covariance matrix. This step is not necessary as by default our GUI uses non-informative priors Select the tuning parameter for the Metropolis-Hastings algorithm, that is, the Degrees of freedom: Multivariate Student’s t distribution Click the Go! button Analyze results Download posterior chains and diagnostic plots using the Download Posterior Chains and Download Posterior Graphs buttons The following code in R demonstrates how to implement the M-H algorithm from scratch. The first part simulates the dataset, the second part constructs the log-likelihood function, and the third part implements the M-H algorithm. We use vague priors centered at zero, with a covariance matrix of \\(1000\\mathbf{I}_7\\). We observe that the posterior estimates closely match the population parameters, and all 95% credible intervals contain the population parameters. remove(list = ls()) set.seed(12345) # Simulation of data N&lt;-1000 # Sample Size B&lt;-c(0.5,0.8,-3); B1&lt;-c(-2.5,-3.5,0); B2&lt;-c(1,1,0) # Alternative specific attributes of choice 1, for instance, price, quality and duration of choice 1 X1&lt;-matrix(cbind(rnorm(N,0,1),rnorm(N,0,1),rnorm(N,0,1)),N,length(B)) # Alternative specific attributes of choice 2, for instance, price, quality and duration of choice 2 X2&lt;-matrix(cbind(rnorm(N,0,1),rnorm(N,0,1),rnorm(N,0,1)),N,length(B)) # Alternative specific attributes of choice 3, for instance, price, quality and duration of choice 3 X3&lt;-matrix(cbind(rnorm(N,0,1),rnorm(N,0,1),rnorm(N,0,1)),N,length(B)) X4&lt;-matrix(rnorm(N,1,1),N,1) V1&lt;-B2[1]+X1%*%B+B1[1]*X4; V2&lt;-B2[2]+X2%*%B+B1[2]*X4; V3&lt;-B2[3]+X3%*%B+B1[3]*X4 suma&lt;-exp(V1)+exp(V2)+exp(V3) p1&lt;-exp(V1)/suma; p2&lt;-exp(V2)/suma; p3&lt;-exp(V3)/suma p&lt;-cbind(p1,p2,p3) y&lt;- apply(p,1, function(x)sample(1:3, 1, prob = x, replace = TRUE)) y1&lt;-y==1; y2&lt;-y==2; y3&lt;-y==3 # Log likelihood log.L&lt;- function(Beta){ V1&lt;-Beta[1]+Beta[3]*X4+X1%*%Beta[5:7] V2&lt;-Beta[2]+Beta[4]*X4+X2%*%Beta[5:7] V3&lt;- X3%*%Beta[5:7] suma&lt;-exp(V1)+exp(V2)+exp(V3) p11&lt;-exp(V1)/suma; p22&lt;-exp(V2)/suma; p33&lt;-exp(V3)/suma suma2&lt;-NULL for(i in 1:N){ suma1&lt;-y1[i]*log(p11[i])+y2[i]*log(p22[i])+y3[i]*log(p33[i]) suma2&lt;-c(suma2,suma1)} logL&lt;-sum(suma2) return(-logL) } # Parameters: Proposal k &lt;- 7 res.optim&lt;-optim(rep(0, k), log.L, method=&quot;BFGS&quot;, hessian=TRUE) MeanT &lt;- res.optim$par ScaleT &lt;- as.matrix(Matrix::forceSymmetric(solve(res.optim$hessian))) # Force this matrix to be symmetric # Hyperparameters: Priors B0 &lt;- 1000*diag(k); b0 &lt;- rep(0, k) MHfunction &lt;- function(iter, tuning){ Beta &lt;- rep(0, k); Acept &lt;- NULL BetasPost &lt;- matrix(NA, iter, k) pb &lt;- winProgressBar(title = &quot;progress bar&quot;, min = 0, max = iter, width = 300) for(s in 1:iter){ LogPostBeta &lt;- -log.L(Beta) + mvtnorm::dmvnorm(Beta, mean = b0, sigma = B0, log = TRUE) BetaC &lt;- c(LaplacesDemon::rmvt(n=1, mu = MeanT, S = ScaleT, df = tuning)) LogPostBetaC &lt;- -log.L(BetaC) + mvtnorm::dmvnorm(BetaC, mean = b0, sigma = B0, log = TRUE) alpha &lt;- min(exp((LogPostBetaC-mvtnorm::dmvt(BetaC, delta = MeanT, sigma = ScaleT, df = tuning, log = TRUE))-(LogPostBeta-mvtnorm::dmvt(Beta, delta = MeanT, sigma = ScaleT, df = tuning, log = TRUE))) ,1) u &lt;- runif(1) if(u &lt;= alpha){ Acepti &lt;- 1; Beta &lt;- BetaC }else{ Acepti &lt;- 0; Beta &lt;- Beta } BetasPost[s, ] &lt;- Beta; Acept &lt;- c(Acept, Acepti) setWinProgressBar(pb, s, title=paste( round(s/iter*100, 0),&quot;% done&quot;)) } close(pb); AcepRate &lt;- mean(Acept) Results &lt;- list(AcepRate = AcepRate, BetasPost = BetasPost) return(Results) } # MCMC parameters mcmc &lt;- 10000; burnin &lt;- 1000; thin &lt;- 5; iter &lt;- mcmc + burnin; keep &lt;- seq(burnin, iter, thin); tuning &lt;- 6 # Degrees of freedom ResultsPost &lt;- MHfunction(iter = iter, tuning = tuning) summary(coda::mcmc(ResultsPost$BetasPost[keep[-1], ])) ## ## Iterations = 1:2000 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 2000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## [1,] 0.9711 0.20162 0.004508 0.004508 ## [2,] 0.9742 0.20934 0.004681 0.004681 ## [3,] -2.4350 0.18950 0.004237 0.004137 ## [4,] -3.4195 0.24656 0.005513 0.005513 ## [5,] 0.5253 0.07396 0.001654 0.001654 ## [6,] 0.8061 0.08007 0.001790 0.001790 ## [7,] -3.0853 0.17689 0.003955 0.003955 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## var1 0.5862 0.8367 0.9650 1.1017 1.3683 ## var2 0.5679 0.8310 0.9681 1.1151 1.3761 ## var3 -2.8239 -2.5607 -2.4291 -2.3050 -2.0812 ## var4 -3.9176 -3.5806 -3.4074 -3.2496 -2.9423 ## var5 0.3840 0.4761 0.5250 0.5759 0.6647 ## var6 0.6555 0.7494 0.8064 0.8616 0.9604 ## var7 -3.4476 -3.1991 -3.0777 -2.9641 -2.7500 References "],["sec66.html", "6.6 Ordered probit model", " 6.6 Ordered probit model The ordered probit model is used when there is a natural order in the categorical response variable. In this case, there is a latent variable \\(y_i^* = \\mathbf{x}_i^{\\top}\\boldsymbol{\\beta} + \\mu_i\\), where \\(\\mathbf{x}_i\\) is a \\(K\\)-dimensional vector of regressors, \\(\\mu_i \\stackrel{i.i.d.}{\\sim} N(0,1)\\), such that \\(y_i = l\\) if and only if \\(\\alpha_{l-1} &lt; y_i^* \\leq \\alpha_l\\), for \\(l \\in \\{1, 2, \\dots, L\\}\\), where \\(\\alpha_0 = -\\infty\\), \\(\\alpha_1 = 0\\), and \\(\\alpha_L = \\infty\\).33 Then, the probability of observing \\(y_i = l\\) is given by: \\[ p(y_i = l) = \\Phi(\\alpha_l - \\mathbf{x}_i^{\\top}\\boldsymbol{\\beta}) - \\Phi(\\alpha_{l-1} - \\mathbf{x}_i^{\\top}\\boldsymbol{\\beta}), \\] and the likelihood function is: \\[ p(\\boldsymbol{\\beta}, \\boldsymbol{\\alpha} \\mid \\mathbf{y}, \\mathbf{X}) = \\prod_{i=1}^{N} p(y_i = l \\mid \\boldsymbol{\\beta}, \\boldsymbol{\\alpha}, \\mathbf{X}). \\] The priors in this model are independent, i.e., \\(\\pi(\\boldsymbol{\\beta}, \\boldsymbol{\\gamma}) = \\pi(\\boldsymbol{\\beta}) \\times \\pi(\\boldsymbol{\\gamma})\\), where \\(\\boldsymbol{\\beta} \\sim N(\\boldsymbol{\\beta}_0, \\boldsymbol{B}_0)\\) and \\(\\boldsymbol{\\gamma} \\sim N(\\boldsymbol{\\gamma}_0, \\boldsymbol{\\Gamma}_0)\\), and \\(\\boldsymbol{\\gamma} = \\left[ \\gamma_2 \\ \\gamma_3 \\ \\dots \\ \\gamma_{L-1} \\right]^{\\top}\\), such that: \\[ \\boldsymbol{\\alpha} = \\left[ \\exp\\left\\{\\gamma_2\\right\\} \\ \\sum_{l=2}^{3} \\exp\\left\\{\\gamma_l\\right\\} \\ \\dots \\ \\sum_{l=2}^{L-1} \\exp\\left\\{\\gamma_l\\right\\} \\right]^{\\top}. \\] This structure imposes the ordinal condition on the cut-offs. This model does not have a standard conditional posterior distribution for \\(\\boldsymbol{\\gamma}\\) (\\(\\boldsymbol{\\alpha}\\)), but it does have a standard conditional distribution for \\(\\boldsymbol{\\beta}\\) once data augmentation is used. We can then use a Metropolis-within-Gibbs sampling algorithm. In particular, we use Gibbs sampling to draw \\(\\boldsymbol{\\beta}\\) and \\(\\boldsymbol{y}^*\\), where: \\[ \\boldsymbol{\\beta} \\mid \\boldsymbol{y}^*, \\boldsymbol{\\alpha}, \\boldsymbol{X} \\sim N(\\boldsymbol{\\beta}_n, \\boldsymbol{B}_n), \\] with \\(\\boldsymbol{B}_n = (\\boldsymbol{B}_0^{-1} + \\boldsymbol{X}^{\\top}\\boldsymbol{X})^{-1}\\), \\(\\boldsymbol{\\beta}_n = \\boldsymbol{B}_n(\\boldsymbol{B}_0^{-1}\\boldsymbol{\\beta}_0 + \\boldsymbol{X}^{\\top}\\boldsymbol{y}^*)\\), and: \\[ y_i^* \\mid \\boldsymbol{\\beta}, \\boldsymbol{\\alpha}, \\boldsymbol{y}, \\boldsymbol{X} \\sim TN_{(\\alpha_{y_i-1}, \\alpha_{y_i})}(\\boldsymbol{x}_i^{\\top}\\boldsymbol{\\beta}, 1). \\] We use a random-walk Metropolis–Hastings algorithm for \\(\\boldsymbol{\\gamma}\\) with a proposal distribution that is Gaussian with mean equal to the current value and covariance matrix \\(s^2(\\boldsymbol{\\Gamma}_0^{-1} + \\hat{\\boldsymbol{\\Sigma}}_{\\gamma}^{-1})^{-1}\\), where \\(s &gt; 0\\) is a tuning parameter and \\(\\hat{\\boldsymbol{\\Sigma}}_{\\gamma}\\) is the sample covariance matrix associated with \\(\\gamma\\) from the maximum likelihood estimation. Example: Determinants of preventive health care visits We used the file named 2HealthMed.csv in this application. In particular, the dependent variable is MedVisPrevOr, which is an ordered variable equal to 1 if the individual did not visit a physician for preventive reasons, 2 if the individual visited once in that year, and so on, until it is equal to 6 for visiting five or more times. The latter category represents 1.6% of the sample. Observe that the dependent variable has six categories. In this example, the set of regressors is given by SHI, which is an indicator of being in the subsidized health care system (1 means being in the system), sex (Female), age (both linear and squared), socioeconomic conditions indicator (Est2 and Est3), with the lowest being the baseline category, self-perception of health status (Fair, Good, and Excellent), where Bad is the baseline, and education level (PriEd, HighEd, VocEd, UnivEd), with no education as the baseline category. We ran this application with 50,000 MCMC iterations plus 10,000 as burn-in, and a thinning parameter equal to 5. This setting means 10,000 effective posterior draws. We set \\(\\boldsymbol{\\beta}_0 = \\boldsymbol{0}_{11}\\), \\(\\boldsymbol{B}_0 = 1000\\boldsymbol{I}_{11}\\), \\(\\boldsymbol{\\gamma}_0 = \\boldsymbol{0}_4\\), \\(\\boldsymbol{\\Gamma}_0 = \\boldsymbol{I}_4\\), and the tuning parameter is 1. We can run the ordered probit models in our GUI following the steps in the next Algorithm. Algorithm: Ordered probit models Select Univariate Models on the top panel Select Ordered Probit model using the left radio button Upload the dataset by first selecting whether there is a header in the file, and the kind of separator in the csv file of the dataset (comma, semicolon, or tab). Then, use the Browse button under the Choose File legend. You should see a preview of the dataset Select MCMC iterations, burn-in, and thinning parameters using the Range sliders Select dependent and independent variables using the Formula builder table Click the Build formula button to generate the formula in R syntax. Remember that this formula must have -1 to omit the intercept in the specification Set the hyperparameters: mean vectors and covariance matrices. This step is not necessary as by default our GUI uses non-informative priors Select the number of ordered alternatives Set the hyperparameters: mean and covariance matrix of the cutoffs. This step is not necessary as by default our GUI uses non-informative prior Select the tuning parameter for the Metropolis-Hastings algorithm Click the Go! button Analyze results Download posterior chains and diagnostic plots using the Download Posterior Chains and Download Posterior Graphs buttons The following R code shows how to perform inference in this model using the command rordprobitGibbs from the bayesm library, which is the command that our GUI uses. rm(list = ls()) set.seed(010101) Data &lt;- read.csv(&quot;https://raw.githubusercontent.com/besmarter/BSTApp/refs/heads/master/DataApp/2HealthMed.csv&quot;, sep = &quot;,&quot;, header = TRUE, quote = &quot;&quot;) attach(Data) ## The following objects are masked from mydata: ## ## Age, Age2, Bad, Est1, Est2, Est3, Excellent, Fair, Female, ## FemaleAge, Good, HighEd, Hosp, id, MedVisPrev, MedVisPrevOr, NoEd, ## PriEd, PTL, SHI, UnivEd, VocEd ## The following objects are masked from Data (pos = 4): ## ## Age, Age2 ## The following object is masked from DataUtEst: ## ## id y &lt;- MedVisPrevOr # MedVisPrevOr: Oredered variable for preventive visits to doctors in one year: 1 (none), 2 (once), ... 6 (five or more) X &lt;- cbind(SHI, Female, Age, Age2, Est2, Est3, Fair, Good, Excellent, PriEd, HighEd, VocEd, UnivEd) k &lt;- dim(X)[2] L &lt;- length(table(y)) # Hyperparameters b0 &lt;- rep(0, k); c0 &lt;- 1000; B0 &lt;- c0*diag(k) gamma0 &lt;- rep(0, L-2); Gamma0 &lt;- diag(L-2) # MCMC parameters mcmc &lt;- 60000+1; thin &lt;- 5; tuningPar &lt;- 1/(L-2)^0.5 DataApp &lt;- list(y = y, X = X, k = L) Prior &lt;- list(betabar = b0, A = solve(B0), dstarbar = gamma0, Ad = Gamma0) mcmcpar &lt;- list(R = mcmc, keep = 5, s = tuningPar, nprint = 0) PostBeta &lt;- bayesm::rordprobitGibbs(Data = DataApp, Prior = Prior, Mcmc = mcmcpar) ## ## Starting Gibbs Sampler for Ordered Probit Model ## with 12975 observations ## ## Table of y values ## y ## 1 2 3 4 5 6 ## 1935 2837 1241 2043 4711 208 ## ## Prior Parms: ## betabar ## [1] 0 0 0 0 0 0 0 0 0 0 0 0 0 ## ## A ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] ## [1,] 0.001 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 ## [2,] 0.000 0.001 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 ## [3,] 0.000 0.000 0.001 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 ## [4,] 0.000 0.000 0.000 0.001 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 ## [5,] 0.000 0.000 0.000 0.000 0.001 0.000 0.000 0.000 0.000 0.000 0.000 0.000 ## [6,] 0.000 0.000 0.000 0.000 0.000 0.001 0.000 0.000 0.000 0.000 0.000 0.000 ## [7,] 0.000 0.000 0.000 0.000 0.000 0.000 0.001 0.000 0.000 0.000 0.000 0.000 ## [8,] 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.001 0.000 0.000 0.000 0.000 ## [9,] 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.001 0.000 0.000 0.000 ## [10,] 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.001 0.000 0.000 ## [11,] 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.001 0.000 ## [12,] 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.001 ## [13,] 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 ## [,13] ## [1,] 0.000 ## [2,] 0.000 ## [3,] 0.000 ## [4,] 0.000 ## [5,] 0.000 ## [6,] 0.000 ## [7,] 0.000 ## [8,] 0.000 ## [9,] 0.000 ## [10,] 0.000 ## [11,] 0.000 ## [12,] 0.000 ## [13,] 0.001 ## ## dstarbar ## [1] 0 0 0 0 ## ## Ad ## [,1] [,2] [,3] [,4] ## [1,] 1 0 0 0 ## [2,] 0 1 0 0 ## [3,] 0 0 1 0 ## [4,] 0 0 0 1 ## ## MCMC parms: ## R= 60001 keep= 5 nprint= 0 s= 0.5 ## BetasPost &lt;- coda::mcmc(PostBeta[[&quot;betadraw&quot;]]) colnames(BetasPost) &lt;- c(&quot;SHI&quot;, &quot;Female&quot;, &quot;Age&quot;, &quot;Age2&quot;, &quot;Est2&quot;, &quot;Est3&quot;, &quot;Fair&quot;, &quot;Good&quot;, &quot;Excellent&quot;, &quot;PriEd&quot;, &quot;HighEd&quot;, &quot;VocEd&quot;, &quot;UnivEd&quot;) summary(BetasPost) ## ## Iterations = 1:12000 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 12000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## SHI 0.0654824 2.281e-02 2.082e-04 3.357e-04 ## Female -0.0374788 1.908e-02 1.742e-04 1.742e-04 ## Age 0.0190336 1.869e-03 1.706e-05 4.576e-05 ## Age2 -0.0002328 2.438e-05 2.225e-07 6.690e-07 ## Est2 0.0949445 2.226e-02 2.032e-04 4.659e-04 ## Est3 -0.1383965 3.411e-02 3.114e-04 3.459e-04 ## Fair 0.6451828 5.375e-02 4.907e-04 3.924e-03 ## Good 0.7343932 4.955e-02 4.523e-04 4.491e-03 ## Excellent 0.9826531 6.393e-02 5.836e-04 5.261e-03 ## PriEd 0.0309418 2.376e-02 2.169e-04 2.221e-04 ## HighEd -0.1805753 2.910e-02 2.656e-04 3.456e-04 ## VocEd 0.1395760 9.640e-02 8.800e-04 9.291e-04 ## UnivEd -0.2218120 1.189e-01 1.086e-03 1.086e-03 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## SHI 0.0209045 0.0499525 0.0654041 0.0808572 0.1102130 ## Female -0.0746364 -0.0504288 -0.0377778 -0.0245643 0.0002350 ## Age 0.0155088 0.0178114 0.0190228 0.0202305 0.0226864 ## Age2 -0.0002804 -0.0002479 -0.0002328 -0.0002168 -0.0001864 ## Est2 0.0514963 0.0800442 0.0948246 0.1096800 0.1393326 ## Est3 -0.2055927 -0.1614479 -0.1381575 -0.1156348 -0.0717986 ## Fair 0.5579955 0.6129584 0.6414878 0.6726800 0.7439563 ## Good 0.6669005 0.7080863 0.7303217 0.7540621 0.8106430 ## Excellent 0.8891998 0.9477048 0.9783661 1.0102615 1.0846084 ## PriEd -0.0158405 0.0149388 0.0310167 0.0471892 0.0773202 ## HighEd -0.2378212 -0.2003574 -0.1802174 -0.1607329 -0.1243538 ## VocEd -0.0491123 0.0747424 0.1381100 0.2041479 0.3333107 ## UnivEd -0.4538119 -0.3023902 -0.2219313 -0.1414801 0.0086323 # Convergence diagnostics coda::geweke.diag(BetasPost) ## ## Fraction in 1st window = 0.1 ## Fraction in 2nd window = 0.5 ## ## SHI Female Age Age2 Est2 Est3 Fair Good ## 1.9824 0.1488 1.6564 -1.5988 0.9782 -1.9159 1.2891 1.2890 ## Excellent PriEd HighEd VocEd UnivEd ## 1.3675 2.2458 -1.3570 1.0199 -0.6709 coda::raftery.diag(BetasPost,q=0.5,r=0.05,s = 0.95) ## ## Quantile (q) = 0.5 ## Accuracy (r) = +/- 0.05 ## Probability (s) = 0.95 ## ## Burn-in Total Lower bound Dependence ## (M) (N) (Nmin) factor (I) ## SHI 2 393 385 1.020 ## Female 2 382 385 0.992 ## Age 2 401 385 1.040 ## Age2 2 399 385 1.040 ## Est2 2 409 385 1.060 ## Est3 1 385 385 1.000 ## Fair 6 1227 385 3.190 ## Good 12 1792 385 4.650 ## Excellent 6 1233 385 3.200 ## PriEd 2 392 385 1.020 ## HighEd 2 392 385 1.020 ## VocEd 2 390 385 1.010 ## UnivEd 2 393 385 1.020 coda::heidel.diag(BetasPost) ## ## Stationarity start p-value ## test iteration ## SHI passed 1201 0.8026 ## Female passed 1 0.5041 ## Age passed 1201 0.0812 ## Age2 passed 1201 0.0928 ## Est2 passed 1201 0.1970 ## Est3 passed 1201 0.4047 ## Fair failed NA 0.0360 ## Good failed NA 0.0156 ## Excellent failed NA 0.0403 ## PriEd passed 1 0.1479 ## HighEd passed 1201 0.0870 ## VocEd passed 1 0.5223 ## UnivEd passed 1 0.6614 ## ## Halfwidth Mean Halfwidth ## test ## SHI passed 0.065098 4.19e-04 ## Female passed -0.037479 3.41e-04 ## Age passed 0.018970 3.38e-05 ## Age2 passed -0.000232 4.40e-07 ## Est2 passed 0.094472 4.10e-04 ## Est3 passed -0.138067 6.42e-04 ## Fair &lt;NA&gt; NA NA ## Good &lt;NA&gt; NA NA ## Excellent &lt;NA&gt; NA NA ## PriEd passed 0.030942 4.35e-04 ## HighEd passed -0.180255 5.47e-04 ## VocEd passed 0.139576 1.82e-03 ## UnivEd passed -0.221812 2.13e-03 # Cut offs Cutoffs &lt;- PostBeta[[&quot;cutdraw&quot;]] summary(Cutoffs) ## Summary of Posterior Marginal Distributions ## Moments ## mean std dev num se rel eff sam size ## 1 0.00 0.000 -1.0e+04 -9999 -9999 ## 2 0.71 0.013 1.3e-03 108 99 ## 3 0.96 0.014 1.3e-03 96 112 ## 4 1.37 0.015 1.3e-03 85 127 ## 5 3.20 0.030 1.8e-03 38 277 ## ## Quantiles ## 2.5% 5% 50% 95% 97.5% ## 1 0.00 0.00 0.00 0.00 0.00 ## 2 0.68 0.69 0.71 0.73 0.73 ## 3 0.93 0.94 0.96 0.98 0.98 ## 4 1.33 1.34 1.37 1.39 1.39 ## 5 3.14 3.15 3.20 3.25 3.26 ## based on 10800 valid draws (burn-in=1200) coda::geweke.diag(Cutoffs) ## ## Fraction in 1st window = 0.1 ## Fraction in 2nd window = 0.5 ## ## var1 var2 var3 var4 var5 ## NaN 0.5305 1.2222 1.2512 1.6850 coda::heidel.diag(Cutoffs) ## ## Stationarity start p-value ## test iteration ## [,1] failed NA NA ## [,2] passed 1201 0.2060 ## [,3] passed 1201 0.1192 ## [,4] passed 1201 0.1004 ## [,5] passed 1201 0.0681 ## ## Halfwidth Mean Halfwidth ## test ## [,1] &lt;NA&gt; NA NA ## [,2] passed 0.71 0.00399 ## [,3] passed 0.96 0.00349 ## [,4] passed 1.37 0.00300 ## [,5] passed 3.20 0.00295 coda::raftery.diag(Cutoffs[,-1],q=0.5,r=0.05,s = 0.95) ## ## Quantile (q) = 0.5 ## Accuracy (r) = +/- 0.05 ## Probability (s) = 0.95 ## ## Burn-in Total Lower bound Dependence ## (M) (N) (Nmin) factor (I) ## 390 49320 385 128.0 ## 340 43214 385 112.0 ## 224 28504 385 74.0 ## 64 7432 385 19.3 The results suggest that older individuals (at a decreasing rate) in the subsidized health program, characterized by being in the second socioeconomic status, with an increasing self-perception of good health, and not having high school as their highest education degree, have a higher probability of visiting a physician for preventive health purposes. Convergence diagnostics look well, except for the self-health perception draws. We also obtained the posterior estimates of the cutoffs in the ordered probit model. These estimates are necessary to calculate the probability that an individual is in a specific category of physician visits. Due to identification restrictions, the first cutoff is set equal to 0. This is why we observe NaN values in J. Geweke (1992) and Heidelberger and Welch (1983) tests, and only four values in the A. E. Raftery and Lewis (1992) test, which correspond to the remaining free cutoffs. It seems that these cutoff estimates have some convergence issues when using the A. E. Raftery and Lewis (1992) test as a diagnostic tool. Furthermore, their dependence factors are also very high. References "],["negative-binomial-model.html", "6.7 Negative binomial model", " 6.7 Negative binomial model The dependent variable in the negative binomial model is a nonnegative integer or count. In contrast to the Poisson model, the negative binomial model accounts for over-dispersion. The Poisson model assumes equi-dispersion, meaning the mean and variance are equal. We assume that \\(y_i \\stackrel{i.i.d.} {\\sim} \\text{NB}(\\gamma, \\theta_i)\\), where the density function for individual \\(i\\) is \\[ \\frac{\\Gamma(y_i + \\gamma)}{\\Gamma(\\gamma) y_i!} (1 - \\theta_i)^{y_i} \\theta_i^{\\gamma}, \\] with the success probability \\(\\theta_i = \\frac{\\gamma}{\\lambda_i + \\gamma}\\), where \\(\\lambda_i = \\exp\\left\\{\\mathbf{x}_i^{\\top} \\boldsymbol{\\beta}\\right\\}\\) is the mean, and \\(\\gamma = \\exp\\left\\{\\alpha \\right\\}\\) is the target for the number of successful trials, or the dispersion parameter, and \\(\\mathbf{x}_i\\) is a \\(K\\)-dimensional vector of regressors. We assume independent priors for this model: \\(\\boldsymbol{\\beta} \\sim N(\\boldsymbol{\\beta}_0, \\mathbf{B}_0)\\) and \\(\\alpha \\sim G(\\alpha_0, \\delta_0)\\). This model does not have standard conditional posterior distributions. Therefore, P. E. Rossi, Allenby, and McCulloch (2012) propose using a random-walk Metropolis–Hastings algorithm where the proposal distribution for \\(\\boldsymbol{\\beta}\\) is Gaussian, centered at the current stage, with covariance matrix \\(s_{\\boldsymbol{\\beta}}^2 \\hat{\\mathbf{\\Sigma}}_{\\boldsymbol{\\beta}}\\), where \\(s_{\\boldsymbol{\\beta}}\\) is a tuning parameter and \\(\\hat{\\mathbf{\\Sigma}}_{\\boldsymbol{\\beta}}\\) is the maximum likelihood covariance estimator. Additionally, the proposal for \\(\\alpha\\) is normal, centered at the current value, with variance \\(s_{\\alpha}^2 \\hat{\\sigma}_{\\alpha}^2\\), where \\(s_{\\alpha}\\) is a tuning parameter and \\(\\hat{\\sigma}_{\\alpha}^2\\) is the maximum likelihood variance estimator. Example: Simulation exercise Let’s do a simulation exercise to check the performance of the M-H algorithms in the negative binomial model. There are two regressors, \\(x_{i1} \\sim U(0,1)\\) and \\(x_{i2} \\sim N(0,1)\\), and the intercept. The dispersion parameter is \\(\\gamma = \\exp\\left\\{1.2\\right\\}\\), and \\(\\boldsymbol{\\beta} = \\left[1 \\ 1 \\ 1\\right]^{\\top}\\). The sample size is 1,000. We run this simulation using 10,000 MCMC iterations, a burn-in equal to 1,000, and a thinning parameter equal to 5. We set vague priors for the location parameters, particularly, \\(\\boldsymbol{\\beta}_0 = \\boldsymbol{0}_{3}\\) and \\(\\boldsymbol{B}_0 = 1000\\boldsymbol{I}_{3}\\), and \\(\\alpha_0 = 0.5\\) and \\(\\delta_0 = 0.1\\), which are the default values in the rnegbinRw command from the bayesm package in R. In addition, the tuning parameters of the Metropolis–Hastings algorithms are \\(s_{\\boldsymbol{\\beta}} = 2.93/k^{1/2}\\) and \\(s_{\\alpha} = 2.93\\), which are also the default parameters in rnegbinRw, where \\(k\\) is the number of location parameters. We can run the negative binomial models in our GUI following the steps in the next Algorithm. Algorithm: Negative binomial models Select Univariate Models on the top panel Select Negative Binomial (Poisson) model using the left radio button Upload the dataset by first selecting whether there is a header in the file, and the kind of separator in the csv file of the dataset (comma, semicolon, or tab). Then, use the Browse button under the Choose File legend. You should see a preview of the dataset Select MCMC iterations, burn-in, and thinning parameters using the Range sliders Select dependent and independent variables using the Formula builder table Click the Build formula button to generate the formula in R syntax. You can modify the formula in the Main equation box using valid arguments of the formula command structure in R Set the hyperparameters: mean vector, covariance matrix, shape, and scale parameters. This step is not necessary as by default our GUI uses non-informative priors Select the tuning parameters for the Metropolis-Hastings algorithms Click the Go! button Analyze results Download posterior chains and diagnostic plots using the Download Posterior Chains and Download Posterior Graphs buttons The following R code shows how to perform inference in the negative binomial model programming the M-H algorithms from scratch. We ask to estimate this example using the rnegbinRw command in Exercise 8. We observe from the results that all 95% credible intervals encompass the population parameters, and the posterior means are very close to the population parameters. rm(list = ls()) set.seed(010101) N &lt;- 2000 # Sample size x1 &lt;- runif(N); x2 &lt;- rnorm(N) X &lt;- cbind(1, x1, x2); k &lt;- dim(X)[2]; B &lt;- rep(1, k) alpha &lt;- 1.2; gamma &lt;- exp(alpha); lambda &lt;- exp(X%*%B) y &lt;- rnbinom(N, mu = lambda, size = gamma) # log likelihood logLik &lt;- function(par){ alpha &lt;- par[1]; beta &lt;- par[2:(k+1)] gamma &lt;- exp(alpha) lambda &lt;- exp(X%*%beta) logLikNB &lt;- sum(sapply(1:N, function(i){dnbinom(y[i], size = gamma, mu = lambda[i], log = TRUE)})) return(-logLikNB) } # Parameters: Proposal par0 &lt;- rep(0.5, k+1) res.optim &lt;- suppressWarnings(optim(par0, logLik, method=&quot;BFGS&quot;, hessian=TRUE)) res.optim$par ## [1] 1.3173049 1.0267103 0.9981069 0.9669848 res.optim$convergence ## [1] 0 Covar &lt;- solve(res.optim$hessian) CovarBetas &lt;- Covar[2:(k+1),2:(k+1)] VarAlpha &lt;- Covar[1:1] # Hyperparameters: Priors B0 &lt;- 1000*diag(k); b0 &lt;- rep(0, k) alpha0 &lt;- 0.5; delta0 &lt;- 0.1 # Metropolis-Hastings function MHfunction &lt;- function(iter, sbeta, salpha){ Beta &lt;- rep(0, k); Acept1 &lt;- NULL; Acept2 &lt;- NULL BetasPost &lt;- matrix(NA, iter, k); alpha &lt;- 1 alphaPost &lt;- rep(NA, iter); par &lt;- c(alpha, Beta) pb &lt;- winProgressBar(title = &quot;progress bar&quot;, min = 0, max = iter, width = 300) for(s in 1:iter){ LogPostBeta &lt;- -logLik(par) + dgamma(alpha, shape = alpha0, scale = delta0, log = TRUE) + mvtnorm::dmvnorm(Beta, mean = b0, sigma = B0, log = TRUE) BetaC &lt;- c(MASS::mvrnorm(1, mu = Beta, Sigma = sbeta^2*CovarBetas)) parC &lt;- c(alpha, BetaC) LogPostBetaC &lt;- -logLik(parC) + dgamma(alpha, shape = alpha0, scale = delta0, log = TRUE) + mvtnorm::dmvnorm(BetaC, mean = b0, sigma = B0, log = TRUE) alpha1 &lt;- min(exp((LogPostBetaC - mvtnorm::dmvnorm(BetaC, mean = Beta, sigma = sbeta^2*CovarBetas, log = TRUE))-(LogPostBeta - mvtnorm::dmvnorm(Beta, mean = Beta, sigma = sbeta^2*CovarBetas, log = TRUE))),1) u1 &lt;- runif(1) if(u1 &lt;= alpha1){Acept1i &lt;- 1; Beta &lt;- BetaC}else{ Acept1i &lt;- 0; Beta &lt;- Beta } par &lt;- c(alpha, Beta) LogPostBeta &lt;- -logLik(par) + dgamma(alpha, shape = alpha0, scale = delta0, log = TRUE) + mvtnorm::dmvnorm(Beta, mean = b0, sigma = B0, log = TRUE) alphaC &lt;- rnorm(1, mean = alpha, sd = salpha*VarAlpha^0.5) parC &lt;- c(alphaC, Beta) LogPostBetaC &lt;- -logLik(parC) + dgamma(alphaC, shape = alpha0, scale = delta0, log = TRUE) + mvtnorm::dmvnorm(Beta, mean = b0, sigma = B0, log = TRUE) alpha2 &lt;- min(exp((LogPostBetaC - dnorm(alphaC, mean = alpha, sd = salpha*VarAlpha^0.5, log = TRUE))-(LogPostBeta - dnorm(alpha, mean = alpha, sd = salpha*VarAlpha^0.5, log = TRUE))),1) u2 &lt;- runif(1) if(u2 &lt;= alpha2){Acept2i &lt;- 1; alpha &lt;- alphaC}else{ Acept2i &lt;- 0; alpha &lt;- alpha } BetasPost[s, ] &lt;- Beta; alphaPost[s] &lt;- alpha Acept1 &lt;- c(Acept1, Acept1i); Acept2 &lt;- c(Acept2, Acept2i) setWinProgressBar(pb, s, title=paste( round(s/iter*100, 0),&quot;% done&quot;)) } close(pb) AcepRateBeta &lt;- mean(Acept1); AcepRateAlpha &lt;- mean(Acept2) Results &lt;- list(AcepRateBeta = AcepRateBeta, AcepRateAlpha = AcepRateAlpha, BetasPost = BetasPost, alphaPost = alphaPost) return(Results) } # MCMC parameters mcmc &lt;- 10000 burnin &lt;- 1000 thin &lt;- 5 iter &lt;- mcmc + burnin keep &lt;- seq(burnin, iter, thin) sbeta &lt;- 2.93/sqrt(k); salpha &lt;- 2.93 # Run M-H ResultsPost &lt;- MHfunction(iter = iter, sbeta = sbeta, salpha = salpha) ResultsPost$AcepRateBeta ## [1] 0.3892727 ResultsPost$AcepRateAlpha ## [1] 0.4021818 summary(coda::mcmc(ResultsPost$BetasPost[keep[-1], ])) ## ## Iterations = 1:2000 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 2000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## [1,] 1.0269 0.04612 0.0010314 0.0014371 ## [2,] 0.9973 0.07593 0.0016978 0.0023584 ## [3,] 0.9676 0.02343 0.0005239 0.0006485 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## var1 0.9429 0.9946 1.0276 1.0567 1.118 ## var2 0.8529 0.9454 0.9967 1.0525 1.138 ## var3 0.9221 0.9525 0.9677 0.9831 1.014 summary(coda::mcmc(ResultsPost$alphaPost[keep[-1]])) ## ## Iterations = 1:2000 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 2000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## 1.280156 0.058052 0.001298 0.001491 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## 1.169 1.242 1.279 1.317 1.396 References "],["sec68.html", "6.8 Tobit model", " 6.8 Tobit model The dependent variable is partially observed in Tobit models due to sampling schemes, whereas the regressors are completely observed. In particular, \\[\\begin{equation} y_i = \\begin{Bmatrix} L, &amp; \\quad y_i^* &lt; L, \\\\ y_i^*, &amp; \\quad L \\leq y_i^* &lt; U, \\\\ U, &amp; \\quad y_i^* \\geq U, \\end{Bmatrix} \\end{equation}\\] where \\(y_i^* \\stackrel{i.i.d.}{\\sim} N(\\mathbf{x}_i^{\\top} \\boldsymbol{\\beta}, \\sigma^2)\\), \\(\\mathbf{x}_i\\) is a \\(K\\)-dimensional vector of regressors.34 We use conjugate independent priors \\(\\boldsymbol{\\beta} \\sim N(\\boldsymbol{\\beta}_0, \\mathbf{B}_0)\\) and \\(\\sigma^2 \\sim IG(\\alpha_0/2, \\delta_0/2)\\), and data augmentation using \\(\\mathbf{y}^*_C\\) such that \\(y_{C_i}^* \\stackrel{i.n.d.}{\\thicksim} N(\\mathbf{x}_i^{\\top} \\boldsymbol{\\beta}, \\sigma^2)\\), \\(y_{C_i} = \\left\\{ y_{C_i^L}^* \\cup y_{C_i^U}^* \\right\\}\\) are lower and upper censored data. This allows implementing the Gibbs sampling algorithm (S. Chib 1992). Then, \\[\\begin{align} \\pi(\\boldsymbol{\\beta}, \\sigma^2, \\mathbf{y^*} \\mid \\mathbf{y}, \\mathbf{X}) &amp;\\propto \\prod_{i=1}^N \\left[ \\mathbb{1}({y_i = L}) \\mathbb{1}({y_{C_i^L}^* &lt; L}) + \\mathbb{1}({L \\leq y_i &lt; U}) + \\mathbb{1}({y_i = U}) \\mathbb{1}({y_{C_i^U}^* \\geq U}) \\right] \\\\ &amp;\\times N(y_i^* \\mid \\mathbf{x}_i^{\\top} \\boldsymbol{\\beta}, \\sigma^2) \\times N(\\boldsymbol{\\beta} \\mid \\boldsymbol{\\beta}_0, \\mathbf{B}_0) \\times IG(\\sigma^2 \\mid \\alpha_0/2, \\delta_0/2) \\end{align}\\] The posterior distributions are: \\[\\begin{equation} y_{C_i}^* \\mid \\boldsymbol{\\beta}, \\sigma^2, \\mathbf{y}, \\mathbf{X} \\sim \\begin{Bmatrix} TN_{(-\\infty,L)}(\\mathbf{x}_i^{\\top}\\boldsymbol{\\beta}, \\sigma^2) \\ , \\ y_i = L \\\\ TN_{[U, \\infty)}(\\mathbf{x}_i^{\\top}\\boldsymbol{\\beta}, \\sigma^2) \\ \\ , \\ y_i = U \\end{Bmatrix} \\end{equation}\\] \\[\\begin{equation} \\boldsymbol{\\beta} \\mid \\sigma^2, \\mathbf{y}, \\mathbf{X} \\sim N(\\boldsymbol{\\beta}_n, \\sigma^2 \\mathbf{B}_n) \\end{equation}\\] \\[\\begin{equation} \\sigma^2 \\mid \\boldsymbol{\\beta}, \\mathbf{y}, \\mathbf{X} \\sim IG(\\alpha_n/2, \\delta_n/2) \\end{equation}\\] where \\(\\mathbf{B}_n = (\\mathbf{B}_0^{-1} + \\sigma^{-2} \\mathbf{X}^{\\top} \\mathbf{X})^{-1}\\), \\(\\boldsymbol{\\beta}_n = \\mathbf{B}_n(\\mathbf{B}_0^{-1} \\boldsymbol{\\beta}_0 + \\sigma^{-2} \\mathbf{X}^{\\top} \\mathbf{y}^*)\\), \\(\\alpha_n = \\alpha_0 + N\\), and \\(\\delta_n = \\delta_0 + (\\mathbf{y}^* - \\mathbf{X} \\boldsymbol{\\beta})^{\\top}(\\mathbf{y}^* - \\mathbf{X} \\boldsymbol{\\beta})\\). Example: The market value of soccer players in Europe continues We continue with the example of the market value of soccer players from Section 6.1. We specify the same equation but assume that the sample is censored from below, such that we only have information for soccer players whose market value is higher than one million euros. The dependent variable is log(ValueCens), and the left censoring point is 13.82. The following Algorithm illustrates how to estimate Tobit models in our GUI. Our GUI utilizes the MCMCtobit command from the MCMCpack package. Algorithm: Tobit models Select Univariate Models on the top panel Select Tobit model using the left radio button Upload the dataset by first selecting whether there is a header in the file, and the kind of separator in the csv file of the dataset (comma, semicolon, or tab). Then, use the Browse button under the Choose File legend. You should see a preview of the dataset Select MCMC iterations, burn-in, and thinning parameters using the Range sliders Select dependent and independent variables using the Formula builder table Click the Build formula button to generate the formula in R syntax. You can modify the formula in the Main equation box using valid arguments of the formula command structure in R Set the left and right censoring points. To censor above only, specify -Inf in the left censoring box, and to censor below only, specify Inf in the right censoring box Set the hyperparameters: mean vector, covariance matrix, shape, and scale parameters. This step is not necessary as by default our GUI uses non-informative priors Click the Go! button Analyze results Download posterior chains and diagnostic plots using the Download Posterior Chains and Download Posterior Graphs buttons We run this application using the same hyperparameters that we set in the example of Section 6.1. All results seem similar to those in the example of linear models. In addition, the posterior chains seem to achieve good diagnostics. rm(list = ls()); set.seed(010101) Data &lt;- read.csv(&quot;https://raw.githubusercontent.com/besmarter/BSTApp/refs/heads/master/DataApp/1ValueFootballPlayers.csv&quot;, sep = &quot;,&quot;, header = TRUE, quote = &quot;&quot;) attach(Data) ## The following objects are masked from Data (pos = 3): ## ## Age, Age2 ## The following objects are masked from mydata: ## ## Age, Age2 ## The following objects are masked from Data (pos = 5): ## ## Age, Age2, Assists, Exp, Exp2, Goals, Goals2, NatTeam, Perf, Perf2, ## Player, Value, ValueCens y &lt;- log(ValueCens) X &lt;- cbind(1, Perf, Age, Age2, NatTeam, Goals, Exp, Exp2) k &lt;- dim(X)[2] N &lt;- dim(X)[1] # Hyperparameters d0 &lt;- 0.001; a0 &lt;- 0.001 b0 &lt;- rep(0, k); c0 &lt;- 1000; B0 &lt;- c0*diag(k) B0i &lt;- solve(B0) # MCMC parameters mcmc &lt;- 50000 burnin &lt;- 10000 tot &lt;- mcmc + burnin thin &lt;- 1 # Posterior distributions using packages: MCMCpack sets the model in terms of the precision matrix posterior &lt;- MCMCpack::MCMCtobit(y~X-1, b0=b0, B0 = B0i, c0 = a0, d0 = d0, burnin = burnin, mcmc = mcmc, thin = thin, below = 13.82, above = Inf) summary(coda::mcmc(posterior)) ## ## Iterations = 1:50000 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 50000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## X 1.049702 2.639780 1.181e-02 1.676e-02 ## XPerf 0.033979 0.004512 2.018e-05 2.288e-05 ## XAge 1.024758 0.213319 9.540e-04 1.337e-03 ## XAge2 -0.021861 0.004002 1.790e-05 2.546e-05 ## XNatTeam 0.847758 0.126113 5.640e-04 6.463e-04 ## XGoals 0.010091 0.001649 7.376e-06 7.688e-06 ## XExp 0.174196 0.070237 3.141e-04 3.808e-04 ## XExp2 -0.005652 0.002977 1.331e-05 1.555e-05 ## sigma2 0.982768 0.095944 4.291e-04 6.698e-04 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## X -4.192313 -0.713326 1.071600 2.841806 6.1771087 ## XPerf 0.025131 0.030948 0.033967 0.036976 0.0428691 ## XAge 0.609991 0.880679 1.023709 1.167147 1.4480407 ## XAge2 -0.029803 -0.024542 -0.021820 -0.019162 -0.0141026 ## XNatTeam 0.603262 0.762408 0.847351 0.932705 1.0950039 ## XGoals 0.006877 0.008975 0.010094 0.011193 0.0133502 ## XExp 0.037752 0.126722 0.173706 0.221290 0.3127266 ## XExp2 -0.011525 -0.007632 -0.005642 -0.003657 0.0001633 ## sigma2 0.811752 0.915417 0.976781 1.042729 1.1887701 # Gibbs sampling functions XtX &lt;- t(X)%*%X PostBeta &lt;- function(Yl, sig2){ Bn &lt;- solve(B0i + sig2^(-1)*XtX) bn &lt;- Bn%*%(B0i%*%b0 + sig2^(-1)*t(X)%*%Yl) Beta &lt;- MASS::mvrnorm(1, bn, Bn) return(Beta) } PostYl &lt;- function(Beta, L, U, i){ Ylmean &lt;- X[i,]%*%Beta if(y[i] == L){ Yli &lt;- truncnorm::rtruncnorm(1, a = -Inf, b = L, mean = Ylmean, sd = sig2^0.5) }else{ if(y[i] == U){ Yli &lt;- truncnorm::rtruncnorm(1, a = U, b = Inf, mean = Ylmean, sd = sig2^0.5) }else{ Yli &lt;- y[i] } } return(Yli) } PostSig2 &lt;- function(Beta, Yl){ an &lt;- a0 + length(y) dn &lt;- d0 + t(Yl - X%*%Beta)%*%(Yl - X%*%Beta) sig2 &lt;- invgamma::rinvgamma(1, shape = an/2, rate = dn/2) return(sig2) } PostBetas &lt;- matrix(0, mcmc+burnin, k); Beta &lt;- rep(0, k) PostSigma2 &lt;- rep(0, mcmc+burnin); sig2 &lt;- 1 L &lt;- log(1000000); U &lt;- Inf # create progress bar in case that you want to see iterations progress pb &lt;- winProgressBar(title = &quot;progress bar&quot;, min = 0, max = tot, width = 300) for(s in 1:tot){ Yl &lt;- sapply(1:N, function(i){PostYl(Beta = Beta, L = L, U = U, i)}) Beta &lt;- PostBeta(Yl = Yl, sig2) sig2 &lt;- PostSig2(Beta = Beta, Yl = Yl) PostBetas[s,] &lt;- Beta; PostSigma2[s] &lt;- sig2 setWinProgressBar(pb, s, title=paste( round(s/tot*100, 0), &quot;% done&quot;)) } close(pb) ## NULL keep &lt;- seq((burnin+1), tot, thin) PosteriorBetas &lt;- PostBetas[keep,] colnames(PosteriorBetas) &lt;- c(&quot;Intercept&quot;, &quot;Perf&quot;, &quot;Age&quot;, &quot;Age2&quot;, &quot;NatTeam&quot;, &quot;Goals&quot;, &quot;Exp&quot;, &quot;Exp2&quot;) summary(coda::mcmc(PosteriorBetas)) ## ## Iterations = 1:50000 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 50000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## Intercept 1.023783 2.640151 1.181e-02 1.649e-02 ## Perf 0.033982 0.004496 2.011e-05 2.198e-05 ## Age 1.026527 0.213505 9.548e-04 1.322e-03 ## Age2 -0.021902 0.004005 1.791e-05 2.520e-05 ## NatTeam 0.849435 0.125673 5.620e-04 6.394e-04 ## Goals 0.010093 0.001652 7.390e-06 7.745e-06 ## Exp 0.175137 0.070498 3.153e-04 3.877e-04 ## Exp2 -0.005685 0.002985 1.335e-05 1.578e-05 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## Intercept -4.218202 -0.737377 1.048790 2.818320 6.1265295 ## Perf 0.025253 0.030947 0.033956 0.036986 0.0428926 ## Age 0.612543 0.881473 1.024929 1.169122 1.4478207 ## Age2 -0.029837 -0.024583 -0.021874 -0.019170 -0.0141402 ## NatTeam 0.603543 0.764706 0.849179 0.933046 1.0994449 ## Goals 0.006808 0.008979 0.010097 0.011208 0.0133334 ## Exp 0.038449 0.127461 0.174294 0.223045 0.3138970 ## Exp2 -0.011563 -0.007695 -0.005659 -0.003663 0.0001001 summary(coda::mcmc(PostSigma2[keep])) ## ## Iterations = 1:50000 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 50000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## 0.9860750 0.0963754 0.0004310 0.0006757 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## 0.8156 0.9186 0.9792 1.0469 1.1937 References "],["sec69.html", "6.9 Quantile regression", " 6.9 Quantile regression In quantile regression, the location parameters vary according to the quantile of the dependent variable. Let \\(q_{\\tau}(\\boldsymbol{x}_i) = \\boldsymbol{x}_i^{\\top} \\boldsymbol{\\beta}_{\\tau}\\) denote the \\(\\tau\\)-th quantile regression function of \\(y_i\\) given \\(\\boldsymbol{x}_i\\), where \\(\\boldsymbol{x}_i\\) is a \\(K\\)-dimensional vector of regressors, and \\(0 &lt; \\tau &lt; 1\\). Specifically, we have the model \\(y_i = \\boldsymbol{x}_i^{\\top} \\boldsymbol{\\beta}_{\\tau} + \\mu_i\\), with the condition \\(\\int_{-\\infty}^{0} f_{\\tau}(\\mu_i) \\, d\\mu_i = \\tau\\), meaning that the \\(\\tau\\)-th quantile of \\(\\mu_i\\) is 0. In particular, Kozumi and Kobayashi (2011) propose the asymmetric Laplace distribution for \\(f_{\\tau}(\\mu_i)\\), given by \\[ f_{\\tau}(\\mu_i) = \\tau(1 - \\tau) \\exp\\left\\{- \\mu_i(\\tau - \\mathbb{1}({\\mu_i &lt; 0})) \\right\\}, \\] where \\(\\mu_i(\\tau - \\mathbb{1}({\\mu_i &lt; 0}))\\) is the check (loss) function. These authors also propose a location-scale mixture of normals representation, given by \\[ \\mu_i = \\theta e_i + \\psi \\sqrt{e_i} z_i, \\] where \\(\\theta = \\frac{1 - 2\\tau}{\\tau(1 - \\tau)}\\), \\(\\psi^2 = \\frac{2}{\\tau(1 - \\tau)}\\), \\(e_i \\sim E(1)\\), and \\(z_i \\sim N(0,1)\\), with \\(e_i \\perp z_i\\).35 As a result of this representation and the fact that the sample is i.i.d., the likelihood function is \\[ p(\\boldsymbol{y} \\mid \\boldsymbol{\\beta}_{\\tau}, \\boldsymbol{e}, \\boldsymbol{X}) \\propto \\left( \\prod_{i=1}^{N} e_i^{-1/2} \\right) \\exp\\left\\{- \\sum_{i=1}^{N} \\frac{(y_i - \\boldsymbol{x}_i^{\\top} \\boldsymbol{\\beta}_{\\tau} - \\theta e_i)^2}{2 \\psi^2 e_i} \\right\\}. \\] Assuming a normal prior for \\(\\boldsymbol{\\beta}_{\\tau}\\), i.e., \\(\\boldsymbol{\\beta}_{\\tau} \\sim N(\\boldsymbol{\\beta}_{\\tau 0}, \\boldsymbol{B}_{\\tau 0})\\), and using data augmentation for \\(\\boldsymbol{e}\\), we can implement a Gibbs sampling algorithm for this model. The posterior distributions are as follows: \\[\\begin{equation*} \\boldsymbol{\\beta}_{\\tau} \\mid \\boldsymbol{e}, \\boldsymbol{y}, \\boldsymbol{X} \\sim N(\\boldsymbol{\\beta}_{n\\tau}, \\boldsymbol{B}_{n\\tau}), \\end{equation*}\\] \\[\\begin{equation*} e_i \\mid \\boldsymbol{\\beta}_{\\tau}, \\boldsymbol{y}, \\boldsymbol{X} \\sim \\text{GIG}\\left( \\frac{1}{2}, \\alpha_{ni}, \\delta_{ni} \\right), \\end{equation*}\\] where \\[\\begin{align*} \\boldsymbol{B}_{n\\tau} &amp;= \\left( \\boldsymbol{B}_{\\tau 0}^{-1} + \\sum_{i=1}^{N} \\frac{\\boldsymbol{x}_i \\boldsymbol{x}_i^{\\top}}{\\psi^2 e_i} \\right)^{-1}, \\\\ \\boldsymbol{\\beta}_{n\\tau} &amp;= \\boldsymbol{B}_{n\\tau} \\left( \\boldsymbol{B}_{\\tau 0}^{-1} \\boldsymbol{\\beta}_{\\tau 0} + \\sum_{i=1}^{N} \\frac{\\boldsymbol{x}_i (y_i - \\theta e_i)}{\\psi^2 e_i} \\right), \\\\ \\alpha_{ni} &amp;= \\frac{(y_i - \\boldsymbol{x}_i^{\\top} \\boldsymbol{\\beta}_{\\tau})^2}{\\psi^2}, \\quad \\delta_{ni} = 2 + \\frac{\\theta^2}{\\psi^2}. \\end{align*}\\] Example: The market value of soccer players in Europe continues We continue the example of the market value of soccer players from Section 6.1. Now, we want to examine whether the marginal effect of having been on the national team varies with the quantile of the market value of top soccer players in Europe. Thus, we use the same regressors as in the previous example, but analyze the effects at the 0.5-th and 0.9-th quantiles of NatTeam. The following Algorithm shows how to estimate quantile regression models in our GUI. Our GUI uses the command MCMCquantreg from the package MCMCpack. The following code demonstrates how to perform this analysis using the package. The results show that at the median market value (0.5-th quantile), the 95% credible interval for the coefficient associated with national team is (0.34, 1.02), with a posterior mean of 0.69. At the 0.9-th quantile, these values are (0.44, 1.59) and 1.03, respectively. It appears that being on the national team increases the market value of more expensive players more significantly on average, although there is some overlap in the credible intervals. Algorithm: Quantile regression Select Univariate Models on the top panel Select Quantile model using the left radio button Upload the dataset by first selecting whether there is a header in the file, and the kind of separator in the csv file of the dataset (comma, semicolon, or tab). Then, use the Browse button under the Choose File legend. You should see a preview of the dataset Select MCMC iterations, burn-in, and thinning parameters using the Range sliders Select dependent and independent variables using the Formula builder table Click the Build formula button to generate the formula in R syntax. You can modify the formula in the Main equation box using valid arguments of the formula command structure in R Set the quantile to be analyzed, by default it is 0.5 Set the hyperparameters: mean vector and covariance matrix. This step is not necessary as by default our GUI uses non-informative priors Click the Go! button Analyze results Download posterior chains and diagnostic plots using the Download Posterior Chains and Download Posterior Graphs buttons rm(list = ls()); set.seed(010101) Data &lt;- read.csv(&quot;https://raw.githubusercontent.com/besmarter/BSTApp/refs/heads/master/DataApp/1ValueFootballPlayers.csv&quot;, sep = &quot;,&quot;, header = TRUE, quote = &quot;&quot;) attach(Data) ## The following objects are masked from Data (pos = 3): ## ## Age, Age2, Assists, Exp, Exp2, Goals, Goals2, NatTeam, Perf, Perf2, ## Player, Value, ValueCens ## The following objects are masked from Data (pos = 4): ## ## Age, Age2 ## The following objects are masked from mydata: ## ## Age, Age2 ## The following objects are masked from Data (pos = 6): ## ## Age, Age2, Assists, Exp, Exp2, Goals, Goals2, NatTeam, Perf, Perf2, ## Player, Value, ValueCens y &lt;- log(ValueCens) X &lt;- cbind(1, Perf, Age, Age2, NatTeam, Goals, Exp, Exp2) k &lt;- dim(X)[2]; N &lt;- dim(X)[1] # Hyperparameters b0 &lt;- rep(0, k); c0 &lt;- 1000; B0 &lt;- c0*diag(k); B0i &lt;- solve(B0) # MCMC parameters mcmc &lt;- 50000; burnin &lt;- 10000 tot &lt;- mcmc + burnin; thin &lt;- 1 # Quantile q &lt;- 0.5 posterior05 &lt;- MCMCpack::MCMCquantreg(y~X-1, tau = q, b0=b0, B0 = B0i, burnin = burnin, mcmc = mcmc, thin = thin, below = 13.82, above = Inf) summary(coda::mcmc(posterior05)) ## ## Iterations = 1:50000 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 50000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## X 7.380881 2.922415 1.307e-02 2.305e-02 ## XPerf 0.029380 0.005972 2.671e-05 5.269e-05 ## XAge 0.550080 0.242058 1.083e-03 1.911e-03 ## XAge2 -0.012009 0.004607 2.061e-05 3.665e-05 ## XNatTeam 0.681238 0.170806 7.639e-04 1.564e-03 ## XGoals 0.010642 0.002415 1.080e-05 1.958e-05 ## XExp 0.091802 0.085777 3.836e-04 6.821e-04 ## XExp2 -0.002962 0.003874 1.733e-05 2.930e-05 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## X 1.721153 5.421451 7.355579 9.3156087 13.189612 ## XPerf 0.017526 0.025434 0.029410 0.0333849 0.040987 ## XAge 0.070621 0.389228 0.552940 0.7121539 1.020032 ## XAge2 -0.020951 -0.015103 -0.012073 -0.0089386 -0.002859 ## XNatTeam 0.341558 0.568023 0.682516 0.7949333 1.017583 ## XGoals 0.005849 0.009081 0.010586 0.0122120 0.015472 ## XExp -0.068241 0.032809 0.088512 0.1472835 0.269448 ## XExp2 -0.010951 -0.005446 -0.002856 -0.0003978 0.004471 q &lt;- 0.9 posterior09 &lt;- MCMCpack::MCMCquantreg(y~X-1, tau = q, b0=b0, B0 = B0i, burnin = burnin, mcmc = mcmc, thin = thin, below = 13.82, above = Inf) summary(coda::mcmc(posterior09)) ## ## Iterations = 1:50000 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 50000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## X 8.871556 5.825738 2.605e-02 6.605e-02 ## XPerf 0.019617 0.010110 4.521e-05 1.127e-04 ## XAge 0.531550 0.473922 2.119e-03 5.320e-03 ## XAge2 -0.012324 0.008689 3.886e-05 9.523e-05 ## XNatTeam 1.039941 0.295468 1.321e-03 3.453e-03 ## XGoals 0.008703 0.004295 1.921e-05 4.799e-05 ## XExp 0.136201 0.176328 7.886e-04 2.064e-03 ## XExp2 -0.002835 0.007613 3.405e-05 8.450e-05 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## X -2.4546594 4.890189 8.838894 12.807759 20.296222 ## XPerf -0.0001067 0.012859 0.019580 0.026298 0.039655 ## XAge -0.3889773 0.210175 0.531298 0.850672 1.462811 ## XAge2 -0.0295151 -0.018080 -0.012278 -0.006447 0.004438 ## XNatTeam 0.4437112 0.845176 1.045862 1.241973 1.600731 ## XGoals 0.0018928 0.005572 0.008122 0.011280 0.018537 ## XExp -0.2241036 0.019995 0.142557 0.258915 0.461877 ## XExp2 -0.0163570 -0.008121 -0.003296 0.001949 0.013474 References "],["sec610.html", "6.10 Bayesian bootstrap regression", " 6.10 Bayesian bootstrap regression We implement the Bayesian bootstrap (Donnald B. Rubin 1981) for linear regression models. In particular, the Bayesian bootstrap simulates the posterior distributions by assuming that the sample cumulative distribution function (CDF) is the population CDF (this assumption is also implicit in the frequentist bootstrap (B. Efron 1979)). Given \\(y_i \\stackrel{i.i.d.}{\\sim} \\mathcal{F}\\), where \\(\\mathcal{F}\\) does not specify a particular parametric family of distributions, but instead sets \\(\\mathbb{E}(y_i \\mid \\boldsymbol{x}_i) = \\boldsymbol{x}_i^{\\top} \\boldsymbol{\\beta}\\), with \\(\\boldsymbol{x}_i\\) being a \\(K\\)-dimensional vector of regressors and \\(\\boldsymbol{\\beta}\\) a \\(K\\)-dimensional vector of parameters, the Bayesian bootstrap generates posterior probabilities for each \\(y_i\\), where the values of \\(\\boldsymbol{y}\\) that are not observed have zero posterior probability. The algorithm to implement the Bayesian bootstrap is the following: Algorithm: Bayesian bootstrap Draw g ∼ Dir(α1, α2, ..., αN) such that αi=1 for all i g=(g1, g2, ..., gN) is the vector of probabilities to attach to (y1,x1), (y2,x2), ..., (yN,xN) for each Bayesian bootstrap replication. Sample (yi,xi) N times with replacement and probabilities gi, i=1,2, ...,N. Estimate β using ordinary least squares in the model E(y|X)=Xβ, y being a S1 dimensional vector, and X a S1 X K matrix from the previous stage. Repeat this process S times. The distribution of β(s) is the Bayesian distribution of β. Example: Simulation exercise Let’s perform a simulation exercise to evaluate the performance of the previous Algorithm for inference using the Bayesian bootstrap. The data-generating process is defined by two regressors, each distributed as standard normal. The location vector is \\(\\boldsymbol{\\beta} = \\left[1 \\ 1 \\ 1\\right]^{\\top}\\), with a variance of \\(\\sigma^2 = 1\\), and the sample size is 1,000. The following Algorithm illustrates how to use our GUI to run the Bayesian bootstrap. Our GUI is based on the bayesboot command from the bayesboot package in R. Exercise 11 asks about using this package to perform inference in this simulation and compares the results with those obtained using our GUI with \\(S = 10000\\). Algorithm: Bayesian Bootstrap in Linear Regression Select Univariate Models on the top panel Select Bootstrap model using the left radio button Upload the dataset by first selecting whether there is a header in the file, and the kind of separator in the csv file of the dataset (comma, semicolon, or tab). Then, use the Browse button under the Choose File legend. You should see a preview of the dataset Select number of bootstrap replications using the Range sliders Select dependent and independent variables using the Formula builder table Click the Build formula button to generate the formula in R syntax. You can modify the formula in the Main equation box using valid arguments of the formula command structure in R Click the Go! button Analyze results Download posterior chains and diagnostic plots using the Download Posterior Chains and Download Posterior Graphs buttons The following R code shows how to program the Bayesian bootstrap from scratch. We observe from the results that all 95% credible intervals encompass the population parameters, and the posterior means are close to the population parameters. rm(list = ls()); set.seed(010101) N &lt;- 1000; x1 &lt;- runif(N); x2 &lt;- rnorm(N) X &lt;- cbind(x1, x2); k &lt;- dim(X)[2] B &lt;- rep(1, k+1); sig2 &lt;- 1 u &lt;- rnorm(N, 0, sig2); y &lt;- cbind(1, X)%*%B + u data &lt;- as.data.frame(cbind(y, X)) names(data) &lt;- c(&quot;y&quot;, &quot;x1&quot;, &quot;x2&quot;) Reg &lt;- function(d){ Reg &lt;- lm(y ~ x1 + x2, data = d) Bhat &lt;- Reg$coef return(Bhat) } S &lt;- 10000; alpha &lt;- 1 BB &lt;- function(S, df, alpha){ Betas &lt;- matrix(NA, S, dim(df)[2]) N &lt;- dim(df)[1] pb &lt;- winProgressBar(title = &quot;progress bar&quot;, min = 0, max = S, width = 300) for(s in 1:S){ g &lt;- LaplacesDemon::rdirichlet(N, alpha) ids &lt;- sample(1:N, size = N, replace = TRUE, prob = g) datas &lt;- df[ids,] names(datas) &lt;- names(df) Bs &lt;- Reg(d = datas) Betas[s, ] &lt;- Bs setWinProgressBar(pb, s, title=paste( round(s/S*100, 0), &quot;% done&quot;)) } close(pb) return(Betas) } BBs &lt;- BB(S = S, df = data, alpha = alpha) summary(coda::mcmc(BBs)) ## ## Iterations = 1:10000 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 10000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## [1,] 0.9182 0.06475 0.0006475 0.0006475 ## [2,] 1.1735 0.10948 0.0010948 0.0010948 ## [3,] 1.0133 0.03359 0.0003359 0.0003359 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## var1 0.7882 0.8755 0.9178 0.9612 1.045 ## var2 0.9560 1.1009 1.1738 1.2467 1.391 ## var3 0.9467 0.9902 1.0134 1.0362 1.079 References "],["sec611.html", "6.11 Summary", " 6.11 Summary In this chapter, we present the core univariate regression models and demonstrate how to perform Bayesian inference using Markov Chain Monte Carlo (MCMC) methods. Specifically, we cover a range of algorithms: Gibbs sampling, Metropolis-Hastings, nested Metropolis-Hastings, and Metropolis-Hastings-within-Gibbs. These algorithms form the foundation for performing Bayesian inference in more complex settings using cross-sectional datasets. "],["sec612.html", "6.12 Exercises", " 6.12 Exercises Get the posterior conditional distributions of the Gaussian linear model assuming independent priors \\(\\pi(\\boldsymbol{\\beta}, \\sigma^2) = \\pi(\\boldsymbol{\\beta}) \\times \\pi(\\sigma^2)\\), where \\(\\boldsymbol{\\beta} \\sim N(\\boldsymbol{\\beta}_0, \\boldsymbol{B}_0)\\) and \\(\\sigma^2 \\sim IG(\\alpha_0/2, \\delta_0/2)\\). Given the model \\(y_i \\sim N(\\boldsymbol{x}_i^{\\top} \\boldsymbol{\\beta}, \\sigma^2/\\tau_i)\\) (Gaussian linear model with heteroskedasticity) with independent priors, \\(\\pi(\\boldsymbol{\\beta}, \\sigma^2, \\boldsymbol{\\tau}) = \\pi(\\boldsymbol{\\beta}) \\times \\pi(\\sigma^2) \\times \\prod_{i=1}^N \\pi(\\tau_i)\\), where \\(\\boldsymbol{\\beta} \\sim N(\\boldsymbol{\\beta}_0, \\boldsymbol{B}_0)\\), \\(\\sigma^2 \\sim IG(\\alpha_0/2, \\delta_0/2)\\), and \\(\\tau_i \\sim G(v/2, v/2)\\). Show that \\[ \\boldsymbol{\\beta} \\mid \\sigma^2, \\boldsymbol{\\tau}, \\boldsymbol{y}, \\boldsymbol{X} \\sim N(\\boldsymbol{\\beta}_n, \\boldsymbol{B}_n), \\quad \\sigma^2 \\mid \\boldsymbol{\\beta}, \\boldsymbol{\\tau}, \\boldsymbol{y}, \\boldsymbol{X} \\sim IG(\\alpha_n/2, \\delta_n/2), \\] and \\[ \\tau_i \\mid \\boldsymbol{\\beta}, \\sigma^2, \\boldsymbol{y}, \\boldsymbol{X} \\sim G(v_{1n}/2, v_{2in}/2), \\] where \\(\\boldsymbol{\\tau} = [\\tau_1 \\dots \\tau_n]^{\\top}\\), \\(\\boldsymbol{B}_n = (\\boldsymbol{B}_0^{-1} + \\sigma^{-2} \\boldsymbol{X}^{\\top} \\Psi \\boldsymbol{X})^{-1}\\), \\[ \\boldsymbol{\\beta}_n = \\boldsymbol{B}_n (\\boldsymbol{B}_0^{-1} \\boldsymbol{\\beta}_0 + \\sigma^{-2} \\boldsymbol{X}^{\\top} \\Psi \\boldsymbol{y}), \\] \\(\\alpha_n = \\alpha_0 + N\\), \\(\\delta_n = \\delta_0 + (\\boldsymbol{y} - \\boldsymbol{X} \\boldsymbol{\\beta})^{\\top} \\Psi (\\boldsymbol{y} - \\boldsymbol{X} \\boldsymbol{\\beta})\\), \\(v_{1n} = v + 1\\), \\(v_{2in} = v + \\sigma^{-2}(y_i - \\boldsymbol{x}_i^{\\top} \\boldsymbol{\\beta})^2\\), and \\(\\Psi = \\text{diagonal}\\{\\tau_i\\}\\). The market value of soccer players in Europe continues Use the setting of the previous exercise to perform inference using a Gibbs sampling algorithm of the market value of soccer players in Europe, setting \\(v = 5\\) and the same other hyperparameters as the homoscedastic case. Is there any meaningful difference for the coefficient associated with the national team compared to the application in the homoscedastic case? Example: Determinants of hospitalization continues Program a Gibbs sampling algorithm in the application of determinants of hospitalization. Choice of the fishing mode continues Run the Algorithm of the Multinomial Probit of the book to show the results of the Geweke (J. Geweke 1992), Raftery (A. E. Raftery and Lewis 1992), and Heidelberger (Heidelberger and Welch 1983) tests using our GUI. Use the command rmnpGibbs to do the example of the choice of the fishing mode. Simulation exercise of the multinomial logit model continues Perform inference in the simulation of the multinomial logit model using the command rmnlIndepMetrop from the bayesm package of R and using our GUI. Simulation of the ordered probit model Simulate an ordered probit model where the first regressor distributes \\(N(6, 5)\\) and the second distributes \\(G(1, 1)\\), the location vector is \\(\\boldsymbol{\\beta} = \\left[ 0.5, -0.25, 0.5 \\right]^{\\top}\\), and the cutoffs are in the vector \\(\\boldsymbol{\\alpha} = \\left[ 0, 1, 2.5 \\right]^{\\top}\\). Program from scratch a Metropolis-within-Gibbs sampling algorithm to perform inference in this simulation. Simulation of the negative binomial model continues Perform inference in the simulation of the negative binomial model using the bayesm package in R software. The market value of soccer players in Europe continues Perform the application of the value of soccer players with left censoring at one million Euros in our GUI using the Algorithm of the Tobit models, and the hyperparameters of the example. The market value of soccer players in Europe continues Program from scratch the Gibbs sampling algorithm in the example of the market value of soccer players at the 0.75 quantile. Use the bayesboot package to perform inference in the simulation exercise of Section 6.10, and compare the results with the ones that we get using our GUI, setting \\(S = 10000\\). References "],["Chap7.html", "Chapter 7 Multivariate regression", " Chapter 7 Multivariate regression We describe how to perform Bayesian inference in multivariate response models, including multivariate regression, seemingly unrelated regression, instrumental variables, and the multivariate probit model. In particular, we present the posterior distributions of the parameters and demonstrate several applications and simulations. Additionally, we show how to perform inference in these models using three levels of programming skills: GUI, packages, and programming the algorithms from scratch. Finally, we provide some mathematical and computational exercises. Remember that we can run our GUI typing shiny::runGitHub(\"besmarter/BSTApp\", launch.browser=T) in the R console or any R code editor and execute it. However, users should see Chapter 5 for details. "],["sec71.html", "7.1 Multivariate regression", " 7.1 Multivariate regression A complete presentation of this model is given in Section 3.4. We show here the setting, and the posterior distributions for facility in exposition. In particular, there are \\(M\\) multiply dependent variables which share the same set of regressors, and their stochastic errors are contemporaneously correlated. In particular, \\(\\boldsymbol{Y} = \\left[ \\boldsymbol{y_{1}} \\ \\boldsymbol{y_{2}} \\ \\ldots \\ \\boldsymbol{y_{M}} \\right]\\) is an \\(N \\times M\\) matrix that is generated by \\(\\boldsymbol{Y} = \\boldsymbol{X} \\boldsymbol{B} + \\boldsymbol{U}\\) where \\(\\boldsymbol{X}\\) is an \\(N \\times K\\) matrix of regressors, \\(\\boldsymbol{B} = \\left[ \\boldsymbol{\\beta}_{1} \\ \\boldsymbol{\\beta}_{2} \\ldots \\boldsymbol{\\beta}_{M} \\right]\\) is a \\(K \\times M\\) matrix of parameters, and \\(\\boldsymbol{U} = \\left[ \\boldsymbol{\\mu}_{1} \\ \\boldsymbol{\\mu}_{2} \\ldots \\boldsymbol{\\mu}_{M} \\right]\\) is a matrix of stochastic random errors such that \\(\\boldsymbol{\\mu}_i \\sim N(\\boldsymbol{0}, \\boldsymbol{\\Sigma})\\), for \\(i = 1, 2, \\dots, N\\), each row of \\(\\boldsymbol{U}\\). The prior is given by \\(\\boldsymbol{B} \\mid \\boldsymbol{\\Sigma} \\sim N(\\boldsymbol{B}_0, \\boldsymbol{V}_0, \\boldsymbol{\\Sigma})\\) and \\(\\boldsymbol{\\Sigma} \\sim IW(\\boldsymbol{\\Psi}_0, \\alpha_0)\\). Therefore, the conditional posterior distributions are: \\[ \\boldsymbol{B} \\mid \\boldsymbol{\\Sigma}, \\boldsymbol{Y}, \\boldsymbol{X} \\sim N(\\boldsymbol{B}_n, \\boldsymbol{V}_n, \\boldsymbol{\\Sigma}), \\] \\[ \\boldsymbol{\\Sigma} \\mid \\boldsymbol{Y}, \\boldsymbol{X} \\sim IW(\\boldsymbol{\\Psi}_n, \\alpha_n), \\] where \\[ \\boldsymbol{V}_n = (\\boldsymbol{X}^{\\top} \\boldsymbol{X} + \\boldsymbol{V}_0^{-1})^{-1}, \\quad \\boldsymbol{B}_n = \\boldsymbol{V}_n (\\boldsymbol{V}_0^{-1} \\boldsymbol{B}_0 + \\boldsymbol{X}^{\\top} \\boldsymbol{X} \\hat{\\boldsymbol{B}}), \\] \\[ \\hat{\\boldsymbol{B}} = (\\boldsymbol{X}^{\\top} \\boldsymbol{X})^{-1} \\boldsymbol{X}^{\\top} \\boldsymbol{Y}, \\quad \\boldsymbol{\\Psi}_n = \\boldsymbol{\\Psi}_{0} + \\boldsymbol{S} + \\boldsymbol{B}_{0}^{\\top} \\boldsymbol{V}_{0}^{-1} \\boldsymbol{B}_{0} + \\hat{\\boldsymbol{B}}^{\\top} \\boldsymbol{X}^{\\top} \\boldsymbol{X} \\hat{\\boldsymbol{B}} - \\boldsymbol{B}_n^{\\top} \\boldsymbol{V}_n^{-1} \\boldsymbol{B}_n, \\] and \\[ \\alpha_n = \\alpha_0 + N. \\] We can use a Gibbs sampling algorithm in this model since the conditional posterior distributions are standard. Example: The effect of institutions on per capita gross domestic product To illustrate multivariate regression models, we use the dataset provided by Acemoglu, Johnson, and Robinson (2001), who analyzed the effect of property rights on economic growth. We begin with the following simultaneous structural economic model:36 \\[\\begin{align} \\log(\\text{pcGDP95}_i) &amp;= \\beta_1 + \\beta_2 \\text{PAER}_i + \\beta_3 \\text{Africa} + \\beta_4 \\text{Asia} + \\beta_5 \\text{Other} + u_{1i}, \\tag{7.1} \\end{align}\\] \\[\\begin{align} \\text{PAER}_i &amp;= \\alpha_1 + \\alpha_2 \\log(\\text{pcGDP95}_i) + \\alpha_3 \\log(\\text{Mort}_i) + u_{2i}, \\tag{7.2} \\end{align}\\] where pcGDP95, PAER, and Mort represent the per capita gross domestic product (GDP) in 1995, the average index of protection against expropriation between 1985 and 1995, and the settler mortality rate during the period of colonization, respectively. Africa, Asia, and Other are indicator variables for continents, with America serving as the baseline group. In this model, there is reverse (simultaneous) causality due to the contemporaneous effect of GDP on PAER, and vice versa.37 Therefore, estimating Equations (7.1) and (7.2) without accounting for this phenomenon results in posterior mean estimates that are biased and inconsistent from a sampling (frequentist) perspective.38 A potential strategy to address this issue is to estimate the reduced-form model, i.e., a model without simultaneous causality, where all endogenous variables are functions of exogenous variables. The former are determined within the model (e.g., \\(\\log(\\text{pcGDP95}_i)\\) and PAER in this example), while the latter are determined outside the model (e.g., \\(\\log(\\text{Mort}_i)\\), Africa, Asia, and Other in this example). Replacing Equation (7.2) into Equation (7.1), and solving for \\(\\log(\\textit{pcGDP95})\\), \\[\\begin{align} \\log(\\text{pcGDP95}_i)=\\pi_1+\\pi_2\\log(\\text{Mort}_i)+\\pi_3 \\text{Africa}+\\pi_4 \\text{Asia}+\\pi_5 \\text{Other}+e_{1i}. \\tag{7.3} \\end{align}\\] Then, by substituting Equation (7.3) into Equation (7.2), and solving for PAER, we obtain \\[\\begin{align} \\text{PAER}_i = \\gamma_1 + \\gamma_2 \\log(\\text{Mort}_i) + \\gamma_3 \\text{Africa} + \\gamma_4 \\text{Asia} + \\gamma_5 \\text{Other} + e_{2i}, \\tag{7.4} \\end{align}\\] where \\(\\pi_2 = \\frac{\\beta_2\\alpha_3}{1 - \\beta_2\\alpha_2}\\) and \\(\\gamma_2 = \\frac{\\alpha_3}{1 - \\beta_2\\alpha_2}\\), given that \\(\\beta_2 \\alpha_2 \\neq 1\\), i.e., independent equations (see Exercise 2). Observe that Equations (7.3) and (7.4) have the form of a multivariate regression model, where the common set of regressors is \\[ \\boldsymbol{X} = \\left[\\log(\\text{Mort}) \\ \\text{Africa} \\ \\text{Asia} \\ \\text{Other}\\right] \\] and the common set of dependent variables is \\[ \\boldsymbol{Y} = \\left[\\log(\\text{pcGDP95}) \\ \\text{PAER}\\right]. \\] Therefore, we can estimate this model using the setup outlined in this section. In the first stage, we estimate the parameters of the reduced-form model (Equations (7.3) and (7.4)), but the main interest lies in estimating the parameters of the structural model (Equations (7.1) and (7.2)). A valid question is whether we can recover (identify) the structural parameters from the reduced-form parameters. There are two criteria to answer this question: the order condition, which is necessary, and the rank condition, which is both necessary and sufficient. The order condition Given a system of equations with \\(M\\) endogenous variables, and \\(K\\) exogenous variables (including the intercept), there are two ways to assess the order condition: The parameters of an equation in the system are identified if there are at least \\(M-1\\) variables excluded from the equation (exclusion restrictions). The equation is exactly identified if the number of excluded variables is \\(M-1\\), and is over identified if the number of excluded variables is greater than \\(M-1\\). The parameters of equation \\(m\\) in the system are identified if \\(K-K_m\\geq M_m-1\\), where \\(K_m\\) and \\(M_m\\) are the number of exogenous and endogenous variables in equation \\(m\\), respectively. The \\(m\\)-th equation is exactly identified if \\(K-K_m = M_m-1\\), and over identified if \\(K-K_m &gt; M_m-1\\). We can see from Equations (7.1) and (7.2) in this example that \\(K=5\\), \\(M=2\\), \\(K_1=4\\), \\(K_2=2\\), \\(M_1=2\\), and \\(M_2=2\\). This means that \\(K-K_1=1=M-1\\) and \\(K-K_2=3&gt;M-1=1\\), that is, the order condition says that both equations satisfy the necessary condition of identification, the first equation would be exactly identified, and the second equation would be over identified. Observe that there is one excluded variable from the first equation, and there are three excluded variables from the second equation. The rank condition The rank condition (necessary and sufficient) says that given a structural model with \\(M\\) equations (\\(M\\) endogenous variables), an equation is identified if and only if there is at least one determinant different from zero from a \\((M-1)\\times(M-1)\\) matrix built using the excluded variables in the analyzed equation, but included in any other equation of the system. It is useful to build the identification matrix to implement the rank condition. The next Table shows this matrix in this example. Table 7.1: Example: Rank condition \\(\\log(\\text{pcGDP95})\\) \\(\\text{PAER}\\) Constant \\(\\log(\\text{Mort})\\) Africa Asia Other 1 \\(-\\beta_2\\) \\(-\\beta_1\\) 0 \\(-\\beta_3\\) \\(-\\beta_4\\) \\(-\\beta_5\\) \\(-\\alpha_2\\) 1 \\(-\\alpha_1\\) \\(-\\alpha_3\\) 0 0 0 The only excluded variable in the \\(\\log(\\text{pcGDP95})\\) equation is \\(\\log(\\text{Mort})\\). Therefore, there is only one matrix that can be constructed using the excluded variables from this equation, which is \\([-\\alpha_3]\\) (see column 4 in the Table). The determinant of this matrix is \\(-\\alpha_3\\), and as long as this coefficient is nonzero (i.e., \\(\\alpha_3 \\neq 0\\)), meaning that the mortality rate is relevant in the PAER equation, the coefficients in the \\(\\log(\\text{pcGDP95})\\) equation are exactly identified. For example, \\(\\beta_2 = \\frac{\\pi_2}{\\gamma_2}\\), which represents the effect of property rights on GDP, is exactly identified. It is crucial to observe the importance of excluding \\(\\log(\\text{Mort})\\) from the \\(\\log(\\text{pcGDP95})\\) equation, while including \\(\\log(\\text{Mort})\\) in the PAER equation. This is known as the exclusion restriction, which requires the presence of an exogenous source of variability in the PAER equation to help identify the \\(\\log(\\text{pcGDP95})\\) equation. The presence of relevant exogenous sources of variability is an essential factor in the identification, estimation, and inference of structural parameters. As for the identification of the structural parameters in the PAER equation, there are three potential matrices that can be constructed: \\([-\\beta_3]\\), \\([-\\beta_4]\\), and \\([-\\beta_5]\\) (see columns 5, 6, and 7 in the Table). As long as any of these parameters are relevant in the \\(\\log(\\text{pcGDP95})\\) equation, the PAER equation is identified. In this case, the PAER equation is over-identified, meaning there are multiple ways to estimate the parameters in this equation. For example, \\(\\alpha_2 = \\gamma_3/\\pi_3 = \\gamma_4/\\pi_4 = \\gamma_5/\\pi_5\\) (see Exercise 2). In general, recovering the structural parameters from the reduced-form parameters can be challenging due to the need for relevant identification restrictions, which can be difficult to find in some applications.39 For this example, we set non-informative priors: \\(\\boldsymbol{B}_0 = \\left[\\boldsymbol{0}_5 \\ \\boldsymbol{0}_5\\right]\\), \\(\\boldsymbol{V}_0 = 100 \\boldsymbol{I}_K\\), \\(\\boldsymbol{\\Psi}_0 = 5 \\boldsymbol{I}_2\\), and \\(\\alpha_0 = 5\\).40 Once our GUI is displayed (see the beginning of this chapter), we should follow the next Algorithm to run multivariate linear models in the GUI (see Chapter 5 for details, particularly on how to set the data set). Algorithm: Multivariate Linear Model Select Multivariate Models on the top panel Select Simple Multivariate model using the left radio button Upload the dataset selecting first if there is header in the file, and the kind of separator in the csv file of the dataset (comma, semicolon, or tab). Then, use the Browse button under the Choose File legend Select MCMC iterations, burn-in, and thinning parameters using the Range sliders Select the number of dependent variables in the box Number of endogenous variables: m Select the number of independent variables (including the intercept) in the box Number of exogenous variables: k Set the hyperparameters: mean vectors, covariance matrix, degrees of freedom, and the scale matrix. This step is not necessary as by default our GUI uses non-informative priors Click the Go! button Analyze results Download posterior chains and diagnostic plots using the Download Posterior Chains and Download Posterior Graphs buttons The following R code shows how to perform the Gibss sampling algorithm in this example using the dataset 4Institutions.csv. We ask to run this example using the rmultireg command from the bayesm package as an exercise. We find that the posterior mean structural effect of property rights on GDP is 0.98, and the 95% credible interval is (0.56, 2.87). This means that there is evidence supporting a positive effect of property rights on gross domestic product. rm(list = ls()) set.seed(12345) DataInst &lt;- read.csv(&quot;https://raw.githubusercontent.com/besmarter/BSTApp/refs/heads/master/DataApp/4Institutions.csv&quot;, sep = &quot;,&quot;, header = TRUE, quote = &quot;&quot;) attach(DataInst) Y &lt;- cbind(logpcGDP95, PAER) X &lt;- cbind(1, logMort, Africa, Asia, Other) M &lt;- dim(Y)[2] K &lt;- dim(X)[2] N &lt;- dim(Y)[1] # Hyperparameters B0 &lt;- matrix(0, K, M) c0 &lt;- 100 V0 &lt;- c0*diag(K) Psi0 &lt;- 5*diag(M) a0 &lt;- 5 # Posterior parameters Bhat &lt;- solve(t(X)%*%X)%*%t(X)%*%Y S &lt;- t(Y - X%*%Bhat)%*%(Y - X%*%Bhat) Vn &lt;- solve(solve(V0) + t(X)%*%X) Bn &lt;- Vn%*%(solve(V0)%*%B0 + t(X)%*%X%*%Bhat) Psin &lt;- Psi0 + S + t(B0)%*%solve(V0)%*%B0 + t(Bhat)%*%t(X)%*%X%*%Bhat - t(Bn)%*%solve(Vn)%*%Bn an &lt;- a0 + N #Posterior draws s &lt;- 10000 #Number of posterior draws SIGs &lt;- replicate(s, LaplacesDemon::rinvwishart(an, Psin)) BsCond &lt;- sapply(1:s, function(s) {MixMatrix::rmatrixnorm(n = 1, mean=Bn, U = Vn,V = SIGs[,,s])}) summary(coda::mcmc(t(BsCond))) ## ## Iterations = 1:10000 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 10000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## [1,] 10.3789 0.44935 0.0044935 0.0044935 ## [2,] -0.4170 0.09972 0.0009972 0.0009972 ## [3,] -0.7318 0.24032 0.0024032 0.0024032 ## [4,] -0.5840 0.28959 0.0028959 0.0028959 ## [5,] 0.2972 0.48248 0.0048248 0.0048248 ## [6,] 8.5156 0.75222 0.0075222 0.0075222 ## [7,] -0.4283 0.16725 0.0016725 0.0016725 ## [8,] -0.2677 0.40099 0.0040099 0.0040361 ## [9,] 0.3475 0.48749 0.0048749 0.0048749 ## [10,] 1.2454 0.81787 0.0081787 0.0081787 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## var1 9.4953 10.07783 10.3766 10.6768666 11.27717 ## var2 -0.6136 -0.48366 -0.4158 -0.3496649 -0.22143 ## var3 -1.1985 -0.89381 -0.7327 -0.5695042 -0.25578 ## var4 -1.1527 -0.77805 -0.5827 -0.3900056 -0.01057 ## var5 -0.6587 -0.02514 0.2945 0.6224207 1.24241 ## var6 7.0210 8.01999 8.5116 9.0111246 10.00396 ## var7 -0.7558 -0.53971 -0.4285 -0.3165409 -0.10184 ## var8 -1.0600 -0.53703 -0.2676 0.0002646 0.52081 ## var9 -0.6090 0.02377 0.3500 0.6740956 1.30291 ## var10 -0.3446 0.69699 1.2418 1.7939884 2.86752 SIGMs &lt;- t(sapply(1:s, function(l) {gdata::lowerTriangle(SIGs[,,l], diag=TRUE, byrow=FALSE)})) summary(coda::mcmc(SIGMs)) ## ## Iterations = 1:10000 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 10000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## [1,] 0.5381 0.09524 0.0009524 0.0009813 ## [2,] 0.5372 0.13144 0.0013144 0.0013144 ## [3,] 1.5225 0.26763 0.0026763 0.0026763 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## var1 0.3853 0.4695 0.5267 0.5942 0.7545 ## var2 0.3181 0.4449 0.5234 0.6137 0.8359 ## var3 1.0863 1.3324 1.4924 1.6799 2.1354 hdiBs &lt;- HDInterval::hdi(t(BsCond), credMass = 0.95) # Highest posterior density credible interval hdiBs ## [,1] [,2] [,3] [,4] [,5] [,6] ## lower 9.44900 -0.6131229 -1.1769984 -1.16535714 -0.670223 7.041383 ## upper 11.22169 -0.2212954 -0.2393919 -0.02786525 1.227650 10.017329 ## [,7] [,8] [,9] [,10] ## lower -0.74678771 -1.0419989 -0.6358514 -0.3253181 ## upper -0.09525447 0.5322414 1.2748474 2.8767518 ## attr(,&quot;credMass&quot;) ## [1] 0.95 hdiSIG &lt;- HDInterval::hdi(SIGMs, credMass = 0.95) # Highest posterior density credible interval hdiSIG ## [,1] [,2] [,3] ## lower 0.3735344 0.2960049 1.023421 ## upper 0.7318534 0.8022998 2.034439 ## attr(,&quot;credMass&quot;) ## [1] 0.95 beta2 &lt;- BsCond[2,]/BsCond[7,] summary(coda::mcmc(beta2)) # Effect of property rights on GDP ## ## Iterations = 1:10000 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 10000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## 0.9796 16.8430 0.1684 0.1684 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## 0.5604 0.7984 0.9677 1.2329 2.8709 References "],["sec72.html", "7.2 Seemingly Unrelated Regression", " 7.2 Seemingly Unrelated Regression In seemingly unrelated regression (SUR) models, there are \\(M\\) dependent variables, each with potentially different regressors, such that the stochastic errors are contemporaneously correlated. The model is given by: \\[ \\boldsymbol{y}_m = \\boldsymbol{X}_m \\boldsymbol{\\beta}_m + \\boldsymbol{\\mu}_m, \\] where \\(\\boldsymbol{y}_m\\) is an \\(N\\)-dimensional vector of observations, \\(\\boldsymbol{X}_m\\) is an \\(N \\times K_m\\) matrix of regressors, \\(\\boldsymbol{\\beta}_m\\) is a \\(K_m\\)-dimensional vector of location parameters, and \\(\\boldsymbol{\\mu}_m\\) is an \\(N\\)-dimensional vector of stochastic errors, for \\(m = 1, 2, \\dots, M\\). Let \\(\\boldsymbol{\\mu}_i = \\left[\\mu_{i1} \\ \\mu_{i2} \\ \\dots \\ \\mu_{iM}\\right]^{\\top}\\), where \\(\\boldsymbol{\\mu}_i \\sim \\mathcal{N}(\\boldsymbol{0}, \\boldsymbol{\\Sigma})\\). Stacking the \\(M\\) equations, we can write the model as: \\[ \\boldsymbol{y} = \\boldsymbol{X} \\boldsymbol{\\beta} + \\boldsymbol{\\mu}, \\] where \\(\\boldsymbol{y} = \\left[\\boldsymbol{y}_1^{\\top} \\ \\boldsymbol{y}_2^{\\top} \\ \\dots \\ \\boldsymbol{y}_M^{\\top}\\right]^{\\top}\\) is an \\(MN\\)-dimensional vector, \\(\\boldsymbol{\\beta} = \\left[\\boldsymbol{\\beta}_1^{\\top} \\ \\boldsymbol{\\beta}_2^{\\top} \\ \\dots \\ \\boldsymbol{\\beta}_M^{\\top}\\right]^{\\top}\\) is a \\(K\\)-dimensional vector with \\(K = \\sum_{m=1}^M K_m\\), and \\(\\boldsymbol{X}\\) is an \\(MN \\times K\\) block-diagonal matrix composed of the individual \\(\\boldsymbol{X}_m\\), i.e., \\[ \\boldsymbol{X} = \\begin{bmatrix} \\boldsymbol{X}_1 &amp; \\boldsymbol{0} &amp; \\dots &amp; \\boldsymbol{0} \\\\ \\boldsymbol{0} &amp; \\boldsymbol{X}_2 &amp; \\dots &amp; \\boldsymbol{0} \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ \\boldsymbol{0} &amp; \\boldsymbol{0} &amp; \\dots &amp; \\boldsymbol{X}_M \\end{bmatrix}. \\] Similarly, the vector of errors is given by \\(\\boldsymbol{\\mu} = \\left[\\boldsymbol{\\mu}_1^{\\top} \\ \\boldsymbol{\\mu}_2^{\\top} \\ \\dots \\ \\boldsymbol{\\mu}_M^{\\top}\\right]^{\\top}\\), which is an \\(MN\\)-dimensional vector of stochastic errors, with \\(\\boldsymbol{\\mu} \\sim \\mathcal{N}(\\boldsymbol{0}, \\boldsymbol{\\Sigma} \\otimes \\boldsymbol{I}_N)\\). The likelihood function for the parameters is then: \\[ p(\\boldsymbol{\\beta}, \\boldsymbol{\\Sigma} \\mid \\boldsymbol{y}, \\boldsymbol{X}) \\propto |\\boldsymbol{\\Sigma}|^{-N/2} \\exp\\left\\{ -\\frac{1}{2} (\\boldsymbol{y} - \\boldsymbol{X} \\boldsymbol{\\beta})^{\\top} (\\boldsymbol{\\Sigma}^{-1} \\otimes \\boldsymbol{I}_N) (\\boldsymbol{y} - \\boldsymbol{X} \\boldsymbol{\\beta}) \\right\\}. \\] Using independent priors \\(\\pi(\\boldsymbol{\\beta}) \\sim \\mathcal{N}(\\boldsymbol{\\beta}_0, \\boldsymbol{B}_0)\\) and \\(\\pi(\\boldsymbol{\\Sigma}^{-1}) \\sim W(\\alpha_0, \\boldsymbol{\\Psi}_0)\\), the posterior distributions are \\[ \\boldsymbol{\\beta} \\mid \\boldsymbol{\\Sigma}, \\boldsymbol{y}, \\boldsymbol{X} \\sim \\mathcal{N}(\\boldsymbol{\\beta}_n, \\boldsymbol{B}_n), \\] \\[ \\boldsymbol{\\Sigma}^{-1} \\mid \\boldsymbol{\\beta}, \\boldsymbol{y}, \\boldsymbol{X} \\sim W(\\alpha_n, \\boldsymbol{\\Psi}_n), \\] where \\(\\boldsymbol{B}_n = (\\boldsymbol{X}^{\\top} (\\boldsymbol{\\Sigma}^{-1} \\otimes \\boldsymbol{I}_N) \\boldsymbol{X} + \\boldsymbol{B}_0^{-1})^{-1}\\), \\(\\boldsymbol{\\beta}_n = \\boldsymbol{B}_n (\\boldsymbol{B}_0^{-1} \\boldsymbol{\\beta}_0 + \\boldsymbol{X}^{\\top} (\\boldsymbol{\\Sigma}^{-1} \\otimes \\boldsymbol{I}_N) \\boldsymbol{y})\\), \\(\\alpha_n = \\alpha_0 + N\\) and \\(\\boldsymbol{\\Psi}_n = (\\boldsymbol{\\Psi}_0^{-1} + \\boldsymbol{U}^{\\top} \\boldsymbol{U})^{-1}\\), where \\(\\boldsymbol{U}\\) is an \\(N \\times M\\) matrix whose columns are \\(\\boldsymbol{y}_m - \\boldsymbol{X}_m \\boldsymbol{\\beta}_m\\). We can demonstrate, through straightforward yet tedious algebra, that by defining \\(\\boldsymbol{y}_i = [y_{i1} \\ y_{i2} \\ \\dots \\ y_{iM}]\\) and \\[ \\boldsymbol{X}_i = \\begin{bmatrix} x_{1i}^{\\top} &amp; \\boldsymbol{0} &amp; \\dots &amp; \\boldsymbol{0} \\\\ \\boldsymbol{0} &amp; x_{2i}^{\\top} &amp; \\dots &amp; \\boldsymbol{0} \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ \\boldsymbol{0} &amp; \\boldsymbol{0} &amp; \\dots &amp; x_{Mi}^{\\top} \\end{bmatrix}, \\] we alternatively have \\(\\boldsymbol{B}_n = (\\boldsymbol{B}_0^{-1} + \\sum_{i=1}^N \\boldsymbol{X}_i^{\\top} \\boldsymbol{\\Sigma}^{-1} \\boldsymbol{X}_i)^{-1}\\), \\(\\boldsymbol{\\beta}_n = \\boldsymbol{B}_n (\\boldsymbol{B}_0^{-1} \\boldsymbol{\\beta}_0 + \\sum_{i=1}^N \\boldsymbol{X}_i^{\\top} \\boldsymbol{\\Sigma}^{-1} \\boldsymbol{y}_i)\\) and \\(\\boldsymbol{\\Psi}_n = (\\boldsymbol{\\Psi}_0^{-1} + \\sum_{i=1}^N (\\boldsymbol{y}_i - \\boldsymbol{X}_i^{\\top} \\boldsymbol{\\beta}) (\\boldsymbol{y}_i - \\boldsymbol{X}_i^{\\top} \\boldsymbol{\\beta})^{\\top})^{-1}\\). Observe that we have standard conditional posteriors, thus, we can employ a Gibbs sampling algorithm to get the posterior draws. Example: Utility demand Let’s use the dataset Utilities.csv to estimate a seemingly unrelated regression (SUR) model for utilities. We adopt the same setting as in Exercise 14 of Chapter 3, where we estimate a multivariate regression model while omitting households with no consumption in any utility. In this exercise, we observe that not all regressors are relevant for the demand of electricity, water, and gas. Thus, we estimate the following model: \\[\\begin{align*} \\log(\\text{electricity}_i) &amp; = \\beta_1 + \\beta_2\\log(\\text{electricity price}_i) + \\beta_3\\log(\\text{water price}_i) \\\\ &amp; + \\beta_4\\log(\\text{gas price}_i) + \\beta_5\\text{IndSocio1}_i + \\beta_6\\text{IndSocio2}_i + \\beta_7\\text{Altitude}_i \\\\ &amp; + \\beta_8\\text{Nrooms}_i + \\beta_9\\text{HouseholdMem}_i + \\beta_{10}\\log(\\text{Income}_i) + \\mu_{i1} \\\\ \\log(\\text{water}_i) &amp; = \\alpha_1 + \\alpha_2\\log(\\text{electricity price}_i) + \\alpha_3\\log(\\text{water price}_i) \\\\ &amp; + \\alpha_4\\log(\\text{gas price}_i) + \\alpha_5\\text{IndSocio1}_i + \\alpha_6\\text{IndSocio2}_i \\\\ &amp; + \\alpha_7\\text{Nrooms}_i + \\alpha_8\\text{HouseholdMem}_i + \\mu_{i2} \\\\ \\log(\\text{gas}_i) &amp; = \\gamma_1 + \\gamma_2\\log(\\text{electricity price}_i) + \\gamma_3\\log(\\text{water price}_i) \\\\ &amp; + \\gamma_4\\log(\\text{gas price}_i) + \\gamma_5\\text{IndSocio1}_i + \\gamma_6\\text{IndSocio2}_i + \\gamma_7\\text{Altitude}_i \\\\ &amp; + \\gamma_8\\text{Nrooms}_i + \\gamma_9\\text{HouseholdMem}_i + \\mu_{i3}, \\end{align*}\\] where electricity, water, and gas represent the monthly consumption of electricity (kWh), water (m\\(^3\\)), and gas (m\\(^3\\)) of Colombian households. The dataset includes information on 2,103 households, with details on the average prices of electricity (USD/kWh), water (USD/m\\(^3\\)), and gas (USD/m\\(^3\\)), as well as indicators of the socioeconomic conditions of the neighborhood where the household is located (IndSocio1 being the lowest and IndSocio3 the highest). Additionally, there is information on whether the household is located in a municipality situated at over 1,000 meters above sea level, the number of rooms in the house, the number of household members, and monthly income (USD). Since each equation has a different set of regressors, and we suspect correlation between the stochastic errors of the three equations, we should estimate a seemingly unrelated regression (SUR) model. We expect unobserved correlation across these equations because we are modeling utilities, and in some cases, a single provider handles all three services and issues one bill. The following Algorithm demonstrates how to estimate SUR models using our GUI. Our GUI utilizes the command rsurGibbs from the bayesm package in R software. See Chapter 5 for further details, including instructions on how to set up the dataset, and check the templates available in our GitHub repository (https://github.com/besmarter/BSTApp) in the DataApp and DataSim folders. Algorithm: Seemingly Unrelated Regression (SUR) Select Multivariate Models on the top panel Select Seemingly Unrelated Regression model using the left radio button Upload the dataset, selecting first if there is a header in the file, and the kind of separator in the csv file of the dataset (comma, semicolon, or tab). Then, use the Browse button under the Choose File legend Select MCMC iterations, burn-in, and thinning parameters using the Range sliders Select the number of dependent variables in the box Number of endogenous variables: m Select the number of independent variables in the box TOTAL number of Exogenous Variables: k. This is the sum of all exogenous variables over all equations, including intercepts. In the example of Utility demand, it is equal to 27 Set the hyperparameters: mean vectors, covariance matrix, degrees of freedom, and the scale matrix. This step is not necessary as by default our GUI uses non-informative priors Click the Go! button Analyze results Download posterior chains and diagnostic plots using the Download Posterior Chains and Download Posterior Graphs buttons The following code shows how to program this application using this package. We use 10,000 MCMC iterations, \\(\\boldsymbol{\\beta}_0 = \\boldsymbol{0}_{27}\\), \\(\\boldsymbol{B}_0 = 100\\boldsymbol{I}_{27}\\), \\(\\alpha_0 = 5\\) and \\(\\boldsymbol{\\Psi} = 5\\boldsymbol{I}_3\\). We find that the posterior median estimates of the own-price elasticities of demand for electricity, water, and gas are -1.88, -0.36, and -0.62, respectively, and none of the 95% credible intervals encompass 0. This means that a 1% increase in the prices of electricity, water, and gas results in a 1.88%, 0.36%, and 0.62% decrease in the monthly consumption of these utilities, respectively.41 In general, there is evidence supporting the relevance of all regressors in these equations, with a few exceptions, and unobserved correlation in the demand for these services, which further supports the use of a SUR model in this application. rm(list = ls()) set.seed(010101) library(dplyr) DataUt &lt;- read.csv(&quot;https://raw.githubusercontent.com/besmarter/BSTApp/refs/heads/master/DataApp/Utilities.csv&quot;, sep = &quot;,&quot;, header = TRUE, quote = &quot;&quot;) DataUtEst &lt;- DataUt %&gt;% filter(Electricity != 0 &amp; Water !=0 &amp; Gas != 0) attach(DataUtEst) ## The following object is masked from Data (pos = 7): ## ## id ## The following object is masked from mydata: ## ## id ## The following objects are masked from DataUtEst (pos = 13): ## ## Altitude, Children, Electricity, Gas, HouseholdMem, id, IndSocio1, ## IndSocio2, IndSocio3, Lnincome, LnPriceElect, LnPriceGas, ## LnPriceWater, Nrooms, Water y1 &lt;- log(Electricity); y2 &lt;- log(Water); y3 &lt;- log(Gas) X1 &lt;- cbind(1, LnPriceElect, LnPriceWater, LnPriceGas, IndSocio1, IndSocio2, Altitude, Nrooms, HouseholdMem, Lnincome) X2 &lt;- cbind(1, LnPriceElect, LnPriceWater, LnPriceGas, IndSocio1, IndSocio2, Nrooms, HouseholdMem) X3 &lt;- cbind(1, LnPriceElect, LnPriceWater, LnPriceGas, IndSocio1, IndSocio2, Altitude, Nrooms, HouseholdMem) regdata &lt;- NULL regdata[[1]] &lt;- list(y = y1, X = X1); regdata[[2]] &lt;- list(y = y2, X = X2); regdata[[3]] &lt;- list(y = y3, X = X3) M &lt;- length(regdata); K1 &lt;- dim(X1)[2]; K2 &lt;- dim(X2)[2]; K3 &lt;- dim(X3)[2] K &lt;- K1 + K2 + K3 # Hyperparameters b0 &lt;- rep(0, K); c0 &lt;- 100; B0 &lt;- c0*diag(K); V &lt;- 5*diag(M); a0 &lt;- M Prior &lt;- list(betabar = b0, A = solve(B0), nu = a0, V = V) #Posterior draws S &lt;- 10000; keep &lt;- 1; Mcmc &lt;- list(R = S, keep = keep, nprint = 0) PosteriorDraws &lt;- bayesm::rsurGibbs(Data = list(regdata = regdata), Mcmc = Mcmc, Prior = Prior) ## ## Starting Gibbs Sampler for SUR Regression Model ## with 3 regressions ## and 1574 observations for each regression ## ## Prior Parms: ## betabar ## [1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## A ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] ## [1,] 0.01 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [2,] 0.00 0.01 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [3,] 0.00 0.00 0.01 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [4,] 0.00 0.00 0.00 0.01 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [5,] 0.00 0.00 0.00 0.00 0.01 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [6,] 0.00 0.00 0.00 0.00 0.00 0.01 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [7,] 0.00 0.00 0.00 0.00 0.00 0.00 0.01 0.00 0.00 0.00 0.00 0.00 0.00 ## [8,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.01 0.00 0.00 0.00 0.00 0.00 ## [9,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.01 0.00 0.00 0.00 0.00 ## [10,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.01 0.00 0.00 0.00 ## [11,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.01 0.00 0.00 ## [12,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.01 0.00 ## [13,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.01 ## [14,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [15,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [16,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [17,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [18,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [19,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [20,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [21,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [22,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [23,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [24,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [25,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [26,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [27,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [,14] [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] [,25] ## [1,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [2,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [3,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [4,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [5,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [6,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [7,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [8,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [9,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [10,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [11,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [12,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [13,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [14,] 0.01 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [15,] 0.00 0.01 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [16,] 0.00 0.00 0.01 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [17,] 0.00 0.00 0.00 0.01 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [18,] 0.00 0.00 0.00 0.00 0.01 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [19,] 0.00 0.00 0.00 0.00 0.00 0.01 0.00 0.00 0.00 0.00 0.00 0.00 ## [20,] 0.00 0.00 0.00 0.00 0.00 0.00 0.01 0.00 0.00 0.00 0.00 0.00 ## [21,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.01 0.00 0.00 0.00 0.00 ## [22,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.01 0.00 0.00 0.00 ## [23,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.01 0.00 0.00 ## [24,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.01 0.00 ## [25,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.01 ## [26,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [27,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [,26] [,27] ## [1,] 0.00 0.00 ## [2,] 0.00 0.00 ## [3,] 0.00 0.00 ## [4,] 0.00 0.00 ## [5,] 0.00 0.00 ## [6,] 0.00 0.00 ## [7,] 0.00 0.00 ## [8,] 0.00 0.00 ## [9,] 0.00 0.00 ## [10,] 0.00 0.00 ## [11,] 0.00 0.00 ## [12,] 0.00 0.00 ## [13,] 0.00 0.00 ## [14,] 0.00 0.00 ## [15,] 0.00 0.00 ## [16,] 0.00 0.00 ## [17,] 0.00 0.00 ## [18,] 0.00 0.00 ## [19,] 0.00 0.00 ## [20,] 0.00 0.00 ## [21,] 0.00 0.00 ## [22,] 0.00 0.00 ## [23,] 0.00 0.00 ## [24,] 0.00 0.00 ## [25,] 0.00 0.00 ## [26,] 0.01 0.00 ## [27,] 0.00 0.01 ## nu = 3 ## V = ## [,1] [,2] [,3] ## [1,] 5 0 0 ## [2,] 0 5 0 ## [3,] 0 0 5 ## ## MCMC parms: ## R= 10000 keep= 1 nprint= 0 ## Bs &lt;- PosteriorDraws[[&quot;betadraw&quot;]] Names &lt;- c(&quot;Const&quot;, &quot;LnPriceElect&quot;, &quot;LnPriceWater&quot;, &quot;LnPriceGas&quot;, &quot;IndSocio1&quot;, &quot;IndSocio2&quot;, &quot;Altitude&quot;, &quot;Nrooms&quot;, &quot;HouseholdMem&quot;, &quot;Lnincome&quot;, &quot;Const&quot;, &quot;LnPriceElect&quot;, &quot;LnPriceWater&quot;, &quot;LnPriceGas&quot;, &quot;IndSocio1&quot;, &quot;IndSocio2&quot;, &quot;Nrooms&quot;, &quot;HouseholdMem&quot;,&quot;Const&quot;, &quot;LnPriceElect&quot;, &quot;LnPriceWater&quot;, &quot;LnPriceGas&quot;, &quot;IndSocio1&quot;, &quot;IndSocio2&quot;, &quot;Altitude&quot;, &quot;Nrooms&quot;, &quot;HouseholdMem&quot;) colnames(Bs) &lt;- Names summary(coda::mcmc(Bs)) ## ## Iterations = 1:10000 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 10000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## Const 1.343420 0.45854 0.0045854 0.0045854 ## LnPriceElect -1.883221 0.26486 0.0026486 0.0026100 ## LnPriceWater -0.356765 0.04423 0.0004423 0.0004423 ## LnPriceGas -0.098387 0.05960 0.0005960 0.0006046 ## IndSocio1 -0.737529 0.07192 0.0007192 0.0006969 ## IndSocio2 -0.151118 0.04787 0.0004787 0.0004859 ## Altitude -0.220988 0.02531 0.0002531 0.0002531 ## Nrooms 0.070102 0.01236 0.0001236 0.0001236 ## HouseholdMem 0.086989 0.01057 0.0001057 0.0001057 ## Lnincome 0.062892 0.01244 0.0001244 0.0001223 ## Const 2.177612 0.65917 0.0065917 0.0065917 ## LnPriceElect -0.050723 0.39241 0.0039241 0.0039241 ## LnPriceWater -0.364801 0.06656 0.0006656 0.0006656 ## LnPriceGas 0.226759 0.08681 0.0008681 0.0008681 ## IndSocio1 -0.427636 0.11136 0.0011136 0.0011334 ## IndSocio2 -0.359542 0.07427 0.0007427 0.0007427 ## Nrooms 0.093014 0.01868 0.0001868 0.0001868 ## HouseholdMem 0.131650 0.01612 0.0001612 0.0001612 ## Const -1.215735 0.54177 0.0054177 0.0054177 ## LnPriceElect -1.794509 0.31960 0.0031960 0.0031960 ## LnPriceWater -0.003921 0.05257 0.0005257 0.0005257 ## LnPriceGas -0.625445 0.07270 0.0007270 0.0007270 ## IndSocio1 -0.744103 0.08706 0.0008706 0.0008706 ## IndSocio2 -0.203635 0.05893 0.0005893 0.0005893 ## Altitude 0.311631 0.03136 0.0003136 0.0003136 ## Nrooms 0.089361 0.01481 0.0001481 0.0001488 ## HouseholdMem 0.169882 0.01264 0.0001264 0.0001264 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## Const 0.44452 1.03120 1.342407 1.65192 2.25376 ## LnPriceElect -2.39679 -2.06328 -1.882706 -1.70369 -1.36996 ## LnPriceWater -0.44221 -0.38678 -0.356850 -0.32669 -0.26969 ## LnPriceGas -0.21655 -0.13777 -0.098191 -0.05902 0.01872 ## IndSocio1 -0.87630 -0.78653 -0.737701 -0.68840 -0.59675 ## IndSocio2 -0.24601 -0.18286 -0.151440 -0.11896 -0.05681 ## Altitude -0.27080 -0.23838 -0.220742 -0.20385 -0.17259 ## Nrooms 0.04596 0.06178 0.070023 0.07835 0.09422 ## HouseholdMem 0.06600 0.07994 0.086857 0.09411 0.10785 ## Lnincome 0.03836 0.05421 0.062957 0.07165 0.08717 ## Const 0.88957 1.73496 2.169638 2.62170 3.47216 ## LnPriceElect -0.81956 -0.31624 -0.054075 0.21132 0.71842 ## LnPriceWater -0.49559 -0.40995 -0.364248 -0.32026 -0.23639 ## LnPriceGas 0.06075 0.16754 0.226690 0.28570 0.39476 ## IndSocio1 -0.64203 -0.50302 -0.427819 -0.35226 -0.21315 ## IndSocio2 -0.50401 -0.40949 -0.359821 -0.31063 -0.21199 ## Nrooms 0.05688 0.08023 0.093139 0.10555 0.12968 ## HouseholdMem 0.10041 0.12065 0.131506 0.14260 0.16314 ## Const -2.28569 -1.58566 -1.220078 -0.84612 -0.14787 ## LnPriceElect -2.42484 -2.01228 -1.797269 -1.57889 -1.16396 ## LnPriceWater -0.10684 -0.03923 -0.004088 0.03153 0.09905 ## LnPriceGas -0.76526 -0.67445 -0.625899 -0.57734 -0.48125 ## IndSocio1 -0.91381 -0.80243 -0.744909 -0.68577 -0.57341 ## IndSocio2 -0.31791 -0.24388 -0.203300 -0.16415 -0.09012 ## Altitude 0.24896 0.29099 0.311668 0.33256 0.37278 ## Nrooms 0.06050 0.07921 0.089386 0.09943 0.11793 ## HouseholdMem 0.14467 0.16144 0.170024 0.17843 0.19431 summary(PosteriorDraws[[&quot;Sigmadraw&quot;]]) ## Posterior Means of Std Deviations and Correlation Matrix ## Std Dev 1 2 3 ## 1 0.46 1.00 0.30 0.25 ## 2 0.72 0.30 1.00 0.23 ## 3 0.56 0.25 0.23 1.00 ## ## Upper Triangle of Var-Cov Matrix ## Summary of Posterior Marginal Distributions ## Moments ## mean std dev num se rel eff sam size ## 1,1 0.214 0.0077 7.1e-05 0.78 9000 ## 1,2 0.099 0.0087 9.2e-05 1.01 4500 ## 2,2 0.512 0.0182 1.9e-04 0.95 9000 ## 1,3 0.064 0.0068 6.6e-05 0.84 9000 ## 2,3 0.094 0.0105 1.1e-04 1.02 4500 ## 3,3 0.317 0.0114 1.2e-04 0.94 9000 ## based on 9000 valid draws (burn-in=1000) We ask in the Exercise 5 to run this application using our GUI and the information in the dataset Utilities.csv. Observe that this file should be modified to agree the structure that requires our GUI (see the dataset 5Institutions.csv in the folder DataApp of our GitHub repository -https://github.com/besmarter/BSTApp- for a template). In addition, we ask to program from scratch the Gibbs sampler algorithm in this application. References "],["sec73.html", "7.3 Instrumental variable", " 7.3 Instrumental variable This inferential approach is used when there are endogeneity issues, that is, when the stochastic error is not independent of the regressors. This, in turn, generates bias in posterior mean estimates when we use an inferential approach that does not account for this issue. Endogeneity can be caused by reverse causality, omitting relevant correlated variables, or measurement error in the regressors.42 Let’s specify the dependent variable as a linear function of one endogenous regressor and some exogenous regressors. That is, \\[ y_{i} = \\boldsymbol{x}_{ei}^{\\top} \\boldsymbol{\\beta}_1 + \\beta_s x_{si} + \\mu_{i} \\] where \\[ x_{si} = \\boldsymbol{x}_{ei}^{\\top} \\boldsymbol{\\gamma}_1 + \\boldsymbol{z}_i^{\\top} \\boldsymbol{\\gamma}_2 + v_{i}, \\] \\(x_s\\) is the variable that generates the endogeneity issues (\\(\\mathbb{E}[\\mu \\mid x_{s}] \\neq 0\\)), \\(\\boldsymbol{x}_e\\) are \\(K_1\\) exogenous regressors (\\(\\mathbb{E}[\\mu \\mid \\boldsymbol{x}_{e}] = \\boldsymbol{0}\\)), and \\(\\boldsymbol{z}\\) are \\(K_2\\) instruments. The instruments are regressors that drive \\(x_s\\) (\\(\\mathbb{E}[x_{s} \\boldsymbol{z}] \\neq \\boldsymbol{0}\\)), but do not have a direct effect on \\(y\\) (\\(\\mathbb{E}[y \\boldsymbol{z} \\mid x_s] = \\boldsymbol{0}\\)). The equation for \\(y\\) is called the structural equation, and it is the equation that the researcher is ultimately interested in. Assuming \\[ (u_{i},v_i)^{\\top} \\stackrel{i.i.d.}{\\thicksim} N(0,\\boldsymbol{\\Sigma}), \\] where \\(\\boldsymbol{\\Sigma}=[\\sigma_{lm}]\\), \\(l,m=1,2\\), the likelihood function is \\[ p(\\boldsymbol{\\beta},\\boldsymbol{\\gamma},\\boldsymbol{\\Sigma} \\mid \\boldsymbol{y},\\boldsymbol{X},\\boldsymbol{Z}) = \\frac{1}{(2\\pi)^\\frac{N}{2}|\\boldsymbol{\\Sigma}|^\\frac{N}{2}} \\exp\\left\\{-\\frac{1}{2} \\sum_{i=1}^N (y_i-\\boldsymbol{x}_i^{\\top} \\boldsymbol{\\beta}, x_{si} -\\boldsymbol{w}_i^{\\top} \\boldsymbol{\\gamma}) \\boldsymbol{\\Sigma}^{-1} \\begin{pmatrix} y_i - \\boldsymbol{x}_i^{\\top} \\boldsymbol{\\beta} \\\\ x_{si} - \\boldsymbol{w}_i^{\\top} \\boldsymbol{\\gamma} \\end{pmatrix} \\right\\}, \\] where \\[ \\boldsymbol{\\beta}=\\begin{bmatrix} \\boldsymbol{\\beta}_1^{\\top} &amp; \\beta_s \\end{bmatrix}^{\\top}, \\quad \\boldsymbol{\\gamma}=\\begin{bmatrix} \\boldsymbol{\\gamma}_1^{\\top} &amp; \\boldsymbol{\\gamma}_2^{\\top} \\end{bmatrix}^{\\top}, \\quad \\boldsymbol{x}_i=\\begin{bmatrix} \\boldsymbol{x}_{ei}^{\\top} &amp; x_{si} \\end{bmatrix}^{\\top}, \\quad \\boldsymbol{w}_i=\\begin{bmatrix} \\boldsymbol{x}_{ei}^{\\top} &amp; \\boldsymbol{z}_{i}^{\\top} \\end{bmatrix}^{\\top}. \\] We obtain the standard conditional posterior densities by specifying the following independent priors: \\[ \\boldsymbol{\\gamma} \\sim N(\\boldsymbol{\\gamma}_0, \\boldsymbol{G}_0), \\quad \\boldsymbol{\\beta} \\sim N(\\boldsymbol{\\beta}_0, \\boldsymbol{B}_0), \\quad \\boldsymbol{\\Sigma}^{-1} \\sim W(\\alpha_0, \\boldsymbol{\\Psi}_0). \\] In particular, the conditional distributions are: \\[ \\boldsymbol{\\beta} \\mid \\boldsymbol{\\gamma}, \\boldsymbol{\\Sigma}, \\boldsymbol{y}, \\boldsymbol{X}, \\boldsymbol{Z} \\sim N(\\boldsymbol{\\beta}_n, \\boldsymbol{B}_n), \\] \\[ \\boldsymbol{\\gamma} \\mid \\boldsymbol{\\beta}, \\boldsymbol{\\Sigma}, \\boldsymbol{y}, \\boldsymbol{X}, \\boldsymbol{Z} \\sim N(\\boldsymbol{\\gamma}_n, \\boldsymbol{G}_n), \\] \\[ \\boldsymbol{\\Sigma}^{-1} \\mid \\boldsymbol{\\beta}, \\boldsymbol{\\gamma}, \\boldsymbol{y}, \\boldsymbol{X}, \\boldsymbol{Z} \\sim W(\\alpha_n, \\boldsymbol{\\Psi}_n), \\] where \\[ \\boldsymbol{\\beta}_n = \\boldsymbol{B}_n \\left( \\boldsymbol{B}_0^{-1} \\boldsymbol{\\beta}_0 + \\omega_1^{-1} \\sum_{i=1}^{N} \\left[ \\boldsymbol{x}_i \\left( y_i - \\frac{\\sigma_{12}(x_{si} - \\boldsymbol{w}_i^{\\top} \\boldsymbol{\\gamma})}{\\sigma_{22}} \\right) \\right] \\right), \\] \\[ \\boldsymbol{B}_n = \\left( \\omega_1^{-1} \\sum_{i=1}^{N} \\boldsymbol{x}_i \\boldsymbol{x}_i^{\\top} + \\boldsymbol{B}_0^{-1} \\right)^{-1}, \\quad \\omega_1 = \\sigma_{11} - \\frac{\\sigma_{12}^2}{\\sigma_{22}}, \\] \\[ \\boldsymbol{G}_n = \\left( \\omega_2^{-1} \\sum_{i=1}^{N} \\boldsymbol{w}_i \\boldsymbol{w}_i^{\\top} + \\boldsymbol{G}_0^{-1} \\right)^{-1}, \\quad \\boldsymbol{\\gamma}_n = \\boldsymbol{G}_n \\left( \\boldsymbol{G}_0^{-1} \\boldsymbol{\\gamma}_0 + \\omega_2^{-1} \\sum_{i=1}^{N} \\left[ \\boldsymbol{w}_i \\left( x_{si} - \\frac{\\sigma_{12} (y_i - \\boldsymbol{x}_i^{\\top} \\boldsymbol{\\beta})}{\\sigma_{11}} \\right) \\right] \\right), \\] \\[ \\omega_2 = \\sigma_{22} - \\frac{\\sigma_{12}^2}{\\sigma_{11}}, \\quad \\boldsymbol{\\Psi}_n = \\left[ \\boldsymbol{\\Psi}_0^{-1} + \\sum_{i=1}^N \\begin{pmatrix} y_i - \\boldsymbol{x}_i^{\\top} \\boldsymbol{\\beta} \\\\ x_{si} - \\boldsymbol{w}_i^{\\top} \\boldsymbol{\\gamma} \\end{pmatrix} (y_i - \\boldsymbol{x}_i^{\\top} \\boldsymbol{\\beta}, x_{si} - \\boldsymbol{w}_i^{\\top} \\boldsymbol{\\gamma}) \\right]^{-1}, \\] \\[ \\alpha_n = \\alpha_0 + N, \\quad \\sigma_{lj} \\text{ are the elements of } \\boldsymbol{\\Sigma}. \\] We also use a Gibbs sampling algorithm in this model since we have standard conditional posterior distributions. Example: Simulation exercise Let’s simulate the simple process \\(y_i=\\beta_1+\\beta_2x_{si}+\\mu_i\\) and \\(x_{si}=\\gamma_1+\\gamma_2z_i+v_i\\) where \\([\\mu_i \\ v_i]^{\\top} \\sim N(\\boldsymbol{0},\\boldsymbol{\\Sigma})\\), \\(\\boldsymbol{\\Sigma}=[\\sigma_{lj}]\\) such that \\(\\sigma_{12} \\neq 0\\), \\(i=1,2,\\dots,100\\). Observe that \\(\\mu\\mid v\\sim N\\left(\\frac{\\sigma_{12}}{\\sigma_{22}}v,\\sigma_{11}-\\frac{\\sigma_{21}^2}{\\sigma_{22}}\\right)\\), this implies that \\(\\mathbb{E}[\\mu\\mid x_s]=\\mathbb{E}[\\mu\\mid v]=\\frac{\\sigma_{12}}{\\sigma_{22}}v\\neq 0\\) given \\(\\sigma_{12}\\neq 0\\) and \\(\\mathbb{E}[\\mu\\mid z]=0\\). Let’s set all location parameters equal to 1, and \\(\\sigma_{11}=\\sigma_{22}=1\\), \\(\\sigma_{12}=0.8\\), and \\(z\\sim N(0,1)\\). We know from the large sampling properties of the posterior mean that this converges to the maximum likelihood estimator (see Section 1.1, and Lehmann and Casella (2003), Van der Vaart (2000)), which in this setting is \\[ \\hat{\\beta}_2=\\frac{\\widehat{\\text{Cov}}(x_s,y)}{\\widehat{\\text{Var}}(x_s)} \\] which converges in probability to \\[ \\beta_2+\\frac{\\sigma_{12}}{\\sigma_{22}\\text{Var}(x_s)}=\\beta_2+\\frac{\\sigma_{12}}{\\sigma_{22}(\\gamma_2^2\\text{Var}(z)+\\sigma_{22})}=1.4, \\] that is, the asymptotic bias when using the posterior mean of a linear regression without taking into account endogeneity is 0.4 in this example. We assess the sampling performance of the Bayesian estimators by simulating this setting 100 times. The following code demonstrates how to do this using a linear model that does not account for the endogeneity issue (see Section 6.1), as well as how to implement the instrumental variable model. In this setup, we use \\(\\boldsymbol{B}_0 = 1000 \\mathbf{I}_2\\), \\(\\boldsymbol{\\beta}_0 = \\mathbf{0}_2\\), and the parameters of the inverse gamma distribution are set to 0.0005. For the instrumental variable model, we additionally set \\(\\boldsymbol{\\gamma}_0 = \\mathbf{0}_2\\), \\(\\boldsymbol{G}_0 = 1000 \\mathbf{I}_2\\), \\(\\alpha_0 = 3\\), and \\(\\boldsymbol{\\Psi}_0 = 3 \\mathbf{I}_2\\). rm(list = ls()); set.seed(010101) N &lt;- 100; k &lt;- 2 B &lt;- rep(1, k); G &lt;- rep(1, 2); s12 &lt;- 0.8 SIGMA &lt;- matrix(c(1, s12, s12, 1), 2, 2) z &lt;- rnorm(N); Z &lt;- cbind(1, z); w &lt;- matrix(1,N,1); S &lt;- 100 U &lt;- replicate(S, MASS::mvrnorm(n = N, mu = rep(0, 2), SIGMA)) x &lt;- G[1] + G[2]*z + U[,2,]; y &lt;- B[1] + B[2]*x + U[,1,] # Hyperparameters d0 &lt;- 0.001/2; a0 &lt;- 0.001/2 b0 &lt;- rep(0, k); c0 &lt;- 1000; B0 &lt;- c0*diag(k) B0i &lt;- solve(B0); g0 &lt;- rep(0, 2) G0 &lt;- 1000*diag(2); G0i &lt;- solve(G0) nu &lt;- 3; Psi0 &lt;- nu*diag(2) # MCMC parameters mcmc &lt;- 5000; burnin &lt;- 1000 tot &lt;- mcmc + burnin; thin &lt;- 1 # Gibbs sampling Gibbs &lt;- function(x, y){ Data &lt;- list(y = y, x = x, w = w, z = Z) Mcmc &lt;- list(R = mcmc, keep = thin, nprint = 0) Prior &lt;- list(md = g0, Ad = G0i, mbg = b0, Abg = B0i, nu = nu, V = Psi0) RestIV &lt;- bayesm::rivGibbs(Data = Data, Mcmc = Mcmc, Prior = Prior) PostBIV &lt;- mean(RestIV[[&quot;betadraw&quot;]]) ResLM &lt;- MCMCpack::MCMCregress(y ~ x + w - 1, b0 = b0, B0 = B0i, c0 = a0, d0 = d0) PostB &lt;- mean(ResLM[,1]); Res &lt;- c(PostB,PostBIV) return(Res) } PosteriorMeans &lt;- sapply(1:S, function(s) {Gibbs(x = x[,s], y = y[,s])}) ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## rowMeans(PosteriorMeans) ## [1] 1.408272 1.035428 Model &lt;- c(replicate(S, &quot;Ordinary&quot;), replicate(S, &quot;Instrumental&quot;)) postmeans &lt;- c(t(PosteriorMeans)) df &lt;- data.frame(postmeans, Model, stringsAsFactors = FALSE) library(ggplot2); library(latex2exp) histExo &lt;- ggplot(df, aes(x = postmeans, fill = Model)) + geom_histogram(bins = 40, position = &quot;identity&quot;, color = &quot;black&quot;, alpha = 0.5) + labs(title = &quot;Overlayed Histograms&quot;, x = &quot;Value&quot;, y = &quot;Count&quot;) + scale_fill_manual(values = c(&quot;blue&quot;, &quot;red&quot;)) + geom_vline(aes(xintercept = mean(postmeans[1:S])), color = &quot;black&quot;, linewidth = 1, linetype = &quot;dashed&quot;) + geom_vline(aes(xintercept = mean(postmeans[101:200])), color = &quot;black&quot;, linewidth = 1, linetype = &quot;dashed&quot;) + geom_vline(aes(xintercept = B[2]), color = &quot;green&quot;, linewidth = 1, linetype = &quot;dashed&quot;) + xlab(TeX(&quot;$E[\\\\beta_2]$&quot;)) + ylab(&quot;Frequency&quot;) + ggtitle(&quot;Histogram: Posterior means simulating 100 samples&quot;) histExo The Figure displays the histograms of the posterior means of \\(\\beta_2\\) using the ordinary model, which does not account for endogeneity, and the instrumental variable model. On one hand, the mean of the posterior means for the ordinary model is 1.41 (black dashed line in the red histogram), implying a bias of 0.41, which is very close to the population bias of 0.40. On the other hand, the mean of the posterior means for the instrumental variable model is 1.04 (black dashed line in the blue histogram), which is close to the population value of \\(\\beta_2 = 1\\) (green dashed line). We also observe that the histogram of the posterior means for the ordinary model is less dispersed. That is, this estimator is more efficient, which is a well-known result in the Frequentist inferential approach when comparing ordinary least squares and two-stage least squares (see Jeffrey M. Wooldridge (2010)). Two very important aspects in the instrumental variables literature are the weakness and exogeneity of the instruments. The former refers to how strong the relationship is between the instruments and the endogenous regressors, while the latter refers to the independence of the instruments from the stochastic error in the structural equation. In Exercise 6, we ask you to use the previous code as a baseline to study these two aspects. Observe the link between the weakness and exogeneity of the instrument, and the exclusion restrictions (\\(\\mathbb{E}[x_s \\boldsymbol{z}] \\neq \\boldsymbol{0}\\) and \\(\\mathbb{E}[y \\boldsymbol{z} \\mid x_s] = \\boldsymbol{0}\\)). This is the point of departure of Conley, Hansen, and Rossi (2012), who propose assessing the plausibility of the exclusion restrictions by defining plausible exogeneity as having prior information that the effect of the instrument in the structural equation is near zero, but perhaps not exactly zero. The following Algorithm can be used to estimate the instrumental variable model using our GUI. We ask in Exercise 8 to replicate the example of the effect of institutions on per capita GDP using our GUI. Algorithm: Instrumental Variable Model Select Multivariate Models on the top panel Select Variable instrumental (two equations) model using the left radio button Upload the dataset, selecting first if there is a header in the file, and the kind of separator in the csv file of the dataset (comma, semicolon, or tab). Then, use the Browse button under the Choose File legend Select MCMC iterations, burn-in, and thinning parameters using the Range sliders Write down the formula of the structural equation in the Main Equation box. This formula must be written using the syntax of the formula command of R software. This equation includes the intercept by default, do not include it in the equation Write down the formula of the endogenous regressor in the Instrumental Equation box. This formula must be written using the syntax of the formula command of R software. This equation includes the intercept by default, do not include it in the equation Set the hyperparameters: mean vectors, covariance matrices, degrees of freedom, and the scale matrix. This step is not necessary as by default our GUI uses non-informative priors Click the Go! button Analyze results Download posterior chains and diagnostic plots using the Download Posterior Chains and Download Posterior Graphs buttons References "],["sec74.html", "7.4 Multivariate probit model", " 7.4 Multivariate probit model In the multivariate probit model Edwards and Allenby (2003), the response variable \\(y_{il} = \\{0, 1\\}\\) indicates that individual \\(i\\) makes binary choices among \\(L\\) mutually exclusive alternatives, where \\(l = 1, 2, \\dots, L\\) and \\(i = 1, 2, \\dots, N\\). Specifically, \\[ y_{il} = \\begin{cases} 0, &amp; \\quad y_{il}^* \\leq 0 \\\\ 1, &amp; \\quad y_{il}^* &gt; 0 \\end{cases} \\] where \\(\\boldsymbol{y}_i^* = \\boldsymbol{X}_i \\boldsymbol{\\beta} + \\boldsymbol{\\mu}_i \\sim \\text{i.i.d.} \\, N(\\boldsymbol{0}, \\boldsymbol{\\Sigma})\\). Here, \\(\\boldsymbol{y}_i^*\\) is an unobserved latent \\(L\\)-dimensional vector, \\(\\boldsymbol{X}_i = \\boldsymbol{x}_i^\\top \\otimes \\mathbf{I}_L\\) is an \\(L \\times K\\) design matrix of regressors, with \\(K = L \\times k\\), where \\(k\\) is the number of regressors (i.e., the length of \\(\\boldsymbol{x}_i\\)). In addition, \\(\\boldsymbol{\\beta} = \\left[\\boldsymbol{\\beta}_1^\\top \\ \\boldsymbol{\\beta}_2^\\top \\dots \\boldsymbol{\\beta}_k^\\top\\right]^\\top\\), where \\(\\boldsymbol{\\beta}_j\\) forms an \\(L\\)-dimensional vector of coefficients for \\(j = 1, 2, \\dots, k\\). The likelihood function for this model is given by \\[ p(\\boldsymbol{\\beta}, \\boldsymbol{\\Sigma} \\mid \\boldsymbol{y}, \\boldsymbol{X}) = \\prod_{i=1}^N \\prod_{l=1}^L p_{il}^{y_{il}}, \\] where \\(p_{il} = p(y_{il}^* \\geq 0)\\). Observe that \\(p({y}_{il}^*\\geq 0)=p({\\lambda}_{ll}{y}_{il}^*\\geq 0)\\), \\(\\lambda_{ll}&gt;0\\). This generates identification issues because only the correlation matrix can be identified, similar to the univariate probit model where the variance of the model is fixed to 1. We follow the post-processing strategy proposed by Edwards and Allenby (2003) to obtain identified parameters, that is, \\(\\tilde{\\boldsymbol{\\beta}}=\\text{vec}\\left\\{\\boldsymbol{\\Lambda}\\mathbf{B}\\right\\}\\) and the correlation matrix \\(\\boldsymbol{R}=\\boldsymbol{\\Lambda}\\boldsymbol{\\Sigma}\\boldsymbol{\\Lambda}\\), where \\(\\boldsymbol{\\Lambda}=\\text{diag}\\left\\{\\sigma_{ll}\\right\\}^{-1/2}\\) and \\(\\mathbf{B}=\\left[\\boldsymbol{\\beta}_1 \\ \\boldsymbol{\\beta}_2 \\dots \\boldsymbol{\\beta}_k\\right]\\).43 We assume independent priors: \\(\\boldsymbol{\\beta} \\sim N(\\boldsymbol{\\beta}_0, \\boldsymbol{B}_0)\\) and \\(\\boldsymbol{\\Sigma}^{-1} \\sim W(\\alpha_0, \\boldsymbol{\\Psi}_0)\\). We can apply Gibbs sampling to this model, as it is a standard Bayesian linear regression model when data augmentation in \\(\\boldsymbol{y}^*\\) is used. The posterior conditional distributions are \\[\\begin{equation} \\boldsymbol{\\beta}\\mid \\boldsymbol{\\Sigma},\\boldsymbol{w} \\sim N(\\boldsymbol{\\beta}_n,\\boldsymbol{B}_n), \\end{equation}\\] \\[\\begin{equation} \\boldsymbol{\\Sigma}^{-1} \\mid \\boldsymbol{\\beta},\\boldsymbol{w} \\sim W(\\alpha_n,\\boldsymbol{\\Psi}_n), \\end{equation}\\] \\[\\begin{equation} y_{il}^* \\mid \\boldsymbol{y}_{i,-l}^*,\\boldsymbol{\\beta},\\boldsymbol{\\Sigma}^{-1},\\boldsymbol{y_i} \\sim TN_{I_{il}}(m_{il},\\tau_{ll}^2) \\end{equation}\\] where \\(\\boldsymbol{B}_n=(\\boldsymbol{B}_0^{-1}+\\boldsymbol{X}^{*\\top}\\boldsymbol{X}^*)^{-1}\\), \\(\\boldsymbol{\\beta}_n=\\boldsymbol{B}_n(\\boldsymbol{B}_0^{-1}\\boldsymbol{\\beta}_0+\\boldsymbol{X}^{*\\top}\\boldsymbol{y}^{**})\\), \\(\\boldsymbol{\\Sigma}^{-1}=\\boldsymbol{C}^{\\top}\\boldsymbol{C}\\), \\(\\boldsymbol{X}_i^{*}=\\boldsymbol{C}^{\\top}\\boldsymbol{X}_i\\), \\(\\boldsymbol{y}_i^{**}=\\boldsymbol{C}^{\\top}\\boldsymbol{y}_i^*\\), \\(\\alpha_n=\\alpha_0+N\\), \\(\\boldsymbol{\\Psi}_n=(\\boldsymbol{\\Psi}_0+\\sum_{i=1}^N (\\boldsymbol{y}_i^*-\\boldsymbol{X}_i\\boldsymbol{\\beta})(\\boldsymbol{y}_i^*-\\boldsymbol{X}_i\\boldsymbol{\\beta})^{\\top})^{-1}\\), \\[ m_{il}=\\boldsymbol{x}_{il}^{\\top}\\boldsymbol{\\beta}+\\boldsymbol{f}_l^{\\top}(\\boldsymbol{y}_{i,-l}^*-\\boldsymbol{X}_{i,-l}\\boldsymbol{\\beta}), \\] where \\(\\boldsymbol{y}_{i,-l}^*\\) is an \\(L-1\\) dimensional vector of all components of \\(\\boldsymbol{y}_i^*\\) excluding \\(y_{il}^*\\), \\(\\boldsymbol{x}_{il}^{\\top}\\) is the \\(l\\)-th row of \\(\\boldsymbol{X}_i\\), \\(\\boldsymbol{X}_{i,-l}\\) is \\(\\boldsymbol{X}_{i}\\) after deleting the \\(l\\)-th row, \\[ \\boldsymbol{f}_l^{\\top}=\\boldsymbol{\\omega}_{l,-l}^{\\top}\\boldsymbol{\\Sigma}_{-l,-l}^{-1}, \\] where \\(\\boldsymbol{\\omega}_{l,-l}^{\\top}\\) and \\(\\boldsymbol{\\Sigma}_{-l,-l}\\) are the \\(l\\)-th row of \\(\\boldsymbol{\\Sigma}\\) extracting the \\(l\\)-th element, and the sub-matrix of \\(\\boldsymbol{\\Sigma}\\) extracting the \\(l,l\\) element, and \\[ \\tau_{ll}^2=\\sigma_{l,l}-\\boldsymbol{\\omega}_{l,-l}^{\\top}\\boldsymbol{\\Sigma}_{-l,-l}^{-1}\\boldsymbol{\\omega}_{-l,l}, \\] and \\[ \\boldsymbol{X}^*= \\begin{bmatrix} \\boldsymbol{X}_1^*\\\\ \\boldsymbol{X}_2^*\\\\ \\vdots\\\\ \\boldsymbol{X}_N^* \\end{bmatrix}, \\quad I_{il}= \\begin{Bmatrix} y_{il}^*&gt; 0, &amp; y_{il}=1\\\\ y_{il}^*\\leq 0 , &amp; y_{il}=0 \\end{Bmatrix}, \\quad \\boldsymbol{\\Sigma}= \\begin{bmatrix} \\boldsymbol{\\omega}_1^{\\top} \\\\ \\boldsymbol{\\omega}_2^{\\top} \\\\ \\vdots \\\\ \\boldsymbol{\\omega}_{L}^{\\top} \\end{bmatrix}. \\] The setting in our GUI has the same regressors in each binary decision. However, we can see that the multivariate probit model is similar to a SUR model in latent variables. We ask in Exercise 9 to implement a Gibbs sampling algorithm for a multivariate probit model with different regressors in each equation. Example: Self selection in hospitalization due to a subsidized health care program We use the dataset 7HealthMed.csv, where the dependent variable is \\(y = \\left[\\text{Hosp} \\ \\text{SHI}\\right]^{\\top}\\), with \\(\\text{Hosp} = 1\\) if an individual was hospitalized in the year prior to the survey (0 otherwise), and \\(\\text{SHI} = 1\\) if the individual had subsidized health insurance (0 otherwise). Recall that our application of binary response models aimed to uncover the determinants of hospitalization in Medellín (Colombia), where one of the regressors was a binary indicator of participation in a subsidized health care program (Section 6.3). We can use a bivariate probit model if we suspect there is dependence between the decisions regarding these two variables. A priori, we would expect that being in a subsidized health care program increases the probability of hospitalization ceteris paribus, due to reduced costs for the patient. However, if an individual expects to be hospitalized in the future, and the factors influencing this decision are unobserved by the modeler, a feedback effect may exist from hospitalization to enrollment in the subsidized health care program. We considered seven regressors: a constant, gender (female), age, self-perception of health status (with categories fair, good, and excellent, using bad as the reference category), and the proportion of the individual’s age spent living in their neighborhood. The last variable attempts to account for social capital, which can affect enrollment in the subsidized health insurance program, as the target population is identified by the local government (Ramírez-Hassan and Guerra-Urzola 2021). The dataset includes 12,975 individuals who can “choose” two options: hospitalization and enrollment in the subsidized health insurance regime. The following Algorithm shows how to run a multivariate probit model using our GUI. Algorithm: Multivariate Probit Model Select Multivariate Models on the top panel Select Multivariate Probit model using the left radio button Upload the dataset, selecting first if there is a header in the file, and the kind of separator in the csv file of the dataset (comma, semicolon, or tab). Then, use the Browse button under the Choose File legend Select MCMC iterations, burn-in, and thinning parameters using the Range sliders Write down the number of cross-sectional units in the Number of individuals: n box Write down the number of exogenous variables in the Number of exogenous variables: k box Write down the number of choices in the Number of choices: l box Set the hyperparameters: mean vectors, covariance matrix, degrees of freedom, and the scale matrix. This step is not necessary as by default our GUI uses non-informative priors Click the Go! button Analyze results Download posterior chains and diagnostic plots using the Download Posterior Chains and Download Posterior Graphs buttons We set 20,000 MCMC iterations with a thinning parameter equal to 5. The hyperparameters are \\(\\boldsymbol{\\beta}_0 = \\boldsymbol{0}_{14}\\), \\(\\boldsymbol{B}_0 = 100\\boldsymbol{I}_{14}\\), \\(\\alpha_0 = 4\\), and \\(\\boldsymbol{\\Psi}_0 = 4\\boldsymbol{I}_2\\).44 rm(list = ls()); set.seed(010101) Data &lt;- read.csv(&quot;https://raw.githubusercontent.com/besmarter/BSTApp/refs/heads/master/DataApp/7HealthMed.csv&quot;, sep = &quot;,&quot;, header = TRUE, quote = &quot;&quot;) attach(Data); str(Data) ## The following object is masked from DataUtEst (pos = 3): ## ## id ## The following object is masked from Data (pos = 6): ## ## Age ## The following object is masked from Data (pos = 7): ## ## Age ## The following objects are masked from Data (pos = 8): ## ## Age, Excellent, Fair, Female, Good, id, PTL ## The following objects are masked from mydata: ## ## Age, Excellent, Fair, Female, Good, id, PTL ## The following object is masked from Data (pos = 10): ## ## Age ## The following object is masked from DataUtEst (pos = 14): ## ## id ## &#39;data.frame&#39;: 25950 obs. of 9 variables: ## $ id : int 1 1 2 2 3 3 4 4 5 5 ... ## $ y : int 0 1 0 1 0 1 0 1 0 0 ... ## $ Constant : int 1 1 1 1 1 1 1 1 1 1 ... ## $ Female : int 0 0 1 1 1 1 1 1 0 0 ... ## $ Age : int 7 7 39 39 23 23 15 15 8 8 ... ## $ Fair : int 0 0 0 0 0 0 0 0 0 0 ... ## $ Good : int 1 1 1 1 1 1 1 1 0 0 ... ## $ Excellent: int 0 0 0 0 0 0 0 0 1 1 ... ## $ PTL : num 0.43 0.43 0 0 0 0 0 0 0 0 ... p &lt;- 2; nd &lt;- 7; N &lt;- length(y)/p; y &lt;- y Xd &lt;- as.matrix(Data[seq(1, p*N, 2),3:9]) XcreateMP&lt;-function(p,nxs,nind,Data){ pandterm = function(message) { stop(message, call. = FALSE) } if (missing(nxs)) pandterm(&quot;requires number of regressors: include intercept if required&quot;) if (missing(nind)) pandterm(&quot;requires number of units (individuals)&quot;) if (missing(Data)) pandterm(&quot;requires dataset&quot;) if (nrow(Data)!=nind*2) pandterm(&quot;check dataset! number of units times number alternatives should be equal to dataset rows&quot;) XXDat&lt;-array(0,c(p,1+nxs,nind)) XX&lt;-array(0,c(p,nxs*p,nind)) YY&lt;-array(0,c(p,1,nind)) is&lt;- seq(p,nind*p,p) cis&lt;- seq(nxs,nxs*p+1,nxs) for(i in is){ j&lt;-which(i==is) XXDat[,,j]&lt;-as.matrix(Data[c((i-(p-1)):i),-1]) YY[,,j]&lt;-XXDat[,1,j] for(l in 1:p){ XX[l,((cis[l]-(nxs-1)):cis[l]),j]&lt;-XXDat[l,-1,j] } } return(list(y=YY,X=XX)) } Dat &lt;- XcreateMP(p = p, nxs = nd, nind = N, Data = Data) y&lt;-NULL; X&lt;-NULL for(i in 1:dim(Dat$y)[3]){ y&lt;-c(y,Dat$y[,,i]) X&lt;-rbind(X,Dat$X[,,i]) } DataMP = list(p=p, y=y, X=X) # Hyperparameters k &lt;- dim(X)[2]; b0 &lt;- rep(0, k); c0 &lt;- 1000 B0 &lt;- c0*diag(k); B0i &lt;- solve(B0) a0 &lt;- p - 1 + 3; Psi0 &lt;- a0*diag(p) Prior &lt;- list(betabar = b0, A = B0i, nu = a0, V = Psi0) # MCMC parameters mcmc &lt;- 20000; thin &lt;- 5; Mcmc &lt;- list(R = mcmc, keep = thin, nprint = 0) Results &lt;- bayesm::rmvpGibbs(Data = DataMP, Mcmc = Mcmc, Prior = Prior) ## Table of y values ## y ## 0 1 ## 15653 10297 ## ## Starting Gibbs Sampler for MVP ## 12975 obs of 2 binary indicators; 14 indep vars (including intercepts) ## ## Prior Parms: ## betabar ## [1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## A ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] ## [1,] 0.001 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 ## [2,] 0.000 0.001 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 ## [3,] 0.000 0.000 0.001 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 ## [4,] 0.000 0.000 0.000 0.001 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 ## [5,] 0.000 0.000 0.000 0.000 0.001 0.000 0.000 0.000 0.000 0.000 0.000 0.000 ## [6,] 0.000 0.000 0.000 0.000 0.000 0.001 0.000 0.000 0.000 0.000 0.000 0.000 ## [7,] 0.000 0.000 0.000 0.000 0.000 0.000 0.001 0.000 0.000 0.000 0.000 0.000 ## [8,] 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.001 0.000 0.000 0.000 0.000 ## [9,] 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.001 0.000 0.000 0.000 ## [10,] 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.001 0.000 0.000 ## [11,] 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.001 0.000 ## [12,] 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.001 ## [13,] 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 ## [14,] 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 ## [,13] [,14] ## [1,] 0.000 0.000 ## [2,] 0.000 0.000 ## [3,] 0.000 0.000 ## [4,] 0.000 0.000 ## [5,] 0.000 0.000 ## [6,] 0.000 0.000 ## [7,] 0.000 0.000 ## [8,] 0.000 0.000 ## [9,] 0.000 0.000 ## [10,] 0.000 0.000 ## [11,] 0.000 0.000 ## [12,] 0.000 0.000 ## [13,] 0.001 0.000 ## [14,] 0.000 0.001 ## nu ## [1] 4 ## V ## [,1] [,2] ## [1,] 4 0 ## [2,] 0 4 ## ## MCMC Parms: ## 20000 reps; keeping every 5 th draw nprint= 0 ## initial beta= 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## initial sigma= ## [,1] [,2] ## [1,] 1 0 ## [2,] 0 1 ## betatilde1 &lt;- Results$betadraw[,1:7] / sqrt(Results$sigmadraw[,1]) summary(coda::mcmc(betatilde1)) ## ## Iterations = 1:4000 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 4000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## [1,] -0.973678 0.12756 0.0020170 2.414e-03 ## [2,] 0.122745 0.04872 0.0007704 1.326e-03 ## [3,] 0.002941 0.00110 0.0000174 2.577e-05 ## [4,] -0.522298 0.11435 0.0018080 1.781e-03 ## [5,] -1.234641 0.11131 0.0017599 1.859e-03 ## [6,] -1.093871 0.13165 0.0020816 2.591e-03 ## [7,] -0.064123 0.05942 0.0009395 1.619e-03 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## var1 -1.2247602 -1.059257 -0.970870 -0.889741 -0.733411 ## var2 0.0269885 0.090098 0.121863 0.155585 0.220662 ## var3 0.0007652 0.002207 0.002925 0.003685 0.005049 ## var4 -0.7477149 -0.598898 -0.522549 -0.445173 -0.296718 ## var5 -1.4520842 -1.309922 -1.234633 -1.160468 -1.018396 ## var6 -1.3503717 -1.182381 -1.092511 -1.005472 -0.837939 ## var7 -0.1791758 -0.103506 -0.064418 -0.024499 0.051849 betatilde2 &lt;- Results$betadraw[,8:14] / sqrt(Results$sigmadraw[,4]) summary(coda::mcmc(betatilde2)) ## ## Iterations = 1:4000 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 4000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## [1,] 0.567199 0.1346170 2.128e-03 2.409e-03 ## [2,] 0.306014 0.0242202 3.830e-04 3.672e-04 ## [3,] 0.009125 0.0006758 1.068e-05 1.109e-05 ## [4,] -0.221882 0.1347631 2.131e-03 2.447e-03 ## [5,] -0.421087 0.1307593 2.067e-03 2.364e-03 ## [6,] -0.435578 0.1370951 2.168e-03 2.449e-03 ## [7,] 0.224500 0.0304865 4.820e-04 4.829e-04 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## var1 0.306343 0.477265 0.564698 0.656616 0.82932 ## var2 0.258347 0.289819 0.305902 0.322116 0.35284 ## var3 0.007848 0.008656 0.009124 0.009591 0.01045 ## var4 -0.488810 -0.313532 -0.218459 -0.130373 0.04144 ## var5 -0.677686 -0.511529 -0.418139 -0.332415 -0.17322 ## var6 -0.703355 -0.527642 -0.433378 -0.341355 -0.16989 ## var7 0.164388 0.203623 0.224533 0.245306 0.28513 sigmadraw12 &lt;- Results$sigmadraw[,3] / (Results$sigmadraw[,1]*Results$sigmadraw[,4])^0.5 summary(coda::mcmc(sigmadraw12)) ## ## Iterations = 1:4000 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 4000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## -0.003338 0.033076 0.000523 0.001288 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## -0.070515 -0.025009 -0.002895 0.018432 0.060986 The previous R code demonstrates how to obtain the posterior draws using the rmvpGibbs command from the bayesm package. The results suggest that females, older individuals, and those who self-assess their health as poor are more likely to be hospitalized. Furthermore, females, older individuals, and those with a poor or fair self-perception of health, who have lived a larger proportion of their life in their current neighborhood, are more likely to be enrolled in the subsidized health care system. However, the results indicate that there is no unobserved correlation between the two equations, as the 95% credible interval for the correlation is (-0.07, 0.06). References "],["sec75.html", "7.5 Summary", " 7.5 Summary In this chapter, we present the setting and posterior distributions of the most common multivariate models. The multivariate framework allows us to address endogeneity issues by using the conditional distribution of a multivariate normal vector. Moreover, we always obtain posterior conditional distributions that belong to standard families (multivariate normal, Wishart, and truncated normal) in these models. This property enables the implementation of the Gibbs sampling algorithm for all these models. "],["sec76.html", "7.6 Exercises", " 7.6 Exercises Show that \\(\\mathbb{E}[u_1\\text{PAER}] = \\frac{\\alpha_1}{1 - \\beta_1\\alpha_1} \\sigma_1^2\\), assuming that \\(\\mathbb{E}[u_1 u_2] = 0\\), where \\(\\text{Var}(u_1) = \\sigma_1^2\\), in the example of the effect of institutions on per capita GDP. Show that \\(\\beta_1=\\pi_1/\\gamma_1\\), in the example of the effect of institutions on per capita GDP. The effect of institutions on per capita gross domestic product continues I Use the rmultireg command from the bayesm package to perform inference in the example of the effect of institutions on per capita GDP. Demand and supply simulation Given the structural demand-supply model: \\[ \\begin{aligned} q_i^d &amp;= \\beta_1 + \\beta_2 p_i + \\beta_3 y_i + \\beta_4 pc_i + \\beta_5 ps_i + u_{i1}, \\\\ q_i^s &amp;= \\alpha_1 + \\alpha_2 p_i + \\alpha_3 er_i + u_{i2}, \\end{aligned} \\] where \\(q^d\\) is demand, \\(q^s\\) is supply, \\(p\\), \\(y\\), \\(pc\\), \\(ps\\), and \\(er\\) are price, income, complementary price, substitute price, and exchange rate, respectively. Complementary and substitute prices refer to the prices of complementary and substitute goods for \\(q\\). Assume that \\[ \\boldsymbol{\\beta} = \\begin{bmatrix} 5 \\\\ -0.5 \\\\ 0.8 \\\\ -0.4 \\\\ 0.7 \\end{bmatrix}, \\quad \\boldsymbol{\\alpha} = \\begin{bmatrix} -2 \\\\ 0.5 \\\\ -0.4 \\end{bmatrix}, \\] \\(u_1 \\sim N(0, 0.5^2)\\), and \\(u_2 \\sim N(0, 0.5^2)\\). Additionally, assume that \\(y \\sim N(10, 1)\\), \\(pc \\sim N(5, 1)\\), \\(ps \\sim N(5, 1)\\), and \\(er \\sim N(15, 1)\\). Find the reduced-form model by using the condition that in equilibrium, demand and supply are equal, i.e., \\(q^d = q^s\\). This condition defines the observable quantity, \\(q\\). Simulate \\(p\\) and \\(q\\) from the reduced-form equations. Perform inference for the reduced-form model using the rmultireg command from the bayesm package. Use the posterior draws of the reduced-form parameters to perform inference for the structural parameters. Any issues? Hint: Are all structural parameters exactly identified? Utility demand continues Run the Utility demand application using our GUI and the information in the dataset Utilities.csv. Hint: This file should be modified to agree with the structure that our GUI requires (see the dataset 5Institutions.csv in the folder DataApp of our GitHub repository - https://github.com/besmarter/BSTApp - for a template). Program from scratch the Gibbs sampler algorithm in this application. Simulation exercise of instrumental variables continues I Use the setting of the simulation exercise with instrumental variables to analyze the impact of a weak instrument. For instance, set \\(\\gamma_2 = 0.2\\) and compare the performance of the posterior means of the ordinary and instrumental variable models. Perform a simulation to analyze how the degree of exogeneity of the instrument affects the performance of the posterior mean in the instrumental variable model. Simulation exercise of instrumental variables continues II Program from scratch the Gibbs sampling algorithm of the instrumental model for the simulation exercise of the instrumental variables. The effect of institutions on per capita gross domestic product continues II Estimate the structural Equation (7.1) using the instrumental variable model where the instrument of PAER is \\(\\log(\\textit{Mort})\\). Compare the effect of property rights on per capita GDP of this model with the effect estimated in the example of the effect of institutions on per capita gross domestic product. Use the file 6Institutions.csv to do this exercise in our GUI, and set \\[ \\boldsymbol{B}_0=100\\boldsymbol{I}_5, \\quad \\boldsymbol{\\beta}_0=\\boldsymbol{0}_5, \\quad \\boldsymbol{\\gamma}_0=\\boldsymbol{0}_2, \\quad \\boldsymbol{G}_0=100\\boldsymbol{I}_2, \\quad \\alpha_0=3, \\quad \\boldsymbol{\\Psi}_0=3\\boldsymbol{I}_2. \\] The MCMC iterations, burn-in, and thinning parameters are 50000, 1000, and 5, respectively. Multivariate probit with different regressors Let’s do a simulation exercise where \\[ \\begin{aligned} y_{i1}^* &amp;= 0.5 - 1.2x_{i11} + 0.7x_{i12} + 0.8x_{i3} + \\mu_{i1}, \\\\ y_{i2}^* &amp;= 1.5 - 0.8x_{i21} + 0.5x_{i22} + \\mu_{i2}, \\end{aligned} \\] with \\[ \\boldsymbol{\\Sigma}= \\begin{bmatrix} 1 &amp; 0.5 \\\\ 0.5 &amp; 1 \\end{bmatrix}, \\] where all regressors follow a standard normal distribution, and \\(N=5000\\). Use \\[ \\boldsymbol{\\beta}_0=\\boldsymbol{0}, \\quad \\boldsymbol{B}_0=1000\\boldsymbol{B}, \\quad \\alpha_0=4, \\quad \\boldsymbol{\\Psi}_0=4\\boldsymbol{I}_2. \\] Set the number of iterations to 2000 and a thinning parameter equal to 5. Perform inference using the setting of Section 7.4, that is, assuming that \\(x_{i3}\\) could have an effect on \\(y_{i2}\\). Program a Gibbs sampling algorithm taking into account that there are different regressors in each binary decision, that is, \\(x_{i3}\\) does not have an effect on \\(y_{i2}\\). "],["Chap8.html", "Chapter 8 Time series", " Chapter 8 Time series In this chapter, we provide a brief introduction to performing inference in time series models using a Bayesian framework. There is a large literature on time series in statistics and econometrics, making it impossible to present a thorough treatment in just a few pages of an introductory book. However, there are excellent books on Bayesian inference in time series; see, for instance, West and Harrison (2006), Petris, Petrone, and Campagnoli (2009), and Pole, West, and Harrison (2018). A time series is a sequence of observations collected in chronological order, allowing us to track how variables change over time. However, it also introduces technical challenges, as we must account for statistical features such as autocorrelation and stationarity. Since time series data is time-dependent, we adjust our notation. Specifically, we use \\(t\\) and \\(T\\) instead of \\(i\\) and \\(N\\) to explicitly indicate time. Our starting point in this chapter is the state-space representation of time series models. Much of the Bayesian inference literature in time series adopts this approach, as it allows dynamic systems to be modeled in a structured way. This representation provides modularity, flexibility, efficiency, and interpretability in complex models where the state evolves over time. It also enables the use of recursive estimation methods, such as the Kalman filter for dynamic Gaussian linear models and the particle filter (also known as sequential Monte Carlo) for non-Gaussian and nonlinear state-space models. The latter method is especially useful for online predictions or when there are data storage limitations. These inferential tools are based on the sequential updating process of Bayes’ rule, where the posterior at time \\(t\\) becomes the prior at time \\(t+1\\). Remember that we can run our GUI typing shiny::runGitHub(\"besmarter/BSTApp\", launch.browser=T) in the R console or any R code editor and execute it. However, users should see Chapter 5 for details. References "],["sec81.html", "8.1 State-space representation", " 8.1 State-space representation A state-space model consists of an unobservable state vector \\(\\boldsymbol{\\beta}_t \\in \\mathbb{R}^K\\) and an observed measure \\(\\boldsymbol{Y}_t \\in \\mathbb{R}^M\\), for \\(t=1,2,\\dots\\). These components satisfy two key properties: (i) \\(\\boldsymbol{\\beta}_t\\) follows a Markov process, meaning that \\(\\pi(\\boldsymbol{\\beta}_t\\mid \\boldsymbol{\\beta}_{1:t-1})=\\pi(\\boldsymbol{\\beta}_t\\mid \\boldsymbol{\\beta}_{t-1})\\). In other words, all information about \\(\\boldsymbol{\\beta}_t\\) is carried by \\(\\boldsymbol{\\beta}_{t-1}\\), and (ii) \\(\\boldsymbol{Y}_t\\) is independent of \\(\\boldsymbol{Y}_s\\) given \\(\\boldsymbol{\\beta}_t\\) for all \\(s &lt; t\\) (Petris, Petrone, and Campagnoli 2009, chap. 2). These assumptions imply that \\[ \\pi(\\boldsymbol{\\beta}_{0:t},\\boldsymbol{Y}_{1:t})=\\pi(\\boldsymbol{\\beta}_0)\\prod_{s=1}^{t}\\pi(\\boldsymbol{\\beta}_s\\mid \\boldsymbol{\\beta}_{s-1})\\pi(\\boldsymbol{Y}_s\\mid \\boldsymbol{\\beta}_s). \\] A state-space model where the states are discrete random variables is called a hidden Markov model. There are three key aims in state-space models: filtering, smoothing, and forecasting. - In filtering, we estimate the current state given observations up to time \\(t\\), obtaining the density \\(\\pi(\\boldsymbol{\\beta}_{s}\\mid \\boldsymbol{y}_{1:t})\\) for \\(s = t\\). - In smoothing, we analyze past states, obtaining \\(\\pi(\\boldsymbol{\\beta}_{s}\\mid \\boldsymbol{y}_{1:t})\\) for \\(s &lt; t\\). - In forecasting, we predict future observations by first computing \\(\\pi(\\boldsymbol{\\beta}_{s}\\mid \\boldsymbol{y}_{1:t})\\) as an intermediate step to obtain \\(\\pi(\\boldsymbol{Y}_{s}\\mid \\boldsymbol{y}_{1:t})\\) for \\(s &gt; t\\). A key advantage of these methods is that all these densities can be calculated recursively. Petris, Petrone, and Campagnoli (2009) provide the recursive equations in Propositions 2.1 (filtering), 2.3 (smoothing), and 2.5 (forecasting). 8.1.1 Gaussian linear state-space models An important class of state-space models is the Gaussian linear state-space model, also known as a dynamic linear model: \\[\\begin{align} \\boldsymbol{Y}_t &amp;= \\boldsymbol{X}_t\\boldsymbol{\\beta}_t+\\boldsymbol{\\mu}_t &amp; \\text{(Observation equations)} \\\\ \\boldsymbol{\\beta}_t &amp;= \\boldsymbol{G}_t\\boldsymbol{\\beta}_{t-1}+\\boldsymbol{w}_t &amp; \\text{(State equations)} \\end{align}\\] where \\(\\boldsymbol{\\beta}_0\\sim N(\\boldsymbol{b}_0,\\boldsymbol{B}_0)\\), \\(\\boldsymbol{\\mu}_t\\sim N(\\boldsymbol{0}, \\boldsymbol{\\Sigma}_t)\\), and \\(\\boldsymbol{w}_t\\sim N(\\boldsymbol{0}, \\boldsymbol{\\Omega}_t)\\). The terms \\(\\boldsymbol{\\beta}_0\\), \\(\\boldsymbol{\\mu}_t\\), and \\(\\boldsymbol{w}_t\\) are independent, while \\(\\boldsymbol{X}_t\\) and \\(\\boldsymbol{G}_t\\) are known matrices of dimensions \\(M\\times K\\) and \\(K\\times K\\), respectively. These assumptions imply that \\[ \\boldsymbol{Y}_t\\mid \\boldsymbol{\\beta}_t \\sim N(\\boldsymbol{X}_t\\boldsymbol{\\beta}_t, \\boldsymbol{\\Sigma}_t), \\quad \\boldsymbol{\\beta}_t\\mid \\boldsymbol{\\beta}_{t-1} \\sim N(\\boldsymbol{G}_t\\boldsymbol{\\beta}_{t-1}, \\boldsymbol{\\Omega}_t). \\] A general state-space model is defined as \\(\\boldsymbol{Y}_t = \\boldsymbol{f}_t(\\boldsymbol{\\beta}_t, \\boldsymbol{\\mu}_t)\\) and \\(\\boldsymbol{\\beta}_t = \\boldsymbol{m}_t(\\boldsymbol{\\beta}_{t-1}, \\boldsymbol{w}_t)\\), where \\(\\boldsymbol{f}_t\\) and \\(\\boldsymbol{m}_t\\) are arbitrary functions with corresponding distributions for \\(\\boldsymbol{\\mu}_t\\) and \\(\\boldsymbol{w}_t\\), and a prior for \\(\\boldsymbol{\\beta}_0\\). Let \\(\\boldsymbol{\\beta}_{t-1}\\mid \\boldsymbol{y}_{1:t-1}\\sim N(\\boldsymbol{b}_{t-1},\\boldsymbol{B}_{t-1})\\), then, we can get the Kalman filter by obtaining: The one-step-ahead predictive distribution of \\(\\boldsymbol{\\beta}_t\\) given \\(\\boldsymbol{y}_{1:t-1}\\) is \\(\\boldsymbol{\\beta}_t\\mid \\boldsymbol{y}_{1:t-1}\\sim N(\\boldsymbol{a}_t, \\boldsymbol{R}_t)\\), where \\[\\boldsymbol{a}_t=\\boldsymbol{G}_t\\boldsymbol{b}_{t-1}, \\quad \\boldsymbol{R}_t=\\boldsymbol{G}_t\\boldsymbol{B}_{t-1}\\boldsymbol{G}_t^{\\top}+\\boldsymbol{\\Omega}_t.\\] The one-step-ahead predictive distribution of \\(\\boldsymbol{Y}_t\\) given \\(\\boldsymbol{y}_{1:t-1}\\) is \\(\\boldsymbol{Y}_t\\mid \\boldsymbol{y}_{1:t-1}\\sim N(\\boldsymbol{f}_t, \\boldsymbol{Q}_t)\\), where \\[\\boldsymbol{f}_t=\\boldsymbol{X}_t\\boldsymbol{a}_t, \\quad \\boldsymbol{Q}_t=\\boldsymbol{X}_t\\boldsymbol{R}_t\\boldsymbol{X}_t^{\\top}+\\boldsymbol{\\Sigma}_t.\\] The distribution of the one-step-ahead prediction error \\(\\boldsymbol{e}_t=\\boldsymbol{Y}_t-\\mathbb{E}[\\boldsymbol{Y}_t\\mid \\boldsymbol{y}_{1:t-1}]=\\boldsymbol{Y}_t-\\boldsymbol{f}_t\\) is \\(N(\\boldsymbol{0}, \\boldsymbol{Q}_t)\\) Shumway and Stoffer (2017), Chap. 6. The filtering distribution of \\(\\boldsymbol{\\beta}_t\\) given \\(\\boldsymbol{y}_{1:t}\\) is \\(\\boldsymbol{\\beta}_t\\mid \\boldsymbol{y}_{1:t}\\sim N(\\boldsymbol{b}_t, \\boldsymbol{B}_t)\\), where \\[\\boldsymbol{b}_t=\\boldsymbol{a}_t+\\boldsymbol{K}_t\\boldsymbol{e}_t, \\quad \\boldsymbol{K}_t=\\boldsymbol{R}_t\\boldsymbol{X}_t^{\\top}\\boldsymbol{Q}_t^{-1}\\] is the Kalman gain, and \\[\\boldsymbol{B}_t=\\boldsymbol{R}_t-\\boldsymbol{R}_t\\boldsymbol{X}_t^{\\top}\\boldsymbol{Q}_t^{-1}\\boldsymbol{X}_t\\boldsymbol{R}_t.\\] The formal proofs of these results can be found in Petris, Petrone, and Campagnoli (2009), Chap. 2. Just take into account that the logic of these results follows the Seemingly Unrelated Regression (SUR) model in 7.2 for a particular time period. In addition, we know that the posterior distribution using information up to \\(t-1\\) becomes the prior in \\(t\\), \\[\\pi(\\boldsymbol{\\theta}\\mid \\mathbf{y}_{1:t})\\propto p(y_{t}\\mid \\boldsymbol{y}_{1:t-1},\\boldsymbol{\\theta})\\times \\pi(\\boldsymbol{\\theta}\\mid \\boldsymbol{y}_{1:t-1}).\\] This is the updating process from \\(\\boldsymbol{\\beta}_t\\mid \\boldsymbol{y}_{1:t-1}\\sim N(\\boldsymbol{a}_t, \\boldsymbol{R}_t)\\) to \\(\\boldsymbol{\\beta}_t\\mid \\boldsymbol{y}_{1:t}\\sim N(\\boldsymbol{b}_t, \\boldsymbol{B}_t)\\). Moreover, the posterior mean and variance of the SUR model with independent conjugate priors for a particular time period can be written as \\[\\boldsymbol{a}_{t}+\\boldsymbol{R}_{t}\\boldsymbol{X}_t^{\\top}(\\boldsymbol{X}_t\\boldsymbol{R}_{t}\\boldsymbol{X}_t^{\\top}+ \\boldsymbol{\\Sigma}_t)^{-1}(\\boldsymbol{y}_t-\\boldsymbol{X}_t\\boldsymbol{a}_{t})\\] and \\[\\boldsymbol{R}_{t}-\\boldsymbol{R}_{t}\\boldsymbol{X}_t^{\\top}(\\boldsymbol{X}_t\\boldsymbol{R}_{t}\\boldsymbol{X}_t^{\\top}+\\boldsymbol{\\Sigma}_t)^{-1} \\boldsymbol{X}_t\\boldsymbol{R}_{t}^{\\top},\\] respectively. Let’s see this, we know from 7.2 that \\[\\boldsymbol{B}_t=(\\boldsymbol{R}_t^{-1}+\\boldsymbol{X}_t^{\\top}\\boldsymbol{\\Sigma}^{-1}\\boldsymbol{X}_t)^{-1}\\] and \\[\\boldsymbol{\\beta}_t=\\boldsymbol{B}_t(\\boldsymbol{R}_t^{-1}\\boldsymbol{a}_t+\\boldsymbol{X}_t^{\\top}\\boldsymbol{\\Sigma}^{-1}\\boldsymbol{y}_t).\\] Thus, let’s show that both conditional posterior distributions are the same. In particular, the posterior mean in the state-space representation is \\[[\\boldsymbol{I}_K-\\boldsymbol{R}_{t}\\boldsymbol{X}_t^{\\top}(\\boldsymbol{X}_t\\boldsymbol{R}_{t}\\boldsymbol{X}_t^{\\top}+ \\boldsymbol{\\Sigma}_t)^{-1}\\boldsymbol{X}_t]\\boldsymbol{a}_{t}+\\boldsymbol{R}_{t}\\boldsymbol{X}_t^{\\top}(\\boldsymbol{X}_t\\boldsymbol{R}_{t}\\boldsymbol{X}_t^{\\top}+ \\boldsymbol{\\Sigma}_t)^{-1}\\boldsymbol{y}_t,\\] where \\[\\begin{align*} \\boldsymbol{R}_{t}\\boldsymbol{X}_t^{\\top}(\\boldsymbol{X}_t\\boldsymbol{R}_{t}\\boldsymbol{X}_t^{\\top}+ \\boldsymbol{\\Sigma}_t)^{-1} &amp;=\\boldsymbol{R}_{t}\\boldsymbol{X}_t^{\\top}[\\boldsymbol{\\Sigma}_t^{-1}-\\boldsymbol{\\Sigma}_t^{-1}\\boldsymbol{X}_t(\\boldsymbol{R}_t^{-1}+\\boldsymbol{X}_t^{\\top}\\boldsymbol{\\Sigma}_t^{-1}\\boldsymbol{X}_t)^{-1}\\boldsymbol{X}_t^{\\top}\\boldsymbol{\\Sigma}_t^{-1}]\\\\ &amp;=\\boldsymbol{R}_{t}[\\boldsymbol{I}_K-\\boldsymbol{X}_t^{\\top}\\boldsymbol{\\Sigma}_t^{-1}\\boldsymbol{X}_t(\\boldsymbol{R}_t^{-1}+\\boldsymbol{X}_t^{\\top}\\boldsymbol{\\Sigma}_t^{-1}\\boldsymbol{X}_t)^{-1}]\\boldsymbol{X}_t^{\\top}\\boldsymbol{\\Sigma}_t^{-1}\\\\ &amp;=\\boldsymbol{R}_{t}(\\boldsymbol{I}_K-[\\boldsymbol{I}_K-\\boldsymbol{R}_t^{-1}(\\boldsymbol{R}_t^{-1}+\\boldsymbol{X}_t^{\\top}\\boldsymbol{\\Sigma}_t^{-1}\\boldsymbol{X}_t)^{-1}])\\boldsymbol{X}_t^{\\top}\\boldsymbol{\\Sigma}_t^{-1}\\\\ &amp;=(\\boldsymbol{R}_t^{-1}+\\boldsymbol{X}_t^{\\top}\\boldsymbol{\\Sigma}_t^{-1}\\boldsymbol{X}_t)^{-1}\\boldsymbol{X}_t^{\\top}\\boldsymbol{\\Sigma}_t^{-1}, \\end{align*}\\] where the first equality uses the Woodbury matrix identity (matrix inversion lemma), and the third equality uses \\(\\boldsymbol{D}(\\boldsymbol{D}+\\boldsymbol{E})^{-1}=\\boldsymbol{I}-\\boldsymbol{E}(\\boldsymbol{D}+\\boldsymbol{E})^{-1}\\). Thus, we have the following expression: \\[\\begin{align*} &amp;[\\mathbf{I}_K - \\mathbf{R}_t \\mathbf{X}_t^{\\top} (\\mathbf{X}_t \\mathbf{R}_t \\mathbf{X}_t^{\\top} + \\boldsymbol{\\Sigma}_t)^{-1} \\mathbf{X}_t] \\mathbf{a}_t + \\mathbf{R}_t \\mathbf{X}_t^{\\top} (\\mathbf{X}_t \\mathbf{R}_t \\mathbf{X}_t^{\\top} + \\boldsymbol{\\Sigma}_t)^{-1} \\mathbf{y}_t \\\\ &amp;= [\\mathbf{I}_K - (\\mathbf{R}_t^{-1} + \\mathbf{X}_t^{\\top} \\boldsymbol{\\Sigma}_t^{-1} \\mathbf{X}_t)^{-1} \\mathbf{X}_t^{\\top} \\boldsymbol{\\Sigma}_t^{-1} \\mathbf{X}_t] \\mathbf{a}_t + (\\mathbf{R}_t^{-1} + \\mathbf{X}_t^{\\top} \\boldsymbol{\\Sigma}_t^{-1} \\mathbf{X}_t)^{-1} \\mathbf{X}_t^{\\top} \\boldsymbol{\\Sigma}_t^{-1} \\mathbf{y}_t \\\\ &amp;= (\\mathbf{R}_t^{-1} + \\mathbf{X}_t^{\\top} \\boldsymbol{\\Sigma}_t^{-1} \\mathbf{X}_t)^{-1} \\mathbf{R}_t^{-1} \\mathbf{a}_t + (\\mathbf{R}_t^{-1} + \\mathbf{X}_t^{\\top} \\boldsymbol{\\Sigma}_t^{-1} \\mathbf{X}_t)^{-1} \\mathbf{X}_t^{\\top} \\boldsymbol{\\Sigma}_t^{-1} \\mathbf{y}_t \\\\ &amp;= (\\mathbf{R}_t^{-1} + \\mathbf{X}_t^{\\top} \\boldsymbol{\\Sigma}_t^{-1} \\mathbf{X}_t)^{-1} (\\mathbf{R}_t^{-1} \\mathbf{a}_t + \\mathbf{X}_t^{\\top} \\boldsymbol{\\Sigma}_t^{-1} \\mathbf{y}_t) \\\\ &amp;= (\\mathbf{R}_t^{-1} + \\mathbf{X}_t^{\\top} \\boldsymbol{\\Sigma}_t^{-1} \\mathbf{X}_t)^{-1} (\\mathbf{R}_t^{-1} \\mathbf{a}_t + \\mathbf{X}_t^{\\top} \\boldsymbol{\\Sigma}_t^{-1} \\mathbf{X}_t \\hat{\\boldsymbol{\\beta}}_t), \\end{align*}\\] where the second equality uses the identity: \\[ \\boldsymbol{I} - (\\boldsymbol{D} + \\boldsymbol{E})^{-1} \\boldsymbol{D} = (\\boldsymbol{D} + \\boldsymbol{E})^{-1} \\boldsymbol{E}, \\] and the estimator \\(\\hat{\\boldsymbol{\\beta}}_t\\) is defined as: \\[ \\hat{\\boldsymbol{\\beta}}_t = (\\boldsymbol{X}_t^{\\top} \\boldsymbol{\\Sigma}_t^{-1} \\boldsymbol{X}_t)^{-1} \\boldsymbol{X}_t^{\\top} \\boldsymbol{\\Sigma}_t^{-1} \\boldsymbol{y}_t. \\] This shows that the posterior mean is a weighted average of the prior mean and the maximum likelihood estimator (which is the generalized least squares estimator). The weights are linked to the signal-to-noise ratio, that is, the proportion of the total variability (\\(\\boldsymbol{\\Omega}_t+\\boldsymbol{\\Sigma}_t\\)) due to the signal (\\(\\boldsymbol{\\Omega}_t\\)) versus the noise (\\(\\boldsymbol{\\Sigma}_t\\)). Note that in the simplest case where \\(M=K=1\\), and \\(\\boldsymbol{X}_t=\\boldsymbol{G}_t=1\\), then \\(\\boldsymbol{K}_t=\\boldsymbol{R}_t\\boldsymbol{Q}_t^{-1}=(B_{t-1}+\\Omega_t)/(B_{t-1}+\\Omega_t+\\Sigma_t)\\). Thus, the weight associated with the observations is equal to 1 if \\(\\Sigma_t=0\\), that is, the posterior mean is equal to the actual observation. On the other hand, if \\(\\Sigma_t\\) increases compare to \\(\\Omega_t\\), there is more weight to the prior information, and consequently, the posterior mean is smoother as it heavily dependents on the history. We ask in Exercise 1 to perform simulations with different signal-to-noise ratios to see the effects on the system. The equality of variances of both approaches is as follows: \\[\\begin{align*} Var[\\boldsymbol{\\beta}_t\\mid \\boldsymbol{y}_{1:t}]&amp; = \\boldsymbol{R}_{t}-\\boldsymbol{R}_{t}\\boldsymbol{X}_t^{\\top}(\\boldsymbol{X}_t\\boldsymbol{R}_{t}\\boldsymbol{X}_t^\\top+\\boldsymbol{\\Sigma}_t)^{-1} \\boldsymbol{X}_t\\boldsymbol{R}_{t}\\\\ &amp;=\\boldsymbol{R}_{t}-\\boldsymbol{R}_{t}\\boldsymbol{X}_t^{\\top}(\\boldsymbol{\\Sigma}_t^{-1}- \\boldsymbol{\\Sigma}_t^{-1}\\boldsymbol{X}_t(\\boldsymbol{R}_{t}^{-1}+\\boldsymbol{X}_t^{\\top}\\boldsymbol{\\Sigma}_t^{-1}\\boldsymbol{X}_t)^{-1}\\boldsymbol{X}_t^{\\top}\\boldsymbol{\\Sigma}_t^{-1})\\boldsymbol{X}_t\\boldsymbol{R}_{t}\\\\ &amp;=\\boldsymbol{R}_{t}-\\boldsymbol{R}_{t}\\boldsymbol{X}_t^{\\top}\\boldsymbol{\\Sigma}_t^{-1}\\boldsymbol{X}_t\\boldsymbol{R}_{t}+ \\boldsymbol{R}_{t}\\boldsymbol{X}_t^{\\top}\\boldsymbol{\\Sigma}_t^{-1}\\boldsymbol{X}_t(\\boldsymbol{R}_{t}^{-1}+\\boldsymbol{X}_t^{\\top}\\boldsymbol{\\Sigma}_t^{-1}\\boldsymbol{X}_t)^{-1}\\boldsymbol{X}_t^{\\top}\\boldsymbol{\\Sigma}_t^{-1}\\boldsymbol{X}_t\\boldsymbol{R}_{t}\\\\ &amp;=\\boldsymbol{R}_{t}-\\boldsymbol{R}_{t}\\boldsymbol{X}_t^{\\top}\\boldsymbol{\\Sigma}_t^{-1}\\boldsymbol{X}_t\\boldsymbol{R}_{t}+ \\boldsymbol{R}_{t}\\boldsymbol{X}_t^{\\top}\\boldsymbol{\\Sigma}_t^{-1}\\boldsymbol{X}_t[\\boldsymbol{I}_K-(\\boldsymbol{R}_{t}^{-1}+\\boldsymbol{X}_t^{\\top}\\boldsymbol{\\Sigma}_t^{-1}\\boldsymbol{X}_t)^{-1}\\boldsymbol{R}_{t}^{-1}]\\boldsymbol{R}_{t}\\\\ &amp;=\\boldsymbol{R}_{t}-\\boldsymbol{R}_{t}\\boldsymbol{X}_t^{\\top}\\boldsymbol{\\Sigma}_t^{-1}\\boldsymbol{X}_t(\\boldsymbol{R}_{t}^{-1}+\\boldsymbol{X}_t^{\\top}\\boldsymbol{\\Sigma}_t^{-1}\\boldsymbol{X}_t)^{-1}\\\\ &amp;=\\boldsymbol{R}_t[\\boldsymbol{I}_K-\\boldsymbol{X}_t^{\\top}\\boldsymbol{\\Sigma}_t^{-1}\\boldsymbol{X}_t(\\boldsymbol{R}_{t}^{-1}+\\boldsymbol{X}_t^{\\top}\\boldsymbol{\\Sigma}_t^{-1}\\boldsymbol{X}_t)^{-1}]\\\\ &amp;=\\boldsymbol{R}_{t}[\\boldsymbol{I}_K-(\\boldsymbol{I}_K-\\boldsymbol{R}_{t}^{-1}(\\boldsymbol{R}_{t}^{-1}+\\boldsymbol{X}_t^{\\top}\\boldsymbol{\\Sigma}_t^{-1}\\boldsymbol{X}_t)^{-1})]\\\\ &amp;=(\\boldsymbol{R}_{t}^{-1}+\\boldsymbol{X}_t^{\\top}\\boldsymbol{\\Sigma}_t^{-1}\\boldsymbol{X}_t)^{-1}, \\end{align*}\\] where the second equality uses the Woodbury matrix identity, the fourth equality uses \\((\\boldsymbol{D}+\\boldsymbol{E})^{-1}\\boldsymbol{D}=\\boldsymbol{I}-(\\boldsymbol{D}+\\boldsymbol{E})^{-1}\\boldsymbol{E}\\), and the seventh equality uses \\(\\boldsymbol{D}(\\boldsymbol{D}+\\boldsymbol{E})^{-1}=\\boldsymbol{I}-\\boldsymbol{E}(\\boldsymbol{D}+\\boldsymbol{E})^{-1}\\). The Kalman filter allows calculating recursively in a forward way \\(\\pi(\\boldsymbol{\\beta}_t\\mid \\boldsymbol{y}_{1:t})\\) from \\(\\pi(\\boldsymbol{\\beta}_{t-1}\\mid \\boldsymbol{y}_{1:t-1})\\) starting from \\(\\pi(\\boldsymbol{\\beta}_0)\\). Let \\(\\boldsymbol{\\beta}_{t+1} \\mid \\mathbf{y}_{1:T} \\sim N(\\boldsymbol{s}_{t+1}, \\mathbf{S}_{t+1})\\), then we can get the Kalman smoother by \\(\\boldsymbol{\\beta}_{t} \\mid \\mathbf{y}_{1:T} \\sim N(\\boldsymbol{s}_{t}, \\mathbf{S}_{t})\\), where \\[ \\boldsymbol{s}_t = \\mathbf{b}_t + \\mathbf{B}_t \\mathbf{G}_{t+1}^{\\top} \\mathbf{R}_{t+1}^{-1} (\\boldsymbol{s}_{t+1} - \\mathbf{a}_{t+1}) \\] and \\[ \\mathbf{S}_t = \\mathbf{B}_t - \\mathbf{B}_t \\mathbf{G}_{t+1}^{\\top} \\mathbf{R}_{t+1}^{-1} (\\mathbf{R}_{t+1} - \\mathbf{S}_{t+1}) \\mathbf{R}_{t+1}^{-1} \\mathbf{G}_{t+1} \\mathbf{B}_{t}. \\] The proof can be found in Petris, Petrone, and Campagnoli (2009), Chap. 2. Thus, we can calculate the Kalman smoother starting from \\(t = T-1\\), that is, \\(\\boldsymbol{\\beta}_{T} \\mid \\mathbf{y}_{1:T} \\sim N(\\boldsymbol{s}_{T}, \\mathbf{S}_{T})\\). However, this is the filtering distribution at \\(T\\), which means \\(\\boldsymbol{s}_{T} = \\mathbf{b}_{T}\\) and \\(\\mathbf{S}_{T} = \\mathbf{B}_{T}\\), and then, we should proceed recursively in a backward way. Finally, the forecasting recursion in the dynamic linear model, given \\(\\mathbf{a}_t(0) = \\mathbf{b}_t\\) and \\(\\mathbf{R}_t(0) = \\mathbf{B}_t\\), \\(h \\geq 1\\), is given by The forecasting distribution of \\(\\boldsymbol{\\beta}_{t+h} \\mid \\mathbf{y}_{1:t}\\) is \\(N(\\mathbf{a}_t(h), \\mathbf{R}_t(h))\\), where \\[ \\mathbf{a}_t(h) = \\mathbf{G}_{t+h} \\mathbf{a}_{t}(h-1), \\quad \\mathbf{R}_t(h) = \\mathbf{G}_{t+h} \\mathbf{R}_t(h-1) \\mathbf{G}_{t+h}^{\\top} + \\boldsymbol{\\Omega}_{t+h}. \\] The forecasting distribution \\(\\mathbf{Y}_{t+h} \\mid \\mathbf{y}_{1:t}\\) is \\(N(\\mathbf{f}_t(h), \\mathbf{Q}_t(h))\\), where \\[ \\mathbf{f}_t(h) = \\mathbf{X}_{t+h} \\mathbf{a}_t(h), \\quad \\mathbf{Q}_t(h) = \\mathbf{X}_{t+h} \\mathbf{R}_t(h) \\mathbf{X}_{t+h}^{\\top} + \\boldsymbol{\\Sigma}_{t+h}. \\] The proof can be found in Petris, Petrone, and Campagnoli (2009), Chap. 2. These recursive equations allow us to perform probabilistic forecasting \\(h\\)-steps-ahead for the state and observation equations. These results demonstrate how to use these recursive equations for filtering, smoothing, and forecasting in dynamic linear models (Gaussian linear state-space models). Although these algorithms appear simple, they suffer from numerical instability, which can lead to non-symmetric and negative-definite covariance matrices. Thus, special care must be taken when working with them. In addition, this setup assumes that \\(\\boldsymbol{\\Sigma}_t\\) and \\(\\boldsymbol{\\Omega}_t\\) are known. However, this is rarely the case in most situations. Therefore, we need to estimate them. One option is to perform maximum likelihood estimation. However, this approach does not account for the uncertainty associated with the fact that \\(\\boldsymbol{\\Sigma}_t\\) and \\(\\boldsymbol{\\Omega}_t\\) are unknown when their estimates are plugged into the state space recursions. On the other hand, we can use a Bayesian approach and perform the recursions associated with each posterior draw of the unknown parameters, thus taking their uncertainty into account. The point of departure is the posterior distribution, such that \\[ \\pi(\\boldsymbol{\\theta}, \\boldsymbol{\\beta}_0, \\dots, \\boldsymbol{\\beta}_T \\mid \\mathbf{y}, \\mathbf{X}, \\mathbf{G}) \\propto \\pi(\\boldsymbol{\\beta}_0 \\mid \\boldsymbol{\\theta}) \\pi(\\boldsymbol{\\theta}) \\prod_{t=1}^{T} \\pi(\\boldsymbol{\\beta}_t \\mid \\boldsymbol{\\beta}_{t-1}, \\boldsymbol{\\theta}) \\pi(\\mathbf{y}_t \\mid \\boldsymbol{\\beta}_t, \\boldsymbol{\\theta}), \\] where \\(\\boldsymbol{\\theta}\\) is the vector of unknown parameters. We can compute \\[\\pi(\\boldsymbol{\\beta}_s, \\boldsymbol{\\theta} \\mid \\mathbf{y}_{1:t}) = \\pi(\\boldsymbol{\\beta}_s \\mid \\mathbf{y}_{1:t}, \\boldsymbol{\\theta}) \\pi(\\boldsymbol{\\theta} \\mid \\mathbf{y}_{1:t}),\\] for \\(s=t\\) (filtering), \\(s&lt;t\\) (smoothing), and \\(s&gt;t\\) (forecasting). The marginal posterior distribution of the states is \\[ \\pi(\\boldsymbol{\\beta}_s \\mid \\mathbf{y}_{1:t}) = \\int_{\\boldsymbol{\\Theta}} \\pi(\\boldsymbol{\\beta}_s \\mid \\mathbf{y}_{1:t}, \\boldsymbol{\\theta}) \\pi(\\boldsymbol{\\theta} \\mid \\mathbf{y}_{1:t}) d\\boldsymbol{\\theta}. \\] We can use the Gibbs sampling algorithm to get the posterior draws in the dynamic linear model assuming conjugate families. In particular, let’s see the univariate case with random walk states, \\[\\begin{align} y_t&amp;=\\boldsymbol{x}_t^{\\top}\\boldsymbol{\\beta}_t+\\mu_t \\tag{8.1}\\\\ \\boldsymbol{\\beta}_t&amp;=\\boldsymbol{\\beta}_{t-1}+\\boldsymbol{w}_t, \\tag{8.2} \\end{align}\\] where \\(\\mu_t\\sim N(0,\\sigma^2)\\) and \\(\\boldsymbol{w}_t\\sim N(\\boldsymbol{0},\\text{diag}\\left\\{\\omega_1^2,\\dots,\\omega_K^2\\right\\})\\). We assume that \\(\\pi(\\sigma^2,\\omega_1^2,\\dots,\\omega_K^2,\\boldsymbol{\\beta}_0)=\\pi(\\sigma^2)\\pi(\\omega_1^2),\\dots,\\pi(\\omega_K^2)\\pi(\\boldsymbol{\\beta}_0)\\) where \\(\\sigma^2\\sim IG(\\alpha_0/2,\\delta_0/2)\\), \\(\\omega_k^2\\sim IG(\\alpha_{k0}/2,\\delta_{k0}/2)\\), \\(k=1,\\dots,K\\), and \\(\\boldsymbol{\\beta}_0\\sim N(\\boldsymbol{b}_0,\\boldsymbol{B}_0)\\). Thus, the conditional posterior distributions are \\(\\sigma^2\\mid \\boldsymbol{y},\\boldsymbol{X},\\boldsymbol{\\beta}_{1:T}\\sim IG(\\alpha_{n}/2,\\delta_n/2)\\), where \\(\\alpha_{n}=T+\\alpha_0\\) and \\(\\delta_n=\\sum_{t=1}^T(y_t-\\boldsymbol{x}_t^{\\top}\\boldsymbol{\\beta}_t)^2+\\delta_0\\), and \\(\\omega_k^2\\mid \\boldsymbol{y},\\boldsymbol{X},\\boldsymbol{\\beta}_{0:T}\\sim IG(\\alpha_{kn}/2,\\delta_{kn}/2)\\), where \\(\\alpha_{kn}=T+\\alpha_{k0}\\) and \\(\\delta_{kn}=\\sum_{t=1}^T(\\boldsymbol{\\beta}_{t,k}-\\boldsymbol{\\beta}_{t-1,k})^2+\\delta_{k0}\\). The vector of the dependent variable is \\(\\boldsymbol{y}\\), and all regressors are in \\(\\boldsymbol{X}\\). We also need to sample the states from \\(\\pi(\\boldsymbol{\\beta}_{1:T}\\mid \\boldsymbol{y},\\boldsymbol{X},\\sigma^2,\\omega_1^2,\\dots,\\omega_K^2)\\). This can be done using the forward filtering backward sampling (FFBS) algorithm (Carter and Kohn 1994; Frühwirth-Schnatter 1994; Shephard 1994). This algorithm is basically a simulation version of the smoothing recursion, which allows getting draws of the states, even if we do not have analytical solutions, for instance, in non-linear settings. See below and Petris, Petrone, and Campagnoli (2009) Chap. 3 for details. A word of caution here, users should be careful to set non-informative priors in this setting, and in general, settings where there are a large number of parameters (see G. M. Koop (2003) Chap. 8 for details). Thus, it is useful to use empirical Bayes methods focusing on relevant hyperparameters, for instance, the hyperparameters of the inverse-gamma distributions which define the signal-to-noise ratio. We use the command dlmGibbsDIG from the dlm package in our GUI to perform Bayesian inference in the univariate dynamic linear model with random walk states. This function uses the FFBS algorithm, and assumes independent gamma priors for the precision (inverse of variance) parameters. In addition, this package uses the singular value decomposition to calculate the covariance matrices to avoid numerical instability. The following Algorithm shows how to perform inference in the univariate dynamic linear model with random walk states in our GUI. See also Chapter 5 for details regarding the dataset structure. Algorithm: Dynamic Linear Models Select Time series Model on the top panel Select Dynamic linear model using the left radio button Upload the dataset selecting first if there is a header in the file, and the kind of separator in the csv file of the dataset (comma, semicolon, or tab). Then, use the Browse button under the Choose File legend Select MCMC iterations, burn-in, and thinning parameters using the Range sliders Set the hyperparameters of the precision of the observation equation: prior mean and variance Set the hyperparameters of the precision of the state equations: just one set of prior mean and variance parameters Click the Go! button Analyze results Download posterior chains of variances of observation and state equations, and posterior chains of states using the Download Results button Example: Simulation exercise of the dynamic linear model We simulate the process \\(y_t = \\beta_{t1} + x_t \\beta_{t2} + \\mu_t\\) and \\(\\boldsymbol{\\beta}_t = \\boldsymbol{\\beta}_{t-1} + \\boldsymbol{w}_t\\), \\(t = 1, 2, \\dots, 200\\), where \\(\\boldsymbol{\\beta}_t = [\\beta_{t1} \\ \\beta_{t2}]^{\\top}\\), \\(\\mu_t \\sim N(0, 0.5^2)\\), \\(\\boldsymbol{w}_t \\sim N(\\boldsymbol{0}, \\text{diag}\\{0.2, 0.1\\})\\), \\(x_t \\sim N(1, 1)\\), \\(\\boldsymbol{\\beta}_0\\) and \\(\\boldsymbol{B}_0\\) are the OLS estimates and variance of the recursive OLS estimates (see below), respectively. The following algorithm demonstrates how to perform inference using dlmGibbsDIG and compares the results to those of the maximum likelihood estimator, which is based on the dlmMLE function. We also use the dlmSvd2var function, which is based on singular value decomposition, to calculate the variance of the smoothing states. All these functions are from the dlm package in R. Users can observe that we employ a straightforward strategy for setting the hyperparameters. First, we recursively estimate the model using ordinary least squares (OLS), progressively increasing the sample size, and save the location parameters. Next, we compute the covariance matrix of this sequence and use it to set the priors: the prior mean of the precision of the state vector is set equal to the inverse of the maximum element of the main diagonal of this covariance matrix (a.theta), and the prior variance is set equal to ten times this value (b.theta). For the observation equation, the prior mean of the precision is set equal to the inverse of the OLS variance estimate (a.y), and the prior variance is set equal to ten times this value (b.y). We perform some sensitivity analysis of the results regarding the hyperparameters, and it seems that the results are robust. However, we encourage giving more consideration to empirical Bayes methods for setting hyperparameters in state-space models. rm(list = ls()); set.seed(010101) T &lt;- 200; sig2 &lt;- 0.5^2 x &lt;- rnorm(T, mean = 1, sd = 1) X &lt;- cbind(1, x); B0 &lt;- c(1, 0.5) K &lt;- length(B0) e &lt;- rnorm(T, mean = 0, sd = sig2^0.5) Omega &lt;- diag(c(0.2, 0.1)) w &lt;- MASS::mvrnorm(T, c(0, 0), Omega) Bt &lt;- matrix(NA, T, K); Bt[1,] &lt;- B0 yt &lt;- rep(NA, T) yt[1] &lt;- X[1,]%*%B0 + e[1] for(t in 1:T){ if(t == 1){ Bt[t,] &lt;- w[t,] }else{ Bt[t,] &lt;- Bt[t-1,] + w[t,] } yt[t] &lt;- X[t,]%*%Bt[t,] + e[t] } RegLS &lt;- lm(yt ~ x) SumRegLS &lt;- summary(RegLS) SumRegLS; SumRegLS$sigma^2 ## ## Call: ## lm(formula = yt ~ x) ## ## Residuals: ## Min 1Q Median 3Q Max ## -16.247 -1.293 0.699 2.632 9.560 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 4.4941 0.4215 10.66 &lt;2e-16 *** ## x 4.2508 0.2858 14.87 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 4.274 on 198 degrees of freedom ## Multiple R-squared: 0.5277, Adjusted R-squared: 0.5253 ## F-statistic: 221.2 on 1 and 198 DF, p-value: &lt; 2.2e-16 ## [1] 18.27024 Bp &lt;- matrix(RegLS$coefficients, T, K, byrow = TRUE) S &lt;- 20 for(t in S:T){ RegLSt &lt;- lm(yt[1:t] ~ x[1:t]) Bp[t,] &lt;- RegLSt$coefficients } # plot(Bp[S:T,2], type = &quot;l&quot;) VarBp &lt;- var(Bp) # State space model ModelReg &lt;- function(par){ Mod &lt;- dlm::dlmModReg(x, dV = exp(par[1]), dW = exp(par[2:3]), m0 = RegLS$coefficients, C0 = VarBp) return(Mod) } outMLEReg &lt;- dlm::dlmMLE(yt, parm = rep(0, K+1), ModelReg) exp(outMLEReg$par) ## [1] 0.1880010 0.2773561 0.0785071 RegFilter &lt;- dlm::dlmFilter(yt, ModelReg(outMLEReg$par)) RegSmoth &lt;- dlm::dlmSmooth(yt, ModelReg(outMLEReg$par)) SmoothB2 &lt;- RegSmoth$s[-1,2] VarSmooth &lt;- dlm::dlmSvd2var(u = RegSmoth[[&quot;U.S&quot;]], RegSmoth[[&quot;D.S&quot;]]) SDVarSmoothB2 &lt;- sapply(2:(T+1), function(t){VarSmooth[[t]][K,K]^0.5}) LimInfB2 &lt;- SmoothB2 - qnorm(0.975)*SDVarSmoothB2 LimSupB2 &lt;- SmoothB2 + qnorm(0.975)*SDVarSmoothB2 # Gibbs MCMC &lt;- 2000; burnin &lt;- 1000 a.y &lt;- (SumRegLS$sigma^2)^(-1); b.y &lt;- 10*a.y; a.theta &lt;- (max(diag(VarBp)))^(-1); b.theta &lt;- 10*a.theta gibbsOut &lt;- dlm::dlmGibbsDIG(yt, mod = dlm::dlmModReg(x), a.y = a.y, b.y = b.y, a.theta = a.theta, b.theta = b.theta, n.sample = MCMC, thin = 5, save.states = TRUE) B2t &lt;- matrix(0, MCMC - burnin, T + 1) for(t in 1:(T+1)){ B2t[,t] &lt;- gibbsOut[[&quot;theta&quot;]][t,2,-c(1:burnin)] } Lims &lt;- apply(B2t, 2, function(x){quantile(x, c(0.025, 0.975))}) summary(coda::mcmc(gibbsOut[[&quot;dV&quot;]])) ## ## Iterations = 1:2000 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 2000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## 27.06996 2.95137 0.06599 0.06599 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## 21.94 24.92 26.81 29.02 33.26 summary(coda::mcmc(gibbsOut[[&quot;dW&quot;]])) ## ## Iterations = 1:2000 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 2000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## W.1 0.1272 0.07831 0.001751 0.005149 ## W.2 0.1185 0.05903 0.001320 0.003612 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## W.1 0.03489 0.07248 0.1072 0.1605 0.3397 ## W.2 0.03917 0.07601 0.1052 0.1485 0.2625 # Figure require(latex2exp) # LaTeX equations in figures xx &lt;- c(1:(T+1), (T+1):1) yy &lt;- c(Lims[1,], rev(Lims[2,])) plot (xx, yy, type = &quot;n&quot;, xlab = &quot;Time&quot;, ylab = TeX(&quot;$\\\\beta_{t2}$&quot;)) polygon(xx, yy, col = &quot;lightblue&quot;, border = &quot;lightblue&quot;) xxML &lt;- c(1:T, T:1) yyML &lt;- c(LimInfB2, rev(LimSupB2)) polygon(xxML, yyML, col = &quot;blue&quot;, border = &quot;blue&quot;) lines(colMeans(B2t), col = &quot;red&quot;, lw = 2) lines(Bt[,2], col = &quot;black&quot;, lw = 2) lines(SmoothB2, col = &quot;green&quot;, lw = 2) title(&quot;State vector: Slope parameter&quot;) The Figure shows the comparison between maximum likelihood (ML) and Bayesian inference. The light blue (Bayesian) and dark blue (maximum likelihood) shadows show the credible and confidence intervals at 95% for the state slope parameter (\\(\\beta_{t2}\\)). We see that the Bayesian interval encompass the ML interval. This is a reflection of the extra uncertainty of the unknown variances. The black line is the actual trajectory of \\(\\beta_{t2}\\), the green and red lines are the smoothing recursions using the ML and Bayesian estimates (posterior mean), respectively. Example: Effects of inflation on interest rate I We use the dataset 16INTDEF.csv provided by Jeffrey M. Wooldridge (2016) to study the effects of inflation on the interest rate. The specification is \\[ \\Delta i_t = \\beta_{t1} + \\beta_{t2} \\Delta \\text{inf}_t + \\beta_{t3} \\Delta \\text{def}_t + \\mu_t \\] and \\[ \\boldsymbol{\\beta}_t = \\boldsymbol{\\beta}_{t-1} + \\boldsymbol{w}_t, \\] where \\(\\Delta z_t = z_t - z_{t-1}\\) is the difference operator, \\(i_t\\) is the three-month T-bill rate, \\(\\text{inf}_t\\) is the annual inflation rate based on the consumer price index (CPI), and \\(\\text{def}_t\\) is the federal budget deficit as a percentage of gross domestic product (GDP) from 1948 to 2003 in the USA. In addition, \\(\\mu_t \\sim N(0, \\sigma^2)\\) and \\(\\boldsymbol{w}_t \\sim N(\\boldsymbol{0}, \\text{diag}\\{\\omega_1^2, \\omega_2^2\\})\\). We assume inverse-gamma distributions for the priors of the scale parameters and set 12,000 MCMC iterations, 2,000 as burn-in, and 10 as the thinning parameter. The following code shows how to perform this application. We use the variance of the recursive estimation of OLS to set the hyperparameters of the inverse-gamma distribution for the variances of \\(\\boldsymbol{w}_t\\), and the OLS estimate of the variance of the model to set the hyperparameters of the distribution of \\(\\sigma^2\\). Note that, as we are using the function dlmGibbsDIG from the dlm package, the hyperparameters are set in terms of precision parameters. The Figure shows the posterior results of the effect of inflation on the interest rate. This is a fan chart indicating deciles from 10% to 90%. The red shaded area shows the range around the median value, and the black line represents the mean value of the state associated with the annual change in inflation. We see that the annual changes in interest rates are weakly positively related to annual changes in inflation. rm(list = ls()); set.seed(010101) DataIntRate &lt;- read.csv(&quot;https://raw.githubusercontent.com/besmarter/BSTApp/refs/heads/master/DataApp/16INTDEF.csv&quot;, sep = &quot;,&quot;, header = TRUE, quote = &quot;&quot;) attach(DataIntRate); Xt &lt;- cbind(diff(inf), diff(def)) K &lt;- dim(Xt)[2] + 1; yt &lt;- diff(i3) T &lt;- length(yt); RegLS &lt;- lm(yt ~ Xt) SumRegLS &lt;- summary(RegLS); SumRegLS; SumRegLS$sigma^2 ## ## Call: ## lm(formula = yt ~ Xt) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.60299 -0.82620 0.02311 0.91651 2.92275 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.1145 0.1874 0.611 0.5443 ## Xt1 0.1683 0.1002 1.680 0.0999 . ## Xt2 -0.1075 0.1719 -0.625 0.5349 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.293 on 45 degrees of freedom ## Multiple R-squared: 0.161, Adjusted R-squared: 0.1237 ## F-statistic: 4.316 on 2 and 45 DF, p-value: 0.01928 ## [1] 1.671989 # Recursive OLS Bp &lt;- matrix(RegLS$coefficients, T, K, byrow = TRUE) S &lt;- 20 for(t in S:T){ RegLSt &lt;- lm(yt[1:t] ~ Xt[1:t,]) Bp[t,] &lt;- RegLSt$coefficients } VarBp &lt;- var(Bp) # State space model ModelReg &lt;- function(par){ Mod &lt;- dlm::dlmModReg(Xt, dV = exp(par[1]), dW = exp(par[2:(K+1)]), m0 = RegLS$coefficients, C0 = diag(VarBp)) return(Mod) } MCMC &lt;- 12000; burnin &lt;- 2000; thin &lt;- 10 a.y &lt;- (SumRegLS$sigma^2)^(-1); b.y &lt;- 10*a.y; a.theta &lt;- (max(diag(VarBp)))^(-1); b.theta &lt;- 10*a.theta gibbsOut &lt;- dlm::dlmGibbsDIG(yt, mod = dlm::dlmModReg(Xt), a.y = a.y, b.y = b.y, a.theta = a.theta, b.theta = b.theta, n.sample = MCMC, thin = 5, save.states = TRUE) B2t &lt;- matrix(0, MCMC - burnin, T + 1) for(t in 1:(T+1)){ B2t[,t] &lt;- gibbsOut[[&quot;theta&quot;]][t,2,-c(1:burnin)] } dV &lt;- coda::mcmc(gibbsOut[[&quot;dV&quot;]][-c(1:burnin)]) dW &lt;- coda::mcmc(gibbsOut[[&quot;dW&quot;]][-c(1:burnin),]) summary(dV); summary(dW) ## ## Iterations = 1:10000 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 10000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## 2.19167 0.53702 0.00537 0.00537 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## 1.401 1.814 2.104 2.476 3.517 ## ## Iterations = 1:10000 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 10000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## W.1 0.005957 0.001504 1.504e-05 1.544e-05 ## W.2 0.005899 0.001411 1.411e-05 1.480e-05 ## W.3 0.006022 0.001518 1.518e-05 1.515e-05 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## W.1 0.003733 0.004895 0.005739 0.006776 0.009440 ## W.2 0.003710 0.004898 0.005714 0.006686 0.009139 ## W.3 0.003761 0.004953 0.005788 0.006830 0.009646 plot(dV); plot(dW) library(fanplot); library(latex2exp) ## Warning: package &#39;fanplot&#39; was built under R version 4.3.3 df &lt;- as.data.frame(B2t) plot(NULL, main=&quot;Percentiles&quot;, xlim = c(1, T+1), ylim = c(-1, 2), xlab = &quot;Time&quot;, ylab = TeX(&quot;$\\\\beta_{t1}$&quot;)) fan(data = df); lines(colMeans(B2t), col = &quot;black&quot;, lw = 2) abline(h=0, col = &quot;blue&quot;) We can extend the dynamic linear model with random walk states to take into account time-invariant location parameters. In particular, we follow De Jong and Shephard (1995), who propose the simulation smoother. This algorithm overcomes some shortcomings of the FFBS algorithm, such as slow convergence and computational overhead. We focus on the case \\(M = 1\\), \\[\\begin{align} y_t &amp;= \\boldsymbol{z}_t^{\\top} \\boldsymbol{\\alpha} + \\boldsymbol{x}_t^{\\top} \\boldsymbol{\\beta}_t + \\boldsymbol{h}_t^{\\top} \\boldsymbol{\\epsilon}_t, &amp; t = 1, 2, \\dots, T. &amp; \\text{ (Observation equation)} \\tag{8.3} \\\\ \\boldsymbol{\\beta}_t &amp;= \\boldsymbol{\\beta}_{t-1} + \\boldsymbol{H}_t \\boldsymbol{\\epsilon}_t, &amp; t = 1, 2, \\dots, T. &amp; \\text{ (States equation)} \\tag{8.4} \\end{align}\\] where \\(\\boldsymbol{z}_t\\) and \\(\\boldsymbol{x}_t\\) are \\(L\\)-dimensional and \\(K\\)-dimensional vectors of regressors associated with time-invariant and time-varying parameters, respectively, \\(\\boldsymbol{h}_t\\) is a vector of dimension \\(1+K\\), \\(\\boldsymbol{H}_t\\) is a matrix of dimension \\(K \\times (1+K)\\), \\(\\boldsymbol{\\beta}_0 = \\boldsymbol{0}\\), and \\(\\boldsymbol{\\epsilon}_t \\sim N(\\boldsymbol{0}_{1+K}, \\sigma^2 \\boldsymbol{I}_{1+K})\\). Observe that this specification encompasses Equations (8.1) and (8.2) setting \\(\\boldsymbol{\\epsilon}_t = [\\mu_t \\ \\boldsymbol{w}_t^{\\top}]^{\\top}\\), \\(\\boldsymbol{h}_t = [1 \\ 0 \\ \\dots \\ 0]\\), \\(\\boldsymbol{H}_t = [\\boldsymbol{0}_K \\ \\boldsymbol{U}_{K \\times K}]\\) such that \\(\\text{diag}\\{\\omega_1^2 \\ \\dots \\ \\omega_K^2\\} = \\sigma^2 \\boldsymbol{U} \\boldsymbol{U}^{\\top}\\), \\(\\boldsymbol{\\alpha} = \\boldsymbol{0}\\), and \\(\\boldsymbol{h}_t \\boldsymbol{H}_t^{\\top} = \\boldsymbol{0}_K\\). The nice idea of De Jong and Shephard (1995) was to propose an efficient algorithm to get draws from \\(\\boldsymbol{\\eta}_t = \\boldsymbol{F}_t \\boldsymbol{\\epsilon}_t\\), where the most common choice is \\(\\boldsymbol{F}_t = \\boldsymbol{H}_t\\), which means drawing samples from the perturbations of the states, and then, recovering the states from Equation (8.4) with \\(\\boldsymbol{\\beta}_0 = \\boldsymbol{0}\\). De Jong and Shephard (1995) present a more general version of the state space model than the one presented here. Using the system given by Equations (8.3) and (8.4), \\(\\boldsymbol{F}_t=\\boldsymbol{H}_t\\) and \\(\\boldsymbol{h}_t\\boldsymbol{H}_t^{\\top}=\\boldsymbol{0}_{K}\\), the filtering recursions are given by \\(e_t=Y_t-\\boldsymbol{z}_t^{\\top}\\boldsymbol{\\alpha}-\\boldsymbol{x}_t^{\\top}\\boldsymbol{b}_{t-1}\\), \\({q}_t=\\boldsymbol{x}_t^{\\top}\\boldsymbol{B}_{t-1}\\boldsymbol{x}_t+\\boldsymbol{h}_t^{\\top}\\boldsymbol{h}_t\\), \\(\\boldsymbol{K}_t=\\boldsymbol{B}_{t-1}\\boldsymbol{x}_tq_t^{-1}\\), \\(\\boldsymbol{b}_t=\\boldsymbol{b}_{t-1}+\\boldsymbol{K}_t e_t\\), and \\(\\boldsymbol{B}_t=\\boldsymbol{B}_{t-1}-\\boldsymbol{B}_{t-1}\\boldsymbol{x}_t\\boldsymbol{K}_t^{\\top}+\\boldsymbol{H}_t\\boldsymbol{H}_t^{\\top}\\), where \\(\\boldsymbol{b}_0=\\boldsymbol{0}\\) and \\(\\boldsymbol{B}_0=\\boldsymbol{H}_0\\boldsymbol{H}_0^{\\top}\\). See system 2 in De Jong and Shephard (1995) for a more general case. We should save \\(e_t\\) (innovation vector), \\(q_t\\) (scale innovation variance) and \\(\\boldsymbol{K}_t\\) (Kalman gain) from this recursion. Then, setting \\(\\boldsymbol{r}_T=0\\) and \\(\\boldsymbol{M}_T=\\boldsymbol{0}\\), we run backwards from \\(t=T-1, T-2, \\dots, 1\\), the following recursions: \\(\\boldsymbol{\\Lambda}_{t+1}=\\boldsymbol{H}_{t+1}\\boldsymbol{H}_{t+1}^{\\top}\\), \\(\\boldsymbol{C}_{t+1}=\\boldsymbol{\\Lambda}_{t+1}-\\boldsymbol{\\Lambda}_{t+1}\\boldsymbol{M}_{t+1}\\boldsymbol{\\Lambda}_{t+1}^{\\top}\\), \\(\\boldsymbol{\\xi}_{t+1}\\sim N(\\boldsymbol{0}_K,\\sigma^2\\boldsymbol{C}_{t+1})\\), \\(\\boldsymbol{L}_{t+1}=\\boldsymbol{I}_K-\\boldsymbol{K}_{t+1}\\boldsymbol{x}_{t+1}^{\\top}\\), \\(\\boldsymbol{V}_{t+1}=\\boldsymbol{\\Lambda}_{t+1}\\boldsymbol{M}_{t+1}\\boldsymbol{L}_{t+1}\\), \\(\\boldsymbol{r}_{t}=\\boldsymbol{x}_{t+1} e_{t+1}/q_{t+1} + \\boldsymbol{L}_{t+1}^{\\top}\\boldsymbol{r}_{t+1}-\\boldsymbol{V}_{t+1}^{\\top}\\boldsymbol{C}_{t+1}^{-1}\\boldsymbol{\\xi}_{t+1}\\), \\(\\boldsymbol{M}_{t}=\\boldsymbol{x}_{t+1}\\boldsymbol{x}_{t+1}^{\\top}/q_{t+1}+\\boldsymbol{L}_{t+1}^{\\top}\\boldsymbol{M}_{t+1}\\boldsymbol{L}_{t+1}+\\boldsymbol{V}_{t+1}^{\\top}\\boldsymbol{C}_{t+1}^{-1}\\boldsymbol{V}_{t+1}\\), and \\(\\boldsymbol{\\eta}_{t+1}=\\boldsymbol{\\Lambda}_{t+1}\\boldsymbol{r}_{t+1}+\\boldsymbol{\\xi}_{t+1}\\). De Jong and Shephard (1995) show that \\(\\boldsymbol{\\eta}=[\\boldsymbol{\\eta}_1^{\\top} \\ \\dots \\ \\boldsymbol{\\eta}_T^{\\top}]^{\\top}\\) is drawn from \\(p(\\boldsymbol{H}_t\\boldsymbol{\\epsilon}_t\\mid y_t,\\boldsymbol{x}_t,\\boldsymbol{z}_t,\\boldsymbol{h}_t,\\boldsymbol{H}_t,\\boldsymbol{\\alpha},\\sigma^2, t=1,2,\\dots,T)\\). Thus, we can recover \\(\\boldsymbol{\\beta}_t\\) using (8.4) and \\(\\boldsymbol{\\beta}_0=\\boldsymbol{0}_K\\). We assume in the model given by Equations (8.3) and (8.4) that \\(\\boldsymbol{h}_t=[1 \\ 0 \\ \\dots \\ 0]^{ \\top}\\) and \\(\\boldsymbol{H}_t=[\\boldsymbol{0}_K \\ \\text{diag}\\left\\{1/\\tau_1\\dots1/\\tau_K\\right\\}]\\), and then perform Bayesian inference assuming independent priors, that is, \\(\\pi(\\boldsymbol{\\beta}_0,\\boldsymbol{\\alpha},\\sigma^2,\\boldsymbol{\\tau})=\\pi(\\boldsymbol{\\beta}_0)\\pi(\\boldsymbol{\\alpha})\\pi(\\sigma^2)\\prod_{k=1}^K\\pi(\\tau_k^2)\\) where \\(\\sigma^2\\sim IG(\\alpha_0/2,\\delta_0/2)\\), \\(\\tau_k^2\\sim G(v_{0}/2,v_{0}/2)\\), \\(k=1,\\dots,K\\), \\(\\boldsymbol{\\alpha}\\sim N(\\boldsymbol{a}_0,\\boldsymbol{A}_0)\\) and \\(\\boldsymbol{\\beta}_0\\sim N(\\boldsymbol{b}_0,\\boldsymbol{B}_0)\\). The conditional posterior distributions are \\(\\sigma^2\\mid \\boldsymbol{y},\\boldsymbol{X},\\boldsymbol{Z},\\boldsymbol{\\beta}_{0:T},\\boldsymbol{\\alpha},\\boldsymbol{\\tau}\\sim IG(\\alpha_{n}/2,\\delta_n/2)\\), where \\(\\delta_n=\\sum_{t=1}^T\\left[(\\boldsymbol{\\beta}_t-\\boldsymbol{\\beta}_{t-1})^{\\top}\\boldsymbol{\\Psi}(\\boldsymbol{\\beta}_t-\\boldsymbol{\\beta}_{t-1})+(y_t-\\boldsymbol{z}_t^{\\top}\\boldsymbol{\\alpha}-\\boldsymbol{x}_t^{\\top}\\boldsymbol{\\beta}_t)^{\\top}(y_t-\\boldsymbol{z}_t^{\\top}\\boldsymbol{\\alpha}-\\boldsymbol{x}_t^{\\top}\\boldsymbol{\\beta}_t)\\right]+\\delta_0\\) and \\(\\alpha_{n}=T(K+1)+\\alpha_0\\), \\(\\boldsymbol{\\tau}=[\\tau_1 \\ \\dots \\ \\tau_K]\\), \\(\\boldsymbol{\\Psi}=\\text{diag}\\left\\{\\tau_1^2,\\dots,\\tau_K^2\\right\\}\\), and \\(\\tau_k^2\\mid \\boldsymbol{y},\\boldsymbol{X},\\boldsymbol{Z},\\boldsymbol{\\beta}_{0:T},\\sigma^2\\sim G(v_{1n}/2,v_{2kn}/2)\\), where \\(v_{1n}=T+v_{0}\\) and \\(v_{2kn}=\\sigma^{-2}\\sum_{t=1}^T(\\boldsymbol{\\beta}_{t,k}-\\boldsymbol{\\beta}_{t-1,k})^2+v_{0}\\), and \\(\\boldsymbol{\\alpha}\\mid \\boldsymbol{y},\\boldsymbol{X},\\boldsymbol{Z},\\sigma^2,\\boldsymbol{\\beta}_{1:T},\\boldsymbol{\\tau}\\sim N(\\boldsymbol{a}_n,\\boldsymbol{A}_n)\\), where \\(\\boldsymbol{A}_n=(\\boldsymbol{A}_0^{-1}+\\sigma^{-2}\\sum_{t=1}^T\\boldsymbol{z}_t\\boldsymbol{z}_t^{\\top})^{-1}\\) and \\(\\boldsymbol{a}_n=\\boldsymbol{A}_n(\\boldsymbol{A}_0^{-1}\\boldsymbol{a}_0+\\sigma^{-2}\\sum_{t=1}^T\\boldsymbol{z}_t(y_t-\\boldsymbol{x}_t^{\\top}\\boldsymbol{\\beta}_t))\\). The vector of the dependent variable is \\(\\boldsymbol{y}\\), and all regressors are in \\(\\boldsymbol{X}\\) and \\(\\boldsymbol{Z}\\). We can see that all the previous posterior distributions are conditional on the state vector \\(\\boldsymbol{\\beta}_{0:T}\\), which can be sampled using the simulation smoother algorithm, conditional on draws of the time-invariant parameters. Thus, the state space model provides an excellent illustration of the modular nature of the Bayesian framework, where performing inference on more complex models often simply involves adding new blocks to an MCMC algorithm. This means we can break down a complex inferential problem into smaller, more manageable parts, which is a “divide and conquer” approach. This is possible due to the structure of the conditional posterior distributions. Exercise 3 asks you to perform a simulation of the model given by Equations (8.3) and (8.4), and to program the MCMC algorithm, including the simulation smoother. References "],["sec82.html", "8.2 ARMA processes", " 8.2 ARMA processes Since the seminal work of George E. P. Box and Jenkins (1976), autoregressive moving average (ARMA) models have become ubiquitous in time series analysis. Thus, we present a brief introduction to these models in this section. Let’s start with the linear Gaussian model with autoregressive errors: \\[\\begin{align} y_t &amp;= \\boldsymbol{x}_t^{\\top} \\boldsymbol{\\beta} + \\mu_t \\tag{8.5} \\\\ \\phi(L) \\mu_t &amp;= \\epsilon_t \\tag{8.6} \\end{align}\\] where \\(\\boldsymbol{x}_t\\) is a \\(K\\)-dimensional vector of regressors, \\(\\epsilon_t \\sim \\text{iid} \\, N(0, \\sigma^2)\\), and \\(\\phi(L) = 1 - \\phi_1 L - \\phi_2 L^2 - \\dots - \\phi_p L^p\\) is a polynomial in the lag operator \\(L\\), where \\(L z_t = z_{t-1}\\), and in general, \\(L^r z_t = z_{t-r}\\). Thus, we see that the stochastic error \\(\\mu_t\\) follows an autoregressive process of order \\(p\\), i.e., \\(\\mu_t \\sim AR(p)\\). It is standard practice to assume that \\(\\mu_t\\) is second-order stationary, meaning the mean, variance, and autocovariance of \\(\\mu_t\\) are finite and independent of \\(t\\) and \\(s\\), although \\(\\mathbb{E}[\\mu_t \\mu_s]\\) may depend on \\(|t - s|\\). Then, all roots of \\(\\phi(L)\\) lie outside the unit circle. For instance, for an \\(AR(1)\\), \\(1 - \\phi_1 L = 0\\), implying \\(L = 1/\\phi_1\\), such that \\(|\\phi_1| &lt; 1\\) for the process to be second-order stationary. The likelihood function conditional on the first \\(p\\) observations is: \\[\\begin{align*} p(y_{p+1}, \\dots, y_T \\mid y_{p}, \\dots, y_1, \\boldsymbol{\\theta}) &amp;= \\prod_{t=p+1}^{T} p(y_t \\mid \\mathcal{I}_{t-1}, \\boldsymbol{\\theta}) \\\\ &amp;\\propto \\sigma^{-(T-p)} \\exp\\left\\{-\\frac{1}{2\\sigma^2} \\sum_{t=p+1}^T \\left(y_t - \\hat{y}_{t \\mid t-1, \\boldsymbol{\\theta}}\\right)^2 \\right\\} \\end{align*}\\] where \\(\\mathcal{I}_{t-1}\\) is the past information, \\(\\boldsymbol{\\theta}\\) collects all parameters \\((\\boldsymbol{\\beta}, \\phi_1, \\dots, \\phi_p, \\sigma^2)\\), and \\(\\hat{y}_{t \\mid t-1, \\boldsymbol{\\theta}} = (1 - \\phi(L)) y_t + \\phi(L) \\boldsymbol{x}^{\\top} \\boldsymbol{\\beta}\\). We can see that multiplying the first expression in Equation (8.5) by \\(\\phi(L)\\), we can express the model as \\[\\begin{align} y_t^*=\\boldsymbol{x}_t^{*\\top}\\boldsymbol{\\beta}+\\epsilon_t \\tag{8.7} \\end{align}\\] where \\(y_t^*=\\phi(L)Y_t\\) and \\(\\boldsymbol{x}_t^{*}=\\phi(L)\\boldsymbol{x}_t\\). Thus, collecting all observations \\(t=p+1,p+2,\\dots,T\\), we have \\(\\boldsymbol{y}^*=\\boldsymbol{X}^*\\boldsymbol{\\beta}+\\boldsymbol{\\epsilon}\\), where \\(\\boldsymbol{\\epsilon}\\sim N(\\boldsymbol{0},\\sigma^2\\boldsymbol{I}_{T-p})\\), \\(\\boldsymbol{y}^*\\) is a \\(T-p\\) dimensional vector, and \\(\\boldsymbol{X}^*\\) is a \\((T-p)\\times K\\) dimensional matrix. Assuming that \\(\\boldsymbol{\\beta}\\mid \\sigma\\sim N(\\boldsymbol{\\beta}_0,\\sigma^2\\boldsymbol{B}_0)\\), \\(\\sigma^2\\sim IG(\\alpha_0/2,\\delta_0/2)\\) and \\(\\boldsymbol{\\phi}\\sim N(\\boldsymbol{\\phi}_0,\\boldsymbol{\\Phi}_0)\\mathbb{1}(\\boldsymbol{\\phi}\\in S_{\\boldsymbol{\\phi}})\\), where \\(S_{\\boldsymbol{\\phi}}\\) is the stationary region of \\(\\boldsymbol{\\phi}=[\\phi_1 \\ \\dots \\ \\phi_p]^{\\top}\\). Then, Equation (8.7) implies that \\(\\boldsymbol{\\beta}\\mid \\sigma^2,\\boldsymbol{\\phi},\\boldsymbol{y},\\boldsymbol{X}\\sim N(\\boldsymbol{\\beta}_n, \\sigma^2{\\boldsymbol{B}}_n)\\), where \\(\\boldsymbol{B}_n = (\\boldsymbol{B}_0^{-1} + \\boldsymbol{X}^{*\\top}\\boldsymbol{X}^{*})^{-1}\\) and \\(\\boldsymbol{\\beta}_n = \\boldsymbol{B}_n(\\boldsymbol{B}_0^{-1}\\boldsymbol{\\beta}_0 + \\boldsymbol{X}^{*\\top}\\boldsymbol{y}^{*})\\). In addition, \\(\\sigma^2\\mid \\boldsymbol{\\beta},\\boldsymbol{\\phi},\\boldsymbol{y},\\boldsymbol{X}\\sim IG(\\alpha_n/2,\\delta_n/2)\\) where \\(\\alpha_n=\\alpha_0+T-p\\) and \\(\\delta_n=\\delta_0+(\\boldsymbol{y}^*-\\boldsymbol{X}^{*}\\boldsymbol{\\beta})^{\\top}(\\boldsymbol{y}^*-\\boldsymbol{X}^{*}\\boldsymbol{\\beta})+(\\boldsymbol{\\beta}-\\boldsymbol{\\beta}_0)\\boldsymbol{B}_0^{-1}(\\boldsymbol{\\beta}-\\boldsymbol{\\beta}_0)\\). Thus, the previous conditional posterior distributions imply that we can use a Gibbs sampling algorithm to perform inference of these parameters (Siddhartha Chib 1993). We know from Equation q(eq:eq1) that \\(\\mu_t=y_t-\\boldsymbol{x}_t^{\\top}\\boldsymbol{\\beta}\\), from Equation (8.6) that \\(\\mu_t=\\phi_1\\mu_{t-1}+\\dots+\\phi_p\\mu_{t-p}+\\epsilon_t\\), \\(t=p+1,\\dots,T\\). In matrix notation \\(\\boldsymbol{\\mu}=\\boldsymbol{U}\\boldsymbol{\\phi}+\\boldsymbol{\\epsilon}\\), where \\(\\boldsymbol{\\mu}\\) is a \\(T-p\\) dimensional vector, \\(\\boldsymbol{U}\\) is a \\((T-p)\\times p\\) matrix whose \\(t\\)-th row is \\([\\mu_{t-1} \\ \\dots \\ \\mu_{t-p}]\\). Thus, the posterior distribution of \\(\\boldsymbol{\\phi}\\mid \\boldsymbol{\\beta},\\sigma^2,\\boldsymbol{y},\\boldsymbol{X}\\) is \\(N(\\boldsymbol{\\phi}_n, \\boldsymbol{\\Phi}_n)\\mathbb{1}(\\boldsymbol{\\phi}\\in S_{\\boldsymbol{\\phi}})\\), where \\(\\boldsymbol{\\Phi}_n=(\\boldsymbol{\\Phi}_0^{-1}+\\sigma^{-2}\\boldsymbol{U}^{\\top}\\boldsymbol{U})\\) and \\(\\boldsymbol{\\phi}_n=\\boldsymbol{\\Phi}_n(\\boldsymbol{\\Phi}_0^{-1}\\boldsymbol{\\phi}_0+\\sigma^{-2}\\boldsymbol{U}^{\\top}\\boldsymbol{\\mu})\\) (see Exercise 4). Drawing from the model under the stationarity restriction is straightforward: we simply sample from the multivariate normal distribution and discard draws that do not satisfy the stationarity condition. The proportion of draws that meet this restriction represents the conditional probability that the process is stationary. Example: Effects of inflation on interest rate II We specify a dynamic linear model in the example of the effects of inflation on interest rates to account for a potential dynamic relationship. However, we can introduce dynamics in this model by assuming \\[ \\Delta i_t = \\beta_{1} + \\beta_{2} \\Delta inf_t + \\beta_{3} \\Delta def_t + \\mu_t, \\] where \\(\\mu_t = \\phi \\mu_{t-1} + \\epsilon_t\\). This leads to the model: \\[ \\Delta i_t = \\beta_{1}(1-\\phi_1) + \\phi_1 \\Delta i_{t-1} + \\beta_{2}(\\Delta inf_t - \\phi_1 \\Delta inf_{t-1}) + \\beta_{3}(\\Delta def_t - \\phi_1 \\Delta def_{t-1}) + \\epsilon_t. \\] Thus, we again use the dataset 16INTDEF.csv provided by Jeffrey M. Wooldridge (2016) to illustrate linear regressions with \\(AR(1)\\) errors. The following code demonstrates how to implement this application using vague priors, assuming \\(\\alpha_0 = \\delta_0 = 0.01\\), \\(\\boldsymbol{\\beta}_0 = \\boldsymbol{0}\\), \\(\\boldsymbol{B}_0 = \\boldsymbol{I}\\), \\(\\boldsymbol{\\phi}_0 = \\boldsymbol{0}\\), and \\(\\boldsymbol{\\Phi}_0 = \\boldsymbol{I}\\). We use 15,000 MCMC iterations, with a burn-in of 5,000 and a thinning parameter of 5. rm(list = ls()) set.seed(010101) DataIntRate &lt;- read.csv(&quot;https://raw.githubusercontent.com/besmarter/BSTApp/refs/heads/master/DataApp/16INTDEF.csv&quot;, sep = &quot;,&quot;, header = TRUE, quote = &quot;&quot;) attach(DataIntRate) ## The following objects are masked from DataIntRate (pos = 4): ## ## def, i3, inf, Year yt &lt;- diff(i3); ytlag &lt;- dplyr::lag(yt, n = 1) T &lt;- length(yt) Xt &lt;- cbind(diff(inf), diff(def)); Xtlag &lt;- dplyr::lag(Xt, n = 1) K &lt;- dim(Xt)[2] + 1 Reg &lt;- lm(yt ~ ytlag + I(Xt[,-1] - Xtlag)) SumReg &lt;- summary(Reg); SumReg ## ## Call: ## lm(formula = yt ~ ytlag + I(Xt[, -1] - Xtlag)) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.85560 -0.86022 0.04917 0.95966 2.85684 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.07375 0.19570 0.377 0.7081 ## ytlag 0.13495 0.15530 0.869 0.3897 ## I(Xt[, -1] - Xtlag)1 -0.13756 0.07594 -1.811 0.0771 . ## I(Xt[, -1] - Xtlag)2 -0.14807 0.09212 -1.607 0.1153 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.331 on 43 degrees of freedom ## (1 observation deleted due to missingness) ## Multiple R-squared: 0.1506, Adjusted R-squared: 0.09137 ## F-statistic: 2.542 on 3 and 43 DF, p-value: 0.06878 PostSig2 &lt;- function(Beta, Phi){ Xstar&lt;- matrix(NA, T-1, K - 1) ystar &lt;- matrix(NA, T-1, 1) for(t in 2:T){ Xstar[t-1,] &lt;- Xt[t,] - Phi*Xt[t-1,] ystar[t-1,] &lt;- yt[t] - Phi*yt[t-1] } Xstar &lt;- cbind(1, Xstar) an &lt;- T - 1 + a0 dn &lt;- d0 + t(ystar - Xstar%*%Beta)%*%(ystar - Xstar%*%Beta) + t(Beta - b0)%*%B0i%*%(Beta - b0) sig2 &lt;- invgamma::rinvgamma(1, shape = an/2, rate = dn/2) return(sig2) } PostBeta &lt;- function(sig2, Phi){ Xstar&lt;- matrix(NA, T-1, K - 1) ystar &lt;- matrix(NA, T-1, 1) for(t in 2:T){ Xstar[t-1,] &lt;- Xt[t,] - Phi*Xt[t-1,] ystar[t-1,] &lt;- yt[t] - Phi*yt[t-1] } Xstar &lt;- cbind(1, Xstar) XtXstar &lt;- t(Xstar)%*%Xstar Xtystar &lt;- t(Xstar)%*%ystar Bn &lt;- solve(B0i + XtXstar) bn &lt;- Bn%*%(B0i%*%b0 + Xtystar) Beta &lt;- MASS::mvrnorm(1, bn, sig2*Bn) return(Beta) } PostPhi &lt;- function(sig2, Beta){ u &lt;- yt - cbind(1,Xt)%*%Beta U &lt;- u[-T] ustar &lt;- u[-1] UtU &lt;- t(U)%*%U Utu &lt;- t(U)%*%ustar Phin &lt;- solve(Phi0i + sig2^(-1)*UtU) phin &lt;- Phin%*%(Phi0i%*%phi0 + sig2^(-1)*Utu) Phi &lt;- truncnorm::rtruncnorm(1, a = -1, b = 1, mean = phin, sd = Phin^0.5) return(Phi) } # Hyperparameters d0 &lt;- 0.01; a0 &lt;- 0.01 b0 &lt;- rep(0, K); c0 &lt;- 1; B0 &lt;- c0*diag(K); B0i &lt;- solve(B0) phi0 &lt;- 0; Phi0 &lt;- 1; Phi0i &lt;- 1/Phi0 # MCMC parameters mcmc &lt;- 15000 burnin &lt;- 5000 tot &lt;- mcmc + burnin thin &lt;- 1 PostBetas &lt;- matrix(0, mcmc+burnin, K) PostSigma2s &lt;- rep(0, mcmc+burnin) PostPhis &lt;- rep(0, mcmc+burnin) Beta &lt;- rep(0, K); Phi &lt;- 0 sig2 &lt;- SumReg$sigma^2; Phi &lt;- SumReg$coefficients[2,1] Beta &lt;- SumReg$coefficients[c(1,3,4),1] pb &lt;- winProgressBar(title = &quot;progress bar&quot;, min = 0, max = tot, width = 300) for(s in 1:tot){ sig2 &lt;- PostSig2(Beta = Beta, Phi = Phi) PostSigma2s[s] &lt;- sig2 Beta &lt;- PostBeta(sig2 = sig2, Phi = Phi) PostBetas[s,] &lt;- Beta Phi &lt;- PostPhi(sig2 = sig2, Beta = Beta) PostPhis[s] &lt;- Phi setWinProgressBar(pb, s, title=paste( round(s/tot*100, 0), &quot;% done&quot;)) } close(pb) ## NULL keep &lt;- seq((burnin+1), tot, thin) PosteriorBetas &lt;- coda::mcmc(PostBetas[keep,]) summary(PosteriorBetas) ## ## Iterations = 1:15000 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 15000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## [1,] 0.0663 0.1904 0.0015545 0.001554 ## [2,] 0.2293 0.1171 0.0009563 0.001163 ## [3,] -0.1451 0.1704 0.0013913 0.001391 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## var1 -0.307875 -0.05914 0.06597 0.19276 0.4392 ## var2 -0.004462 0.15191 0.22912 0.30839 0.4564 ## var3 -0.475203 -0.25696 -0.14711 -0.03156 0.1918 PosteriorSigma2 &lt;- coda::mcmc(PostSigma2s[keep]) summary(PosteriorSigma2) ## ## Iterations = 1:15000 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 15000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## 1.698250 0.385326 0.003146 0.003462 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## 1.110 1.423 1.643 1.909 2.611 PosteriorPhi &lt;- coda::mcmc(PostPhis[keep]) summary(PosteriorPhi) ## ## Iterations = 1:15000 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 15000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## 0.020208 0.163454 0.001335 0.001705 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## -0.28977 -0.09105 0.01602 0.12843 0.34971 dfBinf &lt;- as.data.frame(PosteriorBetas[,2]) # Basic density library(ggplot2) p &lt;- ggplot(dfBinf, aes(x=var1)) + geom_density(color=&quot;darkblue&quot;, fill=&quot;lightblue&quot;) + geom_vline(aes(xintercept=mean(var1)), color=&quot;blue&quot;, linetype=&quot;dashed&quot;, linewidth=1) + geom_vline(aes(xintercept=quantile(var1, 0.025)), color=&quot;red&quot;, linetype=&quot;dashed&quot;, linewidth=1) + geom_vline(aes(xintercept=quantile(var1, 0.975)), color=&quot;red&quot;, linetype=&quot;dashed&quot;, linewidth=1) + labs(title=&quot;Density effect of inflation on interest rate&quot;, x=&quot;Effect of inflation&quot;, y = &quot;Density&quot;) p This figure shows the posterior density plot of the effects of inflation rate on interest rate. The posterior mean of this coefficient is approximately 0.25, and the credible interval at 95% is (0, 0.46), which indicates again that the annual changes in interest rate are weakly positive related to annual changes in inflation. Observe that the previous setting encompasses the particular relevant case \\(y_t\\sim AR(p)\\), it is just omitting the covariates such that \\(y_t=\\mu_t\\). Siddhartha Chib and Greenberg (1994) extend the Bayesian inference of linear regression with \\(AR(p)\\) errors to \\(ARMA(p,q)\\) errors using a state-space representation. Setting \\(y_t=\\mu_t\\) such that \\(y_t=\\sum_{s=1}^{p}\\phi_jy_{t-s}+\\sum_{s=1}^{q}\\theta_s \\epsilon_{t-s}+\\epsilon_t\\), letting \\(r=\\max \\left\\{p,q+1\\right\\}\\), \\(\\phi_s=0\\) for \\(s&gt;p\\) and \\(\\theta_s=0\\) for \\(s&gt;q\\), and defining \\(\\boldsymbol{x}^{\\top}=[1 \\ 0 \\ \\dots \\ 0]\\), and \\(\\boldsymbol{H}=[1 \\ \\psi_1 \\ \\dots \\ \\psi_{r-1}]^{\\top}\\) \\(r\\)-dimensional vectors, and \\[\\begin{align*} \\boldsymbol{G}=\\begin{bmatrix} \\phi_1 &amp; 1 &amp; 0 &amp; \\dots &amp; 0\\\\ \\phi_2 &amp; 0 &amp; 1 &amp; \\dots &amp; 0\\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; &amp;\\\\ \\phi_{r-1} &amp; 0 &amp; 0 &amp; \\dots &amp; 1\\\\ \\phi_r &amp; 0 &amp; 0 &amp; \\dots &amp; 0\\\\ \\end{bmatrix} = \\begin{bmatrix} \\phi_1 &amp; \\vdots &amp; &amp; &amp; \\\\ \\phi_2 &amp; \\vdots &amp; &amp; \\boldsymbol{I}_{r-1} &amp; \\\\ \\vdots &amp; \\vdots &amp; &amp; &amp;\\\\ \\dots &amp; \\dots &amp; \\dots &amp; \\dots &amp; \\dots\\\\ \\phi_r &amp; 0 &amp; 0 &amp; \\dots &amp; 0\\\\ \\end{bmatrix}, \\end{align*}\\] which is a \\(r\\times r\\) dimensional matrix, and give the state vector \\(\\boldsymbol{\\beta}_t=[\\beta_{1,t} \\ \\beta_{2,t} \\ \\dots \\ \\beta_{r,t}]^{\\top}\\), the \\(ARMA\\) model has the following representation: \\[\\begin{align*} y_t&amp;=\\boldsymbol{x}^{\\top}\\boldsymbol{\\beta}_t\\\\ \\boldsymbol{\\beta}_t &amp;= \\boldsymbol{G}\\boldsymbol{\\beta}_{t-1}+\\boldsymbol{H}\\epsilon_{t}. \\end{align*}\\] This is a dynamic linear model where \\(\\boldsymbol{\\Sigma}_t=0\\), and \\(\\boldsymbol{\\Omega}_t=\\sigma^2\\boldsymbol{H}\\boldsymbol{H}^{\\top}\\) (see Petris, Petrone, and Campagnoli (2009) and Siddhartha Chib and Greenberg (1994)). A notable advantage of the state-space representation of the \\(ARMA\\) model is that the evaluation of the likelihood can be performed efficiently using the recursive laws. Extensions to autoregressive integrated moving average \\(ARIMA(p,d,q)\\) models are discussed in Petris, Petrone, and Campagnoli (2009). In \\(ARIMA(p,d,q)\\) models, \\(d\\) refers to the level of integration (or differencing) required to eliminate the stochastic trend in a time series (see Enders (2014) for details). Example: \\(AR(2)\\) process Let’s see the state-space representation of a stationary \\(AR(2)\\) process with intercept, that is, \\(y_t=\\mu+\\phi_1y_{t-1}+\\phi_2y_{t-2}+\\epsilon_t\\), where \\(\\epsilon_t\\sim N(0,\\sigma^2)\\). Thus, \\(\\mathbb{E}[y_t]=\\frac{\\mu}{1-\\phi_1-\\phi_2}\\), and variance \\(Var[y_t]=\\frac{\\sigma^2(1-\\phi_2)}{1-\\phi_2-\\phi_1^2-\\phi_1^2\\phi_2-\\phi_2^2+\\phi_2^3}\\). In addition, we can proof that setting \\(z_t=Y_t-\\bar{\\mu}\\), we have \\(z_t=\\phi_1z_{t-1}+\\phi_2z_{t-2}+\\epsilon_t\\) where \\(\\mathbb{E}[z_t]=0\\), and these are equivalent representations (see Exercise 5). Then, setting \\(\\boldsymbol{x}^{\\top}=[1 \\ 0]\\), \\(\\boldsymbol{H}=[1 \\ 0]^{\\top}\\), \\(\\boldsymbol{G}=\\begin{bmatrix} \\phi_1 &amp; 1\\\\ \\phi_2 &amp; 0 \\\\ \\end{bmatrix}\\), \\(\\boldsymbol{\\beta}_t=[\\beta_{t1} \\ \\beta_{t2}]^{\\top}\\), \\(\\boldsymbol{\\Sigma}_t=0\\) and \\(\\boldsymbol{\\Omega}_t=\\sigma^2\\) we have \\[\\begin{align*} z_t&amp;=\\boldsymbol{x}^{\\top}\\boldsymbol{\\beta}_t&amp; \\text{(Observation equation)}\\\\ \\boldsymbol{\\beta}_t&amp;=\\boldsymbol{G}\\boldsymbol{\\beta}_{t-1}+\\boldsymbol{H}{\\epsilon}_t &amp; \\text{(States equations)}. \\end{align*}\\] We use the function stan_sarima from the package bayesforecast to perform Bayesian inference in \\(ARMA\\) models in our GUI. The following code shows how to simulate an \\(AR(2)\\) process, and perform Bayesian inference using this function. We perform 10000 MCMC iterations plus a burn-in equal 5000 assuming \\(\\sigma^2\\sim IG(0.01/2, 0.01/2)\\), \\(\\mu\\sim N(0, 1)\\) and \\(\\phi_k\\sim N(0, 1)\\), \\(k=1,2\\). The trace plots look well, and all 95% credible intervals encompass the population values. rm(list = ls()); set.seed(010101) T &lt;- 200; mu &lt;- 0.5 phi1 &lt;- 0.5; phi2 &lt;- 0.3; sig &lt;- 0.5 Ey &lt;- mu/(1-phi1-phi2); Sigy &lt;- sig*((1-phi2)/(1-phi2-phi1^2-phi2*phi1^2-phi2^2+phi2^3))^0.5 y &lt;- rnorm(T, mean = Ey, sd = Sigy) e &lt;- rnorm(T, mean = 0, sd = sig) for(t in 3:T){ y[t] &lt;- mu + phi1*y[t-1] + phi2*y[t-2] + e[t] } mean(y); sd(y) ## [1] 2.642552 ## [1] 0.7734486 y &lt;- ts(y, start=c(1820, 1), frequency=1) plot(y) iter &lt;- 10000; burnin &lt;- 5000; thin &lt;- 1; tot &lt;- iter + burnin library(bayesforecast) ## Warning: package &#39;bayesforecast&#39; was built under R version 4.3.3 ## Registered S3 methods overwritten by &#39;bayesforecast&#39;: ## method from ## autoplot.ts forecast ## forecast.ts forecast ## fortify.ts forecast ## print.garch tseries ## print.laplace LaplacesDemon ## ## Attaching package: &#39;bayesforecast&#39; ## The following objects are masked from &#39;package:base&#39;: ## ## beta, gamma sf1 &lt;- bayesforecast::stan_sarima(y, order = c(2, 0, 0), prior_mu0 = normal(0, 1), prior_ar = normal(0, 1), prior_sigma0 = inverse.gamma(0.01/2, 0.01/2), seasonal = c(0, 0, 0), iter = tot, warmup = burnin, chains = 1) ## ## SAMPLING FOR MODEL &#39;Sarima&#39; NOW (CHAIN 1). ## Chain 1: ## Chain 1: Gradient evaluation took 9.4e-05 seconds ## Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.94 seconds. ## Chain 1: Adjust your expectations accordingly! ## Chain 1: ## Chain 1: ## Chain 1: Iteration: 1 / 15000 [ 0%] (Warmup) ## Chain 1: Iteration: 1500 / 15000 [ 10%] (Warmup) ## Chain 1: Iteration: 3000 / 15000 [ 20%] (Warmup) ## Chain 1: Iteration: 4500 / 15000 [ 30%] (Warmup) ## Chain 1: Iteration: 5001 / 15000 [ 33%] (Sampling) ## Chain 1: Iteration: 6500 / 15000 [ 43%] (Sampling) ## Chain 1: Iteration: 8000 / 15000 [ 53%] (Sampling) ## Chain 1: Iteration: 9500 / 15000 [ 63%] (Sampling) ## Chain 1: Iteration: 11000 / 15000 [ 73%] (Sampling) ## Chain 1: Iteration: 12500 / 15000 [ 83%] (Sampling) ## Chain 1: Iteration: 14000 / 15000 [ 93%] (Sampling) ## Chain 1: Iteration: 15000 / 15000 [100%] (Sampling) ## Chain 1: ## Chain 1: Elapsed Time: 5.066 seconds (Warm-up) ## Chain 1: 10.572 seconds (Sampling) ## Chain 1: 15.638 seconds (Total) ## Chain 1: keep &lt;- seq(burnin+1, tot, thin) Postmu &lt;- sf1[[&quot;stanfit&quot;]]@sim[[&quot;samples&quot;]][[1]][[&quot;mu0&quot;]][keep] Postsig &lt;- sf1[[&quot;stanfit&quot;]]@sim[[&quot;samples&quot;]][[1]][[&quot;sigma0&quot;]][keep] Postphi1 &lt;- sf1[[&quot;stanfit&quot;]]@sim[[&quot;samples&quot;]][[1]][[&quot;ar0[1]&quot;]][keep] Postphi2 &lt;- sf1[[&quot;stanfit&quot;]]@sim[[&quot;samples&quot;]][[1]][[&quot;ar0[2]&quot;]][keep] Postdraws &lt;- coda::mcmc(cbind(Postmu, Postsig, Postphi1, Postphi2)) summary(Postdraws) ## ## Iterations = 1:10000 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 10000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## Postmu 0.6628 0.13547 0.0013547 0.0017646 ## Postsig 0.5260 0.02700 0.0002700 0.0003311 ## Postphi1 0.5624 0.06932 0.0006932 0.0009865 ## Postphi2 0.1916 0.06782 0.0006782 0.0009535 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## Postmu 0.39914 0.5732 0.6625 0.7518 0.9346 ## Postsig 0.47696 0.5071 0.5248 0.5439 0.5829 ## Postphi1 0.42384 0.5159 0.5634 0.6089 0.6979 ## Postphi2 0.06034 0.1456 0.1920 0.2361 0.3286 The following Algorithm shows how to perform inference in \\(ARMA(p,q)\\) models using our GUI. See also Chapter 5 for details regarding the dataset structure. Algorithm: Autoregressive Moving Average (ARMA) Models Select Time series Model on the top panel Select ARMA using the left radio button Upload the dataset selecting first if there is a header in the file, and the kind of separator in the csv file of the dataset (comma, semicolon, or tab). Then, use the Browse button under the Choose File legend Select MCMC iterations, burn-in, and thinning parameters using the Range sliders Set the order of the ARMA model, p and q parameters Set the frequency: annual (1), quarterly (4), monthly (12), etc. Set the location and scale hyperparameters of the intercept, autoregressive (AR), moving average (MA) and standard deviation. Take into account that there is just one set of hyperparameters for AR and MA coefficients. This step is not necessary as by default our GUI uses non-informative priors Click the Go! button Analyze results Download posterior chains and figures (density, autocorrelation and trace plots) using the Download Results button The function stan_sarima uses the Stan software (Stan Development Team 2024), which in turn employs Hamiltonian Monte Carlo (HMC). The following code illustrates how to perform Bayesian inference in the \\(AR(2)\\) model by programming the HMC from scratch. It is important to note that this is only an illustration, as HMC is less efficient than the Gibbs sampler in this example. However, HMC can outperform traditional MCMC algorithms in more complex models, particularly when dealing with high-dimensional probability distributions or when MCMC struggles with poor mixing due to posterior correlation. In the first block, we perform the simulation by setting \\(\\mu=0.5\\), \\(\\phi_1=0.5\\), \\(\\phi_2=0.3\\), \\(\\sigma=0.25\\), and a sample size of 200. We then set the hyperparameters and define the function to calculate the logarithm of the posterior distribution. The model is parametrized using \\(\\tau = \\log(\\sigma^2)\\), such that \\(\\sigma^2=\\exp(\\tau)\\), which avoids issues related to the non-negativity restriction of \\(\\sigma^2\\). As a result, we need to account for the Jacobian due to this transformation, specifically \\(d\\sigma^2/d\\tau = \\exp(\\tau)\\). Next, we define the function to compute the gradient vector of the log posterior distribution. It is preferable to calculate the gradient vector analytically, as using finite differences can be computationally expensive. However, it is a good practice to check the analytical calculations by evaluating the function at the maximum posterior estimate, where the function should return values close to 0, or by comparing the results with finite differences at a few evaluation points. The posterior distribution is given by45 \\[\\begin{align*} \\pi(\\mu,\\phi_1,\\phi_2,\\tau\\mid \\boldsymbol{y})&amp;\\propto \\prod_{t=3}^T(\\exp(\\tau))^{-1/2}\\exp\\left\\{-\\frac{1}{2\\exp(\\tau)}(y_t-\\mu-\\phi_1y_{t-1}-\\phi_2y_{t-2})^2\\right\\}\\\\ &amp;\\times\\exp\\left\\{-\\frac{1}{2\\sigma^2_{\\mu}}(\\mu-\\mu_0)^2\\right\\}\\times\\exp\\left\\{-\\frac{1}{2\\sigma^2_{\\phi_1}}(\\phi_1-\\phi_{10})^2\\right\\}\\\\ &amp;\\times\\exp\\left\\{-\\frac{1}{2\\sigma^2_{\\phi_2}}(\\phi_2-\\phi_{20})^2\\right\\}\\times\\exp\\left\\{-(\\alpha_0/2+1)\\tau\\right\\}\\exp\\left\\{-\\delta_0/(2\\exp(\\tau))\\right\\}\\exp(\\tau). \\end{align*}\\] The components of the gradient vector of the log posterior distribution are given by \\[\\begin{align*} \\frac{\\partial \\log(\\pi(\\mu,\\phi_1,\\phi_2,\\tau\\mid \\boldsymbol{y}))}{\\partial\\mu}&amp;=\\frac{\\sum_{t=3}^T(y_t-\\mu-\\phi_1y_{t-1}-\\phi_2y_{t-2})}{\\exp(\\tau)}-\\frac{1}{\\sigma_{\\mu}^2}(\\mu-\\mu_0)\\\\ \\frac{\\partial\\log(\\pi(\\mu,\\phi_1,\\phi_2,\\tau\\mid \\boldsymbol{y}))}{\\partial\\phi_1}&amp;=\\frac{\\sum_{t=3}^T(y_t-\\mu-\\phi_1y_{t-1}-\\phi_2y_{t-2})y_{t-1}}{\\exp(\\tau)}-\\frac{1}{\\sigma_{\\phi_1}^2}(\\phi_1-\\phi_{10})\\\\ \\frac{\\partial\\log(\\pi(\\mu,\\phi_1,\\phi_2,\\tau\\mid \\boldsymbol{y}))}{\\partial\\phi_2}&amp;=\\frac{\\sum_{t=3}^T(y_t-\\mu-\\phi_1y_{t-1}-\\phi_2y_{t-2})y_{t-2}}{\\exp(\\tau)}-\\frac{1}{\\sigma_{\\phi_2}^2}(\\phi_2-\\phi_{20})\\\\ \\frac{\\partial\\log(\\pi(\\mu,\\phi_1,\\phi_2,\\tau\\mid \\boldsymbol{y}))}{\\partial\\tau}&amp;=-\\frac{(T-2)}{2}+\\frac{\\sum_{t=3}^T(y_t-\\mu-\\phi_1y_{t-1}-\\phi_2y_{t-2})^2}{2\\exp(\\tau)}\\\\ &amp;-(\\alpha_0/2+1)+\\delta_0/(2\\exp(\\tau))+1.\\\\ \\end{align*}\\] Next, we provide the code for the Hamiltonian Monte Carlo, as outlined in Chapter 4. The initial values are set as follows: \\(\\mu=\\bar{y}=\\frac{1}{T-2}\\sum_{t=3}^T y_t\\), \\(\\phi_1=\\phi_2=0\\), and \\(\\tau=\\exp\\left(\\frac{1}{T-2}\\sum_{t=3}^T(y_t-\\bar{y})^2\\right)\\), with \\(M\\) being the inverse covariance matrix of the posterior distribution evaluated at its maximum. Additionally, \\(\\epsilon\\) is randomly drawn from a uniform distribution between 0 and \\(2\\epsilon_0\\), and \\(L\\) is set to the highest integer near \\(1/\\epsilon\\), in order to approximately satisfy \\(L\\epsilon=1\\), where \\(\\epsilon_0=0.1\\). We can verify that all 95% credible intervals encompass the population values, and the posterior means are close to the population values. The acceptance rate averages above 65%, so we should consider increasing the base step (\\(\\epsilon_0\\)). Furthermore, we do not impose the stationarity conditions on \\(\\phi_1\\) and \\(\\phi_2\\). Exercise 6 asks to program an HMC that takes these requirements into account. # Simulation AR(2) rm(list = ls()); set.seed(010101); T &lt;- 1000; K &lt;- 4 mu &lt;- 0.5; phi1 &lt;- 0.5; phi2 &lt;- 0.3; sig &lt;- 0.5 Ey &lt;- mu/(1-phi1-phi2); Sigy &lt;- sig*((1-phi2)/(1-phi2-phi1^2-phi2*phi1^2-phi2^2+phi2^3))^0.5 y &lt;- rnorm(T, mean = Ey, sd = Sigy); e &lt;- rnorm(T, mean = 0, sd = sig) for(t in 3:T){ y[t] &lt;- mu + phi1*y[t-1] + phi2*y[t-2] + e[t] } # Hyperparameters d0 &lt;- 0.01; a0 &lt;- 0.01; mu0 &lt;- 0; MU0 &lt;- 1 phi0 &lt;- c(0, 0); Phi0 &lt;- diag(2) # Log posterior multiply by -1 to use optim LogPost &lt;- function(theta, y){ mu &lt;- theta[1]; phi1 &lt;- theta[2]; phi2 &lt;- theta[3] tau &lt;- theta[4]; sig2 &lt;- exp(tau); logLik &lt;- NULL for(t in 3:T){ logLikt &lt;- dnorm(y[t], mean = mu + phi1*y[t-1] + phi2*y[t-2], sd = sig2^0.5, log = TRUE) logLik &lt;- c(logLik, logLikt) } logLik &lt;- sum(logLik) logPrior &lt;- dnorm(mu, mean = mu0, sd = MU0^0.5, log = TRUE) + dnorm(phi1, mean = phi0[1], sd = Phi0[1,1]^0.5, log = TRUE) + dnorm(phi2, mean = phi0[2], sd = Phi0[2,2]^0.5, log = TRUE) + invgamma::dinvgamma(sig2, shape = a0/2, rate = d0/2, log = TRUE) logPosterior &lt;- logLik + logPrior + tau return(-logPosterior) # Multiply by -1 to minimize using optim } theta0 &lt;- c(mean(y), 0, 0, var(y)) Opt &lt;- optim(theta0, LogPost, y = y, hessian = TRUE) theta0 &lt;- Opt$par; VarPost &lt;- solve(Opt$hessian) # Gradient log posterior GradientTheta &lt;- function(theta, y){ mu &lt;- theta[1]; phi1 &lt;- theta[2]; phi2 &lt;- theta[3] tau &lt;- theta[4]; sig2 &lt;- exp(tau); SumLik &lt;- matrix(0, 3, 1) SumLik2 &lt;- NULL for(t in 3:T){ xt &lt;- matrix(c(1, y[t-1], y[t-2]), 3, 1) SumLikt &lt;- (y[t] - (mu + phi1*y[t-1] + phi2*y[t-2]))*xt SumLik2t &lt;- (y[t] - (mu + phi1*y[t-1] + phi2*y[t-2]))^2 SumLik &lt;- rowSums(cbind(SumLik, SumLikt)) SumLik2 &lt;- sum(SumLik2, SumLik2t) } Grad_mu &lt;- SumLik[1]/sig2 - (1/MU0)*(mu - mu0) Grad_phi1 &lt;- SumLik[2]/exp(tau) - 1/Phi0[1,1]*(phi1 - phi0[1]) Grad_phi2 &lt;- SumLik[3]/exp(tau) - 1/Phi0[2,2]*(phi2 - phi0[2]) Grad_tau &lt;- -(T-2)/2 + SumLik2/(2*exp(tau)) - (a0/2 + 1) + d0/(2*exp(tau)) + 1 Grad &lt;- c(Grad_mu, Grad_phi1, Grad_phi2, Grad_tau) return(Grad) } # Hamiltonian Monte Carlo function HMC &lt;- function(theta, y, epsilon, M){ L &lt;- ceiling(1/epsilon) Minv &lt;- solve(M); thetat &lt;- theta K &lt;- length(thetat) mom &lt;- t(mvtnorm::rmvnorm(1, rep(0, K), M)) logPost_Mom_t &lt;- -LogPost(thetat, y) + mvtnorm::dmvnorm(t(mom), rep(0, K), M, log = TRUE) for(l in 1:L){ if(l == 1 | l == L){ mom &lt;- mom + 0.5*epsilon*GradientTheta(theta, y) theta &lt;- theta + epsilon*Minv%*%mom }else{ mom &lt;- mom + epsilon*GradientTheta(theta, y) theta &lt;- theta + epsilon*Minv%*%mom } } logPost_Mom_star &lt;- -LogPost(theta, y) + mvtnorm::dmvnorm(t(mom), rep(0, K), M, log = TRUE) alpha &lt;- min(1, exp(logPost_Mom_star-logPost_Mom_t)) u &lt;- runif(1) if(u &lt;= alpha){ thetaNew &lt;- c(theta) }else{ thetaNew &lt;- thetat } rest &lt;- list(theta = thetaNew, Prob = alpha) return(rest) } # Posterior draws S &lt;- 1000; burnin &lt;- 1000; thin &lt;- 2; tot &lt;- S + burnin thetaPost &lt;- matrix(NA, tot, K) ProbAccept &lt;- rep(NA, tot) theta0 &lt;- c(mean(y), 0, 0, exp(var(y))) M &lt;- solve(VarPost); epsilon0 &lt;- 0.1 pb &lt;- winProgressBar(title = &quot;progress bar&quot;, min = 0, max = tot, width = 300) for(s in 1:tot){ epsilon &lt;- runif(1, 0, 2*epsilon0) L &lt;- ceiling(1/epsilon) HMCs &lt;- HMC(theta = theta0, y, epsilon, M) theta0 &lt;- HMCs$theta thetaPost[s,] &lt;- HMCs$theta ProbAccept[s] &lt;- HMCs$Prob setWinProgressBar(pb, s, title=paste( round(s/tot*100, 0), &quot;% done&quot;)) } close(pb) ## NULL keep &lt;- seq((burnin+1), tot, thin) thetaF &lt;- coda::mcmc(thetaPost[keep,]) summary(thetaF) ## ## Iterations = 1:500 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 500 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## [1,] 0.4830 0.05773 0.002582 0.003488 ## [2,] 0.5167 0.02843 0.001272 0.001698 ## [3,] 0.2927 0.02918 0.001305 0.001481 ## [4,] -1.3317 0.04577 0.002047 0.002756 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## var1 0.3607 0.4470 0.4864 0.5212 0.5902 ## var2 0.4536 0.5009 0.5160 0.5334 0.5721 ## var3 0.2363 0.2728 0.2923 0.3139 0.3484 ## var4 -1.4202 -1.3604 -1.3331 -1.3020 -1.2431 summary(exp(thetaF[,K])) ## ## Iterations = 1:500 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 500 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## 0.2642942 0.0121270 0.0005423 0.0007275 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## 0.2417 0.2566 0.2637 0.2720 0.2885 ProbAcceptF &lt;- coda::mcmc(ProbAccept[keep]) summary(ProbAcceptF) ## ## Iterations = 1:500 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 500 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## 0.916318 0.129812 0.005805 0.005805 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## 0.5470 0.8746 0.9841 1.0000 1.0000 References "],["sec83.html", "8.3 Stochastic volatility models", " 8.3 Stochastic volatility models A notable example of non-linear and non-Gaussian state-space models is stochastic volatility models (SVMs), which are widely used to model the volatility of financial returns. SVMs have gained significant attention due to their flexibility, ability to capture complex dynamics such as asymmetries, and ease of generalization to simultaneously model multiple returns, making them advantageous over generalized autoregressive conditional heteroskedasticity (GARCH) models proposed by Bollerslev (1986). However, estimating SVMs is more challenging than estimating GARCH models. This is because GARCH models set variance in a deterministic manner, whereas SVMs do so stochastically. Consequently, GARCH models are typically estimated using maximum likelihood methods, while SVMs require Bayesian approaches, adding complexity to the estimation process. The specification of the stochastic volatility model is given by \\[\\begin{align} y_t&amp;=\\boldsymbol{x}_t^{\\top}\\boldsymbol{\\beta}+\\exp\\left\\{0.5h_t\\right\\}\\mu_t&amp; \\text{(Observation equation)} \\tag{8.8}\\\\ h_t&amp;=\\mu+\\phi(h_{t-1}-\\mu)+\\sigma w_t&amp; \\text{(State equation)} \\tag{8.9}, \\end{align}\\] where \\(y_t\\) are the log-returns, \\(\\boldsymbol{x}_t\\) are controls, \\(\\boldsymbol{\\beta}\\) are time-invariant location parameters, \\(\\mu_t\\sim N(0,1)\\), \\(w_t\\sim N(0,1)\\), \\(\\mu_t\\perp w_t\\), the initial log-variance process \\(h_0\\sim N(\\mu, \\sigma^2/(1-\\phi^2))\\), \\(\\mu\\), \\(\\phi\\) and \\(\\sigma\\) are the level, persistence and standard deviation of the log-variance, respectively. Given the specification in Equations (8.8) and (8.9), we can write the observation equation as \\[ \\log\\left\\{(y_t-\\boldsymbol{x}_t^{\\top}\\boldsymbol{\\beta})^2\\right\\} = h_t + \\log(\\mu_t^2), \\] which leads to a linear, but non-Gaussian, state-space model. Kastner and Frühwirth-Schnatter (2014) approximate the distribution of \\(\\log(\\mu_t^2)\\) by a mixture of normal distributions, that is, \\[ \\log(\\mu_t^2)\\mid l_t \\sim N(m_{l_t},s_{l_t}^2), \\] where \\(l_t \\in \\{1, 2, \\dots, 10\\}\\) defines the mixture component indicator at time \\(t\\). Thus, the model can be written as \\[ \\log\\left\\{(y_t-\\boldsymbol{x}_t^{\\top}\\boldsymbol{\\beta})^2\\right\\} = h_t + \\log(\\mu_t^2), \\] and \\[ h_t = \\mu + \\phi(h_{t-1} - \\mu) + \\sigma w_t. \\] This forms a linear and conditionally Gaussian state-space model, where \\[ \\log\\left\\{(y_t-\\boldsymbol{x}_t^{\\top}\\boldsymbol{\\beta})^2\\right\\} = m_{l_t} + h_t + \\mu_t^2, \\] and \\[ \\mu_t \\sim N(0, s_{l_t}^2). \\] We use the stochvol package in our GUI to perform MCMC inference in the SVMs (Hosszejni and Kastner 2021); this package is based on the MCMC algorithms proposed by Kastner and Frühwirth-Schnatter (2014). The default prior distributions in the stochvol package are: \\[ \\boldsymbol{\\beta} \\sim N(\\boldsymbol{b}_0, \\boldsymbol{B}_0), \\quad \\mu \\sim N(\\mu_0, \\sigma_{\\mu0}^2), \\quad \\frac{\\phi+1}{2} \\sim B(\\alpha_0, \\beta_0), \\quad \\sigma^2 \\sim G\\left(\\frac{1}{2}, \\frac{1}{2\\sigma^2_{\\sigma^2}}\\right). \\] The prior distribution for \\(\\phi\\) is set to ensure stationarity of the process (\\(\\phi \\in (-1,1)\\)). In most applications, \\(\\phi \\approx 1\\), so the authors of the package recommend setting \\(\\alpha_0 \\gtrsim 5\\) and \\(\\beta_0 \\approx 1.5\\). The prior distribution for \\(\\sigma\\) is \\(|N(0, \\sigma^2_{\\sigma^2})|\\) (a half-normal distribution). This is recommended by the authors since the conjugate inverse-gamma distribution does not work well in this case, as it bounds \\(\\sigma\\) away from 0, which is undesirable when modeling the log-variance of log-returns. The following Algorithm shows how to perform inference in stochastic volatility models using our GUI. See also Chapter 5 for details regarding the dataset structure. Algorithm: Stochastic Volatility Models Select Time series Model on the top panel Select Stochastic volatility using the left radio button Upload the dataset selecting first if there is a header in the file, and the kind of separator in the csv file of the dataset (comma, semicolon, or tab). Then, use the Browse button under the Choose File legend Select MCMC iterations, burn-in, and thinning parameters using the Range sliders Set the hyperparameters: the mean and standard deviation of the Gaussian prior for the regression parameters, mean and standard deviation for the Gaussian prior distribution of the level of the log-volatility, shape parameters for the Beta prior distribution of the transformed persistence parameter, and the positive real number, which stands for the scaling of the transformed volatility of log-volatility. This step is not necessary as by default our GUI uses default values in the stochvol package Click the Go! button Analyze results Download posterior chains of the fixed coefficients, and the states using the Download Results button Example: Simulation exercise of the stochastic volatility model The following code shows how to simulate and perform Bayesian inference in the stochastic volatility model using the function svsample from the stochvol package. We set the stochastic volatility parameters to \\(\\mu = -10\\), \\(\\phi = 0.95\\), and \\(\\sigma = 0.3\\). We assume two regressors, which are distributed as standard normal, with \\(\\boldsymbol{\\beta} = [0.5 \\ 0.3]^{\\top}\\), and the sample size is 1250, which corresponds to approximately 5 years of daily returns. We use the default hyperparameters: 10000 MCMC iterations, a burn-in of 5000, and a thinning parameter of 5. The summary statistics of the posterior draws show that all 95% credible intervals encompass the population parameters, and the posterior chains appear to have converged. The Figure displays the posterior results for the volatility (\\(h_t\\)). The posterior mean (blue) follows the “observed” series (black), and the 95% credible intervals (light blue) typically encompass the “observed” series. rm(list = ls()); set.seed(010101) T &lt;- 1250; K &lt;- 2 X &lt;- matrix(rnorm(T*K), T, K) B &lt;- c(0.5, 0.3); mu &lt;- -10; phi &lt;- 0.95; sigma &lt;- 0.3 h &lt;- numeric(T); y &lt;- numeric(T) h[1] &lt;- rnorm(1, mu, sigma / sqrt(1 - phi^2)) # Initial state y[1] &lt;- X[1,]%*%B + rnorm(1, 0, exp(h[1] / 2)) # Initial observation for (t in 2:T) { h[t] &lt;- mu + phi*(h[t-1]-mu) + rnorm(1, 0, sigma) y[t] &lt;- X[t,]%*%B + rnorm(1, 0, sd = exp(0.5*h[t])) } df &lt;- as.data.frame(cbind(y, X)) colnames(df) &lt;- c(&quot;y&quot;, &quot;x1&quot;, &quot;x2&quot;) MCMC &lt;- 10000; burnin &lt;- 10000; thin &lt;- 5 res &lt;- stochvol::svsample(y, designmatrix = X, draws = MCMC, burnin = burnin, thin = thin, priormu = c(0, 100), priorsigma = c(1), priorphi = c(5, 1.5), priorbeta = c(0, 10000)) ## Done! ## Summarizing posterior draws... summary(res[[&quot;para&quot;]][[1]][,-c(4,5)]) ## ## Iterations = 10005:20000 ## Thinning interval = 5 ## Number of chains = 1 ## Sample size per chain = 2000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## mu -9.9350 0.14258 0.0031882 0.0034505 ## phi 0.9414 0.01661 0.0003714 0.0009051 ## sigma 0.2733 0.03855 0.0008619 0.0024256 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## mu -10.2077 -10.0238 -9.9301 -9.8439 -9.6508 ## phi 0.9032 0.9315 0.9434 0.9531 0.9689 ## sigma 0.2077 0.2461 0.2700 0.2961 0.3608 summary(res[[&quot;beta&quot;]]) ## ## Iterations = 10005:20000 ## Thinning interval = 5 ## Number of chains = 1 ## Sample size per chain = 2000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## beta_0 0.5001 0.0001851 4.139e-06 3.936e-06 ## beta_1 0.2999 0.0001799 4.023e-06 4.023e-06 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## beta_0 0.4997 0.4999 0.5001 0.5002 0.5004 ## beta_1 0.2995 0.2998 0.2999 0.3000 0.3002 ht &lt;- res[[&quot;latent&quot;]][[1]] library(dplyr) library(ggplot2) library(latex2exp) ggplot2::theme_set(theme_bw()) x_means &lt;- colMeans(ht) x_quantiles &lt;- apply(ht, 2, function(x) quantile(x, probs = c(0.025, 0.975))) df &lt;- tibble(t = seq(1, T), mean = x_means, lower = x_quantiles[1, ], upper = x_quantiles[2, ], x_true = h, observations = y) plot_filtering_estimates &lt;- function(df) { pchap8 &lt;- ggplot(data = df, aes(x = t)) + geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 1, fill = &quot;lightblue&quot;) + geom_line(aes(y = x_true), colour = &quot;black&quot;, alpha = 1, linewidth = 0.5) + geom_line(aes(y = mean), colour = &quot;blue&quot;, linewidth = 0.5) + ylab(TeX(&quot;$h_{t}$&quot;)) + xlab(&quot;Time&quot;) print(pchap8) } plot_filtering_estimates(df) So far, we have used MCMC algorithms to perform inference in state-space models. These algorithms require all observations to estimate the unknown parameters, a process referred to as offline or batch inference. However, this approach has limitations when online inference is needed, as every new observation requires simulating a new posterior chain. This is because MCMC algorithms do not naturally adapt to sequential updates. In contrast, particle filter algorithms, which are a subset of sequential Monte Carlo (SMC) methods, are specifically designed for sequential use, making them suitable for online inference. Remember from Chapter 4 that particle filters (sequential Monte Carlo) are algorithms that allow computing a numerical approximation to the filtering distribution \\(\\pi(\\boldsymbol{\\theta}_{1:t}\\mid \\boldsymbol{y}_{1:t})\\) sequentially in time. This is particularly relevant in non-linear and non-Gaussian models where there is no analytical solution for the filtering distribution. The following code shows how to perform particle filtering in the vanilla stochastic volatility model assuming that the proposal distribution is the conditional prior distribution, that is, \\(q(h_t\\mid h_{t-1},y_t)=\\pi(h_t\\mid h_{t-1})\\), which is normal with mean \\(\\mu+\\phi(h_{t-1}-\\mu)\\) and variance \\(\\sigma^2\\). This choice implies that the incremental importance weights are equal to \\(p(y_t\\mid h_t)\\), which is \\(N(0,\\exp(h_t))\\). Therefore, the weights are proportional to the likelihood function. We perform multinomial resampling every time period in the code, and start the algorithm in the stationary distribution of \\(h_t\\). Remember that there are other resampling approaches that are more efficient, for instance, residual resampling. We ask in Exercise 7 to modify this code to perform resampling when the effective sample size is lower than 50% of the initial number of particles. In addition, we ask to program a sequential importance sampling, and check why is important to perform resampling in this simple example. rm(list = ls()); set.seed(010101) T &lt;- 1250; mu &lt;- -10; phi &lt;- 0.95; sigma &lt;- 0.3 h &lt;- numeric(T); y &lt;- numeric(T) h[1] &lt;- rnorm(1, mu, sigma / sqrt(1 - phi^2)) y[1] &lt;- rnorm(1, 0, exp(h[1] / 2)) for (t in 2:T) { h[t] &lt;- mu + phi*(h[t-1]-mu) + rnorm(1, 0, sigma) y[t] &lt;- rnorm(1, 0, sd = exp(0.5*h[t])) } N &lt;- 10000 log_Weights &lt;- matrix(NA, N, T) # Log weights Weights &lt;- matrix(NA, N, T) # Weights WeightsST &lt;- matrix(NA, N, T) # Normalized weights WeightsSTT &lt;- matrix(1/N, N, T) # Normalized weights bar particles &lt;- matrix(NA, N, T) # Particles particlesT &lt;- matrix(NA, N, T) # Particles bar logalphas &lt;- matrix(NA, N, T) # Incremental importance particles[, 1] &lt;- rnorm(N, mu, sigma / sqrt(1 - phi^2)) # Stationary prior log_Weights[, 1] &lt;- dnorm(y[1], 0, sd = exp(0.5*particles[,1]), log = TRUE) # Likelihood Weights[, 1] &lt;- exp(log_Weights[, 1]) WeightsST[, 1] &lt;- Weights[, 1] / sum(Weights[, 1]) ind &lt;- sample(1:N, size = N, replace = TRUE, prob = WeightsST[, 1]) # Resample particles[, 1] &lt;- particles[ind, 1] # Resampled particles particlesT[, 1] &lt;- particles[, 1] # Resampled particles WeightsST[, 1] &lt;- rep(1/N, N) # Resampled weights pb &lt;- winProgressBar(title = &quot;progress bar&quot;, min = 0, max = T, width = 300) for (t in 2:T) { particles[, t] &lt;- rnorm(N, mu + phi*(particles[, t - 1] - mu), sigma) # Sample from proposal logalphas[, t] &lt;- dnorm(y[t], 0, sd = exp(0.5*particles[,t]), log = TRUE) Weights[, t] &lt;- exp(logalphas[, t]) WeightsST[, t] &lt;- Weights[, t] / sum(Weights[, t]) if(t &lt; T){ ind &lt;- sample(1:N, size = N, replace = TRUE, prob = WeightsST[, t]) particles[, 1:t] &lt;- particles[ind, 1:t] }else{ ind &lt;- sample(1:N, size = N, replace = TRUE, prob = WeightsST[, t]) particlesT[, 1:t] &lt;- particles[ind, 1:t] } setWinProgressBar(pb, t, title=paste( round(t/T*100, 0), &quot;% done&quot;)) } close(pb) ## NULL FilterDist &lt;- colSums(particles * WeightsST) SDFilterDist &lt;- (colSums(particles^2 * WeightsST) - FilterDist^2)^0.5 FilterDistT &lt;- colSums(particlesT * WeightsSTT) SDFilterDistT &lt;- (colSums(particlesT^2 * WeightsSTT) - FilterDistT^2)^0.5 MargLik &lt;- colMeans(Weights) # plot(MargLik, type = &quot;l&quot;) library(dplyr) library(ggplot2) require(latex2exp) ggplot2::theme_set(theme_bw()) Tfig &lt;- 250 keepFig &lt;- 1:Tfig df &lt;- tibble(t = keepFig, mean = FilterDist[keepFig], lower = FilterDist[keepFig] - 2*SDFilterDist[keepFig], upper = FilterDist[keepFig] + 2*SDFilterDist[keepFig], meanT = FilterDistT[keepFig], lowerT = FilterDistT[keepFig] - 2*SDFilterDistT[keepFig], upperT = FilterDistT[keepFig] + 2*SDFilterDistT[keepFig], x_true = h[keepFig]) plot_filtering_estimates &lt;- function(df) { pchap8l &lt;- ggplot(data = df, aes(x = t)) + geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 1, fill = &quot;lightblue&quot;) + geom_line(aes(y = x_true), colour = &quot;black&quot;, alpha = 1, linewidth = 0.5) + geom_line(aes(y = mean), colour = &quot;blue&quot;, linewidth = 0.5) + geom_line(aes(y = meanT), colour = &quot;purple&quot;, linewidth = 0.5) + ylab(TeX(&quot;$h_{t}$&quot;)) + xlab(&quot;Time&quot;) print(pchap8l) } plot_filtering_estimates(df) The Figure illustrates the filtering recursion using SMC with uneven weights (blue line), even weights (purple line), bands corresponding to plus/minus two standard deviations (light blue shaded area), and the true state (black line).46 The results indicate that SMC performs well even with a simple implementation, with no significant differences between using even and uneven weights (see Chapter 4). In this example, we use the population parameters to perform the filtering recursion. However, this is not the case in practice, as we must estimate the time-invariant parameters. Therefore, more elaborate algorithms are required to achieve this. For instance, Christophe Andrieu, Doucet, and Holenstein (2010) propose particle Markov chain Monte Carlo, a family of methods that combines MCMC and SMC. See Dahlin and Schön (2019) for a tutorial on particle Metropolis-Hastings in R. A potential practical solution for applications that require sequential updating of a posterior distribution over an unbounded time horizon is to estimate the time-invariant parameters offline using MCMC algorithms up to a specific time period, and then update the state vector sequentially online during subsequent time periods, iterating this process. This is not optimal, but it can be practical. References "],["sec84.html", "8.4 Vector Autoregressive models", " 8.4 Vector Autoregressive models Another widely used methodological approach in time series analysis is the vector autoregressive (VAR) model, which extends AR(p) models to the multivariate case. Since the seminal work by Sims (1980) (Sims 1980), these models have become a cornerstone of macroeconomic research to perform forecasts, and impulse-response (structural) analysis. This chapter provides an introduction to Bayesian inference in VAR models, with detailed discussions available in Gary Koop, Korobilis, et al. (2010), Del Negro and Schorfheide (2011), Woźniak (2016), and Chan et al. (2019). The reduced-form VAR(p) model can be written as \\[\\begin{align} \\boldsymbol{y}_t=\\boldsymbol{v} + \\sum_{j=1}^p\\boldsymbol{A}_{j}\\boldsymbol{y}_{t-j}+\\boldsymbol{\\mu}_t, \\tag{8.10} \\end{align}\\] where \\(\\boldsymbol{y}_t\\) is a \\(M\\)-dimensional vector having information of \\(M\\) time series variables, \\(\\boldsymbol{v}\\) is a \\(M\\)-dimensional vector of intercepts, \\(\\boldsymbol{A}_{j}\\) are \\(M\\times M\\) matrices of coefficients, and \\(\\boldsymbol{\\mu}_t \\stackrel{iid}{\\sim} N_M(\\boldsymbol{0}, \\boldsymbol{\\Sigma})\\) are stochastic errors, \\(t=1,2,\\dots,T\\) and \\(j=1,2,\\dots,p\\). Other deterministic terms and exogenous variables can be added to the specification without main difficulty, we do not do this to keep simply the notation. In addition, we assume that the stability condition is satisfied such that the stochastic process is stationary (see Helmut (2005) Chap. 2 for details), and we have available \\(p\\) presample values for each variable. Following the matrix-form notation of the multivariate regression model (see sections 3.4 and 7.1), we can set \\(\\boldsymbol{Y}=\\left[{\\boldsymbol{y_{1}}} \\ {\\boldsymbol{y_{2}}} \\ \\ldots \\ {\\boldsymbol{y_{M}}}\\right]\\), which is an \\(T \\times M\\) matrix, \\(\\boldsymbol{x}_t=[1 \\ \\boldsymbol{y}_{t-1}^{\\top} \\ \\dots \\ \\boldsymbol{y}_{t-p}^{\\top}]\\) is a \\((1+Mp)\\)-dimensional row vector, we define \\(K=1+Mp\\) to facilitate notation, and set \\[\\begin{align*} \\boldsymbol{X}=\\begin{bmatrix} \\boldsymbol{x}_1\\\\ \\boldsymbol{x}_2\\\\ \\vdots \\\\ \\boldsymbol{x}_T\\\\ \\end{bmatrix}, \\end{align*}\\] which is a \\(T\\times K\\) matrix, \\(\\boldsymbol{B}=\\left[\\boldsymbol{v} \\ \\boldsymbol{A}_{1} \\ \\boldsymbol{A}_{2} \\ldots \\boldsymbol{A}_{P}\\right]^{\\top}\\) is a \\(K \\times M\\) matrix of parameters, and \\(\\boldsymbol{U}=\\left[\\boldsymbol{\\mu}_{1} \\ \\boldsymbol{\\mu}_{2}\\ldots \\boldsymbol{\\mu}_{M}\\right]\\) is a \\(T\\times M\\)-dimensional matrix of stochastic random errors such that \\(\\boldsymbol{U}\\sim N_{T\\times M}(\\boldsymbol{0}_{T\\times M},\\boldsymbol{\\Sigma}\\otimes \\boldsymbol{I}_T)\\). Thus, we can express the VAR(p) model in the form of a multivariate regression model, \\[\\begin{align*} \\boldsymbol{Y}=\\boldsymbol{X}\\boldsymbol{B}+\\boldsymbol{U}. \\end{align*}\\] We can assume conjugate priors to facilitate computation, that is, \\[ \\pi({\\boldsymbol{B}}, {\\boldsymbol{\\Sigma}}) = \\pi({\\boldsymbol{B}} \\mid {\\boldsymbol{\\Sigma}}) \\pi({\\boldsymbol{\\Sigma}}), \\] where \\({\\boldsymbol{B}} \\mid {\\boldsymbol{\\Sigma}} \\sim N_{K \\times M}({\\boldsymbol{B}}_{0}, {\\boldsymbol{V}}_{0}, {\\boldsymbol{\\Sigma}})\\) and \\({\\boldsymbol{\\Sigma}} \\sim IW({\\boldsymbol{\\Psi}}_{0}, \\alpha_{0})\\). Thus, \\[ \\pi({\\boldsymbol{B}}, {\\boldsymbol{\\Sigma}} \\mid {\\boldsymbol{Y}}, {\\boldsymbol{X}}) = \\pi({\\boldsymbol{B}} \\mid {\\boldsymbol{\\Sigma}}, {\\boldsymbol{Y}}, {\\boldsymbol{X}}) \\pi({\\boldsymbol{\\Sigma}} \\mid {\\boldsymbol{Y}}, {\\boldsymbol{X}}), \\] where \\({\\boldsymbol{B}} \\mid {\\boldsymbol{\\Sigma}}, {\\boldsymbol{Y}}, {\\boldsymbol{X}} \\sim N_{K \\times M}({\\boldsymbol{B}}_n, {\\boldsymbol{V}}_n, {\\boldsymbol{\\Sigma}})\\) and \\({\\boldsymbol{\\Sigma}} \\mid {\\boldsymbol{Y}}, {\\boldsymbol{X}} \\sim IW({\\boldsymbol{\\Psi}}_n, \\alpha_n)\\). The quantities \\({\\boldsymbol{B}}_n\\), \\({\\boldsymbol{V}}_n\\), \\({\\boldsymbol{\\Psi}}_n\\), and \\(\\alpha_n\\) are given by the following expressions: \\[ {\\boldsymbol{B}}_n = ({\\boldsymbol{V}}_{0}^{-1} + {\\boldsymbol{X}}^{\\top}{\\boldsymbol{X}})^{-1}({\\boldsymbol{V}}_{0}^{-1}{\\boldsymbol{B}}_{0} + {\\boldsymbol{X}}^{\\top}{\\boldsymbol{X}} \\widehat{\\boldsymbol{B}}), \\] \\[ {\\boldsymbol{V}}_n = ({\\boldsymbol{V}}_{0}^{-1} + {\\boldsymbol{X}}^{\\top}{\\boldsymbol{X}})^{-1}, \\] \\[ {\\boldsymbol{\\Psi}}_n = {\\boldsymbol{\\Psi}}_{0} + {\\boldsymbol{S}} + {\\boldsymbol{B}}_{0}^{\\top}{\\boldsymbol{V}}_{0}^{-1}{\\boldsymbol{B}}_{0} + \\widehat{\\boldsymbol{B}}^{\\top}{\\boldsymbol{X}}^{\\top}{\\boldsymbol{X}} \\widehat{\\boldsymbol{B}} - {\\boldsymbol{B}}_n^{\\top} {\\boldsymbol{V}}_n^{-1} {\\boldsymbol{B}}_n, \\] \\[ {\\boldsymbol{S}} = ({\\boldsymbol{Y}} - {\\boldsymbol{X}} \\widehat{\\boldsymbol{B}})^{\\top}({\\boldsymbol{Y}} - {\\boldsymbol{X}} \\widehat{\\boldsymbol{B}}), \\] \\[ \\widehat{\\boldsymbol{B}} = ({\\boldsymbol{X}}^{\\top}{\\boldsymbol{X}})^{-1}{\\boldsymbol{X}}^{\\top}{\\boldsymbol{Y}}, \\] and \\[ \\alpha_n = T + \\alpha_0. \\] Thus, we see that once we express a VAR(p) model in the correct form, we can perform Bayesian inference as we did in the multivariate regression model. However, assuming conjugate priors has some limitations. First, VAR(p) models have many parameters. For instance, with 4 lags and 6 variables, we would have 150 location parameters (\\((1 + (6 \\times 4)) \\times 6\\)) and 21 scale parameters (\\(6 \\times (6 + 1)/2\\)) for the covariance matrix. This can lead to a loss of precision, especially when using macroeconomic data, due to the typical lack of large sample sizes. Therefore, it is desirable to impose prior restrictions on the model specification, which cannot be achieved using conjugate priors. Second, natural conjugate priors do not allow for flexible extensions, such as having different regressors in different equations. Third, the prior structure implies that the prior covariance of the coefficients in any two equations must be proportional to each other. This is because the prior covariance form is \\(\\boldsymbol{\\Sigma} \\otimes \\boldsymbol{V}_0\\). However, this does not always make sense in certain applications. For example, imposing zero prior restrictions on some coefficients would imply that the prior variance of these coefficients should be near zero, but this does not need to be true for all coefficients in the model. To address the first issue, we can think of the VAR(p) specification in a similar way to the seemingly unrelated regression (SUR) model, where we have different regressors in different equations and account for unobserved dependence. This approach allows us to impose zero restrictions on the VAR(p) model, thereby improving its parsimony. Following the setup in Section 7.2, we have \\[ \\boldsymbol{y}_{m} = \\boldsymbol{Z}_{m} \\boldsymbol{\\beta}_m + \\boldsymbol{\\mu}_m, \\] where \\(\\boldsymbol{y}_m\\) is a \\(T\\)-dimensional vector corresponding to the \\(m\\)-th time series variable, \\(\\boldsymbol{Z}_m\\) is a \\(T \\times K_m\\) matrix of regressors, \\(\\boldsymbol{\\beta}_m\\) is a \\(K_m\\)-dimensional vector of location parameters, and \\(\\boldsymbol{\\mu}_m\\) is a \\(T\\)-dimensional vector of stochastic errors, for \\(m = 1, 2, \\dots, M\\). Stacking the \\(M\\) equations, we can write \\(\\boldsymbol{y}=\\boldsymbol{Z}\\boldsymbol{\\beta}+\\boldsymbol{\\mu}\\) where \\(\\boldsymbol{y}=\\left[\\boldsymbol{y}_{1}^{\\top} \\ \\boldsymbol{y}_{2}^{\\top} \\dots \\boldsymbol{y}_{M}^{\\top}\\right]^{\\top}\\) is a \\(MT\\)-dimensional vector, \\(\\boldsymbol{\\beta}=\\left[\\boldsymbol{\\beta}_{1}^{\\top} \\ \\boldsymbol{\\beta}_{2}^{\\top} \\ldots \\boldsymbol{\\beta}_{M}^{\\top}\\right]^{\\top}\\) is a \\(K\\) dimensional vector, \\(K=\\sum_{m=1}^{M} K_m\\), \\(\\boldsymbol{Z}\\) is an \\(MT\\times K\\) block diagonal matrix composed of \\(\\boldsymbol{Z}_{m}\\), that is, \\[\\begin{align*} \\boldsymbol{Z}&amp;=\\begin{bmatrix} \\boldsymbol{Z}_1 &amp; \\boldsymbol{0} &amp; \\dots &amp; \\boldsymbol{0}\\\\ \\boldsymbol{0} &amp; \\boldsymbol{Z}_2 &amp; \\dots &amp; \\boldsymbol{0}\\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots\\\\ \\boldsymbol{0} &amp; \\boldsymbol{0} &amp; \\dots &amp; \\boldsymbol{Z}_M \\end{bmatrix}, \\end{align*}\\] and \\(\\boldsymbol{\\mu}=\\left[\\boldsymbol{\\mu}_{1}^{\\top} \\ \\boldsymbol{\\mu}_{2}^{\\top} \\dots \\ \\boldsymbol{\\mu}_{M}^{\\top}\\right]^{\\top}\\) is a \\(MT\\)-dimensional vector of stochastic errors such that \\(\\boldsymbol{\\mu}\\sim{N}(\\boldsymbol{0},\\boldsymbol{\\Sigma}\\otimes \\boldsymbol{I}_T)\\). We can use independent priors in this model to overcome the limitations of the conjugate prior, that is, \\(\\pi(\\boldsymbol{\\beta})\\sim{N}(\\boldsymbol{\\beta}_0,\\boldsymbol{B}_0)\\) and \\(\\pi(\\boldsymbol{\\Sigma}^{-1})\\sim{W}(\\alpha_0,\\boldsymbol{\\Psi}_0)\\). Thus, we know from Section 7.2 that the posterior distributions are \\[\\begin{equation*} \\boldsymbol{\\beta}\\mid \\boldsymbol{\\Sigma}, \\boldsymbol{y}, \\boldsymbol{Z} \\sim {N}(\\boldsymbol{\\beta}_n, \\boldsymbol{B}_n), \\end{equation*}\\] \\[\\begin{equation*} \\boldsymbol{\\Sigma}^{-1}\\mid \\boldsymbol{\\beta}, \\boldsymbol{y}, \\boldsymbol{Z} \\sim {W}(\\alpha_n, \\boldsymbol{\\Psi}_n), \\end{equation*}\\] where \\(\\boldsymbol{B}_n=(\\boldsymbol{Z}^{\\top}(\\boldsymbol{\\Sigma}^{-1}\\otimes \\boldsymbol{I}_T )\\boldsymbol{Z}+\\boldsymbol{B}_0^{-1})^{-1}\\), \\(\\boldsymbol{\\beta}_n=\\boldsymbol{B}_n(\\boldsymbol{B}_0^{-1}\\boldsymbol{\\beta}_0 + \\boldsymbol{Z}^{\\top}(\\boldsymbol{\\Sigma}^{-1}\\otimes \\boldsymbol{I}_T)\\boldsymbol{y})\\), \\(\\alpha_n = \\alpha_0 + T\\) and \\(\\boldsymbol{\\Psi}_n = (\\boldsymbol{\\Psi}_0^{-1} + \\boldsymbol{U}^{\\top}\\boldsymbol{U})^{-1}\\), where \\(\\boldsymbol{U}\\) is an \\(T\\times M\\) matrix whose columns are \\(\\boldsymbol{y}_m-\\boldsymbol{Z}_m\\boldsymbol{\\beta}_m\\).47 Observe that we have standard conditional posteriors, thus, we can employ a Gibbs sampling algorithm to get the posterior draws. We can calculate the prediction \\(\\boldsymbol{y}_{T+1}=[y_{1T+1} \\ y_{2T+1} \\ \\dots \\ y_{MT+1}]^{\\top}\\) knowing that \\(\\boldsymbol{y}_{T+1}\\sim N(\\boldsymbol{Z}_{T}\\boldsymbol{\\beta},\\boldsymbol{\\Sigma})\\), where \\[\\begin{align*} \\boldsymbol{Z}_T&amp;=\\begin{bmatrix} \\boldsymbol{z}_{1T}^{\\top} &amp; 0 &amp; \\dots &amp; 0\\\\ 0 &amp; \\boldsymbol{z}_{2T}^{\\top} &amp; \\dots &amp; 0\\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots\\\\ 0 &amp; 0&amp; \\dots &amp; \\boldsymbol{z}_{MT}^{\\top} \\end{bmatrix}, \\end{align*}\\] and using the posterior draws of \\(\\boldsymbol{\\beta}^{(s)}\\) and \\(\\boldsymbol{\\Sigma}^{(s)}\\), \\(s=1,2,\\dots,S\\). We can also perform inference of functions of the parameters that are of main interest when using VAR models. Note that independent priors offer more flexibility regarding prior information. For instance, we can set \\(\\boldsymbol{\\Psi}_0 = \\boldsymbol{S}^{-1}\\), \\(\\alpha_0 = T\\), \\(\\boldsymbol{\\beta}_0 = \\boldsymbol{0}\\), and \\(\\boldsymbol{B}_0\\) as a diagonal matrix, where the variance of the components associated with the coefficients in the \\(m\\)-th equation is such that the prior variance of the coefficients for the own lags is \\(a_1/l^2\\), the variances for lag \\(l\\) of variable \\(m \\neq j\\) are \\(a_2s_{m}^2/(l^2 s_{j}^2)\\), and the variance of the intercepts is set to \\(a_3 s_{m}^2\\), with \\(l = 1, 2, \\dots, p\\), where \\(s_m\\) is the estimated standard error of the residuals from an unrestricted univariate autoregression of variable \\(m\\) against a constant and its \\(p\\) lags (Litterman 1986; Gary Koop, Korobilis, et al. 2010). Note that setting \\(a_1 &gt; a_2\\) implies that own lags are more important as predictors than lags of other variables, and dividing by \\(l^2\\) implies that more recent lags are more relevant than those further in the past. The specific choices of \\(a_1\\), \\(a_2\\), and \\(a_3\\) (\\(a_k &gt; 0\\), \\(k = 1, 2, 3\\)) depend on the specific application, but it is generally easier to elicit these parameters rather than the \\(K(K+1)/2\\) different components of \\(\\boldsymbol{B}_0\\).48 This setting is known as the Minnesota prior, as it is based on the seminal proposals for Bayesian VAR models by researchers at the University of Minnesota and the Federal Reserve Bank of Minneapolis (Doan, Litterman, and Sims 1984; Litterman 1986).49 An important non-linear function of parameters when performing VAR analysis is the impulse response function, which is, the response of one variable to an impulse in another variable in the model. The impulse response function can be deduced using the \\(MA\\) representation of the VAR model. In particular, we can write Equation (8.10) using the lag operator (see Section 8.2), \\[\\begin{align} \\boldsymbol{y}_t=\\boldsymbol{v} + (\\boldsymbol{A}_{1}L+\\boldsymbol{A}_{2}L^2+\\dots+\\boldsymbol{A}_{p}L^p)\\boldsymbol{y}_t+\\boldsymbol{\\mu}_t, \\tag{8.11} \\end{align}\\] thus \\(\\boldsymbol{A}(L)\\boldsymbol{y}_t=\\boldsymbol{v}+\\boldsymbol{\\mu}_t\\), where \\(\\boldsymbol{A}(L)=\\boldsymbol{I}_M-\\boldsymbol{A}_{1}L-\\boldsymbol{A}_{2}L^2-\\dots-\\boldsymbol{A}_{p}L^p\\). Let \\(\\boldsymbol{\\Phi}(L):= \\sum_{s=0}^{\\infty}\\boldsymbol{\\Phi}_sL^s\\) an operator such that \\(\\boldsymbol{\\Phi}(L)\\boldsymbol{A}(L)=\\boldsymbol{I}_M\\). Thus, we have that \\(\\boldsymbol{\\Phi}(L)\\boldsymbol{A}(L)\\boldsymbol{y}_t=\\left(\\sum_{s=0}^{\\infty}\\boldsymbol{\\Phi}_sL^s\\right)\\boldsymbol{v}+\\left(\\sum_{s=0}^{\\infty}\\boldsymbol{\\Phi}_sL^s\\right)\\boldsymbol{\\mu}_{t}=\\boldsymbol{\\mu}+\\sum_{s=0}^{\\infty}\\boldsymbol{\\Phi}_s\\boldsymbol{\\mu}_{t-s}\\). Note that \\(L^s\\boldsymbol{v}=\\boldsymbol{v}\\) because \\(\\boldsymbol{v}\\) is constant, thus we set \\(\\sum_{s=0}^{\\infty}\\boldsymbol{\\Phi}_sL^s\\boldsymbol{v}=\\sum_{s=0}^{\\infty}\\boldsymbol{\\Phi}_s\\boldsymbol{v}=\\boldsymbol{\\Phi}(1)\\boldsymbol{v}=(\\boldsymbol{I}_M-\\boldsymbol{A}_{1}-\\boldsymbol{A}_{2}-\\dots-\\boldsymbol{A}_{p})^{-1}\\boldsymbol{v}:=\\boldsymbol{\\mu}\\), which is the mean of the process (Helmut 2005). Therefore, the MA representation of the VAR is \\[\\begin{align} \\boldsymbol{y}_t=\\boldsymbol{\\mu} + \\sum_{s=0}^{\\infty}\\boldsymbol{\\Phi}_s\\boldsymbol{\\mu}_{t-s}, \\tag{8.12} \\end{align}\\] where \\(\\boldsymbol{\\Phi}_0=\\boldsymbol{I}_M\\), and we can get the coefficients in \\(\\boldsymbol{\\Phi}_s\\) by the recursion \\(\\boldsymbol{\\Phi}_s=\\sum_{l=1}^s\\boldsymbol{\\Phi}_{s-l}\\boldsymbol{A}_l\\), \\(\\boldsymbol{A}_l=\\boldsymbol{0}\\), \\(l&gt;p\\) and \\(s=1,2,..\\) (Helmut 2005). This impulse response function is called forecast error impulse response function. The MA coefficients contain the impulse responses of the system. In particular, \\(\\phi_{mj,s}\\), which is the \\(mj\\)-th element of the matrix \\(\\boldsymbol{\\Phi}_s\\), represents the response of the \\(m\\)-th variable to a unit shock of the variable \\(j\\) in the system, \\(s\\) periods ago, provided that the effect is not contaminated by other shocks in the system. The long-term effects (total multipliers) are given by \\(\\boldsymbol{\\Psi}_{\\infty}:=\\sum_{s=1}^{\\infty}\\boldsymbol{\\Phi}_s=(\\boldsymbol{I}_M-\\boldsymbol{A}_{1}-\\boldsymbol{A}_{2}-\\dots-\\boldsymbol{A}_{p})^{-1}\\). An assumption in these impulse response functions is that a shock occurs in only one variable at a time. This can be questionable as different shocks may be correlated, consequently, occurring simultaneously. Thus, the impulse response analysis can be performed based on the alternative MA representation, \\(\\boldsymbol{y}_t=\\boldsymbol{\\mu} + \\sum_{s=0}^{\\infty}\\boldsymbol{\\Phi}_s\\boldsymbol{P}\\boldsymbol{P}^{-1}\\boldsymbol{\\mu}_{t-s}=\\boldsymbol{\\mu} + \\sum_{s=0}^{\\infty}\\boldsymbol{\\Theta}_s\\boldsymbol{w}_{t-s}\\), where \\(\\boldsymbol{\\Theta}_s=\\boldsymbol{\\Phi}_s\\boldsymbol{P}\\) and \\(\\boldsymbol{w}_{t}=\\boldsymbol{P}^{-1}\\boldsymbol{\\mu}_{t}\\), \\(\\boldsymbol{P}\\) is a lower triangular matrix such that \\(\\boldsymbol{\\Sigma}=\\boldsymbol{P}\\boldsymbol{P}^{\\top}\\) (Cholesky factorization/decomposition). Note that the covariance matrix of \\(\\boldsymbol{w}_t\\) is \\(\\boldsymbol{I}_M\\) due to \\(\\mathbb{E}[\\boldsymbol{w}_t\\boldsymbol{w}_t^{\\top}]=\\mathbb{E}[\\boldsymbol{P}^{-1}\\boldsymbol{\\mu}_{t}\\boldsymbol{\\mu}_t^{\\top}(\\boldsymbol{P}^{-1})^{\\top}]=\\boldsymbol{P}^{-1}\\boldsymbol{\\Sigma}(\\boldsymbol{P}^{-1})^{\\top}=\\boldsymbol{P}^{-1}\\boldsymbol{P}\\boldsymbol{P}^{\\top}(\\boldsymbol{P}^{-1})^{\\top}=\\boldsymbol{I}_M\\). In this representation is sensible to assume that each shock occurs independently due to the covariance matrix of \\(\\boldsymbol{w}_t\\) being an identity. In addition, a unit shock is a shock of size one standard deviation due the result of the covariance matrix. This is named the ortogonalized impulse response, where \\(\\theta_{mj,s}\\), which is the \\(mj\\)-th element of the matrix \\(\\boldsymbol{\\Theta}_s\\), represents the response of the \\(m\\)-th variable to a standard deviation shock of the variable \\(j\\) in the system, \\(s\\) periods ago. The critical point with the ortogonalized impulse responses is that the order of the variables in the VAR is really important because implicitly establishes a recursive model, that is, the \\(m\\)-th equation in the system may contain \\(y_{1t}, y_{2t}, \\dots, y_{m-1t}\\), but not \\(y_{mt}, y_{m+1t}, \\dots, y_{Mt}\\) on the hand-right side of its equation. Thus, \\(y_{mt}\\) cannot have an instantaneous impact on \\(y_{jt}\\) for \\(j&lt;m\\) (Helmut 2005). Beyond the fascinating macroeconomic implications embedded in the specification of VAR models, the key point for this section is that we can infer impulse response functions using the posterior draws. Example: US fiscal system Let’s use the dataset provided by Woźniak (2024) of the US fiscal system, where ttr is the quarterly total tax revenue, gs is the quarterly total government spending, and gdp is the quarterly gross domestic product, all expressed in log, real, per person terms, and the period is 1948q1 to 2024q2. This dataset is the 18USAfiscal.csv file. Mertens and Ravn (2014) analyze the US fiscal policy shocks using these variables. Let’s estimate a VAR model where \\(\\boldsymbol{y}_t=[\\Delta(ttr_t) \\ \\Delta(gs_t) \\ \\Delta(gdp_t)]^{\\top}\\), that is, we work with the log differences (variation rates), and we set \\(p=1\\). We use the package bvartools to estimate the forecast error and ortogonalized impulse response functions. We use vague independent priors setting \\(\\boldsymbol{\\beta}_0=\\boldsymbol{0}\\), \\(\\boldsymbol{B}_0=100\\boldsymbol{I}\\), \\(\\boldsymbol{V}_0=5^{-1}\\boldsymbol{I}\\) and \\(\\alpha_0=3\\), and the Minnesota prior setting \\(a_1=2\\), \\(\\kappa_2=0.5\\) and \\(\\kappa_3=5\\) (default values).50 The following code shows how to do this, take into account that we use the first 301 observations to estimate the model, and keep the last 4 observations to check the forecasting performance. The first and second figures show the impulse response functions of gs with respect to gs, the forecast error impulse response using vague independent priors, and the orthogonalized impulse response using the Minnesota prior, respectively. We see that the effect of the Minnesota prior is to decrease uncertainty. In addition, the forecasting exercise results indicate that these assumptions have same effects in this example. In particular, the third Figure shows that the mean forecasts using the vague prior (green line) and the Minnesota prior (red line) are indistinguishable from the true observations (black line). However, the Minnesota prior enhances forecast precision, as its 95% predictive interval (blue shaded area) is narrower and fully contained within the 95% predictive interval obtained using vague priors (light blue shaded area). This improvement is attributable to the shrinkage properties of the Minnesota prior. rm(list = ls()); set.seed(010101) DataUSfilcal &lt;- read.csv(&quot;https://raw.githubusercontent.com/besmarter/BSTApp/refs/heads/master/DataApp/18USAfiscal.csv&quot;, sep = &quot;,&quot;, header = TRUE, quote = &quot;&quot;) attach(DataUSfilcal) # upload data ## The following object is masked from dataset (pos = 16): ## ## year ## The following object is masked from dataset (pos = 18): ## ## year Y &lt;- cbind(diff(as.matrix(DataUSfilcal[,-c(1:2)]))) T &lt;- dim(Y)[1]-1; K &lt;- dim(Y)[2] Ynew &lt;- Y[-c((T-2):(T+1)), ] # Use 4 last observations to check forecast y1 &lt;- Ynew[-1, 1]; y2 &lt;- Ynew[-1, 2]; y3 &lt;- Ynew[-1, 3] X1 &lt;- cbind(1, lag(Ynew)); X1 &lt;- X1[-1,] X2 &lt;- cbind(1, lag(Ynew)); X2 &lt;- X2[-1,] X3 &lt;- cbind(1, lag(Ynew)); X3 &lt;- X3[-1,] M &lt;- dim(Y)[2]; K1 &lt;- dim(X1)[2]; K2 &lt;- dim(X2)[2]; K3 &lt;- dim(X3)[2] K &lt;- K1 + K2 + K3 # Hyperparameters b0 &lt;- 0; c0 &lt;- 100; V0 &lt;- 5^(-1); a0 &lt;- M #Posterior draws library(tibble) MCMC &lt;- 10000; burnin &lt;- 1000; H &lt;- 10; YnewPack &lt;- ts(Ynew) model &lt;- bvartools::gen_var(YnewPack, p = 1, deterministic = &quot;const&quot;, iterations = MCMC, burnin = burnin) # Create model model &lt;- bvartools::add_priors(model, coef = list(v_i = c0^-1, v_i_det = c0^-1, const = b0), sigma = list(df = a0, scale = V0/a0), coint_var = FALSE) # Add priors object &lt;- bvartools::draw_posterior(model) # Posterior draws ## Estimating model... ir &lt;- bvartools::irf.bvar(object, impulse = &quot;gs&quot;, response = &quot;gs&quot;, n.ahead = H, type = &quot;feir&quot;, cumulative = FALSE) # Calculate IR # Plot IR plot_IR &lt;- function(df) { p &lt;- ggplot(data = df, aes(x = t)) + geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 1, fill = &quot;lightblue&quot;) + geom_line(aes(y = mean), colour = &quot;blue&quot;, linewidth = 0.5) + ylab(&quot;Impulse response&quot;) + xlab(&quot;Time&quot;) + xlim(0,H) print(p) } dfNew &lt;- tibble(t = 0:H, mean = as.numeric(ir[,2]), lower = as.numeric(ir[,1]), upper = as.numeric(ir[,3])) FigNew &lt;- plot_IR(dfNew) FigNew # Using Minnesota prior modelMin &lt;- bvartools::gen_var(YnewPack, p = 1, deterministic = &quot;const&quot;, iterations = MCMC, burnin = burnin) modelMin &lt;- bvartools::add_priors(modelMin, minnesota = list(kappa0 = 2, kappa1 = 0.5, kappa3 = 5), coint_var = FALSE) # Minnesota prior objectMin &lt;- bvartools::draw_posterior(modelMin) # Posterior draws ## Estimating model... irMin &lt;- bvartools::irf.bvar(objectMin, impulse = &quot;gs&quot;, response = &quot;gs&quot;, n.ahead = H, type = &quot;feir&quot;, cumulative = FALSE) # Calculate IR dfNewMin &lt;- tibble(t = 0:H, mean = as.numeric(irMin[,2]), lower = as.numeric(irMin[,1]), upper = as.numeric(irMin[,3])) FigNewMin &lt;- plot_IR(dfNewMin) FigNewMin ### Forecasting bvar_pred &lt;- predict(object, n.ahead = 4, new_d = rep(1, 4)) bvar_predOR &lt;- predict(objectMin, n.ahead = 4, new_d = rep(1, 4)) dfFore &lt;- tibble(t = c((T-2):(T+1)), mean = as.numeric(bvar_pred[[&quot;fcst&quot;]][[&quot;gs&quot;]][,2]), lower = as.numeric(bvar_pred[[&quot;fcst&quot;]][[&quot;gs&quot;]][,1]), upper = as.numeric(bvar_pred[[&quot;fcst&quot;]][[&quot;gs&quot;]][,3]), mean1 = as.numeric(bvar_predOR[[&quot;fcst&quot;]][[&quot;gs&quot;]][,2]), lower1 = as.numeric(bvar_predOR[[&quot;fcst&quot;]][[&quot;gs&quot;]][,1]), upper1 = as.numeric(bvar_predOR[[&quot;fcst&quot;]][[&quot;gs&quot;]][,3]), true = as.numeric(Y[c((T-2):(T+1)),2])) plot_FORE &lt;- function(df) { p &lt;- ggplot(data = dfFore, aes(x = t)) + geom_ribbon(aes(ymin = lower1, ymax = upper1), alpha = 1, fill = &quot;blue&quot;) + geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 1, fill = &quot;lightblue&quot;) + geom_line(aes(y = mean), colour = &quot;green&quot;, linewidth = 0.5) + geom_line(aes(y = mean1), colour = &quot;red&quot;, linewidth = 0.5) + geom_line(aes(y = true), colour = &quot;black&quot;, linewidth = 0.5) + ylab(&quot;Forecast&quot;) + xlab(&quot;Time&quot;) + xlim(c((T-2),(T+1))) print(p) } FigFore &lt;- plot_FORE(dfFore) FigFore The following Algorithm shows how to do perform inference in VAR models using our GUI. See also Chapter 5 for details regarding the dataset structure. Algorithm: Vector Autoregressive Models Select Time series Model on the top panel Select VAR models using the left radio button Upload the dataset selecting first if there is a header in the file, and the kind of separator in the csv file of the dataset (comma, semicolon, or tab). Then, use the Browse button under the Choose File legend Select MCMC iterations, burn-in, and thinning parameters using the Range sliders Set the number of lags (p) Set the hyperparameters for the Minnesota prior: a1, κ2 and κ3. This step is not necessary as by default our GUI uses default values in the bvartools package Select the type of impulse response functions: forecast error or orthogonalized, and ordinary or cumulative Set the time horizon for the impulse response functions and the forecasts Click the Go! button Analyze results Download impulse responses and forecasts using the Download Results button There are other good packages in R to perform Bayesian inference in VAR models. For instance, bayesianVARs package implements inference of reduced-form VARs with stochastic volatility (Luis and Gregor 2024), BVAR package performs inference using hierarchical priors (Nikolas et al. 2022), bvarsv implements time-varying parameters models (Krueger 2022), bsvars performs estimation of structural VAR models (Woźniak 2024), and bsvarSIGNs to estimating structural VAR models with sign restrictions (Xiaolei and Woźniak 2024). References "],["sec85.html", "8.5 Summary", " 8.5 Summary We present a brief review of Bayesian inference in time series models. In particular, we introduce the state-space representation and demonstrate how to perform inferential analysis for these models, focusing on the dynamic linear model and the stochastic volatility model. Additionally, we show how ARMA(p,q) processes can be expressed in state-space form and provide methods for estimating such models. We also include code for implementing computational inference algorithms, such as sequential Monte Carlo (SMC), Hamiltonian Monte Carlo (HMC), and various Markov chain Monte Carlo (MCMC) methods. Finally, we introduce VAR(p) models, detailing how to perform impulse-response analysis and forecasting within this framework. Time series analysis is a highly active research area with remarkable methodological developments and applications. Interested readers can refer to excellent materials in chapters 7 and 9 of John Geweke, Koop, and Dijk (2011), and chapters 17 to 20 of Chan et al. (2019), along with the references therein. References "],["sec86.html", "8.6 Exercises", " 8.6 Exercises Simulate the dynamic linear model assuming \\(X_t \\sim N(1, 0.1\\sigma^2)\\), \\(w_t \\sim N(0, 0.5\\sigma^2)\\), \\(\\mu_t \\sim N(0, \\sigma^2)\\), \\(\\beta_0 = 1\\), \\(B_0 = 0.5\\sigma^2\\), \\(\\sigma^2 = 0.25\\), and \\(G_t = 1\\), for \\(t = 1, \\dots, 100\\). Then, perform the filtering recursion fixing \\(\\Sigma = 25 \\times 0.25\\), \\(\\Omega_1 = 0.5\\Sigma\\) (high signal-to-noise ratio) and \\(\\Omega_2 = 0.1\\Sigma\\) (low signal-to-noise ratio). Plot and compare the results. Simulate the dynamic linear model \\(y_t = \\beta_t x_t + \\mu_t\\), \\(\\beta_t = \\beta_{t-1} + w_t\\), where \\(x_t \\sim N(1, 0.1\\sigma^2)\\), \\(w_t \\sim N(0, 0.5\\sigma^2)\\), \\(\\mu_t \\sim N(0, \\sigma^2)\\), \\(\\beta_0 = 0\\), \\(B_0 = 0.5\\sigma^2\\), and \\(\\sigma^2 = 1\\), for \\(t = 1, \\dots, 100\\). Perform the filtering and smoothing recursions from scratch. Simulate the process \\(y_t = \\alpha z_t + \\beta_t x_t + \\boldsymbol{h}^{\\top}\\boldsymbol{\\epsilon}_t\\), \\(\\beta_t = \\beta_{t-1} + \\boldsymbol{H}^{\\top}\\boldsymbol{\\epsilon}_t\\), where \\(\\boldsymbol{h}^{\\top} = [1 \\ 0]\\), \\(\\boldsymbol{H}^{\\top} = [0 \\ 1/\\tau]\\), \\(\\boldsymbol{v}_t \\sim N(\\boldsymbol{0}_2, \\sigma^2 \\boldsymbol{I}_2)\\), \\(x_t \\sim N(1, 2\\sigma^2)\\), \\(z_t \\sim N(0, 2\\sigma^2)\\), \\(\\alpha = 2\\), \\(\\tau^2 = 5\\), and \\(\\sigma^2 = 0.1\\), for \\(t = 1, \\dots, 200\\). Assume \\(\\pi({\\beta}_0, {\\alpha}, \\sigma^2, {\\tau}) = \\pi({\\beta}_0)\\pi({\\alpha})\\pi(\\sigma^2)\\pi(\\tau^2)\\) where \\(\\sigma^2 \\sim IG(\\alpha_0/2, \\delta_0/2)\\), \\(\\tau^2 \\sim G(v_{0}/2, v_{0}/2)\\), \\({\\alpha} \\sim N({a}_0, {A}_0)\\), and \\({\\beta}_0 \\sim N({b}_0, {B}_0)\\) such that \\(\\alpha_0 = \\delta_0 = 1\\), \\(v_0 = 5\\), \\(a_0 = 0\\), \\(A_0 = 1\\), \\(\\beta_0 = 0\\), \\(B_0 = \\sigma^2/\\tau^2\\). Program the MCMC algorithm including the simulation smoother. Show that the posterior distribution of \\(\\boldsymbol{\\phi} \\mid \\boldsymbol{\\beta}, \\sigma^2, \\boldsymbol{y}, \\boldsymbol{X}\\) in the model \\(y_t = \\boldsymbol{x}_t^{\\top} \\boldsymbol{\\beta} + \\mu_t\\) where \\(\\phi(L) \\mu_t = \\epsilon_t\\) and \\(\\epsilon_t \\stackrel{iid}{\\sim} N(0, \\sigma^2)\\) is \\(N(\\boldsymbol{\\phi}_n, \\boldsymbol{\\Phi}_n)\\mathbb{1}(\\boldsymbol{\\phi} \\in S_{\\boldsymbol{\\phi}})\\), where \\(\\boldsymbol{\\Phi}_n = (\\boldsymbol{\\Phi}_0^{-1} + \\sigma^{-2} \\boldsymbol{U}^{\\top} \\boldsymbol{U})\\), \\(\\boldsymbol{\\phi}_n = \\boldsymbol{\\Phi}_n (\\boldsymbol{\\Phi}_0^{-1} \\boldsymbol{\\phi}_0 + \\sigma^{-2} \\boldsymbol{U}^{\\top} \\boldsymbol{\\mu})\\), and \\(S_{\\boldsymbol{\\phi}}\\) is the stationary region of \\(\\boldsymbol{\\phi}\\). Show that in the \\(AR(2)\\) stationary process, \\(y_t = \\mu + \\phi_1 y_{t-1} + \\phi_2 y_{t-2} + \\epsilon_t\\), where \\(\\epsilon_t \\sim N(0, \\sigma^2)\\), \\(\\mathbb{E}[y_t] = \\frac{\\mu}{1 - \\phi_1 - \\phi_2}\\), and \\(\\text{Var}[y_t] = \\frac{\\sigma^2(1 - \\phi_2)}{1 - \\phi_2 - \\phi_1^2 - \\phi_1^2 \\phi_2 - \\phi_2^2 + \\phi_2^3}\\). Program a Hamiltonian Monte Carlo taking into account the stationary restrictions on \\(\\phi_1\\) and \\(\\phi_2\\), and \\(\\epsilon_0\\) such that the acceptance rate is near 65%. Stochastic volatility model Program a sequential importance sampling (SIS) from scratch in the vanilla stochastic volatility model setting \\(\\mu = -10\\), \\(\\phi = 0.95\\), \\(\\sigma = 0.3\\), and \\(T = 250\\). Check what happens with its performance. Modify the sequential Monte Carlo (SMC) to perform multinomial resampling when the effective sample size is lower than 50% the initial number of particles. Estimate the vanilla stochastic volatility model using the dataset 17ExcRate.csv, provided by Ramı́rez-Hassan and Frazier (2024), which contains the exchange rate log daily returns for USD/EUR, USD/GBP, and GBP/EUR from one year before and after the WHO declared the COVID-19 pandemic on 11 March 2020. Simulate the VAR(1) process: \\[ \\begin{bmatrix} y_{1t}\\\\ y_{2t}\\\\ y_{3t}\\\\ \\end{bmatrix} = \\begin{bmatrix} 2.8\\\\ 2.2\\\\ 1.3\\\\ \\end{bmatrix} + \\begin{bmatrix} 0.5 &amp; 0 &amp; 0\\\\ 0.1 &amp; 0.1 &amp; 0.3\\\\ 0 &amp; 0.2 &amp; 0.3\\\\ \\end{bmatrix} \\begin{bmatrix} y_{1t-1}\\\\ y_{2t-1}\\\\ y_{3t-1}\\\\ \\end{bmatrix} + \\begin{bmatrix} \\mu_{1t}\\\\ \\mu_{2t}\\\\ \\mu_{3t}\\\\ \\end{bmatrix}, \\] where \\(\\boldsymbol{\\Sigma} = \\begin{bmatrix} 2.25 &amp; 0 &amp; 0\\\\ 0 &amp; 1 &amp; 0.5\\\\ 0 &amp; 0.5 &amp; 0.74\\\\ \\end{bmatrix}\\). Use vague independent priors setting \\(\\boldsymbol{\\beta}_0 = \\boldsymbol{0}\\), \\(\\boldsymbol{B}_0 = 100\\boldsymbol{I}\\), \\(\\boldsymbol{V}_0 = 5\\boldsymbol{I}\\), \\(\\alpha_0 = 3\\), and estimate a VAR(1) model using the rsurGibbs function from the package bayesm. Then, program from scratch References "],["Chap9.html", "Chapter 9 Longitudinal regression", " Chapter 9 Longitudinal regression We describe how to perform inference in longitudinal/panel models using a Bayesian framework. In this context, multiple cross-sectional units are observed repeatedly over time, a structure referred to as panel data by econometricians and longitudinal data by statisticians. Specifically, we present models for continuous (normal), binary (logit), and count (Poisson) responses. Applications and exercises illustrate the potential of these models. In longitudinal/panel data sets, we have \\(y_{it}\\) where \\(i=1,2,\\dots,N\\) and \\(t=1,2,\\dots,T_i\\). If \\(T_i=T\\) for all \\(i\\), the dataset is balanced; otherwise, it is unbalanced. Longitudinal data typically involves by far more cross-sectional units than time periods, this is called typically a short panel. It assumes that cross-sectional units are independent, though serial correlation exists within each unit over time, and unobserved heterogeneity for each unit must be accounted for. We can treat this unobserved heterogeneity as random variables, assuming it is either independent or dependent on control variables. Econometricians refer to these cases as random effects and fixed effects, respectively. The Bayesian literature takes a different approach, modeling the panel structure hierarchically, where the unobserved heterogeneity may or may not depend on other controls.51. Remember that we can run our GUI typing shiny::runGitHub(\"besmarter/BSTApp\", launch.browser=T) in the R console or any R code editor and execute it. However, users should see Chapter 5 for details. References "],["sec91.html", "9.1 Normal model", " 9.1 Normal model The longitudinal/panel normal model establishes \\(\\boldsymbol{y}_i=\\boldsymbol{X}_i\\boldsymbol{\\beta}+\\boldsymbol{W}_i\\boldsymbol{b}_i+\\boldsymbol{\\mu}_i\\) where \\(\\boldsymbol{y}_i\\) are \\(T_i\\)-dimensional vectors corresponding to units \\(i=1,2,\\dots,N\\), \\(\\boldsymbol{X}_i\\) and \\(\\boldsymbol{W}_i\\) are \\(T_i\\times K_1\\) and \\(T_i\\times K_2\\) matrices, respectively. In the statistical literature, \\(\\boldsymbol{\\beta}\\) is a \\(K_1\\)-dimensional vector of fixed effects, and \\(\\boldsymbol{b}_i\\) is a \\(K_2\\)-dimensional vector of unit-specific random effects that allow unit-specific means, and enable capturing marginal dependence among the observations on the cross-sectional units. We assume normal stochastic errors, \\(\\boldsymbol{\\mu}_i\\sim{N}(\\boldsymbol{0},\\sigma^2\\boldsymbol{I}_{T_i})\\), which means that the likelihood function is \\[\\begin{align*} p(\\boldsymbol{\\beta},\\boldsymbol{b},\\sigma^2\\mid \\boldsymbol{y}, \\boldsymbol{X},\\boldsymbol{W}) &amp; \\propto \\prod_{i=1}^N |\\sigma^2\\boldsymbol{I}_{T_i}|^{-1/2}\\exp\\left\\{-\\frac{1}{2\\sigma^2}(\\boldsymbol{y}_i-\\boldsymbol{X}_i\\boldsymbol{\\beta}-\\boldsymbol{W}_i\\boldsymbol{b}_i)^{\\top}(\\boldsymbol{y}_i-\\boldsymbol{X}_i\\boldsymbol{\\beta}-\\boldsymbol{W}_i\\boldsymbol{b}_i)\\right\\}\\\\ &amp; = (\\sigma^2)^{-\\frac{\\sum_{i=1}^N T_i}{2}}\\exp\\left\\{-\\frac{1}{2\\sigma^2}\\sum_{i=1}^N(\\boldsymbol{y}_i-\\boldsymbol{X}_i\\boldsymbol{\\beta}-\\boldsymbol{W}_i\\boldsymbol{b}_i)^{\\top}(\\boldsymbol{y}_i-\\boldsymbol{X}_i\\boldsymbol{\\beta}-\\boldsymbol{W}_i\\boldsymbol{b}_i)\\right\\}, \\end{align*}\\] where \\(\\boldsymbol{b}=[\\boldsymbol{b}_1^{\\top}, \\boldsymbol{b}_2^{\\top},\\dots, \\boldsymbol{b}_N^{\\top}]^{\\top}\\). Panel data modeling in the Bayesian approach assumes a hierarchical structure in the random effects. Following S. Chib and Carlin (1999), there is a first stage where \\(\\boldsymbol{b}_i\\sim{N}(\\boldsymbol{0},\\boldsymbol{D})\\), \\(\\boldsymbol{D}\\) allows serial correlation within each cross-sectional unit \\(i\\), and then, there is a second stage where \\(\\boldsymbol{D}\\sim{I}{W}(d_0,d_0\\boldsymbol{D}_0)\\). Thus, we can see that there is an additional layer of priors as there is a prior on the hyperparameter \\(\\boldsymbol{D}\\). In addition, we have standard conjugate prior distributions for \\(\\boldsymbol{\\beta}\\) and \\(\\sigma^2\\), \\(\\boldsymbol{\\beta} \\sim {N}(\\boldsymbol{\\beta}_0,\\boldsymbol{B}_0)\\) and \\(\\sigma^2 \\sim {I}{G}(\\alpha_0, \\delta_0)\\). S. Chib and Carlin (1999) propose a blocking algorithm to perform inference in longitudinal hierarchical models by considering the distribution of \\(\\boldsymbol{y}_i\\) marginalized over the random effects. Given that \\(\\boldsymbol{y}_i\\mid \\boldsymbol{\\beta},\\boldsymbol{b}_i,\\sigma^2,\\boldsymbol{X}_i,\\boldsymbol{W}_i\\sim N(\\boldsymbol{X}_i\\boldsymbol{\\beta}+\\boldsymbol{W}_i\\boldsymbol{b}_i,\\sigma^2\\boldsymbol{I}_{T_i})\\), we can see that \\(\\boldsymbol{y}_i\\mid \\boldsymbol{\\beta},\\boldsymbol{D},\\sigma^2,\\boldsymbol{X}_i,\\boldsymbol{W}_i\\sim{N}(\\boldsymbol{X}_i\\boldsymbol{\\beta},\\boldsymbol{V}_i)\\), where \\(\\boldsymbol{V}_i=\\sigma^2\\boldsymbol{I}_{T_i}+\\boldsymbol{W}_i\\boldsymbol{D}\\boldsymbol{W}_i^{\\top}\\) given that \\(\\mathbb{E}[\\boldsymbol{b}_i]=\\boldsymbol{0}\\) and \\(Var[\\boldsymbol{b}_i]=\\boldsymbol{D}\\). If we have just random intercepts, then \\(\\boldsymbol{W}_i=\\boldsymbol{i}_{T_i}\\), where \\(\\boldsymbol{i}_{T_i}\\) is a \\(T_i\\)-dimensional vector of ones. Thus, \\(\\boldsymbol{V}_i=\\sigma^2\\boldsymbol{I}_{T_i}+\\sigma_{b}^2\\boldsymbol{i}_{T_i}\\boldsymbol{i}_{T_i}^{\\top}\\), the variance is \\(\\sigma^2+\\sigma^2_{b}\\) and the covariance is \\(\\sigma^2_{b}\\) within each cross-sectional unit through time. We can deduce the posterior distribution of \\(\\boldsymbol{\\beta}\\) given \\(\\sigma^2\\) and \\(\\boldsymbol{D}\\), \\[\\begin{align*} \\pi(\\boldsymbol{\\beta}\\mid \\sigma^2, \\boldsymbol{D},\\boldsymbol{y}, \\boldsymbol{X}, \\boldsymbol{W}) &amp; \\propto \\exp\\left\\{-\\frac{1}{2}\\sum_{i=1}^N(\\boldsymbol{y}_i-\\boldsymbol{X}_i\\boldsymbol{\\beta})^{\\top}\\boldsymbol{V}_i^{-1}(\\boldsymbol{y}_i-\\boldsymbol{X}_i\\boldsymbol{\\beta})\\right\\}\\\\ &amp;\\times \\exp\\left\\{-\\frac{1}{2}(\\boldsymbol{\\beta}-\\boldsymbol{\\beta}_0)^{\\top}\\boldsymbol{B}_0^{-1}(\\boldsymbol{\\beta}-\\boldsymbol{\\beta}_0)\\right\\}. \\end{align*}\\] This implies that (see Exercise 1) \\[\\begin{equation*} \\boldsymbol{\\beta}\\mid \\sigma^2,\\boldsymbol{D},\\boldsymbol{y}, \\boldsymbol{X}, \\boldsymbol{W} \\sim {N}(\\boldsymbol{\\beta}_n,\\boldsymbol{B}_n), \\end{equation*}\\] where \\(\\boldsymbol{B}_n = (\\boldsymbol{B}_0^{-1} +\\sum_{i=1}^N \\boldsymbol{X}_i^{\\top}\\boldsymbol{V}_i^{-1}\\boldsymbol{X}_i)^{-1}\\), \\(\\boldsymbol{\\beta}_n= \\boldsymbol{B}_n(\\boldsymbol{B}_0^{-1}\\boldsymbol{\\beta}_0 + \\sum_{i=1}^N\\boldsymbol{X}_i^{\\top}\\boldsymbol{V}_i^{-1}\\boldsymbol{y}_i)\\). We can use the likelihood \\(p(\\boldsymbol{\\beta},\\boldsymbol{b}_i,\\sigma^2\\mid \\boldsymbol{y}, \\boldsymbol{X},\\boldsymbol{W})\\) to get the posterior distributions of \\(\\boldsymbol{b}_i\\), \\(\\sigma^2\\) and \\(\\boldsymbol{D}\\). In particular, \\[\\begin{align*} \\pi(\\boldsymbol{b}_i\\mid \\boldsymbol{\\beta},\\sigma^2,\\boldsymbol{D},\\boldsymbol{y}, \\boldsymbol{X}, \\boldsymbol{W})&amp;\\propto \\exp\\left\\{-\\frac{1}{2\\sigma^2}\\sum_{i=1}^N(\\boldsymbol{y}_i-\\boldsymbol{X}_i\\boldsymbol{\\beta}-\\boldsymbol{W}_i\\boldsymbol{b}_i)^{\\top}(\\boldsymbol{y}_i-\\boldsymbol{X}_i\\boldsymbol{\\beta}-\\boldsymbol{W}_i\\boldsymbol{b}_i)\\right\\}\\\\ &amp;\\times \\exp\\left\\{-\\frac{1}{2}\\sum_{i=1}^N \\boldsymbol{b}_i^{\\top}\\boldsymbol{D}^{-1}\\boldsymbol{b}_i\\right\\}\\\\ &amp;\\propto\\exp\\left\\{-\\frac{1}{2}\\sum_{i=1}^N(-2\\boldsymbol{b}_i^{\\top}(\\sigma^{-2}\\boldsymbol{W}_i^{\\top}(\\boldsymbol{y}_i-\\boldsymbol{X}_i\\boldsymbol{\\beta}))+ \\boldsymbol{b}_i^{\\top}(\\sigma^{-2}\\boldsymbol{W}_i^{\\top}\\boldsymbol{W}_i+\\boldsymbol{D}^{-1})\\boldsymbol{b}_i)\\right\\}\\\\ &amp;\\propto\\exp\\left\\{-\\frac{1}{2}(-2\\boldsymbol{b}_i^{\\top}\\boldsymbol{B}_{ni}^{-1}\\boldsymbol{B}_{ni}(\\sigma^{-2}\\boldsymbol{W}_i^{\\top}(\\boldsymbol{y}_i-\\boldsymbol{X}_i\\boldsymbol{\\beta}))+ \\boldsymbol{b}_i^{\\top}\\boldsymbol{B}_{ni}^{-1}\\boldsymbol{b}_i)\\right\\}\\\\ &amp;=\\exp\\left\\{-\\frac{1}{2}(-2\\boldsymbol{b}_i^{\\top}\\boldsymbol{B}_{ni}^{-1}\\boldsymbol{b}_{ni}+ \\boldsymbol{b}_i^{\\top}\\boldsymbol{B}_{ni}^{-1}\\boldsymbol{b}_i)\\right\\}, \\end{align*}\\] where \\(\\boldsymbol{B}_{ni}=(\\sigma^{-2}\\boldsymbol{W}_i^{\\top}\\boldsymbol{W}_i+\\boldsymbol{D}^{-1})^{-1}\\) and \\(\\boldsymbol{b}_{ni}=\\boldsymbol{B}_{ni}(\\sigma^{-2}\\boldsymbol{W}_i^{\\top}(\\boldsymbol{y}_i-\\boldsymbol{X}_i\\boldsymbol{\\beta}))\\). We can complete the square in this expression by adding and subtracting \\(\\boldsymbol{b}_{ni}^{\\top}\\boldsymbol{B}_{ni}^{-1}\\boldsymbol{b}_{ni}\\). Thus, \\[\\begin{align*} \\pi(\\boldsymbol{b}_i\\mid \\boldsymbol{\\beta},\\sigma^2,\\boldsymbol{D},\\boldsymbol{y}, \\boldsymbol{X}, \\boldsymbol{W})&amp;\\propto \\exp\\left\\{-\\frac{1}{2}(-2\\boldsymbol{b}_i^{\\top}\\boldsymbol{B}_{ni}^{-1}\\boldsymbol{b}_{ni}+ \\boldsymbol{b}_i^{\\top}\\boldsymbol{B}_{ni}^{-1}\\boldsymbol{b}_i+\\boldsymbol{b}_{ni}^{\\top}\\boldsymbol{B}_{ni}^{-1}\\boldsymbol{b}_{ni}-\\boldsymbol{b}_{ni}^{\\top}\\boldsymbol{B}_{ni}^{-1}\\boldsymbol{b}_{ni})\\right\\}\\\\ &amp;\\propto \\exp\\left\\{(\\boldsymbol{b}_i-\\boldsymbol{b}_{ni})^{\\top}\\boldsymbol{B}_{ni}^{-1}(\\boldsymbol{b}_i-\\boldsymbol{b}_{ni})\\right\\}. \\end{align*}\\] This is the kernel of a multivariate normal distribution with mean \\(\\boldsymbol{b}_{ni}\\) and variance \\(\\boldsymbol{B}_{ni}\\). Thus, \\[\\begin{equation*} \\boldsymbol{b}_i\\mid \\boldsymbol{\\beta},\\sigma^2,\\boldsymbol{D},\\boldsymbol{y}, \\boldsymbol{X}, \\boldsymbol{W} \\sim {N}(\\boldsymbol{b}_{ni},\\boldsymbol{B}_{ni}), \\end{equation*}\\] Let’s see the posterior distribution of \\(\\sigma^2\\), \\[\\begin{align*} \\pi(\\sigma^2\\mid \\boldsymbol{\\beta},\\boldsymbol{b},\\boldsymbol{y}, \\boldsymbol{X}, \\boldsymbol{W})&amp;\\propto (\\sigma^2)^{-\\frac{\\sum_{i=1}^N T_i}{2}}\\exp\\left\\{-\\frac{1}{2\\sigma^2}\\sum_{i=1}^N(\\boldsymbol{y}_i-\\boldsymbol{X}_i\\boldsymbol{\\beta}-\\boldsymbol{W}_i\\boldsymbol{b}_i)^{\\top}(\\boldsymbol{y}_i-\\boldsymbol{X}_i\\boldsymbol{\\beta}-\\boldsymbol{W}_i\\boldsymbol{b}_i)\\right\\}\\\\ &amp;\\times (\\sigma^2)^{-\\alpha_0-1}\\exp\\left\\{-\\frac{\\delta_0}{\\sigma^2}\\right\\}\\\\ &amp;=(\\sigma^2)^{-\\frac{\\sum_{i=1}^N T_i}{2}-\\alpha_0-1}\\\\ &amp;\\times \\exp\\left\\{-\\frac{1}{\\sigma^2}\\left(\\delta_0+\\sum_{i=1}^N\\frac{(\\boldsymbol{y}_i-\\boldsymbol{X}_i\\boldsymbol{\\beta}-\\boldsymbol{W}_i\\boldsymbol{b}_i)^{\\top}(\\boldsymbol{y}_i-\\boldsymbol{X}_i\\boldsymbol{\\beta}-\\boldsymbol{W}_i\\boldsymbol{b}_i)}{2}\\right)\\right\\}. \\end{align*}\\] Thus, \\[\\begin{equation*} \\sigma^2\\mid \\boldsymbol{\\beta}, \\boldsymbol{b}, \\boldsymbol{y}, \\boldsymbol{X}, \\boldsymbol{W} \\sim {I}{G}(\\alpha_n, \\delta_n), \\end{equation*}\\] where \\(\\alpha_n=\\alpha_0+\\frac{1}{2}\\sum_{i=1}^N T_i\\) and \\(\\delta_n=\\delta_0+\\frac{1}{2}\\sum_{i=1}^N(\\boldsymbol{y}_i-\\boldsymbol{X}_i\\boldsymbol{\\beta}-\\boldsymbol{W}_i\\boldsymbol{b}_i)^{\\top}(\\boldsymbol{y}_i-\\boldsymbol{X}_i\\boldsymbol{\\beta}-\\boldsymbol{W}_i\\boldsymbol{b}_i)\\). The posterior distribution of \\(\\boldsymbol{D}\\) is the following, \\[\\begin{align*} \\pi(\\boldsymbol{D}\\mid \\boldsymbol{b})&amp;\\propto |\\boldsymbol{D}|^{-N/2} \\exp\\left\\{-\\frac{1}{2}\\sum_{i=1}^N \\boldsymbol{b}_i^{\\top}\\boldsymbol{D}^{-1}\\boldsymbol{b}_i\\right\\}\\\\ &amp;\\times |\\boldsymbol{D}|^{-(d_0+K_2+1)/2}\\exp\\left\\{-\\frac{1}{2}tr(d_0\\boldsymbol{D}_0\\boldsymbol{D}^{-1})\\right\\}\\\\ &amp;=|\\boldsymbol{D}|^{-(d_0+N+K_2+1)/2}\\exp\\left\\{-\\frac{1}{2}tr\\left(\\left(d_0\\boldsymbol{D}_0+\\sum_{i=1}^N\\boldsymbol{b}_i\\boldsymbol{b}_i^{\\top}\\right)\\boldsymbol{D}^{-1}\\right) \\right\\}. \\end{align*}\\] This is the kernel of an inverse Wishart distribution with degrees of freedom \\(d_n=d_0+N\\) and scale matrix \\(\\boldsymbol{D}_n=d_0\\boldsymbol{D}_0+\\sum_{i=1}^N\\boldsymbol{b}_i\\boldsymbol{b}_i^{\\top}\\). Thus, \\[\\begin{equation*} \\boldsymbol{D}\\mid \\boldsymbol{b} \\sim {I}{W}(d_n, \\boldsymbol{D}_n). \\end{equation*}\\] Observe that the posterior distribution of \\(\\boldsymbol{D}\\) dependents just on \\(\\boldsymbol{b}\\). All the posterior conditional distributions belong to standard families, this implies that we can use a Gibbs sampling algorithm to perform inference in these hierarchical normal models. Example: The relation between productivity and public investment We used the dataset named 8PublicCap.csv used by Ramírez Hassan (2017) to analyze the relation between public investment and gross state product in the setting of a spatial panel dataset consisting of 48 US states from 1970 to 1986. In particular, we perform inference based on the following equation \\[\\begin{equation*} \\log(\\text{gsp}_{it})=b_i+\\beta_1+\\beta_2\\log(\\text{pcap}_{it})+\\beta_3\\log(\\text{pc}_{it})+\\beta_4\\log(\\text{emp}_{it})+\\beta_5\\text{unemp}_{it}+\\mu_{it}, \\end{equation*}\\] where gsp in the gross state product, pcap is public capital, and pc is private capital all in USD, emp is employment (people), and unemp is the unemployment rate in percentage. The following Algorithm shows how to perform inference in hierarchical longitudinal normal models in our GUI. See also Chapter 5 for details regarding the dataset structure. Algorithm: Hierarchical Longitudinal Normal Models Select Hierarchical Longitudinal Model on the top panel Select Normal model using the left radio button Upload the dataset, selecting first if there is a header in the file, and the kind of separator in the csv file of the dataset (comma, semicolon, or tab). Then, use the Browse button under the Choose File legend Select MCMC iterations, burn-in, and thinning parameters using the Range sliders Write down the formula of the fixed effects equation in the Main Equation: Fixed Effects box. This formula must be written using the syntax of the formula command of R software. This equation includes intercept by default, do not include it in the equation Write down the formula of the random effects equation in the Main Equation: Random Effects box without writing the dependent variable, that is, starting the equation with the tilde (“~”) symbol. This formula must be written using the syntax of the formula command of R software. This equation includes intercept by default, do not include it in the equation. If there are just random intercepts do not write anything in this box Write down the name of the grouping variable, that is, the variable that indicates the cross-sectional units Set the hyperparameters of the fixed effects: mean vector, covariance matrix, shape and scale parameters. This step is not necessary as by default our GUI uses non-informative priors Set the hyperparameters of the random effects: degrees of freedom and scale matrix of the inverse Wishart distribution. This step is not necessary as by default our GUI uses non-informative priors Click the Go! button Analyze results Download posterior chains and diagnostic plots using the Download Posterior Chains and Download Posterior Graphs buttons We ask in Exercise 2 to run this application in our GUI using 10,000 MCMC iterations plus a burn-in equal to 5,000 iterations, and a thinning parameter equal to 1. We also used the default values for the hyperparameters of the prior distributions, that is, \\(\\boldsymbol{\\beta}_0=\\boldsymbol{0}_5\\), \\(\\boldsymbol{B}_0=\\boldsymbol{I}_5\\), \\(\\alpha_0=\\delta_0=0.001\\), \\(d_0=5\\) and \\(\\boldsymbol{D}_0=\\boldsymbol{I}_1\\). It seems that all posterior draws come from stationary distributions, as suggested by the diagnostics and posterior plots (see Exercise 2). The following code uses the command MCMChregress from the package MCMCpack to run this application. This command is also used by our GUI to perform inference in hierarchical longitudinal normal models. We can see that the 95% symmetric credible intervals for public capital, private capital, employment, and unemployment are (-2.54e-02, -2.06e-02), (2.92e-01, 2.96e-01), (7.62e-01, 7.67e-01) and (-5.47e-03, -5.31e-03), respectively. The posterior mean elasticity estimate of public capital to GSP is -0.023, that is, an increase by 1% in public capital means a 0.023% decrease in gross state product. The posterior mean estimates of private capital and employment elasticities are 0.294 and 0.765, respectively. In addition, a 1 percentage point increase in the unemployment rate means a decrease of 0.54% in GSP. It seems that all these variables are statistically relevant. In addition, the posterior mean estimates of the variance associated with the unobserved heterogeneity and stochastic errors are 1.06e-01 and 1.45e-03. We obtained the posterior chain of the proportion of the variance associated with the unobserved heterogeneity. The 95% symmetric credible interval is (0.98, 0.99) for this proportion, that is, unobserved heterogeneity is very important to explain the total variability. rm(list = ls()) set.seed(12345) DataGSP &lt;- read.csv(&quot;https://raw.githubusercontent.com/besmarter/BSTApp/refs/heads/master/DataApp/8PublicCap.csv&quot;, sep = &quot;,&quot;, header = TRUE, quote = &quot;&quot;) attach(DataGSP) ## The following object is masked from DataUSfilcal: ## ## year ## The following object is masked from Data (pos = 9): ## ## id ## The following object is masked from DataUtEst (pos = 10): ## ## id ## The following object is masked from Data (pos = 15): ## ## id ## The following object is masked from mydata: ## ## id ## The following object is masked from dataset (pos = 18): ## ## year ## The following object is masked from dataset (pos = 20): ## ## year ## The following object is masked from DataUtEst (pos = 21): ## ## id K1 &lt;- 5; K2 &lt;- 1 b0 &lt;- rep(0, K1); B0 &lt;- diag(K1) r0 &lt;- 5; R0 &lt;- diag(K2) a0 &lt;- 0.001; d0 &lt;- 0.001 Resultshreg &lt;- MCMCpack::MCMChregress(fixed = log(gsp)~log(pcap)+log(pc)+log(emp)+unemp, random = ~1, group = &quot;id&quot;, data = DataGSP, burnin = 5000, mcmc = 10000, thin = 1, r = r0, R = R0, nu = a0, delta = d0) ## ## Running the Gibbs sampler. It may be long, keep cool :) ## ## **********:10.0% ## **********:20.0% ## **********:30.0% ## **********:40.0% ## **********:50.0% ## **********:60.0% ## **********:70.0% ## **********:80.0% ## **********:90.0% ## **********:100.0% Betas &lt;- Resultshreg[[&quot;mcmc&quot;]][,1:K1] Sigma2RanEff &lt;- Resultshreg[[&quot;mcmc&quot;]][,54] Sigma2 &lt;- Resultshreg[[&quot;mcmc&quot;]][,55] summary(Betas) ## ## Iterations = 5001:15000 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 10000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## beta.(Intercept) 2.330139 7.940e-03 7.940e-05 7.940e-05 ## beta.log(pcap) -0.023082 1.225e-03 1.225e-05 1.225e-05 ## beta.log(pc) 0.293729 1.007e-03 1.007e-05 1.007e-05 ## beta.log(emp) 0.764645 1.333e-03 1.333e-05 1.340e-05 ## beta.unemp -0.005387 4.114e-05 4.114e-07 4.071e-07 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## beta.(Intercept) 2.314556 2.324656 2.330193 2.33567 2.345548 ## beta.log(pcap) -0.025442 -0.023926 -0.023104 -0.02227 -0.020655 ## beta.log(pc) 0.291738 0.293068 0.293721 0.29441 0.295716 ## beta.log(emp) 0.761969 0.763755 0.764650 0.76554 0.767220 ## beta.unemp -0.005468 -0.005414 -0.005387 -0.00536 -0.005307 summary(Sigma2RanEff) ## ## Iterations = 5001:15000 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 10000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## 0.1058028 0.0215133 0.0002151 0.0002151 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## 0.07208 0.09086 0.10331 0.11751 0.15600 summary(Sigma2) ## ## Iterations = 5001:15000 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 10000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## 1.453e-03 7.361e-05 7.361e-07 7.698e-07 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## 0.001316 0.001403 0.001451 0.001501 0.001606 There are many extensions of this model. For instance, S. Chib and Carlin (1999) propose introducing heteroskedasticity in this model by assuming \\(\\mu_{it} \\mid \\tau_{it} \\sim N(0, \\sigma^2/\\tau_{it})\\), \\(\\tau_{it} \\sim G(v/2,v/2)\\). We ask in Exercise 2 to perform inference on the relationship between productivity and public investment using this setting. Another potential extension is to allow dependence between \\(\\boldsymbol{b}_i\\) and some controls, let’s say \\(\\boldsymbol{z}_i\\), a \\(K_3\\)-dimensional vector, and assume \\(\\boldsymbol{b}_i \\sim N(\\boldsymbol{Z}_i \\boldsymbol{\\gamma}, \\boldsymbol{D})\\) where \\(\\boldsymbol{Z}_i = \\mathbf{I}_{K_2} \\otimes \\boldsymbol{z}_i^{\\top}\\), and complete the model using a prior for \\(\\boldsymbol{\\gamma}\\), \\(\\boldsymbol{\\gamma} \\sim N(\\boldsymbol{\\gamma}_0, \\boldsymbol{\\Gamma}_0)\\). We ask to perform a simulation using this setting in Exercise 3. Example: Simulation exercise of the longitudinal normal model with heteroskedasticity Let’s perform a simulation exercise to assess some potential extensions of the longitudinal hierarchical normal model. The point of departure is to assume that \\[y_{it}=\\beta_0+\\beta_1x_{it1}+\\beta_2x_{it2}+\\beta_3x_{it3}+b_i+w_{it1}b_{i1}+\\mu_{it},\\] where \\(x_{itk}\\sim N(0,1)\\), \\(k=1,2,3\\), \\(w_{it1}\\sim N(0,1)\\), \\(b_i\\sim N(0, 0.7^{1/2})\\), \\(b_{i1}\\sim N(0, 0.6^{1/2})\\), \\(\\mu_{it}\\sim N(0, (0.1/\\tau)^{1/2})\\), \\(\\tau_{it}\\sim G(v/2,v/2)\\) and \\(\\boldsymbol{\\beta}=[0.5 \\ 0.4 \\ 0.6 \\ -0.6]^{\\top}\\), \\(i=1,2,\\dots,50\\). The sample size is 2000 in an unbalanced panel structure. Following same stages as in this section and Exercise 1, the posterior conditional distributions assuming that \\(\\mu_{it}\\mid \\tau_{it}\\sim N(0, \\sigma^2/\\tau_{it})\\), \\(\\tau_{it}\\sim G(v/2,v/2)\\) are given by \\[\\begin{equation*} \\boldsymbol{\\beta}\\mid \\sigma^2,\\boldsymbol{\\tau},\\boldsymbol{D},\\boldsymbol{y}, \\boldsymbol{X}, \\boldsymbol{W} \\sim {N}(\\boldsymbol{\\beta}_n,\\boldsymbol{B}_n), \\end{equation*}\\] where \\(\\boldsymbol{\\tau}=[\\tau_{it}]^{\\top}\\), \\(\\boldsymbol{B}_n = (\\boldsymbol{B}_0^{-1} +\\sum_{i=1}^N \\boldsymbol{X}_i^{\\top}\\boldsymbol{V}_i^{-1}\\boldsymbol{X}_i)^{-1}\\), \\(\\boldsymbol{\\beta}_n= \\boldsymbol{B}_n(\\boldsymbol{B}_0^{-1}\\boldsymbol{\\beta}_0 + \\sum_{i=1}^N\\boldsymbol{X}_i^{\\top}\\boldsymbol{V}_i^{-1}\\boldsymbol{y}_i)\\), \\(\\boldsymbol{V}_i=\\sigma^2\\boldsymbol{\\Psi}_i+\\sigma_{b}^2\\boldsymbol{i}_{T_i}\\boldsymbol{i}_{T_i}^{\\top}\\) and \\(\\boldsymbol{\\Psi}_i=diag\\left\\{\\tau_{it}^{-1}\\right\\}\\). \\[\\begin{equation*} \\boldsymbol{b}_i\\mid \\boldsymbol{\\beta},\\sigma^2,\\boldsymbol{\\tau},\\boldsymbol{D},\\boldsymbol{y}, \\boldsymbol{X}, \\boldsymbol{W} \\sim {N}(\\boldsymbol{b}_{ni},\\boldsymbol{B}_{ni}), \\end{equation*}\\] where \\(\\boldsymbol{B}_{ni}=(\\sigma^{-2}\\boldsymbol{W}_i^{\\top}\\boldsymbol{\\Psi}_i^{-1}\\boldsymbol{W}_i+\\boldsymbol{D}^{-1})^{-1}\\) and \\(\\boldsymbol{b}_{ni}=\\boldsymbol{B}_{ni}(\\sigma^{-2}\\boldsymbol{W}_i^{\\top}\\boldsymbol{\\Psi}_i^{-1}(\\boldsymbol{y}_i-\\boldsymbol{X}_i\\boldsymbol{\\beta}))\\). \\[\\begin{equation*} \\sigma^2\\mid \\boldsymbol{\\beta}, \\boldsymbol{b}, \\boldsymbol{\\tau}, \\boldsymbol{y}, \\boldsymbol{X}, \\boldsymbol{W} \\sim {I}{G}(\\alpha_n, \\delta_n), \\end{equation*}\\] where \\(\\alpha_n=\\alpha_0+\\frac{1}{2}\\sum_{i=1}^N T_i\\) and \\(\\delta_n=\\delta_0+\\frac{1}{2}\\sum_{i=1}^N(\\boldsymbol{y}_i-\\boldsymbol{X}_i\\boldsymbol{\\beta}-\\boldsymbol{W}_i\\boldsymbol{b}_i)^{\\top}\\boldsymbol{\\Psi}_i^{-1}(\\boldsymbol{y}_i-\\boldsymbol{X}_i\\boldsymbol{\\beta}-\\boldsymbol{W}_i\\boldsymbol{b}_i)\\). \\[\\begin{equation*} \\boldsymbol{D}\\mid \\boldsymbol{b} \\sim {I}{W}(d_n, \\boldsymbol{D}_n), \\end{equation*}\\] where \\(d_n=d_0+N\\) and \\(\\boldsymbol{D}_n=d_0\\boldsymbol{D}_0+\\sum_{i=1}^N\\boldsymbol{b}_i\\boldsymbol{b}_i^{\\top}\\). And \\[\\begin{equation*} \\tau_{it}\\mid \\sigma^2, \\boldsymbol{\\beta}, \\boldsymbol{b}, \\boldsymbol{y}, \\boldsymbol{X}, \\boldsymbol{W} \\sim {G}(v_{1n}/2, v_{2ni}/2), \\end{equation*}\\] where \\(v_{1n}=v+1\\) and \\(v_{2ni}=v+\\sigma^{-2}(y_{it}-\\boldsymbol{x}_{it}^{\\top}\\boldsymbol{\\beta}-\\boldsymbol{w}_{it}^{\\top}\\boldsymbol{b}_i)^2\\). The following code implements this simulation, and gets draws of the posterior distributions. We set MCMC iterations, burn-in and thinning parameters equal to 5000, 1000 and 1, respectively. In addition, \\(\\boldsymbol{\\beta}_0=\\boldsymbol{0}_5\\), \\(\\boldsymbol{B}_0=\\boldsymbol{I}_5\\), \\(\\alpha_0=\\delta_0=0.001\\), \\(d_0=2\\), \\(\\boldsymbol{D}_0=\\boldsymbol{I}_2\\) and \\(v=5\\). rm(list = ls()); set.seed(010101) NT &lt;- 2000; N &lt;- 50 id &lt;- c(1:N, sample(1:N, NT - N,replace=TRUE)) table(id) ## id ## 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 ## 42 35 48 53 44 36 43 34 42 38 40 39 41 43 40 30 27 56 39 51 36 30 45 35 33 48 ## 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 ## 37 51 32 46 47 41 44 39 40 48 37 44 37 42 42 34 42 34 41 35 36 34 31 38 x1 &lt;- rnorm(NT); x2 &lt;- rnorm(NT); x3 &lt;- rnorm(NT) X &lt;- cbind(1, x1, x2, x3); K1 &lt;- dim(X)[2] w1 &lt;- rnorm(NT); W &lt;- cbind(1, w1) K2 &lt;- dim(W)[2]; B &lt;- c(0.5, 0.4, 0.6, -0.6) D &lt;- c(0.7, 0.6) b1 &lt;- rnorm(N, 0, sd = D[1]^0.5) b2 &lt;- rnorm(N, 0, sd = D[2]^0.5) b &lt;- cbind(b1, b2) v &lt;- 5; tau &lt;- rgamma(NT, shape = v/2, rate = v/2) sig2 &lt;- 0.1; u &lt;- rnorm(NT, 0, sd = (sig2/tau)^0.5) y &lt;- NULL for(i in 1:NT){ yi &lt;- X[i,]%*%B + W[i,]%*%b[id[i],] + u[i] y &lt;- c(y, yi) } Data &lt;- as.data.frame(cbind(y, x1, x2, x3, w1, id)) mcmc &lt;- 5000; burnin &lt;- 1000; thin &lt;- 1; tot &lt;- mcmc + burnin b0 &lt;- rep(0, K1); B0 &lt;- diag(K1); B0i &lt;- solve(B0) r0 &lt;- K2; R0 &lt;- diag(K2); a0 &lt;- 0.001; d0 &lt;- 0.001 PostBeta &lt;- function(sig2, D, tau){ XVX &lt;- matrix(0, K1, K1) XVy &lt;- matrix(0, K1, 1) for(i in 1:N){ ids &lt;- which(id == i) Ti &lt;- length(ids) Wi &lt;- W[ids, ] taui &lt;- tau[ids] Vi &lt;- sig2*solve(diag(1/taui)) + Wi%*%D%*%t(Wi) ViInv &lt;- solve(Vi) Xi &lt;- X[ids, ] XVXi &lt;- t(Xi)%*%ViInv%*%Xi XVX &lt;- XVX + XVXi yi &lt;- y[ids] XVyi &lt;- t(Xi)%*%ViInv%*%yi XVy &lt;- XVy + XVyi } Bn &lt;- solve(B0i + XVX) bn &lt;- Bn%*%(B0i%*%b0 + XVy) Beta &lt;- MASS::mvrnorm(1, bn, Bn) return(Beta) } Postb &lt;- function(Beta, sig2, D, tau){ Di &lt;- solve(D); bis &lt;- matrix(0, N, K2) for(i in 1:N){ ids &lt;- which(id == i) Wi &lt;- W[ids, ]; Xi &lt;- X[ids, ] yi &lt;- y[ids]; taui &lt;- tau[ids] Taui &lt;- solve(diag(1/taui)) Wtei &lt;- sig2^(-1)*t(Wi)%*%Taui%*%(yi - Xi%*%Beta) Bni &lt;- solve(sig2^(-1)*t(Wi)%*%Taui%*%Wi + Di) bni &lt;- Bni%*%Wtei bi &lt;- MASS::mvrnorm(1, bni, Bni) bis[i, ] &lt;- bi } return(bis) } PostSig2 &lt;- function(Beta, bs, tau){ an &lt;- a0 + 0.5*NT ete &lt;- 0 for(i in 1:N){ ids &lt;- which(id == i) Xi &lt;- X[ids, ]; yi &lt;- y[ids] Wi &lt;- W[ids, ]; taui &lt;- tau[ids] Taui &lt;- solve(diag(1/taui)) ei &lt;- yi - Xi%*%Beta - Wi%*%bs[i, ] etei &lt;- t(ei)%*%Taui%*%ei ete &lt;- ete + etei } dn &lt;- d0 + 0.5*ete sig2 &lt;- MCMCpack::rinvgamma(1, shape = an, scale = dn) return(sig2) } PostD &lt;- function(bs){ rn &lt;- r0 + N btb &lt;- matrix(0, K2, K2) for(i in 1:N){ bsi &lt;- bs[i, ] btbi &lt;- bsi%*%t(bsi) btb &lt;- btb + btbi } Rn &lt;- d0*R0 + btb Sigma &lt;- MCMCpack::riwish(v = rn, S = Rn) return(Sigma) } PostTau &lt;- function(sig2, Beta, bs){ v1n &lt;- v + 1 v2n &lt;- NULL for(i in 1:NT){ Xi &lt;- X[i, ]; yi &lt;- y[i] Wi &lt;- W[i, ]; bi &lt;- bs[id[i],] v2ni &lt;- v + sig2^(-1)*(yi - Xi%*%Beta - Wi%*%bi)^2 v2n &lt;- c(v2n, v2ni) } tau &lt;- rgamma(NT, shape = rep(v1n/2, NT), rate = v2n/2) return(tau) } PostBetas &lt;- matrix(0, tot, K1); PostDs &lt;- matrix(0, tot, K2*(K2+1)/2) PostSig2s &lt;- rep(0, tot); Postbs &lt;- array(0, c(N, K2, tot)) PostTaus &lt;- matrix(0, tot, NT); RegLS &lt;- lm(y ~ X - 1) SumLS &lt;- summary(RegLS) Beta &lt;- SumLS[[&quot;coefficients&quot;]][,1] sig2 &lt;- SumLS[[&quot;sigma&quot;]]^2; D &lt;- diag(K2) tau &lt;- rgamma(NT, shape = v/2, rate = v/2) pb &lt;- winProgressBar(title = &quot;progress bar&quot;, min = 0, max = tot, width = 300) for(s in 1:tot){ bs &lt;- Postb(Beta = Beta, sig2 = sig2, D = D, tau = tau) D &lt;- PostD(bs = bs) Beta &lt;- PostBeta(sig2 = sig2, D = D, tau = tau) sig2 &lt;- PostSig2(Beta = Beta, bs = bs, tau = tau) tau &lt;- PostTau(sig2 = sig2, Beta = Beta, bs = bs) PostBetas[s,] &lt;- Beta PostDs[s,] &lt;- matrixcalc::vech(D) PostSig2s[s] &lt;- sig2 Postbs[, , s] &lt;- bs PostTaus[s,] &lt;- tau setWinProgressBar(pb, s, title=paste( round(s/tot*100, 0),&quot;% done&quot;)) } close(pb) ## NULL keep &lt;- seq((burnin+1), tot, thin) Bs &lt;- PostBetas[keep,]; Ds &lt;- PostDs[keep,] bs &lt;- Postbs[, , keep]; sig2s &lt;- PostSig2s[keep] taus &lt;- PostTaus[keep,] summary(coda::mcmc(Bs)) ## ## Iterations = 1:5000 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 5000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## [1,] 0.3215 0.12222 0.0017284 0.0017051 ## [2,] 0.3696 0.01471 0.0002081 0.0001595 ## [3,] 0.6254 0.01555 0.0002199 0.0001687 ## [4,] -0.6068 0.01498 0.0002118 0.0001636 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## var1 0.07833 0.2412 0.3232 0.4022 0.5619 ## var2 0.34101 0.3598 0.3697 0.3793 0.3988 ## var3 0.59596 0.6150 0.6251 0.6351 0.6574 ## var4 -0.63722 -0.6165 -0.6067 -0.5966 -0.5785 summary(coda::mcmc(Ds)) ## ## Iterations = 1:5000 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 5000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## [1,] 0.70746 0.14999 0.002121 0.002121 ## [2,] -0.08457 0.09101 0.001287 0.001316 ## [3,] 0.54517 0.11304 0.001599 0.001647 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## var1 0.4720 0.5995 0.68858 0.79206 1.05285 ## var2 -0.2721 -0.1405 -0.08185 -0.02482 0.09186 ## var3 0.3689 0.4644 0.52978 0.60946 0.81999 summary(coda::mcmc(sig2s)) ## ## Iterations = 1:5000 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 5000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## 0.1531713 0.0592737 0.0008383 0.0014390 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## 0.1022 0.1157 0.1324 0.1683 0.3217 We can see that all the 95% credible intervals encompass the population parameters, except for the second fixed effect and the variance of the model, but both for a tiny margin. References "],["sec92.html", "9.2 Logit model", " 9.2 Logit model We can use the framework of Section 9.1 to perform inference in models with longitudinal/panel data of binary response variables. In particular, let \\(y_{it} \\sim B(\\pi_{it})\\), where \\(\\text{logit}(\\pi_{it}) = \\log\\left(\\frac{\\pi_{it}}{1 - \\pi_{it}}\\right) \\equiv y_{it}^*\\), such that \\(y_{it}^* \\sim N(\\boldsymbol{x}_{it}^{\\top} \\boldsymbol{\\beta} + \\boldsymbol{w}_{it}^{\\top} \\boldsymbol{b}_i, \\sigma^2)\\). Thus, we can augment the model with the latent variable \\(y_{it}^*\\) and perform inference using a Metropolis-within-Gibbs sampling algorithm based on the posterior conditional distributions from the previous section. We can implement a Gibbs sampling algorithm to sample draws from the posterior conditional distributions of \\(\\boldsymbol{\\beta}\\), \\(\\sigma^2\\), \\(\\boldsymbol{b}_i\\), and \\(\\boldsymbol{D}\\) using the equations in Section 9.1 conditional on \\(\\boldsymbol{y}_i^*\\). Then, we can use a random walk Metropolis-Hastings algorithm to sample \\(y_{it}^*\\), where the proposal distribution is Gaussian with mean \\(y_{it}^*\\) and variance \\(v^2\\), that is, \\(y_{it}^{*c} = y_{it}^* + \\epsilon_{it}\\), where \\(\\epsilon_{it} \\sim \\mathcal{N}(0, v^2)\\), and \\(v\\) is a tuning parameter to achieve good acceptance rates. Finally, for making predictions, we should take into account that \\(\\mathbb{E}[\\pi_{it}] = \\frac{1}{1 + \\exp\\left\\{(\\boldsymbol{x}_{it}^{\\top} \\boldsymbol{\\beta} + \\boldsymbol{w}_{it}^{\\top} \\boldsymbol{b}_i)/\\sqrt{1 + \\left(\\frac{16\\sqrt{3}}{15\\pi}\\right)^2 \\sigma^2}\\right\\}}\\) (Diggle et al. 2002). The posterior distribution of this model is \\[\\begin{align*} \\pi(\\boldsymbol{\\beta},\\sigma^2, \\boldsymbol{b}_i, \\boldsymbol{D}, \\boldsymbol{y}^*\\mid \\boldsymbol{y}, \\boldsymbol{X}, \\boldsymbol{W})&amp;\\propto \\prod_{i=1}^N \\prod_{t=1}^{T_i}\\left\\{\\pi_{it}^{y_{it}}(1-\\pi_{it})^{1-y_{it}}\\right.\\\\ &amp;\\left.\\times (\\sigma^2)^{-1}\\exp\\left\\{-\\frac{1}{2\\sigma^2}(y_{it}^{*}-\\boldsymbol{x}_{it}^{\\top}\\boldsymbol{\\beta}-\\boldsymbol{w}_{it}^{\\top}\\boldsymbol{b}_i)^{\\top}(y_{it}^{*}-\\boldsymbol{x}_{it}^{\\top}\\boldsymbol{\\beta}-\\boldsymbol{w}_{it}^{\\top}\\boldsymbol{b}_i)\\right\\}\\right\\}\\\\ &amp;\\times \\exp\\left\\{-\\frac{1}{2}(\\boldsymbol{\\beta}-\\boldsymbol{\\beta}_0)^{\\top}\\boldsymbol{B}_0^{-1}(\\boldsymbol{\\beta}-\\boldsymbol{\\beta}_0)\\right\\}\\\\ &amp;\\times \\exp\\left\\{-\\frac{1}{2}\\sum_{i=1}^N \\boldsymbol{b}_i^{\\top}\\boldsymbol{D}^{-1}\\boldsymbol{b}_i\\right\\}\\\\ &amp;\\times (\\sigma^2)^{-\\alpha_0-1}\\exp\\left\\{-\\frac{\\delta_0}{\\sigma^2}\\right\\}\\\\ &amp;\\times |\\boldsymbol{D}|^{-(d_0+K_2+1)/2}\\exp\\left\\{-\\frac{1}{2}tr(d_0\\boldsymbol{D}_0\\boldsymbol{D}^{-1})\\right\\}. \\end{align*}\\] We can get samples of \\(y_{it}^*\\) from a normal distribution with mean equal to \\(\\boldsymbol{x}_{it}^{\\top}\\boldsymbol{\\beta}+\\boldsymbol{w}_{it}^{\\top}\\boldsymbol{b}_i\\) and variance \\(\\sigma^2\\), and use these samples to get \\(\\pi_{it}=\\frac{1}{1+e^{-y_{it}^*}}\\), \\(y_{it}^{*c}=y_{it}^{*}+\\epsilon_{it}\\) and \\(\\pi_{it}^c=\\frac{1}{1+e^{-y_{it}^{*c}}}\\), and calculate the acceptance rate of the Metropolis-Hastings algorithm, \\[\\begin{align*} \\alpha=\\min\\left(1,\\frac{ \\pi_{it}^{cy_{it}}(1-\\pi_{it}^c)^{(1-y_{it})}\\times\\exp\\left\\{-\\frac{1}{2\\sigma^2}(y_{it}^{c*}-\\boldsymbol{x}_{it}^{\\top}\\boldsymbol{\\beta}-\\boldsymbol{w}_{it}^{\\top}\\boldsymbol{b}_i)^{\\top}(y_{it}^{c*}-\\boldsymbol{x}_{it}^{\\top}\\boldsymbol{\\beta}-\\boldsymbol{w}_{it}^{\\top}\\boldsymbol{b}_i)\\right\\}}{\\pi_{it}^{y_{it}}(1-\\pi_{it})^{(1-y_{it})}\\times\\exp\\left\\{-\\frac{1}{2\\sigma^2}(y_{it}^{*}-\\boldsymbol{x}_{it}^{\\top}\\boldsymbol{\\beta}-\\boldsymbol{w}_{it}^{\\top}\\boldsymbol{b}_i)^{\\top}(y_{it}^{*}-\\boldsymbol{x}_{it}^{\\top}\\boldsymbol{\\beta}-\\boldsymbol{w}_{it}^{\\top}\\boldsymbol{b}_i)\\right\\}}\\right). \\end{align*}\\] Example: Doctor visits in Germany We used the dataset 9VisitDoc.csv provided by Winkelmann (2004)52. We analyze the determinants of a binary variable (DocVis), which equals 1 if an individual visited a physician in the last three months and 0 otherwise. The dataset contains 32,837 observations of 9,197 individuals in an unbalanced longitudinal/panel dataset over the years 1995–1999 from the German Socioeconomic Panel Data. The specification is given by \\[\\begin{align*} \\text{logit}(\\pi_{it}) &amp;= \\beta_1 + \\beta_2 \\text{Age} + \\beta_3 \\text{Male} + \\beta_4 \\text{Sport} + \\beta_5 \\text{LogInc} \\\\ &amp;\\quad + \\beta_6 \\text{GoodHealth} + \\beta_7 \\text{BadHealth} + b_i + b_{i1} \\text{Sozh}, \\end{align*}\\] where \\(\\pi_{it} = p(\\text{DocVis}_{it} = 1)\\). This specification controls for age, a gender indicator (with 1 representing male), whether the individual practices any sport (with 1 for sport), the logarithm of monthly gross income, and self-perception of health status, where “good” and “bad” are compared to a baseline of “regular”. Additionally, we assume that unobserved heterogeneity is linked to whether the individual receives welfare payments (with Sozh equal to 1 for receiving welfare). We set 10,000 MCMC iterations, plus 1,000 burn-in, and a thinning parameter equal to 10. In addition, \\(\\boldsymbol{\\beta}_0 = \\boldsymbol{0}_7\\), \\(\\boldsymbol{B}_0 = \\boldsymbol{I}_7\\), \\(\\alpha_0 = \\delta_0 = 0.001\\), \\(d_0 = 5\\), and \\(\\boldsymbol{D}_0 = \\boldsymbol{I}_2\\). The following Algorithm shows how to perform inference of the hierarchical longitudinal logit model using our GUI. Algorithm: Hierarchical Longitudinal Logit Model Select Hierarchical Longitudinal Model on the top panel Select Logit model using the left radio button Upload the dataset selecting first if there is a header in the file and the kind of separator in the csv file of the dataset (comma, semicolon, or tab). Then, use the Browse button under the Choose File legend Select MCMC iterations, burn-in, and thinning parameters using the Range sliders Write down the formula of the fixed effects equation in the Main Equation: Fixed Effects box. This formula must be written using the syntax of the formula command of R software. This equation includes the intercept by default, so do not include it in the equation Write down the formula of the random effects equation in the Main Equation: Random Effects box without writing the dependent variable, that is, starting the equation with the tilde (~) symbol. This formula must be written using the syntax of the formula command of R software. This equation includes the intercept by default, so do not include it in the equation. If there are just random intercepts, do not write anything in this box Write down the name of the grouping variable, that is, the variable that indicates the cross-sectional units Set the hyperparameters of the fixed effects: mean vector, covariance matrix, shape, and scale parameters. This step is not necessary as by default our GUI uses non-informative priors Set the hyperparameters of the random effects: degrees of freedom and scale matrix of the inverse Wishart distribution. This step is not necessary as by default our GUI uses non-informative priors Click the Go! button Analyze results Download posterior chains and diagnostic plots using the Download Posterior Chains and Download Posterior Graphs buttons We show in the following code how to perform inference of this example using the command MCMChlogit from the MCMCpack package. We fixed the variance for over-dispersion (\\(\\sigma^2\\)) setting FixOD = 1 in this example. Our GUI does not fix this value, that is, it sets FixOD = 0, which is the default value in the command MCMChlogit. We ask to replicate this example using our GUI in Exercise 4. The command MCMChlogit uses an adaptive algorithm to tune \\(v\\) based on an optimal acceptance rate equal to 0.44. rm(list = ls()) set.seed(12345) Data &lt;- read.csv(&quot;https://raw.githubusercontent.com/besmarter/BSTApp/refs/heads/master/DataApp/9VisitDoc.csv&quot;, sep = &quot;,&quot;, header = TRUE, quote = &quot;&quot;) attach(Data) ## The following objects are masked from DataGSP: ## ## id, unemp ## The following object is masked from DataIntRate (pos = 7): ## ## Year ## The following object is masked from DataIntRate (pos = 9): ## ## Year ## The following objects are masked from Data (pos = 10): ## ## Age, id ## The following object is masked from DataUtEst (pos = 11): ## ## id ## The following object is masked from Data (pos = 14): ## ## Age ## The following object is masked from Data (pos = 15): ## ## Age ## The following objects are masked from Data (pos = 16): ## ## Age, id ## The following objects are masked from mydata: ## ## Age, id ## The following object is masked from Data (pos = 18): ## ## Age ## The following object is masked from DataUtEst (pos = 22): ## ## id K1 &lt;- 7; K2 &lt;- 2; N &lt;- 9197 b0 &lt;- rep(0, K1); B0 &lt;- diag(K1) r0 &lt;- 5; R0 &lt;- diag(K2) a0 &lt;- 0.001; d0 &lt;- 0.001 RegLogit &lt;- glm(DocVis ~ Age + Male + Sport + LogInc + GoodHealth + BadHealth, family = binomial(link = &quot;logit&quot;)) SumLogit &lt;- summary(RegLogit) Beta0 &lt;- SumLogit[[&quot;coefficients&quot;]][,1] mcmc &lt;- 10000; burnin &lt;- 1000; thin &lt;- 10 # MCMChlogit Resultshlogit &lt;- MCMCpack::MCMChlogit(fixed = DocVis ~ Age + Male + Sport + LogInc + GoodHealth + BadHealth, random = ~Sozh, group=&quot;id&quot;, data = Data, burnin = burnin, mcmc = mcmc, thin = thin, mubeta = b0, Vbeta = B0, r = r0, R = R0, nu = a0, delta = d0, beta.start = Beta0, FixOD = 1) ## ## Running the Gibbs sampler. It may be long, keep cool :) ## ## **********:10.0%, mean accept. rate=0.445 ## **********:20.0%, mean accept. rate=0.445 ## **********:30.0%, mean accept. rate=0.446 ## **********:40.0%, mean accept. rate=0.446 ## **********:50.0%, mean accept. rate=0.445 ## **********:60.0%, mean accept. rate=0.446 ## **********:70.0%, mean accept. rate=0.446 ## **********:80.0%, mean accept. rate=0.445 ## **********:90.0%, mean accept. rate=0.446 ## **********:100.0%, mean accept. rate=0.445 Betas &lt;- Resultshlogit[[&quot;mcmc&quot;]][,1:K1] Sigma2RanEff &lt;- Resultshlogit[[&quot;mcmc&quot;]][,c(K2*N+K1+1, 2*N+K1+K2^2)] summary(Betas) ## ## Iterations = 1001:10991 ## Thinning interval = 10 ## Number of chains = 1 ## Sample size per chain = 1000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## beta.(Intercept) -0.410007 0.351422 1.111e-02 0.018150 ## beta.Age 0.009393 0.002241 7.088e-05 0.000122 ## beta.Male -1.098865 0.048329 1.528e-03 0.002393 ## beta.Sport 0.315638 0.046056 1.456e-03 0.002079 ## beta.LogInc 0.268030 0.048295 1.527e-03 0.002604 ## beta.GoodHealth -1.071630 0.047380 1.498e-03 0.002606 ## beta.BadHealth 1.375003 0.079114 2.502e-03 0.005421 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## beta.(Intercept) -1.108562 -0.642896 -0.416944 -0.16633 0.28044 ## beta.Age 0.005106 0.007813 0.009507 0.01091 0.01374 ## beta.Male -1.191406 -1.132530 -1.098185 -1.06565 -1.00809 ## beta.Sport 0.225693 0.284683 0.315987 0.34871 0.40168 ## beta.LogInc 0.178283 0.235760 0.266105 0.29965 0.36735 ## beta.GoodHealth -1.164836 -1.104623 -1.070151 -1.04015 -0.98393 ## beta.BadHealth 1.223310 1.324250 1.371644 1.42690 1.53306 summary(Sigma2RanEff) ## ## Iterations = 1001:10991 ## Thinning interval = 10 ## Number of chains = 1 ## Sample size per chain = 1000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## VCV.(Intercept).(Intercept) 2.2409 0.09263 0.002929 0.009415 ## VCV.Sozh.Sozh 0.7015 0.26915 0.008511 0.095633 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## VCV.(Intercept).(Intercept) 2.0749 2.1709 2.238 2.303 2.422 ## VCV.Sozh.Sozh 0.3536 0.4875 0.626 0.906 1.271 The results suggest that age, sports, income and a bad perception of health status increase the probability of visiting the physician, the posterior estimates have 95% symmetric credible intervals equal to (5.1e-03, 1.3e-02), (0.23, 0.40), (0.18, 0.37) and (1.22, 1.53), whereas men have a lower probability of visiting a physician, the 95% credible interval is (-1.19, -1.01), and individuals who have a good perception of their health status also have a lower probability of visiting the doctor, the 95% credible interval is (-1.16, -0.98). The 95% credible interval of the variances of the unobserved heterogeneity associated with the welfare program is (0.35, 1.27). References "],["sec93.html", "9.3 Poisson model", " 9.3 Poisson model We can use same ideas as in Section 9.2 to perform inference in longitudinal/panel datasets where the dependent variable takes non-negative integers. Let’s assume that \\(y_{it}\\sim P(\\lambda_{it})\\) where \\(\\log(\\lambda_{it})=y_{it}^*\\) such that \\(y_{it}^*\\sim N(\\boldsymbol{x}_{it}^{\\top}\\boldsymbol{\\beta}+\\boldsymbol{w}_{it}^{\\top}\\boldsymbol{b}_i,\\sigma^2)\\). We can augment the model with the latent variable \\(y_{it}^{*}\\), and again use a Metropolis-within-Gibbs algorithm to perform inference in this model. The posterior distribution of this model is \\[\\begin{align*} \\pi(\\boldsymbol{\\beta},\\sigma^2, \\boldsymbol{b}_i, \\boldsymbol{D}, \\boldsymbol{y}^*\\mid \\boldsymbol{y}, \\boldsymbol{X}, \\boldsymbol{W})&amp;\\propto \\prod_{i=1}^N \\prod_{t=1}^{T_i}\\left\\{\\lambda_{it}^{y_{it}}\\exp\\left\\{-\\lambda_{it}\\right\\}\\right.\\\\ &amp;\\left.\\times (\\sigma^2)^{-1}\\exp\\left\\{-\\frac{1}{2\\sigma^2}(y_{it}^*-\\boldsymbol{x}_{it}^{\\top}\\boldsymbol{\\beta}-\\boldsymbol{w}_{it}^{\\top}\\boldsymbol{b}_i)^{\\top}(y_{it}^*-\\boldsymbol{x}_{it}^{\\top}\\boldsymbol{\\beta}-\\boldsymbol{w}_{it}^{\\top}\\boldsymbol{b}_i)\\right\\}\\right\\}\\\\ &amp;\\times \\exp\\left\\{-\\frac{1}{2}(\\boldsymbol{\\beta}-\\boldsymbol{\\beta}_0)^{\\top}\\boldsymbol{B}_0^{-1}(\\boldsymbol{\\beta}-\\boldsymbol{\\beta}_0)\\right\\}\\\\ &amp;\\times \\exp\\left\\{-\\frac{1}{2}\\sum_{i=1}^N \\boldsymbol{b}_i^{\\top}\\boldsymbol{D}^{-1}\\boldsymbol{b}_i\\right\\}\\\\ &amp;\\times (\\sigma^2)^{-\\alpha_0-1}\\exp\\left\\{-\\frac{\\delta_0}{\\sigma^2}\\right\\}\\\\ &amp;\\times |\\boldsymbol{D}|^{-(d_0+K_2+1)/2}\\exp\\left\\{-\\frac{1}{2}tr(d_0\\boldsymbol{D}_0\\boldsymbol{D}^{-1})\\right\\}. \\end{align*}\\] We can get samples of \\(y_{it}^*\\) from a normal distribution with mean equal to \\(\\boldsymbol{x}_{it}^{\\top}\\boldsymbol{\\beta}+\\boldsymbol{w}_{it}^{\\top}\\boldsymbol{b}_i\\) and variance \\(\\sigma^2\\), and use these samples to get \\(\\lambda_{it}=\\exp(y_{it}^*)\\), \\(y_{it}^{*c}=y_{it}^{*}+\\epsilon_{it}\\), where \\(\\epsilon_{it}\\sim\\mathcal{N}(0,v^2)\\), \\(v\\) is a tuning parameter to get good acceptance rates, and \\(\\lambda_{it}^c=\\exp(y_{it}^{*c})\\). The acceptance rate of the Metropolis-Hastings algorithm is \\[\\begin{align*} \\alpha=\\min\\left(1,\\frac{ \\lambda_{it}^{cy_{it}}\\exp(-\\lambda_{it}^c)\\times\\exp\\left\\{-\\frac{1}{2\\sigma^2}(y_{it}^{c*}-\\boldsymbol{x}_{it}^{\\top}\\boldsymbol{\\beta}-\\boldsymbol{w}_{it}^{\\top}\\boldsymbol{b}_i)^{\\top}(y_{it}^{c*}-\\boldsymbol{x}_{it}^{\\top}\\boldsymbol{\\beta}-\\boldsymbol{w}_{it}^{\\top}\\boldsymbol{b}_i)\\right\\}}{\\lambda_{it}^{y_{it}}\\exp(-\\lambda_{it})\\times\\exp\\left\\{-\\frac{1}{2\\sigma^2}(y_{it}^{*}-\\boldsymbol{x}_{it}^{\\top}\\boldsymbol{\\beta}-\\boldsymbol{w}_{it}^{\\top}\\boldsymbol{b}_i)^{\\top}(y_{it}^{*}-\\boldsymbol{x}_{it}^{\\top}\\boldsymbol{\\beta}-\\boldsymbol{w}_{it}^{\\top}\\boldsymbol{b}_i)\\right\\}}\\right). \\end{align*}\\] In addition, we should use the posterior conditional distributions from Section 9.1 to complete the algorithm getting samples of \\(\\boldsymbol{\\beta}\\), \\(\\sigma^2\\), \\(\\boldsymbol{b}_i\\) and \\(\\boldsymbol{D}\\) replacing \\(y_{it}\\) by \\({y}_{it}^*\\). We should take into account for doing predictions that \\(\\mathbb{E}[{\\lambda}_{it}]=\\exp\\left\\{\\boldsymbol{x}_{it}^{\\top}\\boldsymbol{\\beta}+\\boldsymbol{w}_{it}^{\\top}\\boldsymbol{b}_i+0.5\\sigma^2\\right\\}\\) (Diggle et al. 2002). Example: Simulation exercise Let’s perform a simulation exercise to assess the performance of the hierarchical longitudinal Poisson model. The point of departure is to assume that \\[ y_{it}^* = \\beta_0 + \\beta_1 x_{it1} + \\beta_2 x_{it2} + \\beta_3 x_{it3} + b_i + w_{it1} b_{i1}, \\] where \\(x_{itk} \\sim N(0,1)\\) for \\(k = 1, 2, 3\\), \\(w_{it1} \\sim N(0,1)\\), \\(b_i \\sim N(0, 0.7^{1/2})\\), \\(b_{i1} \\sim N(0, 0.6^{1/2})\\), and \\(\\boldsymbol{\\beta} = [0.5 \\ 0.4 \\ 0.6 \\ -0.6]^{\\top}\\), with \\(i = 1, 2, \\dots, 50\\). Additionally, \\(y_{it} \\sim P(\\lambda_{it})\\), where \\(\\lambda_{it} = \\exp(y_{it}^*)\\). The sample size is 1000 in an unbalanced panel structure. We set the priors as \\(\\boldsymbol{\\beta}_0 = \\boldsymbol{0}_4\\), \\(\\boldsymbol{B}_0 = \\boldsymbol{I}_4\\), \\(\\alpha_0 = \\delta_0 = 0.001\\), \\(d_0 = 2\\), and \\(\\boldsymbol{D}_0 = \\boldsymbol{I}_2\\). The number of MCMC iterations, burn-in, and thinning parameters are 15,000, 5,000, and 10, respectively. The following code shows how to perform inference in the hierarchical longitudinal Poisson model programming the Metropolis-within-Gibbs sampler. rm(list = ls()); set.seed(010101) NT &lt;- 1000; N &lt;- 50 id &lt;- c(1:N, sample(1:N, NT - N,replace=TRUE)) x1 &lt;- rnorm(NT); x2 &lt;- rnorm(NT); x3 &lt;- rnorm(NT) X &lt;- cbind(1, x1, x2, x3) K1 &lt;- dim(X)[2]; w1 &lt;- rnorm(NT) W &lt;- cbind(1, w1); K2 &lt;- dim(W)[2] B &lt;- c(0.5, 0.4, 0.6, -0.6) D &lt;- c(0.7, 0.6); sig2 &lt;- 0.1 b1 &lt;- rnorm(N, 0, sd = D[1]^0.5) b2 &lt;- rnorm(N, 0, sd = D[2]^0.5) b &lt;- cbind(b1, b2) yl &lt;- NULL for(i in 1:NT){ ylmeani &lt;- X[i,]%*%B + W[i,]%*%b[id[i],] yli &lt;- rnorm(1, ylmeani, sig2^0.5) yl &lt;- c(yl, yli) } lambdait &lt;- exp(yl); y &lt;- rpois(NT, lambdait) Data &lt;- as.data.frame(cbind(y, x1, x2, x3, w1, id)) mcmc &lt;- 15000; burnin &lt;- 5000; thin &lt;- 10; tot &lt;- mcmc + burnin b0 &lt;- rep(0, K1); B0 &lt;- diag(K1); B0i &lt;- solve(B0) r0 &lt;- K2; R0 &lt;- diag(K2); a0 &lt;- 0.001; d0 &lt;- 0.001 LatentMHV1 &lt;- function(tuning, Beta, bs, sig2){ ylhat &lt;- rep(0, NT) accept &lt;- NULL for(i in 1:NT){ ids &lt;- which(id == i) yi &lt;- y[i] ylhatmeani &lt;- X[i,]%*%Beta + W[i,]%*%bs[id[i],] ylhati &lt;- rnorm(1, ylhatmeani, sd = sig2^0.5) lambdahati &lt;- exp(ylhati) ei &lt;- rnorm(1, 0, sd = tuning) ylpropi &lt;- ylhati + ei lambdapropi &lt;- exp(ylpropi) logPosthati &lt;- sum(dpois(yi, lambdahati, log = TRUE) + dnorm(ylhati, ylhatmeani, sig2^0.5, log = TRUE)) logPostpropi &lt;- sum(dpois(yi, lambdapropi, log = TRUE) + dnorm(ylpropi, ylhatmeani, sig2^0.5, log = TRUE)) alphai &lt;- min(1, exp(logPostpropi - logPosthati)) ui &lt;- runif(1) if(ui &lt;= alphai){ ylhati &lt;- ylpropi; accepti &lt;- 1 }else{ ylhati &lt;- ylhati; accepti &lt;- 0 } ylhat[i] &lt;- ylhati accept &lt;- c(accept, accepti) } res &lt;- list(ylhat = ylhat, accept = mean(accept)) return(res) } PostBeta &lt;- function(D, ylhat, sig2){ XVX &lt;- matrix(0, K1, K1); XVy &lt;- matrix(0, K1, 1) for(i in 1:N){ ids &lt;- which(id == i); Ti &lt;- length(ids) Wi &lt;- W[ids, ] Vi &lt;- diag(Ti)*sig2 + Wi%*%D%*%t(Wi) ViInv &lt;- solve(Vi); Xi &lt;- X[ids, ] XVXi &lt;- t(Xi)%*%ViInv%*%Xi XVX &lt;- XVX + XVXi yi &lt;- ylhat[ids] XVyi &lt;- t(Xi)%*%ViInv%*%yi XVy &lt;- XVy + XVyi } Bn &lt;- solve(B0i + XVX); bn &lt;- Bn%*%(B0i%*%b0 + XVy) Beta &lt;- MASS::mvrnorm(1, bn, Bn) return(Beta) } Postb &lt;- function(Beta, D, ylhat, sig2){ Di &lt;- solve(D); bis &lt;- matrix(0, N, K2) for(i in 1:N){ ids &lt;- which(id == i) Wi &lt;- W[ids, ]; Xi &lt;- X[ids, ] yi &lt;- ylhat[ids] Wtei &lt;- sig2^(-1)*t(Wi)%*%(yi - Xi%*%Beta) Bni &lt;- solve(sig2^(-1)*t(Wi)%*%Wi + Di) bni &lt;- Bni%*%Wtei bi &lt;- MASS::mvrnorm(1, bni, Bni) bis[i, ] &lt;- bi } return(bis) } PostD &lt;- function(bs){ rn &lt;- r0 + N; btb &lt;- matrix(0, K2, K2) for(i in 1:N){ bsi &lt;- bs[i, ]; btbi &lt;- bsi%*%t(bsi) btb &lt;- btb + btbi } Rn &lt;- d0*R0 + btb Sigma &lt;- MCMCpack::riwish(v = rn, S = Rn) return(Sigma) } PostSig2 &lt;- function(Beta, bs, ylhat){ an &lt;- a0 + 0.5*NT; ete &lt;- 0 for(i in 1:N){ ids &lt;- which(id == i) Xi &lt;- X[ids, ] yi &lt;- ylhat[ids] Wi &lt;- W[ids, ] ei &lt;- yi - Xi%*%Beta - Wi%*%bs[i, ] etei &lt;- t(ei)%*%ei ete &lt;- ete + etei } dn &lt;- d0 + 0.5*ete sig2 &lt;- MCMCpack::rinvgamma(1, shape = an, scale = dn) return(sig2) } PostBetas &lt;- matrix(0, tot, K1); PostDs &lt;- matrix(0, tot, K2*(K2+1)/2) Postbs &lt;- array(0, c(N, K2, tot)); PostSig2s &lt;- rep(0, tot) Accepts &lt;- rep(NULL, tot) RegPois &lt;- glm(y ~ X - 1, family = poisson(link = &quot;log&quot;)) SumPois &lt;- summary(RegPois) Beta &lt;- SumPois[[&quot;coefficients&quot;]][,1] sig2 &lt;- sum(SumPois[[&quot;deviance.resid&quot;]]^2)/SumPois[[&quot;df.residual&quot;]] D &lt;- diag(K2); bs1 &lt;- rnorm(N, 0, sd = D[1,1]^0.5) bs2 &lt;- rnorm(N, 0, sd = D[2,2]^0.5); bs &lt;- cbind(bs1, bs2) tuning &lt;- 0.1; ropt &lt;- 0.44 tunepariter &lt;- seq(round(tot/10, 0), tot, round(tot/10, 0)); l &lt;- 1 pb &lt;- winProgressBar(title = &quot;progress bar&quot;, min = 0, max = tot, width = 300) for(s in 1:tot){ LatY &lt;- LatentMHV1(tuning = tuning, Beta = Beta, bs = bs, sig2 = sig2) ylhat &lt;- LatY[[&quot;ylhat&quot;]] bs &lt;- Postb(Beta = Beta, D = D, ylhat=ylhat, sig2 = sig2) D &lt;- PostD(bs = bs) Beta &lt;- PostBeta(D = D, ylhat = ylhat, sig2 = sig2) sig2 &lt;- PostSig2(Beta = Beta, bs = bs, ylhat = ylhat) PostBetas[s,] &lt;- Beta PostDs[s,] &lt;- matrixcalc::vech(D) Postbs[, , s] &lt;- bs; PostSig2s[s] &lt;- sig2 AcceptRate &lt;- LatY[[&quot;accept&quot;]] Accepts[s] &lt;- AcceptRate if(AcceptRate &gt; ropt){ tuning = tuning*(2-(1-AcceptRate)/(1-ropt)) }else{ tuning = tuning/(2-AcceptRate/ropt) } if(s == tunepariter[l]){ print(AcceptRate); l &lt;- l + 1 } setWinProgressBar(pb, s, title=paste( round(s/tot*100, 0),&quot;% done&quot;)) } ## [1] 0.434 ## [1] 0.447 ## [1] 0.448 ## [1] 0.451 ## [1] 0.439 ## [1] 0.46 ## [1] 0.44 ## [1] 0.409 ## [1] 0.477 ## [1] 0.479 close(pb) ## NULL keep &lt;- seq((burnin+1), tot, thin) Bs &lt;- PostBetas[keep,]; Ds &lt;- PostDs[keep,] bs &lt;- Postbs[, , keep]; sig2s &lt;- PostSig2s[keep] summary(coda::mcmc(Bs)) ## ## Iterations = 1:1500 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 1500 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## [1,] 0.5169 0.20869 0.005388 0.004732 ## [2,] 0.3610 0.06215 0.001605 0.002049 ## [3,] 0.5450 0.06383 0.001648 0.001999 ## [4,] -0.5713 0.06544 0.001690 0.001903 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## var1 0.1038 0.3803 0.5199 0.6534 0.9259 ## var2 0.2432 0.3166 0.3608 0.4003 0.4796 ## var3 0.4213 0.5017 0.5453 0.5885 0.6682 ## var4 -0.7038 -0.6149 -0.5729 -0.5269 -0.4459 summary(coda::mcmc(Ds)) ## ## Iterations = 1:1500 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 1500 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## [1,] 0.5965 0.16852 0.004351 0.005085 ## [2,] -0.1323 0.09418 0.002432 0.003072 ## [3,] 0.2885 0.09854 0.002544 0.003397 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## var1 0.3331 0.4788 0.5732 0.69316 0.99135 ## var2 -0.3354 -0.1926 -0.1277 -0.06692 0.03674 ## var3 0.1252 0.2182 0.2780 0.34731 0.51055 We can see that all 95% credible intervals encompass the population parameters of the fixed effects, the posterior medians are relatively near the population values. However, we do not get good posterior estimates of the covariance matrix of the random effects as the 95% credible intervals do not encompass the second element of the diagonal of this matrix. In addition, the posterior draws of this algorithm over-estimates the over-dispersion parameter. We can perform inference for the hierarchical longitudinal Poisson model in our GUI using the following Algorithm. Our GUI is based on the MCMChpoisson command from the MCMCpack package.53 Algorithm: Hierarchical Longitudinal Poisson Model Select Hierarchical Longitudinal Model on the top panel Select Poisson model using the left radio button Upload the dataset selecting first if there is a header in the file and the kind of separator in the csv file of the dataset (comma, semicolon, or tab). Then, use the Browse button under the Choose File legend Select MCMC iterations, burn-in, and thinning parameters using the Range sliders Write down the formula of the fixed effects equation in the Main Equation: Fixed Effects box. This formula must be written using the syntax of the formula command of R software. This equation includes the intercept by default, so do not include it in the equation Write down the formula of the random effects equation in the Main Equation: Random Effects box without writing the dependent variable, that is, starting the equation with the tilde (~) symbol. This formula must be written using the syntax of the formula command of R software. This equation includes the intercept by default, so do not include it in the equation. If there are just random intercepts, do not write anything in this box Write down the name of the grouping variable, that is, the variable that indicates the cross-sectional units Set the hyperparameters of the fixed effects: mean vector, covariance matrix, shape, and scale parameters. This step is not necessary as by default our GUI uses non-informative priors Set the hyperparameters of the random effects: degrees of freedom and scale matrix of the inverse Wishart distribution. This step is not necessary as by default our GUI uses non-informative priors Click the Go! button Analyze results Download posterior chains and diagnostic plots using the Download Posterior Chains and Download Posterior Graphs buttons References "],["sec94.html", "9.4 Summary", " 9.4 Summary In this chapter, we present how to perform inference in longitudinal/panel data models from a Bayesian perspective. In particular, the Bayesian approach uses a hierarchical structure, where the random effects have priors that depend on hyperparameters, which in turn also have priors. We cover the three most common cases: continuous, binary, and count dependent variables. The basic models presented in this chapter can be easily extended to more flexible cases, given the hierarchical structure. "],["sec95.html", "9.5 Exercises", " 9.5 Exercises Show that the posterior distribution of \\(\\boldsymbol{\\beta} \\mid \\sigma^2, \\boldsymbol{D}\\) is \\(N(\\boldsymbol{\\beta}_n, \\boldsymbol{B}_n)\\), where \\(\\boldsymbol{B}_n = (\\boldsymbol{B}_0^{-1} + \\sum_{i=1}^N \\boldsymbol{X}_i^{\\top} \\boldsymbol{V}_i^{-1} \\boldsymbol{X}_i)^{-1}\\), \\(\\boldsymbol{\\beta}_n = \\boldsymbol{B}_n (\\boldsymbol{B}_0^{-1} \\boldsymbol{\\beta}_0 + \\sum_{i=1}^N \\boldsymbol{X}_i^{\\top} \\boldsymbol{V}_i^{-1} \\boldsymbol{y}_i)\\). The relation between productivity and public investment example continues Perform inference of this example using our GUI. Program from scratch a Gibbs sampling algorithm to perform this application. Set \\(\\boldsymbol{\\beta}_0 = \\boldsymbol{0}_5\\), \\(\\boldsymbol{B}_0 = \\boldsymbol{I}_5\\), \\(\\alpha_0 = \\delta_0 = 0.001\\), \\(d_0 = 5\\) and \\(\\boldsymbol{D}_0 = \\boldsymbol{I}_1\\). Perform inference in this example assuming that \\(\\mu_{it} \\mid \\tau_{it} \\sim N(0, \\sigma^2 / \\tau_{it})\\) and \\(\\tau_{it} \\sim G(v/2, v/2)\\) setting \\(v = 5\\). Simulation exercise of the longitudinal normal model continues Assume that \\[ y_{it} = \\beta_0 + \\beta_1 x_{it1} + \\beta_2 x_{it2} + \\beta_3 x_{it3} + \\beta_4 z_{i1} + b_i + w_{it1} b_{i1} + \\mu_{it}, \\] where \\(x_{itk} \\sim N(0, 1)\\), \\(k = 1, 2, 3\\), \\(z_{i1} \\sim B(0.5)\\), \\(w_{it1} \\sim N(0, 1)\\), \\(b_i \\sim N(0, 0.7^{1/2})\\), \\(b_{i1} \\sim N(0, 0.6^{1/2})\\), \\(\\mu_{it} \\sim N(0, 0.1^{1/2})\\), \\(\\boldsymbol{\\beta} = [0.5, 0.4, 0.6, -0.6, 0.7]^{\\top}\\), \\(i = 1, 2, \\dots, 50\\), and the sample size is 2,000 in an unbalanced panel structure. In addition, we assume that \\(\\boldsymbol{b}_i\\) depends on \\(\\boldsymbol{z}_i = [1, z_{i1}]^{\\top}\\) such that \\(\\boldsymbol{b}_i \\sim N(\\boldsymbol{Z}_i \\boldsymbol{\\gamma}, \\boldsymbol{D})\\) where \\(\\boldsymbol{Z}_i = \\boldsymbol{I}_{K_2} \\otimes \\boldsymbol{z}_i^{\\top}\\), and \\(\\boldsymbol{\\gamma} = [1, 1, 1, 1]\\). The prior for \\(\\boldsymbol{\\gamma}\\) is \\(N(\\boldsymbol{\\gamma}_0, \\boldsymbol{\\Gamma}_0)\\) where we set \\(\\boldsymbol{\\gamma}_0 = \\boldsymbol{0}_4\\) and \\(\\boldsymbol{\\Gamma}_0 = \\boldsymbol{I}_4\\). Perform inference in this model without taking into account the dependence between \\(\\boldsymbol{b}_i\\) and \\(z_{i1}\\), and compare the posterior estimates with the population parameters. Perform inference in this model taking into account the dependence between \\(\\boldsymbol{b}_i\\) and \\(z_{i1}\\), and compare the posterior estimates with the population parameters. Doctor visits in Germany continues I Replicate this example using our GUI, which by default does not fix the over-dispersion parameter (\\(\\sigma^2\\)), and compare the results with the results of this example in Section 9.2. Simulation exercise of the longitudinal logit model Perform a simulation exercise to assess the performance of the hierarchical longitudinal logit model. The point of departure is to assume that \\[ y_{it}^* = \\beta_0 + \\beta_1 x_{it1} + \\beta_2 x_{it2} + \\beta_3 x_{it3} + b_i + w_{it1} b_{i1}, \\] where \\(x_{itk} \\sim N(0, 1)\\), \\(k = 1, 2, 3\\), \\(w_{it1} \\sim N(0, 1)\\), \\(b_i \\sim N(0, 0.7^{1/2})\\), \\(b_{i1} \\sim N(0, 0.6^{1/2})\\), \\(\\boldsymbol{\\beta} = [0.5, 0.4, 0.6, -0.6]^{\\top}\\), \\(i = 1, 2, \\dots, 50\\), and \\(y_{it} \\sim B(\\pi_{it})\\), where \\(\\pi_{it} = \\frac{1}{1 + \\exp(y_{it}^*)}\\). The sample size is 1,000 in an unbalanced panel structure. Perform inference using the command MCMChlogit fixing the over-dispersion parameter, and using \\(\\boldsymbol{\\beta}_0 = \\boldsymbol{0}_4\\), \\(\\boldsymbol{B}_0 = \\boldsymbol{I}_4\\), \\(\\alpha_0 = \\delta_0 = 0.001\\), \\(d_0 = 2\\), and \\(\\boldsymbol{D}_0 = \\boldsymbol{I}_2\\). Program from scratch a Metropolis-within-Gibbs algorithm to perform inference in this simulation. Doctor visits in Germany continues II Take a sub-sample of the first 500 individuals of the dataset 9VisitDoc.csv to perform inference in the number of visits to doctors (DocNum) with the same specification of the example of Doctor visits in Germany in Section 9.2. "],["Chap10.html", "Chapter 10 Bayesian model averaging in variable selection", " Chapter 10 Bayesian model averaging in variable selection We outline in this chapter a framework for addressing model uncertainty and averaging across different models in a probabilistically consistent manner. The discussion tackles two major computational challenges in Bayesian model averaging: the vast space of possible models and the absence of analytical solutions for the marginal likelihood. We begin by illustrating the approach within the Gaussian linear model, assuming exogeneity of the regressors, and extend the analysis to cases with endogenous regressors, and dynamic models. Additionally, we adapt the framework to generalized linear models, including the logit, gamma, and Poisson families. Lastly, we explore alternative methods for computing marginal likelihoods, especially when the Bayesian information criterion’s asymptotic approximation proves inadequate. Remember that we can run our GUI typing shiny::runGitHub(\"besmarter/BSTApp\", launch.browser=T) in the R console or any R code editor and execute it. However, users should see Chapter 5 for details. "],["sec10_1.html", "10.1 Foundation", " 10.1 Foundation Remember from Chapter 1 that Bayesian model averaging (BMA) is an approach which takes into account model uncertainty. In particular, we consider uncertainty in the regressors (variable selection) in a regression framework where there are \\(K\\) possible explanatory variables.54 This implies \\(2^K\\) potential models indexed by parameters \\(\\boldsymbol{\\theta}_m\\), \\(m=1,2,\\dots,2^K\\). Following Simmons et al. (2010), the posterior model probability is \\[\\begin{equation*} \\pi(\\mathcal{M}_j |\\boldsymbol{y})=\\frac{p(\\boldsymbol{y} | \\mathcal{M}_j)\\pi(\\mathcal{M}_j)}{\\sum_{m=1}^{2^K}p(\\boldsymbol{y} | \\mathcal{M}_m)\\pi(\\mathcal{M}_m)}, \\end{equation*}\\] where \\(\\pi(\\mathcal{M}_j)\\) is the prior model probability,55 \\[\\begin{equation*} p(\\boldsymbol{y} | \\mathcal{M}_j)=\\int_{\\boldsymbol{\\Theta}_j} p(\\boldsymbol{y}| \\boldsymbol{\\theta}_j,\\mathcal{M}_j)\\pi(\\boldsymbol{\\theta}_j | \\mathcal{M}_j) d\\boldsymbol{\\theta}_{j} \\end{equation*}\\] is the marginal likelihood, and \\(\\pi(\\boldsymbol{\\theta}_j | \\mathcal{M}_j)\\) is the prior distribution of \\(\\boldsymbol{\\theta}_j\\) conditional on model \\(\\mathcal{M}_j\\). Following Adrian E. Raftery (1993), the posterior distribution of \\(\\boldsymbol{\\theta}\\) is \\[\\begin{equation*} \\pi(\\boldsymbol{\\theta}|\\boldsymbol{y})= \\sum_{m=1}^{2^K}\\pi(\\boldsymbol{\\theta}_m|\\boldsymbol{y},\\mathcal{M}_m) \\pi(\\mathcal{M}_m|\\boldsymbol{y}) \\end{equation*}\\] The posterior distribution of the parameter vector \\(\\boldsymbol{\\theta}\\) under model \\(\\mathcal{M}_m\\) is denoted as \\(\\pi(\\boldsymbol{\\theta}_m|\\boldsymbol{y}, \\mathcal{M}_m)\\). The posterior mean of \\(\\boldsymbol{\\theta}\\) is given by: \\[ \\mathbb{E}[\\boldsymbol{\\theta}|\\boldsymbol{y}] = \\sum_{m=1}^{2^K} \\hat{\\boldsymbol{\\theta}}_m \\, \\pi(\\mathcal{M}_m|\\boldsymbol{y}), \\] where \\(\\hat{\\boldsymbol{\\theta}}_m\\) represents the posterior mean under model \\(\\mathcal{M}_m\\). The variance of the \\(k\\)-th element of \\(\\boldsymbol{\\theta}\\) given the data \\(\\boldsymbol{y}\\) is: \\[ \\text{Var}(\\theta_{km}|\\boldsymbol{y}) = \\sum_{m=1}^{2^K} \\pi(\\mathcal{M}_m|\\boldsymbol{y}) \\, \\widehat{\\text{Var}}(\\theta_{km}|\\boldsymbol{y}, \\mathcal{M}_m) + \\sum_{m=1}^{2^K} \\pi(\\mathcal{M}_m|\\boldsymbol{y}) \\left( \\hat{\\theta}_{km} - \\mathbb{E}[\\theta_{km}|\\boldsymbol{y}] \\right)^2, \\] where \\(\\widehat{\\text{Var}}(\\theta_{km}|\\boldsymbol{y}, \\mathcal{M}_m)\\) denotes the posterior variance of the \\(k\\)-th element of \\(\\boldsymbol{\\theta}\\) under model \\(\\mathcal{M}_m\\). The posterior variance highlights how BMA accounts for model uncertainty. The first term represents the weighted variance of each model, averaged across all potential models, while the second term reflects the stability of the estimates across models. The greater the variation in estimates between models, the higher the posterior variance. The posterior predictive distribution is \\[\\begin{equation*} \\pi(\\boldsymbol{y}_0|\\boldsymbol{y})= \\sum_{m=1}^{2^K}p_m(\\boldsymbol{y}_0|\\boldsymbol{y},\\mathcal{M}_m) \\pi(M_m|\\boldsymbol{y}) \\end{equation*}\\] where \\(p_m(\\boldsymbol{y}_0|\\boldsymbol{y},\\mathcal{M}_m)=\\int_{\\boldsymbol{\\Theta}_m} p(\\boldsymbol{y}_0|\\boldsymbol{y},\\boldsymbol{\\theta}_m,\\mathcal{M}_m)\\pi(\\boldsymbol{\\theta}_m |\\boldsymbol{y}, \\mathcal{M}_m) d\\boldsymbol{\\theta}_{m}\\) is the posterior predictive distribution under model \\(\\mathcal{M}_m\\). Another important statistic in BMA is the posterior inclusion probability associated with variable \\(\\boldsymbol{x}_k\\), \\(k=1,2,\\dots,K\\), which is \\[\\begin{equation*} PIP(\\boldsymbol{x}_k)=\\sum_{m=1}^{2^K}\\pi(\\mathcal{M}_m|\\boldsymbol{y})\\times \\mathbb{1}_{k,m}, \\end{equation*}\\] where \\(\\mathbb{1}_{k,m}= \\left\\{ \\begin{array}{lcc} 1&amp; if &amp; \\boldsymbol{x}_{k}\\in \\mathcal{M}_m \\\\ \\\\ 0 &amp; if &amp; \\boldsymbol{x}_{k}\\not \\in \\mathcal{M}_m \\end{array} \\right\\}.\\) R. E. Kass and Raftery (1995) suggest that posterior inclusion probabilities (PIP) less than 0.5 are evidence against the regressor, \\(0.5\\leq PIP&lt;0.75\\) is weak evidence, \\(0.75\\leq PIP&lt;0.95\\) is positive evidence, \\(0.95\\leq PIP&lt;0.99\\) is strong evidence, and \\(PIP\\geq 0.99\\) is very strong evidence. There are two main computational issues in implementing BMA based on variable selection. First, the number of models in the model space is \\(2^K\\), which sometimes can be enormous. For instance, three regressors imply just eight models, see the next Table, but 40 regressors implies approximately 1.1e+12 models. Take into account that models always include the intercept, and all regressors should be standardized to avoid scale issues.56 The second computational issue is calculating the marginal likelihood \\(p(\\boldsymbol{y} | \\mathcal{M}_j)=\\int_{\\boldsymbol{\\Theta}_j} p(\\boldsymbol{y}| \\boldsymbol{\\theta}_j,\\mathcal{M}_j)\\pi(\\boldsymbol{\\theta}_j | \\mathcal{M}_j) d\\boldsymbol{\\theta}_{j}\\), which most of the time does not have an analytic solution. Table 10.1: Space of models Variable \\(M_{1}\\) \\(M_{2}\\) \\(M_{3}\\) \\(M_{4}\\) \\(M_{5}\\) \\(M_{6}\\) \\(M_{7}\\) \\(M_{8}\\) \\(x_1\\) 1 1 1 1 0 0 0 0 \\(x_2\\) 1 1 0 0 1 1 0 0 \\(x_3\\) 1 0 1 0 1 0 1 0 The first computational issue is basically a problem of ranking models. This can be tackled using different approaches, such as Occam’s window criterion (D. Madigan and Raftery 1994; Adrian E. Raftery, Madigan, and Hoeting 1997), reversible jump Markov chain Monte Carlo computation (Green 1995), Markov chain Monte Carlo model composition (D. Madigan, York, and Allard 1995), and multiple testing using intrinsic priors (G. Casella and Moreno 2006) or nonlocal prior densities (Jhonson and Rossell 2012). We focus on Occam’s window and Markov chain Monte Carlo model composition in our GUI.57 In Occam’s window, a model is discarded if its predictive performance is much worse than that of the best model (D. Madigan and Raftery 1994; Adrian E. Raftery, Madigan, and Hoeting 1997). Thus, models not belonging to \\(\\mathcal{M}&#39;=\\left\\{\\mathcal{M}_j:\\frac{\\max_m {\\pi(\\mathcal{M}_m|\\boldsymbol{y})}}{\\pi(\\mathcal{M}_j|\\boldsymbol{y})}\\leq c\\right\\}\\) should be discarded, where \\(c\\) is chosen by the user (D. Madigan and Raftery (1994) propose \\(c=20\\)). In addition, complicated models than are less supported by the data than simpler models are also discarded, that is, \\(\\mathcal{M}&#39;&#39;=\\left\\{\\mathcal{M}_j:\\exists \\mathcal{M}_m\\in\\mathcal{M}&#39;,\\mathcal{M}_m\\subset \\mathcal{M}_j,\\frac{\\pi(\\mathcal{M}_m|\\boldsymbol{y})}{\\pi(\\mathcal{M}_j|\\boldsymbol{y})}&gt;1\\right\\}\\). Then, the set of models used in BMA is \\(\\mathcal{M}^*=\\mathcal{M}&#39;\\cap \\mathcal{M}&#39;&#39;^c\\in\\mathcal{M}\\). Adrian E. Raftery, Madigan, and Hoeting (1997) find that the number of models in \\(\\mathcal{M}^*\\) is normally less than 25. However, the previous theoretical framework requires finding the model with the maximum a posteriori model probability (\\(\\max_m {\\pi(\\mathcal{M}_m|\\boldsymbol{y})}\\)), which implies calculating all possible models in \\(\\mathcal{M}\\). This is computationally burdensome. Hence, a heuristic approach is proposed by Adrian Raftery et al. (2012) based on ideas of D. Madigan and Raftery (1994). The search strategy is based on a series of nested comparisons of ratios of posterior model probabilities. Let \\(\\mathcal{M}_0\\) be a model with one regressor less than model \\(\\mathcal{M}_1\\), then: If \\(\\log(\\pi(\\mathcal{M}_0|\\boldsymbol{y})/\\pi(\\mathcal{M}_1|\\boldsymbol{y}))&gt;\\log(O_R)\\), then \\(\\mathcal{M}_1\\) is rejected and \\(\\mathcal{M}_0\\) is considered. If \\(\\log(\\pi(\\mathcal{M}_0|\\boldsymbol{y})/\\pi(\\mathcal{M}_1|\\boldsymbol{y}))\\leq -\\log(O_L)\\), then \\(\\mathcal{M}_0\\) is rejected, and \\(\\mathcal{M}_1\\) is considered. If \\(\\log(O_L)&lt;\\log(\\pi(\\mathcal{M}_0|\\boldsymbol{y})/\\pi(\\mathcal{M}_1|\\boldsymbol{y}))\\leq \\log(O_R\\)), \\(\\mathcal{M}_0\\) and \\(\\mathcal{M}_1\\) are considered. Here \\(O_R\\) is a number specifying the maximum ratio for excluding models in Occam’s window, and \\(O_L=1/O_R^{2}\\) is defined by default in Adrian Raftery et al. (2012). The search strategy can be “up’‘, adding one regressor, or “down’’, dropping one regressor (see D. Madigan and Raftery (1994) for details about the down and up algorithms). The leaps and bounds algorithm (Furnival and Wilson 1974) is implemented to improve the computational efficiency of this search strategy (Adrian Raftery et al. 2012). Once the set of potentially acceptable models is defined, we discard all the models that are not in \\(\\mathcal{M}&#39;\\), and the models that are in \\(\\mathcal{M}&#39;&#39;\\) where 1 is replaced by \\(\\exp\\left\\{O_R\\right\\}\\) due to the leaps and bounds algorithm giving an approximation to BIC, so as to ensure that no good models are discarded. The second approach that we consider in our GUI to tackle the model space size issue is Markov chain Monte Carlo model composition (MC3) (David Madigan, York, and Allard 1995). In particular, given the space of models \\(\\mathcal{M}_m\\), we simulate a chain of \\(\\mathcal{M}_s\\) models, \\(s = 1, 2, ..., S&lt;&lt;2^K\\), where the algorithm randomly extracts a candidate model \\(\\mathcal{M}_c\\) from a neighborhood of models (\\(nbd(\\mathcal{M}_m)\\)) that consists of the actual model itself and the set of models with either one variable more or one variable less (Adrian E. Raftery, Madigan, and Hoeting 1997). Therefore, there is a transition kernel in the space of models \\(q(\\mathcal{M}_m\\rightarrow \\mathcal{M}_c)\\), such that \\(q(\\mathcal{M}_m\\rightarrow \\mathcal{M}_{c})=0 \\ \\forall \\mathcal{M}_{c}\\notin nbd(\\mathcal{M}_m)\\) and \\(q(\\mathcal{M}_m\\rightarrow \\mathcal{M}_{c})=\\frac{1}{|nbd(\\mathcal{M}_m)|} \\ \\forall \\mathcal{M}_m\\in nbd(\\mathcal{M}_m)\\), \\(|nbd(\\mathcal{M}_m)|\\) being the number of neighbors of \\(\\mathcal{M}_m\\). This candidate model is accepted with probability \\[\\begin{equation*} \\alpha (\\mathcal{M}_{s-1},\\mathcal{M}_{c})=\\min \\bigg \\{ \\frac{|nbd(\\mathcal{M}_m)|p(\\boldsymbol{y} | \\mathcal{M}_c)\\pi(\\mathcal{M}_c)}{|nbd(\\mathcal{M}^{c})|p(\\boldsymbol{y}| \\mathcal{M}_{(s-1)})\\pi(\\mathcal{M}_{(s-1)})},1 \\bigg \\}. \\end{equation*}\\] Observe that by construction \\(|nbd(\\mathcal{M}_m)|=|nbd(\\mathcal{M}_c)|=k\\), except in extreme cases where a model has only one regressor or has all regressors. The Bayesian information criterion is a possible solution for the second computational issue in BMA, that is, calculating the marginal likelihood when there is no an analytic solution. Defining \\(h(\\boldsymbol{\\theta}|\\mathcal{M}_j)=-\\frac{\\log(p(\\boldsymbol{y}| \\boldsymbol{\\theta}_j,\\mathcal{M}_j)\\pi(\\boldsymbol{\\theta}_j | \\mathcal{M}_j))}{N}\\), then \\(p(\\boldsymbol{y} | \\mathcal{M}_j)=\\int_{\\boldsymbol{\\Theta}_j} \\exp\\left\\{-N h(\\boldsymbol{\\theta}|\\mathcal{M}_j)\\right\\} d\\boldsymbol{\\theta}_{j}\\). If \\(N\\) is sufficiently large (technically \\(N\\to \\infty\\)), we can make the following assumptions (Hoeting et al. 1999): We can use the Laplace method for approximating integrals (Tierney and Kadane 1986). The posterior mode is reached at the same point as the maximum likelihood estimator (MLE), denoted by \\(\\hat{\\boldsymbol{\\theta}}_{MLE}\\). We get the following results under these assumptions: \\[\\begin{align*} p(\\boldsymbol{y} | \\mathcal{M}_j)\\approx&amp;\\left( \\frac{2\\pi}{N}\\right)^{K_j/2}|\\boldsymbol{\\Sigma}|^{-1/2} \\exp\\left\\{-N h(\\boldsymbol{\\hat{\\theta}}_j^{MLE}|\\mathcal{M}_j)\\right\\}, \\ N\\rightarrow\\infty, \\end{align*}\\] where \\(\\boldsymbol{\\Sigma}\\) is the inverse of the Hessian matrix of \\(h(\\boldsymbol{\\hat{\\theta}}_j^{MLE}|\\mathcal{M}_j)\\), and \\(K_j=dim\\left\\{\\boldsymbol{\\theta}_j\\right\\}\\). This implies \\[\\begin{align*} \\log\\left(p(\\boldsymbol{y} | \\mathcal{M}_j)\\right)\\approx&amp; \\frac{K_j}{2}\\log(2\\pi)- \\frac{K_j}{2}\\log(N) -\\frac{1}{2}\\log(|\\boldsymbol{\\Sigma}|) + \\log(p(\\boldsymbol{y}| \\boldsymbol{\\hat{\\theta}}_j^{MLE},\\mathcal{M}_j))+\\log(\\pi(\\boldsymbol{\\hat{\\theta}}_j^{MLE} | \\mathcal{M}_j)), \\ N\\rightarrow\\infty. \\end{align*}\\] Since \\(\\frac{K_j}{2}\\log(2\\pi)\\) and \\(\\log(\\pi(\\boldsymbol{\\hat{\\theta}}_j^{MLE} | \\mathcal{M}_j))\\) are constants as functions of \\(\\boldsymbol{y}\\), and \\(|\\boldsymbol{\\Sigma}|\\) is bounded by a finite constant, we have \\[\\begin{align*} log\\left(p(\\boldsymbol{y} | \\mathcal{M}_j)\\right)\\approx&amp; -\\frac{K_j}{2}\\log(N)+\\log(p(\\boldsymbol{y}| \\boldsymbol{\\hat{\\theta}}_j^{MLE},\\mathcal{M}_j))= -\\frac{BIC}{2}, \\ N \\rightarrow \\infty. \\end{align*}\\] The marginal likelihood thus asymptotically converges to a linear transformation of the Bayesian Information Criterion (BIC), significantly simplifying its calculation. In addition, the BIC is consistent, that is, the probability of uncovering the population statistical model converges to one as the sample size converges to infinity given a \\(\\mathcal{M}\\)-closed view (J. Bernardo and Smith 1994), that is, one of the models in consideration is the population statistical model (data generating process) (Schwarz 1978; Burnham and Anderson 2004). In case that there is an \\(\\mathcal{M}\\)-completed view of nature, that is, there is a true data generating process, but the space of models that we are comparing does not include it, the BIC asymptotically selects the model that minimizes the Kullback-Leiber (KL) divergence to the true (population) model (Claeskens and Hjort 2008). References "],["sec102.html", "10.2 The Gaussian linear model", " 10.2 The Gaussian linear model The Gaussian linear model specifies \\(\\boldsymbol{y}=\\alpha\\boldsymbol{i}_N+\\boldsymbol{X}_m\\boldsymbol{\\beta}_m+\\boldsymbol{\\mu}_m\\) such that \\(\\boldsymbol{\\mu}_m\\sim{N}(\\boldsymbol{0},\\sigma^2\\boldsymbol{I}_n)\\), and \\(\\boldsymbol{X}_m\\) does not have the column of ones. Following G. M. Koop (2003), the conjugate prior for the location parameters is \\(\\boldsymbol{\\beta}_m|\\sigma^2 \\sim {N}(\\boldsymbol{\\beta}_{m0}, \\sigma^2 \\boldsymbol{B}_{m0})\\), and the priors for \\(\\sigma^2\\) and \\(\\alpha\\) can be improper, as these parameters are common to all models \\(\\mathcal{M}_m\\). Particularly, \\(\\pi(\\sigma^2)\\propto 1/\\sigma^2\\) (Jeffreys’ prior for the linear Gaussian model, see Ibrahim and Laud (1991)) and \\(\\pi(\\alpha)\\propto 1\\). The selection of the hyperparameters of \\(\\boldsymbol{\\beta}_m\\) is more critical, as these parameters are not common to all models. A very common prior for the location parameters in the BMA literature is the Zellner’s prior (Zellner 1986), where \\(\\boldsymbol{\\beta}_{m0}=\\boldsymbol{0}_m\\) and \\(\\boldsymbol{B}_{m0}=(g_m\\boldsymbol{X}_m^{\\top}\\boldsymbol{X}_m)^{-1}\\). Observe that this covariance matrix is similar to the covariance matrix of the ordinary least squares estimator of the location parameters. This suggests that there is compatibility between the prior information and the sample information, and the only parameter to elicit is \\(g_m\\geq 0\\), which facilitates the elicitation process, as eliciting covariance matrices is a very hard endeavor. Following same steps as in Section 3.3, the posterior conditional distribution of \\(\\boldsymbol{\\beta}_m\\) has covariance matrix \\(\\sigma^2\\boldsymbol{B}_{mn}\\), where \\(\\boldsymbol{B}_{mn}=((1+g_m)\\boldsymbol{X}_m^{\\top}\\boldsymbol{X}_m)^{-1}\\) (Exercise 1), which means that \\(g_m=0\\) implies a non-informative prior, whereas \\(g_m=1\\) implies that prior and data information have same weights. We follow Fernandez, Ley, and Steel (2001), who recommend \\[\\begin{align*} g_m &amp; = \\begin{Bmatrix} 1/K^2, &amp; N \\leq K^2\\\\ 1/N, &amp; N&gt;K^2 \\end{Bmatrix}. \\end{align*}\\] Given the likelihood function, \\[\\begin{equation*} p(\\boldsymbol{\\beta}_m, \\sigma^2|\\boldsymbol{y}, \\boldsymbol{X}_m) = (2\\pi\\sigma^2)^{-\\frac{N}{2}} \\exp \\left\\{-\\frac{1}{2\\sigma^2} (\\boldsymbol{y} - \\alpha\\boldsymbol{i}_N - \\boldsymbol{X}_m\\boldsymbol{\\beta}_m)^{\\top}(\\boldsymbol{y} - \\alpha\\boldsymbol{i}_N - \\boldsymbol{X}_m\\boldsymbol{\\beta}_m) \\right\\}, \\end{equation*}\\] the marginal likelihood associated with model \\(\\mathcal{M}_m\\) is proportional to (Exercise 1) \\[\\begin{align*} p(\\boldsymbol{y}|\\mathcal{M}_m)&amp;\\propto \\left(\\frac{g_m}{1+g_m}\\right)^{k_m/2} \\left[(\\boldsymbol{y}-\\bar{y}\\boldsymbol{i}_N)^{\\top}(\\boldsymbol{y}-\\bar{y}\\boldsymbol{i}_N)-\\frac{1}{1+g_m}(\\boldsymbol{y}^{\\top}\\boldsymbol{P}_{X_m}\\boldsymbol{y})\\right]^{-(N-1)/2}, \\end{align*}\\] where all parameters are indexed to model \\(\\mathcal{M}_m\\), \\(\\boldsymbol{P}_{X_m}=\\boldsymbol{X}_m(\\boldsymbol{X}_m^{\\top}\\boldsymbol{X}_m)^{-1}\\boldsymbol{X}_m\\) is the projection matrix on the space generated by the columns of \\(\\boldsymbol{X}_m\\), and \\(\\bar{y}\\) is the sample mean of \\(\\boldsymbol{y}\\). We implement in our GUI four approaches to perform BMA in the Gaussian linear model: the BIC approximation using the Occam’s window approach, the MC3 algorithm using the analytical expression for calculating the marginal likelihood, an instrumental variable approach based on conditional likelihoods, and dynamic variable selection. Example: Simulation exercise Let’s perform a simulation exercise to assess the performance of the BIC approximation using the Occam’s window, and the Markov chain Monte Carlo model composition approaches. Let’s set a model where the computational burden is low and we know the data generating process (population statistical model). In particular, we set 10 regressors such that \\(x_k\\sim N(1, 1)\\), \\(k =1,\\dots,6\\), and \\(x_k\\sim B(0.5)\\), \\(k=7,\\dots,10\\). We set \\(\\boldsymbol{\\beta}=[1 \\ 0 \\ 0 \\ 0 \\ 0.5 \\ 0, 0, 0, 0, -0.7]^{\\top}\\) such that just \\(x_1\\), \\(x_5\\) and \\(x_{10}\\) are relevant to drive \\(y_i=1+\\boldsymbol{x}^{\\top}\\boldsymbol{\\beta}+\\mu_i\\), \\(\\mu_i\\sim N(0,0.5^2)\\). Observe that we just have \\(2^{10}=1024\\) models in this setting, thus, we can calculate the posterior model probability for each model. Our GUI uses the commands bicreg and MC3.REG from the package BMA to perform Bayesian model averaging in the linear regression model using the BIC approximation and MC3, respectively. These commands in turn are based on A. Raftery (1995) and Adrian E. Raftery, Madigan, and Hoeting (1997). The following code shows how to perform the simulation and get the posterior mean and standard deviation using these commands with the default values of hyperparameters and tuning parameters. rm(list = ls()); set.seed(010101) N &lt;- 1000 K1 &lt;- 6; K2 &lt;- 4; K &lt;- K1 + K2 X1 &lt;- matrix(rnorm(N*K1,1 ,1), N, K1) X2 &lt;- matrix(rbinom(N*K2, 1, 0.5), N, K2) X &lt;- cbind(X1, X2); e &lt;- rnorm(N, 0, 0.5) B &lt;- c(1,0,0,0,0.5,0,0,0,0,-0.7) y &lt;- 1 + X%*%B + e BMAglm &lt;- BMA::bicreg(X, y, strict = FALSE, OR = 50) summary(BMAglm) ## ## Call: ## BMA::bicreg(x = X, y = y, strict = FALSE, OR = 50) ## ## ## 8 models were selected ## Best 5 models (cumulative posterior probability = 0.9176 ): ## ## p!=0 EV SD model 1 model 2 model 3 ## Intercept 100.0 1.0321222 0.031290 1.032e+00 1.047e+00 1.041e+00 ## X1 100.0 1.0018025 0.015274 1.002e+00 1.002e+00 1.002e+00 ## X2 3.0 -0.0002625 0.002997 . . -8.826e-03 ## X3 2.6 0.0001208 0.002530 . . . ## X4 2.9 0.0002341 0.002910 . . . ## X5 100.0 0.4976248 0.015668 4.976e-01 4.975e-01 4.976e-01 ## X6 3.9 -0.0005920 0.004256 . -1.509e-02 . ## X7 2.8 0.0004292 0.005739 . . . ## X8 2.9 0.0004508 0.005860 . . . ## X9 2.9 0.0004729 0.005914 . . . ## X10 100.0 -0.7035270 0.030939 -7.036e-01 -7.036e-01 -7.031e-01 ## ## nVar 3 4 4 ## r2 0.855 0.855 0.855 ## BIC -1.912e+03 -1.906e+03 -1.906e+03 ## post prob 0.791 0.039 0.030 ## model 4 model 5 ## Intercept 1.024e+00 1.024e+00 ## X1 1.002e+00 1.002e+00 ## X2 . . ## X3 . . ## X4 8.150e-03 . ## X5 4.975e-01 4.976e-01 ## X6 . . ## X7 . . ## X8 . 1.569e-02 ## X9 . . ## X10 -7.029e-01 -7.034e-01 ## ## nVar 4 4 ## r2 0.855 0.855 ## BIC -1.906e+03 -1.906e+03 ## post prob 0.029 0.029 BMAreg &lt;- BMA::MC3.REG(y, X, num.its=500) ## Warning in covMcd(X, alpha = alpha, use.correction = use.correction): The 505-th order statistic of the absolute deviation of variable 7 is ## zero. ## There are 505 observations (in the entire dataset of 1000 obs.) lying ## on the hyperplane with equation a_1*(x_i1 - m_1) + ... + a_p*(x_ip - ## m_p) = 0 with (m_1, ..., m_p) the mean of these observations and ## coefficients a_i from the vector a &lt;- c(0, 0, 0, 0, 0, 0, 1, 0, 0, 0) Models &lt;- unique(BMAreg[[&quot;variables&quot;]]) nModels &lt;- dim(Models)[1] nVistModels &lt;- dim(BMAreg[[&quot;variables&quot;]])[1] PMP &lt;- NULL for(m in 1:nModels){ idModm &lt;- NULL for(j in 1:nVistModels){ if(sum(Models[m,] == BMAreg[[&quot;variables&quot;]][j,]) == K){ idModm &lt;- c(idModm, j) }else{ idModm &lt;- idModm } } PMPm &lt;- sum(BMAreg[[&quot;post.prob&quot;]][idModm]) PMP &lt;- c(PMP, PMPm) } PIP &lt;- NULL for(k in 1:K){ PIPk &lt;- sum(PMP[which(Models[,k] == 1)]) PIP &lt;- c(PIP, PIPk) } plot(PIP) Means &lt;- matrix(0, nModels, K) Vars &lt;- matrix(0, nModels, K) for(m in 1:nModels){ idXs &lt;- which(Models[m,] == 1) if(length(idXs) == 0){ Regm &lt;- lm(y ~ 1) }else{ Xm &lt;- X[, idXs] Regm &lt;- lm(y ~ Xm) SumRegm &lt;- summary(Regm) Means[m, idXs] &lt;- SumRegm[[&quot;coefficients&quot;]][-1,1] Vars[m, idXs] &lt;- SumRegm[[&quot;coefficients&quot;]][-1,2]^2 } } BMAmeans &lt;- colSums(Means*PMP) BMAsd &lt;- (colSums(PMP*Vars) + colSums(PMP*(Means-matrix(rep(BMAmeans, each = nModels), nModels, K))^2))^0.5 BMAmeans ## [1] 1.001771e+00 -5.322016e-05 6.635422e-06 3.721457e-07 4.976335e-01 ## [6] -1.271339e-04 1.000932e-08 2.107441e-05 6.578654e-06 -7.035557e-01 BMAsd ## [1] 1.527261e-02 1.353624e-03 5.936816e-04 1.163947e-04 1.566698e-02 ## [6] 1.987360e-03 2.778896e-05 1.270579e-03 6.997305e-04 3.093389e-02 BMAmeans/BMAsd ## [1] 6.559266e+01 -3.931680e-02 1.117673e-02 3.197272e-03 3.176320e+01 ## [6] -6.397124e-02 3.601905e-04 1.658647e-02 9.401697e-03 -2.274385e+01 We can see from the results that the BIC approximation with the Occam’s window, and the MC3 algorithm perform a good job finding the relevant regressors, and their posterior BMA means are very close to the population values. We also see that the BMA results are very similar in the two approaches. We can perform Bayesian model averaging in our GUI for linear Gaussian models using the BIC approximation and MC3 using the following Algorithms. We ask in Exercise 2 to perform BMA using the dataset 10ExportDiversificationHHI.csv from Jetter and Ramírez Hassan (2015). Algorithm: Bayesian Model Averaging in Linear Gaussian Models using the Bayesian Information Criterion Select Bayesian Model Averaging on the top panel Select Normal data model using the left radio button Select BIC using the right radio button under Which type do you want to perform? Upload the dataset, selecting first if there is a header in the file and the kind of separator in the csv file of the dataset (comma, semicolon, or tab). Then, use the Browse button under the Choose File legend Type the OR number of the Occam’s window in the box under OR: Number between 5 and 50 (this step is optional, as the default value is 50) Click the Go! button Analyze results: After a few seconds or minutes, a table appears showing, for each regressor in the dataset, the PIP (posterior inclusion probability, p!=0), the BMA posterior mean (EV), the BMA standard deviation (SD), and the posterior mean for models with the highest PMP. At the bottom of the table, for the models with the largest PMP, the number of variables (nVar), the coefficient of determination (r2), the BIC, and the PMP (post prob) are displayed Download posterior results using the Download results using BIC button. Two files are provided: The first file contains the best models by row according to the PMP (last column), indicating variable inclusion with a 1 (0 indicates no inclusion) The second file contains the PIP, the BMA expected value, and the standard deviation for each variable in the dataset Algorithm: Bayesian Model Averaging in Linear Gaussian Models using Markov Chain Monte Carlo Model Composition Select Bayesian Model Averaging on the top panel Select Normal data model using the left radio button Select MC3 using the right radio button under Which type do you want to perform? Upload the dataset, selecting first if there is a header in the file and the kind of separator in the csv file of the dataset (comma, semicolon, or tab). Then, use the Browse button under the Choose File legend Select MC3 iterations using the Range slider under the label MC3 iterations: Click the Go! button Analyze results: After a few seconds or minutes, a table appears showing, for each regressor in the dataset, the PIP (posterior inclusion probability, p!=0), the BMA posterior mean (EV), the BMA standard deviation (SD), and the posterior mean for models with the highest PMP. At the bottom of the table, for the models with the largest PMP, the number of variables (nVar), the coefficient of determination (r2), the BIC, and the PMP (post prob) are displayed Download posterior results using the Download results using BIC button. Two files are provided: The first file contains the best models by row according to the PMP (last column), indicating variable inclusion with a 1 (0 indicates no inclusion) The second file contains the PIP, the BMA expected value, and the standard deviation for each variable in the dataset We show in the following code how to program a MC3 algorithm from scratch to perform BMA using the setting from the previous simulation exercise. The first part of the code is the function to calculate the log marginal likelihood. This is a small simulation setting, thus we can calculate the marginal likelihood for all 1024 models, and then calculate the posterior model probability standardizing using the model with the largest log marginal likelihood. We see from the results that this model is the data generating process (population statistical model). We also find that the posterior inclusion probabilities for \\(x_{1}\\), \\(x_{5}\\) and \\(x_{10}\\) are 1, whereas the PIP for the other variables are less than 0.05. Although BMA allows incorporating model uncertainty in a regression framework, sometimes it is desirable to select just one model. Two compelling alternatives are the model with the largest posterior model probability, and the median probability model. The latter is the model which includes every predictor that has posterior inclusion probability higher than 0.5. The first model is the best alternative for prediction in the case of a 0–1 loss function (Clyde and George 2004), whereas the second is the best alternative when there is a quadratic loss function in prediction (Barbieri and Berger 2004). In this simulation, the two criteria indicate selection of the data generating process. We also show how to estimate the posterior mean and standard deviation based on BMA in this code. We see that the posterior means are very close to the population parameters. rm(list = ls()); set.seed(010101) N &lt;- 1000 K1 &lt;- 6; K2 &lt;- 4; K &lt;- K1 + K2 X1 &lt;- matrix(rnorm(N*K1,1 ,1), N, K1) X2 &lt;- matrix(rbinom(N*K2, 1, 0.5), N, K2) X &lt;- cbind(X1, X2); e &lt;- rnorm(N, 0, 0.5) B &lt;- c(1,0,0,0,0.5,0,0,0,0,-0.7) y &lt;- 1 + X%*%B + e LogMLfunt &lt;- function(Model){ indr &lt;- Model == 1 kr &lt;- sum(indr) if(kr &gt; 0){ gr &lt;- ifelse(N &gt; kr^2, 1/N, kr^(-2)) Xr &lt;- matrix(Xnew[ , indr], ncol = kr) PX &lt;- Xr%*%solve(t(Xr)%*%Xr)%*%t(Xr) s2pos &lt;- c((t(y - mean(y))%*%(y - mean(y))) - t(y)%*%PX%*%y/(1 + gr)) mllMod &lt;- (kr/2)*log(gr/(1+gr))-(N-1)/2*log(s2pos) }else{ gr &lt;- ifelse(N &gt; kr^2, 1/N, kr^(-2)) s2pos &lt;- c((t(y - mean(y))%*%(y - mean(y)))) mllMod &lt;- (kr/2)*log(gr/(1+gr))-(N-1)/2*log(s2pos) } return(mllMod) } combs &lt;- expand.grid(c(0,1), c(0,1), c(0,1), c(0,1), c(0,1),c(0,1), c(0,1), c(0,1), c(0,1), c(0,1)) Xnew &lt;- apply(X, 2, scale) mll &lt;- sapply(1:2^K, function(s){LogMLfunt(matrix(combs[s,], 1, K))}) MaxPMP &lt;- which.max(mll); StMarLik &lt;- exp(mll-max(mll)) PMP &lt;- StMarLik/sum(StMarLik) PMP[MaxPMP] ## [1] 0.7705196 combs[MaxPMP,] ## Var1 Var2 Var3 Var4 Var5 Var6 Var7 Var8 Var9 Var10 ## 530 1 0 0 0 1 0 0 0 0 1 PIP &lt;- NULL for(k in 1:K){ PIPk &lt;- sum(PMP[which(combs[,k] == 1)]); PIP &lt;- c(PIP, PIPk) } PIP ## [1] 1.00000000 0.03617574 0.03208369 0.03516743 1.00000000 0.04795509 ## [7] 0.03457102 0.03468819 0.03510209 1.00000000 nModels &lt;- dim(combs)[1]; Means &lt;- matrix(0, nModels, K) Vars &lt;- matrix(0, nModels, K) for(m in 1:nModels){ idXs &lt;- which(combs[m,] == 1) if(length(idXs) == 0){ Regm &lt;- lm(y ~ 1) }else{ Xm &lt;- X[, idXs]; Regm &lt;- lm(y ~ Xm) SumRegm &lt;- summary(Regm) Means[m, idXs] &lt;- SumRegm[[&quot;coefficients&quot;]][-1,1] Vars[m, idXs] &lt;- SumRegm[[&quot;coefficients&quot;]][-1,2]^2 } } BMAmeans &lt;- colSums(Means*PMP) BMAmeans ## [1] 1.0018105888 -0.0003196423 0.0001489711 0.0002853524 0.4976225353 ## [6] -0.0007229563 0.0005342718 0.0005441905 0.0005758708 -0.7035206822 BMAsd &lt;- (colSums(PMP*Vars) + colSums(PMP*(Means-matrix(rep(BMAmeans, each = nModels), nModels, K))^2))^0.5 BMAsd ## [1] 0.015274980 0.003304115 0.002814491 0.003214722 0.015668278 0.004694003 ## [7] 0.006400541 0.006435695 0.006528471 0.030940753 BMAmeans/BMAsd ## [1] 65.58506579 -0.09674068 0.05293002 0.08876427 31.75987477 ## [6] -0.15401700 0.08347292 0.08455816 0.08820914 -22.73767175 #### MC3 Algorithm #### M &lt;- 100 Models &lt;- matrix(rbinom(K*M, 1, p = 0.5), ncol=K, nrow = M) mllnew &lt;- sapply(1:M,function(s){LogMLfunt(matrix(Models[s,], 1, K))}) oind &lt;- order(mllnew, decreasing = TRUE) mllnew &lt;- mllnew[oind]; Models &lt;- Models[oind, ]; iter &lt;- 1000 pb &lt;- winProgressBar(title = &quot;progress bar&quot;, min = 0, max = iter, width = 300); s &lt;- 1 while(s &lt;= iter){ ActModel &lt;- Models[M,]; idK &lt;- which(ActModel == 1) Kact &lt;- length(idK) if(Kact &lt; K &amp; Kact &gt; 1){ CardMol &lt;- K; opt &lt;- sample(1:3, 1) if(opt == 1){ # Same CandModel &lt;- ActModel }else{ if(opt == 2){ # Add All &lt;- 1:K; NewX &lt;- sample(All[-idK], 1) CandModel &lt;- ActModel; CandModel[NewX] &lt;- 1 }else{ # Subtract LessX &lt;- sample(idK, 1); CandModel &lt;- ActModel CandModel[LessX] &lt;- 0 } } }else{ CardMol &lt;- K + 1 if(Kact == K){ opt &lt;- sample(1:2, 1) if(opt == 1){ # Same CandModel &lt;- ActModel }else{ # Subtract LessX &lt;- sample(1:K, 1); CandModel &lt;- ActModel CandModel[LessX] &lt;- 0 } }else{ if(K == 1){ opt &lt;- sample(1:3, 1) if(opt == 1){ # Same CandModel &lt;- ActModel }else{ if(opt == 2){ # Add All &lt;- 1:K; NewX &lt;- sample(All[-idK], 1) CandModel &lt;- ActModel; CandModel[NewX] &lt;- 1 }else{ # Subtract LessX &lt;- sample(idK, 1); CandModel &lt;- ActModel CandModel[LessX] &lt;- 0 } } }else{ # Add NewX &lt;- sample(1:K, 1); CandModel &lt;- ActModel CandModel[NewX] &lt;- 1 } } } LogMLact &lt;- LogMLfunt(matrix(ActModel, 1, K)) LogMLcand &lt;- LogMLfunt(matrix(CandModel, 1, K)) alpha &lt;- min(1, exp(LogMLcand-LogMLact)) u &lt;- runif(1) if(u &lt;= alpha){ mllnew[M] &lt;- LogMLcand; Models[M, ] &lt;- CandModel oind &lt;- order(mllnew, decreasing = TRUE) mllnew &lt;- mllnew[oind]; Models &lt;- Models[oind, ] }else{ mllnew &lt;- mllnew; Models &lt;- Models } s &lt;- s + 1 setWinProgressBar(pb, s, title=paste( round(s/iter*100, 0),&quot;% done&quot;)) } close(pb) ## NULL ModelsUni &lt;- unique(Models) mllnewUni &lt;- sapply(1:dim(ModelsUni)[1], function(s){LogMLfunt(matrix(ModelsUni[s,], 1, K))}) StMarLik &lt;- exp(mllnewUni-mllnewUni[1]) PMP &lt;- StMarLik/sum(StMarLik) # PMP based on unique selected models nModels &lt;- dim(ModelsUni)[1] StMarLik &lt;- exp(mllnew-mllnew[1]) PMPold &lt;- StMarLik/sum(StMarLik) # PMP all selected models PMPot &lt;- NULL PMPap &lt;- NULL FreqMod &lt;- NULL for(m in 1:nModels){ idModm &lt;- NULL for(j in 1:M){ if(sum(ModelsUni[m,] == Models[j,]) == K){ idModm &lt;- c(idModm, j) }else{ idModm &lt;- idModm } } PMPm &lt;- sum(PMPold[idModm]) # PMP unique models using sum of all selected models PMPot &lt;- c(PMPot, PMPm) PMPapm &lt;- length(idModm)/M # PMP using relative frequency in all selected models PMPap &lt;- c(PMPap, PMPapm) FreqMod &lt;- c(FreqMod, length(idModm)) } PIP &lt;- NULL for(k in 1:K){ PIPk &lt;- sum(PMP[which(ModelsUni[,k] == 1)]) PIP &lt;- c(PIP, PIPk) } Means &lt;- matrix(0, nModels, K) Vars &lt;- matrix(0, nModels, K) for(m in 1:nModels){ idXs &lt;- which(ModelsUni[m,] == 1) if(length(idXs) == 0){ Regm &lt;- lm(y ~ 1) }else{ Xm &lt;- X[, idXs] Regm &lt;- lm(y ~ Xm) SumRegm &lt;- summary(Regm) Means[m, idXs] &lt;- SumRegm[[&quot;coefficients&quot;]][-1,1] Vars[m, idXs] &lt;- SumRegm[[&quot;coefficients&quot;]][-1,2]^2 } } BMAmeans &lt;- colSums(Means*PMP) BMAsd &lt;- (colSums(PMP*Vars) + colSums(PMP*(Means-matrix(rep(BMAmeans, each = nModels), nModels, K))^2))^0.5 BMAmeans; BMAsd; BMAmeans/BMAsd ## [1] 1.001787e+00 -1.099674e-05 5.928440e-06 1.237330e-06 4.976289e-01 ## [6] -7.240575e-04 5.317222e-04 4.590382e-05 5.316641e-04 -7.035531e-01 ## [1] 0.0152733978 0.0006149476 0.0005564602 0.0002155678 0.0156674028 ## [6] 0.0046971545 0.0063886626 0.0018639899 0.0062682419 0.0309357255 ## [1] 65.590349277 -0.017882401 0.010653843 0.005739863 31.762056368 ## [6] -0.154148108 0.083229033 0.024626646 0.084818691 -22.742415397 The second part of the code demonstrates how to perform the MC3 algorithm. While this algorithm is not strictly necessary for this small-dimensional problem, it serves as a useful pedagogical exercise. The starting point is to set \\(S=100\\) random models and order their log marginal likelihoods. The logic of the algorithm is to select the worst model among the \\(S\\) models and propose a candidate model to compete against it. We repeat this process for 1000 iterations (as shown in the code). Note that 1000 iterations is fewer than the number of potential models (1024). This is the essence of the MC3 algorithm: performing fewer iterations than the number of models in the space. In our algorithm, we analyze all model scenarios using different conditionals and reasonably assume the same prior model probability for all models, with the same cardinality for both the actual and candidate models. The posterior model probability (PMP) can be calculated in several ways. One method is to recover the unique models from the final set of \\(S\\) models, calculate the log marginal likelihood for these models, and then standardize by the best model among them. Another method involves calculating the PMP using the complete set of \\(S\\) final models, accounting for the fact that some models may appear multiple times in the set, which requires summing the PMPs of repeated models. A third method is to calculate the PMP based on the relative frequency with which a model appears in the final set of \\(S\\) models. These three methods can yield different PMPs, particularly when the number of MC3 iterations is small. In our example, using 1000 MC3 iterations, the data-generating process receives the highest PMP across all three methods. A noteworthy aspect of this algorithm is that we can obtain a single model after significantly increasing the number of iterations (for example, try using 10,000 iterations). This can be advantageous if we require only one model. However, this approach neglects model uncertainty, which could be a desirable characteristic in some cases. As a challenge, we suggest programming an algorithm that yields \\(S\\) different models after completing the MC3 iterations (Exercise 3). An important issue to account for regressors (model) uncertainty in the identification of causal effects, rather than finding good predictors (association relationships), is endogeneity. Thus, we also implement the instrumental variable approach of Section 7.3 to tackle this issue in BMA. We assume that \\(\\boldsymbol{\\gamma}\\sim {N}(\\boldsymbol{0},\\boldsymbol{I})\\), \\(\\boldsymbol{\\beta}\\sim {N}(\\boldsymbol{0},\\boldsymbol{I})\\), and \\(\\boldsymbol{\\Sigma}^{-1} \\sim {W}(3,\\boldsymbol{I})\\) (Karl and Lenkoski 2012). Lenkoski, Karl, and Neudecker (2013) propose an algorithm based on conditional Bayes factors (J. M. Dickey and Gunel 1978) that allows embedding MC3 within a Gibbs sampling algorithm. Given the candidate (\\(M_{c}^{2nd}\\)) and actual (\\(M_{s-1}^{2nd}\\)) models for the iteration \\(s\\) in the second stage, the conditional Bayes factor is \\[\\begin{equation*} CBF^{2nd}=\\frac{p(\\boldsymbol{y}|M_{c}^{2nd},\\boldsymbol{\\gamma},\\boldsymbol{\\Sigma})}{p(\\boldsymbol{y}|M_{s-1}^{2nd},\\boldsymbol{\\gamma},\\boldsymbol{\\Sigma})}, \\end{equation*}\\] where \\[\\begin{align*} p(\\boldsymbol{y}|M_{c}^{2nd},\\boldsymbol{\\gamma},\\boldsymbol{\\Sigma})&amp;=\\int_{\\mathcal{M}^{2nd}}p(\\boldsymbol{y}|\\boldsymbol{\\beta},\\boldsymbol{\\gamma},\\boldsymbol{\\Sigma})\\pi(\\boldsymbol{\\beta}|M_{c}^{2nd})d\\boldsymbol{\\beta}\\\\ &amp;\\propto |\\boldsymbol{B}_n|^{-1/2} \\exp\\left\\{\\frac{1}{2}{\\boldsymbol{\\beta}_n}^{\\top}\\boldsymbol{B}_n^{-1}\\boldsymbol{\\beta}_n\\right\\} . \\end{align*}\\] In the first stage, \\[\\begin{equation*} CBF^{1st}=\\frac{p(\\boldsymbol{y}|M_{c}^{1st},\\boldsymbol{\\beta},\\boldsymbol{\\Sigma})}{p(\\boldsymbol{y}|M_{s-1}^{1st},\\boldsymbol{\\beta},\\boldsymbol{\\Sigma})}, \\end{equation*}\\] where \\[\\begin{align*} p(\\boldsymbol{y}|M_{c}^{1st},\\boldsymbol{\\beta},\\boldsymbol{\\Sigma})&amp;=\\int_{\\mathcal{M}^{1st}}p(\\boldsymbol{y}|\\boldsymbol{\\gamma},\\boldsymbol{\\beta},\\boldsymbol{\\Sigma})\\pi(\\boldsymbol{\\gamma}|M_{c}^{1st})d\\boldsymbol{\\gamma}\\\\ &amp;\\propto |\\boldsymbol{G}_n|^{-1/2} \\exp\\left\\{\\frac{1}{2}{\\boldsymbol{\\gamma}_n}^{\\top}\\boldsymbol{G}_n^{-1}\\boldsymbol{\\gamma}_n\\right\\}. \\end{align*}\\] These conditional Bayes factors assume \\(\\pi(M^{1st},M^{2sd})\\propto 1\\). See Lenkoski, Karl, and Neudecker (2013) for more details of the instrumental variable BMA algorithm.58 We perform instrumental variable BMA in our GUI using the package ivbma. The following Algorithm shows how to perform this in our GUI. Algorithm: Instrumental Variable Bayesian Model Averaging in Linear Gaussian Models Select Bayesian Model Averaging on the top panel Select Normal data model using the left radio button Select Instrumental variable using the right radio button under Which type do you want to perform? Upload the dataset containing the dependent variable, endogenous regressors, and exogenous regressors (including the constant). The user should first select if there is a header in the file and the kind of separator in the csv file (comma, semicolon, or tab). Then, use the Browse button under the Choose File legend Upload the dataset containing the instruments. The user should first select if there is a header in the file and the kind of separator in the csv file (comma, semicolon, or tab). Then, use the Browse button under the Choose File (Instruments) legend Write down the number of endogenous regressors in the box labeled Number of Endogenous variables Select MCMC iterations and burn-in using the Range slider under the labels MCMC iterations: and Burn-in Sample: Click the Go! button Analyze results: After a few seconds or minutes, two tables appear showing, for each regressor in the dataset, the PIP (posterior inclusion probability, p!=0), and the BMA posterior mean (EV). The top table shows the results of the second stage (main equation), and the bottom table shows the results of the first stage (auxiliary equations) Download posterior results using the Download results using IV button. Three files are provided: The first file contains the posterior inclusion probabilities of each variable and the BMA posterior means of the coefficients in the first stage equations The second file contains these results for the second stage (main equation) The third file contains the posterior chains of all parameters by iteration Example: Simulation exercise Let’s assume that \\(y_i = 2 + 0.5x_{i1} - x_{i2} + x_{i3} + \\mu_i\\), where \\(x_{i1} = 4z_{i1} - z_{i2} + 2z_{i3} + \\epsilon_{i1}\\) and \\(x_{i2} = -2z_{i1} + 3z_{i2} - z_{i3} + \\epsilon_{i2}\\), such that \\([\\epsilon_{i1} \\ \\epsilon_{i2} \\ \\mu_i]^{\\top} \\sim N(\\boldsymbol{0}, \\boldsymbol{\\Sigma})\\), where \\(\\boldsymbol{\\Sigma} = \\begin{bmatrix} 1 &amp; 0 &amp; 0.8 \\\\ 0 &amp; 1 &amp; 0.5 \\\\ 0.8 &amp; 0.5 &amp; 1 \\end{bmatrix}\\), for \\(i = 1, 2, \\dots, 1000\\). The endogeneity arises due to the correlation between \\(\\mu_i\\) and \\(x_{i1}\\) and \\(x_{i2}\\) through the stochastic errors. In addition, there are three instruments, \\(z_{il} \\sim U(0,1)\\), for \\(l = 1, 2, 3\\), and another 18 regressors believed to influence \\(y_i\\), which are distributed according to a standard normal distribution. The following code shows how to perform IV BMA using the ivbma package. We see from the results that the PIP of \\(x_{i1}\\), \\(x_{i2}\\), intercept and \\(x_{i3}\\) are equal to 1, whereas the remaining PIP are close to 0. In addition, the BMA means are also close to the population values. The PIP of the first stage equations, as well as their BMA posterior means, are very close to the populations values. The same happens with the covariance matrix. rm(list = ls()) set.seed(010101) simIV &lt;- function(delta1,delta2,beta0,betas1,betas2,beta2,Sigma,n,z) { eps &lt;- matrix(rnorm(3*n),ncol=3) %*% chol(Sigma) xs1 &lt;- z%*%delta1 + eps[,1] xs2 &lt;- z%*%delta2 + eps[,2] x2 &lt;- rnorm(dim(z)[1]) y &lt;- beta0+betas1*xs1+betas2*xs2+beta2*x2 + eps[,3] X &lt;- as.matrix(cbind(xs1,xs2,1,x2)) colnames(X) &lt;- c(&quot;x1en&quot;,&quot;x2en&quot;,&quot;cte&quot;,&quot;xex&quot;) y &lt;- matrix(y,dim(z)[1],1) colnames(y) &lt;- c(&quot;y&quot;) list(X=X,y=y) } n &lt;- 1000 ; p &lt;- 3 z &lt;- matrix(runif(n*p),ncol=p) rho31 &lt;- 0.8; rho32 &lt;- 0.5; Sigma &lt;- matrix(c(1,0,rho31,0,1,rho32,rho31,rho32,1),ncol=3) delta1 &lt;- c(4,-1,2); delta2 &lt;- c(-2,3,-1); betas1 &lt;- .5; betas2 &lt;- -1; beta2 &lt;- 1; beta0 &lt;- 2 simiv &lt;- simIV(delta1,delta2,beta0,betas1,betas2,beta2,Sigma,n,z) nW &lt;- 18 W &lt;- matrix(rnorm(nW*dim(z)[1]),dim(z)[1],nW) YXW&lt;-cbind(simiv$y, simiv$X, W) y &lt;- YXW[,1]; X &lt;- YXW[,2:3]; W &lt;- YXW[,-c(1:3)] S &lt;- 10000; burnin &lt;- 1000 regivBMA &lt;- ivbma::ivbma(Y = y, X = X, Z = z, W = W, s = S+burnin, b = burnin, odens = S, print.every = round(S/10), run.diagnostics = FALSE) ## [1] &quot;Running IVBMA for 11000 iterations 2025-02-22 09:00:00.487545&quot; ## [1] &quot;On Iteration 1000 2025-02-22 09:00:03.325673&quot; ## [1] &quot;On Iteration 2000 2025-02-22 09:00:06.260956&quot; ## [1] &quot;On Iteration 3000 2025-02-22 09:00:09.462995&quot; ## [1] &quot;On Iteration 4000 2025-02-22 09:00:12.326744&quot; ## [1] &quot;On Iteration 5000 2025-02-22 09:00:15.294278&quot; ## [1] &quot;On Iteration 6000 2025-02-22 09:00:18.343097&quot; ## [1] &quot;On Iteration 7000 2025-02-22 09:00:21.325808&quot; ## [1] &quot;On Iteration 8000 2025-02-22 09:00:24.42158&quot; ## [1] &quot;On Iteration 9000 2025-02-22 09:00:27.375601&quot; ## [1] &quot;On Iteration 10000 2025-02-22 09:00:30.311979&quot; ## [1] &quot;On Iteration 11000 2025-02-22 09:00:33.489982&quot; PIPmain &lt;- regivBMA[[&quot;L.bar&quot;]] # PIP outcome PIPmain ## [1] 1.0000 1.0000 1.0000 1.0000 0.0140 0.0243 0.0116 0.0309 0.0305 0.0145 ## [11] 0.0105 0.0103 0.0233 0.0402 0.0048 0.0349 0.0210 0.0343 0.0044 0.0137 ## [21] 0.0175 0.0223 EVmain &lt;- regivBMA[[&quot;rho.bar&quot;]] # Posterior mean outcome EVmain ## [1] 5.074816e-01 -9.873671e-01 2.004880e+00 1.005181e+00 -1.849026e-04 ## [6] -3.951743e-04 -8.087320e-05 6.401508e-04 6.699469e-04 -1.456550e-04 ## [11] 7.932297e-05 -5.582272e-05 -1.913875e-04 6.135038e-04 2.458307e-05 ## [16] -5.885881e-04 -2.431515e-05 -1.170588e-04 1.793956e-05 7.936547e-05 ## [21] -2.579314e-05 -2.026556e-04 PIPaux &lt;- regivBMA[[&quot;M.bar&quot;]] # PIP auxiliary EVaux &lt;- regivBMA[[&quot;lambda.bar&quot;]] # Posterior mean auxiliary plot(EVaux[,1]) plot(EVaux[,2]) EVsigma &lt;- regivBMA[[&quot;Sigma.bar&quot;]] # Posterior mean variance matrix EVsigma ## [,1] [,2] [,3] ## [1,] 1.0345164 0.848730076 0.515301058 ## [2,] 0.8487301 1.081309693 0.008180855 ## [3,] 0.5153011 0.008180855 1.028434857 Bayesian model averaging has been also extended to state-space models. The point of departure is the univariate random walk state-space model (see Chapter 8) conditional on model \\(\\mathcal{M}_m\\), \\(m=1,2\\dots,M\\). \\[\\begin{align} y_t&amp;=\\boldsymbol{x}_{mt}^{\\top}\\boldsymbol{\\beta}_{mt}+\\mu_{mt}\\\\ \\boldsymbol{\\beta}_{mt}&amp;=\\boldsymbol{\\beta}_{mt-1}+\\boldsymbol{w}_{mt}, \\end{align}\\] where \\(\\mu_{mt}\\sim N(0,\\sigma^2)\\) and \\(\\boldsymbol{w}_{mt}\\sim N(\\boldsymbol{0},\\boldsymbol{\\Omega}_{mt})\\). Given \\(\\boldsymbol{\\beta}_{mt-1}|\\boldsymbol{y}_{1:t-1}\\sim N(\\boldsymbol{b}_{mt-1},\\boldsymbol{B}_{mt-1})\\), then, we know from Chapter 8 that \\(\\boldsymbol{\\beta}_{mt}|\\boldsymbol{y}_{1:t-1}\\sim N(\\boldsymbol{b}_{mt-1}, \\boldsymbol{R}_{mt})\\), \\(\\boldsymbol{R}_{mt}=\\boldsymbol{B}_{mt-1}+\\boldsymbol{\\Omega}_{mt}\\). Specification of \\(\\boldsymbol{\\Omega}_t\\) can be highly demanding. Thus, a common approach is to express \\(\\boldsymbol{\\Omega}_{mt}=\\frac{1-\\lambda}{\\lambda}\\boldsymbol{B}_{mt-1}\\), where \\(\\lambda\\) is called the forgetting parameter or discount factor, because it discounts the matrix \\(\\boldsymbol{B}_{mt-1}\\) that we would have with a deterministic state evolution into the matrix \\(\\boldsymbol{R}_{mt}\\) (Petris, Petrone, and Campagnoli 2009). This parameter is typically slightly below 1, and implies that \\(\\boldsymbol{R}_{mt}=\\lambda^{-1}\\boldsymbol{B}_{mt-1}\\). (\\(\\lambda^{-1}&gt;1\\)). Adrian E. Raftery, Kárnỳ, and Ettler (2010) assume that the model changes infrequently, and its evolution is given by the transition matrix \\(\\boldsymbol{T}=[t_{ml}]\\), where \\(t_{ml}=P(\\mathcal{M}_t=\\mathcal{M}_m|\\mathcal{M}_{t-1}=\\mathcal{M}_l)\\). Then, the aim is to calculate the filtering distribution \\(p(\\boldsymbol{\\beta}_{mt},\\mathcal{M}_t|y_t)=\\sum_{m=1}^Mp(\\boldsymbol{\\beta}_{mt}|\\mathcal{M}_t=\\mathcal{M}_m,y_t)p(\\mathcal{M}_t=\\mathcal{M}_m|y_t)\\). Thus, given the conditional distribution of the state at time \\(t-1\\), \\(p(\\boldsymbol{\\beta}_{mt-1},\\mathcal{M}_{t-1}|{y}_{t-1})=\\sum_{m=1}^Mp(\\boldsymbol{\\beta}_{mt-1}|\\mathcal{M}_{t-1}=\\mathcal{M}_m,{y}_{t-1})p(\\mathcal{M}_{t-1}=\\mathcal{M}_m|{y}_{t-1})\\), where the conditional distribution of \\(\\boldsymbol{\\beta}_{mt-1}\\) is approximated by a Gaussian distribution, \\(\\boldsymbol{\\beta}_{mt-1}|\\mathcal{M}_{t-1}=\\mathcal{M}_{m},y_{t-1}\\sim N(\\boldsymbol{b}_{mt-1},\\boldsymbol{B}_{mt-1})\\), then the first step to get the one-step-ahead predictive distribution is getting the prediction of the model indicator, \\[\\begin{align*} p(\\mathcal{M}_t=\\mathcal{M}_l|y_{t-1})&amp;=\\sum_{m=1}^M p(\\mathcal{M}_{t-1}=\\mathcal{M}_m|y_{t-1})\\times t_{lm}\\\\ &amp;\\approx \\frac{p(\\mathcal{M}_{t-1}=\\mathcal{M}_l|y_{t-1})^{\\delta}+c}{\\sum_{m=1}^M p(\\mathcal{M}_{t-1}=\\mathcal{M}_m|y_{t-1})^{\\delta}+c}, \\end{align*}\\] where the second equality is used to avoid dealing with the \\(M^2\\) elements of the transition matrix \\(\\boldsymbol{T}\\) such that the forgetting parameter \\(\\delta\\) is used, this parameter is slightly less than 1, and \\(c=0.001/M\\) is introduced to handle a model probability being brought to computational zero by outliers. Then, we get the one-step-ahead predictive distribution of the state vector, \\(\\boldsymbol{\\beta}_{mt}|\\mathcal{M}_{t}=\\mathcal{M}_{m},y_{t-1}\\sim N(\\boldsymbol{b}_{mt-1},\\lambda^{-1}\\boldsymbol{B}_{mt-1})\\) Now, we consider the filtering stage, where the model filtering equation is \\[\\begin{align*} p(\\mathcal{M}_t=\\mathcal{M}_l|y_{t})=\\frac{p(\\mathcal{M}_t=\\mathcal{M}_l|y_{t-1})p_l(y_t|y_{t-1})}{\\sum_{m=1}^M p(\\mathcal{M}_t=\\mathcal{M}_m|y_{t-1})p_m(y_t|y_{t-1})}, \\end{align*}\\] where \\(p_m(y_t|y_{t-1})\\) is the one-step-ahead predictive distribution of \\(y_t|{y}_{t-1}\\), which is \\(N(f_t,Q_t)\\), where \\(f_t=\\boldsymbol{x}_t^{\\top}\\boldsymbol{b}_{t-1}\\) and \\(Q_t=\\boldsymbol{x}_{mt}^{\\top}\\lambda^{-1}\\boldsymbol{B}_{mt-1}\\boldsymbol{x}_{mt}+\\sigma^2\\) (see Chapter 8). The states filtering equation is \\(\\boldsymbol{\\beta}_{mt}|\\mathcal{M}_{t}=\\mathcal{M}_{m},y_{t}\\sim N(\\boldsymbol{b}_{mt},\\boldsymbol{B}_{mt})\\) where \\(\\boldsymbol{b}_{mt}\\) and \\(\\boldsymbol{B}_{mt}\\) are given in the Kalman filtering recursion of Chapter 8. Adrian E. Raftery, Kárnỳ, and Ettler (2010) initiate their algorithm assuming equal prior model probabilities, and \\(\\sigma^2\\) is estimated using a recursive method of moments estimator.59 We implement dynamic Bayesian model averaging in our GUI using the function dma from the package dma. The next Algorithm shows how to perform inference using our GUI. Algorithm: Dynamic Bayesian Model Averaging Select Bayesian Model Averaging on the top panel Select Normal data model using the left radio button Select Dynamic Bayesian Model Averaging using the right radio button under Which type do you want to perform? Upload the dataset, selecting first whether there is a header in the file and the type of separator in the csv file (comma, semicolon, or tab). Then, use the Browse button under the Choose File legend Upload the matrix of models, selecting first whether there is a header in the file and the type of separator in the csv file (comma, semicolon, or tab). Then, use the Browse button under the Choose File legend Type the forgetting parameters in the boxes under Lambda: Number slightly below 1 and Delta: Number slightly below 1. This is not necessary, as the default values are 0.99 for both Click the Go! button Analyze results: After a few seconds or minutes, a table appears showing, for each regressor in the dataset, the dynamic Bayesian average filtering recursions for each state (Mean and Standard deviation), the posterior model probability (PMP), and the Bayesian model averaging prediction (Prediction) Download posterior results using the Download results DBMA button. Two files are provided: The first file contains the dynamic Bayesian average filtering recursions for each state The second file contains the PMP of each model and the dynamic Bayesian model averaging prediction Example: Dynamic Bayesian model averaging We perform a simulation exercise where there are 8 (\\(2^3\\)) competing models originating from 3 regressors: \\(x_{tk} \\sim N(0.5, 0.8^2)\\) for \\(k = 2, 3, 4\\), with \\(\\beta_1 = 0.5\\). The sequence \\(\\beta_{2t}\\) ranges from 1 to 2 in steps of \\(1/T\\), and \\(\\beta_{3t}\\) is given by: \\[ \\beta_{3t} = \\begin{cases} -1, &amp; 1 &lt; t \\leq 0.75T \\\\ 0, &amp; 0.75T &lt; t \\leq T \\end{cases} \\] and \\(\\beta_4 = 1.2\\). Then, we have the model: \\[ y_t = \\beta_1 + \\beta_{2t} x_{2t} + \\beta_{3t} x_{3t} + \\beta_4 x_{4t} + \\mu_t, \\] where \\(\\mu_t \\sim N(0,1)\\) for \\(t = 1, 2, \\dots, 500\\). This setting implies that during the first 75% of the period, the model with all 3 regressors is the data-generating process, while after this, the model with regressors 2 and 4 is the data-generating process. The following code shows the simulation exercise and the results of the dynamic Bayesian model averaging, setting \\(\\lambda = \\delta = 0.99\\). rm(list = ls()); set.seed(010101) T &lt;- 500; K &lt;- 3 X &lt;- matrix(rnorm(T*K, mean = 0.5, sd = 0.8), T, K) combs &lt;- expand.grid(c(0,1), c(0,1), c(0,1)) B1 &lt;- 0.5; B2t &lt;- seq(1, 2, length.out=T ) a &lt;- 0.75; B3t &lt;- c(rep(-1,round(a*T)), rep(0,round((1-a)*T))) B4 &lt;- 1.2; sigma &lt;- 1; mu &lt;- rnorm(T, 0, sigma) y &lt;- B1 + X[,1]*B2t + X[,2]*B3t + X[,3]*B4 + mu T0 &lt;- 50 dma.test &lt;- dma::dma(X, y, combs, lambda=.99, gamma=.99, initialperiod = T0) plot(dma.test[[&quot;pmp&quot;]][-c(1:T0),8], type = &quot;l&quot;, col = &quot;green&quot;, main = &quot;Posterior model probability&quot;, xlab = &quot;Time&quot;, ylab = &quot;PMP&quot;) lines(dma.test[[&quot;pmp&quot;]][-c(1:T0),6], col = &quot;red&quot;) legend(x = 0, y = 1, legend = c(&quot;Model: All regressors&quot;, &quot;Model: Regressors 2 and 4&quot;), col = c(&quot;green&quot;, &quot;red&quot;), lty=1:1, cex=0.8) require(latex2exp) plot(dma.test[[&quot;thetahat.ma&quot;]][-c(1:T0),1], type = &quot;l&quot;, col = &quot;green&quot;, main = &quot;Bayesian model average filtering recursion&quot;, xlab = &quot;Time&quot;, ylab = TeX(&quot;$\\\\beta_{1}$&quot;)) abline(h = B1, col = &quot;red&quot;) legend(x = 0, y = 0.4, legend = c(&quot;State filtering&quot;, &quot;State population&quot;), col = c(&quot;green&quot;, &quot;red&quot;), lty=1:1, cex=0.8) plot(dma.test[[&quot;thetahat.ma&quot;]][-c(1:T0),2], type = &quot;l&quot;, col = &quot;green&quot;, main = &quot;Bayesian model average filtering recursion&quot;, xlab = &quot;Time&quot;, ylab = TeX(&quot;$\\\\beta_{2t}$&quot;), ylim = c(0.5,2)) lines(B2t[-c(1:T0)], col = &quot;red&quot;) legend(x = 0, y = 0.8, legend = c(&quot;State filtering&quot;, &quot;State population&quot;), col = c(&quot;green&quot;, &quot;red&quot;), lty=1:1, cex=0.8) plot(dma.test[[&quot;thetahat.ma&quot;]][-c(1:T0),3], type = &quot;l&quot;, col = &quot;green&quot;, main = &quot;Bayesian model average filtering recursion&quot;, xlab = &quot;Time&quot;, ylab = TeX(&quot;$\\\\beta_{3t}$&quot;)) lines(B3t[-c(1:T0)], col = &quot;red&quot;) legend(x = 0, y = -0.4, legend = c(&quot;State filtering&quot;, &quot;State population&quot;), col = c(&quot;green&quot;, &quot;red&quot;), lty=1:1, cex=0.8) plot(dma.test[[&quot;thetahat.ma&quot;]][-c(1:T0),4], type = &quot;l&quot;, col = &quot;green&quot;, main = &quot;Bayesian model average filtering recursion&quot;, xlab = &quot;Time&quot;, ylab = TeX(&quot;$\\\\beta_{4t}$&quot;)) abline(h = B4, col = &quot;red&quot;) legend(x = 0, y = 1.3, legend = c(&quot;State filtering&quot;, &quot;State population&quot;), col = c(&quot;green&quot;, &quot;red&quot;), lty=1:1, cex=0.8) The first Figure shows the posterior model probabilities for the model with all the regressors (green line) and the model with regressors 2 and 4 (red line). On one hand, we see that the model with all regressors, which is the data-generating process in the first period (\\(t \\leq 0.75T\\)), has a PMP close to 1, and then its PMP decreases. On the other hand, the model with regressors 2 and 4 has a PMP close to 0 in the first part of the period, and then its PMP increases to values higher than 60% on average, when this model becomes the data-generating process. These results suggest that, in this particular simulation exercise, the dynamic Bayesian model averaging method works relatively well in calculating the PMPs. The following four Figures show a comparison between the Bayesian model averaging filtering recursions of the states (green lines) and their population values (red lines). We observe that the filtering recursions follow the general pattern of the population values. However, the values are not perfectly aligned. This discrepancy arises because the posterior model probabilities (PMPs) of the models that match the data-generating process are not equal to 1, which in turn affects the performance of the filtering recursions. Dynamic Bayesian model averaging was extended to logit models by McCormick et al. (2012). We ask in Exercise 12 to perform a simulation of this model, and perform BMA using the function logistic.dma from the dma package. References "],["sec103.html", "10.3 Generalized linear models", " 10.3 Generalized linear models Generalized linear models (GLMs) were introduced by Nelder and Wedderburn (1972), extending the concept of linear regression to a more general setting. These models are characterized by: i) a dependent variable \\(y_i\\) whose probability distribution function belongs to the exponential family (see Section 3.1, ii) a linear predictor \\(\\eta = \\boldsymbol{x}^{\\top}\\boldsymbol{\\beta}\\), and iii) a link function such that \\(\\mathbb{E}[y|\\boldsymbol{x}] = g^{-1}(\\boldsymbol{x}^{\\top}\\boldsymbol{\\beta})\\), which implies that \\(g(\\mathbb{E}[y|\\boldsymbol{x}]) = \\boldsymbol{x}^{\\top}\\boldsymbol{\\beta}\\). GLMs can be extended to the overdispersed exponential family (McCullagh and Nelder 1989). As we know from Section 3.1, the Poisson distribution belongs to the exponential family, such that \\(p(y|\\lambda) = \\frac{\\exp(-\\lambda)\\exp(y\\log(\\lambda))}{y!}\\), or in the canonical form \\(p(y|\\eta) = \\frac{\\exp(\\eta y - \\exp(\\eta))}{y!}\\), where \\(\\eta = \\log(\\lambda)\\), which means that \\(\\boldsymbol{x}^{\\top}\\boldsymbol{\\beta} = \\log(\\lambda)\\). Consequently, \\(\\mathbb{E}[y|\\boldsymbol{x}] = \\nabla(\\exp(\\eta)) = \\exp(\\eta) = \\lambda = \\exp(\\boldsymbol{x}^{\\top}\\boldsymbol{\\beta})\\). Therefore, the link function in the Poisson case is the log function. In Exercise 6, we ask you to show that the link function in the Bernoulli case is the logit function. Other examples include the identity function in the case of the Gaussian distribution and the negative inverse in the case of the gamma distribution. We can use the GLM framework to perform Bayesian model averaging (BMA) using the BIC approximation, following A. Raftery (1995). Specifically, the BIC is given by \\(BIC = k_m \\log(N) - 2 \\log(p(\\hat{\\boldsymbol{\\theta}}_m | \\boldsymbol{y}))\\), where \\(\\hat{\\boldsymbol{\\theta}}_m\\) is the maximum likelihood estimator. Thus, we simply need to calculate the likelihood function at the maximum likelihood estimator. Example: Simulation exercises Let’s perform some simulation exercises to assess the performance of the BIC approximation using the Occam’s window in GLMs. There are 27 regressors, where \\(x_{i1}\\) and \\(x_{i2}\\) are just the relevant regressors in all exercises, \\(i=1,2,\\dots,1000\\). Logit: \\(x_k\\sim N(0, 1)\\), \\(k =1,\\dots,27\\), and \\(p(y_i=1|\\boldsymbol{x}_i)=\\exp(0.5+0.8x_{i1}-1.2x_{i2})/(1+\\exp(0.5+0.8x_{i1}-1.2x_{i2}))\\). Gamma: \\(x_k\\sim N(0, 0.5^2)\\), \\(k =1,\\dots,27\\), and \\(y_i\\sim G(\\alpha,\\delta)\\) where \\(\\alpha=-(0.5+0.2x_{i1}0.1x_{i2})^{-1}\\) and \\(\\delta=1\\). Poisson: \\(x_k\\sim N(0, 1)\\), \\(k =1,\\dots,27\\), and \\(\\mathbb{E}[y_i|\\boldsymbol{x}_i]=\\lambda_i=\\exp(0.5+1.1x_{i1}+0.7x_{i2})\\). Our GUI uses the command bic.glm from the BMA package to perform BMA using the BIC approximation with the Occam’s window in GLMs. The next Algorithm shows how to do this in our GUI, and the following code shows how to perform BMA in logit models using the simulation setting. Algorithm: Bayesian Model Averaging in Generalized Linear Models using BIC Select Bayesian Model Averaging on the top panel Select the Generalized Linear Model using the left radio button. Options: Binomial data (Logit) Real positive data (Gamma) Count data (Poisson) Upload the dataset, selecting first whether there is a header in the file and the type of separator in the csv file (comma, semicolon, or tab). Then, use the Browse button under the Choose File legend Type the OR number of Occam’s window in the box under OR: Number between 5 and 50. This is not necessary, as the default value is 50 Type the OL number of Occam’s window in the box under OL: Number between 0.0001 and 1. This is not necessary, as the default value is 0.0025 Click the Go! button Analyze results: After a few seconds or minutes, a table appears showing, for each regressor in the dataset: The posterior inclusion probability (p!=0) The BMA posterior mean (EV) The BMA standard deviation (SD) The PMP for the most relevant models (highest PMPs) Download posterior results using the Download results using BIC button. Two files are provided: The first file contains the best models by row according to the PMP (last column), indicating variable inclusion with 1 (0 indicates no inclusion) The second file contains the PIP, the BMA expected value, and the standard deviation for each variable in the dataset The results show that the PIPs of \\(x_{i1}\\) and \\(x_{i2}\\) are equal 1 in all three settings, the data generating process gets the highest PMP, and the BMA posterior means are close to the population values in each simulation setting. The other variables get PIPs close to 0, except a few exceptions, and the BMA posterior means are also close to 0. This suggests that the BIC approximation does a good job finding the data generating process in generalized linear models. We can take advantage of the glm function in R to perform BMA by programming an MC3 algorithm. The following code illustrates how to do this in the Poisson simulation. First, we simulate the data; second, we define a function to compute the log marginal likelihood approximation using the results from the glm function. Then, we initialize the models to begin the MC3 algorithm. After that, we implement the MC3 algorithm, which involves small modifications of the code used for MC3 in Gaussian linear models. We can calculate the posterior model probabilities (PMPs), posterior inclusion probabilities (PIPs), BMA means, and standard deviations as we did previously. The simulation setting involves \\(2^{27}\\) models, which corresponds to approximately 135 million models in the model space. We run our MC3 algorithm using the BIC approximation with 50,000 iterations. This takes considerably more time than the BIC approximation from the BMA package, but it seems to perform well in identifying the data-generating process, as the PMP of this model equals 1. The posterior inclusion probabilities (PIPs) for \\(x_{i1}\\) and \\(x_{i2}\\) are also 1, and the posterior means are 1.1 and 0.7, respectively, which are equal to the population values. The t-ratios are far greater than 2. However, running 50,000 iterations results in mass concentration in one model, in this case, the data-generating process. If we run 25,000 MC3 iterations, the highest PMP is 0.8, but it is not associated with the data-generating process. Nonetheless, the PIP is equal to 1 for \\(x_{i1}\\) and \\(x_{i2}\\), and other regressors also have high PIPs. The BMA means for \\(x_{i1}\\) and \\(x_{i2}\\) are equal to the population values, and the BMA means for the other regressors are equal to 0. The t-ratios of the regressors in the population statistical model are much greater than 2, whereas the t-ratios of the other regressors are equal to 0. This exercise demonstrates that 25,000 iterations were not sufficient to uncover the data-generating process. However, it also emphasizes an important point: we need to analyze all the relevant results from the BMA analysis, not just the PMPs and/or PIPs. In Exercise 10, we ask you to use this approach to perform a BMA algorithm in the logit regression, using the simulation setting for logit models from this section. ### Logit ### rm(list = ls()); set.seed(010101) n&lt;-1000; B&lt;-c(0.5,0.8,-1.2) X&lt;-matrix(cbind(rep(1,n),rnorm(n,0,1),rnorm(n,0,1)),n,length(B)) p &lt;- exp(X%*%B)/(1+exp(X%*%B)); y &lt;- rbinom(n, 1, p) nXgar&lt;-25; Xgar&lt;-matrix(rnorm(nXgar*n),n,nXgar) df&lt;-as.data.frame(cbind(y,X[,-1],Xgar)) colnames(df) &lt;- c(&quot;y&quot;, &quot;x1&quot;, &quot;x2&quot;, &quot;x3&quot;, &quot;x4&quot;, &quot;x5&quot;, &quot;x6&quot;, &quot;x7&quot;, &quot;x8&quot;, &quot;x9&quot;, &quot;x10&quot;, &quot;x11&quot;, &quot;x12&quot;, &quot;x13&quot;, &quot;x14&quot;, &quot;x15&quot;, &quot;x16&quot;, &quot;x17&quot;, &quot;x18&quot;, &quot;x19&quot;, &quot;x20&quot;, &quot;x21&quot;, &quot;x22&quot;, &quot;x23&quot;, &quot;x24&quot;, &quot;x25&quot;, &quot;x26&quot;, &quot;x27&quot;) BMAglmLogit &lt;- BMA::bic.glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10+x11+x12+x13+x14+x15+x16+x17+x18+x19+x20+x21+x22+x23+x24+x25+x26+x27, data = df, glm.family = binomial(link=&quot;logit&quot;), strict = FALSE, OR = 50) summary(BMAglmLogit) ## ## Call: ## bic.glm.formula(f = y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 + x10 + x11 + x12 + x13 + x14 + x15 + x16 + x17 + x18 + x19 + x20 + x21 + x22 + x23 + x24 + x25 + x26 + x27, data = df, glm.family = binomial(link = &quot;logit&quot;), strict = FALSE, OR = 50) ## ## ## 40 models were selected ## Best 5 models (cumulative posterior probability = 0.6196 ): ## ## p!=0 EV SD model 1 model 2 model 3 ## Intercept 100 4.231e-01 0.076191 0.4212 0.4182 0.4296 ## x1.x 100.0 8.512e-01 0.084649 0.8467 0.8541 0.8549 ## x2.x 100.0 -1.105e+00 0.089964 -1.1029 -1.1079 -1.1023 ## x3.x 2.9 2.382e-03 0.018557 . . . ## x4.x 24.5 -4.203e-02 0.082651 . . -0.1699 ## x5.x 0.8 1.304e-04 0.006885 . . . ## x6.x 1.8 1.240e-03 0.013934 . . . ## x7.x 14.8 2.273e-02 0.061659 . . . ## x8.x 0.8 -6.231e-05 0.006677 . . . ## x9.x 0.9 -2.308e-04 0.007548 . . . ## x10.x 0.9 -3.683e-04 0.008215 . . . ## x11.x 1.1 -6.107e-04 0.009791 . . . ## x12.x 0.8 -1.680e-05 0.006267 . . . ## x13.x 1.1 -6.397e-04 0.009839 . . . ## x14.x 0.8 1.517e-04 0.007144 . . . ## x15.x 0.9 -1.923e-04 0.007157 . . . ## x16.x 1.0 4.411e-04 0.008425 . . . ## x17.x 1.8 1.298e-03 0.013796 . . . ## x18.x 0.8 4.661e-05 0.006742 . . . ## x19.x 1.0 4.311e-04 0.008746 . . . ## x20.x 0.8 -1.571e-04 0.007049 . . . ## x21.x 7.5 8.922e-03 0.037260 . . . ## x22.x 0.8 4.378e-05 0.006687 . . . ## x23.x 24.3 -4.202e-02 0.083002 . -0.1718 . ## x24.x 0.8 -1.384e-04 0.007200 . . . ## x25.x 0.8 -1.363e-05 0.006489 . . . ## x26.x 1.8 1.336e-03 0.014274 . . . ## x27.x 1.9 1.354e-03 0.014298 . . . ## ## nVar 2 3 3 ## BIC -5812.0652 -5810.3862 -5810.3482 ## post prob 0.260 0.112 0.110 ## model 4 model 5 ## Intercept 0.4221 0.4271 ## x1.x 0.8481 0.8627 ## x2.x -1.1016 -1.1087 ## x3.x . . ## x4.x . -0.1784 ## x5.x . . ## x6.x . . ## x7.x 0.1575 . ## x8.x . . ## x9.x . . ## x10.x . . ## x11.x . . ## x12.x . . ## x13.x . . ## x14.x . . ## x15.x . . ## x16.x . . ## x17.x . . ## x18.x . . ## x19.x . . ## x20.x . . ## x21.x . . ## x22.x . . ## x23.x . -0.1801 ## x24.x . . ## x25.x . . ## x26.x . . ## x27.x . . ## ## nVar 3 4 ## BIC -5809.6482 -5809.1451 ## post prob 0.078 0.060 ## ## 1 observations deleted due to missingness. ### Gamma ### rm(list = ls()); set.seed(010101) n&lt;-1000; B&lt;- c(0.5, 0.2, 0.1) X&lt;-matrix(cbind(rep(1,n),rnorm(n,0,0.5),rnorm(n,0,0.5)),n,length(B)) y1 &lt;- (X%*%B)^(-1) y &lt;- rgamma(n,y1,scale=1) nXgar&lt;-25; Xgar&lt;-matrix(rnorm(nXgar*n),n,nXgar) df&lt;-as.data.frame(cbind(y,X[,-1],Xgar)) colnames(df) &lt;- c(&quot;y&quot;, &quot;x1&quot;, &quot;x2&quot;, &quot;x3&quot;, &quot;x4&quot;, &quot;x5&quot;, &quot;x6&quot;, &quot;x7&quot;, &quot;x8&quot;, &quot;x9&quot;, &quot;x10&quot;, &quot;x11&quot;, &quot;x12&quot;, &quot;x13&quot;, &quot;x14&quot;, &quot;x15&quot;, &quot;x16&quot;, &quot;x17&quot;, &quot;x18&quot;, &quot;x19&quot;, &quot;x20&quot;, &quot;x21&quot;, &quot;x22&quot;, &quot;x23&quot;, &quot;x24&quot;, &quot;x25&quot;, &quot;x26&quot;, &quot;x27&quot;) BMAglmGamma &lt;- BMA::bic.glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10+x11+x12+x13+x14+x15+x16+x17+x18+x19+x20+x21+x22+x23+x24+x25+x26+x27, data = df, glm.family = Gamma(link=&quot;inverse&quot;), strict = FALSE, OR = 50) summary(BMAglmGamma) ## ## Call: ## bic.glm.formula(f = y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 + x10 + x11 + x12 + x13 + x14 + x15 + x16 + x17 + x18 + x19 + x20 + x21 + x22 + x23 + x24 + x25 + x26 + x27, data = df, glm.family = Gamma(link = &quot;inverse&quot;), strict = FALSE, OR = 50) ## ## ## 36 models were selected ## Best 5 models (cumulative posterior probability = 0.6264 ): ## ## p!=0 EV SD model 1 model 2 model 3 ## Intercept 100 4.890e-01 0.0117343 4.885e-01 4.895e-01 4.902e-01 ## x1.x 100.0 2.026e-01 0.0187327 2.021e-01 2.033e-01 2.042e-01 ## x2.x 99.2 7.552e-02 0.0210472 7.577e-02 7.595e-02 7.820e-02 ## x3.x 1.1 3.661e-05 0.0011044 . . . ## x4.x 1.2 7.240e-05 0.0012692 . . . ## x5.x 1.0 1.013e-06 0.0010648 . . . ## x6.x 1.0 -7.413e-06 0.0009672 . . . ## x7.x 2.1 1.787e-04 0.0019443 . . . ## x8.x 2.7 3.187e-04 0.0025652 . . . ## x9.x 2.8 3.287e-04 0.0026193 . . . ## x10.x 2.5 -2.618e-04 0.0023160 . . . ## x11.x 2.2 -1.909e-04 0.0018748 . . . ## x12.x 1.3 -1.021e-04 0.0014787 . . . ## x13.x 1.1 5.812e-05 0.0012447 . . . ## x14.x 1.2 -8.201e-05 0.0013340 . . . ## x15.x 1.1 5.983e-05 0.0012278 . . . ## x16.x 1.0 4.335e-06 0.0010045 . . . ## x17.x 1.0 1.127e-05 0.0010351 . . . ## x18.x 1.0 1.195e-05 0.0010612 . . . ## x19.x 1.2 -8.152e-05 0.0013225 . . . ## x20.x 25.2 5.858e-03 0.0112689 . 2.329e-02 . ## x21.x 11.5 -2.200e-03 0.0069431 . . -1.938e-02 ## x22.x 1.1 -3.714e-05 0.0011170 . . . ## x23.x 10.4 1.998e-03 0.0067118 . . . ## x24.x 1.0 8.960e-06 0.0009762 . . . ## x25.x 1.5 1.462e-04 0.0017640 . . . ## x26.x 2.1 -1.856e-04 0.0019576 . . . ## x27.x 1.0 5.144e-06 0.0010106 . . . ## ## nVar 2 3 3 ## BIC -5.849e+03 -5.848e+03 -5.846e+03 ## post prob 0.316 0.149 0.072 ## model 4 model 5 ## Intercept 4.893e-01 4.903e-01 ## x1.x 2.019e-01 2.027e-01 ## x2.x 7.641e-02 7.639e-02 ## x3.x . . ## x4.x . . ## x5.x . . ## x6.x . . ## x7.x . . ## x8.x . . ## x9.x . . ## x10.x . . ## x11.x . . ## x12.x . . ## x13.x . . ## x14.x . . ## x15.x . . ## x16.x . . ## x17.x . . ## x18.x . . ## x19.x . . ## x20.x . 2.364e-02 ## x21.x . . ## x22.x . . ## x23.x 1.914e-02 1.948e-02 ## x24.x . . ## x25.x . . ## x26.x . . ## x27.x . . ## ## nVar 3 4 ## BIC -5.846e+03 -5.845e+03 ## post prob 0.060 0.030 ## ## 1 observations deleted due to missingness. ### Poisson ### rm(list = ls()); set.seed(010101) n&lt;-1000; B&lt;-c(2,1.1,0.7) X&lt;-matrix(cbind(rep(1,n),rnorm(n,0,1),rnorm(n,0,1)),n,length(B)) y1&lt;-exp(X%*%B); y&lt;-rpois(n,y1) nXgar&lt;-25; Xgar&lt;-matrix(rnorm(nXgar*n),n,nXgar) df&lt;-as.data.frame(cbind(y,X[,-1],Xgar)) colnames(df) &lt;- c(&quot;y&quot;, &quot;x1&quot;, &quot;x2&quot;, &quot;x3&quot;, &quot;x4&quot;, &quot;x5&quot;, &quot;x6&quot;, &quot;x7&quot;, &quot;x8&quot;, &quot;x9&quot;, &quot;x10&quot;, &quot;x11&quot;, &quot;x12&quot;, &quot;x13&quot;, &quot;x14&quot;, &quot;x15&quot;, &quot;x16&quot;, &quot;x17&quot;, &quot;x18&quot;, &quot;x19&quot;, &quot;x20&quot;, &quot;x21&quot;, &quot;x22&quot;, &quot;x23&quot;, &quot;x24&quot;, &quot;x25&quot;, &quot;x26&quot;, &quot;x27&quot;) BMAglmPoisson &lt;- BMA::bic.glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10+x11+x12+x13+x14+x15+x16+x17+x18+x19+x20+x21+x22+x23+x24+x25+x26+x27, data = df, glm.family = poisson(link=&quot;log&quot;), strict = FALSE, OR = 50) summary(BMAglmPoisson) ## ## Call: ## bic.glm.formula(f = y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 + x10 + x11 + x12 + x13 + x14 + x15 + x16 + x17 + x18 + x19 + x20 + x21 + x22 + x23 + x24 + x25 + x26 + x27, data = df, glm.family = poisson(link = &quot;log&quot;), strict = FALSE, OR = 50) ## ## ## 26 models were selected ## Best 5 models (cumulative posterior probability = 0.6228 ): ## ## p!=0 EV SD model 1 model 2 model 3 ## Intercept 100 2.004e+00 0.0120917 2.004e+00 2.002e+00 2.003e+00 ## x1.x 100.0 1.093e+00 0.0071406 1.093e+00 1.096e+00 1.095e+00 ## x2.x 100.0 7.020e-01 0.0076175 7.020e-01 7.023e-01 7.011e-01 ## x3.x 1.9 -1.202e-04 0.0013752 . . . ## x4.x 1.4 -2.783e-05 0.0009363 . . . ## x5.x 5.8 7.628e-04 0.0036096 . . 1.326e-02 ## x6.x 1.9 -1.311e-04 0.0014441 . . . ## x7.x 1.5 5.797e-05 0.0010305 . . . ## x8.x 1.4 -2.484e-05 0.0009678 . . . ## x9.x 1.6 -7.084e-05 0.0011074 . . . ## x10.x 3.7 -4.232e-04 0.0026514 . . . ## x11.x 1.4 -3.190e-05 0.0010090 . . . ## x12.x 1.5 4.617e-05 0.0009407 . . . ## x13.x 1.4 2.822e-05 0.0009560 . . . ## x14.x 1.4 2.029e-05 0.0010251 . . . ## x15.x 2.1 -1.445e-04 0.0014510 . . . ## x16.x 1.6 7.135e-05 0.0011593 . . . ## x17.x 1.5 -5.180e-05 0.0010208 . . . ## x18.x 1.6 -8.503e-05 0.0012462 . . . ## x19.x 3.2 -3.442e-04 0.0023704 . . . ## x20.x 5.8 -7.149e-04 0.0033497 . -1.223e-02 . ## x21.x 1.4 -2.393e-05 0.0009079 . . . ## x22.x 2.1 1.578e-04 0.0015657 . . . ## x23.x 1.7 9.252e-05 0.0012586 . . . ## x24.x 1.5 -4.766e-05 0.0010436 . . . ## x25.x 2.1 -1.453e-04 0.0014830 . . . ## x26.x 3.4 -3.780e-04 0.0025203 . . . ## x27.x 4.1 -4.169e-04 0.0024626 . . . ## ## nVar 2 3 3 ## BIC -5.798e+03 -5.794e+03 -5.794e+03 ## post prob 0.429 0.058 0.058 ## model 4 model 5 ## Intercept 2.004e+00 2.004e+00 ## x1.x 1.094e+00 1.093e+00 ## x2.x 7.024e-01 7.024e-01 ## x3.x . . ## x4.x . . ## x5.x . . ## x6.x . . ## x7.x . . ## x8.x . . ## x9.x . . ## x10.x . -1.139e-02 ## x11.x . . ## x12.x . . ## x13.x . . ## x14.x . . ## x15.x . . ## x16.x . . ## x17.x . . ## x18.x . . ## x19.x . . ## x20.x . . ## x21.x . . ## x22.x . . ## x23.x . . ## x24.x . . ## x25.x . . ## x26.x . . ## x27.x -1.027e-02 . ## ## nVar 3 3 ## BIC -5.793e+03 -5.793e+03 ## post prob 0.041 0.037 ## ## 1 observations deleted due to missingness. ######################################## rm(list = ls()); set.seed(010101) n&lt;-1000; B&lt;-c(2,1.1,0.7) X&lt;-matrix(cbind(rep(1,n),rnorm(n,0,1),rnorm(n,0,1)),n,length(B)) y1&lt;-exp(X%*%B); y&lt;-rpois(n,y1) nXgar&lt;-25; Xgar&lt;-matrix(rnorm(nXgar*n),n,nXgar) df&lt;-as.data.frame(cbind(y,X[,-1],Xgar)) colnames(df) &lt;- c(&quot;y&quot;, &quot;x1&quot;, &quot;x2&quot;, &quot;x3&quot;, &quot;x4&quot;, &quot;x5&quot;, &quot;x6&quot;, &quot;x7&quot;, &quot;x8&quot;, &quot;x9&quot;, &quot;x10&quot;, &quot;x11&quot;, &quot;x12&quot;, &quot;x13&quot;, &quot;x14&quot;, &quot;x15&quot;, &quot;x16&quot;, &quot;x17&quot;, &quot;x18&quot;, &quot;x19&quot;, &quot;x20&quot;, &quot;x21&quot;, &quot;x22&quot;, &quot;x23&quot;, &quot;x24&quot;, &quot;x25&quot;, &quot;x26&quot;, &quot;x27&quot;) Xnew &lt;- apply(df[,-1], 2, scale) BICfunt &lt;- function(Model){ indr &lt;- Model == 1; kr &lt;- sum(indr) if(kr &gt; 0){ Xr &lt;- as.matrix(Xnew[ , indr]) model &lt;- glm(y ~ Xr, family = poisson(link = &quot;log&quot;)) model_bic &lt;- BIC(model) mllMod &lt;- -model_bic/2 }else{ model &lt;- glm(y ~ 1, family = poisson(link = &quot;log&quot;)) model_bic &lt;- BIC(model); mllMod &lt;- -model_bic/2 } return(mllMod) } M &lt;- 500; K &lt;- dim(df)[2] - 1 Models &lt;- matrix(rbinom(K*M, 1, p = 0.5), ncol = K, nrow = M) mllnew &lt;- sapply(1:M, function(s){BICfunt(matrix(Models[s,], 1, K))}) oind &lt;- order(mllnew, decreasing = TRUE) mllnew &lt;- mllnew[oind]; Models &lt;- Models[oind, ] # Hyperparameters MC3 iter &lt;- 25000 pb &lt;- winProgressBar(title = &quot;progress bar&quot;, min = 0, max = iter, width = 300) s &lt;- 1 while(s &lt;= iter){ ActModel &lt;- Models[M,] idK &lt;- which(ActModel == 1) Kact &lt;- length(idK) if(Kact &lt; K &amp; Kact &gt; 1){ CardMol &lt;- K opt &lt;- sample(1:3, 1) if(opt == 1){ # Same CandModel &lt;- ActModel }else{ if(opt == 2){ # Add All &lt;- 1:K NewX &lt;- sample(All[-idK], 1) CandModel &lt;- ActModel CandModel[NewX] &lt;- 1 }else{ # Subtract LessX &lt;- sample(idK, 1) CandModel &lt;- ActModel CandModel[LessX] &lt;- 0 } } }else{ CardMol &lt;- K + 1 if(Kact == K){ opt &lt;- sample(1:2, 1) if(opt == 1){ # Same CandModel &lt;- ActModel }else{ # Subtract LessX &lt;- sample(1:K, 1) CandModel &lt;- ActModel CandModel[LessX] &lt;- 0 } }else{ if(K == 1){ opt &lt;- sample(1:3, 1) if(opt == 1){ # Same CandModel &lt;- ActModel }else{ if(opt == 2){ # Add All &lt;- 1:K NewX &lt;- sample(All[-idK], 1) CandModel &lt;- ActModel CandModel[NewX] &lt;- 1 }else{ # Subtract LessX &lt;- sample(idK, 1) CandModel &lt;- ActModel CandModel[LessX] &lt;- 0 } } }else{ # Add NewX &lt;- sample(1:K, 1) CandModel &lt;- ActModel CandModel[NewX] &lt;- 1 } } } LogMLact &lt;- BICfunt(matrix(ActModel, 1, K)) LogMLcand &lt;- BICfunt(matrix(CandModel, 1, K)) alpha &lt;- min(1, exp(LogMLcand-LogMLact)) u &lt;- runif(1) if(u &lt;= alpha){ mllnew[M] &lt;- LogMLcand Models[M, ] &lt;- CandModel oind &lt;- order(mllnew, decreasing = TRUE) mllnew &lt;- mllnew[oind] Models &lt;- Models[oind, ] }else{ mllnew &lt;- mllnew Models &lt;- Models } s &lt;- s + 1 setWinProgressBar(pb, s, title=paste( round(s/iter*100, 0),&quot;% done&quot;)) } close(pb) ## NULL ModelsUni &lt;- unique(Models) mllnewUni &lt;- sapply(1:dim(ModelsUni)[1], function(s){BICfunt(matrix(ModelsUni[s,], 1, K))}) StMarLik &lt;- exp(mllnewUni-mllnewUni[1]) PMP &lt;- StMarLik/sum(StMarLik) # PMP based on unique selected models plot(PMP) ModelsUni[1,] ## [1] 1 1 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 PIP &lt;- NULL for(k in 1:K){ PIPk &lt;- sum(PMP[which(ModelsUni[,k] == 1)]) PIP &lt;- c(PIP, PIPk) } plot(PIP) Xnew &lt;- df[,-1] nModels &lt;- dim(ModelsUni)[1] Means &lt;- matrix(0, nModels, K) Vars &lt;- matrix(0, nModels, K) for(m in 1:nModels){ idXs &lt;- which(ModelsUni[m,] == 1) if(length(idXs) == 0){ Regm &lt;- glm(y ~ 1, family = poisson(link = &quot;log&quot;)) }else{ Xm &lt;- as.matrix(Xnew[, idXs]) Regm &lt;- glm(y ~ Xm, family = poisson(link = &quot;log&quot;)) SumRegm &lt;- summary(Regm) Means[m, idXs] &lt;- SumRegm[[&quot;coefficients&quot;]][-1,1] Vars[m, idXs] &lt;- SumRegm[[&quot;coefficients&quot;]][-1,2]^2 } } BMAmeans &lt;- colSums(Means*PMP) BMAsd &lt;- (colSums(PMP*Vars) + colSums(PMP*(Means-matrix(rep(BMAmeans, each = nModels), nModels, K))^2))^0.5 plot(BMAmeans) plot(BMAsd) plot(BMAmeans/BMAsd) References "],["sec10_4.html", "10.4 Calculating the marginal likelihood", " 10.4 Calculating the marginal likelihood The BIC is an asymptotic approximation of the marginal likelihood, and consequently, it is used to obtain the Bayes factors. However, this method has limitations in applications with moderate and small sample sizes (Alan E. Gelfand and Dey 1994). Therefore, other methods are available to calculate the Bayes factors when there is no analytical solution for the marginal likelihood. Observe that calculating the Bayes factor with respect to a reference model (\\(\\mathcal{M}_0\\)) helps to obtain the posterior model probabilities, \\[\\begin{align*} \\pi(\\mathcal{M}_j |\\boldsymbol{y})&amp;=\\frac{p(\\boldsymbol{y} | \\mathcal{M}_j)\\pi(\\mathcal{M}_j)}{\\sum_{m=1}^{M}p(\\boldsymbol{y} | \\mathcal{M}_m)\\pi(\\mathcal{M}_m)}\\\\ &amp;=\\frac{p(\\boldsymbol{y} | \\mathcal{M}_j)\\pi(\\mathcal{M}_j)/p(\\boldsymbol{y} | \\mathcal{M}_0)}{\\sum_{m=1}^{M}p(\\boldsymbol{y} | \\mathcal{M}_m)\\pi(\\mathcal{M}_m)/p(\\boldsymbol{y} | \\mathcal{M}_0)}\\\\ &amp;=\\frac{BF_{j0}\\times\\pi(\\mathcal{M}_j)}{\\sum_{m=1}^{M}BF_{l0}\\times\\pi(\\mathcal{M}_l)}. \\end{align*}\\] Thus, \\(\\pi(\\mathcal{M}_j |\\boldsymbol{y})=\\frac{BF_{j0}}{\\sum_{m=1}^{M}BF_{l0}}\\) assuming equal prior model probabilities. In addition, it has been established in many settings that the Bayes factor is consistent. That is, the probability of identifying the true data generating process converges to 1 as the sample size increases to infinity. Alternatively, it asymptotically identifies the model that minimizes the Kullback-Leibler divergence with respect to the data generating process when this process is not part of the models under consideration (Siddhartha Chib and Kuffner 2016; Stephen G. Walker 2004b; Stephen G. Walker 2004a).60 10.4.1 Savage-Dickey density ratio The Savage-Dickey density ratio is a way to calculate the Bayes factors when we compare nested models with particular priors (James M. Dickey 1971; Verdinelli and Wasserman 1995). In particular, given the parameter space \\(\\boldsymbol{\\theta}=(\\boldsymbol{\\omega}^{\\top}, \\boldsymbol{\\psi}^{\\top})^{\\top}\\in \\boldsymbol{\\Theta}=\\boldsymbol{\\Omega}\\times \\boldsymbol{\\Psi}\\), where we wish to test the null hypothesis \\(H_0:\\boldsymbol{\\omega}=\\boldsymbol{\\omega}_0\\) (model \\(\\mathcal{M}_1\\)) versus \\(H_1:\\boldsymbol{\\omega}\\neq \\boldsymbol{\\omega}_0\\) (model \\(\\mathcal{M}_2\\)), if \\(\\pi(\\boldsymbol{\\psi}|\\boldsymbol{\\omega}_0,\\mathcal{M}_2)=\\pi(\\boldsymbol{\\psi}|\\mathcal{M}_1)\\),61 then the Bayes factor comparing \\(\\mathcal{M}_1\\) versus \\(\\mathcal{M}_2\\) is \\[\\begin{equation} BF_{12}=\\frac{\\pi(\\boldsymbol{\\omega}=\\boldsymbol{\\omega}_0|\\boldsymbol{y},\\mathcal{M}_2)}{\\pi(\\boldsymbol{\\omega}=\\boldsymbol{\\omega}_0|\\mathcal{M}_2)}, \\tag{10.1} \\end{equation}\\] where \\(\\pi(\\boldsymbol{\\omega}=\\boldsymbol{\\omega}_0|\\boldsymbol{y},\\mathcal{M}_2)\\) and \\(\\pi(\\boldsymbol{\\omega}=\\boldsymbol{\\omega}_0|\\mathcal{M}_2)\\) are the posterior and prior densities of \\(\\boldsymbol{\\omega}\\) under \\(\\mathcal{M}_2\\) evaluated at \\(\\boldsymbol{\\omega}_0\\) (see Verdinelli and Wasserman (1995)). Equation (10.1) is called the Savage-Dickey density ratio. A nice feature is that just requires estimation of model \\(\\mathcal{M}_2\\), and evaluation of the prior and posterior densities. This means no evaluation of the marginal likelihood (G. M. Koop 2003). 10.4.2 Chib’s methods Another popular method to calculate the marginal likelihood is given by Siddhartha Chib (1995) and Siddhartha Chib and Jeliazkov (2001). The former is an algorithm to calculate the marginal likelihood from the posterior draws of the Gibbs sampling algorithm, and the latter calculates the marginal likelihood from the posterior draws of the Metropolis-Hastings algorithm. The point of departure in Siddhartha Chib (1995) is the identity \\[\\begin{align*} \\pi(\\boldsymbol{\\theta}^*|\\boldsymbol{y},\\mathcal{M}_m)=\\frac{p(\\boldsymbol{y}|\\boldsymbol{\\theta}^*,\\mathcal{M}_m)\\times\\pi(\\boldsymbol{\\theta}^*|\\mathcal{M}_m)}{p(\\boldsymbol{y}|\\mathcal{M}_m)}, \\end{align*}\\] where \\(\\boldsymbol{\\theta}^*\\) is a particular value of \\(\\boldsymbol{\\theta}\\) of high probability, for instance, the mode. This implies that \\[\\begin{align*} p(\\boldsymbol{y}|\\mathcal{M}_m)=\\frac{p(\\boldsymbol{y}|\\boldsymbol{\\theta}^*,\\mathcal{M}_m)\\times\\pi(\\boldsymbol{\\theta}^*|\\mathcal{M}_m)}{\\pi(\\boldsymbol{\\theta}^*|\\boldsymbol{y},\\mathcal{M}_m)}. \\end{align*}\\] We can easily calculate the numerator of this expression. However, the critical point in this expression is to calculate the denominator as we know \\(\\pi(\\boldsymbol{\\theta}^*|\\boldsymbol{y},\\mathcal{M}_m)\\) up to a normalizing constant. We can calculate this from the posterior draws. Assume that \\(\\boldsymbol{\\theta}=[\\boldsymbol{\\theta}^{\\top}_1 \\ \\boldsymbol{\\theta}^{\\top}_2]^{\\top}\\), then \\(\\pi(\\boldsymbol{\\theta}^*|\\boldsymbol{y},\\mathcal{M}_m)=\\pi(\\boldsymbol{\\theta}^*_1|\\boldsymbol{\\theta}^*_2,\\boldsymbol{y},\\mathcal{M}_m)\\times \\pi(\\boldsymbol{\\theta}^*_2|\\boldsymbol{y},\\mathcal{M}_m)\\). We have the first term because in the Gibbs sampling algorithm the posterior conditional distributions are available. The second is \\[\\begin{align*} \\pi(\\boldsymbol{\\theta}^*_2|\\boldsymbol{y},\\mathcal{M}_m)&amp;=\\int_{\\boldsymbol{\\Theta}_1}\\pi(\\boldsymbol{\\theta}_1,\\boldsymbol{\\theta}^*_2|\\boldsymbol{y},\\mathcal{M}_m)d\\boldsymbol{\\theta}_1\\\\ &amp;=\\int_{\\boldsymbol{\\Theta}_1}\\pi(\\boldsymbol{\\theta}^*_2|\\boldsymbol{\\theta}_1,\\boldsymbol{y},\\mathcal{M}_m)\\pi(\\boldsymbol{\\theta}_1|\\boldsymbol{y},\\mathcal{M}_m)d\\boldsymbol{\\theta}_1\\\\ &amp;\\approx \\frac{1}{S}\\sum_{s=1}^S \\pi(\\boldsymbol{\\theta}^*_2|\\boldsymbol{\\theta}^{(s)}_1,\\boldsymbol{y},\\mathcal{M}_m), \\end{align*}\\] where \\(\\boldsymbol{\\theta}^{(s)}_1\\) are the posterior draws of \\(\\boldsymbol{\\theta}_1\\) from the Gibbs sampling algorithm. The generalization to more blocks can be seen in Siddhartha Chib (1995) and Greenberg (2012). In addition, the extension to the Metropolis-Hastings algorithm can be seen in Siddhartha Chib and Jeliazkov (2001), and Greenberg (2012). 10.4.3 Gelfand-Dey method We can use the Gelfand-Dey method (Alan E. Gelfand and Dey 1994) when we want to calculate the Bayes factor to compare non-nested models, models where the Savage-Dickey density ratio is hard to calculate, or the Chib’s methods are difficult to implement. The Gelfand-Dey method is very general, and can be used in virtually any model (G. M. Koop 2003). Given a probability density function \\(q(\\boldsymbol{\\theta})\\), whose support is in \\(\\boldsymbol{\\Theta}\\), then \\[\\begin{align*} \\mathbb{E}\\left[\\frac{q(\\boldsymbol{\\theta})}{\\pi(\\boldsymbol{\\theta}|\\mathcal{M}_m)p(\\boldsymbol{y}|\\boldsymbol{\\theta}_m,\\mathcal{M}_m)}\\biggr\\rvert \\boldsymbol{y},\\mathcal{M}_m\\right]&amp;=\\frac{1}{p(\\boldsymbol{y}|\\mathcal{M}_m)}, \\end{align*}\\] where the expected value is with respect to the posterior distribution given the model \\(\\mathcal{M}_m\\) (see Exercise 12). The critical point is to select a good \\(q(\\boldsymbol{\\theta})\\). John Geweke (1999) recommends to use \\(q(\\boldsymbol{\\theta})\\) equal to a truncated multivariate normal density function with mean and variance equal to the posterior mean (\\(\\hat{\\boldsymbol{\\theta}}\\)) and variance (\\(\\hat{\\boldsymbol{\\Sigma}}\\)) of \\(\\boldsymbol{\\theta}\\). The truncation region is \\(\\hat{\\boldsymbol{\\Theta}}=\\left\\{\\boldsymbol{\\theta}:(\\boldsymbol{\\theta}-\\hat{\\boldsymbol{\\theta}})^{\\top}\\hat{\\boldsymbol{\\Sigma}}^{-1}(\\boldsymbol{\\theta}-\\hat{\\boldsymbol{\\theta}})\\leq \\chi_{1-\\alpha}^2(K)\\right\\}\\), where \\(\\chi_{1-\\alpha}^2(K)\\) is the \\((1-\\alpha)\\) percentile of the Chi-squared distribution with \\(K\\) degrees of freedom, \\(K\\) is the dimension of \\(\\boldsymbol{\\theta}\\). We can pick small values of \\(\\alpha\\), for instance, \\(\\alpha=0.01\\). Observe that \\[\\begin{align*} \\mathbb{E}\\left[\\frac{q(\\boldsymbol{\\theta})}{\\pi(\\boldsymbol{\\theta}|\\mathcal{M}_m)p(\\boldsymbol{y}|\\boldsymbol{\\theta}_m,\\mathcal{M}_m)}\\biggr\\rvert \\boldsymbol{y},\\mathcal{M}_m\\right]&amp;\\approx \\frac{1}{S}\\sum_{s=1}^S \\left[\\frac{q(\\boldsymbol{\\theta}^{(s)})}{\\pi(\\boldsymbol{\\theta}^{(s)}|\\mathcal{M}_m)p(\\boldsymbol{y}|\\boldsymbol{\\theta}^{(s)}_m,\\mathcal{M}_m)}\\right], \\end{align*}\\] where \\(\\boldsymbol{\\theta}^{(s)}_m\\) are draws from the posterior distribution. Observe that we can calculate the marginal likelihoods of the models in Chapters 6, 7, 8 and 9 using the Chib’s methods and the Gelfand-Dickey method. Example: Simulation exercise Let’s check the performance of the Savage-Dickey density ratio, Chib’s method and the Gelfand-Dey method to calculate the Bayes factor in a setting where we can obtain the analytical solution for the marginal likelihood. In particular, we will consider the Gaussian linear model with a conjugate prior (see Section 3.3). Assume that the data generating process is given by \\[ y_{i} = 0.7 + 0.3x_{i1} + 0.7x_{i2} - 0.2x_{i3} + 0.2x_{i4} + \\mu_i, \\] where \\(x_{i1} \\sim B(0.3)\\), \\(x_{ik} \\sim N(0,1)\\), for \\(k = 2, \\dots, 4\\), and \\(\\mu_i \\sim N(0, 1)\\), for \\(i = 1, 2, \\dots, 500\\). Let us set \\(H_0: \\beta_5 = 0\\) (model \\(\\mathcal{M}_1\\)) versus \\(H_1: \\beta_5 \\neq 0\\) (model \\(\\mathcal{M}_2\\)). We assume that \\(\\boldsymbol{\\beta}_{m0} = \\boldsymbol{0}_{m0}\\), \\(\\boldsymbol{B}_{m0} = 0.5 \\boldsymbol{I}_{m}\\), \\(\\alpha_0 = \\delta_0 = 4\\). The dimensions of \\(\\boldsymbol{0}_{m0}\\) and \\(\\boldsymbol{I}_m\\) are 4 for model \\(\\mathcal{M}_1\\) and 5 for model \\(\\mathcal{M}_2\\). In addition, we assume equal prior probabilities for both models. We know from Section 3.3 that the marginal likelihood is \\[\\begin{align*} p(\\bf{y}|\\mathcal{M}_m)&amp;=\\frac{\\delta_{m0}^{\\alpha_{m0}/2}}{\\delta_{mn}^{\\alpha_{mn}/2}}\\frac{|{\\bf{B}}_{mn}|^{1/2}}{|{\\bf{B}}_{m0}|^{1/2}}\\frac{\\Gamma(\\alpha_{mn}/2)}{\\Gamma(\\alpha_{m0}/2)}, \\end{align*}\\] where \\({{\\boldsymbol{B}}}_{mn} = ({\\boldsymbol{B}}_{m0}^{-1} + {\\boldsymbol{X}}_m^{\\top}{\\boldsymbol{X}}_m)^{-1}\\), \\(\\boldsymbol{\\beta}_{mn} = {{\\bf{B}}}_{mn}({\\boldsymbol{B}}_{m0}^{-1}\\boldsymbol{\\beta}_{m0} + {\\boldsymbol{X}}_m^{\\top}{\\boldsymbol{X}}_m\\hat{\\boldsymbol{\\beta}}_m)\\), \\(\\alpha_{mn}=\\alpha_{m0}+N\\), and \\(\\delta_{mn}=\\delta_{m0}+({\\boldsymbol{y}}-{\\boldsymbol{X}}_m\\hat{\\boldsymbol{\\beta}}_m)^{\\top}({\\boldsymbol{y}}-{\\boldsymbol{X}}_m\\hat{\\boldsymbol{\\beta}}_m)+(\\hat{\\boldsymbol{\\beta}}_m-\\boldsymbol{\\beta}_{m0})^{\\top}(({\\boldsymbol{X}_m}^{\\top}{\\boldsymbol{X}_m})^{-1}+{\\boldsymbol{B}}_{m0})^{-1}(\\hat{\\boldsymbol{\\beta}}_m-\\boldsymbol{\\beta}_{m0})\\), \\(m=1,2\\) are the indices of the models. The log marginal likelihoods for models \\(\\mathcal{M}_1\\) and \\(\\mathcal{M}_2\\) are -751.72 and -740.79, respectively. This implies a \\(2\\times\\log(BF_{21})=21.85\\) which means positive evidence against model \\(\\mathcal{M}_1\\). We have different ways to calculate the Bayes factor using the Savage-Dickey density ratio in this example because we know that the marginal prior and marginal posterior distributions of \\(\\beta_5\\) have analytical solutions. In addition, we can use the posterior draws of \\(\\sigma^2\\) to evaluate the conditional prior and conditional posterior distributions at \\(\\beta_5=0\\). We show in the following code the latter approach, as it is more general than using analytical solutions, which are not always available. We know that the conditional posterior distribution of \\(\\beta_5\\) is \\(N(\\beta_{5n}, \\sigma \\boldsymbol{B}_{55n})\\), where \\(\\beta_{5n}\\) is the 5th element of \\(\\boldsymbol{\\beta}_n\\), and \\(\\boldsymbol{B}_{55n}\\) is the element 5,5 of \\(\\boldsymbol{B}_n\\). Then, \\[\\begin{align*} \\pi(\\beta_5=0|\\boldsymbol{y}, \\mathcal{M}_2) &amp;= \\int_{\\mathcal{R}^+} \\pi(\\beta_5=0|\\boldsymbol{y}, \\sigma^2) \\pi(\\sigma^2|\\boldsymbol{y}) \\, d\\sigma^2 \\\\ &amp;\\approx \\frac{1}{S} \\sum_{s=1}^S \\pi(\\beta_5=0|\\boldsymbol{y}, \\sigma^{2(s)}), \\end{align*}\\] where \\(\\sigma^{2(s)}\\) are draws from the posterior distribution of \\(\\sigma^2\\). We can follow the same logic to obtain an approximation to \\(\\pi(\\beta_5=0|\\mathcal{M}_2)\\) by sampling draws from the prior distribution of \\(\\sigma^2\\). We obtain \\(2 \\times \\log(BF_{21}) = 21.85\\) using the Savage-Dickey density ratio, which is the same value as the analytic solution using the marginal likelihoods. We calculate the log marginal likelihood using the Chib’s method taking into account that \\[\\begin{align*} \\log(p(\\boldsymbol{y}|\\mathcal{M}_m))&amp;=\\log(p(\\boldsymbol{y}|\\boldsymbol{\\theta}^*,\\mathcal{M}_m))+\\log(\\pi(\\boldsymbol{\\theta}^*|\\mathcal{M}_m))-\\log(\\pi(\\boldsymbol{\\theta}^*|\\boldsymbol{y},\\mathcal{M}_m)),\\\\ \\end{align*}\\] where \\(p(\\boldsymbol{y}|\\boldsymbol{\\theta}^*,\\mathcal{M}_m)\\) is the value of a normal density with mean \\(\\boldsymbol{X}_m\\boldsymbol{\\beta}_{m}^*\\) and variance \\(\\sigma^{2*}_m\\boldsymbol{I}_N\\) evaluated at \\(\\boldsymbol{y}\\). In addition, \\(\\log(\\pi(\\boldsymbol{\\theta}^*|\\mathcal{M}_m))=\\log(\\pi(\\boldsymbol{\\beta}_m^*|\\sigma^{2*}_m))+\\log(\\pi(\\sigma^{2*}_m))\\), where the first term is the density of a normal with mean \\(\\boldsymbol{\\beta}_{m0}\\) and variance matrix \\(\\sigma^{2*}\\boldsymbol{B}_{m0}\\) evaluated at \\(\\boldsymbol{\\beta}_m^*\\), and the second term is the density of an inverse-gamma with parameters \\(\\alpha_{m0}/2\\) and \\(\\delta_{m0}/2\\) evaluated at \\(\\sigma^{2*}_m\\). Finally, the third term in the right hand of the previous expression is \\(\\log(\\pi(\\boldsymbol{\\theta}^*|\\boldsymbol{y},\\mathcal{M}_m))=\\log(\\pi(\\boldsymbol{\\beta}_m^*|\\sigma^{2*}_m,\\boldsymbol{y}))+\\log(\\pi(\\sigma^{2*}_m|\\boldsymbol{y}))\\), where the first term is the density of a normal with mean \\(\\boldsymbol{\\beta}_{mn}\\) and variance matrix \\(\\sigma^{2*}_m\\boldsymbol{B}_{mn}\\) evaluated at \\(\\boldsymbol{\\beta}_m^*\\), and the second term is the density of an inverse-gamma with parameters \\(\\alpha_{mn}/2\\) and \\(\\delta_{mn}/2\\) evaluated at \\(\\sigma^{2*}_m\\). We use the modes of the posterior draws of \\(\\boldsymbol{\\beta}_m\\) and \\(\\sigma^2_m\\) as reference values. We get the same value, up to two decimals, for the log marginal likelihood of the restricted and unrestricted models using the Chib’s method and the analytical expression. Thus, \\(2\\times\\log(BF_{21})=21.85\\), that is, positive evidence against model \\(\\mathcal{M}_1\\). We calculate the log marginal likelihood using the Gelfand-Dey method taking into account that \\[\\begin{align*} \\log\\left[\\frac{q(\\boldsymbol{\\theta}^{(s)})}{\\pi(\\boldsymbol{\\theta}^{(s)}|\\mathcal{M}_m)p(\\boldsymbol{y}|\\boldsymbol{\\theta}^{(s)}_m,\\mathcal{M}_m)}\\right]&amp;=\\log(q(\\boldsymbol{\\theta}^{(s)}))-\\log(\\pi(\\boldsymbol{\\theta}^{(s)}|\\mathcal{M}_m))-\\log(p(\\boldsymbol{y}|\\boldsymbol{\\theta}^{(s)}_m,\\mathcal{M}_m)), \\end{align*}\\] where \\(q(\\boldsymbol{\\theta}^{(s)})\\) is the truncated multivariate normal density of Subsection @ref(sec10_4_3) evaluated at \\(\\boldsymbol{\\theta}^{(s)}=[\\boldsymbol{\\beta}^{(s)\\top} \\ \\sigma^{2(s)}]^{\\top}\\), which is the \\(s\\)-th posterior draw of the Gibbs sampling algorithm, such that \\(\\boldsymbol{\\theta}^{(s)}\\) satisfies the truncation restriction. \\(\\log(\\pi(\\boldsymbol{\\theta}^{(s)}|\\mathcal{M}_m))=\\log(\\pi(\\boldsymbol{\\beta}_m^{(s)}|\\sigma^{2(s)}_m))+\\log(\\pi(\\sigma^{2(s)}_m))\\), where the first term is the density of a normal with mean \\(\\boldsymbol{\\beta}_{m0}\\) and variance matrix \\(\\sigma^{2(s)}\\boldsymbol{B}_{m0}\\) evaluated at \\(\\boldsymbol{\\beta}_m^{(s)}\\), and the second term is the density of an inverse-gamma with parameters \\(\\alpha_{m0}/2\\) and \\(\\delta_{m0}/2\\) evaluated at \\(\\sigma^{2(s)}_m\\). The third term \\(p(\\boldsymbol{y}|\\boldsymbol{\\theta}^{(s)},\\mathcal{M}_m)\\) is the value of a normal density with mean \\(\\boldsymbol{X}_m\\boldsymbol{\\beta}_{m}^{(s)}\\) and variance \\(\\sigma^{2(s)}_m\\boldsymbol{I}_N\\) evaluated at \\(\\boldsymbol{y}\\). The log marginal likelihoods of the restricted and unrestricted models using the Gelfand-Dey method are -751.79 and -740.89, respectively. This implies \\(2\\times \\log(BF_{21})=21.81\\), which is positive evidence in favor of the unrestricted model. We see in this example that these methods give very good approximations to the true marginal likelihoods. However, the Savage-Dickey density ratio and Chib’s method performed slightly better than the Gelfand-Dey method. In addition, the computational demand of the Gelfand-Dey method is by far the largest. This is because the Gelfand-Dey method requires many evaluations based on the posterior draws. However, we should keep in mind that the Gelfand-Dey method is more general. The following code shows how to do all these calculations. rm(list = ls()); set.seed(010101) N &lt;- 500; K &lt;- 5; K2 &lt;- 3 B &lt;- c(0.7, 0.3, 0.7, -0.2, 0.2) X1 &lt;- rbinom(N, 1, 0.3) X2 &lt;- matrix(rnorm(K2*N), N, K2) X &lt;- cbind(1, X1, X2) Y &lt;- X%*%B + rnorm(N, 0, sd = 1) # Hyperparameters d0 &lt;- 4; a0 &lt;- 4 b0 &lt;- rep(0, K); cOpt &lt;- 0.5 an &lt;- N + a0; B0 &lt;- cOpt*diag(K) Bn &lt;- solve(solve(B0)+t(X)%*%X); bhat &lt;- solve(t(X)%*%X)%*%t(X)%*%Y bn &lt;- Bn%*%(solve(B0)%*%b0+t(X)%*%X%*%bhat) dn &lt;- as.numeric(d0 + t(Y-X%*%bhat)%*%(Y-X%*%bhat)+t(bhat - b0)%*%solve(solve(t(X)%*%X)+B0)%*%(bhat - b0)) Hn &lt;- as.matrix(Matrix::forceSymmetric(dn*Bn/an)) S &lt;- 10000 LogMarLikLM &lt;- function(X, c0){ K &lt;- dim(X)[2] N &lt;- dim(X)[1] # Hyperparameters B0 &lt;- c0*diag(K) b0 &lt;- rep(0, K) # Posterior parameters bhat &lt;- solve(t(X)%*%X)%*%t(X)%*%Y # Force this matrix to be symmetric Bn &lt;- as.matrix(Matrix::forceSymmetric(solve(solve(B0) + t(X)%*%X))) bn &lt;- Bn%*%(solve(B0)%*%b0 + t(X)%*%X%*%bhat) dn &lt;- as.numeric(d0 + t(Y)%*%Y+t(b0)%*%solve(B0)%*%b0-t(bn)%*%solve(Bn)%*%bn) an &lt;- a0 + N # Log marginal likelihood logpy &lt;- (N/2)*log(1/pi)+(a0/2)*log(d0)-(an/2)*log(dn) + 0.5*log(det(Bn)/det(B0)) + lgamma(an/2)-lgamma(a0/2) return(-logpy) } LogMarM2 &lt;- -LogMarLikLM(X = X, c0 = cOpt) LogMarM1 &lt;- -LogMarLikLM(X = X[,1:4], c0 = cOpt) BF12 &lt;- exp(LogMarM1-LogMarM2) BF12; 1/BF12 ## [1] 1.79514e-05 ## [1] 55705.95 2*log(1/BF12) ## [1] 21.85568 # Savage-Dickey density ratio # Posterior evaluation Brest &lt;- 0 sig2P &lt;- invgamma::rinvgamma(S, shape = an/2, rate = dn/2) PostRestCom &lt;- mean(sapply(sig2P, function(x){dnorm(Brest, mean = bn[5], sd = (x*Bn[5,5])^0.5, log = FALSE)})) # Prior evaluation sig2 &lt;- invgamma::rinvgamma(S, shape = a0/2, rate = d0/2) PriorRestCom &lt;- mean(sapply(sig2, function(x){dnorm(Brest, mean = 0, sd = (x*cOpt)^0.5, log = FALSE)})) # Bayes factor BF12SD &lt;- PostRestCom/PriorRestCom 2*log(1/BF12SD) ## [1] 21.85275 # Chib&#39;s method sig2Post &lt;- MCMCpack::rinvgamma(S,an/2,dn/2) BetasGibbs &lt;- sapply(1:S, function(s){MASS::mvrnorm(n = 1, mu = bn, Sigma = sig2Post[s]*Bn)}) # Mode function for continuous data mode_continuous &lt;- function(x){ density_est &lt;- density(x) mode_value &lt;- density_est$x[which.max(density_est$y)] return(mode_value) } # Unrestricted model BetasMode &lt;- apply(BetasGibbs, 1, mode_continuous) Sigma2Mode &lt;- mode_continuous(sig2Post) VarModel &lt;- Sigma2Mode*diag(N) MeanModel &lt;- X%*%BetasMode LogLik &lt;- mvtnorm::dmvnorm(c(Y), mean = MeanModel, sigma = VarModel, log = TRUE, checkSymmetry = TRUE) LogPrior &lt;- mvtnorm::dmvnorm(BetasMode, mean = rep(0, K), sigma = Sigma2Mode*cOpt*diag(K), log = TRUE, checkSymmetry = TRUE)+log(MCMCpack::dinvgamma(Sigma2Mode, a0/2, d0/2)) LogPost1 &lt;- mvtnorm::dmvnorm(BetasMode, mean = bn, sigma = Sigma2Mode*Bn, log = TRUE, checkSymmetry = TRUE) LogPost2 &lt;- log(MCMCpack::dinvgamma(Sigma2Mode, an/2, dn/2)) LogMarLikChib &lt;- LogLik + LogPrior -(LogPost1 + LogPost2) # Restricted model anRest &lt;- N + a0; XRest &lt;- X[,-5] KRest &lt;- dim(XRest)[2]; B0Rest &lt;- cOpt*diag(KRest) BnRest &lt;- solve(solve(B0Rest)+t(XRest)%*%XRest) bhatRest &lt;- solve(t(XRest)%*%XRest)%*%t(XRest)%*%Y b0Rest &lt;- rep(0, KRest) bnRest &lt;- BnRest%*%(solve(B0Rest)%*%b0Rest+t(XRest)%*%XRest%*%bhatRest) dnRest &lt;- as.numeric(d0 + t(Y-XRest%*%bhatRest)%*%(Y-XRest%*%bhatRest)+t(bhatRest - b0Rest)%*%solve(solve(t(XRest)%*%XRest)+B0Rest)%*%(bhatRest - b0Rest)) sig2PostRest &lt;- MCMCpack::rinvgamma(S,anRest/2,dnRest/2) BetasGibbsRest &lt;- sapply(1:S, function(s){MASS::mvrnorm(n = 1, mu = bnRest, Sigma = sig2PostRest[s]*BnRest)}) BetasModeRest &lt;- apply(BetasGibbsRest, 1, mode_continuous) Sigma2ModeRest &lt;- mode_continuous(sig2PostRest) VarModelRest &lt;- Sigma2ModeRest*diag(N) MeanModelRest &lt;- XRest%*%BetasModeRest LogLikRest &lt;- mvtnorm::dmvnorm(c(Y), mean = MeanModelRest, sigma = VarModelRest, log = TRUE, checkSymmetry = TRUE) LogPriorRest &lt;- mvtnorm::dmvnorm(BetasModeRest, mean = rep(0, KRest), sigma = Sigma2ModeRest*cOpt*diag(KRest), log = TRUE, checkSymmetry = TRUE)+log(MCMCpack::dinvgamma(Sigma2ModeRest, a0/2, d0/2)) LogPost1Rest &lt;- mvtnorm::dmvnorm(BetasModeRest, mean = bnRest, sigma = Sigma2ModeRest*BnRest, log = TRUE, checkSymmetry = TRUE) LogPost2Rest &lt;- log(MCMCpack::dinvgamma(Sigma2ModeRest, anRest/2, dnRest/2)) LogMarLikChibRest &lt;- LogLikRest + LogPriorRest -(LogPost1Rest + LogPost2Rest) BFChibs &lt;- exp(LogMarLikChibRest-LogMarLikChib) BFChibs; 1/BFChibs; 2*log(1/BFChibs) ## [1] 1.79514e-05 ## [1] 55705.95 ## [1] 21.85568 # Gelfand-Dey method GDmarglik &lt;- function(ids, X, Betas, MeanThetas, VarThetas, sig2Post){ K &lt;- dim(X)[2]; Thetas &lt;- c(Betas[ids,], sig2Post[ids]) Lognom &lt;- (1/(1-alpha))*mvtnorm::dmvnorm(Thetas, mean = MeanThetas, sigma = VarThetas, log = TRUE, checkSymmetry = TRUE) Logden1 &lt;- mvtnorm::dmvnorm(Betas[ids,], mean = rep(0, K), sigma = sig2Post[ids]*cOpt*diag(K), log = TRUE, checkSymmetry = TRUE) + log(MCMCpack::dinvgamma(sig2Post[ids], a0/2, d0/2)) VarModel &lt;- sig2Post[ids]*diag(N) MeanModel &lt;- X%*%Betas[ids,] Logden2 &lt;- mvtnorm::dmvnorm(c(Y), mean = MeanModel, sigma = VarModel, log = TRUE, checkSymmetry = TRUE) LogGDid &lt;- Lognom - Logden1 - Logden2 return(LogGDid) } sig2Post &lt;- MCMCpack::rinvgamma(S,an/2,dn/2) Betas &lt;- LaplacesDemon::rmvt(S, bn, Hn, an) Thetas &lt;- cbind(Betas, sig2Post) MeanThetas &lt;- colMeans(Thetas); VarThetas &lt;- var(Thetas) iVarThetas &lt;- solve(VarThetas) ChiSQ &lt;- sapply(1:S, function(s){(Thetas[s,]-MeanThetas)%*%iVarThetas%*%(Thetas[s,]-MeanThetas)}) alpha &lt;- 0.01; criticalval &lt;- qchisq(1-alpha, K + 1) idGoodThetas &lt;- which(ChiSQ &lt;= criticalval) pb &lt;- winProgressBar(title = &quot;progress bar&quot;, min = 0, max = S, width = 300) InvMargLik2 &lt;- NULL for(s in idGoodThetas){ LogInvs &lt;- GDmarglik(ids = s, X = X, Betas = Betas, MeanThetas = MeanThetas, VarThetas = VarThetas, sig2Post = sig2Post) InvMargLik2 &lt;- c(InvMargLik2, LogInvs) setWinProgressBar(pb, s, title=paste( round(s/S*100, 0),&quot;% done&quot;)) } close(pb); mean(InvMargLik2) ## NULL ## [1] 740.8927 # Restricted model anRest &lt;- N + a0; XRest &lt;- X[,-5] KRest &lt;- dim(XRest)[2]; B0Rest &lt;- cOpt*diag(KRest) BnRest &lt;- solve(solve(B0Rest)+t(XRest)%*%XRest) bhatRest &lt;- solve(t(XRest)%*%XRest)%*%t(XRest)%*%Y b0Rest &lt;- rep(0, KRest) bnRest &lt;- BnRest%*%(solve(B0Rest)%*%b0Rest+t(XRest)%*%XRest%*%bhatRest) dnRest &lt;- as.numeric(d0 + t(Y-XRest%*%bhatRest)%*%(Y-XRest%*%bhatRest)+t(bhatRest - b0Rest)%*%solve(solve(t(XRest)%*%XRest)+B0Rest)%*%(bhatRest - b0Rest)) HnRest &lt;- as.matrix(Matrix::forceSymmetric(dnRest*BnRest/anRest)) sig2PostRest &lt;- MCMCpack::rinvgamma(S,anRest/2,dnRest/2) BetasRest &lt;- LaplacesDemon::rmvt(S, bnRest, HnRest, anRest) ThetasRest &lt;- cbind(BetasRest, sig2PostRest) MeanThetasRest &lt;- colMeans(ThetasRest) VarThetasRest &lt;- var(ThetasRest) iVarThetasRest &lt;- solve(VarThetasRest) ChiSQRest &lt;- sapply(1:S, function(s){(ThetasRest[s,]-MeanThetasRest)%*%iVarThetasRest%*%(ThetasRest[s,]-MeanThetasRest)}) idGoodThetasRest &lt;- which(ChiSQRest &lt;= criticalval) pb &lt;- winProgressBar(title = &quot;progress bar&quot;, min = 0, max = S, width = 300) InvMargLik1 &lt;- NULL for(s in idGoodThetasRest){ LogInvs &lt;- GDmarglik(ids = s, X = XRest, Betas = BetasRest, MeanThetas = MeanThetasRest, VarThetas = VarThetasRest, sig2Post = sig2PostRest) InvMargLik1 &lt;- c(InvMargLik1, LogInvs) setWinProgressBar(pb, s, title=paste( round(s/S*100, 0),&quot;% done&quot;)) } close(pb); summary(coda::mcmc(InvMargLik1)) ## NULL ## ## Iterations = 1:9951 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 9951 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## 7.518e+02 1.275e-01 1.278e-03 1.278e-03 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## 751.6 751.7 751.8 751.9 752.0 mean(InvMargLik1) ## [1] 751.7977 BFFD &lt;- exp(mean(InvMargLik2)-mean(InvMargLik1)) BFFD; mean(1/BFFD); 2*log(1/BFFD) ## [1] 1.836687e-05 ## [1] 54445.85 ## [1] 21.80992 References "],["sec10_5.html", "10.5 Summary", " 10.5 Summary In this chapter, we introduced Bayesian model averaging (BMA) in generalized linear models. For linear Gaussian models, we perform BMA using three approaches: the Bayesian Information Criterion (BIC) approximation with Occam’s window, the Markov Chain Monte Carlo Model Composition (MC3) algorithm, and conditional Bayes factors, which account for endogeneity. Additionally, we show how to perform dynamic Bayesian model averaging in state-space models, where forgetting parameters are used to facilitate computation. For other generalized linear models, such as logit, gamma, and Poisson, we demonstrate how to use the BIC approximation to perform BMA. Finally, we present alternative methods for calculating the marginal likelihood: the Savage-Dickey density ratio, Chib’s method, and the Gelfand-Dey method. These methods are particularly useful when the BIC approximation does not perform well due to small or moderate sample sizes. "],["sec10_6.html", "10.6 Exercises", " 10.6 Exercises The Gaussian linear model specifies \\(\\mathbf{y} = \\alpha\\boldsymbol{i}_N + \\boldsymbol{X}_m\\boldsymbol{\\beta}_m + \\boldsymbol{\\mu}_m\\) such that \\(\\boldsymbol{\\mu}_m \\sim N(\\boldsymbol{0}, \\sigma^2\\boldsymbol{I}_n)\\), and \\(\\boldsymbol{X}_m\\) does not have the column of ones. Assuming that \\(\\pi(\\sigma^2) \\propto 1/{\\sigma^2}\\), \\(\\pi(\\alpha) \\propto 1\\), and \\(\\boldsymbol{\\beta}_m | \\sigma^2 \\sim N(\\boldsymbol{0}_{k_m}, \\sigma^2 (g_m\\boldsymbol{X}_m^{\\top}\\boldsymbol{X}_m)^{-1})\\): Show that the posterior conditional distribution of \\(\\boldsymbol{\\beta}_m\\) is \\(N(\\boldsymbol{\\beta}_{mn}, \\sigma^2\\boldsymbol{B}_{mn})\\), where \\(\\boldsymbol{\\beta}_{mn} = \\boldsymbol{B}_{mn}\\boldsymbol{X}_m^{\\top}\\mathbf{y}\\) and \\(\\boldsymbol{B}_{mn} = ((1+g_m)\\boldsymbol{X}_m^{\\top}\\boldsymbol{X}_m)^{-1}\\). Show that the marginal likelihood associated with model \\(\\mathcal{M}_m\\) is proportional to \\[ p(\\mathbf{y} | \\mathcal{M}_m) \\propto \\left(\\frac{g_m}{1+g_m}\\right)^{k_m/2} \\left[(\\mathbf{y} - \\bar{y}\\boldsymbol{i}_N)^{\\top}(\\mathbf{y} - \\bar{y}\\boldsymbol{i}_N) - \\frac{1}{1+g_m}(\\mathbf{y}^{\\top}\\boldsymbol{P}_{X_m}\\mathbf{y})\\right]^{-(N-1)/2}, \\] where all parameters are indexed to model \\(\\mathcal{M}_m\\), \\(\\boldsymbol{P}_{X_m} = \\boldsymbol{X}_m(\\boldsymbol{X}_m^{\\top}\\boldsymbol{X}_m)^{-1}\\boldsymbol{X}_m\\) is the projection matrix on the space generated by the columns of \\(\\boldsymbol{X}_m\\), and \\(\\bar{y}\\) is the sample mean of \\(\\mathbf{y}\\). Hint: Take into account that \\(\\boldsymbol{i}_N^{\\top}\\boldsymbol{X}_m = \\boldsymbol{0}_{k_m}\\) due to all columns being centered with respect to their means. Determinants of export diversification I Jetter and Ramírez Hassan (2015) use BMA to study the determinants of export diversification. Use the dataset 10ExportDiversificationHHI.csv to perform BMA using the BIC approximation and MC3 to check if these two approaches agree. Simulation exercise of the Markov Chain Monte Carlo model composition Program an algorithm to perform MC3 where the final \\(S\\) models are unique. Use the simulation setting of Section 10.2 increasing the number of regressors to 40, which implies approximately \\(1.1 \\times 10^{12}\\) models. Simulation exercise of IV BMA Use the simulation setting with endogeneity in Section 10.2 to perform BMA based on the BIC approximation and MC3. Determinants of export diversification II Use the datasets 11ExportDiversificationHHI.csv and 12ExportDiversificationHHIInstr.csv to perform IV BMA assuming that the log of per capita gross domestic product is endogenous (avglgdpcap). See Jetter and Ramírez Hassan (2015) for details. Show that the link function in the case of the Bernoulli distribution is \\(\\log(\\theta / (1 - \\theta))\\). Ramı́rez-Hassan (2020), Ramı́rez-Hassan and Carvajal-Rendón (2021) perform variable selection using the file 13InternetMed.csv. In this dataset, the dependent variable is an indicator of Internet adoption (internet) for 5,000 households in Medellín (Colombia) during 2006–2014. This dataset contains 18 potential determinants, implying 262,144 (\\(2^{18}\\)) potential models. Perform BMA using the logit link function with this dataset. Serna Rodríguez, Ramírez Hassan, and Coad (2019) use 14ValueFootballPlayers.csv to analyze the market value of soccer players in Europe’s top leagues. There are 26 potential determinants of the market value of 335 soccer players. Use this dataset to perform BMA using the gamma distribution, setting default values for Occam’s window. Use the dataset 15Fertile2.csv from Jeffrey M. Wooldridge (2012) to perform BMA using the Poisson model with the log link. The dataset contains 1,781 women from Botswana in 1988. The dependent variable is the number of children ever born (ceb), modeled as a function of 19 potential determinants. Perform BMA in the logit model using MC3 and the BIC approximation using the simulation setting of Section 10.3. Use 19ExchangeRateCOPUSD.csv to perform dynmaic BMA using four state-space models explaining annual variations in the COP to USD exchange rate: Interest rate parity \\(\\Delta e_t = \\beta_{1t}^{IRP} + \\beta_{2t}^{IRP} (i_{t-1}^{Col}-i_{t-1}^{USA})+\\mu_{t}^{IRP}\\) Purchasing power parity \\(\\Delta e_t = \\beta_{1t}^{PPP} + \\beta_{2t}^{PPP} (\\pi_{t-1}^{Col}-\\pi_{t-1}^{USA})+\\mu_{t}^{PPP}\\) Taylor rule \\(\\Delta e_t = \\beta_{1t}^{Taylor} + \\beta_{2t}^{Taylor} (\\pi_{t-1}^{Col}-\\pi_{t-1}^{USA})+\\beta_{2t}^{Taylor} (g_{t-1}^{Col}-g_{t-1}^{USA})+\\mu_{t}^{IRP}\\) Money supply \\(\\Delta e_t = \\beta_{1t}^{Money} + \\beta_{2t}^{Money} (g_{t-1}^{Col}-g_{t-1}^{USA})+\\beta_{2t}^{Money} (m_{t-1}^{Col}-m_{t-1}^{USA})+\\mu_{t}^{Money}\\) where varTRM (\\(\\Delta e_t\\)) represents the annual variation rate of the exchange rate from COP to USD, TES_COL10 (\\(i_{t}^{Col}\\)) and TES_USA10 (\\(i_{t}^{USA}\\)) denote the annual return rates of Colombian and U.S. public debts over 10 years, inflation_COL (\\(\\pi_{t}^{Col}\\)) and inflation_USA (\\(\\pi_{t}^{USA}\\)) are the annual inflation rates for Colombia and the U.S., varISE_COL (\\(g_{t}^{Col}\\)) and varISE_USA (\\(g_{t}^{USA}\\)) represent the annual variations of economic activity indices, and varCOL_M3 (\\(m_{t}^{Col}\\)) and varUSA_M3 (\\(m_{t}^{USA}\\)) are the annual variations of the money supply. In addition, \\(\\mu_{t}^{\\cdot}\\) is the stochastic error. The dataset includes monthly variations from January 2006 to November 2023. Perform Bayesian model averaging using these models, calculate posterior model probabilities, and plot the posterior mean and credible interval of \\(\\beta_{2t}^{Money}\\). Perform a simulation of the dynamic logistic model, where there are 7 (\\(2^3 - 1\\), excluding the model without regressors) competing models originating from 3 regressors: \\(x_{tk} \\sim N(0.5, 0.8^2)\\), \\(k = 2, 3, 4\\), and \\(\\beta_1 = 0.5\\), \\(\\beta_{2t}\\) is a sequence from 1 to 2 in steps given by \\(1/T\\), and \\(\\beta_{3t} = \\begin{Bmatrix} -1, &amp; 1 &lt; t \\leq 0.5T \\\\ 0, &amp; 0.5T &lt; t \\leq T \\end{Bmatrix}\\), with \\(\\beta_4 = 1.2\\). Then, \\(\\boldsymbol{x}_t^{\\top} \\boldsymbol{\\beta}_t = \\beta_1 + \\beta_{2t} x_{2t} + \\beta_{3t} x_{3t} + \\beta_4 x_{4t}\\), where \\[ P[Y_t = 1 | \\boldsymbol{x}_t, \\boldsymbol{\\beta}_t] = \\frac{\\exp(\\boldsymbol{x}_t^{\\top} \\boldsymbol{\\beta}_t)}{1 + \\exp(\\boldsymbol{x}_t^{\\top} \\boldsymbol{\\beta}_t)}, \\quad t = 1, 2, \\dots, 1100. \\] Use the function logistic.dma from the dma package to obtain the posterior model probabilities, first setting the forgetting parameter of the models to 0.99, and then to 0.95. Compare the results. Show that \\[ \\mathbb{E}\\left[\\frac{q(\\boldsymbol{\\theta})}{\\pi(\\boldsymbol{\\theta} | \\mathcal{M}_m)p(\\mathbf{y} | \\boldsymbol{\\theta}_m, \\mathcal{M}_m)} \\bigg\\rvert \\mathbf{y}, \\mathcal{M}_m\\right] = \\frac{1}{p(\\mathbf{y} | \\mathcal{M}_m)}, \\] where the expected value is with respect to the posterior distribution given model \\(\\mathcal{M}_m\\), and \\(q(\\boldsymbol{\\theta})\\) is the proposal distribution whose support is \\(\\boldsymbol{\\Theta}\\). References "],["Chap11.html", "Chapter 11 Semi-parametric and non-parametric models", " Chapter 11 Semi-parametric and non-parametric models Non-parametric models are characterized by making minimal assumptions about the data-generating process. Unlike parametric models, which have a finite-dimensional parameter space, non-parametric models often involve infinite-dimensional parameter spaces. A major challenge in non-parametric modeling is the curse of dimensionality, as these models require dense data coverage, necessitating large datasets to achieve reliable estimates. Semi-parametric methods, on the other hand, combine parametric assumptions for part of the model with non-parametric assumptions for the rest. This approach offers a balance between flexibility, tractability, and applicability. In this chapter, we introduce finite Gaussian mixture models (GM) and Dirichlet mixture processes (DMP), the latter representing an infinite mixture. Both can be used to specify an entire statistical model (non-parametric specification) or to model stochastic error distributions in a semi-parametric framework. Additionally, we present non-parametric generalized additive models (GAM), where the outcome depends linearly on smooth non-parametric functions. This method mitigates the curse of dimensionality while remaining interpretable and flexible for practical applications. We let other useful Bayesian non-parametric approaches like Bayesian additive random trees (BART) and Gaussian process (GP) for Chapter 12. "],["sec11_1.html", "11.1 Mixture models", " 11.1 Mixture models Mixture models naturally arise in situations where a sample consists of draws from different subpopulations (clusters) that cannot be easily distinguished based on observable characteristics. However, performing inference on specific identified subpopulations can be misleading if the assumed distribution for each cluster is misspecified. Even when distinct subpopulations do not exist, finite and infinite mixture models provide a useful framework for semi-parametric inference. They effectively approximate distributions with skewness, excess kurtosis, and multimodality, making them useful for modeling stochastic errors. In addition, mixture models help capture unobserved heterogeneity. That is, as data modelers, we may observe individuals with identical sets of observable variables but entirely different response variables. These differences cannot be explained solely by sampling variability; rather, they suggest the presence of an unobserved underlying process, independent of the observable features, that accounts for this pattern. 11.1.1 Finite Gaussian mixtures A finite Gaussian mixture model with \\(H\\) known components assumes that a sample \\(\\boldsymbol{y}=\\left[y_1 \\ y_2 \\ \\dots \\ y_N\\right]^{\\top}\\) consists of observations \\(y_i\\), for \\(i=1,2,\\dots,N\\), where each \\(y_i\\) is generated from one of the \\(H\\) components, \\(h=1,2,\\dots,H\\), conditional on the regressors \\(\\boldsymbol{x}_i\\). Specifically, we assume \\[ y_i \\mid \\boldsymbol{x}_i \\sim N(\\boldsymbol{x}_i^{\\top}\\boldsymbol{\\beta}_h, \\sigma_h^2). \\] Thus, the sampling distribution of \\(y_i\\) is given by \\[ p(y_i \\mid \\{\\lambda_h, \\boldsymbol{\\beta}_h, \\sigma_h^2\\}_{h=1}^H, \\boldsymbol{x}_i) = \\sum_{h=1}^H \\lambda_h \\phi(y_i \\mid \\boldsymbol{x}_i^{\\top}\\boldsymbol{\\beta}_h, \\sigma_h^2), \\] where \\(\\phi(y_i \\mid \\boldsymbol{x}_i^{\\top}\\boldsymbol{\\beta}_h, \\sigma_h^2)\\) is the Gaussian density with mean \\(\\boldsymbol{x}_i^{\\top}\\boldsymbol{\\beta}_h\\) and variance \\(\\sigma_h^2\\), \\(0\\leq \\lambda_h\\leq 1\\) represents the proportion of the population belonging to subpopulation \\(h\\), and the weights satisfy \\(\\sum_{h=1}^H \\lambda_h = 1\\). Then, we allow cross-sectional units to differ according to unobserved clusters (subpopulations) that exhibit homogeneous behavior within each cluster. To model a finite Gaussian mixture, we introduce an individual cluster indicator or latent class \\(\\psi_{ih}\\) such that \\[ \\psi_{ih}= \\begin{cases} 1, &amp; \\text{if the } i\\text{-th unit is drawn from the } h\\text{-th cluster}, \\\\ 0, &amp; \\text{otherwise}. \\end{cases} \\] Thus, \\(P(\\psi_{ih}=1) = \\lambda_h\\) for all clusters \\(h=1,2,\\dots,H\\) and units \\(i=1,2,\\dots,N\\). Note that a high probability of individuals belonging to the same cluster suggests that these clusters capture similar sources of unobserved heterogeneity. This setting implies that \\[ \\boldsymbol{\\psi}_i = [\\psi_{i1} \\ \\psi_{i2} \\ \\dots \\ \\psi_{iH}]^{\\top} \\sim \\text{Categorical}(\\boldsymbol{\\lambda}), \\] where \\(\\boldsymbol{\\lambda} = [\\lambda_1 \\ \\lambda_2 \\ \\dots \\ \\lambda_H]^{\\top}\\) represents the event probabilities. We know from Chapter 4 that the Dirichlet prior distribution is conjugate to the multinomial distribution, where the categorical distribution is a special case in which the number of trials is one. Thus, we assume that \\[ \\pi(\\boldsymbol{\\lambda}) \\sim \\text{Dir}(\\boldsymbol{\\alpha}), \\] where \\(\\boldsymbol{\\alpha} = [\\alpha_1 \\ \\alpha_2 \\ \\dots \\ \\alpha_H]^{\\top}\\). Observe that we are using a hierarchical structure, as we specify a prior on \\(\\boldsymbol{\\lambda}\\), which serves as the hyperparameter for the cluster indicators. The label switching identification problem: All finite mixture models are nonidentifiable due to the distribution being unchanged if the group labels are permuted. This poses problems when performing inference in specific components of the mixtures, but it is not a concern when using the mixture to model the stochastic errors. In the former case, there are post-processing strategies to mitigate the issue, such as random permutation of latent classes (see Andrew Gelman et al. (2021) and Algorithm 3.5 in Frühwirth-Schnatter (2006)). If we do not want to fix in advance the number of clusters, we can follow the approach proposed by Andrew Gelman et al. (2021)… 11.1.2 Dirichlet processes References "],["sec11_2.html", "11.2 Non-parametric generalized additive models", " 11.2 Non-parametric generalized additive models "],["Chap12.html", "Chapter 12 Machine learning", " Chapter 12 Machine learning Machine learning approaches are characterized by high-dimensional parameter spaces that are implicit in non-parametric inference. Take into account that non-parametric inference refers to models of potentially infinite parameters, rather than absence of these ones. "],["sec12_1.html", "12.1 Cross validation and Bayes factors", " 12.1 Cross validation and Bayes factors The issue of overfitting in Bayesian inference is mitigated due to its inherent shrinkage property when proper priors are used. Remember that the posterior distribution is a compromise between the sample information and the prior information. "],["sec12_2.html", "12.2 Regularization", " 12.2 Regularization The linear normal model using the conjugate family is ridge regression (Ishwaran and Rao 2005). We can use empirical Bayes to select the scale parameter of the prior covariance matrix of the location parameters, which is in turn the regularization parameter in ridge regression (see my class notes in MSc in Data Science and Analytics). 12.2.1 Bayesian LASSO 12.2.2 Stochastic search variable selection 12.2.3 Non-local priors (Johnson and Rossell 2012) R package: mombf (Model Selection with Bayesian Methods and Information Criteria) link: https://cran.r-project.org/web/packages/mombf/index.html References "],["sec12_3.html", "12.3 Bayesian additive regression trees", " 12.3 Bayesian additive regression trees "],["sec12_4.html", "12.4 Gaussian processes", " 12.4 Gaussian processes "],["Chap13.html", "Chapter 13 Causal inference ", " Chapter 13 Causal inference "],["sec13_1.html", "13.1 Instrumental variables", " 13.1 Instrumental variables 13.1.1 Semi-parametric IV model "],["sec13_2.html", "13.2 Regression discontinuity design", " 13.2 Regression discontinuity design "],["sec13_3.html", "13.3 Regression kink design", " 13.3 Regression kink design "],["sec13_4.html", "13.4 Synthetic control", " 13.4 Synthetic control "],["sec13_5.html", "13.5 Difference in difference estimation", " 13.5 Difference in difference estimation "],["sec13_6.html", "13.6 Event Analysis", " 13.6 Event Analysis "],["sec13_7.html", "13.7 Bayesian exponential tilted empirical likelihood", " 13.7 Bayesian exponential tilted empirical likelihood Bayesian parametric approaches are often criticized on the basis that they require arbitrary distribution assumptions which often are not examined. Partial information approaches are based only on certain moment assumptions without making specific distributional assumptions. However, there are no free lunch, as these methods imply efficiency losses. The point of departure of Bayesian exponential tilted empirical likelihood (BETEL) are moment conditions that are used to build the likelihood function. "],["sec13_8.html", "13.8 Double-Debiased machine learning causal effects", " 13.8 Double-Debiased machine learning causal effects "],["Chap14.html", "Chapter 14 Approximation methods ", " Chapter 14 Approximation methods "],["sec14_1.html", "14.1 Approximate Bayesian computation", " 14.1 Approximate Bayesian computation "],["sec14_2.html", "14.2 Bayesian synthetic likelihood", " 14.2 Bayesian synthetic likelihood "],["sec14_3.html", "14.3 Expectation propagation", " 14.3 Expectation propagation "],["sec14_4.html", "14.4 Integrated nested Laplace approximations", " 14.4 Integrated nested Laplace approximations "],["sec14_5.html", "14.5 Variational Bayes", " 14.5 Variational Bayes "],["appendix.html", "Appendix", " Appendix Table 14.1: Libraries and commands in our graphical user interface. mpg cyl disp hp drat wt qsec vs Mazda RX4 21.0 6 160.0 110 3.90 2.620 16.46 0 Mazda RX4 Wag 21.0 6 160.0 110 3.90 2.875 17.02 0 Datsun 710 22.8 4 108.0 93 3.85 2.320 18.61 1 Hornet 4 Drive 21.4 6 258.0 110 3.08 3.215 19.44 1 Hornet Sportabout 18.7 8 360.0 175 3.15 3.440 17.02 0 Valiant 18.1 6 225.0 105 2.76 3.460 20.22 1 Duster 360 14.3 8 360.0 245 3.21 3.570 15.84 0 Merc 240D 24.4 4 146.7 62 3.69 3.190 20.00 1 Merc 230 22.8 4 140.8 95 3.92 3.150 22.90 1 Merc 280 19.2 6 167.6 123 3.92 3.440 18.30 1 Table 14.2: Datasets templates in folder DataSim. mpg cyl disp hp drat wt qsec vs Mazda RX4 21.0 6 160.0 110 3.90 2.620 16.46 0 Mazda RX4 Wag 21.0 6 160.0 110 3.90 2.875 17.02 0 Datsun 710 22.8 4 108.0 93 3.85 2.320 18.61 1 Hornet 4 Drive 21.4 6 258.0 110 3.08 3.215 19.44 1 Hornet Sportabout 18.7 8 360.0 175 3.15 3.440 17.02 0 Valiant 18.1 6 225.0 105 2.76 3.460 20.22 1 Duster 360 14.3 8 360.0 245 3.21 3.570 15.84 0 Merc 240D 24.4 4 146.7 62 3.69 3.190 20.00 1 Merc 230 22.8 4 140.8 95 3.92 3.150 22.90 1 Merc 280 19.2 6 167.6 123 3.92 3.440 18.30 1 Table 14.3: Real datasets in folder DataApp. mpg cyl disp hp drat wt qsec vs Mazda RX4 21.0 6 160.0 110 3.90 2.620 16.46 0 Mazda RX4 Wag 21.0 6 160.0 110 3.90 2.875 17.02 0 Datsun 710 22.8 4 108.0 93 3.85 2.320 18.61 1 Hornet 4 Drive 21.4 6 258.0 110 3.08 3.215 19.44 1 Hornet Sportabout 18.7 8 360.0 175 3.15 3.440 17.02 0 Valiant 18.1 6 225.0 105 2.76 3.460 20.22 1 Duster 360 14.3 8 360.0 245 3.21 3.570 15.84 0 Merc 240D 24.4 4 146.7 62 3.69 3.190 20.00 1 Merc 230 22.8 4 140.8 95 3.92 3.150 22.90 1 Merc 280 19.2 6 167.6 123 3.92 3.440 18.30 1 "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
