[["index.html", "Introduction to Bayesian Data Modeling A GUIded toolkit using R Introduction", " Introduction to Bayesian Data Modeling A GUIded toolkit using R Andrés Ramírez-Hassan 2025-02-16 Introduction Since the late 90s, Bayesian inference has gained significant popularity among researchers due to the computational revolution and the availability of algorithms to solve complex integrals. However, many researchers, students, and practitioners still lack a deep understanding and practical application of this inferential approach. The primary reason for this is the requirement for strong programming skills. Introduction to Bayesian Data Modeling: A GUIded Toolkit using R mainly targets those who want to apply Bayesian inference with a solid conceptual and formal understanding but may not have the time to develop programming skills. Thus, this book provides a graphical user interface (GUI) for performing Bayesian regression in a user-friendly environment. It also offers the basic theory and its code implementation using R software (R Core Team, 2021), along with applications that highlight the potential of Bayesian inference. Additionally, the book includes theoretical and computational exercises for those interested in developing more complex models. In particular, the first part presents step-by-step mathematical proofs of basic models, serving as the foundation for deriving key mathematical results in the more complex models covered in the second and third parts. Our GUI is based on an interactive web application using shiny (Chang et al., 2018), along with several packages in R. Users can estimate univariate, multivariate, time series, longitudinal/panel data, and Bayesian model averaging models using our GUI. In addition, it provides basic summaries, as well as formal and graphical diagnostics of the posterior chains. Our GUI can be run on any operating system and is freely available at GitHub. Users can access simulated and real datasets in the folders DataSim and DataApp, respectively. The DataSim folder also includes the files used to simulate different processes, providing access to population parameters. As a result, these files serve as a pedagogical tool for demonstrating various statistical properties. The DataApp folder contains the datasets used in our applications, which users are encouraged to use as templates for structuring their own datasets. This book is divided into three parts: Part One (Chapters 1–4) covers theoretical concepts, mathematical foundations, programming, and simulation. Part Two (Chapters 5–10) focuses on regression applications, with an emphasis on computational methods for obtaining posterior draws at three levels of programming skills: No programming skills required (using our GUI). Intermediate skills (using specialized R packages for Bayesian inference). Advanced skills (coding posterior draws from scratch). Part Three (Chapters 11–14) introduces advanced methods in Bayesian inference. Some mathematical derivations are presented in detail in the first part of the book, while most proofs are omitted in the second and third parts. However, the mathematical steps covered in Part One can be applied to derive results in Parts Two and Three. In the first part, Chapter 1 introduces fundamental concepts in Bayesian inference, starting with Bayes’ rule, its components, formal definitions, and basic examples. It then presents the basics of Bayesian inference within a decision-theoretic framework under uncertainty. Chapter 2 discusses the conceptual differences between Bayesian and Frequentist statistical approaches, providing both a historical and philosophical perspective on Bayesian statistics and econometrics while highlighting contrasts with the Frequentist approach. Chapter 3 introduces conjugate families in basic statistical models, solving them both analytically and computationally. Chapter 4 presents simulation-based methods, which are essential in modern Bayesian inference since most realistic models lack standard forms or analytical solutions. In the second part, Chapter 5 introduces our graphical user interface (GUI). Univariate and multivariate regression models are covered in Chapters 6 and 7. Chapter 8 focuses on univariate and multivariate time series models, while Chapter 9 covers Bayesian longitudinal/panel data models. Chapter 10 introduces Bayesian model averaging. The third part covers advanced topics: - Chapter 11 explores semi-parametric and non-parametric models. - Chapter 12 discusses causal inference. - Chapter 13 covers Bayesian methods in machine learning. - Chapter 14 describes approximation methods. About Me My name is Andrés Ramírez-Hassan, and I am an applied and theoretical econometrician working as a Distinguished Professor in the School of Finance, Economics, and Government at Universidad EAFIT (Medellín, Colombia). I hold a PhD in Statistical Science, a Master’s degree in Finance, a Master’s degree in Economics, and a Bachelor’s degree in Economics. I have been a research fellow at the Department of Econometrics and Business Statistics at Monash University and a visiting professor in the Department of Economics at the University of Melbourne and the University of Glasgow. Since completing my PhD, my research has primarily focused on Bayesian econometrics, with applications in crime, finance, health, sports, and utilities. My work has been published (or is forthcoming) in highly regarded journals, including: International Journal of Forecasting, Journal of Applied Econometrics, Econometric Reviews, Journal of Computational and Graphical Statistics, The R Journal, Economic Modelling, Spatial Economic Analysis, Economic Inquiry, World Development, Journal of Sport Economics, Empirical Economics, Australian and New Zealand Journal of Statistics, Brazilian Journal of Probability and Statistics, among other prestigious international research outlets. I founded BEsmarter — Bayesian Econometrics: simulations, models, and applications to research, teaching, and encoding with responsibility. This research group’s mission is to lead and excel in generating and disseminating Bayesian econometric knowledge through research, teaching, and software. Our vision is to advance worldwide econometric research, teaching, and applications based on the Bayesian framework, aiming to: Inspire new econometric ideas Create a user-friendly environment for Bayesian econometrics applications Transform classical econometric research, teaching, and applications Address critical social problems through scientific advancements Contact Email: aramir21@gmail.com / aramir21@eafit.edu.co Website: http://www.besmarter-team.org License This book is licensed under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. This book is licensed under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. "],["preface.html", "Preface", " Preface The main goal of this book is to make the Bayesian inferential framework more approachable to students, researchers, and practitioners who wish to understand and apply this statistical/econometric approach but do not have the time to develop programming skills. I have aimed to strike a balance between applicability and theory. This book provides a very user-friendly graphical user interface (GUI) to implement the most common regression models, while also covering the basic mathematical developments and their code implementation for those interested in advancing to more complex models. "],["to-instructors-and-students.html", "To instructors and students", " To instructors and students This book is divided into three parts: foundations (chapters 1 to 4), regression analysis (chapters 5 to 10), and Advanced methods (chapters 11 to 14). Our graphical user interface (GUI) is designed for the second part. The source code can be found at https://github.com/besmarter/BSTApp. Instructors and students can access all the code, along with simulated and real datasets. There are three ways to install our GUI: Type shiny::runGitHub(\"besmarter/BSTApp\", launch.browser=T) in the R console or any R code editor and execute it. Visit https://posit.cloud/content/4328505, log in or sign up for Posit Cloud, navigate to the BSTApp-master folder in the Files tab of the right-bottom window, then click on the app.R file and select Run App. Use a Docker image by typing in the Command Prompt: docker pull magralo95/besmartergui:latest docker run --rm -p 3838:3838 magralo95/besmartergui Then users can access our GUI by going to http://localhost:3838/. See Chapter 5 for details. Students should have a basic understanding of probability theory and statistics, as well as some background in econometrics and time series, particularly regression analysis. Familiarity with standard univariate and multivariate probability distributions is strongly recommended. See a nice summary of useful probability distributions in (Greenberg 2012). Additionally, students who wish to master the material in this book should have programming skills in R software. An excellent starting point for R programming is the R Introduction Manual. I have included both formal and computational exercises at the end of each chapter to help students gain a better understanding of the material presented. A solutions manual for these exercises accompanies this book. Instructors can use this book as a textbook for a course on introductory Bayesian Econometrics/Statistics, with a strong emphasis on implementation and applications. This book is intended to be complementary, rather than a substitute, for excellent resources on the topic, such as (Andrew Gelman et al. 2021), (Chan et al. 2019), (P. E. Rossi, Allenby, and McCulloch 2012), (Greenberg 2012), (Geweke 2005), (Lancaster 2004), and (Koop 2003). References "],["acknowledgments.html", "Acknowledgments", " Acknowledgments I began developing our graphical user interface (GUI) in 2016, after being diagnosed with cervical dystonia. I worked on this side project during weekends, which I called ``nerd weekends,’’ and it served as a form of release from my health condition. Once I began to recover, I invited Mateo Graciano, my former student, business partner, and friend, to join the project. He has been instrumental in developing our GUI, and I am enormously grateful to him. I would also like to thank the members of the BEsmarter research group at Universidad EAFIT, as well as the NUMBATs members at Monash University, for their valuable feedback and recommendations to improve our GUI. This book is an extension of the paper (Ramírez-Hassan and Graciano-Londoño 2020), which serves as a brief user guide for our GUI. I decided to write this book to explain the underlying theory and code in our GUI, and to use it as a textbook in my course on Bayesian econometrics/statistics. I am grateful to my students in this course; their insights and thoughtful questions have deepened my understanding of the material. I also thank Chris Parmeter for his suggestions on how to present our user guide, Professor Raul Pericchi and Juan Carlos Correa for introducing me to Bayesian statistics, and Liana Jacobi and Chun Fung Kwok (Jackson) from the University of Melbourne, as well as David Frazier from Monash University, for engaging talks and amazing collaborations in Bayesian econometrics/statistics. My sincere gratitude goes to Professor Peter Diggle for his unwavering support of my career, and especially to Professor Gael Martin, who gave me the opportunity to work with her, she is a constant source of intellectual inspiration. Finally, I would like to express my thanks to my colleagues and staff at Universidad EAFIT for their continuous support. To my parents, Orlando and Nancy, who have always been there for me with their unconditional support. They have taught me that the primary aspect of human spiritual evolution is humility, a lesson I am still learning every day. To my fiancée, Estephania, for her unwavering love and support. References "],["Chap1.html", "Chapter 1 Basic formal concepts", " Chapter 1 Basic formal concepts We introduce formal concepts in Bayesian inference, beginning with Bayes’ rule and its components, along with their formal definitions and basic examples. In addition, we present key features of Bayesian inference, such as Bayesian updating and asymptotic sampling properties. We also cover the basics of Bayesian inference from a decision-theoretic perspective under uncertainty, introducing important concepts like loss functions, risk functions, and optimal decision rules. "],["sec11.html", "1.1 The Bayes’ rule", " 1.1 The Bayes’ rule As expected, the starting point for performing Bayesian inference is Bayes’ rule, which provides the solution to the inverse problem of determining causes from observed effects. This rule combines prior beliefs with objective probabilities based on repeatable experiments, allowing us to move from observations to probable causes.1 Formally, the conditional probability of \\(A_i\\) given \\(B\\) is equal to the conditional probability of \\(B\\) given \\(A_i\\), multiplied by the marginal probability of \\(A_i\\), divided by the marginal probability of \\(B\\): \\[\\begin{align} P(A_i|B)&amp;=\\frac{P(A_i,B)}{P(B)}\\\\ &amp;=\\frac{P(B|A_i) \\times P(A_i)}{P(B)}, \\tag{1.1} \\end{align}\\] where equation (1.1) is Bayes’ rule. By the law of total probability, \\(P(B) = \\sum_i P(B \\mid A_i) P(A_i) \\neq 0\\), and \\(\\{ A_i, i = 1, 2, \\dots \\}\\) is a finite or countably infinite partition of the sample space. In the Bayesian framework, \\(B\\) represents sample information that updates a probabilistic statement about an unknown object \\(A_i\\) according to probability rules. This is done using Bayes’ rule, which incorporates prior “beliefs” about \\(A_i\\), i.e., \\(P(A_i)\\), sample information relating \\(B\\) to the particular state of nature \\(A_i\\) through a probabilistic statement, \\(P(B \\mid A_i)\\), and the probability of observing that specific sample information, \\(P(B)\\). Let’s consider a simple example, the base rate fallacy: Assume that the sample information comes from a positive result from a test whose true positive rate (sensitivity) is 98%, i.e., \\(P(+ \\mid \\text{disease}) = 0.98\\). On the other hand, the prior information regarding being infected with this disease comes from a base incidence rate of 0.002, i.e., \\(P(\\text{disease}) = 0.002\\). The question is: What is the probability of actually being infected, given a positive test result? This is an example of the base rate fallacy, where a positive test result for a disease with a very low base incidence rate still gives a low probability of actually having the disease. The key to answering this question lies in understanding the difference between the probability of having the disease given a positive test result, \\(P(\\text{disease} \\mid +)\\), and the probability of a positive result given the disease, \\(P(+ \\mid \\text{disease})\\). The former is the crucial result, and Bayes’ rule helps us to compute it. Using Bayes’ rule (equation (1.1)): \\[ P(\\text{disease} \\mid +) = \\frac{P(+ \\mid \\text{disease}) \\times P(\\text{disease})}{P(+)} = \\frac{0.98 \\times 0.002}{0.98 \\times 0.002 + (1-0.98) \\times (1-0.002)} = 0.09 \\] where \\(P(+) = P(+ \\mid \\text{disease}) \\times P(\\text{disease}) + P(+ \\mid \\lnot \\text{disease}) \\times P(\\lnot \\text{disease})\\).2 The following code shows how to perform this exercise in R. PD &lt;- 0.002 # Probability of disease PPD &lt;- 0.98 # True positive (Sensitivity) PDP &lt;- PD * PPD / (PD * PPD + (1 - PD)*(1 - PPD)) paste(&quot;Probability of disease given a positive test is&quot;, sep = &quot; &quot;, round(PDP, 2)) ## [1] &quot;Probability of disease given a positive test is 0.09&quot; We observe that despite having a positive result, the probability of actually having the disease remains low. This is due to the base rate being so small. Another interesting example, which lies at the heart of the origin of Bayes’ theorem (Thomas Bayes 1763), is related to the existence of God (Stigler 2018). In Section X of David Hume’s “An Inquiry concerning Human Understanding” (1748), titled Of Miracles, Hume argues that when someone claims to have seen a miracle, this provides poor evidence that the event actually occurred, as it contradicts our everyday observations. In response, Richard Price, who finished and published “An Essay Towards Solving a Problem in the Doctrine of Chances” in 1763 (after Bayes’ death in 1761), argues against Hume by highlighting the difference between impossibility in casual conversation and physical impossibility. Price used an example of a die with a million sides, where impossibility refers to rolling a specific side, and physical impossibility refers to rolling a side that does not exist. In millions of throws, the latter would never happen, while the former would eventually occur. Now, let’s consider a scenario involving two cases of resurrection (Res): Jesus Christ and Elvis. The total number of people who have ever lived is approximately 108.5 billion,3 so the prior base rate is given by \\(\\frac{2}{108.5 \\times 10^9}\\). On the other hand, suppose the sample information comes from a highly reliable witness with a true positive rate of 0.9999999. The question then is: What is the probability of this miracle occurring?4 Using Bayes’ rule: \\[\\begin{align*} P(\\text{Res}\\mid \\text{Witness}) &amp; = \\frac{P(\\text{Witness}\\mid \\text{Res})\\times P(\\text{Res})}{P(\\text{Witness})}\\\\ &amp; =\\frac{2/(108.5 * 10^9) \\times 0.9999999}{2/(108.5 * 10^9) \\times 0.9999999 + (1-2/(108.5 * 10^9)) \\times (1-0.9999999)}\\\\ &amp; = 0.000184297806959661 \\end{align*}\\] where \\(P(\\text{Witness}) = P(\\text{Witness} \\mid \\text{Res}) \\times P(\\text{Res}) + (1 - P(\\text{Witness} \\mid \\text{Res})) \\times (1 - P(\\text{Res}))\\). Thus, the probability of a resurrection, given a very reliable witness, is approximately \\(1.843 \\times 10^{-4}\\). The following code shows how to perform this exercise in R. # Probability of resurrection PR &lt;- 2/(108.5 * 10^9) PWR &lt;- 0.9999999 # True positive rate PRW &lt;- PR * PWR / (PR * PWR + (1 - PR)*(1 - PWR)) paste(&quot;Probability of resurrection given witness is&quot;, sep = &quot; &quot;, PRW) ## [1] &quot;Probability of resurrection given witness is 0.000184297806959661&quot; Observe that we can condition on multiple events in Bayes’ rule. Let’s consider two conditioning events, \\(B\\) and \\(C\\). Then, equation (1.1) becomes \\[\\begin{align} P(A_i\\mid B,C)&amp;=\\frac{P(A_i,B,C)}{P(B,C)}\\nonumber\\\\ &amp;=\\frac{P(B\\mid A_i,C) \\times P(A_i\\mid C) \\times P(C)}{P(B\\mid C)P(C)}. \\tag{1.2} \\end{align}\\] Let’s use this rule in one of the most intriguing statistical puzzles, the Monty Hall problem, to illustrate how to use equation (1.2) (Selvin 1975),(Morgan et al. 1991). This was the situation faced by a contestant in the American television game show Let’s Make a Deal. In this game, the contestant was asked to choose a door, behind one of which there is a car, and behind the others, goats. Let’s say the contestant picks door No. 1, and the host (Monty Hall), who knows what is behind each door, opens door No. 3, revealing a goat. Then, the host asks the tricky question: Do you want to pick door No. 2? Let’s define the following events: \\(P_i\\): the event contestant picks door No. \\(i\\), which stays closed, \\(H_i\\): the event host picks door No. \\(i\\), which is open and contains a goat, \\(C_i\\): the event car is behind door No. \\(i\\). In this particular setting, the contestant is interested in the probability of the event \\(P(C_2 \\mid H_3, P_1)\\). A naive answer would be that it is irrelevant, as initially, \\(P(C_i) = \\frac{1}{3}, \\ i = 1, 2, 3\\), and now \\(P(C_i \\mid H_3) = \\frac{1}{2}, \\ i = 1, 2\\), since the host opened door No. 3. So, why bother changing the initial guess if the odds are the same (1:1)? The important point here is that the host knows what is behind each door and always picks a door where there is a goat, given the contestant’s choice. In this particular setting: \\[ P(H_3 \\mid C_3, P_1) = 0, \\quad P(H_3 \\mid C_2, P_1) = 1, \\quad P(H_3 \\mid C_1, P_1) = \\frac{1}{2}. \\] Then, using equation (1.2), we can calculate the posterior probability. \\[\\begin{align*} P(C_2\\mid H_3,P_1)&amp;= \\frac{P(C_2,H_3,P_1)}{P(H_3,P_1)}\\\\ &amp;= \\frac{P(H_3\\mid C_2,P_1)P(C_2\\mid P_1)P(P_1)}{P(H_3\\mid P_1)\\times P(P_1)}\\\\ &amp;= \\frac{P(H_3\\mid C_2,P_1)P(C_2)}{P(H_3\\mid P_1)}\\\\ &amp;=\\frac{1\\times 1/3}{1/2}, \\end{align*}\\] Where the third equation uses the fact that \\(C_i\\) and \\(P_i\\) are independent events, and \\(P(H_3 \\mid P_1) = \\frac{1}{2}\\) because this depends only on \\(P_1\\) (not on \\(C_2\\)). Therefore, changing the initial decision increases the probability of getting the car from \\(\\frac{1}{3}\\) to \\(\\frac{2}{3}\\)! Thus, it is always a good idea to change the door. Let’s see a simulation exercise in R to check this answer: set.seed(0101) # Set simulation seed S &lt;- 100000 # Simulations Game &lt;- function(switch = 0){ # switch = 0 is not change # switch = 1 is to change opts &lt;- 1:3 car &lt;- sample(opts, 1) # car location guess1 &lt;- sample(opts, 1) # Initial guess if(car != guess1) { host &lt;- opts[-c(car, guess1)] } else { host &lt;- sample(opts[-c(car, guess1)], 1) } win1 &lt;- guess1 == car # Win no change guess2 &lt;- opts[-c(host, guess1)] win2 &lt;- guess2 == car # Win change if(switch == 0){ win &lt;- win1 } else { win &lt;- win2 } return(win) } #Win probabilities not changing Prob &lt;- mean(replicate(S, Game(switch = 0))) paste(&quot;Winning probabilities no changing door is&quot;, Prob, sep = &quot; &quot;) ## [1] &quot;Winning probabilities no changing door is 0.3334&quot; #Win probabilities changing Prob &lt;- mean(replicate(S, Game(switch = 1))) paste(&quot;Winning probabilities changing door is&quot;, Prob, sep = &quot; &quot;) ## [1] &quot;Winning probabilities changing door is 0.6654&quot; References "],["sec12.html", "1.2 Bayesian framework: A brief summary of theory", " 1.2 Bayesian framework: A brief summary of theory Given an unknown parameter set \\(\\boldsymbol{\\theta}\\), and a particular realization of the data \\(\\mathbf{y}\\), Bayes’ rule may be applied analogously,5 \\[\\begin{align} \\pi(\\boldsymbol{\\theta}\\mid \\mathbf{y})&amp;=\\frac{p(\\mathbf{y}\\mid \\boldsymbol{\\theta}) \\times \\pi(\\boldsymbol{\\theta})}{p(\\mathbf{y})}, \\tag{1.3} \\end{align}\\] where \\(\\pi(\\boldsymbol{\\theta}\\mid \\mathbf{y})\\) is the posterior density function, \\(\\pi(\\boldsymbol{\\theta})\\) is the prior density, \\(p(\\mathbf{y}\\mid \\boldsymbol{\\theta})\\) is the likelihood (statistical model), and \\[\\begin{equation} p(\\mathbf{y})=\\int_{\\mathbf{\\Theta}}p(\\mathbf{y}\\mid \\boldsymbol{\\theta})\\pi(\\boldsymbol{\\theta})d\\boldsymbol{\\theta}=\\mathbb{E}\\left[p(\\mathbf{y}\\mid \\boldsymbol{\\theta})\\right] \\tag{1.4} \\end{equation}\\] is the marginal likelihood or prior predictive. Observe that for this expected value to be meaningful, the prior should be a proper density, that is, it must integrate to one; otherwise, it does not make sense. Observe that \\(p(\\mathbf{y} \\mid \\boldsymbol{\\theta})\\) is not a density in \\(\\boldsymbol{\\theta}\\). In addition, \\(\\pi(\\boldsymbol{\\theta})\\) does not have to integrate to 1, that is, \\(\\pi(\\boldsymbol{\\theta})\\) can be an improper density function, \\(\\int_{\\mathbf{\\Theta}} \\pi(\\boldsymbol{\\theta}) d\\boldsymbol{\\theta} = \\infty\\). However, \\(\\pi(\\boldsymbol{\\theta} \\mid \\mathbf{y})\\) is a proper density function, that is, \\(\\int_{\\mathbf{\\Theta}} \\pi(\\boldsymbol{\\theta} \\mid \\mathbf{y}) d\\boldsymbol{\\theta} = 1\\). For instance, set \\(\\pi(\\boldsymbol{\\theta}) = c\\), where \\(c\\) is a constant, then \\(\\int_{\\mathbf{\\Theta}} c d\\boldsymbol{\\theta} = \\infty\\). However, \\[ \\int_{\\mathbf{\\Theta}} \\pi(\\boldsymbol{\\theta} \\mid \\mathbf{y}) d\\boldsymbol{\\theta} = \\int_{\\mathbf{\\Theta}} \\frac{p(\\mathbf{y} \\mid \\boldsymbol{\\theta}) \\times c}{\\int_{\\mathbf{\\Theta}} p(\\mathbf{y} \\mid \\boldsymbol{\\theta}) \\times c \\, d\\boldsymbol{\\theta}} d\\boldsymbol{\\theta} = 1 \\] where \\(c\\) cancels out. \\(\\pi(\\boldsymbol{\\theta} \\mid \\mathbf{y})\\) is a sample updated ``probabilistic belief” version of \\(\\pi(\\boldsymbol{\\theta})\\), where \\(\\pi(\\boldsymbol{\\theta})\\) is a prior probabilistic belief which can be constructed from previous empirical work, theoretical foundations, expert knowledge, and/or mathematical convenience. This prior usually depends on parameters, which are named . In addition, the Bayesian approach implies using a probabilistic model about \\(\\mathbf{Y}\\) given \\(\\boldsymbol{\\theta}\\), that is, \\(p(\\mathbf{y} \\mid \\boldsymbol{\\theta})\\), where its integral over \\(\\mathbf{\\Theta}\\), \\(p(\\mathbf{y})\\), is named due to being a measure of model fit to the data. Observe that the Bayesian inferential approach is conditional, that is, what can we learn about an unknown object \\(\\boldsymbol{\\theta}\\) given that we already observed \\(\\mathbf{ Y} =\\mathbf{y}\\)? The answer is also conditional on the probabilistic model, that is, \\(p(\\mathbf{y} \\mid \\boldsymbol{\\theta})\\). So, what if we want to compare different models, say \\(\\mathcal{M}_m\\), \\(m = \\{1,2,\\dots,M\\}\\)? Then, we should make explicit this in the Bayes’ rule formulation: \\[\\begin{align} \\pi(\\boldsymbol{\\theta}\\mid \\mathbf{y},\\mathcal{M}_m)&amp;=\\frac{p(\\mathbf{y}\\mid \\boldsymbol{\\theta},\\mathcal{M}_m) \\times \\pi(\\boldsymbol{\\theta}\\mid \\mathcal{M}_m)}{p(\\mathbf{y}\\mid \\mathcal{M}_m)}. \\tag{1.5} \\end{align}\\] The posterior model probability is \\[\\begin{align} \\pi(\\mathcal{M}_m\\mid \\mathbf{y})&amp;=\\frac{p(\\mathbf{y}\\mid \\mathcal{M}_m) \\times \\pi(\\mathcal{M}_m)}{p(\\mathbf{y})}, \\tag{1.6} \\end{align}\\] where \\(p(\\mathbf{y}\\mid \\mathcal{M}_m)=\\int_{\\mathbf{\\Theta}}p(\\mathbf{y}\\mid \\boldsymbol{\\theta},\\mathcal{M}_m) \\times \\pi(\\boldsymbol{\\theta}\\mid \\mathcal{M}_m)d\\boldsymbol{\\theta}\\) due to equation (1.5), and \\(\\pi(\\mathcal{M}_m)\\) is the prior model probability. Calculating \\(p(\\mathbf{y})\\) in equations (1.3) and (1.6) is very demanding in most of the realistic cases. Fortunately, it is not required when performing inference about \\(\\boldsymbol{\\theta}\\) as this is integrated out from it. Then, all you need to know about the shape of \\(\\boldsymbol{\\theta}\\) is in \\(p(\\mathbf{y} \\mid \\boldsymbol{\\theta}, \\mathcal{M}_m) \\times \\pi(\\boldsymbol{\\theta} \\mid \\mathcal{M}_m)\\), or without explicitly conditioning on \\(\\mathcal{M}_m\\), \\[\\begin{align} \\pi(\\boldsymbol{\\theta}\\mid \\mathbf{y})&amp; \\propto p(\\mathbf{y}\\mid \\boldsymbol{\\theta}) \\times \\pi(\\boldsymbol{\\theta}). \\tag{1.7} \\end{align}\\] Equation (1.7) is a very good shortcut to perform Bayesian inference about \\(\\boldsymbol{\\theta}\\). We can also avoid calculating \\(p(\\mathbf{y})\\) when performing model selection (hypothesis testing) using the posterior odds ratio, that is, comparing models \\(\\mathcal{M}_1\\) and \\(\\mathcal{M}_2\\), \\[\\begin{align} PO_{12}&amp;=\\frac{\\pi(\\mathcal{M}_1\\mid \\mathbf{y})}{\\pi(\\mathcal{M}_2\\mid \\mathbf{y})} \\nonumber \\\\ &amp;=\\frac{p(\\mathbf{y}\\mid \\mathcal{M}_1)}{p(\\mathbf{y}\\mid \\mathcal{M}_2)}\\times\\frac{\\pi(\\mathcal{M}_1)}{\\pi(\\mathcal{M}_2)}, \\tag{1.8} \\end{align}\\] where the first term in equation (1.8) is named the Bayes factor, and the second term is the prior odds. Observe that the Bayes factor is a ratio of ordinates for \\(\\mathbf{y}\\) under different models. Then, the Bayes factor is a measure of relative sample evidence in favor of model 1 compared to model 2. However, we still need to calculate \\(p(\\mathbf{y}\\mid \\mathcal{M}_m) = \\int_{\\mathbf{\\Theta}} p(\\mathbf{y}\\mid \\boldsymbol{\\theta}, \\mathcal{M}_m) \\pi(\\boldsymbol{\\theta}\\mid \\mathcal{M}_m) d\\boldsymbol{\\theta} = \\mathbb{E}\\left[ p(\\mathbf{y}\\mid \\boldsymbol{\\theta}, \\mathcal{M}_m) \\right]\\). For this integral to be meaningful, the prior must be proper. Using an improper prior has unintended consequences when comparing models; for instance, parsimonious models are favored by posterior odds or Bayes factors, and these values may depend on units of measure (see Chapter 3). A nice feature of comparing models using posterior odds is that if we have an exhaustive set of competing models such that \\(\\sum_{m=1}^M \\pi(\\mathcal{M}_m \\mid \\mathbf{y}) = 1\\), then we can recover \\(\\pi(\\mathcal{M}_m \\mid \\mathbf{y})\\) without calculating \\(p(\\mathbf{y})\\). In particular, given two models \\(\\mathcal{M}_1\\) and \\(\\mathcal{M}_2\\) such that \\(\\pi(\\mathcal{M}_1 \\mid \\mathbf{y}) + \\pi(\\mathcal{M}_2 \\mid \\mathbf{y}) = 1\\), we have: \\[ \\pi(\\mathcal{M}_1 \\mid \\mathbf{y}) = \\frac{PO_{12}}{1 + PO_{12}} \\quad \\text{and} \\quad \\pi(\\mathcal{M}_2 \\mid \\mathbf{y}) = 1 - \\pi(\\mathcal{M}_1 \\mid \\mathbf{y}). \\] In general, \\[ \\pi(\\mathcal{M}_m \\mid \\mathbf{y}) = \\frac{p(\\mathbf{y} \\mid \\mathcal{M}_m) \\times \\pi(\\mathcal{M}_m)}{\\sum_{l=1}^M p(\\mathbf{y} \\mid \\mathcal{M}_l) \\times \\pi(\\mathcal{M}_l)}. \\] These posterior model probabilities can be used to perform Bayesian model averaging. Table 1.1 shows guidelines for the interpretation of \\(2\\log(PO_{12})\\) (R. E. Kass and Raftery 1995). This transformation is done to replicate the structure of the likelihood ratio test statistic. However, posterior odds do not require nested models as the likelihood ratio test does. Table 1.1: Kass and Raftery guidelines \\(2\\log(PO_{12})\\) \\(PO_{12}\\) Evidence against \\(\\mathcal{M}_{2}\\) 0 to 2 1 to 3 Not worth more than a bare mention 2 to 6 3 to 20 Positive 6 to 10 20 to 150 Strong &gt; 10 &gt; 150 Very strong Observe that the posterior odds ratio is a relative criterion, that is, we specify an exhaustive set of competing models and compare them. However, we may want to check the performance of a model on its own or use a non-informative prior. In this case, we can use the posterior predictive p-value (A. Gelman and Meng 1996),(A. Gelman, Meng, and Stern 1996).6 The intuition behind the predictive p-value is simple: analyze the discrepancy between the model’s assumptions and the data by checking a potential extreme tail-area probability. Observe that this approach does not check if a model is true; its focus is on potential discrepancies between the model and the data at hand. This is done by simulating pseudo-data from our sampling model (\\(\\mathbf{y}^{(s)}, s=1,2,\\dots,S\\)) using draws from the posterior distribution, and then calculating a discrepancy measure, \\(D(\\mathbf{y}^{(s)},\\boldsymbol{\\theta})\\), to estimate the posterior predictive p-value, \\[ p_D(\\mathbf{y}) = P[D(\\mathbf{y}^{(s)},\\boldsymbol{\\theta}) \\geq D(\\mathbf{y},\\boldsymbol{\\theta})], \\] using the proportion of the \\(S\\) draws for which \\(D(\\mathbf{y}^{(s)},\\boldsymbol{\\theta}^{(s)}) \\geq D(\\mathbf{y},\\boldsymbol{\\theta}^{(s)})\\). Extreme tail probabilities (\\(p_D(\\mathbf{y}) \\leq 0.05\\) or \\(p_D(\\mathbf{y}) \\geq 0.95\\)) suggest potential discrepancies between the data and the model. A. Gelman, Meng, and Stern (1996) also suggests the posterior predictive p-value based on the minimum discrepancy, \\[ D_{\\min}(\\mathbf{y}) = \\min_{\\boldsymbol{\\theta}} D(\\mathbf{y}, \\boldsymbol{\\theta}), \\] and the average discrepancy statistic \\[ D(\\mathbf{y}) = \\mathbb{E}[D(\\mathbf{y}, \\boldsymbol{\\theta})] = \\int_{\\mathbf{\\Theta}} D(\\mathbf{y}, \\boldsymbol{\\theta}) \\pi(\\boldsymbol{\\theta} \\mid \\mathbf{y}) d\\boldsymbol{\\theta}. \\] These alternatives can be more computationally demanding. The Bayesian approach is also suitable to get probabilistic predictions, that is, we can obtain a posterior predictive density \\[\\begin{align} \\pi(\\mathbf{y}_0\\mid \\mathbf{y},\\mathcal{M}_m) &amp; =\\int_{\\mathbf{\\Theta}}\\pi(\\mathbf{y}_0,\\boldsymbol{\\theta}\\mid \\mathbf{y},\\mathcal{M}_m)d\\boldsymbol{\\theta}\\nonumber\\\\ &amp;=\\int_{\\mathbf{\\Theta}}\\pi(\\mathbf{y}_0\\mid \\boldsymbol{\\theta},\\mathbf{y},\\mathcal{M}_m)\\pi(\\boldsymbol{\\theta}\\mid \\mathbf{y},\\mathcal{M}_m)d\\boldsymbol{\\theta}. \\tag{1.9} \\end{align}\\] Observe that equation (1.9) is again an expectation \\(\\mathbb{E}[\\pi(\\mathbf{y}_0 \\mid \\boldsymbol{\\theta}, \\mathbf{y}, \\mathcal{M}_m)]\\), this time using the posterior distribution. Therefore, the Bayesian approach takes estimation error into account when performing prediction. As we have shown many times, expectation (integration) is a common feature in Bayesian inference. That is why the remarkable relevance of computation based on Monte Carlo integration in the Bayesian framework (see Chapter 4). Bayesian model averaging (BMA) allows for considering model uncertainty in prediction or any unknown probabilistic object. In the case of the predictive density, \\[\\begin{align} \\pi(\\mathbf{y}_0\\mid \\mathbf{y})&amp;=\\sum_{m=1}^M \\pi(\\mathcal{M}_m\\mid \\mathbf{y})\\pi(\\mathbf{y}_0\\mid \\mathbf{y},\\mathcal{M}_m). \\end{align}\\] In the case of the posterior density of the parameters, \\[\\begin{align} \\pi(\\boldsymbol{\\theta}\\mid \\mathbf{y})&amp;=\\sum_{m=1}^M \\pi(\\mathcal{M}_m\\mid \\mathbf{y})\\pi(\\boldsymbol{\\theta}\\mid \\mathbf{y},\\mathcal{M}_m), \\end{align}\\] where \\[\\begin{align} \\mathbb{E}(\\boldsymbol{\\theta}\\mid \\mathbf{y})=\\sum_{m=1}^{M}\\hat{\\boldsymbol{\\theta}}_m \\pi(\\mathcal{M}_m\\mid \\mathbf{y}), \\tag{1.10} \\end{align}\\] and \\[\\begin{align} Var({\\theta}_k\\mid \\mathbf{y})= \\sum_{m=1}^{M}\\pi(\\mathcal{M}_m\\mid \\mathbf{y}) \\widehat{Var} ({\\theta}_{km}\\mid \\mathbf{y},\\mathcal{M}_m)+\\sum_{m=1}^{M} \\pi(\\mathcal{M}_m\\mid \\mathbf{y}) (\\hat{{\\theta}}_{km}-\\mathbb{E}[{\\theta}_{km}\\mid \\mathbf{y}])^2, \\tag{1.11} \\end{align}\\] \\(\\hat{\\boldsymbol{\\theta}}_m\\) is the posterior mean and \\(\\widehat{Var}({\\theta}_{km}\\mid \\mathbf{y},\\mathcal{M}_m)\\) is the posterior variance of the \\(k\\)-th element of \\(\\boldsymbol{\\theta}\\) under model \\(\\mathcal{M}_m\\). Observe how the variance in equation (1.11) captures the extra variability due to potential differences between the mean posterior estimates associated with each model, and the posterior mean that incorporates model uncertainty in equation (1.10). A significant advantage of the Bayesian approach, which is particularly useful in (see Chapter 6), is the way the posterior distribution updates with new sample information. Given \\(\\mathbf{y} = \\mathbf{y}_{1:t+1}\\) as a sequence of observations from 1 to \\(t+1\\), then \\[\\begin{align} \\pi(\\boldsymbol{\\theta}\\mid \\mathbf{y}_{1:t+1})&amp;\\propto p(\\mathbf{y}_{1:t+1}\\mid \\boldsymbol{\\theta})\\times \\pi(\\boldsymbol{\\theta})\\nonumber\\\\ &amp;= p(y_{t+1}\\mid \\mathbf{y}_{1:t},\\boldsymbol{\\theta})\\times p(\\mathbf{y}_{1:t}\\mid \\boldsymbol{\\theta})\\times \\pi(\\boldsymbol{\\theta})\\nonumber\\\\ &amp;\\propto p(y_{t+1}\\mid \\mathbf{y}_{1:t},\\boldsymbol{\\theta})\\times \\pi(\\boldsymbol{\\theta}\\mid \\mathbf{y}_{1:t}). \\tag{1.12} \\end{align}\\] We observe in Equation (1.12) that the new prior is simply the posterior distribution based on the previous observations. This is particularly useful under the assumption of conditional independence, that is, \\(Y_{t+1} \\perp \\mathbf{Y}_{1:t} \\mid \\boldsymbol{\\theta}\\), so that \\(p(y_{t+1} \\mid \\mathbf{y}_{1:t}, \\boldsymbol{\\theta}) = p(y_{t+1} \\mid \\boldsymbol{\\theta})\\), allowing the posterior to be recovered recursively (Petris, Petrone, and Campagnoli 2009). This facilitates online updating because all information up to time \\(t\\) is captured in \\(\\boldsymbol{\\theta}\\). Therefore, \\(\\pi(\\boldsymbol{\\theta} \\mid \\mathbf{y}_{1:t+1}) \\propto p(y_{t+1} \\mid \\boldsymbol{\\theta}) \\times \\pi(\\boldsymbol{\\theta} \\mid \\mathbf{y}_{1:t}) \\propto \\prod_{h=1}^{t+1} p(y_h \\mid \\boldsymbol{\\theta}) \\times \\pi(\\boldsymbol{\\theta})\\). This recursive expression can be computed more efficiently at any specific point in time \\(t\\), compared to a batch-mode algorithm, which requires processing all information up to time \\(t\\) simultaneously. It is also important to consider the sampling properties of “Bayesian estimators”. This topic has attracted the attention of statisticians and econometricians for a long time. For instance, asymptotic posterior concentration on the population parameter vector is discussed by (Bickel and Yahav 1969). The convergence of posterior distributions is stated by the Bernstein-von Mises theorem (Lehmann and Casella 2003),(Van der Vaart 2000), which establishes a link between credible intervals (sets) and confidence intervals (sets), where a credible interval is an interval in the domain of the posterior distribution within which an unknown parameter falls with a particular probability. Credible intervals treat bounds as fixed and parameters as random, whereas confidence intervals reverse this. There are many settings in parametric models where Bayesian credible intervals with an \\(\\alpha\\) level converge asymptotically to confidence intervals at the \\(\\alpha\\) level. This suggests that Bayesian inference is asymptotically correct from a sampling perspective in these settings. A heuristic approach to demonstrate this in the simplest case, where we assume random sampling and \\(\\theta \\in \\mathcal{R}\\), is the following: \\(p(\\mathbf{y} \\mid \\theta) = \\prod_{i=1}^N p(y_i \\mid \\theta)\\), so the log likelihood is \\(l(\\mathbf{y} \\mid \\theta) \\equiv \\log p(\\mathbf{y} \\mid \\theta) = \\sum_{i=1}^N \\log p(y_i \\mid \\theta) = N \\times \\bar{l}(\\mathbf{y} \\mid \\theta)\\), where \\(\\bar{l} \\equiv \\frac{1}{N} \\sum_{i=1}^N \\log p(y_i \\mid \\theta)\\) is the mean likelihood.7 Then, the posterior distribution is proportional to \\[\\begin{align} \\pi(\\theta\\mid \\mathbf{y})&amp;\\propto p(\\mathbf{y}\\mid \\theta) \\times \\pi(\\theta)\\nonumber\\\\ &amp;=\\exp\\left\\{N\\times \\bar{l}(\\mathbf{y}\\mid \\theta)\\right\\} \\times \\pi(\\theta). \\end{align}\\] Observe that as the sample size increases, that is, as \\(N \\to \\infty\\), the exponential term should dominate the prior distribution as long as the prior does not depend on \\(N\\), such that the likelihood determines the posterior distribution asymptotically. Maximum likelihood theory shows that \\(\\lim_{N \\to \\infty} \\bar{l}(\\mathbf{y} \\mid \\theta) \\to \\bar{l}(\\mathbf{y} \\mid \\theta_0)\\), where \\(\\theta_0\\) is the population parameter of the data-generating process. In addition, performing a second-order Taylor expansion of the log likelihood at the maximum likelihood estimator, \\[\\begin{align*} l(\\mathbf{y}\\mid \\theta)&amp;\\approx l(\\mathbf{y}\\mid \\hat{\\theta})+\\left.\\frac{dl(\\mathbf{y}\\mid {\\theta})}{d\\theta}\\right\\vert_{\\hat{\\theta}}(\\theta-\\hat{\\theta})+\\frac{1}{2}\\left.\\frac{d^2l(\\mathbf{y}\\mid {\\theta})}{d\\theta^2}\\right\\vert_{\\hat{\\theta}}(\\theta-\\hat{\\theta})^2\\\\ &amp;= l(\\mathbf{y}\\mid \\hat{\\theta})+\\frac{1}{2}\\left.\\sum_{i=1}^N\\frac{d^2l(y_i\\mid {\\theta})}{d\\theta^2}\\right\\vert_{\\hat{\\theta}}(\\theta-\\hat{\\theta})^2\\\\ &amp;= l(\\mathbf{y}\\mid \\hat{\\theta})-\\frac{1}{2}\\left.N\\left[-\\bar{l}&#39;&#39;\\right\\vert_{\\hat{\\theta}}\\right](\\theta-\\hat{\\theta})^2\\\\ &amp;= l(\\mathbf{y}\\mid \\hat{\\theta})-\\frac{N}{2\\sigma^2}(\\theta-\\hat{\\theta})^2 \\end{align*}\\] where \\(\\left.\\frac{dl(\\mathbf{y}\\mid \\theta)}{d\\theta}\\right\\vert_{\\hat{\\theta}}=0\\), \\(\\bar{l}&#39;&#39;\\equiv\\frac{1}{N}\\left.\\sum_{i=1}^N\\frac{d^2l(y_i\\mid {\\theta})}{d\\theta^2}\\right\\vert_{\\hat{\\theta}}\\) and \\(\\sigma^2:=\\left[\\left.-\\bar{l}&#39;&#39;\\right\\vert_{\\hat{\\theta}}\\right]^{-1}\\).8 Then, \\[\\begin{align*} \\pi(\\theta\\mid \\mathbf{y})&amp;\\propto \\exp\\left\\{{l}(\\mathbf{y}\\mid \\theta)\\right\\} \\times \\pi(\\theta)\\\\ &amp;\\approx \\exp\\left\\{l(\\mathbf{y}\\mid \\hat{\\theta})-\\frac{N}{2\\sigma^2}(\\theta-\\hat{\\theta})^2\\right\\} \\times \\pi(\\theta)\\\\ &amp;\\propto \\exp\\left\\{-\\frac{N}{2\\sigma^2}(\\theta-\\hat{\\theta})^2\\right\\} \\times \\pi(\\theta)\\\\ \\end{align*}\\] Observe that the posterior density is proportional to the kernel of a normal density with mean \\(\\hat{\\theta}\\) and variance \\(\\sigma^2 / N\\), as long as \\(\\pi(\\hat{\\theta}) \\neq 0\\). This kernel dominates as the sample size increases due to the \\(N\\) in the exponential term. It is also important to note that the prior should not exclude values of \\(\\theta\\) that are logically possible, such as \\(\\hat{\\theta}\\). Example: Health insurance Suppose that you are analyzing whether to buy health insurance next year. To make a better decision, you want to know what the probability is that you will visit your doctor at least once next year? To answer this question, you have records of the number of times you have visited your doctor over the last 5 years, \\(\\mathbf{y} = \\{0, 3, 2, 1, 0\\}\\). How should you proceed? Assuming that this is a random sample9 from a data-generating process (statistical model) that is Poisson, i.e., \\(Y_i \\sim P(\\lambda)\\), and your probabilistic prior beliefs about \\(\\lambda\\) are well described by a Gamma distribution with shape and scale parameters \\(\\alpha_0\\) and \\(\\beta_0\\), i.e., \\(\\lambda \\sim G(\\alpha_0, \\beta_0)\\), then you are interested in calculating the probability \\(P(Y_0 &gt; 0 \\mid \\mathbf{y})\\). To answer this, you need to calculate the posterior predictive density \\(\\pi(y_0 \\mid \\mathbf{y})\\) in a Bayesian way. In this example, \\(p(\\mathbf{y} \\mid \\lambda)\\) is Poisson, and \\(\\pi(\\lambda)\\) is Gamma. Therefore, using Equation (1.9). \\[\\begin{align*} \\pi(y_0\\mid \\mathbf{y})=&amp;\\int_{0}^{\\infty}\\frac{\\lambda^{y_0}\\exp\\left\\{-\\lambda\\right\\}}{y_0!}\\times \\pi(\\lambda\\mid \\mathbf{y})d\\lambda,\\\\ \\end{align*}\\] where the posterior distribution is \\[ \\pi(\\lambda\\mid \\mathbf{y})\\propto \\lambda^{\\sum_{i=1}^N y_i + \\alpha_0 - 1}\\exp\\left\\{-\\lambda\\left(\\frac{\\beta_0 N+1}{\\beta_0}\\right)\\right\\} \\] by Equation (1.3). Observe that the last expression is the kernel of a Gamma distribution with parameters \\(\\alpha_n = \\sum_{i=1}^N y_i + \\alpha_0\\) and \\(\\beta_n = \\frac{\\beta_0}{\\beta_0 N + 1}\\). Given that \\(\\int_0^{\\infty} \\pi(\\lambda \\mid \\mathbf{y}) d\\lambda = 1\\), the constant of proportionality in the last expression is \\(\\Gamma(\\alpha_n) \\beta_n^{\\alpha_n}\\), where \\(\\Gamma(\\cdot)\\) is the Gamma function. Thus, the posterior density function \\(\\pi(\\lambda \\mid \\mathbf{y})\\) is \\(G(\\alpha_n, \\beta_n)\\). Observe that \\[\\begin{align*} \\mathbb{E}[\\lambda\\mid \\mathbf{y}]&amp;=\\alpha_n\\beta_n\\\\ &amp;=\\left(\\sum_{i=1}^N y_i + \\alpha_0\\right)\\left(\\frac{\\beta_0}{\\beta_0 N + 1}\\right)\\\\ &amp;=\\bar{y}\\left(\\frac{N\\beta_0}{N\\beta_0+1}\\right)+\\alpha_0\\beta_0\\left(\\frac{1}{N\\beta_0+1}\\right)\\\\ &amp;=w\\bar{y}+(1-w)\\mathbb{E}[\\lambda], \\end{align*}\\] where \\(\\bar{y}\\) is the sample mean estimate, which is the maximum likelihood estimate of \\(\\lambda\\) in this example, \\(w = \\left(\\frac{N\\beta_0}{N\\beta_0 + 1}\\right)\\), and \\(\\mathbb{E}[\\lambda] = \\alpha_0 \\beta_0\\) is the prior mean. The posterior mean is a weighted average of the maximum likelihood estimator (sample information) and the prior mean. Observe that \\(\\lim_{N \\to \\infty} w = 1\\), that is, the sample information asymptotically dominates. The predictive distribution is \\[\\begin{align*} \\pi(y_0\\mid \\mathbf{y})=&amp;\\int_{0}^{\\infty}\\frac{\\lambda^{y_0}\\exp\\left\\{-\\lambda\\right\\}}{y_0!}\\times \\frac{1}{\\Gamma(\\alpha_n)\\beta_n^{\\alpha_n}}\\lambda^{\\alpha_n-1}\\exp\\left\\{-\\lambda/\\beta_n\\right\\} d\\lambda\\\\ =&amp;\\frac{1}{y_0!\\Gamma(\\alpha_n)\\beta_n^{\\alpha_n}}\\int_{0}^{\\infty}\\lambda^{y_0+\\alpha_n-1}\\exp\\left\\{-\\lambda\\left(\\frac{1+\\beta_n}{\\beta_n}\\right)\\right\\}d\\lambda\\\\ =&amp;\\frac{\\Gamma(y_0+\\alpha_n)\\left(\\frac{\\beta_n}{\\beta_n+1}\\right)^{y_0+\\alpha_n}}{y_0!\\Gamma(\\alpha_n)\\beta_n^{\\alpha_n}}\\\\ =&amp;{y_0+\\alpha_n-1 \\choose y_0}\\left(\\frac{\\beta_n}{\\beta_n+1}\\right)^{y_0}\\left(\\frac{1}{\\beta_n+1}\\right)^{\\alpha_n}. \\end{align*}\\] The third equality follows from the kernel of a Gamma density, and the fourth from \\[ {y_0 + \\alpha_n - 1 \\choose y_0} = \\frac{(y_0 + \\alpha_n - 1)(y_0 + \\alpha_n - 2)\\dots\\alpha_n}{y_0!} = \\frac{\\Gamma(y_0 + \\alpha_n)}{\\Gamma(\\alpha_n) y_0!} \\] using a property of the Gamma function. Observe that this is a Negative Binomial density, that is, \\(Y_0 \\mid \\mathbf{y} \\sim \\text{NB}(\\alpha_n, p_n)\\) where \\(p_n = \\frac{\\beta_n}{\\beta_n + 1}\\). Up to this point, we have said nothing about the hyperparameters, which are required to give a concrete response to this exercise. Thus, we show two approaches to set them. First, we set \\(\\alpha_0 = 0.001\\) and \\(\\beta_0 = \\frac{1}{0.001}\\), which imply vague prior information about \\(\\lambda\\) due to having a large degree of variability compared to the mean information.10 In particular, \\(\\mathbb{E}[\\lambda] = 1\\) and \\(\\mathbb{V}ar[\\lambda] = 1000\\). In this setting, \\(P(Y_0 &gt; 0 \\mid \\mathbf{y}) = 1 - P(Y_0 = 0 \\mid \\mathbf{y}) \\approx 0.67\\). That is, the probability of visiting the doctor at least once next year is approximately 0.67. Another approach is using Empirical Bayes, where we set the hyperparameters maximizing the logarithm of the marginal likelihood,11 that is, \\[ \\left[\\hat{\\alpha}_0 \\ \\hat{\\beta}_0\\right]^{\\top} = \\underset{\\alpha_0, \\beta_0}{\\mathrm{argmax}} \\ \\ln p(\\mathbf{y}) \\] where \\[ \\begin{align} p(\\mathbf{y}) &amp;= \\int_0^{\\infty} \\left\\{ \\frac{1}{\\Gamma(\\alpha_0)\\beta_0^{\\alpha_0}} \\lambda^{\\alpha_0 - 1} \\exp\\left\\{-\\lambda / \\beta_0\\right\\} \\prod_{i=1}^N \\frac{\\lambda^{y_i} \\exp\\left\\{-\\lambda\\right\\}}{ y_i!} \\right\\} d\\lambda \\\\ &amp;= \\frac{\\int_0^{\\infty} \\lambda^{\\sum_{i=1}^N y_i + \\alpha_0 - 1} \\exp\\left\\{-\\lambda \\left( \\frac{\\beta_0 N + 1}{\\beta_0} \\right) \\right\\} d\\lambda}{ \\Gamma(\\alpha_0) \\beta_0^{\\alpha_0} \\prod_{i=1}^N y_i! } \\\\ &amp;= \\frac{\\Gamma\\left(\\sum_{i=1}^N y_i + \\alpha_0\\right) \\left( \\frac{\\beta_0}{N\\beta_0 + 1} \\right)^{\\sum_{i=1}^N y_i} \\left( \\frac{1}{N\\beta_0 + 1} \\right)^{\\alpha_0}}{ \\Gamma(\\alpha_0) \\prod_{i=1}^N y_i } \\end{align} \\] Using the empirical Bayes approach, we get \\(\\hat{\\alpha}_0 = 51.8\\) and \\(\\hat{\\beta}_0 = 0.023\\), then \\(P(Y_0 &gt; 0 \\mid \\mathbf{y}) = 1 - P(Y_0 = 0 \\mid \\mathbf{y}) \\approx 0.70\\). Observe that we can calculate the posterior odds comparing the model using an Empirical Bayes prior (model 1) versus the vague prior (model 2). We assume that \\(\\pi(\\mathcal{M}_1) = \\pi(\\mathcal{M}_2) = 0.5\\), then \\[ \\begin{align} PO_{12} &amp;= \\frac{p(\\mathbf{y} \\mid \\text{Empirical Bayes})}{ p(\\mathbf{y} \\mid \\text{Vague prior}) } \\\\ &amp;= \\frac{\\frac{\\Gamma\\left(\\sum_{i=1}^N y_i + 51.807\\right) \\left( \\frac{0.023}{N \\times 0.023 + 1} \\right)^{\\sum_{i=1}^N y_i} \\left( \\frac{1}{N \\times 0.023 + 1} \\right)^{51.807}}{\\Gamma(51.807)}}{\\frac{\\Gamma\\left(\\sum_{i=1}^N y_i + 0.001\\right) \\left( \\frac{1/0.001}{N/0.001 + 1} \\right)^{\\sum_{i=1}^N y_i} \\left( \\frac{1}{N/0.001 + 1} \\right)^{0.001}}{\\Gamma(0.001)}} \\\\ &amp;\\approx 919 \\end{align} \\] Then, \\(2 \\times \\log(PO_{12}) = 13.64\\), which provides very strong evidence against the vague prior model (see Table 1.1). In particular, \\(\\pi(\\text{Empirical Bayes} \\mid \\mathbf{y}) = \\frac{919}{1 + 919} = 0.999\\) and \\(\\pi(\\text{Vague prior} \\mid \\mathbf{y}) = 1 - 0.999 = 0.001\\). These probabilities can be used to perform Bayesian model averaging (BMA). In particular, \\[ \\begin{align} \\mathbb{E}(\\lambda \\mid \\mathbf{y}) &amp;= 1.2 \\times 0.999 + 1.2 \\times 0.001 = 1.2 \\\\ \\text{Var}(\\lambda \\mid \\mathbf{y}) &amp;= 0.025 \\times 0.999 + 0.24 \\times 0.001 \\\\ &amp;+ (1.2 - 1.2)^2 \\times 0.999 + (1.2 - 1.2)^2 \\times 0.001 = 0.025 \\end{align} \\] The BMA predictive distribution is a mix of negative binomial distributions, that is, \\[ Y_0 \\mid \\mathbf{y} \\sim 0.999 \\times \\text{NB}(57.8, 0.02) + 0.001 \\times \\text{NB}(6.001, 0.17) \\] The following code shows how to perform this exercise in R. set.seed(010101) y &lt;- c(0, 3, 2, 1, 0) # Data N &lt;- length(y) ProbBo &lt;- function(y, a0, b0){ N &lt;- length(y) #sample size an &lt;- a0 + sum(y) # Posterior shape parameter bn &lt;- b0 / ((b0 * N) + 1) # Posterior scale parameter p &lt;- bn / (bn + 1) # Probability negative binomial density Pr &lt;- 1 - pnbinom(0, size=an,prob=(1 - p)) # Probability of visiting the Doctor at least once next year # Observe that in R there is a slightly different parametrization. return(Pr) } # Using a vague prior: a0 &lt;- 0.001 # Prior shape parameter b0 &lt;- 1 / 0.001 # Prior scale parameter PriMeanV &lt;- a0 * b0 # Prior mean PriVarV &lt;- a0 * b0^2 # Prior variance Pp &lt;- ProbBo(y, a0 = 0.001, b0 = 1 / 0.001) # This setting is vague prior information. Pp ## [1] 0.6650961 # Using Empirical Bayes LogMgLik &lt;- function(theta, y){ N &lt;- length(y) #sample size a0 &lt;- theta[1] # prior shape hyperparameter b0 &lt;- theta[2] # prior scale hyperparameter an &lt;- sum(y) + a0 # posterior shape parameter if(a0 &lt;= 0 || b0 &lt;= 0){ #Avoiding negative values lnp &lt;- -Inf }else{ lnp &lt;- lgamma(an) + sum(y)*log(b0/(N*b0+1)) - a0*log(N*b0+1) - lgamma(a0) } # log marginal likelihood return(-lnp) } theta0 &lt;- c(0.01, 1/0.1) # Initial values control &lt;- list(maxit = 1000) # Number of iterations in optimization EmpBay &lt;- optim(theta0, LogMgLik, method = &quot;BFGS&quot;, control = control, hessian = TRUE, y = y) # Optimization EmpBay$convergence ## [1] 0 a0EB &lt;- EmpBay$par[1] # Prior shape using empirical Bayes a0EB ## [1] 51.80696 b0EB &lt;- EmpBay$par[2] # Prior scale using empirical Bayes b0EB ## [1] 0.02318341 PriMeanEB &lt;- a0EB * b0EB # Prior mean PriVarEB &lt;- a0EB * b0EB^2 # Prior variance PpEB &lt;- ProbBo(y, a0 = a0EB, b0 = b0EB) # This setting is using emprical Bayes. PpEB ## [1] 0.6953668 # Density figures: # This code helps plotting densities lambda &lt;- seq(0.01, 10, 0.01) # Values of lambda VaguePrior &lt;- dgamma(lambda,shape=a0,scale = b0) EBPrior &lt;- dgamma(lambda,shape=a0EB,scale = b0EB) PosteriorV &lt;- dgamma(lambda, shape = a0 + sum(y), scale = b0 / ((b0 * N) + 1)) PosteriorEB &lt;- dgamma(lambda, shape = a0EB+sum(y), scale = b0EB / ((b0EB * N) + 1)) # Likelihood function Likelihood &lt;- function(theta, y){ LogL &lt;- dpois(y, theta, log = TRUE) Lik &lt;- prod(exp(LogL)) return(Lik) } Liks &lt;- sapply(lambda, function(par) {Likelihood(par, y = y)}) Sc &lt;- max(PosteriorEB)/max(Liks) #Scale for displaying in figure LiksScale &lt;- Liks * Sc data &lt;- data.frame(cbind(lambda, VaguePrior, EBPrior, PosteriorV, PosteriorEB, LiksScale)) #Data frame require(ggplot2) # Cool figures ## Loading required package: ggplot2 ## Warning: package &#39;ggplot2&#39; was built under R version 4.3.3 require(latex2exp) # LaTeX equations in figures ## Loading required package: latex2exp require(ggpubr) # Multiple figures in one page ## Loading required package: ggpubr fig1 &lt;- ggplot(data = data, aes(lambda, VaguePrior)) + geom_line() + xlab(TeX(&quot;$\\\\lambda$&quot;)) + ylab(&quot;Density&quot;) + ggtitle(&quot;Prior: Vague Gamma&quot;) fig2 &lt;- ggplot(data = data, aes(lambda, EBPrior)) + geom_line() + xlab(TeX(&quot;$\\\\lambda$&quot;)) + ylab(&quot;Density&quot;) + ggtitle(&quot;Prior: Empirical Bayes Gamma&quot;) fig3 &lt;- ggplot(data = data, aes(lambda, PosteriorV)) + geom_line() + xlab(TeX(&quot;$\\\\lambda$&quot;)) + ylab(&quot;Density&quot;) + ggtitle(&quot;Posterior: Vague Gamma&quot;) fig4 &lt;- ggplot(data = data, aes(lambda, PosteriorEB)) + geom_line() + xlab(TeX(&quot;$\\\\lambda$&quot;)) + ylab(&quot;Density&quot;) + ggtitle(&quot;Posterior: Empirical Bayes Gamma&quot;) FIG &lt;- ggarrange(fig1, fig2, fig3, fig4, ncol = 2, nrow = 2) annotate_figure(FIG, top = text_grob(&quot;Vague versus Empirical Bayes: Poisson-Gamma model&quot;, color = &quot;black&quot;, face = &quot;bold&quot;, size = 14)) dataNew &lt;- data.frame(cbind(rep(lambda, 3), c(EBPrior, PosteriorEB, LiksScale), rep(1:3, each = 1000))) #Data frame colnames(dataNew) &lt;- c(&quot;Lambda&quot;, &quot;Density&quot;, &quot;Factor&quot;) dataNew$Factor &lt;- factor(dataNew$Factor, levels=c(&quot;1&quot;, &quot;3&quot;, &quot;2&quot;), labels=c(&quot;Prior&quot;, &quot;Likelihood&quot;, &quot;Posterior&quot;)) ggplot(data = dataNew, aes_string(x = &quot;Lambda&quot;, y = &quot;Density&quot;, group = &quot;Factor&quot;)) + geom_line(aes(color = Factor)) + xlab(TeX(&quot;$\\\\lambda$&quot;)) + ylab(&quot;Density&quot;) + ggtitle(&quot;Prior, likelihood and posterior: Empirical Bayes Poisson-Gamma model&quot;) + guides(color=guide_legend(title=&quot;Information&quot;)) + scale_color_manual(values = c(&quot;red&quot;, &quot;yellow&quot;, &quot;blue&quot;)) ## Warning: `aes_string()` was deprecated in ggplot2 3.0.0. ## ℹ Please use tidy evaluation idioms with `aes()`. ## ℹ See also `vignette(&quot;ggplot2-in-packages&quot;)` for more information. ## This warning is displayed once every 8 hours. ## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was ## generated. The first figure displays the prior and posterior densities based on vague and Empirical Bayes hyperparameters. We observe that the prior and posterior densities using the latter are more informative, as expected. The second figure shows the prior, scaled likelihood, and posterior densities of \\(\\lambda\\) based on the hyperparameters from the Empirical Bayes approach. The posterior density is a compromise between prior and sample information. # Predictive distributions PredDen &lt;- function(y, y0, a0, b0){ N &lt;- length(y) #sample size an &lt;- a0 + sum(y) # Posterior shape parameter bn &lt;- b0 / ((b0 * N) + 1) # Posterior scale parameter p &lt;- bn / (bn + 1) # Probability negative binomial density Pr &lt;- dnbinom(y0, size=an, prob=(1 - p)) # Predictive density # Observe that in R there is a slightly different parametrization. return(Pr) } y0 &lt;- 0:10 PredVague &lt;- PredDen(y=y, y0=y0, a0=a0, b0=b0) PredEB &lt;- PredDen(y=y, y0=y0, a0=a0EB, b0=b0EB) dataPred &lt;- as.data.frame(cbind(y0, PredVague, PredEB)) colnames(dataPred) &lt;- c(&quot;y0&quot;, &quot;PredictiveVague&quot;, &quot;PredictiveEB&quot;) ggplot(data = dataPred) + geom_point(aes(y0, PredictiveVague, color = &quot;red&quot;)) + xlab(TeX(&quot;$y_0$&quot;)) + ylab(&quot;Density&quot;) + ggtitle(&quot;Predictive density: Vague and Empirical Bayes priors&quot;) + geom_point(aes(y0, PredictiveEB, color = &quot;yellow&quot;)) + guides(color = guide_legend(title=&quot;Prior&quot;)) + scale_color_manual(labels = c(&quot;Vague&quot;, &quot;Empirical Bayes&quot;), values = c(&quot;red&quot;, &quot;yellow&quot;)) + scale_x_continuous(breaks=seq(0,10,by=1)) This figure displays the predictive probability mass of not having any visits to a physician next year, as well as having one, two, and so on, using Empirical Bayes and vague hyperparameters. The predictive probabilities of not having any visits are approximately 30% and 33% based on the Empirical Bayes and vague hyperparameters, respectively. # Posterior odds: Vague vs Empirical Bayes PO12 &lt;- exp(-LogMgLik(c(a0EB, b0EB), y = y))/exp(-LogMgLik(c(a0, b0), y = y)) PO12 ## [1] 919.0069 PostProMEM &lt;- PO12/(1 + PO12) PostProMEM ## [1] 0.9989131 # Posterior model probability Empirical Bayes PostProbMV &lt;- 1 - PostProMEM PostProbMV ## [1] 0.001086948 # Posterior model probability vague prior # Bayesian model average (BMA) PostMeanEB &lt;- (a0EB + sum(y)) * (b0EB / (b0EB * N + 1)) # Posterior mean Empirical Bayes PostMeanV &lt;- (a0 + sum(y)) * (b0 / (b0 * N + 1)) # Posterior mean vague priors BMAmean &lt;- PostProMEM * PostMeanEB + PostProbMV * PostMeanV BMAmean ## [1] 1.200951 # BMA posterior mean PostVarEB &lt;- (a0EB + sum(y)) * (b0EB/(b0EB * N + 1))^2 # Posterior variance Empirical Bayes PostVarV &lt;- (a0 + sum(y)) * (b0 / (b0 * N + 1))^2 # Posterior variance vague prior BMAVar &lt;- PostProMEM * PostVarEB + PostProbMV*PostVarV + PostProMEM * (PostMeanEB - BMAmean)^2 + PostProbMV * (PostMeanV - BMAmean)^2 # BMA posterior variance BMAVar ## [1] 0.02518372 # BMA: Predictive BMAPred &lt;- PostProMEM * PredEB+PostProbMV * PredVague dataPredBMA &lt;- as.data.frame(cbind(y0, BMAPred)) colnames(dataPredBMA) &lt;- c(&quot;y0&quot;, &quot;PredictiveBMA&quot;) ggplot(data = dataPredBMA) + geom_point(aes(y0, PredictiveBMA, color = &quot;red&quot;)) + xlab(TeX(&quot;$y_0$&quot;)) + ylab(&quot;Density&quot;) + ggtitle(&quot;Predictive density: BMA&quot;) + guides(color = guide_legend(title=&quot;BMA&quot;)) + scale_color_manual(labels = c(&quot;Probability&quot;), values = c(&quot;red&quot;)) + scale_x_continuous(breaks=seq(0,10,by=1)) The first figure displays the predictive density using Bayesian model averaging based on the vague and Empirical Bayes hyperparameters. This figure closely resembles the predictive probability mass function based on the Empirical Bayes framework, as the posterior model probability for that setting is nearly one. The second figure shows how the posterior distribution updates with new sample information, starting from an initial non-informative prior (iteration 1). We observe that iteration 5 incorporates all the sample information in our example. As a result, the posterior density in iteration 5 is identical to the posterior density. References "],["sec14.html", "1.3 Bayesian reports: Decision theory under uncertainty", " 1.3 Bayesian reports: Decision theory under uncertainty The Bayesian framework allows reporting the full posterior distributions. However, some situations require reporting a specific value of the posterior distribution (point estimate), an informative interval (set), point or interval predictions, and/or selecting a specific model. Decision theory offers an elegant framework to make decisions regarding the optimal posterior values to report (J. O. Berger 2013). The starting point is a loss function, which is a non-negative real-valued function whose arguments are the unknown state of nature (\\(\\mathbf{\\Theta}\\)), and a set of actions to be taken (\\(\\mathcal{A}\\)), that is, \\[\\begin{equation*} L(\\mathbf{\\theta}, a):\\mathbf{\\Theta}\\times \\mathcal{A}\\rightarrow \\mathcal{R}^+. \\end{equation*}\\] This function is a mathematical representation of the loss incurred from making mistakes. In particular, selecting action \\(a\\in\\mathcal{A}\\) when \\(\\mathbf{\\theta}\\in\\mathbf{\\Theta}\\) is the true state. In our case, the unknown state of nature can refer to parameters, functions of them, future or unknown realizations, models, etc. From a Bayesian perspective, we should choose the action that minimizes the posterior expected loss (\\(a^*(\\mathbf{y})\\)), that is, the posterior risk function (\\(\\mathbb{E}[L(\\mathbf{\\theta}, a)\\mid \\mathbf{y}]\\)), \\[\\begin{equation*} a^*(\\mathbf{y})=\\underset{a \\in \\mathcal{A}}{\\mathrm{argmin}} \\ \\mathbb{E}[L(\\mathbf{\\theta}, a)\\mid \\mathbf{y}], \\end{equation*}\\] where \\(\\mathbb{E}[L(\\mathbf{\\theta}, a)\\mid \\mathbf{y}] = \\int_{\\mathbf{\\Theta}} L(\\mathbf{\\theta}, a)\\pi(\\mathbf{\\theta}\\mid \\mathbf{y})d\\mathbf{\\theta}\\).12 Different loss functions imply different optimal decisions. We illustrate this assuming \\(\\theta \\in \\mathcal{R}\\). The quadratic loss function, \\(L(\\theta,a)=[\\theta-a]^2\\), gives as the optimal decision the posterior mean, \\(a^*(\\mathbf{y})=\\mathbb{E}[\\theta \\mid \\mathbf{y}]\\), that is: \\[\\begin{equation*} \\mathbb{E}[\\theta \\mid \\mathbf{y}] = \\underset{a \\in \\mathcal{A}}{\\mathrm{argmin}} \\ \\int_{\\Theta} [\\theta - a]^2 \\pi(\\theta \\mid \\mathbf{y}) \\, d\\theta. \\end{equation*}\\] To obtain this result, let’s use the first-order condition, differentiate the risk function with respect to \\(a\\), interchange the differential and integral order, and set the result equal to zero: \\[ -2 \\int_{\\Theta} [\\theta - a^*] \\pi(\\theta \\mid \\mathbf{y}) \\, d\\theta = 0. \\] This implies that \\[ a^* \\int_{\\Theta} \\pi(\\theta \\mid \\mathbf{y}) \\, d\\theta = a^*(\\mathbf{y}) = \\int_{\\Theta} \\theta \\pi(\\theta \\mid \\mathbf{y}) \\, d\\theta = \\mathbb{E}[\\theta \\mid \\mathbf{y}], \\] that is, the posterior mean is the Bayesian optimal action. This means that we should report the posterior mean as a point estimate of \\(\\theta\\) when facing the quadratic loss function. The generalized quadratic loss function, \\(L(\\theta,a) = w(\\theta) [\\theta - a]^2\\), where \\(w(\\theta) &gt; 0\\) is a weighting function, gives as the optimal decision rule the weighted mean. We should follow the same steps as the previous result to obtain \\[ a^*(\\mathbf{y}) = \\frac{\\mathbb{E}[w(\\theta) \\times \\theta \\mid \\mathbf{y}]}{\\mathbb{E}[w(\\theta) \\mid \\mathbf{y}]}. \\] Observe that the weighted average is driven by the weighting function \\(w(\\theta)\\). The absolute error loss function, \\(L(\\theta,a) = |\\theta - a|\\), gives as the optimal action the posterior median (Exercise 5). The generalized absolute error function, \\[ L(\\theta,a) = \\begin{cases} K_0 (\\theta - a), &amp; \\text{if } \\theta - a \\geq 0, \\\\ K_1 (a - \\theta), &amp; \\text{if } \\theta - a &lt; 0, \\end{cases} \\quad K_0, K_1 &gt; 0, \\] implies the following risk function: \\[\\begin{align*} \\mathbb{E}[L(\\theta, a) \\mid \\mathbf{y}] &amp;= \\int_{-\\infty}^{a} K_1(a - \\theta) \\pi(\\theta \\mid \\mathbf{y}) \\, d\\theta + \\int_{a}^{\\infty} K_0 (\\theta - a) \\pi(\\theta \\mid \\mathbf{y}) \\, d\\theta. \\end{align*}\\] Differentiating with respect to \\(a\\), interchanging differentials and integrals, and equating to zero, we get: \\[\\begin{align*} K_1 \\int_{-\\infty}^{a^*} \\pi(\\theta \\mid \\mathbf{y}) \\, d\\theta - K_0 \\int_{a^*}^{\\infty} \\pi(\\theta \\mid \\mathbf{y}) \\, d\\theta &amp;= 0. \\end{align*}\\] Thus, we have \\[ \\int_{-\\infty}^{a^*} \\pi(\\theta \\mid \\mathbf{y}) \\, d\\theta = \\frac{K_0}{K_0 + K_1}, \\] that is, any \\(\\frac{K_0}{K_0 + K_1}\\)-percentile of \\(\\pi(\\theta \\mid \\mathbf{y})\\) is an optimal Bayesian estimate of \\(\\theta\\). We can also use decision theory under uncertainty in hypothesis testing. In particular, testing \\(H_0: \\theta \\in \\Theta_0\\) versus \\(H_1: \\theta \\in \\Theta_1\\), where \\(\\Theta = \\Theta_0 \\cup \\Theta_1\\) and \\(\\emptyset = \\Theta_0 \\cap \\Theta_1\\), there are two actions of interest, \\(a_0\\) and \\(a_1\\), where \\(a_j\\) denotes not rejecting \\(H_j\\), for \\(j = \\{0,1\\}\\). Given the \\(0-K_j\\) loss function: \\[\\begin{equation*} L(\\theta,a_j) = \\begin{cases} 0, &amp; \\text{if } \\theta \\in \\Theta_j, \\\\ K_j, &amp; \\text{if } \\theta \\in \\Theta_i, j \\neq i, \\end{cases} \\end{equation*}\\] where there is no loss if the right decision is made, for instance, not rejecting \\(H_0\\) when \\(\\theta \\in \\Theta_0\\), and the loss is \\(K_j\\) when an error is made. For example, a type I error occurs when rejecting the null hypothesis (\\(H_0\\)) when it is true (\\(\\theta \\in \\Theta_0\\)), which results in a loss of \\(K_1\\) due to choosing action \\(a_1\\), not rejecting \\(H_1\\). The posterior expected loss associated with decision \\(a_j\\), i.e., not rejecting \\(H_j\\), is: \\[ \\mathbb{E}[L(\\theta,a_j) \\mid \\mathbf{y}] = 0 \\times P(\\Theta_j \\mid \\mathbf{y}) + K_j P(\\Theta_i \\mid \\mathbf{y}) = K_j P(\\Theta_i \\mid \\mathbf{y}), \\quad j \\neq i. \\] Therefore, the Bayes optimal decision is the one that minimizes the posterior expected loss. That is, the null hypothesis is rejected (\\(a_1\\) is not rejected) when \\[ K_0 P(\\Theta_1 \\mid \\mathbf{y}) &gt; K_1 P(\\Theta_0 \\mid \\mathbf{y}). \\] Given our framework, \\(\\Theta = \\Theta_0 \\cup \\Theta_1\\) and \\(\\emptyset = \\Theta_0 \\cap \\Theta_1\\), we have \\(P(\\Theta_0 \\mid \\mathbf{y}) = 1 - P(\\Theta_1 \\mid \\mathbf{y})\\). As a result, the rejection region of the Bayesian test is: \\[ R = \\left\\{ \\mathbf{y} : P(\\Theta_1 \\mid \\mathbf{y}) &gt; \\frac{K_1}{K_1 + K_0} \\right\\}. \\] Decision theory also helps to construct interval (region) estimates. Let \\(\\Theta_{C(\\mathbf{y})} \\subset \\Theta\\) be a credible set for \\(\\theta\\), and let the loss function be defined as: \\[ L(\\theta, \\Theta_{C(\\mathbf{y})}) = 1 - \\mathbf{1}\\left\\{\\theta \\in \\Theta_{C(\\mathbf{y})}\\right\\}, \\] where \\[ \\mathbf{1}\\left\\{\\theta \\in \\Theta_{C(\\mathbf{y})}\\right\\} = \\begin{cases} 1, &amp; \\text{if } \\theta \\in \\Theta_{C(\\mathbf{y})}, \\\\ 0, &amp; \\text{if } \\theta \\notin \\Theta_{C(\\mathbf{y})}. \\end{cases} \\] Thus, the loss function becomes: \\[ L(\\theta, \\Theta_{C(\\mathbf{y})}) = \\begin{cases} 0, &amp; \\text{if } \\theta \\in \\Theta_{C(\\mathbf{y})}, \\\\ 1, &amp; \\text{if } \\theta \\notin \\Theta_{C(\\mathbf{y})}. \\end{cases} \\] This is a 0-1 loss function, which equals zero when \\(\\theta \\in \\Theta_{C(\\mathbf{y})}\\) and equals one when \\(\\theta \\notin \\Theta_{C(\\mathbf{y})}\\). Consequently, the risk function is: \\[ 1 - P(\\theta \\in \\Theta_{C(\\mathbf{y})}). \\] Given a measure of credibility \\(\\alpha(\\mathbf{y})\\) that defines the level of trust that \\(\\theta \\in \\Theta_{C(\\mathbf{y})}\\), we can measure the accuracy of the report by the loss function: \\[ L(\\theta, \\alpha(\\mathbf{y})) = \\left[\\mathbf{1}\\left\\{\\theta \\in \\Theta_{C(\\mathbf{y})}\\right\\} - \\alpha(\\mathbf{y})\\right]^2. \\] This loss function could be used to suggest a choice of the report \\(\\alpha(\\mathbf{y})\\). Given that this is a quadratic loss function, the optimal action is the posterior mean, that is, \\[ \\mathbb{E}[\\mathbf{1}\\left\\{\\theta \\in \\Theta_{C(\\mathbf{y})}\\right\\} \\mid \\mathbf{y}] = P(\\theta \\in \\Theta_{C(\\mathbf{y})} \\mid \\mathbf{y}). \\] This probability can be calculated given the posterior distribution as \\[ P(\\theta \\in \\Theta_{C(\\mathbf{y})} \\mid \\mathbf{y}) = \\int_{\\Theta_{C(\\mathbf{y})}} \\pi(\\theta \\mid \\mathbf{y}) \\, d\\theta. \\] This represents a measure of the belief that \\(\\theta \\in \\Theta_{C(\\mathbf{y})}\\) given the prior beliefs and sample information. The set \\(\\Theta_{C(\\mathbf{y})} \\subset \\Theta\\) is a \\(100(1 - \\alpha)\\%\\) credible set with respect to \\(\\pi(\\theta \\mid \\mathbf{y})\\) if \\[ P(\\theta \\in \\Theta_{C(\\mathbf{y})} \\mid \\mathbf{y}) = \\int_{\\Theta_{C(\\mathbf{y})}} \\pi(\\theta \\mid \\mathbf{y}) \\, d\\theta = 1 - \\alpha. \\] Two alternatives for reporting credible sets are the symmetric credible set and the highest posterior density set (HPD). The former is based on the \\(\\frac{\\alpha}{2}\\%\\) and \\((1 - \\frac{\\alpha}{2})\\%\\) percentiles of the posterior distribution, and the latter is a \\(100(1 - \\alpha)\\%\\) credible interval for \\(\\theta\\) with the property that it has the smallest distance compared to any other \\(100(1 - \\alpha)\\%\\) credible interval for \\(\\theta\\) based on the posterior distribution. Specifically, \\[ C(\\mathbf{y}) = \\left\\{ \\theta : \\pi(\\theta \\mid \\mathbf{y}) \\geq k(\\alpha) \\right\\}, \\] where \\(k(\\alpha)\\) is the largest number such that \\[ \\int_{\\theta : \\pi(\\theta \\mid \\mathbf{y}) \\geq k(\\alpha)} \\pi(\\theta \\mid \\mathbf{y}) d\\theta = 1 - \\alpha. \\] The HPD set can be a collection of disjoint intervals when working with multimodal posterior densities. Additionally, HPD sets have the limitation of not necessarily being invariant under transformations. Decision theory can also be used to perform prediction (point, sets, or probabilistic). Suppose that there is a loss function \\(L(Y_0, a)\\) involving the prediction of \\(Y_0\\). Then, the expected loss is \\[ \\mathbb{E}_{Y_0}[L(Y_0, a)] = \\int_{\\mathcal{Y}_0} L(y_0, a) \\pi(y_0 \\mid \\mathbf{y}) \\, dy_0, \\] where \\(\\pi(y_0 \\mid \\mathbf{y})\\) is the predictive density function. Thus, we make an optimal choice for prediction that minimizes the risk function given a specific loss function. Although Bayesian Model Averaging (BMA) allows for incorporating model uncertainty in a regression framework, sometimes it is desirable to select just one model. A compelling alternative is to choose the model with the highest posterior model probability. This model is the best alternative for prediction in the case of a 0-1 loss function (Clyde and George 2004). Example: Health insurance continues We show some optimal rules in the health insurance example, specifically the best point estimates of \\(\\lambda\\) under the quadratic, absolute, and generalized absolute loss functions. For the generalized absolute loss function, we assume that underestimating \\(\\lambda\\) is twice as costly as overestimating it, i.e., \\(K_0 = 2\\) and \\(K_1 = 1\\). Given that the posterior distribution of \\(\\lambda\\) is \\(G(\\alpha_0 + \\sum_{i=1}^N y_i, \\frac{\\beta_0}{\\beta_0 N + 1})\\), and using the hyperparameters from empirical Bayes, we obtain the following optimal point estimates: The posterior mean: \\(\\mathbb{E}[\\lambda \\mid \\mathbf{y}] = \\alpha_n \\beta_n = 1.2\\), The posterior median: 1.19, The 2/3-th quantile: 1.26. These are the optimal point estimates for the quadratic, absolute, and generalized absolute loss functions, respectively. In addition, we test the null hypothesis \\(H_0: \\lambda \\in [0, 1)\\) versus the alternative hypothesis \\(H_1: \\lambda \\in [1, \\infty)\\), setting \\(K_0 = K_1 = 1\\). We should reject the null hypothesis since \\(P(\\lambda \\in [0, 1)) = 0.9 &gt; \\frac{K_1}{K_0 + K_1} = 0.5\\). The 95% symmetric credible interval is \\((0.91, 1.53)\\), and the highest posterior density (HPD) interval is \\((0.90, 1.51)\\). Finally, the optimal point prediction under the quadratic loss function is 1.2, which is the mean value of the posterior predictive distribution. The optimal model, assuming a 0-1 loss function, is the model using the hyperparameters from the empirical Bayes procedure, since the posterior model probability of this model is approximately 1, whereas the posterior model probability of the model using vague hyperparameters is approximately 0. an &lt;- sum(y) + a0EB # Posterior shape parameter bn &lt;- b0EB / (N*b0EB + 1) # Posterior scale parameter S &lt;- 1000000 # Number of posterior draws Draws &lt;- rgamma(1000000, shape = an, scale = bn) # Posterior draws ###### Point estimation ######## OptQua &lt;- an*bn # Mean: Optimal choice quadratic loss function OptQua ## [1] 1.200952 OptAbs &lt;- qgamma(0.5, shape = an, scale = bn) # Median: Optimal choice absolute loss function OptAbs ## [1] 1.194034 # Setting K0 = 2 and K1 = 1, that is, to underestimate lambda is twice as costly as to overestimate it. K0 &lt;- 2; K1 &lt;- 1 OptGenAbs &lt;- quantile(Draws, K0/(K0 + K1)) # Median: Optimal choice generalized absolute loss function OptGenAbs ## 66.66667% ## 1.263182 ###### Hypothesis test ######## # H0: lambda in [0,1) vs H1: lambda in [1, Inf] K0 &lt;- 1; K1 &lt;- 1 ProbH0 &lt;- pgamma(1, shape = an, scale = bn) ProbH0 # Posterior probability H0 ## [1] 0.09569011 ProbH1 &lt;- 1 -ProbH0 ProbH1 # Posterior probability H1 ## [1] 0.9043099 # We should reject H0 given ProbH1 &gt; K1 / (K0 + K1) ###### Credible intervals ######## LimInf &lt;- qgamma(0.025, shape = an, scale = bn) # Lower bound LimInf ## [1] 0.9114851 LimSup &lt;- qgamma(0.975, shape = an, scale = bn) # Upper bound LimSup ## [1] 1.529724 HDI &lt;- HDInterval::hdi(Draws, credMass = 0.95) # Highest posterior density credible interval HDI ## lower upper ## 0.9007934 1.5163109 ## attr(,&quot;credMass&quot;) ## [1] 0.95 ###### Predictive optimal choices ######## p &lt;- bn / (bn + 1) # Probability negative binomial density OptPred &lt;- p/(1-p)*an # Optimal point prediction given a quadratic loss function in prediction OptPred ## [1] 1.200952 References "],["summary.html", "1.4 Summary", " 1.4 Summary We introduce Bayes’ rule to update probabilistic statements using humorous examples. We then study the three key probabilistic objects in Bayesian inference: the posterior distribution, the marginal likelihood, and the predictive density. The posterior distribution allows for inference regarding parameters, the marginal likelihood is required for hypothesis testing and model selection using the Bayes factor, and the predictive density enables probabilistic predictions. We also review some sampling properties of Bayesian estimators and the process of Bayes updating. All of these concepts were illustrated using a simple example in R software. Finally, we introduce decision theory concepts that can be applied to report summary statistics while minimizing posterior expected losses. "],["exercises.html", "1.5 Exercises", " 1.5 Exercises The Court Case: The Blue or Green Cab A cab was involved in a hit-and-run accident at night. There are two cab companies in the town: Blue and Green. The former has 150 cabs, and the latter has 850 cabs. A witness stated that a blue cab was involved in the accident; the court tested the reliability of the witness under similar circumstances and found that 80% of the time the witness correctly identified the color of the cab. What is the probability that the color of the cab involved in the accident was blue, given that the witness said it was blue? The Monty Hall Problem What is the probability of winning a car in the Monty Hall problem if you switch your decision, when there are four doors, three goats, and one car? Solve this problem both analytically and computationally. What if there are \\(n\\) doors, \\(n-1\\) goats, and one car? Solve the health insurance example using a Gamma prior in the rate parametrization, that is, \\(\\pi(\\lambda) = \\frac{\\beta_0^{\\alpha_0}}{\\Gamma(\\alpha_0)} \\lambda^{\\alpha_0 - 1} \\exp\\left\\{-\\lambda \\beta_0\\right\\}\\). Suppose you are analyzing the decision to buy car insurance for the next year. To make a better decision, you want to know: What is the probability that you will have a car claim next year? You have the records of your car claims over the last 15 years, \\(\\mathbf{y} = \\left\\{ 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0 \\right\\}\\). Assume that this is a random sample from a data-generating process (statistical model) that is Bernoulli, \\(Y_i \\sim \\text{Ber}(p)\\). Your prior beliefs about \\(p\\) are well described by a Beta distribution with parameters \\(\\alpha_0\\) and \\(\\beta_0\\), i.e., \\(p \\sim B(\\alpha_0, \\beta_0)\\). You are interested in calculating the probability of a claim the next year, \\(P(Y_0 = 1 \\mid \\mathbf{y})\\). Solve this using both an empirical Bayes approach and a non-informative approach where \\(\\alpha_0 = \\beta_0 = 1\\) (uniform distribution). Show that, given the loss function \\(L(\\theta, a) = |\\theta - a|\\), the optimal decision rule minimizing the risk function, \\(a^*(\\mathbf{y})\\), is the median. "],["Chap2.html", "Chapter 2 Conceptual differences between the Bayesian and Frequentist approaches", " Chapter 2 Conceptual differences between the Bayesian and Frequentist approaches We outline some of the conceptual differences between the Bayesian and Frequentist inferential approaches. We emphasize Bayesian concepts, as most readers may already be familiar with the Frequentist statistical framework. We illustrate the differences between these two inferential approaches using a simple example. In addition, we provide some potential explanations for why the Bayesian inferential framework is not well known at the introductory level among practitioners and applied researchers. "],["sec21.html", "2.1 The concept of probability", " 2.1 The concept of probability Let’s begin with the following thought experiment: Assume that you are watching the international game show “Who Wants to Be a Millionaire?”. The contestant is asked to answer a very simple question: What is the last name of the brothers who are credited with inventing the world’s first successful motor-operated airplane? What is the probability that the contestant answers this question correctly? Unless you have: watched this particular contestant participate in this show many times, seen him asked this same question each time, and computed the relative frequency with which he gives the correct answer, you need to answer this question as a Bayesian! Uncertainty about the event answering this question needs to be expressed as a “degree of belief,” informed by both data on the skill of the particular participant and how much he knows about inventors, as well as possibly prior knowledge of his performance in other game shows. Of course, your prior knowledge of the contestant may be minimal, or it may be well-informed. Either way, your final answer remains a degree of belief about an uncertain, and inherently unrepeatable, state of nature. The point of this hypothetical, light-hearted scenario is simply to highlight that a key distinction between the Frequentist and Bayesian approaches to inference is not the use (or nature) of prior information, but the manner in which probability is used. To the Bayesian, probability is the mathematical construct used to quantify uncertainty about an unknown state of nature, conditional on observed data and prior knowledge about the context in which that state occurs. To the Frequentist, probability is intrinsically linked to the concept of a repeated experiment, and the relative frequency with which a particular outcome occurs, conditional on that unknown state. This distinction remains key whether the Bayesian chooses to be informative or subjective in the specification of prior information, or chooses to be non-informative or objective. Frequentists consider probability to be a physical phenomenon, like mass or wavelength, whereas Bayesians stipulate that probability exists in the mind of scientists, as any scientific construct (Parmigiani and Inoue 2008). It seems that the understanding of the concept of probability for the common human being is more associated with “degrees of belief” rather than relative frequency. Peter Diggle, President of The Royal Statistical Society between 2014 and 2016, was asked in an interview, “A different trend which has surged upwards in statistics during Peter’s career is the popularity of Bayesian statistics. Does Peter consider himself a Bayesian?” He replied, “… you can’t not believe in Bayes’ theorem because it’s true. But that doesn’t make you a Bayesian in the philosophical sense. When people are making personal decisions – even if they don’t formally process Bayes’ theorem in their mind – they are adapting what they think they should believe in response to new evidence as it comes in. Bayes’ theorem is just the formal mathematical machinery for doing that.” However, we should mention that psychological experiments suggest that human beings suffer from anchoring, a cognitive bias that causes us to rely too heavily on previous information (the prior), so that the updating process (posterior) due to new information (likelihood) is not as strong as Bayes’ rule would suggest (Kahneman 2011). References "],["sec22.html", "2.2 Subjectivity is not the key", " 2.2 Subjectivity is not the key The concepts of subjectivity and objectivity indeed characterize both statistical paradigms in differing ways. Among Bayesians, there are those who are immersed in subjective rationality (Ramsey 1926), (Finetti 1937), (Savage 1954), (D. V. Lindley 2000), but others who adopt objective prior distributions such as Jeffreys’, reference, empirical, or robust priors (T. Bayes 1763), (P. Laplace 1812), (Jeffreys 1961), (J. Berger 2006) to operationalize Bayes’ rule and thereby weight quantitative (data-based) evidence. Among Frequentists, there are choices made about significance levels which, if not explicitly subjective, are typically not grounded in any objective and documented assessment of the relative losses of Type I and Type II errors.13 In addition, both Frequentist and Bayesian statisticians make decisions about the form of the data generating process, or “model”, which – if not subject to rigorous diagnostic assessment – retains a subjective element that potentially influences the final inferential outcome. Although we all know that by definition, a model is a schematic and simplified approximation to reality, “Since all models are wrong, the scientist cannot obtain a correct one by excessive elaboration. On the contrary, following William of Occam, he should seek an economical description of natural phenomena.” (G. E. P. Box 1976). We also know that “All models are wrong, but some are useful” (G. E. Box 1979), which is why model diagnostics are important. This task can be performed in both approaches. Particularly, the Bayesian framework can use predictive p-values for absolute testing (A. Gelman and Meng 1996), (M. Bayarri and Berger 2000) or posterior odds ratios for relative statements (Jeffreys 1935), (R. E. Kass and Raftery 1995). This is because the marginal likelihood, conditional on data, is interpreted as the evidence for the prior distribution (J. Berger 1993). In addition, what does objectivity mean in a Frequentist approach? For example, why should we use a 5% or 1% significance level rather than any other value? As someone said, the apparent objectivity is really a consensus (D. V. Lindley 2000). In fact, “Student” (William Gosset) saw statistical significance at any level as being “nearly valueless” in itself (Ziliak 2008). But, this is not just a situation in the Frequentist approach. The cut-offs used to “establish” scientific evidence against a null hypothesis, in terms of \\(log_{10}\\) scale (Jeffreys 1961) or \\(log_{e}\\) scale (R. E. Kass and Raftery 1995) as shown in Table 1.1, are also ad hoc. Although the true state of nature in Bayesian inference is expressed in “degrees of belief”, the distinction between the two paradigms does not reside in one being more, or less, subjective than the other. Rather, the differences are philosophical, pedagogical, and methodological. References "],["sec23.html", "2.3 Estimation, hypothesis testing and prediction", " 2.3 Estimation, hypothesis testing and prediction All that is required to perform estimation, hypothesis testing (model selection), and prediction in the Bayesian approach is to apply Bayes’ rule. This ensures coherence under a probabilistic view. However, there is no free lunch: coherence reduces flexibility. On the other hand, the Frequentist approach may not be coherent from a probabilistic point of view, but it is highly flexible. This approach can be seen as a toolkit that offers inferential solutions under the umbrella of understanding probability as relative frequency. For instance, a point estimator in a Frequentist approach is found such that it satisfies good sampling properties like unbiasedness, efficiency, or a large sample property such as consistency. A notable difference is that optimal Bayesian decisions are calculated by minimizing the expected value of the loss function with respect to the posterior distribution, i.e., conditional on observed data. In contrast, Frequentist “optimal” actions are based on the expected values over the distribution of the estimator (a function of data), conditional on the unknown parameters. This involves considering sampling variability. The Bayesian approach allows for the derivation of the posterior distribution of any unknown object, such as parameters, latent variables, future or unobserved variables, or models. A major advantage is that predictions can account for estimation error, and predictive distributions (probabilistic forecasts) can be easily derived. Hypothesis testing (model selection) in the Bayesian framework is based on inductive logic reasoning (inverse probability). Based on observed data, we evaluate which hypothesis is most tenable, performing this evaluation using posterior odds. These odds are in turn based on Bayes factors, which assess the evidence in favor of a null hypothesis while explicitly considering the alternative (R. E. Kass and Raftery 1995), following the rules of probability (D. V. Lindley 2000). This approach compares how well hypotheses predict data (Goodman 1999), minimizes the weighted sum of type I and type II error probabilities (DeGroot 1975; Pericchi and Pereira 2015), and takes into account the implicit balance of losses (Jeffreys 1961; Bernardo and Smith 1994). Posterior odds allow for the use of the same framework to analyze nested and non-nested models and perform model averaging. However, Bayes factors cannot be based on improper or vague priors (Koop 2003), the practical interplay between model selection and posterior distributions is not as straightforward as it may be in the Frequentist approach, and the computational burden can be more demanding due to the need to solve potentially difficult integrals. On the other hand, the Frequentist approach establishes most of its estimators as the solution to a system of equations. Observe that optimization problems often reduce to solving systems. We can potentially obtain the distribution of these estimators, but most of the time, asymptotic arguments or resampling techniques are required. Hypothesis testing relies on pivotal quantities and/or resampling, and prediction is typically based on a plug-in approach, which means that estimation error is not taken into account.14 In addition, ancillary statistics can be used to build prediction intervals.15 Comparing models depends on their structure. For instance, there are different Frequentist statistical approaches to compare nested and non-nested models. A nice feature in some situations is that there is a practical interplay between hypothesis testing and confidence intervals. For example, in the normal population mean hypothesis framework, you cannot reject a null hypothesis \\(H_0: \\mu = \\mu^0\\) at the \\(\\alpha\\) significance level (Type I error) if \\(\\mu^0\\) is in the \\(1-\\alpha\\) confidence interval. Specifically, \\[ P\\left( \\mu \\in \\left[\\hat{\\mu} - |t_{N-1}^{\\alpha/2}| \\times \\hat{\\sigma}_{\\hat{\\mu}}, \\hat{\\mu} + |t_{N-1}^{\\alpha/2}| \\times \\hat{\\sigma}_{\\hat{\\mu}}\\right] \\right) = 1 - \\alpha, \\] where \\(\\hat{\\mu}\\) and \\(\\hat{\\sigma}_{\\hat{\\mu}}\\) are the maximum likelihood estimators of the mean and standard error, \\(t_{N-1}^{\\alpha/2}\\) is the quantile value of the Student’s \\(t\\)-distribution at the \\(\\alpha/2\\) probability level with \\(N-1\\) degrees of freedom, and \\(N\\) is the sample size. A remarkable difference between the Bayesian and Frequentist inferential frameworks is the interpretation of credible/confidence intervals. Observe that once we have estimates, such that, for example, the previous interval is \\([0.2, 0.4]\\) given a 95% confidence level, we cannot say that \\(P(\\mu \\in [0.2, 0.4]) = 0.95\\) in the Frequentist framework. In fact, this probability is either 0 or 1 in this approach, as \\(\\mu\\) is either in the interval or it is not. The problem is that we will never know for certain in applied settings. This is because \\[ P(\\mu \\in [\\hat{\\mu} - |t_{N-1}^{0.025}| \\times \\hat{\\sigma}_{\\hat{\\mu}}, \\hat{\\mu} + |t_{N-1}^{0.025}| \\times \\hat{\\sigma}_{\\hat{\\mu}}]) = 0.95 \\] is interpreted in the context of repeated sampling. On the other hand, once we have the posterior distribution in the Bayesian framework, we can say that \\(P(\\mu \\in [0.2, 0.4]) = 0.95\\). Following common practice, most researchers and practitioners conduct hypothesis testing based on the p-value in the Frequentist framework. But what is a p-value? Most users do not know the answer, as statistical inference is often not performed by statisticians (J. Berger 2006).16 A p-value is the probability of obtaining a statistical summary of the data equal to or more extreme than what was actually observed, assuming that the null hypothesis is true. Therefore, p-value calculations involve not just the observed data, but also more extreme hypothetical observations. Thus, “What the use of p implies, therefore, is that a hypothesis that may be true may be rejected because it has not predicted observable results that have not occurred.” (Jeffreys 1961) It seems that common Frequentist inferential practice intertwines two different logical reasoning arguments: the p-value (Fisher 1958) and the significance level (Neyman and Pearson 1933). The former is an informal short-run criterion, whose philosophical foundation is reduction to absurdity, which measures the discrepancy between the data and the null hypothesis. Therefore, the p-value is not a direct measure of the probability that the null hypothesis is false. The latter, whose philosophical foundation is deduction, is based on long-run performance and controls the overall number of incorrect inferences in repeated sampling, without regard to individual cases. The p-value fallacy consists of interpreting the p-value as the strength of evidence against the null hypothesis and using it simultaneously with the frequency of Type I error under the null hypothesis (Goodman 1999). The American Statistical Association has several concerns regarding the use of the p-value as a cornerstone for hypothesis testing in science. This concern motivates the ASA’s statement on p-values (Wasserstein and Lazar 2016), which can be summarized in the following principles: “P-values can indicate how incompatible the data are with a specified statistical model.” “P-values do not measure the probability that the studied hypothesis is true, or the probability that the data were produced by random chance alone.” “Scientific conclusions and business or policy decisions should not be based solely on whether a p-value passes a specific threshold.” “Proper inference requires full reporting and transparency.” “A p-value, or statistical significance, does not measure the size of an effect or the importance of a result.” “By itself, a p-value does not provide a good measure of evidence regarding a model or hypothesis.” To sum up, Fisher proposed the p-value as a witness rather than a judge. So, a p-value lower than the significance level means more inspection of the null hypothesis, but it is not a final conclusion about it. Another difference between the Frequentists and the Bayesians is the way in which scientific hypotheses are tested. The former use the p-value, whereas the latter use the Bayes factor. Observe that the p-value is associated with the probability of the data given the hypothesis, whereas the Bayes factor is associated with the probability of the hypothesis given the data. However, there is an approximate link between the \\(t\\) statistic and the Bayes factor for regression coefficients (Raftery 1995). In particular, \\[ |t|&gt;(\\log(N)+6)^{1/2} \\] corresponds to strong evidence in favor of rejecting the null hypothesis of no relevance of a control in a regression. Observe that, in this setting, the threshold of the \\(t\\) statistic, and as a consequence the significance level, depends on the sample size. This setting agrees with the idea in experimental designs of selecting the sample size such that we control Type I and Type II errors. In observational studies, we cannot control the sample size, but we can select the significance level. See also (Sellke, Bayarri, and Berger 2001) and (Benjamin et al. 2018) for exercises that reveal potential flaws of the p-value (\\(p\\)) due to \\(p \\sim U[0,1]\\) under the null hypothesis,17 and calibrations of the p-value to interpret it as the odds ratio and the error probability. In particular, \\[ B(p)=-e \\times p \\times \\log(p) \\quad \\text{when} \\quad p &lt; e^{-1} \\] and interpret this as the Bayes factor of \\(H_0\\) to \\(H_1\\), where \\(H_1\\) denotes the unspecified alternative to \\(H_0\\), and \\[ \\alpha(p) = \\left(1 + \\left[-e \\times p \\times \\log(p)\\right]^{-1}\\right)^{-1} \\] as the error probability \\(\\alpha\\) in rejecting \\(H_0\\). Take into account that \\(B(p)\\) and \\(\\alpha(p)\\) are lower bounds. The logic of argumentation in the Frequentist approach is based on deductive logic, which means that it starts from a statement about the true state of nature (null hypothesis) and predicts what should be observed if this statement were true. On the other hand, the Bayesian approach is based on inductive logic, which means that it defines which hypothesis is more consistent with what is observed. The former inferential approach establishes that the truth of the premises implies the truth of the conclusion, which is why we reject or fail to reject hypotheses. The latter establishes that the premises supply some evidence, but not full assurance, of the truth of the conclusion, which is why we get probabilistic statements. Here, there is a distinction between the effects of causes (forward causal inference) and the causes of effects (reverse causal inference) (Andrew Gelman and Imbens 2013; Dawid, Musio, and Fienberg 2016). To illustrate this point, imagine that a firm increases the price of a specific good. Economic theory would suggest that, as a result, demand for the good decreases. In this case, the premise (null hypothesis) is the price increase, and the consequence is the decrease in the firm’s demand. Alternatively, one could observe a reduction in a firm’s demand and attempt to identify the cause behind it. For example, a reduction in quantity could be due to a negative supply shock. The Frequentist approach typically follows the first view (effects of causes), while Bayesian reasoning focuses on determining the probability of potential causes (causes of effects). References "],["sec24.html", "2.4 The likelihood principle", " 2.4 The likelihood principle The likelihood principle states that in making inferences or decisions about the state of nature, all the relevant experimental information is given by the likelihood function. The Bayesian framework follows this statement, i.e., it is conditional on observed data. We follow (J. Berger 1993), who in turn followed (D. V. Lindley and Phillips 1976), to illustrate the likelihood principle. We are given a coin and are interested in the probability, \\(\\theta\\), of it landing heads when flipped. We wish to test \\(H_0: \\theta = 1/2\\) versus \\(H_1: \\theta &gt; 1/2\\). An experiment is conducted by flipping the coin (independently) in a series of trials, with the result being the observation of 9 heads and 3 tails. This is not yet enough information to specify \\(p(y|\\theta)\\), since the series of trials has not been explained. Two possibilities arise: The experiment consisted of a predetermined 12 flips, so that \\(Y = [ \\text{Heads} ]\\) follows a \\(B(12, \\theta)\\) distribution. In this case, \\[ p_1(y|\\theta) = \\binom{12}{y} \\theta^y (1 - \\theta)^{12 - y} = 220 \\times \\theta^9 (1 - \\theta)^3. \\] The experiment consisted of flipping the coin until 3 tails were observed (\\(r = 3\\)). In this case, \\(Y\\), the number of heads (failures) before obtaining 3 tails, follows a \\(NB(3, 1 - \\theta)\\) distribution. Here, \\[ p_2(y|\\theta) = \\binom{y + r - 1}{r - 1} (1 - (1 - \\theta)^y)(1 - \\theta)^r = 55 \\times \\theta^9 (1 - \\theta)^3. \\] Using a Frequentist approach, the significance level of \\(y=9\\) using the Binomial model against \\(\\theta=1/2\\) would be: \\[ \\alpha_1=P_{1/2}(Y\\geq 9)=p_1(9|1/2)+p_1(10|1/2)+p_1(11|1/2)+p_1(12|1/2)=0.073. \\] success &lt;- 9 # Number of observed success in n trials n &lt;- 12 # Number of trials siglevel &lt;- sum(sapply(9:n,function(y)dbinom(y,n,0.5))) siglevel ## [1] 0.07299805 For the Negative Binomial model, the significance level would be: \\[ \\alpha_2=P_{1/2}(Y\\geq 9)=p_2(9|1/2)+p_2(10|1/2)+\\ldots=0.0327. \\] success &lt;- 3 # Number of target success (tails) failures &lt;- 9 # Number of failures siglevel &lt;- 1 - pnbinom((failures - 1),success,0.5) siglevel ## [1] 0.03271484 We arrive at different conclusions using a significance level of 5%, whereas we obtain the same outcomes using a Bayesian approach because the kernels of both distributions are identical (\\(\\theta^9 \\times (1 - \\theta)^3\\)). References "],["sec25.html", "2.5 Why is not the Bayesian approach that popular?", " 2.5 Why is not the Bayesian approach that popular? At this stage, one might wonder why the Bayesian statistical framework is not the dominant inferential approach, despite its historical origin in 1763 (Thomas Bayes 1763), whereas the Frequentist statistical framework was largely developed in the early 20th century. The scientific debate over the Bayesian inferential approach lasted for 150 years, and this may be explained by some of the following factors. One issue is the apparent subjectivity of the Bayesian approach, which runs counter to the strong conviction that science demands objectivity. Bayesian probability is considered a measure of degrees of belief, where the initial prior may be just a guess. This was not accepted as objective and rigorous science. Initial critics argued that Bayes was quantifying ignorance by assigning equal probabilities to all potential outcomes. As a consequence, prior distributions were dismissed (McGrayne 2011). Bayes himself seemed not to have believed in his idea. Although it seems that Bayes made his breakthrough in the late 1740s, he did not submit it for publication to the Royal Society. It was his friend, Richard Price, another Presbyterian minister, who rediscovered Bayes’ idea, polished it, and published it. However, it was Laplace who independently generalized Bayes’ theorem in 1781. Initially, he applied it to gambling problems and soon thereafter to astronomy, combining various sources of information to advance research in situations where data was scarce. He later sought to apply his discovery to finding the probability of causes, which he thought required large datasets, thus turning to demography. In this field, he had to perform large-scale calculations, leading to the development of Laplace’s approximation and the central limit theorem (P. Laplace 1812). Unfortunately, this came at the cost of abandoning his research on Bayesian inference. Once Laplace passed away in 1827, Bayes’ rule disappeared from the scientific discourse for almost a century. In part, personal attacks against Laplace led to the rule being forgotten. Moreover, there was a prevailing belief that statistics should not address causation, and that the prior was too subjective to be compatible with science. Nonetheless, practitioners continued to use Bayes’ rule to solve problems in astronomy, communication, medicine, military affairs, and social issues with remarkable results. Thus, the concept of degrees of belief to operationalize probability was abandoned in favor of scientific objectivity. Probability was then defined as the frequency with which an event occurs in many repeatable trials, which became the accepted norm. Critics of Laplace argued that these two concepts were diametrically opposed, although Laplace considered them to be basically equivalent when large sample sizes are involved (McGrayne 2011). The era of Frequentists, or sampling theorists, began, led by Karl Pearson and his nemesis, Ronald Fisher. Both were brilliant and persuasive characters, opposing the inverse probability approach and making it nearly impossible to argue against their ideas. Pearson’s legacy was carried on by his son, Egon, and Egon’s friend, Jerzy Neyman. Both inherited the anti-Bayesian and anti-Fisher sentiments. Despite the anti-Bayesian campaign among statisticians, some independent thinkers continued to develop Bayesian ideas, including Borel, Ramsey, and de Finetti, who were isolated in different countries: France, England, and Italy. However, the anti-Bayesian trio of Fisher, Neyman, and Egon Pearson dominated the spotlight in the 1920s and 1930s. Only a geophysicist, Harold Jeffreys, kept Bayesian inference alive during the 1930s and 1940s. Jeffreys was a quiet, reserved gentleman working in the astronomy department at Cambridge. He was Fisher’s friend due to their shared character, although they were intellectual opposites when it came to Bayesian inference, leading to intense intellectual battles. Unfortunately for the Bayesian approach, Jeffreys lost. His work was highly technical, using confusing high-level mathematics. He focused on inference from scientific evidence, rather than guiding future actions based on decision theory, which was crucial in that era for mathematical statistics, especially during the Second World War. In contrast, Fisher was a dominant figure, persuasive in public and a master of practical applications, with his techniques written in a popular style with minimal mathematics. Nevertheless, Bayes’ rule achieved remarkable results in applied settings such as at AT&amp;T and the U.S. Social Security system. Bayesian inference also played a significant role during the Second World War and the Cold War. Alan Turing used inverse probability at Bletchley Park to crack German messages encoded using the Enigma machine, which was employed by U-boats. Andrei Kolmogorov used Bayesian methods to improve firing tables for Russian artillery. Bernard Koopman applied it for searching targets at sea, and the RAND Corporation used it during the Cold War. Unfortunately, these Bayesian developments remained top secret for almost 40 years, keeping the contribution of inverse probability hidden from modern history. In the 1950s and 1960s, three mathematicians led the resurgence of the Bayesian approach: Good, Savage, and Lindley. However, it seems that they were reluctant to apply their theories to real-world problems. Despite the fact that the Bayesian approach proved its worth in various areas such as business decisions, naval searches, and lung cancer detection, it was largely applied to simple models due to its mathematical complexity and requirement for large computations. However, some breakthroughs changed this. First, hierarchical models were introduced by Lindley and Smith, where a complex model is decomposed into many smaller, easier-to-solve models. Second, Markov chain Monte Carlo (MCMC) methods were developed by Hastings in the 1970s (Hastings 1970) and the Geman brothers in the 1980s (Geman and Geman 1984). These methods were incorporated into the Bayesian inferential framework in the 1990s by Gelfand and Smith (A. E. Gelfand and Smith 1990), and Tierney (Tierney 1994), when desktop computers gained sufficient computational power to solve complex models. Since then, the Bayesian inferential framework has gained increasing popularity among both practitioners and scientists. References "],["sec26.html", "2.6 A simple working example", " 2.6 A simple working example We will illustrate some conceptual differences between the Bayesian and Frequentist statistical approaches by performing inference on a random sample \\(\\mathbf{Y} = [Y_1, Y_2, \\dots, Y_N]\\), where \\(Y_i \\stackrel{iid}{\\sim} N(\\mu, \\sigma^2)\\) for \\(i = 1, 2, \\dots, N\\). In particular, we set \\(\\pi(\\mu, \\sigma) = \\pi(\\mu) \\pi(\\sigma) \\propto \\frac{1}{\\sigma}\\). This is a standard non-informative improper prior (Jeffreys prior, see Chapter 3). That is, this prior is perfectly compatible with the sample information. Additionally, we assume independent priors for \\(\\mu\\) and \\(\\sigma\\). \\[ \\begin{aligned} \\pi(\\mu,\\sigma|\\mathbf{y}) &amp;\\propto \\frac{1}{\\sigma}\\times (\\sigma^2)^{-N/2}\\exp\\left\\{-\\frac{1}{2\\sigma^2}\\sum_{i=1}^N (y_i-\\mu)^2\\right\\} \\\\ &amp;= \\frac{1}{\\sigma}\\times (\\sigma^2)^{-N/2}\\exp\\left\\{-\\frac{1}{2\\sigma^2}\\sum_{i=1}^N \\left((y_i-\\bar{y}) - (\\mu-\\bar{y})\\right)^2\\right\\} \\\\ &amp;= \\frac{1}{\\sigma}\\exp\\left\\{-\\frac{N}{2\\sigma^2}(\\mu-\\bar{y})^2\\right\\}\\times (\\sigma)^{-N}\\exp\\left\\{-\\frac{1}{2\\sigma^2}\\sum_{i=1}^N (y_i-\\bar{y})^2\\right\\} \\\\ &amp;= \\frac{1}{\\sigma}\\exp\\left\\{-\\frac{N}{2\\sigma^2}(\\mu-\\bar{y})^2\\right\\}\\times (\\sigma)^{-(\\alpha_n+1)}\\exp\\left\\{-\\frac{\\alpha_n\\hat{\\sigma}^2}{2\\sigma^2}\\right\\}, \\end{aligned} \\] where \\(\\bar{y} = \\frac{\\sum_{i=1}^N y_i}{N}\\), \\(\\alpha_n = N-1\\), and \\(\\hat{\\sigma}^2 = \\frac{\\sum_{i=1}^N (y_i-\\bar{y})^2}{N-1}\\). The first term in the last expression is the kernel of a normal density, \\(\\mu|\\sigma,\\mathbf{y} \\sim N(\\bar{y}, \\sigma^2 / N)\\). The second term is the kernel of an inverted gamma density (Zellner 1996), \\(\\sigma|\\mathbf{y} \\sim IG(\\alpha_n, \\hat{\\sigma}^2)\\). Therefore, \\[ \\pi(\\mu|\\sigma,\\mathbf{y}) = \\frac{1}{\\sqrt{2\\pi \\sigma^2 / N}} \\exp\\left\\{-\\frac{N}{2\\sigma^2}(\\mu-\\bar{y})^2\\right\\}, \\] and \\[ \\pi(\\sigma|\\mathbf{y}) = \\frac{2}{\\Gamma(\\alpha_n / 2)} \\left(\\frac{\\alpha_n \\hat{\\sigma}^2}{2}\\right)^{\\alpha_n / 2} \\frac{1}{\\sigma^{\\alpha_n+1}} \\exp\\left\\{-\\frac{\\alpha_n \\hat{\\sigma}^2}{2 \\sigma^2}\\right\\}. \\] Observe that \\(\\mathbb{E}[\\mu | \\sigma, \\mathbf{y}] = \\bar{y}\\); this is also the maximum likelihood (Frequentist) point estimate of \\(\\mu\\) in this setting. In addition, the Frequentist \\((1-\\alpha)\\%\\) confidence interval and the Bayesian \\((1-\\alpha)\\%\\) credible interval have exactly the same form, \\(\\bar{y} \\pm |z_{\\alpha/2}| \\frac{\\sigma}{\\sqrt{N}}\\), where \\(z_{\\alpha/2}\\) is the \\(\\alpha/2\\) percentile of a standard normal distribution. However, the interpretations are entirely different. The confidence interval has a probabilistic interpretation under sampling variability of \\(\\bar{Y}\\): in repeated sampling, \\((1-\\alpha)\\%\\) of the intervals \\(\\bar{Y} \\pm |z_{\\alpha/2}| \\frac{\\sigma}{\\sqrt{N}}\\) would include \\(\\mu\\). However, given an observed realization of \\(\\bar{Y}\\), say \\(\\bar{y}\\), the probability of \\(\\bar{y} \\pm |z_{\\alpha/2}| \\frac{\\sigma}{\\sqrt{N}}\\) including \\(\\mu\\) is either 1 or 0. This is why we refer to it as a \\((1-\\alpha)\\%\\) confidence interval. On the other hand, \\(\\bar{y} \\pm |z_{\\alpha/2}| \\frac{\\sigma}{\\sqrt{N}}\\) has a straightforward probabilistic interpretation in the Bayesian framework: there is a \\((1-\\alpha)\\%\\) probability that \\(\\mu\\) lies within this interval. If we want to get the marginal posterior density of \\(\\mu\\), \\[\\begin{align*} \\pi(\\mu|\\mathbf{y})&amp;=\\int_{0}^{\\infty} \\pi(\\mu,\\sigma|\\mathbf{y}) d\\sigma\\\\ &amp;\\propto \\int_{0}^{\\infty} \\frac{1}{\\sigma}\\times (\\sigma^2)^{-N/2}\\exp\\left\\{-\\frac{1}{2\\sigma^2}\\sum_{i=1}^N (y_i-\\mu)^2\\right\\} d\\sigma\\\\ &amp;= \\int_{0}^{\\infty} \\left(\\frac{1}{\\sigma}\\right)^{N+1} \\exp\\left\\{-\\frac{N}{2\\sigma^2}\\frac{\\sum_{i=1}^N (y_i-\\mu)^2}{N}\\right\\} d\\sigma\\\\ &amp;=\\left[\\frac{2}{\\Gamma(N/2)}\\left(\\frac{N\\sum_{i=1}^N (y_i-\\mu)^2}{2N}\\right)^{N/2}\\right]^{-1}\\\\ &amp;\\propto \\left[\\sum_{i=1}^N (y_i-\\mu)^2\\right]^{-N/2}\\\\ &amp;=\\left[\\sum_{i=1}^N ((y_i-\\bar{y})-(\\mu-\\bar{y}))^2\\right]^{-N/2}\\\\ &amp;=[\\alpha_n\\hat{\\sigma}^2+N(\\mu-\\bar{y})^2]^{-N/2}\\\\ &amp;\\propto \\left[1+\\frac{1}{\\alpha_n}\\left(\\frac{\\mu-\\bar{y}}{\\hat{\\sigma}/\\sqrt{N}}\\right)^2\\right]^{-(\\alpha_n+1)/2}. \\end{align*}\\] The fourth line arises from the kernel of an inverted gamma density with \\(N\\) degrees of freedom in the integral (Zellner 1996). The last expression represents the kernel of a Student’s \\(t\\)-distribution with \\(\\alpha_n = N - 1\\) degrees of freedom, expected value equal to \\(\\bar{y}\\), and variance \\(\\frac{\\hat{\\sigma}^2}{N} \\left( \\frac{\\alpha_n}{\\alpha_n - 2} \\right)\\). Therefore, \\(\\mu | \\mathbf{y} \\sim t \\left( \\bar{y}, \\frac{\\hat{\\sigma}^2}{N} \\left( \\frac{\\alpha_n}{\\alpha_n - 2} \\right), \\alpha_n \\right)\\). Observe that a \\((1-\\alpha)\\%\\) confidence interval and a \\((1-\\alpha)\\%\\) credible interval have exactly the same form, \\(\\bar{y} \\pm |t_{\\alpha/2}^{\\alpha_n}| \\frac{\\hat{\\sigma}}{\\sqrt{N}}\\), where \\(t_{\\alpha/2}^{\\alpha_n}\\) is the \\(\\alpha/2\\) percentile of a Student’s \\(t\\)-distribution. However, the interpretations are entirely different. The mathematical similarity between the Frequentist and Bayesian expressions in this example arises from the use of an improper prior. Example: Math test You have a random sample of math scores of size \\(N = 50\\) from a normal distribution, \\(Y_i \\sim N(\\mu, \\sigma^2)\\). The sample mean and variance are equal to 102 and 10, respectively. Assuming an improper prior equal to \\(\\frac{1}{\\sigma}\\), we proceed with the following tasks: Compute the 95% confidence and credible intervals for \\(\\mu\\). Determine the posterior probability that \\(\\mu &gt; 103\\). Using the fact that \\(\\mu | \\mathbf{y} \\sim t\\left(\\bar{y}, \\frac{\\hat{\\sigma}^2}{N} \\left( \\frac{\\alpha_n}{\\alpha_n - 2} \\right), \\alpha_n \\right)\\), which implies that the confidence and credible intervals for \\(\\mu\\) are given by: \\[ \\begin{aligned} \\bar{y} \\pm |t_{\\alpha/2}^{\\alpha_n}| \\frac{\\hat{\\sigma}}{\\sqrt{N}}, \\end{aligned} \\] where \\(\\bar{y} = 102\\), \\(\\hat{\\sigma}^2 = 10\\), and \\(\\alpha_n = 49\\). Thus, the 95% confidence and credible intervals for \\(\\mu\\) are the same, namely \\((101.1, 102.9)\\), and the posterior probability that \\(\\mu &gt; 103\\) is 1.49% given the sample information. N &lt;- 50 # Sample size y_bar &lt;- 102 # Sample mean s2 &lt;- 10 # Sample variance alpha &lt;- N - 1 serror &lt;- (s2/N)^0.5 LimInf &lt;- y_bar - abs(qt(0.025, alpha)) * serror LimInf ## [1] 101.1013 # Lower bound LimSup &lt;- y_bar + abs(qt(0.025, alpha)) * serror LimSup ## [1] 102.8987 # Upper bound y.cut &lt;- 103 P &lt;- 1-metRology::pt.scaled(y.cut, df = alpha, mean = y_bar, sd = serror) P ## [1] 0.01496694 # Probability of mu greater than y.cut References "],["sec27.html", "2.7 Summary", " 2.7 Summary The differences between the Bayesian and Frequentist inferential approaches are philosophical, particularly with regard to the role of probability; pedagogical, especially in relation to the use of inference for decision-making; and methodological, due to differences in their mathematical and computational frameworks. Although, at the methodological level, the debate has become considerably muted —except for certain aspects of inference— there is widespread recognition that each approach has much to contribute to statistical practice (Good (1992), M. J. Bayarri and Berger (2004), R. Kass (2011)). As Bradley Efron stated, “Computer-age statistical inference at its most successful combines elements of the two philosophies” (Efron and Hastie (2016)). References "],["sec28.html", "2.8 Exercises", " 2.8 Exercises Jeffreys-Lindley’s Paradox The Jeffreys-Lindley’s paradox (Jeffreys 1961; Dennis V. Lindley 1957) represents an apparent disagreement between the Bayesian and Frequentist frameworks in a hypothesis testing scenario. In particular, assume that in a city, 49,581 boys and 48,870 girls have been born over 20 years. Assume that the male births follow a Binomial distribution with probability \\(\\theta\\). We wish to test the null hypothesis \\(H_0: \\ \\theta = 0.5\\) versus the alternative hypothesis \\(H_1: \\ \\theta \\neq 0.5\\). Show that the posterior model probability for the null model is approximately 0.95. Assume \\(\\pi(H_0) = \\pi(H_1) = 0.5\\), and that \\(\\pi(\\theta)\\) follows a uniform distribution, i.e., \\({U}(0,1)\\), under \\(H_1\\). Show that the p-value for this hypothesis test is 0.0235 using the normal approximation, \\(Y \\sim N(N \\times \\theta, N \\times \\theta \\times (1 - \\theta))\\). We want to test \\(H_0: \\ \\mu = \\mu_0\\) versus \\(H_1: \\ \\mu \\neq \\mu_0\\) given \\(Y_i \\stackrel{iid}{\\sim} N(\\mu, \\sigma^2)\\). Assume \\(\\pi(H_0) = \\pi(H_1) = 0.5\\), and that \\(\\pi(\\mu, \\sigma) \\propto 1/\\sigma\\) under the alternative hypothesis. Show that \\[ p(\\mathbf{y}|\\mathcal{M}_1) = \\frac{\\pi^{-N/2}}{2} \\Gamma(N/2) 2^{N/2} \\left( \\frac{1}{\\alpha_n \\hat{\\sigma}^2} \\right)^{N/2} \\left( \\frac{N}{\\alpha_n \\hat{\\sigma}^2} \\right)^{-1/2} \\frac{\\Gamma(1/2) \\Gamma(\\alpha_n/2)}{\\Gamma((\\alpha_n+1)/2)} \\] and \\[ p(\\mathbf{y}|\\mathcal{M}_0) = (2\\pi)^{-N/2} \\left[ \\frac{2}{\\Gamma(N/2)} \\left( \\frac{N}{2} \\frac{\\sum_{i=1}^N (y_i - \\mu_0)^2}{N} \\right)^{N/2} \\right]^{-1}. \\] Then, the posterior odds ratio is: \\[ PO_{01} = \\frac{p(\\mathbf{y}|\\mathcal{M}_0)}{p(\\mathbf{y}|\\mathcal{M}_1)} = \\frac{\\Gamma((\\alpha_n+1)/2)}{\\Gamma(1/2)\\Gamma(\\alpha_n/2)} (\\alpha_n \\hat{\\sigma}^2 / N)^{-1/2} \\left[ 1 + \\frac{(\\mu_0 - \\bar{y})^2}{\\alpha_n \\hat{\\sigma}^2 / N} \\right]^{-\\left(\\frac{\\alpha_n + 1}{2}\\right)}, \\] where \\(\\alpha_n = N - 1\\) and \\(\\hat{\\sigma}^2 = \\frac{\\sum_{i=1}^N (y_i - \\bar{y})^2}{N-1}\\). Find the relationship between the posterior odds ratio and the classical test statistic for the null hypothesis. Math Test Continues Using the setting of the Example: Math Test in Subsection 2.6, test \\(H_0: \\ \\mu = \\mu_0\\) versus \\(H_1: \\ \\mu \\neq \\mu_0\\) where \\(\\mu_0 = \\{ 100, 100.5, 101, 101.5, 102 \\}\\). What is the p-value for these hypothesis tests? Find the posterior model probability of the null model for each \\(\\mu_0\\). References "],["Chap3.html", "Chapter 3 Cornerstone models: Conjugate families", " Chapter 3 Cornerstone models: Conjugate families We will introduce conjugate families in basic statistical models with examples, solving them analytically and computationally using R. We will have some mathematical, and computational exercises in R. "],["sec41.html", "3.1 Motivation of conjugate families", " 3.1 Motivation of conjugate families Observing three fundamental pieces of Bayesian analysis: the posterior distribution (parameter inference), the marginal likelihood (hypothesis testing), and the predictive distribution (prediction), equations (3.1), (3.2) and (3.3), respectively, \\[\\begin{align} \\pi(\\mathbf{\\theta}|\\mathbf{y})&amp;=\\frac{p(\\mathbf{y}|\\mathbf{\\theta}) \\times \\pi(\\mathbf{\\theta})}{p(\\mathbf{y})}, \\tag{3.1} \\end{align}\\] \\[\\begin{equation} p(\\mathbf{y})=\\int_{\\mathbf{\\Theta}}p(\\mathbf{y}|\\mathbf{\\theta})\\pi(\\mathbf{\\theta})d\\mathbf{\\theta}, \\tag{3.2} \\end{equation}\\] and \\[\\begin{equation} p(\\mathbf{Y}_0|\\mathbf{y})=\\int_{\\mathbf{\\Theta}}p(\\mathbf{Y}_0|\\mathbf{\\theta})\\pi(\\mathbf{\\theta}|\\mathbf{y})d\\mathbf{\\theta}, \\tag{3.3} \\end{equation}\\] we can understand that some of the initial limitations of the application of the Bayesian analysis were associated with the ausence of algorithms to draw from non-standard posterior distributions (equation (3.1)), and the lack of analytical solutions of the marginal likelihood (equation (3.2)) and the predictive distribution (equation (3.3)). Both issues requiring computational power. Although there were algorithms to sample from non-standard posterior distributions since the second half of the last century [Metropolis et al. (1953)](Hastings 1970),(Geman and Geman 1984), their particular application in the Bayesian framework emerged later (A. E. Gelfand and Smith 1990),(Tierney 1994), maybe until increasing computational power of desktop computers. However, it is also common practice nowadays to use models that have standard conditional posterior distributions to mitigate computational requirements. In addition, nice mathematical tricks plus computational algorithms (Alan E. Gelfand and Dey 1994), (Chib 1995),(Chib and Jeliazkov 2001) and approximations [Tierney and Kadane (1986)](Jordan and Saul 1999) are used to obtain the marginal likelihood (prior predictive). Despite these advances, there are two potentially conflicting desirable model specification features that we can see from equations (3.1), (3.2) and (3.3): analytical solutions and the posterior distribution in the same family as the prior distribution for a given likelihood. The latter is called conjugate priors, a family of priors that is closed under sampling (Schlaifer and Raiffa 1961, p.~ 43-57). These features are desirable as the former implies facility to perform hypothesis testing and predictive analysis, and the latter means invariance of the prior-to-posterior updating. Both feautures imply less computational burden. We can easily achieve each of these features independenly, for instance using improper priors for analytical tractability, and defining in a broad sense the family of prior distributions for prior conjugacy. However, these are in conflict. Fortunately, we can achieve these two nice features if we assume that the data generating process is given by a distribution function in the exponential family. That is, given a random sample \\(\\mathbf{y}=[y_1,y_2,\\dots,y_N]^{\\top}\\), a probability density function \\(p(\\mathbf{y}|\\mathbf{\\theta})\\) belongs to the exponential family if it has the form \\[\\begin{align} p(\\mathbf{y}|\\mathbf{\\theta})&amp;=\\prod_{i=1}^N h(y_i) C(\\mathbf{\\theta}) \\exp\\left\\{\\eta(\\mathbf{\\theta})^{\\top}\\mathbf{T}(y_i)\\right\\}\\\\ &amp;=h(\\mathbf{y}) C(\\mathbf{\\theta})^N\\exp\\left\\{\\eta(\\mathbf{\\theta})^{\\top}\\mathbf{T}(\\mathbf{y})\\right\\} \\tag{3.4}\\\\ &amp;=h(\\mathbf{y})\\exp\\left\\{\\eta(\\mathbf{\\theta})^{\\top}\\mathbf{T}(\\mathbf{y})-A(\\mathbf{\\theta})\\right\\}, \\end{align}\\] where \\(h(\\mathbf{y})=\\prod_{i=1}^N h(y_i)\\) is a non-negative function, \\(\\eta(\\mathbf{\\theta})\\) is a known function of the parameters, \\(A(\\mathbf{\\theta})=\\log\\left\\{\\int_{\\mathbf{Y}}h(\\mathbf{y})\\exp\\left\\{\\eta(\\mathbf{\\theta})^{\\top}\\mathbf{T}(\\mathbf{y})\\right\\}d\\mathbf{y}\\right\\}=-N\\log(C(\\mathbf{\\theta}))\\) is a normalization factor, and \\(\\mathbf{T}(\\mathbf{y})=\\sum_{i=1}^N\\mathbf{T}(y_i)\\) is the vector of sufficient statistics of the distribution (by the factorization theorem). If the support of \\(\\mathbf{y}\\) is independent of \\(\\mathbf{\\theta}\\), then the family is said to be regular, otherwise it is irregular. In addition, if we set \\(\\eta=\\eta(\\mathbf{\\theta})\\), then the exponential family is said to be in the canonical form \\[\\begin{align} p(\\mathbf{y}|\\mathbf{\\theta})&amp;=h(\\mathbf{y})D(\\mathbf{\\eta})^N\\exp\\left\\{\\eta^{\\top}\\mathbf{T}(\\mathbf{y})\\right\\}\\\\ &amp;=h(\\mathbf{y})\\exp\\left\\{\\eta^{\\top}\\mathbf{T}(\\mathbf{y})-B(\\mathbf{\\eta})\\right\\}. \\end{align}\\] A nice feature of this representation is that \\(\\mathbb{E}[\\mathbf{T}(\\mathbf{y})|\\mathbf{\\eta}]=\\nabla B(\\mathbf{\\eta})\\) and \\(Var[\\mathbf{T}(\\mathbf{y})|\\mathbf{\\eta}]=\\nabla^2 B(\\mathbf{\\eta})\\). Examples of exponential family distributions Discrete distributions Given a random sample \\(\\mathbf{y}=[y_1,y_2,\\dots,y_N]^{\\top}\\) from a Poisson distribution let’s show that \\(p(\\mathbf{y}|\\lambda)\\) is in the exponential family. \\[\\begin{align} p(\\mathbf{y}|\\lambda)&amp;=\\prod_{i=1}^N \\frac{\\lambda^{y_i} \\exp(-\\lambda)}{y_i!}\\\\ &amp;=\\frac{\\lambda^{\\sum_{i=1}^N y_i}\\exp(-N\\lambda)}{\\prod_{i=1}^N y_i!}\\\\ &amp;=\\frac{\\exp(-N\\lambda)\\exp(\\sum_{i=1}^Ny_i\\log(\\lambda))}{\\prod_{i=1}^N y_i!}, \\end{align}\\] then \\(h(\\mathbf{y})=\\left[\\prod_{i=1}^N y_i!\\right]^{-1}\\), \\(\\eta(\\lambda)=\\log(\\lambda)\\), \\(T(\\mathbf{y})=\\sum_{i=1}^N y_i\\) (sufficient statistic) and \\(C(\\lambda)=\\exp(-\\lambda)\\). If we set \\(\\eta=\\log(\\lambda)\\), then \\[\\begin{align} p(\\mathbf{y}|\\eta)&amp;=\\frac{\\exp(\\eta\\sum_{i=1}^Ny_i-N\\exp(\\eta))}{\\prod_{i=1}^N y_i!}, \\end{align}\\] such that \\(B(\\eta)=N\\exp(\\eta)\\), then \\(\\nabla(B(\\eta))=N\\exp(\\eta)=N\\lambda=\\mathbb{E}\\left[\\sum_{i=1}^N y_i\\biggr\\rvert\\lambda\\right]\\), that is, \\(\\mathbb{E}\\left[\\frac{\\sum_{i=1}^N y_i}{N}\\biggr\\rvert\\lambda\\right]=\\mathbb{E}[\\bar{y}|\\lambda]=\\lambda\\), and \\(\\nabla^2(B(\\eta))=N\\exp(\\eta)=N\\lambda=Var\\left[\\sum_{i=1}^N y_i\\biggr\\rvert\\lambda\\right]=N^2 \\times Var\\left[\\bar{y}\\rvert\\lambda\\right]\\), then \\(Var\\left[\\bar{y}\\rvert\\lambda\\right]=\\frac{\\lambda}{N}\\). Given a random sample \\(\\mathbf{y}=[y_1,y_2,\\dots,y_N]^{\\top}\\) from a Bernoulli distribution let’s show that \\(p(\\mathbf{y}|\\theta)\\) is in the exponential family. \\[\\begin{align} p(\\mathbf{y}|\\theta)&amp;=\\prod_{i=1}^N \\theta^{y_i}(1-\\theta)^{1-y_i}\\\\ &amp;=\\theta^{\\sum_{i=1}^N y_i}(1-\\theta)^{N-\\sum_{i=1}^N y_i}\\\\ &amp;=(1-\\theta)^N\\exp\\left\\{\\sum_{i=1}^N y_i\\log\\left(\\frac{\\theta}{1-\\theta}\\right)\\right\\}, \\end{align}\\] then \\(h(\\mathbf{y})=\\mathbb{I}[y_i\\in\\left\\{0,1\\right\\}]\\), \\(\\eta(\\theta)=\\log\\left(\\frac{\\theta}{1-\\theta}\\right)\\), \\(T(\\mathbf{y})=\\sum_{i=1}^N y_i\\) and \\(C(\\theta)=1-\\theta\\). Write this distribution in the canonical form, and find the mean and variance of the sufficient statistic (exercise 1). Given a random sample \\(\\mathbf{y}=[\\mathbf{y}_1,\\mathbf{y}_2,\\dots,\\mathbf{y}_N]\\) from a m-dimensional multinomial distribution, where \\(\\mathbf{y}_i=\\left[y_{i1},\\dots,y_{im}\\right]\\), \\(\\sum_{l=1}^m y_{il}=n\\), \\(n\\) independent trials each of which leads to a success for exactly one of \\(m\\) categories with probabilities \\(\\mathbf{\\theta}=[\\theta_1,\\theta_2,\\dots,\\theta_m]\\), \\(\\sum_{l=1}^m \\theta_l=1\\). Let’s show that \\(p(\\mathbf{y}|\\mathbf{\\theta})\\) is in the exponential family. \\[\\begin{align} p(\\mathbf{y}|\\mathbf{\\theta})&amp;=\\prod_{i=1}^N \\frac{n!}{\\prod_{l=1}^m y_{il}!} \\prod_{l=1}^m\\theta_l^{y_{il}}\\\\ &amp;=\\frac{(n!)^N}{\\prod_{i=1}^N\\prod_{l=1}^m y_{il}!}\\exp\\left\\{\\sum_{i=1}^N\\sum_{l=1}^m y_{il}\\log(\\theta_l)\\right\\}\\\\ &amp;=\\frac{(n!)^N}{\\prod_{i=1}^N\\prod_{l=1}^m y_{il}!}\\exp\\left\\{\\left(N\\times n-\\sum_{i=1}^N\\sum_{l=1}^{m-1}y_{il}\\right)\\log(\\theta_m)+\\sum_{i=1}^N\\sum_{l=1}^{m-1}y_{il}\\log(\\theta_l)\\right\\}\\\\ &amp;=\\frac{(n!)^N}{\\prod_{i=1}^N\\prod_{l=1}^m y_{il}!}\\theta_m^{N\\times n}\\exp\\left\\{\\sum_{i=1}^N\\sum_{l=1}^{m-1}y_{il}\\log(\\theta_l/\\theta_m)\\right\\}, \\end{align}\\] then \\(h(\\mathbf{y})=\\frac{(n!)^N}{\\prod_{i=1}^N\\prod_{l=1}^m y_{il}!}\\), \\(\\eta(\\mathbf{\\theta})=\\left[\\log\\left(\\frac{\\theta_1}{\\theta_m}\\right)\\dots \\log\\left(\\frac{\\theta_{m-1}}{\\theta_m}\\right)\\right]\\), \\(T(\\mathbf{y})=\\left[\\sum_{i=1}^N y_{i1}\\dots \\sum_{i=1}^N y_{im-1}\\right]\\) and \\(C(\\mathbf{\\theta})=\\theta_m^n\\). Continuous distributions Given a random sample \\(\\mathbf{y}=[y_1,y_2,\\dots,y_N]^{\\top}\\) from a normal distribution let’s show that \\(p(\\mathbf{y}|\\mu,\\sigma^2)\\) is in the exponential family. \\[\\begin{align} p(\\mathbf{y}|\\mu,\\sigma^2)&amp;=\\prod_{i=1}^N \\frac{1}{2\\pi\\sigma^2}\\exp\\left\\{-\\frac{1}{2\\sigma^2}\\left(y_i-\\mu\\right)^2\\right\\}\\\\ &amp;= (2\\pi)^{-N/2}(\\sigma^2)^{-N/2}\\exp\\left\\{-\\frac{1}{2\\sigma^2}\\sum_{i=1}^N\\left(y_i-\\mu\\right)^2\\right\\}\\\\ &amp;= (2\\pi)^{-N/2}\\exp\\left\\{-\\frac{1}{2\\sigma^2}\\sum_{i=1}^Ny_i^2+\\frac{\\mu}{\\sigma^2}\\sum_{i=1}^N y_i-N\\frac{\\mu^2}{2\\sigma^2}-\\frac{N}{2}\\log(\\sigma^2)\\right\\} \\end{align}\\] then \\(h(\\mathbf{y})=(2\\pi)^{-N/2}\\), \\(\\eta(\\mu,\\sigma^2)=\\left[\\frac{\\mu}{\\sigma^2} \\ \\frac{-1}{2\\sigma^2}\\right]\\), \\(T(\\mathbf{y})=\\left[\\sum_{i=1}^N y_i \\ \\sum_{i=1}^N y_i^2\\right]\\) and \\(C(\\mu,\\sigma^2)=\\exp\\left\\{-\\frac{\\mu^2}{2\\sigma^2}-\\frac{\\log(\\sigma^2)}{2}\\right\\}\\). Observe that \\[\\begin{align} p(\\mathbf{y}|\\mu,\\sigma^2)&amp;= (2\\pi)^{-N/2}\\exp\\left\\{\\eta_1\\sum_{i=1}^N y_i+\\eta_2\\sum_{i=1}^Ny_i^2-\\frac{N}{2}\\log(-2\\eta_2)+\\frac{N}{4}\\frac{\\eta_1^2}{\\eta_2}\\right\\}, \\end{align}\\] where \\(B(\\mathbf{\\eta})=\\frac{N}{2}\\log(-2\\eta_2)-\\frac{N}{4}\\frac{\\eta_1^2}{\\eta_2}\\). Then, \\[\\begin{align} \\nabla B(\\mathbf{\\eta}) &amp; = \\begin{bmatrix} -\\frac{N}{2}\\frac{\\eta_1}{\\eta_2}\\\\ -\\frac{N}{2}\\frac{1}{\\eta_2}+\\frac{N}{4}\\frac{\\eta_1^2}{\\eta_2^2} \\end{bmatrix} = \\begin{bmatrix} N\\times\\mu\\\\ N\\times(\\mu^2+\\sigma^2) \\end{bmatrix} = \\begin{bmatrix} \\mathbb{E}\\left[\\sum_{i=1}^N y_i\\bigr\\rvert \\mu,\\sigma^2\\right]\\\\ \\mathbb{E}\\left[\\sum_{i=1}^N y_i^2\\bigr\\rvert \\mu,\\sigma^2\\right] \\end{bmatrix}. \\end{align}\\] Given \\(\\mathbf{Y}=[\\mathbf{y}_1 \\ \\mathbf{y}_2 \\ \\dots \\ \\mathbf{y}_p]\\) a \\(N\\times p\\) matrix such that \\(\\mathbf{y}_i\\sim N_p(\\mathbf{\\mu},\\mathbf{\\Sigma})\\), \\(i=1,2,\\dots,N\\), that is, each \\(i\\)-th row of \\(\\mathbf{Y}\\) follows a multivariate normal distribution. Then, assuming independence between rows, let’s show that \\(p(\\mathbf{y}_1,\\mathbf{y}_2,\\dots,\\mathbf{y}_N|\\mathbf{\\mu},\\mathbf{\\Sigma})\\) is in the exponential family. \\[\\begin{align} p(\\mathbf{y}_1,\\mathbf{y}_2,\\dots,\\mathbf{y}_N|\\mathbf{\\mu},\\mathbf{\\Sigma})&amp;=\\prod_{i=1}^N (2\\pi)^{-p/2}|\\Sigma|^{-1/2}\\exp\\left\\{-\\frac{1}{2}\\left(\\mathbf{y}_i-\\mathbf{\\mu}\\right)^{\\top}\\mathbf{\\Sigma}^{-1}\\left(\\mathbf{y}_i-\\mathbf{\\mu}\\right)\\right\\}\\\\ &amp;= (2\\pi)^{-pN/2}|\\Sigma|^{-N/2}\\exp\\left\\{-\\frac{1}{2}tr\\left[\\sum_{i=1}^N\\left(\\mathbf{y}_i-\\mathbf{\\mu}\\right)^{\\top}\\mathbf{\\Sigma}^{-1}\\left(\\mathbf{y}_i-\\mathbf{\\mu}\\right)\\right]\\right\\}\\\\ &amp;= (2\\pi)^{-p N/2}|\\Sigma|^{-N/2}\\exp\\left\\{-\\frac{1}{2}tr\\left[\\left(\\mathbf{S}+N\\left(\\mathbf{\\mu}-\\hat{\\mathbf{\\mu}}\\right)\\left(\\mathbf{\\mu}-\\hat{\\mathbf{\\mu}}\\right)^{\\top}\\right)\\mathbf{\\Sigma}^{-1}\\right]\\right\\}\\\\ &amp;= (2\\pi)^{-p N/2}\\exp\\left\\{-\\frac{1}{2}\\left[\\left(vec\\left(\\mathbf{S}\\right)^{\\top}+N vec\\left(\\hat{\\mathbf{\\mu}}\\hat{\\mathbf{\\mu}}^{\\top}\\right)^{\\top}\\right)vec \\left(\\mathbf{\\Sigma}^{-1}\\right)\\right.\\right.\\\\ &amp;\\left.\\left.-2N\\hat{\\mathbf{\\mu}}^{\\top}vec\\left(\\mathbf{\\mu}^{\\top}\\mathbf{\\Sigma}^{-1}\\right)+N tr\\left(\\mathbf{\\mu}\\mathbf{\\mu}^{\\top}\\mathbf{\\Sigma}^{-1}\\right)+N\\log (|\\mathbf{\\Sigma}|)\\right]\\right\\}\\\\ \\end{align}\\] where the second line uses the trace operator (\\(tr\\)), and its invariability under cyclic permutation is used in the third line. In addition, we add and subtract \\(\\hat{\\mathbf{\\mu}}=\\frac{1}{N}\\sum_{i=1}^N\\mathbf{y}_i\\) in each parenthesis such that we get \\(\\mathbf{S}=\\sum_{i=1}^N\\left(\\mathbf{y}_i-\\hat{\\mathbf{\\mu}}\\right)\\left(\\mathbf{y}_i-\\hat{\\mathbf{\\mu}}\\right)^{\\top}\\). We get the fourth line after using some properties of the trace operator to introduce the vectorization operator (\\(vec\\)), and collecting terms. Then \\(h(\\mathbf{y})=(2\\pi)^{-pN/2}\\), \\(\\eta(\\mathbf{\\mu},\\mathbf{\\Sigma})^{\\top}=\\left[\\left(vec\\left(\\mathbf{\\Sigma}^{-1}\\right)\\right)^{\\top} \\ \\ \\left(vec\\left(\\mathbf{\\mu}^{\\top}\\mathbf{\\Sigma}^{-1}\\right)\\right)^{\\top}\\right]\\), \\(T(\\mathbf{y})=\\left[-\\frac{1}{2}\\left(vec\\left(\\mathbf{S}\\right)^{\\top}+N vec\\left(\\hat{\\mathbf{\\mu}}\\hat{\\mathbf{\\mu}}^{\\top}\\right)^{\\top}\\right) \\ \\ -N\\hat{\\mathbf{\\mu}}^{\\top}\\right]^{\\top}\\) and \\(C(\\mathbf{\\mu},\\mathbf{\\Sigma})=\\exp\\left\\{-\\frac{1}{2}\\left(tr\\left(\\mathbf{\\mu}\\mathbf{\\mu}^{\\top}\\mathbf{\\Sigma}^{-1}\\right)+\\log(|\\Sigma|)\\right)\\right\\}\\). References "],["sec42.html", "3.2 Conjugate prior to exponential family", " 3.2 Conjugate prior to exponential family Theorem 4.2.1 The prior distribution \\(\\pi(\\mathbf{\\theta})\\propto C(\\mathbf{\\theta})^{b_0}\\exp\\left\\{\\eta(\\mathbf{\\theta})^{\\top}\\mathbf{a}_0\\right\\}\\) is conjugate to the exponential family (equation (3.4)). Proof \\[\\begin{align} \\pi(\\mathbf{\\theta}|\\mathbf{y})&amp; \\propto C(\\mathbf{\\theta})^{b_0}\\exp\\left\\{\\eta(\\mathbf{\\theta})^{\\top}\\mathbf{a}_0\\right\\} \\times h(\\mathbf{y}) C(\\mathbf{\\theta})^N\\exp\\left\\{\\eta(\\mathbf{\\theta})^{\\top}\\mathbf{T}(\\mathbf{y})\\right\\}\\\\ &amp; \\propto C(\\mathbf{\\theta})^{N+b_0} \\exp\\left\\{\\eta(\\mathbf{\\theta})^{\\top}(\\mathbf{T}(\\mathbf{y})+\\mathbf{a}_0\\right\\}. \\end{align}\\] Observe that the posterior is in the exponential family, \\(\\pi(\\mathbf{\\theta}|\\mathbf{y})\\propto C(\\mathbf{\\theta})^{\\beta_n} \\exp\\left\\{\\eta(\\mathbf{\\theta})^{\\top}\\mathbf{\\alpha}_n\\right\\}\\), \\(\\beta_n=N+b_0\\) and \\(\\mathbf{\\alpha}_n=\\mathbf{T}(\\mathbf{y})+\\mathbf{a}_0\\). Remarks We see comparing the prior and the likelihood that \\(b_0\\) plays the role of a hypothetical sample size, and \\(\\mathbf{a}_0\\) plays the role of hypothetical sufficient statistics. This view helps the elicitation process. In addition, we stablished the result in the standard form of the exponential family. We can also stablish this result in the canonical form of the exponential family. Observe that given \\(\\mathbf{\\eta}=\\mathbf{\\eta}(\\mathbf{\\theta})\\) another way to get a prior for \\(\\mathbf{\\eta}\\) is to use the change of variables theorem given a bijective function. In the setting where there is a prior regular conjugate prior (Diaconis, Ylvisaker, et al. 1979) show that we obtain a posterior expectation of the sufficient statistics that is a weighted average between the prior expectation and the likelihood estimate. Examples: Theorem 4.2.1 Likelihood functions from discrete distributions The Poisson-gamma model Given a random sample \\(\\mathbf{y}=[y_1,y_2,\\dots,y_N]^{\\top}\\) from a Poisson distribution then a conjugate prior density for \\(\\lambda\\) has the form \\[\\begin{align} \\pi(\\lambda)&amp;\\propto \\left(\\exp(-\\lambda)\\right)^{b_0} \\exp\\left\\{a_0\\log(\\lambda)\\right\\}\\\\ &amp; = \\exp(-\\lambda b_0) \\lambda^{a_0}\\\\ &amp; = \\exp(-\\lambda \\beta_0) \\lambda^{\\alpha_0-1}. \\end{align}\\] This is the kernel of a gamma density in the rate parametrization, \\(G(\\alpha_0,\\beta_0)\\), \\(\\alpha_0=a_0+1\\) and \\(\\beta_0=b_0\\). 18 Then, a prior conjugate distribution for the Poisson likelihood is a gamma distribution. Taking into account that \\(\\sum_{i=1}^N y_i\\) is a sufficient statistic for the Poisson distribution, then we can think about \\(a_0\\) as the number of occurrences in \\(b_0\\) experiments. Observe that \\[\\begin{align} \\pi(\\lambda|\\mathbf{y})&amp;\\propto \\exp(-\\lambda \\beta_0) \\lambda^{\\alpha_0-1} \\times \\exp(-N\\lambda)\\lambda^{\\sum_{i=1}^Ny_i}\\\\ &amp;= \\exp(-\\lambda(N+\\beta_0)) \\lambda^{\\sum_{i=1}^Ny_i+\\alpha_0-1}. \\end{align}\\] As expected, this is the kernel of a gamma distribution, which means \\(\\lambda|\\mathbf{y}\\sim G(\\alpha_n,\\beta_n)\\), \\(\\alpha_n=\\sum_{i=1}^Ny_i+\\alpha_0\\) and \\(\\beta_n=N+\\beta_0\\). Observe that \\(\\alpha_0/\\beta_0\\) is the prior mean, and \\(\\alpha_0/\\beta_0^2\\) is the prior variance. Then, \\(\\alpha_0\\rightarrow 0\\) and \\(\\beta_0\\rightarrow 0\\) imply a non-informative prior such that the posterior mean converges to the maximum likelihood estimator \\(\\bar{y}=\\frac{\\sum_{i=1}^N y_i}{N}\\), \\[\\begin{align} \\mathbb{E}\\left[\\lambda|\\mathbf{y}\\right]&amp;=\\frac{\\alpha_n}{\\beta_n}\\\\ &amp;=\\frac{\\sum_{i=1}^Ny_i+\\alpha_0}{N+\\beta_0}\\\\ &amp;=\\frac{N\\bar{y}}{N+\\beta_0}+\\frac{\\alpha_0}{N+\\beta_0}. \\end{align}\\] The posterior mean is a weighted average between sample and prior information. This is a general result from regular conjugate priors (Diaconis, Ylvisaker, et al. 1979). Observe that \\(\\mathbb{E}\\left[\\lambda|\\mathbf{y}\\right]=\\bar{y}, \\lim N\\rightarrow\\infty\\). In addition, \\(\\alpha_0\\rightarrow 0\\) and \\(\\beta_0\\rightarrow 0\\) corresponds to \\(\\pi(\\lambda)\\propto \\frac{1}{\\lambda}\\), which is an improper prior. Improper priors have bad consequences on Bayes factors (hypothesis testing). In this setting, we can get analytical solutions for the marginal likelihood and the predictive distribution (see the health insurance example and exercise 3 in Chapter 1). The Bernoulli-beta model Given a random sample \\(\\mathbf{y}=[y_1,y_2,\\dots,y_N]^{\\top}\\) from a Bernoulli distribution then a conjugate prior density for \\(\\theta\\) has the form \\[\\begin{align} \\pi(\\theta)&amp;\\propto (1-\\theta)^{b_0} \\exp\\left\\{a_0\\log\\left(\\frac{\\theta}{1-\\theta}\\right)\\right\\}\\\\ &amp; = (1-\\theta)^{b_0-a_0}\\theta^{a_0}\\\\ &amp; = \\theta^{\\alpha_0-1}(1-\\theta)^{\\beta_0-1}. \\end{align}\\] This is the kernel of a beta density, \\(B(\\alpha_0,\\beta_0)\\), \\(\\alpha_0=a_0+1\\) and \\(\\beta_0=b_0-a_0+1\\). A prior conjugate distribution for the Bernoulli likelihood is a beta distribution. Given that \\(b_0\\) is the hypothetical sample size, and \\(a_0\\) is the hypothetical sufficient statistic, which is the number of successes, then \\(b_0-a_0\\) is the number of failures. This implies that \\(\\alpha_0\\) is the number of prior successes plus one, and \\(\\beta_0\\) is the number of prior failures plus one. Given that the mode of a beta distribuited random variable is \\(\\frac{\\alpha_0-1}{\\alpha_0+\\beta_0-2}=\\frac{a_0}{b_0}\\), then we have the a priori probability of success. Setting \\(\\alpha_0=1\\) and \\(\\beta_0=1\\), which implies a 0-1 uniform distribution, corresponds to a setting with 0 successes (and 0 failures) in 0 experiments. Observe that \\[\\begin{align} \\pi(\\theta|\\mathbf{y})&amp;\\propto \\theta^{\\alpha_0-1}(1-\\theta)^{\\beta_0-1} \\times \\theta^{\\sum_{i=1}^N y_i}(1-\\theta)^{N-\\sum_{i=1}^Ny_i}\\\\ &amp;= \\theta^{\\alpha_0+\\sum_{i=1}^N y_i-1}(1-\\theta)^{\\beta_0+N-\\sum_{i=1}^Ny_i-1}. \\end{align}\\] The posterior distribution is beta, \\(\\theta|\\mathbf{y}\\sim B(\\alpha_n,\\beta_n)\\), \\(\\alpha_n=\\alpha_0+\\sum_{i=1}^N y_i\\) and \\(\\beta_n=\\beta_0+N-\\sum_{i=1}^Ny_i\\), where the posterior mean \\(\\mathbf{E}[\\theta|\\mathbf{y}]=\\frac{\\alpha_n}{\\alpha_n+\\beta_n}=\\frac{\\alpha_0+N\\bar{y}}{\\alpha_0+\\beta_0+N}=\\frac{\\alpha_0+\\beta_0}{\\alpha_0+\\beta_0+N}\\frac{\\alpha_0}{\\alpha_0+\\beta_0}+\\frac{N}{\\alpha_0+\\beta_0+N}\\bar{y}\\). The posterior mean is a weighted average between the prior mean and the maximum likelihood estimate. El marginal likelihood in this setting is \\[\\begin{align} p(\\mathbf{y})=&amp;\\int_{0}^1 \\frac{\\theta^{\\alpha_0-1}(1-\\theta)^{\\beta_0-1}}{B(\\alpha_0,\\beta_0)}\\times \\theta^{\\sum_{i=1}^N y_i}(1-\\theta)^{N-\\sum_{i=1}^N y_i}d\\theta\\\\ =&amp; \\frac{B(\\alpha_n,\\beta_n)}{B(\\alpha_0,\\beta_0)}, \\end{align}\\] where \\(B(\\cdot ,\\cdot)\\) is the beta function. In addition, the predictive density is \\[\\begin{align} p(Y_0|\\mathbf{y})&amp;=\\int_0^1 \\theta^{y_0}(1-\\theta)^{1-y_0}\\times \\frac{\\theta^{\\alpha_n-1}(1-\\theta)^{\\beta_n-1}}{B(\\alpha_n,\\beta_n)}d\\theta\\\\ &amp;=\\frac{B(\\alpha_n+y_0,\\beta_n+1-y_0)}{B(\\alpha_n,\\beta_n)}\\\\ &amp;=\\frac{\\Gamma(\\alpha_n+\\beta_n)\\Gamma(\\alpha_n+y_0)\\Gamma(\\beta_n+1-y_0)}{\\Gamma(\\alpha_n+\\beta_n+1)\\Gamma(\\alpha_n)\\Gamma(\\beta_n)}\\\\ &amp;=\\begin{Bmatrix} \\frac{\\alpha_n}{\\alpha_n+\\beta_n}, &amp; y_0=1\\\\ \\frac{\\beta_n}{\\alpha_n+\\beta_n}, &amp; y_0=0\\\\ \\end{Bmatrix}. \\end{align}\\] This is a Bernoulli distribution with probability of success equal to \\(\\frac{\\alpha_n}{\\alpha_n+\\beta_n}\\). The multinomial-Dirichlet model Given a random sample \\(\\mathbf{y}=[y_1,y_2,\\dots,y_N]^{\\top}\\) from a multinomial distribution then a conjugate prior density for \\(\\mathbf{\\theta}=\\left[\\theta_1,\\theta_2,\\dots,\\theta_m\\right]\\) has the form \\[\\begin{align} \\pi(\\mathbf{\\theta})&amp;\\propto \\theta_m^{b_0} \\exp\\left\\{\\mathbf{\\eta}(\\mathbf{\\theta})^{\\top}\\mathbf{a}_0\\right\\}\\\\ &amp; = \\prod_{l=1}^{m-1}\\theta_l^{a_{0l}}\\theta_m^{b_0-\\sum_{l=1}^{m-1}a_{0l}}\\\\ &amp; = \\prod_{l=1}^{m}\\theta_l^{\\alpha_{0l}-1}, \\end{align}\\] where \\(\\mathbf{\\eta}(\\mathbf{\\theta})=\\left[\\log\\left(\\frac{\\theta_1}{\\theta_m}\\right),\\dots,\\log\\left(\\frac{\\theta_{m-1}}{\\theta_m}\\right)\\right]\\), \\(\\mathbf{a}_0=\\left[a_{01},\\dots,a_{am-1}\\right]^{\\top}\\), \\(\\mathbf{\\alpha}_0=\\left[\\alpha_{01},\\alpha_{02},\\dots,\\alpha_{0m}\\right]\\), \\(\\alpha_{0l}=a_{0l}+1\\), \\(l=1,2,\\dots,m-1\\) and \\(\\alpha_{0m}=b_0-\\sum_{l=1}^{m-1} a_{0l}+1\\). This is the kernel of a Dirichlet distribution, that is, the prior distribution is \\(D(\\mathbf{\\alpha}_0)\\). Observe that \\(a_{0l}\\) is the number of hypothetical number of times outcome \\(l\\) is observed over the hypothetical \\(b_0\\) trials. Setting \\(\\alpha_{0l}=1\\), that is a uniform distribution over the open standard simplex, implicitly we set \\(a_{0l}=0\\), which means that there are 0 occurrences of category \\(l\\) in \\(b_0=0\\) experiments. The posterior distribution of the multinomial-Dirichlet model is given by \\[\\begin{align} \\pi(\\mathbf{\\theta}|\\mathbf{y})&amp;\\propto \\prod_{l=1}^m \\theta_l^{\\alpha_{0l}-1}\\times\\prod_{l=1}^m \\theta_l^{\\sum_{i=1}^{N} y_{il}}\\\\ &amp;=\\prod_{l=1}^m \\theta_l^{\\alpha_{0l}+\\sum_{i=1}^{N} y_{il}-1} \\end{align}\\] This is the kernel of a Dirichlet distribution \\(D(\\mathbf{\\alpha}_n)\\), \\(\\mathbf{\\alpha}_n=\\left[\\alpha_{n1},\\alpha_{n2},\\dots,\\alpha_{nm}\\right]\\), \\(\\alpha_{nl}=\\alpha_{0l}+\\sum_{i=1}^{N}y_{il}\\), \\(l=1,2,\\dots,m\\). Observe that \\[\\begin{align} \\mathbb{E}[\\theta_{j}|\\mathbf{y}]&amp;=\\frac{\\alpha_{nj}}{\\sum_{l=1}^m \\left[\\alpha_{0l}+\\sum_{i=1}^N y_{il}\\right]}\\\\ &amp;=\\frac{\\sum_{l=1}^m \\alpha_{0l}}{\\sum_{l=1}^m \\left[\\alpha_{0l}+\\sum_{i=1}^N y_{il}\\right]}\\frac{\\alpha_{0j}}{\\sum_{l=1}^m \\alpha_{0l}}+\\frac{\\sum_{l=1}^m\\sum_{i=1}^N y_{il}}{\\sum_{l=1}^m \\left[\\alpha_{0l}+\\sum_{i=1}^N y_{il}\\right]}\\frac{\\sum_{i=1}^N y_{ij}}{\\sum_{l=1}^m\\sum_{i=1}^N y_{il}}. \\end{align}\\] We have again that the posterior mean is a weighted average between the prior mean and the maximum likelihood estimate. The marginal likelihood is \\[\\begin{align} p(\\mathbf{y})&amp;=\\int_{\\mathbf{\\Theta}}\\frac{\\prod_{l=1}^m \\theta_l^{\\alpha_{0l}-1}}{B(\\mathbf{\\alpha}_0)}\\times \\prod_{i=1}^N\\frac{n!}{\\prod_{l=1}^m y_{il}}\\prod_{l=1}^m \\theta_{l}^{y_{il}}d\\mathbf{\\theta}\\\\ &amp;=\\frac{N\\times n!}{B(\\mathbf{\\alpha}_0)\\prod_{i=1}^N\\prod_{l=1}^m y_{il}!}\\int_{\\mathbf{\\Theta}} \\prod_{l=1}^m \\theta_l^{\\alpha_{0l}+\\sum_{i=1}^N y_{il}-1} d\\mathbf{\\theta}\\\\ &amp;=\\frac{N\\times n!}{B(\\mathbf{\\alpha}_0)\\prod_{i=1}^N\\prod_{l=1}^m y_{il}!}B(\\mathbf{\\alpha}_n)\\\\ &amp;=\\frac{N\\times n! \\Gamma\\left(\\sum_{l=1}^n \\alpha_{0l}\\right)}{\\Gamma\\left(\\sum_{l=1}^n \\alpha_{0l}+N\\times n\\right)}\\prod_{l=1}^m \\frac{\\Gamma\\left( \\alpha_{nl}\\right)}{\\Gamma\\left(\\alpha_{0l}\\right)\\prod_{i=1}^N y_{il}!}, \\end{align}\\] where \\(B(\\mathbf{\\alpha})=\\frac{\\prod_{l=1}^m\\Gamma(\\alpha_l)}{\\Gamma\\left(\\sum_{l=1}^m \\alpha_l\\right)}\\). Following similar steps we get the predictive density \\[\\begin{align} p(Y_0|\\mathbf{y})&amp;=\\frac{ n! \\Gamma\\left(\\sum_{l=1}^n \\alpha_{nl}\\right)}{\\Gamma\\left(\\sum_{l=1}^n \\alpha_{nl}+ n\\right)}\\prod_{l=1}^m \\frac{\\Gamma\\left( \\alpha_{nl}+y_{0l}\\right)}{\\Gamma\\left(\\alpha_{nl}\\right) y_{0l}!}. \\end{align}\\] This is a Dirichlet-multinomial distribution with parameters \\(\\mathbf{\\alpha}_n\\). Likelihood functions from continuous distributions The normal-normal/inverse-gamma model Given a random sample \\(\\mathbf{y}=[y_1,y_2,\\dots,y_N]^{\\top}\\) from a normal distribution, then the conjugate prior density has the form \\[\\begin{align} \\pi(\\mu,\\sigma^2)&amp;\\propto \\exp\\left\\{b_0\\left(-\\frac{\\mu^2}{2\\sigma^2}-\\frac{\\log \\sigma^2}{2}\\right)\\right\\}\\exp\\left\\{a_{01}\\frac{\\mu}{\\sigma^2}-a_{02}\\frac{1}{\\sigma^2}\\right\\}\\\\ &amp;=\\exp\\left\\{b_0\\left(-\\frac{\\mu^2}{2\\sigma^2}-\\frac{\\log \\sigma^2}{2}\\right)\\right\\}\\exp\\left\\{a_{01}\\frac{\\mu}{\\sigma^2}-a_{02}\\frac{1}{\\sigma^2}\\right\\}\\exp\\left\\{-\\frac{a_{01}^2}{2\\sigma^2b_0}\\right\\}\\exp\\left\\{\\frac{a_{01}^2}{2\\sigma^2b_0}\\right\\}\\\\ &amp;=\\exp\\left\\{-\\frac{b_0}{2\\sigma^2}\\left(\\mu-\\frac{a_{01}}{b_0}\\right)^2\\right\\}\\left(\\frac{1}{\\sigma^2}\\right)^{\\frac{b_0+1-1}{2}}\\exp\\left\\{\\frac{1}{\\sigma^2}\\frac{-2b_0a_{02}+a_{01}^2}{2b_0}\\right\\}\\\\ &amp;=\\underbrace{\\left(\\frac{1}{\\sigma^2}\\right)^{\\frac{1}{2}}\\exp\\left\\{-\\frac{b_0}{2\\sigma^2}\\left(\\mu-\\frac{a_{01}}{b_0}\\right)^2\\right\\}}_{1}\\underbrace{\\left(\\frac{1}{\\sigma^2}\\right)^{\\frac{b_0-1}{2}}\\exp\\left\\{-\\frac{1}{\\sigma^2}\\frac{2b_0a_{02}-a_{01}^2}{2b_0}\\right\\}}_{2}. \\end{align}\\] The first part is the kernel of a normal density with mean \\(\\mu_0=a_{01}/\\beta_0\\) and variance \\(\\sigma^2/\\beta_0\\), \\(\\beta_0=b_0\\) that is, \\(\\mu|\\sigma^2\\sim N(\\mu_0,\\sigma^2/\\beta_0)\\). The second part is the kernel of an inverse gamma density with shape parameter \\(\\alpha_0/2=\\frac{\\beta_0-3}{2}\\), and scale parameter \\(\\delta_0/2=\\frac{2\\beta_0a_{02}-a_{01}^2}{2\\beta_0}\\), \\(\\sigma^2\\sim IG(\\alpha_0/2,\\delta_0/2)\\). Observe that \\(b_0=\\beta_0\\) is the hypothetical sample size, and \\(a_{01}\\) is the hypothetical sum of prior observations, then, it makes sense that \\(a_{01}/\\beta_0\\) and \\(\\sigma^2/\\beta_0\\) are the prior mean and variance, respectively. Therefore, the posterior distribution is also a normal-inverse gamma distribution, \\[\\begin{align} \\pi(\\mu,\\sigma^2|\\mathbf{y})&amp;\\propto \\left(\\frac{1}{\\sigma^2}\\right)^{1/2}\\exp\\left\\{-\\frac{\\beta_0}{2\\sigma^2}(\\mu-\\mu_0)^2\\right\\}\\left(\\frac{1}{\\sigma^2}\\right)^{\\alpha_0/2+1}\\exp\\left\\{-\\frac{\\delta_0}{2\\sigma^2}\\right\\}\\\\ &amp;\\times(\\sigma^2)^{-N/2}\\exp\\left\\{-\\frac{1}{2\\sigma^2}\\sum_{i=1}^N (y_i-\\mu)^2\\right\\}\\\\ &amp; = \\left(\\frac{1}{\\sigma^2}\\right)^{1/2}\\exp\\left\\{-\\frac{1}{2\\sigma^2}\\left(\\beta_0(\\mu-\\mu_0)^2+\\sum_{i=1}^N (y_i-\\bar{y})^2+N(\\mu-\\bar{y})^2+\\delta_0\\right)\\right\\}\\\\ &amp; \\left(\\frac{1}{\\sigma^2}\\right)^{\\frac{\\alpha_0+N}{2}+1} + \\frac{(\\beta_0\\mu_0+N\\bar{y})^2}{\\beta_0+N} - \\frac{(\\beta_0\\mu_0+N\\bar{y})^2}{\\beta_0+N}\\\\ &amp; = \\underbrace{\\left(\\frac{1}{\\sigma^2}\\right)^{1/2}\\exp\\left\\{-\\frac{1}{2\\sigma^2}\\left((\\beta_0+N)\\left(\\mu-\\left(\\frac{\\beta_0\\mu_0+N\\bar{y}}{\\beta_0+N}\\right)\\right)^2\\right)\\right\\}}_{1}\\\\ &amp; \\times \\underbrace{\\left(\\frac{1}{\\sigma^2}\\right)^{\\frac{\\alpha_0+N}{2}+1}\\exp\\left\\{-\\frac{1}{2\\sigma^2}\\left(\\sum_{i=1}^N (y_i-\\bar{y})^2+\\delta_0+\\frac{\\beta_0N}{\\beta_0+N}(\\bar{y}-\\mu_0)^2\\right)\\right\\}}_{2}. \\end{align}\\] The first term is the kernel of a normal density, \\(\\mu|\\sigma^2,\\mathbf{y}\\sim N \\left(\\mu_n, \\sigma_n^2\\right)\\), where \\(\\mu_n=\\frac{\\beta_0\\mu_0+N\\bar{y}}{\\beta_0+N}\\) and \\(\\sigma_n^2=\\frac{\\sigma^2}{\\beta_n}\\), \\(\\beta_n=\\beta_0+N\\). The second term is the kernel of an inverse gamma density, \\(\\sigma^2|\\mathbf{y}\\sim IG(\\alpha_n/2,\\delta_n/2)\\) where \\(\\alpha_n=\\alpha_0+N\\) and \\(\\delta_n=\\sum_{i=1}^N (y_i-\\bar{y})^2+\\delta_0+\\frac{\\beta_0N}{\\beta_0+N}(\\bar{y}-\\mu_0)^2\\). Observe that the posterior mean is a weighted average between prior and sample information. The weights depends on the sample sizes (\\(\\beta_0\\) and \\(N\\)). The marginal posterior for \\(\\sigma^2\\) is inverse gamma with shape and scale parameters \\(\\alpha_n/2\\) and \\(\\delta_n/2\\), respectively. The marginal posterior of \\(\\mu\\) is \\[\\begin{align} \\pi(\\mu|\\mathbf{y})&amp;\\propto \\int_{0}^{\\infty}\\left\\{ \\left(\\frac{1}{\\sigma^2}\\right)^{\\frac{\\alpha_n+1}{2}+1}\\exp\\left\\{-\\frac{1}{2\\sigma^2}(\\beta_n(\\mu-\\mu_n)^2+\\delta_n)\\right\\}\\right\\}d\\sigma^2\\\\ &amp;=\\frac{\\Gamma\\left(\\frac{\\alpha_n+1}{2}\\right)}{\\left[\\frac{\\beta_n(\\mu-\\mu_n)^2+\\delta_n}{2}\\right]^{\\frac{\\alpha_n+1}{2}}}\\\\ &amp;\\propto \\left[\\frac{\\beta_n(\\mu-\\mu_n)^2+\\delta_n}{2}\\right]^{-\\frac{\\alpha_n+1}{2}}\\left(\\frac{\\delta_n}{\\delta_n}\\right)^{-\\frac{\\alpha_n+1}{2}}\\\\ &amp;\\propto \\left[\\frac{\\alpha_n\\beta_n(\\mu-\\mu_n)^2}{\\alpha_n\\delta_n}+1\\right]^{-\\frac{\\alpha_n+1}{2}}, \\end{align}\\] where the second line due to having the kernel of an inverse gamma density with parameters \\((\\alpha_n+1)/2\\) and \\(-\\frac{1}{2\\sigma^2}(\\beta_n(\\mu-\\mu_n)^2+\\delta_n)\\). This is the kernel of a Student’s t distribution, \\(\\mu|\\mathbf{y}\\sim t(\\mu_n,\\delta_n/\\beta_n\\alpha_n,\\alpha_n)\\), where \\(\\mathbb{E}[\\mu|\\mathbf{y}]=\\mu_n\\) and \\(Var[\\mu|\\mathbf{y}]=\\frac{\\alpha_n}{\\alpha_n-2}\\left(\\frac{\\delta_n}{\\beta_n\\alpha_n}\\right)=\\frac{\\delta_n}{(\\alpha_n-2)\\beta_n}\\), \\(\\alpha_n&gt;2\\). Observe that the marginal posterior distribution for \\(\\mu\\) has heavier tails than the conditional posterior distribution due to incorporating uncertainty regarding \\(\\sigma^2\\). The marginal likelihood is \\[\\begin{align} p(\\mathbf{y})&amp;=\\int_{-\\infty}^{\\infty}\\int_{0}^{\\infty}\\left\\{ (2\\pi\\sigma^2/\\beta_0)^{-1/2}\\exp\\left\\{-\\frac{1}{2\\sigma^2/\\beta_0}(\\mu-\\mu_0)^2\\right\\}\\frac{(\\delta_0/2)^{\\alpha_0/2}}{\\Gamma(\\alpha_0/2)}\\left(\\frac{1}{\\sigma^2}\\right)^{\\alpha_0/2+1}\\right.\\\\ &amp;\\times\\left.\\exp\\left\\{-\\frac{\\delta_0}{2\\sigma^2}\\right\\}(2\\pi\\sigma^2)^{-N/2}\\exp\\left\\{-\\frac{1}{2\\sigma^2}\\sum_{i=1}^N(y_i-\\mu)^2\\right\\}\\right\\}d\\sigma^2d\\mu\\\\ &amp;=\\frac{(\\delta_0/2)^{\\alpha_0/2}}{\\Gamma(\\alpha_0/2)}(2\\pi)^{-\\left(\\frac{N+1}{2}\\right)}\\beta_0^{1/2}\\int_{-\\infty}^{\\infty}\\int_{0}^{\\infty}\\left\\{\\left(\\frac{1}{\\sigma^2}\\right)^{\\frac{\\alpha_0+N+1}{2}+1}\\right.\\\\ &amp;\\times\\left.\\exp\\left\\{-\\frac{1}{2\\sigma^2}(\\beta_0(\\mu-\\mu_0)^2+\\sum_{i=1}^N (y_i-\\mu)^2+\\delta_0)\\right\\}\\right\\}d\\sigma^2d\\mu\\\\ &amp;=\\frac{(\\delta_0/2)^{\\alpha_0/2}}{\\Gamma(\\alpha_0/2)}(2\\pi)^{-\\left(\\frac{N+1}{2}\\right)}\\beta_0^{1/2}\\Gamma\\left(\\frac{N+1+\\alpha_0}{2}\\right)\\\\ &amp;\\times \\int_{-\\infty}^{\\infty} \\left[\\frac{\\beta_0(\\mu-\\mu_0)^2+\\sum_{i=1}^N(y_i-\\mu)^2+\\delta_0}{2}\\right]^{-\\frac{\\alpha_0+N+1}{2}}d\\mu\\\\ &amp;=\\frac{(\\delta_0/2)^{\\alpha_0/2}}{\\Gamma(\\alpha_0/2)}(2\\pi)^{-\\left(\\frac{N+1}{2}\\right)}\\beta_0^{1/2}\\Gamma\\left(\\frac{N+1+\\alpha_0}{2}\\right)\\\\ &amp;\\times \\int_{-\\infty}^{\\infty} \\left[\\frac{\\beta_n(\\mu-\\mu_n)^2+\\delta_n}{2}\\right]^{-\\frac{\\alpha_n+1}{2}}d\\mu\\left(\\frac{\\delta_n/2}{\\delta_n/2}\\right)^{-\\frac{\\alpha_n+1}{2}}\\\\ &amp;=\\frac{(\\delta_0/2)^{\\alpha_0/2}}{\\Gamma(\\alpha_0/2)}(2\\pi)^{-\\left(\\frac{N+1}{2}\\right)}\\beta_0^{1/2}\\Gamma\\left(\\frac{\\alpha_n+1}{2}\\right)\\left(\\frac{\\delta_n}{2}\\right)^{-\\frac{\\alpha_n+1}{2}}\\frac{\\left(\\frac{\\delta_n\\pi}{\\beta_n}\\right)^{1/2}\\Gamma\\left(\\frac{\\alpha_n}{2}\\right)}{\\Gamma\\left(\\frac{\\alpha_n+1}{2}\\right)}\\\\ &amp;=\\frac{\\Gamma\\left(\\frac{\\alpha_n}{2}\\right)}{\\Gamma\\left(\\frac{\\alpha_0}{2}\\right)}\\frac{(\\delta_0/2)^{\\alpha_0/2}}{(\\delta_n/2)^{\\alpha_n/2}}\\left(\\frac{\\beta_0}{\\beta_n}\\right)^{1/2}(\\pi)^{-N/2}, \\end{align}\\] where we take into account that \\(\\int_{-\\infty}^{\\infty} \\left[\\frac{\\beta_n(\\mu-\\mu_n)^2+\\delta_n}{2}\\right]^{-\\frac{\\alpha_n+1}{2}}d\\mu\\left(\\frac{\\delta_n/2}{\\delta_n/2}\\right)^{-\\frac{\\alpha_n+1}{2}}=\\int_{-\\infty}^{\\infty} \\left[\\frac{\\beta_n\\alpha_n(\\mu-\\mu_n)^2}{\\delta_n\\alpha_n}+1\\right]^{-\\frac{\\alpha_n+1}{2}}d\\mu\\left(\\frac{\\delta_n}{2}\\right)^{-\\frac{\\alpha_n+1}{2}}\\). The term in the integral is the kernel of a Student’s t density, this means that the integral is equal to \\(\\frac{\\left(\\frac{\\delta_n\\pi}{\\beta_n}\\right)^{1/2}\\Gamma\\left(\\frac{\\alpha_n}{2}\\right)}{\\Gamma\\left(\\frac{\\alpha_n+1}{2}\\right)}\\). The predictive density is \\[\\begin{align} \\pi(Y_0|\\mathbf{y})&amp;\\propto\\int_{-\\infty}^{\\infty}\\int_0^{\\infty}\\left\\{ \\left(\\frac{1}{\\sigma^2}\\right)^{1/2}\\exp\\left\\{-\\frac{1}{2\\sigma^2}(y_0-\\mu)^2\\right\\}\\left(\\frac{1}{\\sigma^2}\\right)^{1/2}\\exp\\left\\{-\\frac{\\beta_n}{2\\sigma^2}(\\mu-\\mu_n)^2\\right\\}\\right.\\\\ &amp;\\times \\left.\\left(\\frac{1}{\\sigma^2}\\right)^{\\alpha_n/2+1}\\exp\\left\\{-\\frac{\\delta_n}{2\\sigma^2}\\right\\}\\right\\}d\\sigma^2d\\mu\\\\ &amp;=\\int_{-\\infty}^{\\infty}\\int_0^{\\infty}\\left\\{ \\left(\\frac{1}{\\sigma^2}\\right)^{\\frac{\\alpha_n+2}{2}+1}\\exp\\left\\{-\\frac{1}{2\\sigma^2}((y_0-\\mu)^2+\\beta_n(\\mu-\\mu_n)^2+\\delta_n)\\right\\}\\right\\}d\\sigma^2d\\mu\\\\ &amp;\\propto\\int_{-\\infty}^{\\infty}\\left[\\beta_n(\\mu-\\mu_n)^2+(y_0-\\mu)^2+\\delta_n\\right]^{-\\left(\\frac{\\alpha_n}{2}+1\\right)}d\\mu\\\\ &amp;=\\int_{-\\infty}^{\\infty}\\left[(\\beta_n+1)\\left(\\mu-\\left(\\frac{\\beta_n\\mu_n+y_0}{\\beta_n+1}\\right)\\right)^2+\\frac{\\beta_n(y_0-\\mu_n)^2}{\\beta_n+1}+\\delta_n\\right]^{-\\left(\\frac{\\alpha_n}{2}+1\\right)}d\\mu\\\\ &amp;=\\int_{-\\infty}^{\\infty}\\left[1+\\frac{(\\beta_n+1)^2\\left(\\mu-\\left(\\frac{\\beta_n\\mu_n+y_0}{\\beta_n+1}\\right)\\right)^2}{\\beta_n(y_0-\\mu_n)^2+(\\beta_n+1)\\delta_n}\\right]^{-\\left(\\frac{\\alpha_n}{2}+1\\right)}d\\mu\\\\ &amp;\\times\\left(\\frac{\\beta_n(y_0-\\mu_n)^2+(\\beta_n+1)\\delta_n}{\\beta_n+1}\\right)^{-\\left(\\frac{\\alpha_n}{2}+1\\right)}\\\\ &amp;\\propto\\left(\\frac{\\beta_n(y_0-\\mu_n)^2+(\\beta_n+1)\\delta_n}{(\\beta_n+1)^2(\\alpha_n+1)}\\right)^{\\frac{1}{2}}\\left(\\frac{\\beta_n(y_0-\\mu_n)^2+(\\beta_n+1)\\delta_n}{\\beta_n+1}\\right)^{-\\left(\\frac{\\alpha_n}{2}+1\\right)}\\\\ &amp;\\propto (\\beta_n(y_0-\\mu_n)^2+(\\beta_n+1)\\delta_n)^{\\left(\\frac{\\alpha_n+1}{2}\\right)}\\\\ &amp;\\propto\\left[1+\\frac{\\beta_n\\alpha_n}{(\\beta_n+1)\\delta_n\\alpha_n}(y_0-\\mu_n)^2\\right]^{-\\left(\\frac{\\alpha_n+1}{2}\\right)}, \\end{align}\\] where we have that \\(\\left[1+\\frac{(\\beta_n+1)^2\\left(\\mu-\\left(\\frac{\\beta_n\\mu_n+y_0}{\\beta_n+1}\\right)\\right)^2}{\\beta_n(y_0-\\mu_n)^2+(\\beta_n+1)\\delta_n}\\right]^{-\\left(\\frac{\\alpha_n}{2}+1\\right)}\\) is the kernel of a Student’s t density with degrees of freedom \\(\\alpha_n+1\\) and scale \\(\\frac{\\beta_n(y_0-\\mu_n)^2+(\\beta_n+1)\\delta_n}{(\\beta_n+1)^2(\\alpha_n+1)}\\). The last expression is the kernel of a Student’s t density, that is, \\(Y_0|\\mathbf{y}\\sim t\\left(\\mu_n,\\frac{(\\beta_n+1)\\delta_n}{\\beta_n\\alpha_n},\\alpha_n\\right)\\). The multivariate normal-normal/inverse-Wishart model We show in the subsection 3.1 that the multivariate normal distribution is in the exponential family where \\(h(\\mathbf{y})=(2\\pi)^{-pN/2}\\), \\(\\eta(\\mathbf{\\mu},\\mathbf{\\Sigma})^{\\top}=\\left[\\left(vec\\left(\\mathbf{\\Sigma}^{-1}\\right)\\right)^{\\top} \\ \\ \\left(vec\\left(\\mathbf{\\mu}^{\\top}\\mathbf{\\Sigma}^{-1}\\right)\\right)^{\\top}\\right]\\), \\(T(\\mathbf{y})=\\left[-\\frac{1}{2}\\left(vec\\left(\\mathbf{S}\\right)^{\\top}+N vec\\left(\\hat{\\mathbf{\\mu}}\\hat{\\mathbf{\\mu}}^{\\top}\\right)^{\\top}\\right) \\ \\ -N\\hat{\\mathbf{\\mu}}^{\\top}\\right]^{\\top}\\) and \\(C(\\mathbf{\\mu},\\mathbf{\\Sigma})=\\exp\\left\\{-\\frac{1}{2}\\left(tr\\left(\\mathbf{\\mu}\\mathbf{\\mu}^{\\top}\\mathbf{\\Sigma}^{-1}\\right)+\\log(|\\Sigma|)\\right)\\right\\}\\). Then, its conjugate prior distribution should have the form \\[\\begin{align} \\pi(\\mathbf{\\mu},\\mathbf{\\Sigma})&amp;\\propto \\exp\\left\\{-\\frac{b_0}{2}\\left(tr\\left(\\mathbf{\\mu}\\mathbf{\\mu}^{\\top}\\mathbf{\\Sigma}^{-1}\\right)+\\log(|\\Sigma|)\\right)\\right\\}\\\\ &amp;\\times \\exp\\left\\{\\mathbf{a}_{01}^{\\top} vec\\left(\\mathbf{\\Sigma}^{-1}\\right)+\\mathbf{a}_{02}^{\\top}vec\\left(\\mathbf{\\mu}^{\\top}\\mathbf{\\Sigma}^{-1}\\right)\\right\\}\\\\ &amp;=|\\Sigma|^{-b_0/2}\\exp\\left\\{-\\frac{b_0}{2}\\left(tr\\left(\\mathbf{\\mu}^{\\top}\\mathbf{\\Sigma}^{-1}\\mathbf{\\mu}\\right)\\right)+tr\\left(\\mathbf{a}_{02}^{\\top}\\mathbf{\\Sigma}^{-1}\\mathbf{\\mu}\\right)\\right\\}\\\\ &amp;\\times \\exp\\left\\{\\mathbf{a}_{01}^{\\top} vec\\left(\\mathbf{\\Sigma}^{-1}\\right)+\\frac{\\mathbf{a}_{02}^{\\top}\\mathbf{\\Sigma}^{-1}\\mathbf{a}_{02}}{2b_0}-\\frac{\\mathbf{a}_{02}^{\\top}\\mathbf{\\Sigma}^{-1}\\mathbf{a}_{02}}{2b_0}\\right\\}\\\\ &amp;=|\\Sigma|^{-b_0/2}\\exp\\left\\{-\\frac{b_0}{2}\\left(\\mathbf{\\mu}-\\frac{\\mathbf{a}_{02}}{b_0}\\right)^{\\top}\\mathbf{\\Sigma}^{-1}\\left(\\mathbf{\\mu}-\\frac{\\mathbf{a}_{02}}{b_0}\\right)\\right\\}\\\\ &amp;\\times \\exp\\left\\{-\\frac{1}{2}tr\\left(\\left(\\mathbf{A}_{01}-\\frac{\\mathbf{a}_{02}\\mathbf{a}_{02}^{\\top}}{b_0}\\right)\\mathbf{\\Sigma}^{-1}\\right)\\right\\}\\\\ &amp;=\\underbrace{|\\Sigma|^{-1/2}\\exp\\left\\{-\\frac{b_0}{2}\\left(\\mathbf{\\mu}-\\frac{\\mathbf{a}_{02}}{b_0}\\right)^{\\top}\\mathbf{\\Sigma}^{-1}\\left(\\mathbf{\\mu}-\\frac{\\mathbf{a}_{02}}{b_0}\\right)\\right\\}}_1\\\\ &amp;\\times \\underbrace{|\\Sigma|^{-(\\alpha_0+p+1)/2}\\exp\\left\\{-\\frac{1}{2}tr\\left(\\left(\\mathbf{A}_{01}-\\frac{\\mathbf{a}_{02}\\mathbf{a}_{02}^{\\top}}{b_0}\\right)\\mathbf{\\Sigma}^{-1}\\right)\\right\\}}_2, \\end{align}\\] where \\(b_0\\) is the hypothetical sample size, and \\(\\mathbf{a}_{01}\\) and \\(\\mathbf{a}_{02}\\) are \\(p^2\\) and \\(p\\) dimensional vectors of prior sufficient statistics, and \\(\\mathbf{a}_{01}=-\\frac{1}{2}vec(\\mathbf{A}_{01})\\) such that \\(\\mathbf{A}_{01}\\) is a \\(p\\times p\\) positive semi-definite matrix. Setting \\(b_0=1+\\alpha_0+p+1\\) we have that the first part in the last expression is the kernel of a multivariate normal density with mean \\(\\mathbf{\\mu}_0=\\mathbf{a}_{02}/b_0\\) and covariance \\(\\frac{\\mathbf{\\Sigma}}{b_0}\\), that is, \\(\\mathbf{\\mu}|\\mathbf{\\Sigma}\\sim N_p\\left(\\mathbf{\\mu}_0,\\frac{\\mathbf{\\Sigma}}{\\beta_0}\\right)\\), \\(b_0=\\beta_0\\). It makes sense these hyperparameters because \\(\\mathbf{a}_{02}\\) is the hypothetical sum of prior observations and \\(b_0\\) is the hypothetical prior sample size. On the other hand, the second expression in the last line is the kernel of a Inverse-Wishart distribution with scale matrix \\(\\mathbf{\\Psi}_0=\\left(\\mathbf{A}_{01}-\\frac{\\mathbf{a}_{02}\\mathbf{a}_{02}^{\\top}}{b_0}\\right)\\) and degrees of freedom \\(\\alpha_0\\), that is, \\(\\mathbf{\\Sigma}\\sim IW_p(\\mathbf{\\Psi}_0,\\alpha_0)\\). Observe that \\(\\mathbf{\\Psi}_0\\) has the same structure as the first part of the sufficient statistics in \\(T(\\mathbf{y})\\), just that it should be understood as coming from prior hypothetical observations. Therefore, the prior distribution in this setting is normal/inverse-Wishart, and given conjugacy, the posterior distribution is in the same family. \\[\\begin{align} \\pi(\\mathbf{\\mu},\\mathbf{\\Sigma}|\\mathbf{Y})&amp;\\propto (2\\pi)^{-p N/2}|\\Sigma|^{-N/2}\\exp\\left\\{-\\frac{1}{2}tr\\left[\\left(\\mathbf{S}+N\\left(\\mathbf{\\mu}-\\hat{\\mathbf{\\mu}}\\right)\\left(\\mathbf{\\mu}-\\hat{\\mathbf{\\mu}}\\right)^{\\top}\\right)\\mathbf{\\Sigma}^{-1}\\right]\\right\\}\\\\ &amp;\\times |\\mathbf{\\Sigma}|^{-1/2}\\exp\\left\\{-\\frac{\\beta_0}{2}tr\\left[(\\mathbf{\\mu}-\\mathbf{\\mu}_0)(\\mathbf{\\mu}-\\mathbf{\\mu}_0)^{\\top}\\mathbf{\\Sigma}^{-1}\\right]\\right\\}|\\mathbf{\\Sigma}|^{-(\\alpha_0+p+1)/2}\\exp\\left\\{-\\frac{1}{2}tr(\\mathbf{\\Psi}_0\\mathbf{\\Sigma}^{-1})\\right\\}. \\end{align}\\] Taking into account that \\[\\begin{align} N\\left(\\mathbf{\\mu}-\\hat{\\mathbf{\\mu}}\\right)\\left(\\mathbf{\\mu}-\\hat{\\mathbf{\\mu}}\\right)^{\\top}+\\beta_0\\left(\\mathbf{\\mu}-\\mathbf{\\mu}_0\\right)\\left(\\mathbf{\\mu}-\\mathbf{\\mu}_0\\right)^{\\top}&amp;=(N+\\beta_0)\\left(\\mathbf{\\mu}-\\mathbf{\\mu}_n\\right)\\left(\\mathbf{\\mu}-\\mathbf{\\mu}_n\\right)^{\\top}\\\\ &amp;+\\frac{N\\beta_0}{N+\\beta_0}\\left(\\hat{\\mathbf{\\mu}}-\\mathbf{\\mu}_0\\right)\\left(\\hat{\\mathbf{\\mu}}-\\mathbf{\\mu}_0\\right)^{\\top}, \\end{align}\\] where \\(\\mathbf{\\mu}_n=\\frac{N}{N+\\beta_0}\\hat{\\mathbf{\\mu}}+\\frac{\\beta_0}{N+\\beta_0}\\mathbf{\\mu}_0\\) is the posterior mean. We have \\[\\begin{align} \\pi(\\mathbf{\\mu},\\mathbf{\\Sigma}|\\mathbf{Y})&amp;\\propto |\\Sigma|^{-1/2}\\exp\\left\\{-\\frac{N+\\beta_0}{2}tr\\left[\\left(\\left(\\mathbf{\\mu}-\\mathbf{\\mu}_n\\right)\\left(\\mathbf{\\mu}-\\mathbf{\\mu}_n\\right)^{\\top}\\right)\\mathbf{\\Sigma}^{-1}\\right]\\right\\}\\\\ &amp;\\times |\\mathbf{\\Sigma}|^{-(N+\\alpha_0+p+1)/2}\\exp\\left\\{-\\frac{1}{2}tr\\left[\\left(\\mathbf{\\Psi}_0+\\mathbf{S}+\\frac{N\\beta_0}{N+\\beta_0}(\\hat{\\mathbf{\\mu}}-\\mathbf{\\mu}_0)(\\hat{\\mathbf{\\mu}}-\\mathbf{\\mu}_0)^{\\top}\\right)\\mathbf{\\Sigma}^{-1}\\right]\\right\\}. \\end{align}\\] Then, \\(\\mathbf{\\mu}|\\mathbf{\\Sigma},\\mathbf{Y}\\sim N_p\\left(\\mathbf{\\mu}_n,\\frac{1}{\\beta_n}\\mathbf{\\Sigma}\\right)\\), and \\(\\mathbf{\\Sigma}|\\mathbf{Y}\\sim W\\left(\\alpha_n,\\mathbf{\\Psi}_n\\right)\\) where \\(\\beta_n=N+\\beta_0\\), \\(\\alpha_n=N+\\alpha_0\\) and \\(\\mathbf{\\Psi}_n=\\mathbf{\\Psi}_0+\\mathbf{S}+\\frac{N\\beta_0}{N+\\beta_0}(\\hat{\\mathbf{\\mu}}-\\mathbf{\\mu}_0)(\\hat{\\mathbf{\\mu}}-\\mathbf{\\mu}_0)^{\\top}\\). The marginal posterior of \\(\\mathbf{\\mu}\\) is given by \\(\\int_{\\mathcal{S}} \\pi(\\mathbf{\\mu},\\mathbf{\\Sigma})d\\mathbf{\\Sigma}\\) where \\(\\mathcal{S}\\) is the space of positive semi-definite matrices. Then, \\[\\begin{align} \\pi(\\mathbf{\\mu}|\\mathbf{Y})&amp;\\propto\\int_{\\mathcal{S}}\\left\\{|\\mathbf{\\Sigma}|^{-(\\alpha_n+p+2)/2} \\exp\\left\\{-\\frac{1}{2}tr\\left[\\left(\\beta_n\\left(\\mathbf{\\mu}-\\mathbf{\\mu}_n\\right)\\left(\\mathbf{\\mu}-\\mathbf{\\mu}_n\\right)^{\\top}+\\mathbf{\\Psi}_n\\right)\\mathbf{\\Sigma}^{-1}\\right]\\right\\} \\right\\}d\\mathbf{\\Sigma}\\\\ &amp;\\propto \\big\\lvert\\left(\\beta_n\\left(\\mathbf{\\mu}-\\mathbf{\\mu}_n\\right)\\left(\\mathbf{\\mu}-\\mathbf{\\mu}_n\\right)^{\\top}+\\mathbf{\\Psi}_n\\right)\\big\\lvert^{-(\\alpha_n+1)/2}\\\\ &amp;=\\left[\\big\\lvert\\mathbf{\\Psi}_n\\big\\lvert\\times \\big\\lvert1+\\beta_n\\left(\\mathbf{\\mu}-\\mathbf{\\mu}_n\\right)^{\\top}\\mathbf{\\Psi}_n^{-1}\\left(\\mathbf{\\mu}-\\mathbf{\\mu}_n\\right)\\big\\lvert\\right]^{-(\\alpha_n+1)/2}\\\\ &amp;\\propto \\left(1+\\frac{1}{\\alpha_n+1-p}\\left(\\mathbf{\\mu}-\\mathbf{\\mu}_n\\right)^{\\top}\\left(\\frac{\\mathbf{\\Psi}_n}{(\\alpha_n+1-p)\\beta_n}\\right)^{-1}\\left(\\mathbf{\\mu}-\\mathbf{\\mu}_n\\right)\\right)^{-(\\alpha_n+1-p+p)/2}, \\end{align}\\] where the second line uses properties of the inverse Wishart distribution, and the third line uses a particular case of the Sylvester’s determinant theorem. We observe that the last line is the kernel of a Multivariate Student’s t distribution, that is, \\(\\mathbf{\\mu}|\\mathbf{Y}\\sim t_p(v_n,\\mathbf{\\mu}_n,\\mathbf{\\Sigma}_n)\\) where \\(v_n=\\alpha_n+1-p\\) and \\(\\mathbf{\\Sigma}_n=\\frac{\\mathbf{\\Psi}_n}{(\\alpha_n+1-p)\\beta_n}\\). The marginal likelihood is given by \\[\\begin{align} p(\\mathbf{Y})=\\frac{\\Gamma_p\\left(\\frac{\\alpha_n}{2}\\right)}{\\Gamma_p\\left(\\frac{\\alpha_0}{2}\\right)}\\frac{|\\mathbf{\\Psi}_0|^{\\alpha_0/2}}{|\\mathbf{\\Psi}_n|^{\\alpha_n/2}}\\left(\\frac{\\beta_0}{\\beta_n}\\right)^{p/2}(2\\pi)^{-Np/2}, \\end{align}\\] where \\(\\Gamma_p\\) is the multivariate gamma function (see Exercise 4). The posterior predictive distribution is \\(\\mathbf{Y}_0|\\mathbf{Y}\\sim t_p(v_n,\\mathbf{\\mu}_n,(\\beta_n+1)\\mathbf{\\Sigma}_n)\\) (see Exercise 5). References "],["linear-regression-the-conjugate-normal-normalinverse-gamma-model.html", "3.3 Linear regression: The conjugate normal-normal/inverse gamma model", " 3.3 Linear regression: The conjugate normal-normal/inverse gamma model In this setting we analyze the conjugate normal-normal/inverse gamma model which is the workhorse in econometrics. In this model, the dependent variable \\(y_i\\) is related to a set of regressors \\({\\mathbf{x}}_i=(x_{i1},x_{i2},\\ldots,x_{iK})^{\\top}\\) in a linear way, that is, \\(y_i=\\beta_1x_{i1}+\\beta_2x_{i2}+\\ldots+\\beta_Kx_{iK}+\\mu_i={\\bf{x}}_i^{\\top}\\beta+\\mu_i\\) where \\(\\mathbf{\\beta}=(\\beta_1,\\beta_2,\\ldots,\\beta_K)^{\\top}\\) and \\(\\mu_i\\stackrel{iid} {\\thicksim}N(0,\\sigma^2)\\) is an stochastic error that is independent of the regressors, \\({\\bf{x}}_i\\perp\\mu_i\\). Defining \\(\\mathbf{y}=\\begin{bmatrix} y_1\\\\ y_2\\\\ \\vdots \\\\ y_N \\end{bmatrix}\\), \\(\\mathbf{X}=\\begin{bmatrix} x_{11} &amp; x_{12} &amp; \\ldots &amp; x_{1K}\\\\ x_{21} &amp; x_{22} &amp; \\ldots &amp; x_{2K}\\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots\\\\ x_{N1} &amp; x_{N2} &amp; \\ldots &amp; x_{NK}\\\\ \\end{bmatrix}\\) and \\(\\mathbf{\\mu}=\\begin{bmatrix} \\mu_1\\\\ \\mu_2\\\\ \\vdots \\\\ \\mu_N \\end{bmatrix}\\), we can write the model in matrix form: \\({\\bf{y}}={\\bf{X}}\\beta+\\mu\\), where \\(\\mu\\sim N(\\bf{0},\\sigma^2{\\bf{I}})\\) which implies that \\({\\bf{y}}\\sim N({\\bf{X}}\\beta,\\sigma^2\\bf{I})\\). Then, the likelihood function is \\[\\begin{align} p({\\bf{y}}|\\beta, \\sigma^2, {{\\bf{X}}}) &amp; = (2\\pi\\sigma^2)^{-\\frac{N}{2}} \\exp \\left\\{-\\frac{1}{2\\sigma^2} ({\\bf{y}} - {\\bf{X}}\\beta)^{\\top}({\\bf{y}} - {\\bf{X}}\\beta) \\right\\} \\\\ &amp; \\propto (\\sigma^2)^{-\\frac{N}{2}} \\exp \\left\\{-\\frac{1}{2\\sigma^2} ({\\bf{y}} - {\\bf{X}}\\beta)^{\\top}({\\bf{y}} - {\\bf{X}}\\beta) \\right\\}. \\end{align}\\] The conjugate priors for the parameters are \\[\\begin{align} \\beta|\\sigma^2 &amp; \\sim N(\\beta_0, \\sigma^2 {\\bf{B}}_0),\\\\ \\sigma^2 &amp; \\sim IG(\\alpha_0/2, \\delta_0/2). \\end{align}\\] Then, the posterior distribution is \\[\\begin{align} \\pi(\\beta,\\sigma^2|\\mathbf{y},\\mathbf{X})&amp;\\propto (\\sigma^2)^{-\\frac{N}{2}} \\exp \\left\\{-\\frac{1}{2\\sigma^2} ({\\bf{y}} - {\\bf{X}}\\beta)^{\\top}({\\bf{y}} - {\\bf{X}}\\beta) \\right\\} \\\\ &amp; \\times (\\sigma^2)^{-\\frac{K}{2}} \\exp \\left\\{-\\frac{1}{2\\sigma^2} (\\beta - \\beta_0)^{\\top}{\\bf{B}}_0^{-1}(\\beta - \\beta_0)\\right\\} \\\\ &amp; \\times \\frac{(\\delta_0/2)^{\\alpha_0/2}}{\\Gamma(\\alpha_0/2)}\\left(\\frac{1}{\\sigma^2}\\right)^{\\alpha_0/2+1}\\exp \\left\\{-\\frac{\\delta_0}{2\\sigma^2} \\right\\} \\\\ &amp; \\propto (\\sigma^2)^{-\\frac{K}{2}} \\exp \\left\\{-\\frac{1}{2\\sigma^2} [\\beta^{\\top}({\\bf{B}}_0^{-1} + {\\bf{X}}^{\\top}{\\bf{X}})\\beta - 2\\beta^{\\top}({\\bf{B}}_0^{-1}\\beta_0 + {\\bf{X}}^{\\top}{\\bf{X}}\\hat{\\beta})] \\right\\} \\\\ &amp; \\times \\left(\\frac{1}{\\sigma^2}\\right)^{(\\alpha_0+N)/2+1}\\exp \\left\\{-\\frac{\\delta_0+ {\\bf{y}}^{\\top}{\\bf{y}} + \\beta_0^{\\top}{\\bf{B}}_0^{-1}\\beta_0}{2\\sigma^2} \\right\\}, \\end{align}\\] where \\(\\hat{\\beta}=({\\bf{X}}^{\\top}{\\bf{X}})^{-1}{\\bf{X}}^{\\top}{\\bf{y}}\\) is the maximum likelihood estimator. Adding and subtracting \\(\\beta_n^{\\top}{{\\bf{B}}}_n^{-1} \\beta_n\\) to complete the square, where \\({{\\bf{B}}}_n = ({\\bf{B}}_0^{-1} + {\\bf{X}}^{\\top}{\\bf{X}})^{-1}\\) and \\(\\beta_n = {{\\bf{B}}}_n({\\bf{B}}_0^{-1}\\beta_0 + {\\bf{X}}^{\\top}{\\bf{X}}\\hat{\\beta})\\), \\[\\begin{align} \\pi(\\beta,\\sigma^2|\\mathbf{y},\\mathbf{X})&amp;\\propto \\underbrace{(\\sigma^2)^{-\\frac{K}{2}} \\exp \\left\\{-\\frac{1}{2\\sigma^2} (\\beta-\\beta_n)^{\\top}{\\bf{B}}^{-1}_n(\\beta-\\beta_n) \\right\\}}_1 \\\\ &amp; \\times \\underbrace{(\\sigma^2)^{-\\left(\\frac{\\alpha_n}{2}+1 \\right)} \\exp \\left\\{-\\frac{\\delta_n}{2\\sigma^2} \\right\\}}_2. \\end{align}\\] The first expression is the kernel of a normal density function, \\(\\beta|\\sigma^2, {\\bf{y}}, {\\bf{X}} \\sim N(\\beta_n, \\sigma^2{\\bf{B}}_n)\\). The second expression is the kernel of a inverse gamma density, \\(\\sigma^2| {\\bf{y}}, {\\bf{X}}\\sim IG(\\alpha_n/2, \\delta_n/2)\\), where \\(\\alpha_n = \\alpha_0 + N\\) and \\(\\delta_n = \\delta_0 + {\\bf{y}}^{\\top}{\\bf{y}} + \\beta_0^{\\top}{\\bf{B}}_0^{-1}\\beta_0 - \\beta_n^{\\top}{\\bf{B}}_n^{-1}\\beta_n\\). Taking into account that \\[\\begin{align}\\beta_n &amp; = ({\\bf{B}}_0^{-1} + {\\bf{X}}^{\\top}{\\bf{X}})^{-1}({\\bf{B}}_0^{-1}\\beta_0 + {\\bf{X}}^{\\top}{\\bf{X}}\\hat{\\beta})\\\\ &amp; = ({\\bf{B}}_0^{-1} + {\\bf{X}}^{\\top}{\\bf{X}})^{-1}{\\bf{B}}_0^{-1}\\beta_0 + ({\\bf{B}}_0^{-1} + {\\bf{X}}^{\\top}{\\bf{X}})^{-1} {\\bf{X}}^{\\top}{\\bf{X}}\\hat{\\beta}, \\end{align}\\] where \\(({\\bf{B}}_0^{-1} + {\\bf{X}}^{\\top}{\\bf{X}})^{-1}{\\bf{B}}_0^{-1}=\\bf{I}_K-({\\bf{B}}_0^{-1} + {\\bf{X}}^{\\top}{\\bf{X}})^{-1}{\\bf{X}}^{\\top}{\\bf{X}}\\) (Smith 1973). Setting \\({\\bf{W}}=({\\bf{B}}_0^{-1} + {\\bf{X}}^{\\top}{\\bf{X}})^{-1}{\\bf{X}}^{\\top}{\\bf{X}}\\) we have \\(\\beta_n=(\\bf{I}_K-{\\bf{W}})\\beta_0+{\\bf{W}}\\hat{\\beta}\\), that is, the posterior mean of \\(\\beta\\) is a weighted average between the sample and prior information, where the weights depend on the precision of each piece of information. Observe that when the prior covariance matrix is highly vague (non–informative), such that \\({\\bf{B}}_0^{-1}\\rightarrow \\bf{0}_K\\), we obtain \\({\\bf{W}} \\rightarrow I_K\\), such that \\(\\beta_n \\rightarrow \\hat{\\beta}\\), that is, the posterior mean location parameter converges to the maximum likelihood estimator. In addition, we know that the posterior conditional covariance matrix of the location parameters \\(\\sigma^2({\\bf{B}}_0^{-1} + {\\bf{X}}^{\\top}{\\bf{X}})^{-1}=\\sigma^2({\\bf{X}}^{\\top}{\\bf{X}})^{-1}-\\sigma^2\\left(({\\bf{X}}^{\\top}{\\bf{X}})^{-1}({\\bf{B}}_0 + ({\\bf{X}}^{\\top}{\\bf{X}})^{-1})^{-1}({\\bf{X}}^{\\top}{\\bf{X}})^{-1}\\right)\\) is positive semi-definite.19 Given that \\(\\sigma^2({\\bf{X}}^{\\top}{\\bf{X}})^{-1}\\) is the covariance matrix of the maximum likelihood estimator, we observe that prior information reduces estimation uncertainty. Now, we calculate the posterior marginal distribution of \\(\\beta\\), \\[\\begin{align} \\pi(\\beta|{\\bf{y}},{\\bf{X}}) &amp; = \\int_0^{\\infty} \\pi(\\beta, \\sigma^2|{\\bf{y}},{\\bf{X}}) d\\sigma^2 \\\\ &amp; = \\int_0^{\\infty} \\left(\\frac{1}{\\sigma^2}\\right)^{\\frac{\\alpha_n+K}{2} + 1} \\exp \\left\\{-\\frac{s}{2\\sigma^2}\\right\\} d\\sigma^2, \\end{align}\\] where \\(s = \\delta_n + (\\beta - \\beta_n)^{\\top}{{\\bf{B}}}_n^{-1}(\\beta - \\beta_n)\\). Then we can write \\[\\begin{align} \\pi(\\beta|{\\bf{y}},{\\bf{X}}) &amp; = \\int_0^{\\infty} \\left(\\frac{1}{\\sigma^2}\\right)^{\\frac{\\alpha_n+K}{2} + 1} \\exp \\left\\{-\\frac{s}{2\\sigma^2}\\right\\} d\\sigma^2 \\\\ &amp; = \\frac{\\Gamma((\\alpha_n+K)/2)}{(s/2)^{(\\alpha_n+K)/2}} \\int_0^{\\infty} \\frac{(s/2)^{(\\alpha_n+K)/2}}{\\Gamma((\\alpha_n+K)/2)} (\\sigma^2)^{-(\\alpha_n+K)/2 - 1} \\exp \\left\\{-\\frac{s}{2\\sigma^2}\\right\\} d\\sigma^2. \\end{align}\\] The right term is the integral of the probability density function of an inverse gamma distribution with parameters \\(\\nu = (\\alpha_n+K)/2\\) and \\(\\tau = s/2\\). Since we are integrating over the whole support of \\(\\sigma^2\\), the integral is equal to 1, and therefore \\[\\begin{align*} \\pi(\\beta|{\\bf{y}},{\\bf{X}}) &amp; = \\frac{\\Gamma((\\alpha_n+K)/2)}{(s/2)^{(\\alpha_n+K)/2}} \\\\ &amp; \\propto s^{-(\\alpha_n+K)/2} \\\\ &amp; = [\\delta_n + (\\beta - \\beta_n)^{\\top}{{\\bf{B}}}_n^{-1}(\\beta - \\beta_n)]^{-(\\alpha_n+K)/2} \\\\ &amp; = \\left[1 + \\frac{(\\beta - \\beta_n)^{\\top}\\left(\\frac{\\delta_n}{\\alpha_n}{{\\bf{B}}}_n\\right)^{-1}(\\beta - \\beta_n)}{\\alpha_n}\\right]^{-(\\alpha_n+K)/2}(\\delta_n)^{-(\\alpha_N+K)/2} \\\\ &amp; \\propto \\left[1 + \\frac{(\\beta - \\beta_n)^{\\top}{\\bf{H}}_n^{-1}(\\beta - \\beta_n)}{\\alpha_n}\\right]^{-(\\alpha_n+K)/2}, \\end{align*}\\] where \\({\\bf{H}}_n = \\frac{\\delta_n}{\\alpha_n}{\\bf{B}}_n\\). This last expression is a multivariate Student’s \\(t\\) distribution for \\(\\beta\\), \\(\\beta|{\\bf{y}},{\\bf{X}} \\sim t_K(\\alpha_n, \\beta_n, {\\bf{H}}_n)\\). Observe that as we have incorporated the uncertainty of the variance, the posterior for \\(\\beta\\) changes from a normal to a Students’ t distribution, which has heavier tails. The marginal likelihood of this model is \\[\\begin{align} p({\\bf{y}})=\\int_0^{\\infty}\\int_{R^K}\\pi (\\beta | \\sigma^2,{\\bf{B}}_0,\\beta_0 )\\pi(\\sigma^2| \\alpha_0/2, \\delta_0/2)p({\\bf{y}}|\\beta, \\sigma^2, {\\bf{X}})d\\sigma^2 d\\beta. \\end{align}\\] Taking into account that \\(({\\bf{y}}-{\\bf{X}}\\beta)^{\\top}({\\bf{y}}-{\\bf{X}}\\beta)+(\\beta-\\beta_0)^{\\top}{\\bf{B}}_0^{-1}(\\beta-\\beta_0)=(\\beta-\\beta_n)^{\\top}{\\bf{B}}_n^{-1}(\\beta-\\beta_n)+m\\), where \\(m={\\bf{y}}^{\\top}{\\bf{y}}+\\beta_0^{\\top}{\\bf{B}}_0^{-1}\\beta_0-\\beta_n^{\\top}{\\bf{B}}_n^{-1}\\beta_n\\), we have that \\[\\begin{align} p({\\bf{y}})&amp;=\\int_0^{\\infty}\\int_{R^K}\\pi (\\beta | \\sigma^2)\\pi(\\sigma^2)p({\\bf{y}}|\\beta, \\sigma^2, {\\bf{X}})d\\sigma^2 d\\beta\\\\ &amp;=\\int_0^{\\infty}\\pi(\\sigma^2) \\frac{1}{(2\\pi\\sigma^2)^{N/2}}\\exp\\left\\{-\\frac{1}{2\\sigma^2}m \\right\\} \\frac{1}{(2\\pi\\sigma^2)^{K/2}|{\\bf{B}}_0|^{1/2}}\\\\ &amp;\\times\\int_{R^K}\\exp\\left\\{-\\frac{1}{2\\sigma^2}(\\beta-\\beta_n)^{\\top}{\\bf{B}}_n^{-1}(\\beta-\\beta_n)\\right\\}d\\sigma^2 d\\beta\\\\ &amp;=\\int_0^{\\infty}\\pi(\\sigma^2) \\frac{1}{(2\\pi\\sigma^2)^{N/2}}\\exp\\left\\{-\\frac{1}{2\\sigma^2}m \\right\\} \\frac{|{\\bf{B}}_n|^{1/2}}{|{\\bf{B}}_0|^{1/2}}d\\sigma^2\\\\ &amp;=\\int_{0}^{\\infty} \\frac{(\\delta_0/2)^{\\alpha_0/2}}{\\Gamma(\\alpha_0/2)}\\left(\\frac{1}{\\sigma^2}\\right)^{\\alpha_0/2+1}\\exp\\left\\{\\left(-\\frac{\\delta_0}{2\\sigma^2}\\right)\\right\\} \\frac{1}{(2\\pi\\sigma^2)^{N/2}}\\exp\\left\\{-\\frac{1}{2\\sigma^2}m \\right\\} \\frac{|{\\bf{B}}_n|^{1/2}}{|{\\bf{B}}_0|^{1/2}} d\\sigma^2\\\\ &amp;= \\frac{1}{(2\\pi)^{N/2}}\\frac{(\\delta_0/2)^{\\alpha_0/2}}{\\Gamma(\\alpha_0/2)}\\frac{|{\\bf{B}}_n|^{1/2}}{|{\\bf{B}}_0|^{1/2}}\\int_{0}^{\\infty}\\left(\\frac{1}{\\sigma^2}\\right)^{\\frac{\\alpha_0+N}{2}+1}\\exp\\left\\{\\left(-\\frac{\\delta_0+m}{2\\sigma^2}\\right)\\right\\}d\\sigma^2\\\\ &amp;= \\frac{1}{\\pi^{N/2}}\\frac{\\delta_0^{\\alpha_0/2}}{\\delta_n^{\\alpha_n/2}}\\frac{|{\\bf{B}}_n|^{1/2}}{|{\\bf{B}}_0|^{1/2}}\\frac{\\Gamma(\\alpha_n/2)}{\\Gamma(\\alpha_0/2)}. \\end{align}\\] The posterior predictive is equal to \\[\\begin{align} \\pi({\\bf{Y}}_0|{\\bf{y}})&amp;=\\int_{0}^{\\infty}\\int_{R^K}p({\\bf{Y}}_0|\\beta,\\sigma^2,{\\bf{y}})\\pi(\\beta|\\sigma^2,{\\bf{y}})\\pi(\\sigma^2|{\\bf{y}})d\\beta d\\sigma^2\\\\ &amp;=\\int_{0}^{\\infty}\\int_{R^K}p({\\bf{Y}}_0|\\beta,\\sigma^2)\\pi(\\beta|\\sigma^2,{\\bf{y}})\\pi(\\sigma^2|{\\bf{y}})d\\beta d\\sigma^2, \\end{align}\\] where we take into account independence between \\({\\bf{Y}}_0\\) and \\({\\bf{Y}}\\). Given \\({\\bf{X}}_0\\), which is the \\(N_0\\times K\\) matrix of regressors associated with \\({\\bf{Y}}_0\\), Then, \\[\\begin{align} \\pi({\\bf{Y}}_0|{\\bf{y}})&amp;=\\int_{0}^{\\infty}\\int_{R^K}\\left\\{ (2\\pi\\sigma^2)^{-\\frac{N_0}{2}} \\exp \\left\\{-\\frac{1}{2\\sigma^2} ({\\bf{Y}}_0 - {\\bf{X}}_0\\beta)^{\\top}({\\bf{Y}}_0 - {\\bf{X}}_0\\beta)^{\\top} \\right\\}\\right. \\\\ &amp; \\times (2\\pi\\sigma^2)^{-\\frac{K}{2}} |{\\bf{B}}_n|^{-1/2} \\exp \\left\\{-\\frac{1}{2\\sigma^2} (\\beta - \\beta_n)^{\\top}{\\bf{B}}_n^{-1}(\\beta - \\beta_n)\\right\\} \\\\ &amp; \\left. \\times \\frac{(\\delta_n/2)^{\\alpha_n/2}}{\\Gamma(\\alpha_n/2)}\\left(\\frac{1}{\\sigma^2}\\right)^{\\alpha_n/2+1}\\exp \\left\\{-\\frac{\\delta_n}{2\\sigma^2} \\right\\}\\right\\}d\\beta d\\sigma^2. \\\\ \\end{align}\\] Setting \\({\\bf{M}}=({\\bf{X}}_0^{\\top}{\\bf{X}}_0+{\\bf{B}}_n^{-1})\\) and \\(\\beta_*={\\bf{M}}^{-1}({\\bf{B}}_n^{-1}\\beta_n+{\\bf{X}}_0^{\\top}{\\bf{Y}}_0)\\), we have \\[\\begin{align} ({\\bf{Y}}_0 - {\\bf{X}}_0\\beta)^{\\top}({\\bf{Y}}_0 - {\\bf{X}}_0\\beta)^{\\top}+(\\beta - \\beta_n)^{\\top}{\\bf{B}}_n^{-1}(\\beta - \\beta_n)&amp;=(\\beta - \\beta_*)^{\\top}{\\bf{M}}(\\beta - \\beta_*)\\\\ &amp;+\\beta_n^{\\top}{\\bf{B}}_n^{-1}\\beta_n+{\\bf{Y}}_0^{\\top}{\\bf{Y}}_0-\\beta_*^{\\top}{\\bf{M}}\\beta_*, \\end{align}\\] Thus, \\[\\begin{align} \\pi({\\bf{Y}}_0|{\\bf{y}})&amp;\\propto\\int_{0}^{\\infty}\\left\\{\\left(\\frac{1}{\\sigma^2}\\right)^{-\\frac{K+N_0+\\alpha_n}{2}+1}\\exp\\left\\{-\\frac{1}{2\\sigma^2}(\\beta_n^{\\top}{\\bf{B}}_n^{-1}\\beta_n+{\\bf{Y}}_0^{\\top}{\\bf{Y}}_0-\\beta_*^{\\top}{\\bf{M}}\\beta_*+\\delta_n)\\right\\}\\right.\\\\ &amp;\\times\\left.\\int_{R^K}\\exp\\left\\{-\\frac{1}{2\\sigma^2}(\\beta - \\beta_*)^{\\top}{\\bf{M}}(\\beta - \\beta_*)\\right\\}d\\beta\\right\\} d\\sigma^2,\\\\ \\end{align}\\] where the term in the second integral is the kernel of a multivariate normal density with mean \\(\\beta_*\\) and covariance matrix \\(\\sigma^2{\\bf{M}}^{-1}\\). Then, \\[\\begin{align} \\pi({\\bf{Y}}_0|{\\bf{y}})&amp;\\propto\\int_{0}^{\\infty}\\left(\\frac{1}{\\sigma^2}\\right)^{\\frac{N_0+\\alpha_n}{2}+1}\\exp\\left\\{-\\frac{1}{2\\sigma^2}(\\beta_n^{\\top}{\\bf{B}}_n^{-1}\\beta_n+{\\bf{Y}}_0^{\\top}{\\bf{Y}}_0-\\beta_*^{\\top}{\\bf{M}}\\beta_*+\\delta_n)\\right\\}d\\sigma^2,\\\\ \\end{align}\\] which is the kernel of an inverse gamma density. Thus, \\[\\begin{align} \\pi({\\bf{Y}}_0|{\\bf{y}})&amp;\\propto \\left[\\frac{\\beta_n^{\\top}{\\bf{B}}_n^{-1}\\beta_n+{\\bf{Y}}_0^{\\top}{\\bf{Y}}_0-\\beta_*^{\\top}{\\bf{M}}\\beta_*+\\delta_n}{2}\\right]^{-\\frac{\\alpha_n+N_0}{2}}. \\end{align}\\] Setting \\({\\bf{C}}^{-1}={\\bf{I}}_{N_0}+{\\bf{X}}_0{\\bf{B}}_n{\\bf{X}}_0^{\\top}\\) such that \\({\\bf{C}}={\\bf{I}}_{N_0}-{\\bf{X}}_0({\\bf{B}}_n^{-1}+{\\bf{X}}_0^{\\top}{\\bf{X}}_0)^{-1}{\\bf{X}}_0^{\\top}={\\bf{I}}_{N_0}-{\\bf{X}}_0{\\bf{M}}^{-1}{\\bf{X}}_0^{\\top}\\),20 and \\({\\bf{\\beta}}_{**}={\\bf{C}}^{-1}{\\bf{X}}_0{\\bf{M}}^{-1}{\\bf{B}}_n^{-1}\\beta_n\\), then \\[\\begin{align} \\beta_n^{\\top}{\\bf{B}}_n^{-1}\\beta_n+{\\bf{Y}}_0^{\\top}{\\bf{Y}}_0-\\beta_*^{\\top}{\\bf{M}}\\beta_*&amp;= \\beta_n^{\\top}{\\bf{B}}_n^{-1}\\beta_n+{\\bf{Y}}_0^{\\top}{\\bf{Y}}_0-(\\beta_n^{\\top}{\\bf{B}}_n^{-1}+{\\bf{Y}}_0^{\\top}{\\bf{X}}_0){\\bf{M}}^{-1}({\\bf{B}}_n^{-1}\\beta_n+{\\bf{X}}_0^{\\top}{\\bf{Y}}_0)\\\\ &amp;=\\beta_n^{\\top}({\\bf{B}}_n^{-1}-{\\bf{B}}_n^{-1}{\\bf{M}}^{-1}{\\bf{B}}_n^{-1})\\beta_n+{\\bf{Y}}_0^{\\top}{\\bf{C}}{\\bf{Y}}_0\\\\ &amp;-2{\\bf{Y}}_0^{\\top}{\\bf{C}}{\\bf{C}}^{-1}{\\bf{X}}_0{\\bf{M}}^{-1}{\\bf{B}}_n^{-1}\\beta_n+{\\bf{\\beta}}_{**}^{\\top}{\\bf{C}}{\\bf{\\beta}}_{**}-{\\bf{\\beta}}_{**}^{\\top}{\\bf{C}}{\\bf{\\beta}}_{**}\\\\ &amp;=\\beta_n^{\\top}({\\bf{B}}_n^{-1}-{\\bf{B}}_n^{-1}{\\bf{M}}^{-1}{\\bf{B}}_n^{-1})\\beta_n+({\\bf{Y}}_0-{\\bf{\\beta}}_{**})^{\\top}{\\bf{C}}({\\bf{Y}}_0-{\\bf{\\beta}}_{**})\\\\ &amp;-{\\bf{\\beta}}_{**}^{\\top}{\\bf{C}}{\\bf{\\beta}}_{**}, \\end{align}\\] where \\(\\beta_n^{\\top}({\\bf{B}}_n^{-1}-{\\bf{B}}_n^{-1}{\\bf{M}}^{-1}{\\bf{B}}_n^{-1})\\beta_n={\\bf{\\beta}}_{**}^{\\top}{\\bf{C}}{\\bf{\\beta}}_{**}\\) and \\(\\beta_{**}={\\mathbf{X}}_0\\beta_n\\) (see Exercise 6). Then, \\[\\begin{align} \\pi({\\bf{Y}}_0|{\\bf{y}})&amp;\\propto\\left[\\frac{({\\bf{Y}}_0-{\\mathbf{X}}_0\\beta_n)^{\\top}{\\bf{C}}({\\bf{Y}}_0-{\\mathbf{X}}_0\\beta_n)+\\delta_n}{2}\\right]^{-\\frac{\\alpha_n+N_0}{2}}\\\\ &amp;\\propto\\left[\\frac{({\\bf{Y}}_0-{\\mathbf{X}}_0\\beta_n)^{\\top}\\left(\\frac{{\\bf{C}}\\alpha_n}{\\delta_n}\\right)({\\bf{Y}}_0-{\\mathbf{X}}_0\\beta_n)}{\\alpha_n}+1\\right]^{-\\frac{\\alpha_n+N_0}{2}}. \\end{align}\\] Then, the posterior predictive is a multivariate Student’s t, \\({\\bf{Y}}_0|{\\bf{y}}\\sim t\\left({\\bf{X}}_0\\beta_n,\\frac{\\delta_n({\\bf{I}}_{N_0}+{\\bf{X}}_0{\\bf{B}}_n{\\bf{X}}_0^{\\top})}{\\alpha_n},\\alpha_n\\right)\\). References "],["multivariate-linear-regression-the-conjugate-normal-normalinverse-wishart-model.html", "3.4 Multivariate linear regression: The conjugate normal-normal/inverse Wishart model", " 3.4 Multivariate linear regression: The conjugate normal-normal/inverse Wishart model Let’s study the multivariate regression setting where there are \\(M\\) \\(N\\)-dimensional vectors \\({\\bf{y}}_m\\), \\(m=1,2,\\dots,M\\) such that \\({\\bf{y}}_m={\\bf{X}}\\beta_m+\\mu_m\\), \\({\\bf{X}}\\) is the set of common regressors, and \\(\\mu_m\\) is the \\(N\\)-dimensional vector of stochastic errors for each equation such that \\({\\bf{U}}=[\\mu_1 \\ \\mu_2 \\ \\dots \\ \\mu_M]\\sim MN_{N,M}({\\bf{0}}, {\\bf{I}}_N, {\\bf\\Sigma})\\), that is, a matrix variate normal distribution where \\(\\bf\\Sigma\\) is the covariance matrix of each \\(i\\)-th row of \\({\\bf{U}}\\), \\(i=1,2,\\dots,N\\), and we are assuming independece between the rows. Then, \\(vec({\\bf U})\\sim N_{N\\times M}({\\bf 0}, \\bf{\\Sigma}\\otimes {\\bf{I}}_N)\\).21 This framework can be written in matricial form \\[\\begin{align} \\underbrace{ \\begin{bmatrix} y_{11} &amp; y_{12} &amp; \\dots &amp; y_{1M}\\\\ y_{21} &amp; y_{22} &amp; \\dots &amp; y_{2M}\\\\ \\vdots &amp; \\vdots &amp; \\dots &amp; \\vdots\\\\ y_{N1} &amp; y_{N2} &amp; \\dots &amp; y_{NM}\\\\ \\end{bmatrix}}_{\\bf{Y}} &amp;= \\underbrace{\\begin{bmatrix} x_{11} &amp; x_{12} &amp; \\dots &amp; x_{1K}\\\\ x_{21} &amp; x_{22} &amp; \\dots &amp; x_{2K}\\\\ \\vdots &amp; \\vdots &amp; \\dots &amp; \\vdots\\\\ x_{N1} &amp; x_{N2} &amp; \\dots &amp; x_{NK}\\\\ \\end{bmatrix}}_{\\bf{X}} \\underbrace{ \\begin{bmatrix} \\beta_{11} &amp; \\beta_{12} &amp; \\dots &amp; \\beta_{1M}\\\\ \\beta_{21} &amp; \\beta_{22} &amp; \\dots &amp; \\beta_{2M}\\\\ \\vdots &amp; \\vdots &amp; \\dots &amp; \\vdots\\\\ \\beta_{K1} &amp; \\beta_{K2} &amp; \\dots &amp; \\beta_{KM}\\\\ \\end{bmatrix}}_{\\bf{B}}\\\\ &amp;+ \\underbrace{\\begin{bmatrix} \\mu_{11} &amp; \\mu_{12} &amp; \\dots &amp; \\mu_{1M}\\\\ \\mu_{21} &amp; \\mu_{22} &amp; \\dots &amp; \\mu_{2M}\\\\ \\vdots &amp; \\vdots &amp; \\dots &amp; \\vdots\\\\ \\mu_{N1} &amp; \\mu_{N2} &amp; \\dots &amp; \\mu_{NM}\\\\ \\end{bmatrix}}_{\\bf{U}} \\end{align}\\] Therefore, \\({\\bf{Y}}\\sim N_{N\\times M}({\\bf{X}}{\\bf{B}},\\bf{\\Sigma}\\otimes {\\bf{I}}_N)\\),22 \\[\\begin{align} p({\\bf{Y}}| {\\bf{B}},{\\bf\\Sigma})&amp;\\propto |{{\\bf \\Sigma}}|^{-N/2}\\exp\\left\\lbrace -\\frac{1}{2}tr\\left[({\\bf{Y}}-{\\bf{X}}{\\bf{B}})^{\\top}({\\bf{Y}}-{\\bf{X}}{\\bf{B}}){{\\bf \\Sigma}}^{-1}\\right]\\right\\rbrace \\\\ &amp;=|{{\\bf \\Sigma}}|^{-N/2}\\exp\\left\\lbrace -\\frac{1}{2}tr\\left[{\\bf{S}}+({\\bf{B}}-\\widehat{\\bf{B}})^{\\top}{\\bf{X}}^{\\top}{\\bf{X}}({\\bf{B}}-\\widehat{\\bf{B}})\\right]{{\\bf \\Sigma}}^{-1}\\right\\rbrace, \\end{align}\\] where \\({\\bf{S}}= ({\\bf{Y}}-{\\bf{X}}\\widehat{\\bf{B}})^{\\top}({\\bf{Y}}-{\\bf{X}}\\widehat{\\bf{B}})\\), \\(\\widehat{\\bf{B}}= ({\\bf{X}}^{\\top}{\\bf{X}})^{-1}{\\bf{X}}^{\\top}{\\bf{Y}}\\) (see Exercise 7). The conjugate prior for this models is \\(\\pi({\\bf{B}},{\\bf{\\Sigma}})=\\pi({\\bf{B}}|{\\bf{\\Sigma}})\\pi({\\bf{\\Sigma}})\\) where \\(\\pi({\\bf{B}}|{\\bf \\Sigma})\\sim N_{K\\times M}({\\bf{B}}_{0},{\\bf\\Sigma} \\otimes {\\bf{V}}_{0})\\) and \\(\\pi({\\bf\\Sigma})\\sim IW({\\bf{\\Psi}}_{0},\\alpha_{0})\\), that is, \\[\\begin{align} \\pi ({\\bf{B}},{\\bf\\Sigma})\\propto &amp;\\left|{\\bf\\Sigma} \\right|^{-K/2}\\exp\\left\\lbrace -\\frac{1}{2}tr\\left[({\\bf{B}}-{\\bf{B}}_{0})^{\\top}{\\bf{V}}_{0}^{-1}({\\bf{B}}-{\\bf{B}}_{0})\\right] {\\bf \\Sigma}^{-1}\\right\\rbrace \\\\ &amp; \\times \\left|{\\bf \\Sigma} \\right|^{-(\\alpha_{0}+M+1)/2}\\exp\\left\\lbrace -\\frac{1}{2}tr \\left[ {\\bf{\\Psi}}_{0} {\\bf \\Sigma}^{-1}\\right] \\right\\rbrace. \\end{align}\\] The posterior distribution is given by \\[\\begin{align} \\pi({\\bf{B}},{\\bf\\Sigma}|{\\bf{Y}},{\\bf{X}})&amp;\\propto p({\\bf{Y}}|{\\bf{B}},{\\bf\\Sigma},{\\bf{X}}) \\pi({\\bf{B}}| {\\bf \\Sigma})\\pi({\\bf\\Sigma})\\\\ &amp;\\propto \\left|{\\bf\\Sigma} \\right|^{-\\frac{N+K+\\alpha_{0}+M+1}{2}}\\\\ &amp;\\times\\exp\\left\\lbrace -\\frac{1}{2}tr\\left[(\\bf{\\Psi}_{0}+{\\bf{S}} +({\\bf{B}}-{\\bf{B}}_{0})^{\\top}{\\bf{V}}_{0}^{-1}({\\bf{B}}-{\\bf{B}}_{0})\\right.\\right.\\\\ &amp;\\left.\\left. +({\\bf{B}}-\\widehat{\\bf{B}})^{\\top}{\\bf{X}}^{\\top}{\\bf{X}}({\\bf{B}}-\\widehat{\\bf{B}}))\\bf{\\Sigma}^{-1}\\right]\\right\\rbrace . \\end{align}\\] Completing the squares on \\({\\bf{B}}\\) and collecting the remaining terms in the bracket yields \\[\\begin{align} {\\bf{\\Psi}}_{0}+{\\bf{S}} +({\\bf{B}}-{\\bf{B}}_{0})^{\\top}{\\bf{V}}_{0}^{-1}({\\bf{B}}-{\\bf{B}}_{0})+({\\bf{B}}-\\widehat{\\bf{B}})^{\\top}{\\bf{X}}^{\\top}{\\bf{X}}({\\bf{B}}-\\widehat{\\bf{B}}) &amp; = ({\\bf{B}}-{\\bf{B}}_n)^{\\top}{\\bf{V}}_n^{-1}({\\bf{B}}-{\\bf{B}}_n)+{\\bf{\\Psi}}_n, \\end{align}\\] where \\[\\begin{align} {\\bf{B}}_n = &amp;({\\bf{V}}_{0}^{-1}+{\\bf{X}}^{\\top}{\\bf{X}})^{-1}({\\bf{V}}_{0}^{-1}{\\bf{B}}_{0}+{\\bf{X}}^{\\top}{\\bf{Y}})=({\\bf{V}}_{0}^{-1}+{\\bf{X}}^{\\top}{\\bf{X}})^{-1}({\\bf{V}}_{0}^{-1}{\\bf{B}}_{0}+{\\bf{X}}^{\\top}{\\bf{X}}\\widehat{\\bf{B}}),\\\\ {\\bf{V}}_n = &amp;({\\bf{V}}_{0}^{-1}+{\\bf{X}}^{\\top}{\\bf{X}})^{-1},\\\\ {\\bf{\\Psi}}_n= &amp;{\\bf{\\Psi}}_{0}+{\\bf{S}}+{\\bf{B}}_{0}^{\\top}{\\bf{V}}_{0}^{-1}{\\bf{B}}_{0}+\\widehat{\\bf{B}}^{\\top}{\\bf{X}}^{\\top}{\\bf{X}}\\widehat{\\bf{B}}-{\\bf{B}}_n^{\\top}{\\bf{V}}_n^{-1}{\\bf{B}}_n. \\end{align}\\] Thus, the posterior distribution can be written as \\[\\begin{align} \\pi({\\bf{B}},{\\bf \\Sigma}| {\\bf{Y}}, {\\bf{X}})\\propto &amp;\\left|{\\bf \\Sigma} \\right|^{-K/2}\\exp\\left\\lbrace -\\frac{1}{2} tr\\left[({\\bf{B}}-{\\bf{B}}_n)^{\\top}{\\bf{V}}_n^{-1}({\\bf{B}}-{\\bf{B}}_n) \\right] {\\bf \\Sigma}^{-1}\\right\\rbrace \\\\ \\times &amp; \\left|{\\bf \\Sigma} \\right|^{-\\frac{N+\\alpha_{0}+M+1}{2}}\\exp\\left\\lbrace -\\frac{1}{2} tr \\left[ {\\bf{\\Psi}}_n{\\bf \\Sigma}^{-1}\\right] \\right\\rbrace . \\end{align}\\] That is \\(\\pi({\\bf{B}},{\\bf \\Sigma}| {\\bf{Y}}, {\\bf{X}})=\\pi ({\\bf{B}}| {\\bf \\Sigma},{\\bf{Y}},{\\bf{X}})\\pi({\\bf \\Sigma}| {\\bf{Y}},{\\bf{X}})\\) where \\(\\pi({\\bf{B}}| {\\bf \\Sigma},{\\bf{Y}}, {\\bf{X}}) \\sim N_{K\\times M}({\\bf{B}}_n,{\\bf \\Sigma}\\otimes {\\bf{V}}_n )\\) and \\(\\pi({\\bf \\Sigma}| {\\bf{Y}},{\\bf{X}}) \\sim IW({\\bf{\\Psi}}_n,{\\alpha}_n)\\), where \\(\\alpha_n= N+\\alpha_{0}\\). The marginal posterior for \\({\\bf{B}}\\) is … The marginal likelihood is … The predictive density is … \\(vec\\) denotes the vectorization operation, and \\(\\otimes\\) denotes the kronecker product↩︎ We can write down the former expression in a more familiar way using vectorization properties, \\(\\underbrace{vec(Y)}_{\\bf{y}}=\\underbrace{({\\bf{I}}_M\\otimes {\\bf{X}})}_{{\\bf{Z}}}\\underbrace{vec({\\bf{B}})}_{\\beta}+\\underbrace{vec({\\bf{U}})}_{\\mu}\\), where \\({\\bf{y}}\\sim N_{N\\times M}({\\bf{Z}}\\beta,\\bf{\\Sigma}\\otimes {\\bf{I}}_N)\\).↩︎ "],["computational-examples.html", "3.5 Computational examples", " 3.5 Computational examples What is the probability that the Sun will rise tomorrow? This is the most famaous Ricard Price^{}s example developed in the Appendix of the Bayes^{} theorem paper (Thomas Bayes 1763). Here, we implicitly use Laplace^{}s Rule of Succession to solve this question. In perticular, if we were a priori uncertain about the probability the Sun will on a specified day rise, that is, a prior uniform distribution over (0,1), that is, a beta (1,1) distribution… References "],["summary-chapter-4.html", "3.6 Summary: Chapter 4", " 3.6 Summary: Chapter 4 "],["exercises-chapter-4.html", "3.7 Exercises: Chapter 4", " 3.7 Exercises: Chapter 4 Write in the canonical form the distribution of the Bernoulli example, and find the mean and variance of the sufficient statistic. Given a random sample \\(\\mathbf{y}=[\\mathbf{y}_1,\\mathbf{y}_2,\\dots,\\mathbf{y}_N]^{\\top}\\) from a binomial distribution where the number of trials (\\(n\\)) is known. Show that \\(p(\\mathbf{y}|\\theta)\\) is in the exponential family, and find the posterior distribution, the marginal likelihood and the predictive distribution of the binomial-beta model assuming the number of trials is known. Given a random sample \\(\\mathbf{y}=[y_1,y_2,\\dots,y_N]^{\\top}\\) from a exponential distribution. Show that \\(p(\\mathbf{y}|\\alpha,\\beta)\\) is in the exponential family, and find the posterior distribution, marginal likelihood and predictive distribution of the exponential-gamma model. Find the marginal likelihood in the normal/inverse-Wishart model. Find the posterior predictive distribution in the normal/inverse-Wishart model. Show that in the linear regression model \\(\\beta_n^{\\top}({\\bf{B}}_n^{-1}-{\\bf{B}}_n^{-1}{\\bf{M}}^{-1}{\\bf{B}}_n^{-1})\\beta_n={\\bf{\\beta}}_{**}^{\\top}{\\bf{C}}{\\bf{\\beta}}_{**}\\) and \\(\\beta_{**}={\\mathbf{X}}_0\\beta_n\\). Show that \\(({\\bf{Y}}-{\\bf{X}}{\\bf{B}})^{\\top}({\\bf{Y}}-{\\bf{X}}{\\bf{B}})={\\bf{S}}+({\\bf{B}}-\\widehat{\\bf{B}})^{\\top}{\\bf{X}}^{\\top}{\\bf{X}}({\\bf{B}}-\\widehat{\\bf{B}})\\) where \\({\\bf{S}}= ({\\bf{Y}}-{\\bf{X}}\\widehat{\\bf{B}})^{\\top}({\\bf{Y}}-{\\bf{X}}\\widehat{\\bf{B}})\\), \\(\\widehat{\\bf{B}}= ({\\bf{X}}^{\\top}{\\bf{X}})^{-1}{\\bf{X}}^{\\top}{\\bf{Y}}\\). "],["Chap4.html", "Chapter 4 Simulation methods", " Chapter 4 Simulation methods Simulation methods are very important in modern Bayesian inference. We will introduce Importance sampling, Gibbs and Metropolis-Hastings, as well as how to calculate the marginal likelihood, which most of the times does not have analytically solution. We also will have examples showing how solve them in R, as well as mathematical and computational exercises in R. "],["Chap5.html", "Chapter 5 Graphical user interface", " Chapter 5 Graphical user interface This chapter presents our graphical user interface (GUI) to carry out Bayesian regression analysis in a very friendly environment without any programming skills (drag and drop). Our GUI is based on an interactive web application using shiny (Chang 2018), and packages like MCMCpack (Martin, Quinn, and Park 2018) and bayesm (P. Rossi 2017) from R software (R Core Team 2023), and is designed for teaching and applied purposes at an introductory level. In the next chapters of the second part of this book, we carry out some applications to highlight the potential of our GUI for applied researchers and practitioners. References "],["Chap8.html", "Chapter 6 Time series", " Chapter 6 Time series We will show the state-space representation of time series models with their theory foundation, and perform applications using R and our GUI. We will have mathematical and computational exercises in our GUI and in R. "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
