[["index.html", "Introduction to Bayesian Data Modeling A GUIded toolkit using R Introduction", " Introduction to Bayesian Data Modeling A GUIded toolkit using R Andrés Ramírez-Hassan 2025-02-18 Introduction Since the late 90s, Bayesian inference has gained significant popularity among researchers due to the computational revolution and the availability of algorithms to solve complex integrals. However, many researchers, students, and practitioners still lack a deep understanding and practical application of this inferential approach. The primary reason for this is the requirement for strong programming skills. Introduction to Bayesian Data Modeling: A GUIded Toolkit using R mainly targets those who want to apply Bayesian inference with a solid conceptual and formal understanding but may not have the time to develop programming skills. Thus, this book provides a graphical user interface (GUI) for performing Bayesian regression in a user-friendly environment. It also offers the basic theory and its code implementation using R software (R Core Team, 2021), along with applications that highlight the potential of Bayesian inference. Additionally, the book includes theoretical and computational exercises for those interested in developing more complex models. In particular, the first part presents step-by-step mathematical proofs of basic models, serving as the foundation for deriving key mathematical results in the more complex models covered in the second and third parts. Our GUI is based on an interactive web application using shiny (Chang et al., 2018), along with several packages in R. Users can estimate univariate, multivariate, time series, longitudinal/panel data, and Bayesian model averaging models using our GUI. In addition, it provides basic summaries, as well as formal and graphical diagnostics of the posterior chains. Our GUI can be run on any operating system and is freely available at GitHub. Users can access simulated and real datasets in the folders DataSim and DataApp, respectively. The DataSim folder also includes the files used to simulate different processes, providing access to population parameters. As a result, these files serve as a pedagogical tool for demonstrating various statistical properties. The DataApp folder contains the datasets used in our applications, which users are encouraged to use as templates for structuring their own datasets. This book is divided into three parts: Part One (Chapters 1–4) covers theoretical concepts, mathematical foundations, programming, and simulation. Part Two (Chapters 5–10) focuses on regression applications, with an emphasis on computational methods for obtaining posterior draws at three levels of programming skills: No programming skills required (using our GUI). Intermediate skills (using specialized R packages for Bayesian inference). Advanced skills (coding posterior draws from scratch). Part Three (Chapters 11–14) introduces advanced methods in Bayesian inference. Some mathematical derivations are presented in detail in the first part of the book, while most proofs are omitted in the second and third parts. However, the mathematical steps covered in Part One can be applied to derive results in Parts Two and Three. In the first part, Chapter 1 introduces fundamental concepts in Bayesian inference, starting with Bayes’ rule, its components, formal definitions, and basic examples. It then presents the basics of Bayesian inference within a decision-theoretic framework under uncertainty. Chapter 2 discusses the conceptual differences between Bayesian and Frequentist statistical approaches, providing both a historical and philosophical perspective on Bayesian statistics and econometrics while highlighting contrasts with the Frequentist approach. Chapter 3 introduces conjugate families in basic statistical models, solving them both analytically and computationally. Chapter 4 presents simulation-based methods, which are essential in modern Bayesian inference since most realistic models lack standard forms or analytical solutions. In the second part, Chapter 5 introduces our graphical user interface (GUI). Univariate and multivariate regression models are covered in Chapters 6 and 7. Chapter 8 focuses on univariate and multivariate time series models, while Chapter 9 covers Bayesian longitudinal/panel data models. Chapter 10 introduces Bayesian model averaging. The third part covers advanced topics: - Chapter 11 explores semi-parametric and non-parametric models. - Chapter 12 discusses causal inference. - Chapter 13 covers Bayesian methods in machine learning. - Chapter 14 describes approximation methods. About Me My name is Andrés Ramírez-Hassan, and I am an applied and theoretical econometrician working as a Distinguished Professor in the School of Finance, Economics, and Government at Universidad EAFIT (Medellín, Colombia). I hold a PhD in Statistical Science, a Master’s degree in Finance, a Master’s degree in Economics, and a Bachelor’s degree in Economics. I have been a research fellow at the Department of Econometrics and Business Statistics at Monash University and a visiting professor in the Department of Economics at the University of Melbourne and the University of Glasgow. Since completing my PhD, my research has primarily focused on Bayesian econometrics, with applications in crime, finance, health, sports, and utilities. My work has been published (or is forthcoming) in highly regarded journals, including: International Journal of Forecasting, Journal of Applied Econometrics, Econometric Reviews, Journal of Computational and Graphical Statistics, The R Journal, Economic Modelling, Spatial Economic Analysis, Economic Inquiry, World Development, Journal of Sport Economics, Empirical Economics, Australian and New Zealand Journal of Statistics, Brazilian Journal of Probability and Statistics, among other prestigious international research outlets. I founded BEsmarter — Bayesian Econometrics: simulations, models, and applications to research, teaching, and encoding with responsibility. This research group’s mission is to lead and excel in generating and disseminating Bayesian econometric knowledge through research, teaching, and software. Our vision is to advance worldwide econometric research, teaching, and applications based on the Bayesian framework, aiming to: Inspire new econometric ideas Create a user-friendly environment for Bayesian econometrics applications Transform classical econometric research, teaching, and applications Address critical social problems through scientific advancements Contact Email: aramir21@gmail.com / aramir21@eafit.edu.co Website: http://www.besmarter-team.org License This book is licensed under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. This book is licensed under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. "],["preface.html", "Preface", " Preface The main goal of this book is to make the Bayesian inferential framework more approachable to students, researchers, and practitioners who wish to understand and apply this statistical/econometric approach but do not have the time to develop programming skills. I have aimed to strike a balance between applicability and theory. This book provides a very user-friendly graphical user interface (GUI) to implement the most common regression models, while also covering the basic mathematical developments and their code implementation for those interested in advancing to more complex models. "],["to-instructors-and-students.html", "To instructors and students", " To instructors and students This book is divided into three parts: foundations (chapters 1 to 4), regression analysis (chapters 5 to 10), and Advanced methods (chapters 11 to 14). Our graphical user interface (GUI) is designed for the second part. The source code can be found at https://github.com/besmarter/BSTApp. Instructors and students can access all the code, along with simulated and real datasets. There are three ways to install our GUI: Type shiny::runGitHub(\"besmarter/BSTApp\", launch.browser=T) in the R console or any R code editor and execute it. Visit https://posit.cloud/content/4328505, log in or sign up for Posit Cloud, navigate to the BSTApp-master folder in the Files tab of the right-bottom window, then click on the app.R file and select Run App. Use a Docker image by typing in the Command Prompt: docker pull magralo95/besmartergui:latest docker run --rm -p 3838:3838 magralo95/besmartergui Then users can access our GUI by going to http://localhost:3838/. See Chapter 5 for details. Students should have a basic understanding of probability theory and statistics, as well as some background in econometrics and time series, particularly regression analysis. Familiarity with standard univariate and multivariate probability distributions is strongly recommended. See a nice summary of useful probability distributions in (Greenberg 2012). Additionally, students who wish to master the material in this book should have programming skills in R software. An excellent starting point for R programming is the R Introduction Manual. I have included both formal and computational exercises at the end of each chapter to help students gain a better understanding of the material presented. A solutions manual for these exercises accompanies this book. Instructors can use this book as a textbook for a course on introductory Bayesian Econometrics/Statistics, with a strong emphasis on implementation and applications. This book is intended to be complementary, rather than a substitute, for excellent resources on the topic, such as Andrew Gelman et al. (2021), Chan et al. (2019), P. E. Rossi, Allenby, and McCulloch (2012), Greenberg (2012), John Geweke (2005), Lancaster (2004), and Koop (2003). References "],["acknowledgments.html", "Acknowledgments", " Acknowledgments I began developing our graphical user interface (GUI) in 2016, after being diagnosed with cervical dystonia. I worked on this side project during weekends, which I called ``nerd weekends,’’ and it served as a form of release from my health condition. Once I began to recover, I invited Mateo Graciano, my former student, business partner, and friend, to join the project. He has been instrumental in developing our GUI, and I am enormously grateful to him. I would also like to thank the members of the BEsmarter research group at Universidad EAFIT, as well as the NUMBATs members at Monash University, for their valuable feedback and recommendations to improve our GUI. This book is an extension of the paper (Ramírez-Hassan and Graciano-Londoño 2020), which serves as a brief user guide for our GUI. I decided to write this book to explain the underlying theory and code in our GUI, and to use it as a textbook in my course on Bayesian econometrics/statistics. I am grateful to my students in this course; their insights and thoughtful questions have deepened my understanding of the material. I also thank Chris Parmeter for his suggestions on how to present our user guide, Professor Raul Pericchi and Juan Carlos Correa for introducing me to Bayesian statistics, and Liana Jacobi and Chun Fung Kwok (Jackson) from the University of Melbourne, as well as David Frazier from Monash University, for engaging talks and amazing collaborations in Bayesian econometrics/statistics. My sincere gratitude goes to Professor Peter Diggle for his unwavering support of my career, and especially to Professor Gael Martin, who gave me the opportunity to work with her, she is a constant source of intellectual inspiration. Finally, I would like to express my thanks to my colleagues and staff at Universidad EAFIT for their continuous support. To my parents, Orlando and Nancy, who have always been there for me with their unconditional support. They have taught me that the primary aspect of human spiritual evolution is humility, a lesson I am still learning every day. To my fiancée, Estephania, for her unwavering love and support. References "],["Chap1.html", "Chapter 1 Basic formal concepts", " Chapter 1 Basic formal concepts We introduce formal concepts in Bayesian inference, beginning with Bayes’ rule and its components, along with their formal definitions and basic examples. In addition, we present key features of Bayesian inference, such as Bayesian updating and asymptotic sampling properties. We also cover the basics of Bayesian inference from a decision-theoretic perspective under uncertainty, introducing important concepts like loss functions, risk functions, and optimal decision rules. "],["sec11.html", "1.1 The Bayes’ rule", " 1.1 The Bayes’ rule As expected, the starting point for performing Bayesian inference is Bayes’ rule, which provides the solution to the inverse problem of determining causes from observed effects. This rule combines prior beliefs with objective probabilities based on repeatable experiments, allowing us to move from observations to probable causes.1 Formally, the conditional probability of \\(A_i\\) given \\(B\\) is equal to the conditional probability of \\(B\\) given \\(A_i\\), multiplied by the marginal probability of \\(A_i\\), divided by the marginal probability of \\(B\\): \\[\\begin{align} P(A_i|B)&amp;=\\frac{P(A_i,B)}{P(B)}\\\\ &amp;=\\frac{P(B|A_i) \\times P(A_i)}{P(B)}, \\tag{1.1} \\end{align}\\] where equation (1.1) is Bayes’ rule. By the law of total probability, \\(P(B) = \\sum_i P(B \\mid A_i) P(A_i) \\neq 0\\), and \\(\\{ A_i, i = 1, 2, \\dots \\}\\) is a finite or countably infinite partition of the sample space. In the Bayesian framework, \\(B\\) represents sample information that updates a probabilistic statement about an unknown object \\(A_i\\) according to probability rules. This is done using Bayes’ rule, which incorporates prior “beliefs” about \\(A_i\\), i.e., \\(P(A_i)\\), sample information relating \\(B\\) to the particular state of nature \\(A_i\\) through a probabilistic statement, \\(P(B \\mid A_i)\\), and the probability of observing that specific sample information, \\(P(B)\\). Let’s consider a simple example, the base rate fallacy: Assume that the sample information comes from a positive result from a test whose true positive rate (sensitivity) is 98%, i.e., \\(P(+ \\mid \\text{disease}) = 0.98\\). On the other hand, the prior information regarding being infected with this disease comes from a base incidence rate of 0.002, i.e., \\(P(\\text{disease}) = 0.002\\). The question is: What is the probability of actually being infected, given a positive test result? This is an example of the base rate fallacy, where a positive test result for a disease with a very low base incidence rate still gives a low probability of actually having the disease. The key to answering this question lies in understanding the difference between the probability of having the disease given a positive test result, \\(P(\\text{disease} \\mid +)\\), and the probability of a positive result given the disease, \\(P(+ \\mid \\text{disease})\\). The former is the crucial result, and Bayes’ rule helps us to compute it. Using Bayes’ rule (equation (1.1)): \\[ P(\\text{disease} \\mid +) = \\frac{P(+ \\mid \\text{disease}) \\times P(\\text{disease})}{P(+)} = \\frac{0.98 \\times 0.002}{0.98 \\times 0.002 + (1-0.98) \\times (1-0.002)} = 0.09 \\] where \\(P(+) = P(+ \\mid \\text{disease}) \\times P(\\text{disease}) + P(+ \\mid \\lnot \\text{disease}) \\times P(\\lnot \\text{disease})\\).2 The following code shows how to perform this exercise in R. PD &lt;- 0.002 # Probability of disease PPD &lt;- 0.98 # True positive (Sensitivity) PDP &lt;- PD * PPD / (PD * PPD + (1 - PD)*(1 - PPD)) paste(&quot;Probability of disease given a positive test is&quot;, sep = &quot; &quot;, round(PDP, 2)) ## [1] &quot;Probability of disease given a positive test is 0.09&quot; We observe that despite having a positive result, the probability of actually having the disease remains low. This is due to the base rate being so small. Another interesting example, which lies at the heart of the origin of Bayes’ theorem (Thomas Bayes 1763), is related to the existence of God (Stigler 2018). In Section X of David Hume’s “An Inquiry concerning Human Understanding” (1748), titled Of Miracles, Hume argues that when someone claims to have seen a miracle, this provides poor evidence that the event actually occurred, as it contradicts our everyday observations. In response, Richard Price, who finished and published “An Essay Towards Solving a Problem in the Doctrine of Chances” in 1763 (after Bayes’ death in 1761), argues against Hume by highlighting the difference between impossibility in casual conversation and physical impossibility. Price used an example of a die with a million sides, where impossibility refers to rolling a specific side, and physical impossibility refers to rolling a side that does not exist. In millions of throws, the latter would never happen, while the former would eventually occur. Now, let’s consider a scenario involving two cases of resurrection (Res): Jesus Christ and Elvis. The total number of people who have ever lived is approximately 108.5 billion,3 so the prior base rate is given by \\(\\frac{2}{108.5 \\times 10^9}\\). On the other hand, suppose the sample information comes from a highly reliable witness with a true positive rate of 0.9999999. The question then is: What is the probability of this miracle occurring?4 Using Bayes’ rule: \\[\\begin{align*} P(\\text{Res}\\mid \\text{Witness}) &amp; = \\frac{P(\\text{Witness}\\mid \\text{Res})\\times P(\\text{Res})}{P(\\text{Witness})}\\\\ &amp; =\\frac{2/(108.5 * 10^9) \\times 0.9999999}{2/(108.5 * 10^9) \\times 0.9999999 + (1-2/(108.5 * 10^9)) \\times (1-0.9999999)}\\\\ &amp; = 0.000184297806959661 \\end{align*}\\] where \\(P(\\text{Witness}) = P(\\text{Witness} \\mid \\text{Res}) \\times P(\\text{Res}) + (1 - P(\\text{Witness} \\mid \\text{Res})) \\times (1 - P(\\text{Res}))\\). Thus, the probability of a resurrection, given a very reliable witness, is approximately \\(1.843 \\times 10^{-4}\\). The following code shows how to perform this exercise in R. # Probability of resurrection PR &lt;- 2/(108.5 * 10^9) PWR &lt;- 0.9999999 # True positive rate PRW &lt;- PR * PWR / (PR * PWR + (1 - PR)*(1 - PWR)) paste(&quot;Probability of resurrection given witness is&quot;, sep = &quot; &quot;, PRW) ## [1] &quot;Probability of resurrection given witness is 0.000184297806959661&quot; Observe that we can condition on multiple events in Bayes’ rule. Let’s consider two conditioning events, \\(B\\) and \\(C\\). Then, equation (1.1) becomes \\[\\begin{align} P(A_i\\mid B,C)&amp;=\\frac{P(A_i,B,C)}{P(B,C)}\\nonumber\\\\ &amp;=\\frac{P(B\\mid A_i,C) \\times P(A_i\\mid C) \\times P(C)}{P(B\\mid C)P(C)}. \\tag{1.2} \\end{align}\\] Let’s use this rule in one of the most intriguing statistical puzzles, the Monty Hall problem, to illustrate how to use equation (1.2) (Selvin 1975; Morgan et al. 1991). This was the situation faced by a contestant in the American television game show Let’s Make a Deal. In this game, the contestant was asked to choose a door, behind one of which there is a car, and behind the others, goats. Let’s say the contestant picks door No. 1, and the host (Monty Hall), who knows what is behind each door, opens door No. 3, revealing a goat. Then, the host asks the tricky question: Do you want to pick door No. 2? Let’s define the following events: \\(P_i\\): the event contestant picks door No. \\(i\\), which stays closed, \\(H_i\\): the event host picks door No. \\(i\\), which is open and contains a goat, \\(C_i\\): the event car is behind door No. \\(i\\). In this particular setting, the contestant is interested in the probability of the event \\(P(C_2 \\mid H_3, P_1)\\). A naive answer would be that it is irrelevant, as initially, \\(P(C_i) = \\frac{1}{3}, \\ i = 1, 2, 3\\), and now \\(P(C_i \\mid H_3) = \\frac{1}{2}, \\ i = 1, 2\\), since the host opened door No. 3. So, why bother changing the initial guess if the odds are the same (1:1)? The important point here is that the host knows what is behind each door and always picks a door where there is a goat, given the contestant’s choice. In this particular setting: \\[ P(H_3 \\mid C_3, P_1) = 0, \\quad P(H_3 \\mid C_2, P_1) = 1, \\quad P(H_3 \\mid C_1, P_1) = \\frac{1}{2}. \\] Then, using equation (1.2), we can calculate the posterior probability. \\[\\begin{align*} P(C_2\\mid H_3,P_1)&amp;= \\frac{P(C_2,H_3,P_1)}{P(H_3,P_1)}\\\\ &amp;= \\frac{P(H_3\\mid C_2,P_1)P(C_2\\mid P_1)P(P_1)}{P(H_3\\mid P_1)\\times P(P_1)}\\\\ &amp;= \\frac{P(H_3\\mid C_2,P_1)P(C_2)}{P(H_3\\mid P_1)}\\\\ &amp;=\\frac{1\\times 1/3}{1/2}, \\end{align*}\\] Where the third equation uses the fact that \\(C_i\\) and \\(P_i\\) are independent events, and \\(P(H_3 \\mid P_1) = \\frac{1}{2}\\) because this depends only on \\(P_1\\) (not on \\(C_2\\)). Therefore, changing the initial decision increases the probability of getting the car from \\(\\frac{1}{3}\\) to \\(\\frac{2}{3}\\)! Thus, it is always a good idea to change the door. Let’s see a simulation exercise in R to check this answer: set.seed(0101) # Set simulation seed S &lt;- 100000 # Simulations Game &lt;- function(switch = 0){ # switch = 0 is not change # switch = 1 is to change opts &lt;- 1:3 car &lt;- sample(opts, 1) # car location guess1 &lt;- sample(opts, 1) # Initial guess if(car != guess1) { host &lt;- opts[-c(car, guess1)] } else { host &lt;- sample(opts[-c(car, guess1)], 1) } win1 &lt;- guess1 == car # Win no change guess2 &lt;- opts[-c(host, guess1)] win2 &lt;- guess2 == car # Win change if(switch == 0){ win &lt;- win1 } else { win &lt;- win2 } return(win) } #Win probabilities not changing Prob &lt;- mean(replicate(S, Game(switch = 0))) paste(&quot;Winning probabilities no changing door is&quot;, Prob, sep = &quot; &quot;) ## [1] &quot;Winning probabilities no changing door is 0.3334&quot; #Win probabilities changing Prob &lt;- mean(replicate(S, Game(switch = 1))) paste(&quot;Winning probabilities changing door is&quot;, Prob, sep = &quot; &quot;) ## [1] &quot;Winning probabilities changing door is 0.6654&quot; References "],["sec12.html", "1.2 Bayesian framework: A brief summary of theory", " 1.2 Bayesian framework: A brief summary of theory Given an unknown parameter set \\(\\boldsymbol{\\theta}\\), and a particular realization of the data \\(\\mathbf{y}\\), Bayes’ rule may be applied analogously,5 \\[\\begin{align} \\pi(\\boldsymbol{\\theta}\\mid \\mathbf{y})&amp;=\\frac{p(\\mathbf{y}\\mid \\boldsymbol{\\theta}) \\times \\pi(\\boldsymbol{\\theta})}{p(\\mathbf{y})}, \\tag{1.3} \\end{align}\\] where \\(\\pi(\\boldsymbol{\\theta}\\mid \\mathbf{y})\\) is the posterior density function, \\(\\pi(\\boldsymbol{\\theta})\\) is the prior density, \\(p(\\mathbf{y}\\mid \\boldsymbol{\\theta})\\) is the likelihood (statistical model), and \\[\\begin{equation} p(\\mathbf{y})=\\int_{\\mathbf{\\Theta}}p(\\mathbf{y}\\mid \\boldsymbol{\\theta})\\pi(\\boldsymbol{\\theta})d\\boldsymbol{\\theta}=\\mathbb{E}\\left[p(\\mathbf{y}\\mid \\boldsymbol{\\theta})\\right] \\tag{1.4} \\end{equation}\\] is the marginal likelihood or prior predictive. Observe that for this expected value to be meaningful, the prior should be a proper density, that is, it must integrate to one; otherwise, it does not make sense. Observe that \\(p(\\mathbf{y} \\mid \\boldsymbol{\\theta})\\) is not a density in \\(\\boldsymbol{\\theta}\\). In addition, \\(\\pi(\\boldsymbol{\\theta})\\) does not have to integrate to 1, that is, \\(\\pi(\\boldsymbol{\\theta})\\) can be an improper density function, \\(\\int_{\\mathbf{\\Theta}} \\pi(\\boldsymbol{\\theta}) d\\boldsymbol{\\theta} = \\infty\\). However, \\(\\pi(\\boldsymbol{\\theta} \\mid \\mathbf{y})\\) is a proper density function, that is, \\(\\int_{\\mathbf{\\Theta}} \\pi(\\boldsymbol{\\theta} \\mid \\mathbf{y}) d\\boldsymbol{\\theta} = 1\\). For instance, set \\(\\pi(\\boldsymbol{\\theta}) = c\\), where \\(c\\) is a constant, then \\(\\int_{\\mathbf{\\Theta}} c d\\boldsymbol{\\theta} = \\infty\\). However, \\[ \\int_{\\mathbf{\\Theta}} \\pi(\\boldsymbol{\\theta} \\mid \\mathbf{y}) d\\boldsymbol{\\theta} = \\int_{\\mathbf{\\Theta}} \\frac{p(\\mathbf{y} \\mid \\boldsymbol{\\theta}) \\times c}{\\int_{\\mathbf{\\Theta}} p(\\mathbf{y} \\mid \\boldsymbol{\\theta}) \\times c \\, d\\boldsymbol{\\theta}} d\\boldsymbol{\\theta} = 1 \\] where \\(c\\) cancels out. \\(\\pi(\\boldsymbol{\\theta} \\mid \\mathbf{y})\\) is a sample updated ``probabilistic belief” version of \\(\\pi(\\boldsymbol{\\theta})\\), where \\(\\pi(\\boldsymbol{\\theta})\\) is a prior probabilistic belief which can be constructed from previous empirical work, theoretical foundations, expert knowledge, and/or mathematical convenience. This prior usually depends on parameters, which are named . In addition, the Bayesian approach implies using a probabilistic model about \\(\\mathbf{Y}\\) given \\(\\boldsymbol{\\theta}\\), that is, \\(p(\\mathbf{y} \\mid \\boldsymbol{\\theta})\\), where its integral over \\(\\mathbf{\\Theta}\\), \\(p(\\mathbf{y})\\), is named due to being a measure of model fit to the data. Observe that the Bayesian inferential approach is conditional, that is, what can we learn about an unknown object \\(\\boldsymbol{\\theta}\\) given that we already observed \\(\\mathbf{ Y} =\\mathbf{y}\\)? The answer is also conditional on the probabilistic model, that is, \\(p(\\mathbf{y} \\mid \\boldsymbol{\\theta})\\). So, what if we want to compare different models, say \\(\\mathcal{M}_m\\), \\(m = \\{1,2,\\dots,M\\}\\)? Then, we should make explicit this in the Bayes’ rule formulation: \\[\\begin{align} \\pi(\\boldsymbol{\\theta}\\mid \\mathbf{y},\\mathcal{M}_m)&amp;=\\frac{p(\\mathbf{y}\\mid \\boldsymbol{\\theta},\\mathcal{M}_m) \\times \\pi(\\boldsymbol{\\theta}\\mid \\mathcal{M}_m)}{p(\\mathbf{y}\\mid \\mathcal{M}_m)}. \\tag{1.5} \\end{align}\\] The posterior model probability is \\[\\begin{align} \\pi(\\mathcal{M}_m\\mid \\mathbf{y})&amp;=\\frac{p(\\mathbf{y}\\mid \\mathcal{M}_m) \\times \\pi(\\mathcal{M}_m)}{p(\\mathbf{y})}, \\tag{1.6} \\end{align}\\] where \\(p(\\mathbf{y}\\mid \\mathcal{M}_m)=\\int_{\\mathbf{\\Theta}}p(\\mathbf{y}\\mid \\boldsymbol{\\theta},\\mathcal{M}_m) \\times \\pi(\\boldsymbol{\\theta}\\mid \\mathcal{M}_m)d\\boldsymbol{\\theta}\\) due to equation (1.5), and \\(\\pi(\\mathcal{M}_m)\\) is the prior model probability. Calculating \\(p(\\mathbf{y})\\) in equations (1.3) and (1.6) is very demanding in most of the realistic cases. Fortunately, it is not required when performing inference about \\(\\boldsymbol{\\theta}\\) as this is integrated out from it. Then, all you need to know about the shape of \\(\\boldsymbol{\\theta}\\) is in \\(p(\\mathbf{y} \\mid \\boldsymbol{\\theta}, \\mathcal{M}_m) \\times \\pi(\\boldsymbol{\\theta} \\mid \\mathcal{M}_m)\\), or without explicitly conditioning on \\(\\mathcal{M}_m\\), \\[\\begin{align} \\pi(\\boldsymbol{\\theta}\\mid \\mathbf{y})&amp; \\propto p(\\mathbf{y}\\mid \\boldsymbol{\\theta}) \\times \\pi(\\boldsymbol{\\theta}). \\tag{1.7} \\end{align}\\] Equation (1.7) is a very good shortcut to perform Bayesian inference about \\(\\boldsymbol{\\theta}\\). We can also avoid calculating \\(p(\\mathbf{y})\\) when performing model selection (hypothesis testing) using the posterior odds ratio, that is, comparing models \\(\\mathcal{M}_1\\) and \\(\\mathcal{M}_2\\), \\[\\begin{align} PO_{12}&amp;=\\frac{\\pi(\\mathcal{M}_1\\mid \\mathbf{y})}{\\pi(\\mathcal{M}_2\\mid \\mathbf{y})} \\nonumber \\\\ &amp;=\\frac{p(\\mathbf{y}\\mid \\mathcal{M}_1)}{p(\\mathbf{y}\\mid \\mathcal{M}_2)}\\times\\frac{\\pi(\\mathcal{M}_1)}{\\pi(\\mathcal{M}_2)}, \\tag{1.8} \\end{align}\\] where the first term in equation (1.8) is named the Bayes factor, and the second term is the prior odds. Observe that the Bayes factor is a ratio of ordinates for \\(\\mathbf{y}\\) under different models. Then, the Bayes factor is a measure of relative sample evidence in favor of model 1 compared to model 2. However, we still need to calculate \\(p(\\mathbf{y}\\mid \\mathcal{M}_m) = \\int_{\\mathbf{\\Theta}} p(\\mathbf{y}\\mid \\boldsymbol{\\theta}, \\mathcal{M}_m) \\pi(\\boldsymbol{\\theta}\\mid \\mathcal{M}_m) d\\boldsymbol{\\theta} = \\mathbb{E}\\left[ p(\\mathbf{y}\\mid \\boldsymbol{\\theta}, \\mathcal{M}_m) \\right]\\). For this integral to be meaningful, the prior must be proper. Using an improper prior has unintended consequences when comparing models; for instance, parsimonious models are favored by posterior odds or Bayes factors, and these values may depend on units of measure (see Chapter 3). A nice feature of comparing models using posterior odds is that if we have an exhaustive set of competing models such that \\(\\sum_{m=1}^M \\pi(\\mathcal{M}_m \\mid \\mathbf{y}) = 1\\), then we can recover \\(\\pi(\\mathcal{M}_m \\mid \\mathbf{y})\\) without calculating \\(p(\\mathbf{y})\\). In particular, given two models \\(\\mathcal{M}_1\\) and \\(\\mathcal{M}_2\\) such that \\(\\pi(\\mathcal{M}_1 \\mid \\mathbf{y}) + \\pi(\\mathcal{M}_2 \\mid \\mathbf{y}) = 1\\), we have: \\[ \\pi(\\mathcal{M}_1 \\mid \\mathbf{y}) = \\frac{PO_{12}}{1 + PO_{12}} \\quad \\text{and} \\quad \\pi(\\mathcal{M}_2 \\mid \\mathbf{y}) = 1 - \\pi(\\mathcal{M}_1 \\mid \\mathbf{y}). \\] In general, \\[ \\pi(\\mathcal{M}_m \\mid \\mathbf{y}) = \\frac{p(\\mathbf{y} \\mid \\mathcal{M}_m) \\times \\pi(\\mathcal{M}_m)}{\\sum_{l=1}^M p(\\mathbf{y} \\mid \\mathcal{M}_l) \\times \\pi(\\mathcal{M}_l)}. \\] These posterior model probabilities can be used to perform Bayesian model averaging. Table 1.1 shows guidelines for the interpretation of \\(2\\log(PO_{12})\\) (R. E. Kass and Raftery 1995). This transformation is done to replicate the structure of the likelihood ratio test statistic. However, posterior odds do not require nested models as the likelihood ratio test does. Table 1.1: Kass and Raftery guidelines \\(2\\log(PO_{12})\\) \\(PO_{12}\\) Evidence against \\(\\mathcal{M}_{2}\\) 0 to 2 1 to 3 Not worth more than a bare mention 2 to 6 3 to 20 Positive 6 to 10 20 to 150 Strong &gt; 10 &gt; 150 Very strong Observe that the posterior odds ratio is a relative criterion, that is, we specify an exhaustive set of competing models and compare them. However, we may want to check the performance of a model on its own or use a non-informative prior. In this case, we can use the posterior predictive p-value (A. Gelman and Meng 1996; A. Gelman, Meng, and Stern 1996).6 The intuition behind the predictive p-value is simple: analyze the discrepancy between the model’s assumptions and the data by checking a potential extreme tail-area probability. Observe that this approach does not check if a model is true; its focus is on potential discrepancies between the model and the data at hand. This is done by simulating pseudo-data from our sampling model (\\(\\mathbf{y}^{(s)}, s=1,2,\\dots,S\\)) using draws from the posterior distribution, and then calculating a discrepancy measure, \\(D(\\mathbf{y}^{(s)},\\boldsymbol{\\theta})\\), to estimate the posterior predictive p-value, \\[ p_D(\\mathbf{y}) = P[D(\\mathbf{y}^{(s)},\\boldsymbol{\\theta}) \\geq D(\\mathbf{y},\\boldsymbol{\\theta})], \\] using the proportion of the \\(S\\) draws for which \\(D(\\mathbf{y}^{(s)},\\boldsymbol{\\theta}^{(s)}) \\geq D(\\mathbf{y},\\boldsymbol{\\theta}^{(s)})\\). Extreme tail probabilities (\\(p_D(\\mathbf{y}) \\leq 0.05\\) or \\(p_D(\\mathbf{y}) \\geq 0.95\\)) suggest potential discrepancies between the data and the model. A. Gelman, Meng, and Stern (1996) also suggest the posterior predictive p-value based on the minimum discrepancy, \\[ D_{\\min}(\\mathbf{y}) = \\min_{\\boldsymbol{\\theta}} D(\\mathbf{y}, \\boldsymbol{\\theta}), \\] and the average discrepancy statistic \\[ D(\\mathbf{y}) = \\mathbb{E}[D(\\mathbf{y}, \\boldsymbol{\\theta})] = \\int_{\\mathbf{\\Theta}} D(\\mathbf{y}, \\boldsymbol{\\theta}) \\pi(\\boldsymbol{\\theta} \\mid \\mathbf{y}) d\\boldsymbol{\\theta}. \\] These alternatives can be more computationally demanding. The Bayesian approach is also suitable to get probabilistic predictions, that is, we can obtain a posterior predictive density \\[\\begin{align} \\pi(\\mathbf{y}_0\\mid \\mathbf{y},\\mathcal{M}_m) &amp; =\\int_{\\mathbf{\\Theta}}\\pi(\\mathbf{y}_0,\\boldsymbol{\\theta}\\mid \\mathbf{y},\\mathcal{M}_m)d\\boldsymbol{\\theta}\\nonumber\\\\ &amp;=\\int_{\\mathbf{\\Theta}}\\pi(\\mathbf{y}_0\\mid \\boldsymbol{\\theta},\\mathbf{y},\\mathcal{M}_m)\\pi(\\boldsymbol{\\theta}\\mid \\mathbf{y},\\mathcal{M}_m)d\\boldsymbol{\\theta}. \\tag{1.9} \\end{align}\\] Observe that equation (1.9) is again an expectation \\(\\mathbb{E}[\\pi(\\mathbf{y}_0 \\mid \\boldsymbol{\\theta}, \\mathbf{y}, \\mathcal{M}_m)]\\), this time using the posterior distribution. Therefore, the Bayesian approach takes estimation error into account when performing prediction. As we have shown many times, expectation (integration) is a common feature in Bayesian inference. That is why the remarkable relevance of computation based on Monte Carlo integration in the Bayesian framework. Bayesian model averaging (BMA) allows for considering model uncertainty in prediction or any unknown probabilistic object. In the case of the predictive density, \\[\\begin{align} \\pi(\\mathbf{y}_0\\mid \\mathbf{y})&amp;=\\sum_{m=1}^M \\pi(\\mathcal{M}_m\\mid \\mathbf{y})\\pi(\\mathbf{y}_0\\mid \\mathbf{y},\\mathcal{M}_m). \\end{align}\\] In the case of the posterior density of the parameters, \\[\\begin{align} \\pi(\\boldsymbol{\\theta}\\mid \\mathbf{y})&amp;=\\sum_{m=1}^M \\pi(\\mathcal{M}_m\\mid \\mathbf{y})\\pi(\\boldsymbol{\\theta}\\mid \\mathbf{y},\\mathcal{M}_m), \\end{align}\\] where \\[\\begin{align} \\mathbb{E}(\\boldsymbol{\\theta}\\mid \\mathbf{y})=\\sum_{m=1}^{M}\\hat{\\boldsymbol{\\theta}}_m \\pi(\\mathcal{M}_m\\mid \\mathbf{y}), \\tag{1.10} \\end{align}\\] and \\[\\begin{align} Var({\\theta}_k\\mid \\mathbf{y})= \\sum_{m=1}^{M}\\pi(\\mathcal{M}_m\\mid \\mathbf{y}) \\widehat{Var} ({\\theta}_{km}\\mid \\mathbf{y},\\mathcal{M}_m)+\\sum_{m=1}^{M} \\pi(\\mathcal{M}_m\\mid \\mathbf{y}) (\\hat{{\\theta}}_{km}-\\mathbb{E}[{\\theta}_{km}\\mid \\mathbf{y}])^2, \\tag{1.11} \\end{align}\\] \\(\\hat{\\boldsymbol{\\theta}}_m\\) is the posterior mean and \\(\\widehat{Var}({\\theta}_{km}\\mid \\mathbf{y},\\mathcal{M}_m)\\) is the posterior variance of the \\(k\\)-th element of \\(\\boldsymbol{\\theta}\\) under model \\(\\mathcal{M}_m\\). Observe how the variance in equation (1.11) captures the extra variability due to potential differences between the mean posterior estimates associated with each model, and the posterior mean that incorporates model uncertainty in equation (1.10). A significant advantage of the Bayesian approach, which is particularly useful in (see Chapter 8), is the way the posterior distribution updates with new sample information. Given \\(\\mathbf{y} = \\mathbf{y}_{1:t+1}\\) as a sequence of observations from 1 to \\(t+1\\), then \\[\\begin{align} \\pi(\\boldsymbol{\\theta}\\mid \\mathbf{y}_{1:t+1})&amp;\\propto p(\\mathbf{y}_{1:t+1}\\mid \\boldsymbol{\\theta})\\times \\pi(\\boldsymbol{\\theta})\\nonumber\\\\ &amp;= p(y_{t+1}\\mid \\mathbf{y}_{1:t},\\boldsymbol{\\theta})\\times p(\\mathbf{y}_{1:t}\\mid \\boldsymbol{\\theta})\\times \\pi(\\boldsymbol{\\theta})\\nonumber\\\\ &amp;\\propto p(y_{t+1}\\mid \\mathbf{y}_{1:t},\\boldsymbol{\\theta})\\times \\pi(\\boldsymbol{\\theta}\\mid \\mathbf{y}_{1:t}). \\tag{1.12} \\end{align}\\] We observe in Equation (1.12) that the new prior is simply the posterior distribution based on the previous observations. This is particularly useful under the assumption of conditional independence, that is, \\(Y_{t+1} \\perp \\mathbf{Y}_{1:t} \\mid \\boldsymbol{\\theta}\\), so that \\(p(y_{t+1} \\mid \\mathbf{y}_{1:t}, \\boldsymbol{\\theta}) = p(y_{t+1} \\mid \\boldsymbol{\\theta})\\), allowing the posterior to be recovered recursively (Petris, Petrone, and Campagnoli 2009). This facilitates online updating because all information up to time \\(t\\) is captured in \\(\\boldsymbol{\\theta}\\). Therefore, \\(\\pi(\\boldsymbol{\\theta} \\mid \\mathbf{y}_{1:t+1}) \\propto p(y_{t+1} \\mid \\boldsymbol{\\theta}) \\times \\pi(\\boldsymbol{\\theta} \\mid \\mathbf{y}_{1:t}) \\propto \\prod_{h=1}^{t+1} p(y_h \\mid \\boldsymbol{\\theta}) \\times \\pi(\\boldsymbol{\\theta})\\). This recursive expression can be computed more efficiently at any specific point in time \\(t\\), compared to a batch-mode algorithm, which requires processing all information up to time \\(t\\) simultaneously. It is also important to consider the sampling properties of “Bayesian estimators”. This topic has attracted the attention of statisticians and econometricians for a long time. For instance, asymptotic posterior concentration on the population parameter vector is discussed by Bickel and Yahav (1969). The convergence of posterior distributions is stated by the Bernstein-von Mises theorem (Lehmann and Casella 2003; Van der Vaart 2000), which establishes a link between credible intervals (sets) and confidence intervals (sets), where a credible interval is an interval in the domain of the posterior distribution within which an unknown parameter falls with a particular probability. Credible intervals treat bounds as fixed and parameters as random, whereas confidence intervals reverse this. There are many settings in parametric models where Bayesian credible intervals with an \\(\\alpha\\) level converge asymptotically to confidence intervals at the \\(\\alpha\\) level. This suggests that Bayesian inference is asymptotically correct from a sampling perspective in these settings. A heuristic approach to demonstrate this in the simplest case, where we assume random sampling and \\(\\theta \\in \\mathcal{R}\\), is the following: \\(p(\\mathbf{y} \\mid \\theta) = \\prod_{i=1}^N p(y_i \\mid \\theta)\\), so the log likelihood is \\(l(\\mathbf{y} \\mid \\theta) \\equiv \\log p(\\mathbf{y} \\mid \\theta) = \\sum_{i=1}^N \\log p(y_i \\mid \\theta) = N \\times \\bar{l}(\\mathbf{y} \\mid \\theta)\\), where \\(\\bar{l} \\equiv \\frac{1}{N} \\sum_{i=1}^N \\log p(y_i \\mid \\theta)\\) is the mean likelihood.7 Then, the posterior distribution is proportional to \\[\\begin{align} \\pi(\\theta\\mid \\mathbf{y})&amp;\\propto p(\\mathbf{y}\\mid \\theta) \\times \\pi(\\theta)\\nonumber\\\\ &amp;=\\exp\\left\\{N\\times \\bar{l}(\\mathbf{y}\\mid \\theta)\\right\\} \\times \\pi(\\theta). \\end{align}\\] Observe that as the sample size increases, that is, as \\(N \\to \\infty\\), the exponential term should dominate the prior distribution as long as the prior does not depend on \\(N\\), such that the likelihood determines the posterior distribution asymptotically. Maximum likelihood theory shows that \\(\\lim_{N \\to \\infty} \\bar{l}(\\mathbf{y} \\mid \\theta) \\to \\bar{l}(\\mathbf{y} \\mid \\theta_0)\\), where \\(\\theta_0\\) is the population parameter of the data-generating process. In addition, performing a second-order Taylor expansion of the log likelihood at the maximum likelihood estimator, \\[\\begin{align*} l(\\mathbf{y}\\mid \\theta)&amp;\\approx l(\\mathbf{y}\\mid \\hat{\\theta})+\\left.\\frac{dl(\\mathbf{y}\\mid {\\theta})}{d\\theta}\\right\\vert_{\\hat{\\theta}}(\\theta-\\hat{\\theta})+\\frac{1}{2}\\left.\\frac{d^2l(\\mathbf{y}\\mid {\\theta})}{d\\theta^2}\\right\\vert_{\\hat{\\theta}}(\\theta-\\hat{\\theta})^2\\\\ &amp;= l(\\mathbf{y}\\mid \\hat{\\theta})+\\frac{1}{2}\\left.\\sum_{i=1}^N\\frac{d^2l(y_i\\mid {\\theta})}{d\\theta^2}\\right\\vert_{\\hat{\\theta}}(\\theta-\\hat{\\theta})^2\\\\ &amp;= l(\\mathbf{y}\\mid \\hat{\\theta})-\\frac{1}{2}\\left.N\\left[-\\bar{l}&#39;&#39;\\right\\vert_{\\hat{\\theta}}\\right](\\theta-\\hat{\\theta})^2\\\\ &amp;= l(\\mathbf{y}\\mid \\hat{\\theta})-\\frac{N}{2\\sigma^2}(\\theta-\\hat{\\theta})^2 \\end{align*}\\] where \\(\\left.\\frac{dl(\\mathbf{y}\\mid \\theta)}{d\\theta}\\right\\vert_{\\hat{\\theta}}=0\\), \\(\\bar{l}&#39;&#39;\\equiv\\frac{1}{N}\\left.\\sum_{i=1}^N\\frac{d^2l(y_i\\mid {\\theta})}{d\\theta^2}\\right\\vert_{\\hat{\\theta}}\\) and \\(\\sigma^2:=\\left[\\left.-\\bar{l}&#39;&#39;\\right\\vert_{\\hat{\\theta}}\\right]^{-1}\\).8 Then, \\[\\begin{align*} \\pi(\\theta\\mid \\mathbf{y})&amp;\\propto \\exp\\left\\{{l}(\\mathbf{y}\\mid \\theta)\\right\\} \\times \\pi(\\theta)\\\\ &amp;\\approx \\exp\\left\\{l(\\mathbf{y}\\mid \\hat{\\theta})-\\frac{N}{2\\sigma^2}(\\theta-\\hat{\\theta})^2\\right\\} \\times \\pi(\\theta)\\\\ &amp;\\propto \\exp\\left\\{-\\frac{N}{2\\sigma^2}(\\theta-\\hat{\\theta})^2\\right\\} \\times \\pi(\\theta)\\\\ \\end{align*}\\] Observe that the posterior density is proportional to the kernel of a normal density with mean \\(\\hat{\\theta}\\) and variance \\(\\sigma^2 / N\\), as long as \\(\\pi(\\hat{\\theta}) \\neq 0\\). This kernel dominates as the sample size increases due to the \\(N\\) in the exponential term. It is also important to note that the prior should not exclude values of \\(\\theta\\) that are logically possible, such as \\(\\hat{\\theta}\\). Example: Health insurance Suppose that you are analyzing whether to buy health insurance next year. To make a better decision, you want to know what the probability is that you will visit your doctor at least once next year? To answer this question, you have records of the number of times you have visited your doctor over the last 5 years, \\(\\mathbf{y} = \\{0, 3, 2, 1, 0\\}\\). How should you proceed? Assuming that this is a random sample9 from a data-generating process (statistical model) that is Poisson, i.e., \\(Y_i \\sim P(\\lambda)\\), and your probabilistic prior beliefs about \\(\\lambda\\) are well described by a Gamma distribution with shape and scale parameters \\(\\alpha_0\\) and \\(\\beta_0\\), i.e., \\(\\lambda \\sim G(\\alpha_0, \\beta_0)\\), then you are interested in calculating the probability \\(P(Y_0 &gt; 0 \\mid \\mathbf{y})\\). To answer this, you need to calculate the posterior predictive density \\(\\pi(y_0 \\mid \\mathbf{y})\\) in a Bayesian way. In this example, \\(p(\\mathbf{y} \\mid \\lambda)\\) is Poisson, and \\(\\pi(\\lambda)\\) is Gamma. Therefore, using Equation (1.9). \\[\\begin{align*} \\pi(y_0\\mid \\mathbf{y})=&amp;\\int_{0}^{\\infty}\\frac{\\lambda^{y_0}\\exp\\left\\{-\\lambda\\right\\}}{y_0!}\\times \\pi(\\lambda\\mid \\mathbf{y})d\\lambda,\\\\ \\end{align*}\\] where the posterior distribution is \\[ \\pi(\\lambda\\mid \\mathbf{y})\\propto \\lambda^{\\sum_{i=1}^N y_i + \\alpha_0 - 1}\\exp\\left\\{-\\lambda\\left(\\frac{\\beta_0 N+1}{\\beta_0}\\right)\\right\\} \\] by Equation (1.3). Observe that the last expression is the kernel of a Gamma distribution with parameters \\(\\alpha_n = \\sum_{i=1}^N y_i + \\alpha_0\\) and \\(\\beta_n = \\frac{\\beta_0}{\\beta_0 N + 1}\\). Given that \\(\\int_0^{\\infty} \\pi(\\lambda \\mid \\mathbf{y}) d\\lambda = 1\\), the constant of proportionality in the last expression is \\(\\Gamma(\\alpha_n) \\beta_n^{\\alpha_n}\\), where \\(\\Gamma(\\cdot)\\) is the Gamma function. Thus, the posterior density function \\(\\pi(\\lambda \\mid \\mathbf{y})\\) is \\(G(\\alpha_n, \\beta_n)\\). Observe that \\[\\begin{align*} \\mathbb{E}[\\lambda\\mid \\mathbf{y}]&amp;=\\alpha_n\\beta_n\\\\ &amp;=\\left(\\sum_{i=1}^N y_i + \\alpha_0\\right)\\left(\\frac{\\beta_0}{\\beta_0 N + 1}\\right)\\\\ &amp;=\\bar{y}\\left(\\frac{N\\beta_0}{N\\beta_0+1}\\right)+\\alpha_0\\beta_0\\left(\\frac{1}{N\\beta_0+1}\\right)\\\\ &amp;=w\\bar{y}+(1-w)\\mathbb{E}[\\lambda], \\end{align*}\\] where \\(\\bar{y}\\) is the sample mean estimate, which is the maximum likelihood estimate of \\(\\lambda\\) in this example, \\(w = \\left(\\frac{N\\beta_0}{N\\beta_0 + 1}\\right)\\), and \\(\\mathbb{E}[\\lambda] = \\alpha_0 \\beta_0\\) is the prior mean. The posterior mean is a weighted average of the maximum likelihood estimator (sample information) and the prior mean. Observe that \\(\\lim_{N \\to \\infty} w = 1\\), that is, the sample information asymptotically dominates. The predictive distribution is \\[\\begin{align*} \\pi(y_0\\mid \\mathbf{y})=&amp;\\int_{0}^{\\infty}\\frac{\\lambda^{y_0}\\exp\\left\\{-\\lambda\\right\\}}{y_0!}\\times \\frac{1}{\\Gamma(\\alpha_n)\\beta_n^{\\alpha_n}}\\lambda^{\\alpha_n-1}\\exp\\left\\{-\\lambda/\\beta_n\\right\\} d\\lambda\\\\ =&amp;\\frac{1}{y_0!\\Gamma(\\alpha_n)\\beta_n^{\\alpha_n}}\\int_{0}^{\\infty}\\lambda^{y_0+\\alpha_n-1}\\exp\\left\\{-\\lambda\\left(\\frac{1+\\beta_n}{\\beta_n}\\right)\\right\\}d\\lambda\\\\ =&amp;\\frac{\\Gamma(y_0+\\alpha_n)\\left(\\frac{\\beta_n}{\\beta_n+1}\\right)^{y_0+\\alpha_n}}{y_0!\\Gamma(\\alpha_n)\\beta_n^{\\alpha_n}}\\\\ =&amp;{y_0+\\alpha_n-1 \\choose y_0}\\left(\\frac{\\beta_n}{\\beta_n+1}\\right)^{y_0}\\left(\\frac{1}{\\beta_n+1}\\right)^{\\alpha_n}. \\end{align*}\\] The third equality follows from the kernel of a Gamma density, and the fourth from \\[ {y_0 + \\alpha_n - 1 \\choose y_0} = \\frac{(y_0 + \\alpha_n - 1)(y_0 + \\alpha_n - 2)\\dots\\alpha_n}{y_0!} = \\frac{\\Gamma(y_0 + \\alpha_n)}{\\Gamma(\\alpha_n) y_0!} \\] using a property of the Gamma function. Observe that this is a Negative Binomial density, that is, \\(Y_0 \\mid \\mathbf{y} \\sim \\text{NB}(\\alpha_n, p_n)\\) where \\(p_n = \\frac{\\beta_n}{\\beta_n + 1}\\). Up to this point, we have said nothing about the hyperparameters, which are required to give a concrete response to this exercise. Thus, we show two approaches to set them. First, we set \\(\\alpha_0 = 0.001\\) and \\(\\beta_0 = \\frac{1}{0.001}\\), which imply vague prior information about \\(\\lambda\\) due to having a large degree of variability compared to the mean information.10 In particular, \\(\\mathbb{E}[\\lambda] = 1\\) and \\(\\mathbb{V}ar[\\lambda] = 1000\\). In this setting, \\(P(Y_0 &gt; 0 \\mid \\mathbf{y}) = 1 - P(Y_0 = 0 \\mid \\mathbf{y}) \\approx 0.67\\). That is, the probability of visiting the doctor at least once next year is approximately 0.67. Another approach is using Empirical Bayes, where we set the hyperparameters maximizing the logarithm of the marginal likelihood,11 that is, \\[ \\left[\\hat{\\alpha}_0 \\ \\hat{\\beta}_0\\right]^{\\top} = \\underset{\\alpha_0, \\beta_0}{\\mathrm{argmax}} \\ \\ln p(\\mathbf{y}) \\] where \\[ \\begin{align} p(\\mathbf{y}) &amp;= \\int_0^{\\infty} \\left\\{ \\frac{1}{\\Gamma(\\alpha_0)\\beta_0^{\\alpha_0}} \\lambda^{\\alpha_0 - 1} \\exp\\left\\{-\\lambda / \\beta_0\\right\\} \\prod_{i=1}^N \\frac{\\lambda^{y_i} \\exp\\left\\{-\\lambda\\right\\}}{ y_i!} \\right\\} d\\lambda \\\\ &amp;= \\frac{\\int_0^{\\infty} \\lambda^{\\sum_{i=1}^N y_i + \\alpha_0 - 1} \\exp\\left\\{-\\lambda \\left( \\frac{\\beta_0 N + 1}{\\beta_0} \\right) \\right\\} d\\lambda}{ \\Gamma(\\alpha_0) \\beta_0^{\\alpha_0} \\prod_{i=1}^N y_i! } \\\\ &amp;= \\frac{\\Gamma\\left(\\sum_{i=1}^N y_i + \\alpha_0\\right) \\left( \\frac{\\beta_0}{N\\beta_0 + 1} \\right)^{\\sum_{i=1}^N y_i} \\left( \\frac{1}{N\\beta_0 + 1} \\right)^{\\alpha_0}}{ \\Gamma(\\alpha_0) \\prod_{i=1}^N y_i } \\end{align} \\] Using the empirical Bayes approach, we get \\(\\hat{\\alpha}_0 = 51.8\\) and \\(\\hat{\\beta}_0 = 0.023\\), then \\(P(Y_0 &gt; 0 \\mid \\mathbf{y}) = 1 - P(Y_0 = 0 \\mid \\mathbf{y}) \\approx 0.70\\). Observe that we can calculate the posterior odds comparing the model using an Empirical Bayes prior (model 1) versus the vague prior (model 2). We assume that \\(\\pi(\\mathcal{M}_1) = \\pi(\\mathcal{M}_2) = 0.5\\), then \\[ \\begin{align} PO_{12} &amp;= \\frac{p(\\mathbf{y} \\mid \\text{Empirical Bayes})}{ p(\\mathbf{y} \\mid \\text{Vague prior}) } \\\\ &amp;= \\frac{\\frac{\\Gamma\\left(\\sum_{i=1}^N y_i + 51.807\\right) \\left( \\frac{0.023}{N \\times 0.023 + 1} \\right)^{\\sum_{i=1}^N y_i} \\left( \\frac{1}{N \\times 0.023 + 1} \\right)^{51.807}}{\\Gamma(51.807)}}{\\frac{\\Gamma\\left(\\sum_{i=1}^N y_i + 0.001\\right) \\left( \\frac{1/0.001}{N/0.001 + 1} \\right)^{\\sum_{i=1}^N y_i} \\left( \\frac{1}{N/0.001 + 1} \\right)^{0.001}}{\\Gamma(0.001)}} \\\\ &amp;\\approx 919 \\end{align} \\] Then, \\(2 \\times \\log(PO_{12}) = 13.64\\), which provides very strong evidence against the vague prior model (see Table 1.1). In particular, \\(\\pi(\\text{Empirical Bayes} \\mid \\mathbf{y}) = \\frac{919}{1 + 919} = 0.999\\) and \\(\\pi(\\text{Vague prior} \\mid \\mathbf{y}) = 1 - 0.999 = 0.001\\). These probabilities can be used to perform Bayesian model averaging (BMA). In particular, \\[ \\begin{align} \\mathbb{E}(\\lambda \\mid \\mathbf{y}) &amp;= 1.2 \\times 0.999 + 1.2 \\times 0.001 = 1.2 \\\\ \\text{Var}(\\lambda \\mid \\mathbf{y}) &amp;= 0.025 \\times 0.999 + 0.24 \\times 0.001 \\\\ &amp;+ (1.2 - 1.2)^2 \\times 0.999 + (1.2 - 1.2)^2 \\times 0.001 = 0.025 \\end{align} \\] The BMA predictive distribution is a mix of negative binomial distributions, that is, \\[ Y_0 \\mid \\mathbf{y} \\sim 0.999 \\times \\text{NB}(57.8, 0.02) + 0.001 \\times \\text{NB}(6.001, 0.17) \\] The following code shows how to perform this exercise in R. set.seed(010101) y &lt;- c(0, 3, 2, 1, 0) # Data N &lt;- length(y) ProbBo &lt;- function(y, a0, b0){ N &lt;- length(y) #sample size an &lt;- a0 + sum(y) # Posterior shape parameter bn &lt;- b0 / ((b0 * N) + 1) # Posterior scale parameter p &lt;- bn / (bn + 1) # Probability negative binomial density Pr &lt;- 1 - pnbinom(0, size=an,prob=(1 - p)) # Probability of visiting the Doctor at least once next year # Observe that in R there is a slightly different parametrization. return(Pr) } # Using a vague prior: a0 &lt;- 0.001 # Prior shape parameter b0 &lt;- 1 / 0.001 # Prior scale parameter PriMeanV &lt;- a0 * b0 # Prior mean PriVarV &lt;- a0 * b0^2 # Prior variance Pp &lt;- ProbBo(y, a0 = 0.001, b0 = 1 / 0.001) # This setting is vague prior information. Pp ## [1] 0.6650961 # Using Empirical Bayes LogMgLik &lt;- function(theta, y){ N &lt;- length(y) #sample size a0 &lt;- theta[1] # prior shape hyperparameter b0 &lt;- theta[2] # prior scale hyperparameter an &lt;- sum(y) + a0 # posterior shape parameter if(a0 &lt;= 0 || b0 &lt;= 0){ #Avoiding negative values lnp &lt;- -Inf }else{ lnp &lt;- lgamma(an) + sum(y)*log(b0/(N*b0+1)) - a0*log(N*b0+1) - lgamma(a0) } # log marginal likelihood return(-lnp) } theta0 &lt;- c(0.01, 1/0.1) # Initial values control &lt;- list(maxit = 1000) # Number of iterations in optimization EmpBay &lt;- optim(theta0, LogMgLik, method = &quot;BFGS&quot;, control = control, hessian = TRUE, y = y) # Optimization EmpBay$convergence ## [1] 0 a0EB &lt;- EmpBay$par[1] # Prior shape using empirical Bayes a0EB ## [1] 51.80696 b0EB &lt;- EmpBay$par[2] # Prior scale using empirical Bayes b0EB ## [1] 0.02318341 PriMeanEB &lt;- a0EB * b0EB # Prior mean PriVarEB &lt;- a0EB * b0EB^2 # Prior variance PpEB &lt;- ProbBo(y, a0 = a0EB, b0 = b0EB) # This setting is using emprical Bayes. PpEB ## [1] 0.6953668 # Density figures: # This code helps plotting densities lambda &lt;- seq(0.01, 10, 0.01) # Values of lambda VaguePrior &lt;- dgamma(lambda,shape=a0,scale = b0) EBPrior &lt;- dgamma(lambda,shape=a0EB,scale = b0EB) PosteriorV &lt;- dgamma(lambda, shape = a0 + sum(y), scale = b0 / ((b0 * N) + 1)) PosteriorEB &lt;- dgamma(lambda, shape = a0EB+sum(y), scale = b0EB / ((b0EB * N) + 1)) # Likelihood function Likelihood &lt;- function(theta, y){ LogL &lt;- dpois(y, theta, log = TRUE) Lik &lt;- prod(exp(LogL)) return(Lik) } Liks &lt;- sapply(lambda, function(par) {Likelihood(par, y = y)}) Sc &lt;- max(PosteriorEB)/max(Liks) #Scale for displaying in figure LiksScale &lt;- Liks * Sc data &lt;- data.frame(cbind(lambda, VaguePrior, EBPrior, PosteriorV, PosteriorEB, LiksScale)) #Data frame require(ggplot2) # Cool figures ## Loading required package: ggplot2 ## Warning: package &#39;ggplot2&#39; was built under R version 4.3.3 require(latex2exp) # LaTeX equations in figures ## Loading required package: latex2exp require(ggpubr) # Multiple figures in one page ## Loading required package: ggpubr fig1 &lt;- ggplot(data = data, aes(lambda, VaguePrior)) + geom_line() + xlab(TeX(&quot;$\\\\lambda$&quot;)) + ylab(&quot;Density&quot;) + ggtitle(&quot;Prior: Vague Gamma&quot;) fig2 &lt;- ggplot(data = data, aes(lambda, EBPrior)) + geom_line() + xlab(TeX(&quot;$\\\\lambda$&quot;)) + ylab(&quot;Density&quot;) + ggtitle(&quot;Prior: Empirical Bayes Gamma&quot;) fig3 &lt;- ggplot(data = data, aes(lambda, PosteriorV)) + geom_line() + xlab(TeX(&quot;$\\\\lambda$&quot;)) + ylab(&quot;Density&quot;) + ggtitle(&quot;Posterior: Vague Gamma&quot;) fig4 &lt;- ggplot(data = data, aes(lambda, PosteriorEB)) + geom_line() + xlab(TeX(&quot;$\\\\lambda$&quot;)) + ylab(&quot;Density&quot;) + ggtitle(&quot;Posterior: Empirical Bayes Gamma&quot;) FIG &lt;- ggarrange(fig1, fig2, fig3, fig4, ncol = 2, nrow = 2) annotate_figure(FIG, top = text_grob(&quot;Vague versus Empirical Bayes: Poisson-Gamma model&quot;, color = &quot;black&quot;, face = &quot;bold&quot;, size = 14)) dataNew &lt;- data.frame(cbind(rep(lambda, 3), c(EBPrior, PosteriorEB, LiksScale), rep(1:3, each = 1000))) #Data frame colnames(dataNew) &lt;- c(&quot;Lambda&quot;, &quot;Density&quot;, &quot;Factor&quot;) dataNew$Factor &lt;- factor(dataNew$Factor, levels=c(&quot;1&quot;, &quot;3&quot;, &quot;2&quot;), labels=c(&quot;Prior&quot;, &quot;Likelihood&quot;, &quot;Posterior&quot;)) # ggplot(data = dataNew, aes_string(x = &quot;Lambda&quot;, y = &quot;Density&quot;, group = &quot;Factor&quot;)) + geom_line(aes(color = Factor)) + xlab(TeX(&quot;$\\\\lambda$&quot;)) + ylab(&quot;Density&quot;) + ggtitle(&quot;Prior, likelihood and posterior: Empirical Bayes Poisson-Gamma model&quot;) + guides(color=guide_legend(title=&quot;Information&quot;)) + scale_color_manual(values = c(&quot;red&quot;, &quot;yellow&quot;, &quot;blue&quot;)) ggplot(data = dataNew, aes(x = Lambda, y = Density, group = Factor, color = Factor)) + geom_line() + xlab(TeX(&quot;$\\\\lambda$&quot;)) + ylab(&quot;Density&quot;) + ggtitle(&quot;Prior, likelihood and posterior: Empirical Bayes Poisson-Gamma model&quot;) + guides(color = guide_legend(title = &quot;Information&quot;)) + scale_color_manual(values = c(&quot;red&quot;, &quot;yellow&quot;, &quot;blue&quot;)) The first figure displays the prior and posterior densities based on vague and Empirical Bayes hyperparameters. We observe that the prior and posterior densities using the latter are more informative, as expected. The second figure shows the prior, scaled likelihood, and posterior densities of \\(\\lambda\\) based on the hyperparameters from the Empirical Bayes approach. The posterior density is a compromise between prior and sample information. # Predictive distributions PredDen &lt;- function(y, y0, a0, b0){ N &lt;- length(y) #sample size an &lt;- a0 + sum(y) # Posterior shape parameter bn &lt;- b0 / ((b0 * N) + 1) # Posterior scale parameter p &lt;- bn / (bn + 1) # Probability negative binomial density Pr &lt;- dnbinom(y0, size=an, prob=(1 - p)) # Predictive density # Observe that in R there is a slightly different parametrization. return(Pr) } y0 &lt;- 0:10 PredVague &lt;- PredDen(y=y, y0=y0, a0=a0, b0=b0) PredEB &lt;- PredDen(y=y, y0=y0, a0=a0EB, b0=b0EB) dataPred &lt;- as.data.frame(cbind(y0, PredVague, PredEB)) colnames(dataPred) &lt;- c(&quot;y0&quot;, &quot;PredictiveVague&quot;, &quot;PredictiveEB&quot;) ggplot(data = dataPred) + geom_point(aes(y0, PredictiveVague, color = &quot;red&quot;)) + xlab(TeX(&quot;$y_0$&quot;)) + ylab(&quot;Density&quot;) + ggtitle(&quot;Predictive density: Vague and Empirical Bayes priors&quot;) + geom_point(aes(y0, PredictiveEB, color = &quot;yellow&quot;)) + guides(color = guide_legend(title=&quot;Prior&quot;)) + scale_color_manual(labels = c(&quot;Vague&quot;, &quot;Empirical Bayes&quot;), values = c(&quot;red&quot;, &quot;yellow&quot;)) + scale_x_continuous(breaks=seq(0,10,by=1)) This figure displays the predictive probability mass of not having any visits to a physician next year, as well as having one, two, and so on, using Empirical Bayes and vague hyperparameters. The predictive probabilities of not having any visits are approximately 30% and 33% based on the Empirical Bayes and vague hyperparameters, respectively. # Posterior odds: Vague vs Empirical Bayes PO12 &lt;- exp(-LogMgLik(c(a0EB, b0EB), y = y))/exp(-LogMgLik(c(a0, b0), y = y)) PO12 ## [1] 919.0069 PostProMEM &lt;- PO12/(1 + PO12) PostProMEM ## [1] 0.9989131 # Posterior model probability Empirical Bayes PostProbMV &lt;- 1 - PostProMEM PostProbMV ## [1] 0.001086948 # Posterior model probability vague prior # Bayesian model average (BMA) PostMeanEB &lt;- (a0EB + sum(y)) * (b0EB / (b0EB * N + 1)) # Posterior mean Empirical Bayes PostMeanV &lt;- (a0 + sum(y)) * (b0 / (b0 * N + 1)) # Posterior mean vague priors BMAmean &lt;- PostProMEM * PostMeanEB + PostProbMV * PostMeanV BMAmean ## [1] 1.200951 # BMA posterior mean PostVarEB &lt;- (a0EB + sum(y)) * (b0EB/(b0EB * N + 1))^2 # Posterior variance Empirical Bayes PostVarV &lt;- (a0 + sum(y)) * (b0 / (b0 * N + 1))^2 # Posterior variance vague prior BMAVar &lt;- PostProMEM * PostVarEB + PostProbMV*PostVarV + PostProMEM * (PostMeanEB - BMAmean)^2 + PostProbMV * (PostMeanV - BMAmean)^2 # BMA posterior variance BMAVar ## [1] 0.02518372 # BMA: Predictive BMAPred &lt;- PostProMEM * PredEB+PostProbMV * PredVague dataPredBMA &lt;- as.data.frame(cbind(y0, BMAPred)) colnames(dataPredBMA) &lt;- c(&quot;y0&quot;, &quot;PredictiveBMA&quot;) ggplot(data = dataPredBMA) + geom_point(aes(y0, PredictiveBMA, color = &quot;red&quot;)) + xlab(TeX(&quot;$y_0$&quot;)) + ylab(&quot;Density&quot;) + ggtitle(&quot;Predictive density: BMA&quot;) + guides(color = guide_legend(title=&quot;BMA&quot;)) + scale_color_manual(labels = c(&quot;Probability&quot;), values = c(&quot;red&quot;)) + scale_x_continuous(breaks=seq(0,10,by=1)) The first figure displays the predictive density using Bayesian model averaging based on the vague and Empirical Bayes hyperparameters. This figure closely resembles the predictive probability mass function based on the Empirical Bayes framework, as the posterior model probability for that setting is nearly one. The second figure shows how the posterior distribution updates with new sample information, starting from an initial non-informative prior (iteration 1). We observe that iteration 5 incorporates all the sample information in our example. As a result, the posterior density in iteration 5 is identical to the posterior density. References "],["sec14.html", "1.3 Bayesian reports: Decision theory under uncertainty", " 1.3 Bayesian reports: Decision theory under uncertainty The Bayesian framework allows reporting the full posterior distributions. However, some situations require reporting a specific value of the posterior distribution (point estimate), an informative interval (set), point or interval predictions, and/or selecting a specific model. Decision theory offers an elegant framework to make decisions regarding the optimal posterior values to report (J. O. Berger 2013). The starting point is a loss function, which is a non-negative real-valued function whose arguments are the unknown state of nature (\\(\\mathbf{\\Theta}\\)), and a set of actions to be taken (\\(\\mathcal{A}\\)), that is, \\[\\begin{equation*} L(\\mathbf{\\theta}, a):\\mathbf{\\Theta}\\times \\mathcal{A}\\rightarrow \\mathcal{R}^+. \\end{equation*}\\] This function is a mathematical representation of the loss incurred from making mistakes. In particular, selecting action \\(a\\in\\mathcal{A}\\) when \\(\\mathbf{\\theta}\\in\\mathbf{\\Theta}\\) is the true state. In our case, the unknown state of nature can refer to parameters, functions of them, future or unknown realizations, models, etc. From a Bayesian perspective, we should choose the action that minimizes the posterior expected loss (\\(a^*(\\mathbf{y})\\)), that is, the posterior risk function (\\(\\mathbb{E}[L(\\mathbf{\\theta}, a)\\mid \\mathbf{y}]\\)), \\[\\begin{equation*} a^*(\\mathbf{y})=\\underset{a \\in \\mathcal{A}}{\\mathrm{argmin}} \\ \\mathbb{E}[L(\\mathbf{\\theta}, a)\\mid \\mathbf{y}], \\end{equation*}\\] where \\(\\mathbb{E}[L(\\mathbf{\\theta}, a)\\mid \\mathbf{y}] = \\int_{\\mathbf{\\Theta}} L(\\mathbf{\\theta}, a)\\pi(\\mathbf{\\theta}\\mid \\mathbf{y})d\\mathbf{\\theta}\\).12 Different loss functions imply different optimal decisions. We illustrate this assuming \\(\\theta \\in \\mathcal{R}\\). The quadratic loss function, \\(L(\\theta,a)=[\\theta-a]^2\\), gives as the optimal decision the posterior mean, \\(a^*(\\mathbf{y})=\\mathbb{E}[\\theta \\mid \\mathbf{y}]\\), that is: \\[\\begin{equation*} \\mathbb{E}[\\theta \\mid \\mathbf{y}] = \\underset{a \\in \\mathcal{A}}{\\mathrm{argmin}} \\ \\int_{\\Theta} [\\theta - a]^2 \\pi(\\theta \\mid \\mathbf{y}) \\, d\\theta. \\end{equation*}\\] To obtain this result, let’s use the first-order condition, differentiate the risk function with respect to \\(a\\), interchange the differential and integral order, and set the result equal to zero: \\[ -2 \\int_{\\Theta} [\\theta - a^*] \\pi(\\theta \\mid \\mathbf{y}) \\, d\\theta = 0. \\] This implies that \\[ a^* \\int_{\\Theta} \\pi(\\theta \\mid \\mathbf{y}) \\, d\\theta = a^*(\\mathbf{y}) = \\int_{\\Theta} \\theta \\pi(\\theta \\mid \\mathbf{y}) \\, d\\theta = \\mathbb{E}[\\theta \\mid \\mathbf{y}], \\] that is, the posterior mean is the Bayesian optimal action. This means that we should report the posterior mean as a point estimate of \\(\\theta\\) when facing the quadratic loss function. The generalized quadratic loss function, \\(L(\\theta,a) = w(\\theta) [\\theta - a]^2\\), where \\(w(\\theta) &gt; 0\\) is a weighting function, gives as the optimal decision rule the weighted mean. We should follow the same steps as the previous result to obtain \\[ a^*(\\mathbf{y}) = \\frac{\\mathbb{E}[w(\\theta) \\times \\theta \\mid \\mathbf{y}]}{\\mathbb{E}[w(\\theta) \\mid \\mathbf{y}]}. \\] Observe that the weighted average is driven by the weighting function \\(w(\\theta)\\). The absolute error loss function, \\(L(\\theta,a) = |\\theta - a|\\), gives as the optimal action the posterior median (Exercise 5). The generalized absolute error function, \\[ L(\\theta,a) = \\begin{cases} K_0 (\\theta - a), &amp; \\text{if } \\theta - a \\geq 0, \\\\ K_1 (a - \\theta), &amp; \\text{if } \\theta - a &lt; 0, \\end{cases} \\quad K_0, K_1 &gt; 0, \\] implies the following risk function: \\[\\begin{align*} \\mathbb{E}[L(\\theta, a) \\mid \\mathbf{y}] &amp;= \\int_{-\\infty}^{a} K_1(a - \\theta) \\pi(\\theta \\mid \\mathbf{y}) \\, d\\theta + \\int_{a}^{\\infty} K_0 (\\theta - a) \\pi(\\theta \\mid \\mathbf{y}) \\, d\\theta. \\end{align*}\\] Differentiating with respect to \\(a\\), interchanging differentials and integrals, and equating to zero, we get: \\[\\begin{align*} K_1 \\int_{-\\infty}^{a^*} \\pi(\\theta \\mid \\mathbf{y}) \\, d\\theta - K_0 \\int_{a^*}^{\\infty} \\pi(\\theta \\mid \\mathbf{y}) \\, d\\theta &amp;= 0. \\end{align*}\\] Thus, we have \\[ \\int_{-\\infty}^{a^*} \\pi(\\theta \\mid \\mathbf{y}) \\, d\\theta = \\frac{K_0}{K_0 + K_1}, \\] that is, any \\(\\frac{K_0}{K_0 + K_1}\\)-percentile of \\(\\pi(\\theta \\mid \\mathbf{y})\\) is an optimal Bayesian estimate of \\(\\theta\\). We can also use decision theory under uncertainty in hypothesis testing. In particular, testing \\(H_0: \\theta \\in \\Theta_0\\) versus \\(H_1: \\theta \\in \\Theta_1\\), where \\(\\Theta = \\Theta_0 \\cup \\Theta_1\\) and \\(\\emptyset = \\Theta_0 \\cap \\Theta_1\\), there are two actions of interest, \\(a_0\\) and \\(a_1\\), where \\(a_j\\) denotes not rejecting \\(H_j\\), for \\(j = \\{0,1\\}\\). Given the \\(0-K_j\\) loss function: \\[\\begin{equation*} L(\\theta,a_j) = \\begin{cases} 0, &amp; \\text{if } \\theta \\in \\Theta_j, \\\\ K_j, &amp; \\text{if } \\theta \\in \\Theta_i, j \\neq i, \\end{cases} \\end{equation*}\\] where there is no loss if the right decision is made, for instance, not rejecting \\(H_0\\) when \\(\\theta \\in \\Theta_0\\), and the loss is \\(K_j\\) when an error is made. For example, a type I error occurs when rejecting the null hypothesis (\\(H_0\\)) when it is true (\\(\\theta \\in \\Theta_0\\)), which results in a loss of \\(K_1\\) due to choosing action \\(a_1\\), not rejecting \\(H_1\\). The posterior expected loss associated with decision \\(a_j\\), i.e., not rejecting \\(H_j\\), is: \\[ \\mathbb{E}[L(\\theta,a_j) \\mid \\mathbf{y}] = 0 \\times P(\\Theta_j \\mid \\mathbf{y}) + K_j P(\\Theta_i \\mid \\mathbf{y}) = K_j P(\\Theta_i \\mid \\mathbf{y}), \\quad j \\neq i. \\] Therefore, the Bayes optimal decision is the one that minimizes the posterior expected loss. That is, the null hypothesis is rejected (\\(a_1\\) is not rejected) when \\[ K_0 P(\\Theta_1 \\mid \\mathbf{y}) &gt; K_1 P(\\Theta_0 \\mid \\mathbf{y}). \\] Given our framework, \\(\\Theta = \\Theta_0 \\cup \\Theta_1\\) and \\(\\emptyset = \\Theta_0 \\cap \\Theta_1\\), we have \\(P(\\Theta_0 \\mid \\mathbf{y}) = 1 - P(\\Theta_1 \\mid \\mathbf{y})\\). As a result, the rejection region of the Bayesian test is: \\[ R = \\left\\{ \\mathbf{y} : P(\\Theta_1 \\mid \\mathbf{y}) &gt; \\frac{K_1}{K_1 + K_0} \\right\\}. \\] Decision theory also helps to construct interval (region) estimates. Let \\(\\Theta_{C(\\mathbf{y})} \\subset \\Theta\\) be a credible set for \\(\\theta\\), and let the loss function be defined as: \\[ L(\\theta, \\Theta_{C(\\mathbf{y})}) = 1 - \\mathbf{1}\\left\\{\\theta \\in \\Theta_{C(\\mathbf{y})}\\right\\}, \\] where \\[ \\mathbf{1}\\left\\{\\theta \\in \\Theta_{C(\\mathbf{y})}\\right\\} = \\begin{cases} 1, &amp; \\text{if } \\theta \\in \\Theta_{C(\\mathbf{y})}, \\\\ 0, &amp; \\text{if } \\theta \\notin \\Theta_{C(\\mathbf{y})}. \\end{cases} \\] Thus, the loss function becomes: \\[ L(\\theta, \\Theta_{C(\\mathbf{y})}) = \\begin{cases} 0, &amp; \\text{if } \\theta \\in \\Theta_{C(\\mathbf{y})}, \\\\ 1, &amp; \\text{if } \\theta \\notin \\Theta_{C(\\mathbf{y})}. \\end{cases} \\] This is a 0-1 loss function, which equals zero when \\(\\theta \\in \\Theta_{C(\\mathbf{y})}\\) and equals one when \\(\\theta \\notin \\Theta_{C(\\mathbf{y})}\\). Consequently, the risk function is: \\[ 1 - P(\\theta \\in \\Theta_{C(\\mathbf{y})}). \\] Given a measure of credibility \\(\\alpha(\\mathbf{y})\\) that defines the level of trust that \\(\\theta \\in \\Theta_{C(\\mathbf{y})}\\), we can measure the accuracy of the report by the loss function: \\[ L(\\theta, \\alpha(\\mathbf{y})) = \\left[\\mathbf{1}\\left\\{\\theta \\in \\Theta_{C(\\mathbf{y})}\\right\\} - \\alpha(\\mathbf{y})\\right]^2. \\] This loss function could be used to suggest a choice of the report \\(\\alpha(\\mathbf{y})\\). Given that this is a quadratic loss function, the optimal action is the posterior mean, that is, \\[ \\mathbb{E}[\\mathbf{1}\\left\\{\\theta \\in \\Theta_{C(\\mathbf{y})}\\right\\} \\mid \\mathbf{y}] = P(\\theta \\in \\Theta_{C(\\mathbf{y})} \\mid \\mathbf{y}). \\] This probability can be calculated given the posterior distribution as \\[ P(\\theta \\in \\Theta_{C(\\mathbf{y})} \\mid \\mathbf{y}) = \\int_{\\Theta_{C(\\mathbf{y})}} \\pi(\\theta \\mid \\mathbf{y}) \\, d\\theta. \\] This represents a measure of the belief that \\(\\theta \\in \\Theta_{C(\\mathbf{y})}\\) given the prior beliefs and sample information. The set \\(\\Theta_{C(\\mathbf{y})} \\subset \\Theta\\) is a \\(100(1 - \\alpha)\\%\\) credible set with respect to \\(\\pi(\\theta \\mid \\mathbf{y})\\) if \\[ P(\\theta \\in \\Theta_{C(\\mathbf{y})} \\mid \\mathbf{y}) = \\int_{\\Theta_{C(\\mathbf{y})}} \\pi(\\theta \\mid \\mathbf{y}) \\, d\\theta = 1 - \\alpha. \\] Two alternatives for reporting credible sets are the symmetric credible set and the highest posterior density set (HPD). The former is based on the \\(\\frac{\\alpha}{2}\\%\\) and \\((1 - \\frac{\\alpha}{2})\\%\\) percentiles of the posterior distribution, and the latter is a \\(100(1 - \\alpha)\\%\\) credible interval for \\(\\theta\\) with the property that it has the smallest distance compared to any other \\(100(1 - \\alpha)\\%\\) credible interval for \\(\\theta\\) based on the posterior distribution. Specifically, \\[ C(\\mathbf{y}) = \\left\\{ \\theta : \\pi(\\theta \\mid \\mathbf{y}) \\geq k(\\alpha) \\right\\}, \\] where \\(k(\\alpha)\\) is the largest number such that \\[ \\int_{\\theta : \\pi(\\theta \\mid \\mathbf{y}) \\geq k(\\alpha)} \\pi(\\theta \\mid \\mathbf{y}) d\\theta = 1 - \\alpha. \\] The HPD set can be a collection of disjoint intervals when working with multimodal posterior densities. Additionally, HPD sets have the limitation of not necessarily being invariant under transformations. Decision theory can also be used to perform prediction (point, sets, or probabilistic). Suppose that there is a loss function \\(L(Y_0, a)\\) involving the prediction of \\(Y_0\\). Then, the expected loss is \\[ \\mathbb{E}_{Y_0}[L(Y_0, a)] = \\int_{\\mathcal{Y}_0} L(y_0, a) \\pi(y_0 \\mid \\mathbf{y}) \\, dy_0, \\] where \\(\\pi(y_0 \\mid \\mathbf{y})\\) is the predictive density function. Thus, we make an optimal choice for prediction that minimizes the risk function given a specific loss function. Although Bayesian Model Averaging (BMA) allows for incorporating model uncertainty in a regression framework, sometimes it is desirable to select just one model. A compelling alternative is to choose the model with the highest posterior model probability. This model is the best alternative for prediction in the case of a 0-1 loss function (Clyde and George 2004). Example: Health insurance continues We show some optimal rules in the health insurance example, specifically the best point estimates of \\(\\lambda\\) under the quadratic, absolute, and generalized absolute loss functions. For the generalized absolute loss function, we assume that underestimating \\(\\lambda\\) is twice as costly as overestimating it, i.e., \\(K_0 = 2\\) and \\(K_1 = 1\\). Given that the posterior distribution of \\(\\lambda\\) is \\(G(\\alpha_0 + \\sum_{i=1}^N y_i, \\frac{\\beta_0}{\\beta_0 N + 1})\\), and using the hyperparameters from empirical Bayes, we obtain the following optimal point estimates: The posterior mean: \\(\\mathbb{E}[\\lambda \\mid \\mathbf{y}] = \\alpha_n \\beta_n = 1.2\\), The posterior median: 1.19, The 2/3-th quantile: 1.26. These are the optimal point estimates for the quadratic, absolute, and generalized absolute loss functions, respectively. In addition, we test the null hypothesis \\(H_0: \\lambda \\in [0, 1)\\) versus the alternative hypothesis \\(H_1: \\lambda \\in [1, \\infty)\\), setting \\(K_0 = K_1 = 1\\). We should reject the null hypothesis since \\(P(\\lambda \\in [0, 1)) = 0.9 &gt; \\frac{K_1}{K_0 + K_1} = 0.5\\). The 95% symmetric credible interval is \\((0.91, 1.53)\\), and the highest posterior density (HPD) interval is \\((0.90, 1.51)\\). Finally, the optimal point prediction under the quadratic loss function is 1.2, which is the mean value of the posterior predictive distribution. The optimal model, assuming a 0-1 loss function, is the model using the hyperparameters from the empirical Bayes procedure, since the posterior model probability of this model is approximately 1, whereas the posterior model probability of the model using vague hyperparameters is approximately 0. an &lt;- sum(y) + a0EB # Posterior shape parameter bn &lt;- b0EB / (N*b0EB + 1) # Posterior scale parameter S &lt;- 1000000 # Number of posterior draws Draws &lt;- rgamma(1000000, shape = an, scale = bn) # Posterior draws ###### Point estimation ######## OptQua &lt;- an*bn # Mean: Optimal choice quadratic loss function OptQua ## [1] 1.200952 OptAbs &lt;- qgamma(0.5, shape = an, scale = bn) # Median: Optimal choice absolute loss function OptAbs ## [1] 1.194034 # Setting K0 = 2 and K1 = 1, that is, to underestimate lambda is twice as costly as to overestimate it. K0 &lt;- 2; K1 &lt;- 1 OptGenAbs &lt;- quantile(Draws, K0/(K0 + K1)) # Median: Optimal choice generalized absolute loss function OptGenAbs ## 66.66667% ## 1.263182 ###### Hypothesis test ######## # H0: lambda in [0,1) vs H1: lambda in [1, Inf] K0 &lt;- 1; K1 &lt;- 1 ProbH0 &lt;- pgamma(1, shape = an, scale = bn) ProbH0 # Posterior probability H0 ## [1] 0.09569011 ProbH1 &lt;- 1 -ProbH0 ProbH1 # Posterior probability H1 ## [1] 0.9043099 # We should reject H0 given ProbH1 &gt; K1 / (K0 + K1) ###### Credible intervals ######## LimInf &lt;- qgamma(0.025, shape = an, scale = bn) # Lower bound LimInf ## [1] 0.9114851 LimSup &lt;- qgamma(0.975, shape = an, scale = bn) # Upper bound LimSup ## [1] 1.529724 HDI &lt;- HDInterval::hdi(Draws, credMass = 0.95) # Highest posterior density credible interval HDI ## lower upper ## 0.9007934 1.5163109 ## attr(,&quot;credMass&quot;) ## [1] 0.95 ###### Predictive optimal choices ######## p &lt;- bn / (bn + 1) # Probability negative binomial density OptPred &lt;- p/(1-p)*an # Optimal point prediction given a quadratic loss function in prediction OptPred ## [1] 1.200952 References "],["summary.html", "1.4 Summary", " 1.4 Summary We introduce Bayes’ rule to update probabilistic statements using humorous examples. We then study the three key probabilistic objects in Bayesian inference: the posterior distribution, the marginal likelihood, and the predictive density. The posterior distribution allows for inference regarding parameters, the marginal likelihood is required for hypothesis testing and model selection using the Bayes factor, and the predictive density enables probabilistic predictions. We also review some sampling properties of Bayesian estimators and the process of Bayes updating. All of these concepts were illustrated using a simple example in R software. Finally, we introduce decision theory concepts that can be applied to report summary statistics while minimizing posterior expected losses. "],["exercises.html", "1.5 Exercises", " 1.5 Exercises The Court Case: The Blue or Green Cab A cab was involved in a hit-and-run accident at night. There are two cab companies in the town: Blue and Green. The former has 150 cabs, and the latter has 850 cabs. A witness stated that a blue cab was involved in the accident; the court tested the reliability of the witness under similar circumstances and found that 80% of the time the witness correctly identified the color of the cab. What is the probability that the color of the cab involved in the accident was blue, given that the witness said it was blue? The Monty Hall Problem What is the probability of winning a car in the Monty Hall problem if you switch your decision, when there are four doors, three goats, and one car? Solve this problem both analytically and computationally. What if there are \\(n\\) doors, \\(n-1\\) goats, and one car? Solve the health insurance example using a Gamma prior in the rate parametrization, that is, \\(\\pi(\\lambda) = \\frac{\\beta_0^{\\alpha_0}}{\\Gamma(\\alpha_0)} \\lambda^{\\alpha_0 - 1} \\exp\\left\\{-\\lambda \\beta_0\\right\\}\\). Suppose you are analyzing the decision to buy car insurance for the next year. To make a better decision, you want to know: What is the probability that you will have a car claim next year? You have the records of your car claims over the last 15 years, \\(\\mathbf{y} = \\left\\{ 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0 \\right\\}\\). Assume that this is a random sample from a data-generating process (statistical model) that is Bernoulli, \\(Y_i \\sim \\text{Ber}(p)\\). Your prior beliefs about \\(p\\) are well described by a Beta distribution with parameters \\(\\alpha_0\\) and \\(\\beta_0\\), i.e., \\(p \\sim B(\\alpha_0, \\beta_0)\\). You are interested in calculating the probability of a claim the next year, \\(P(Y_0 = 1 \\mid \\mathbf{y})\\). Solve this using both an empirical Bayes approach and a non-informative approach where \\(\\alpha_0 = \\beta_0 = 1\\) (uniform distribution). Show that, given the loss function \\(L(\\theta, a) = |\\theta - a|\\), the optimal decision rule minimizing the risk function, \\(a^*(\\mathbf{y})\\), is the median. "],["Chap2.html", "Chapter 2 Conceptual differences between the Bayesian and Frequentist approaches", " Chapter 2 Conceptual differences between the Bayesian and Frequentist approaches We outline some of the conceptual differences between the Bayesian and Frequentist inferential approaches. We emphasize Bayesian concepts, as most readers may already be familiar with the Frequentist statistical framework. We illustrate the differences between these two inferential approaches using a simple example. In addition, we provide some potential explanations for why the Bayesian inferential framework is not well known at the introductory level among practitioners and applied researchers. "],["sec21.html", "2.1 The concept of probability", " 2.1 The concept of probability Let’s begin with the following thought experiment: Assume that you are watching the international game show “Who Wants to Be a Millionaire?”. The contestant is asked to answer a very simple question: What is the last name of the brothers who are credited with inventing the world’s first successful motor-operated airplane? What is the probability that the contestant answers this question correctly? Unless you have: watched this particular contestant participate in this show many times, seen him asked this same question each time, and computed the relative frequency with which he gives the correct answer, you need to answer this question as a Bayesian! Uncertainty about the event answering this question needs to be expressed as a “degree of belief,” informed by both data on the skill of the particular participant and how much he knows about inventors, as well as possibly prior knowledge of his performance in other game shows. Of course, your prior knowledge of the contestant may be minimal, or it may be well-informed. Either way, your final answer remains a degree of belief about an uncertain, and inherently unrepeatable, state of nature. The point of this hypothetical, light-hearted scenario is simply to highlight that a key distinction between the Frequentist and Bayesian approaches to inference is not the use (or nature) of prior information, but the manner in which probability is used. To the Bayesian, probability is the mathematical construct used to quantify uncertainty about an unknown state of nature, conditional on observed data and prior knowledge about the context in which that state occurs. To the Frequentist, probability is intrinsically linked to the concept of a repeated experiment, and the relative frequency with which a particular outcome occurs, conditional on that unknown state. This distinction remains key whether the Bayesian chooses to be informative or subjective in the specification of prior information, or chooses to be non-informative or objective. Frequentists consider probability to be a physical phenomenon, like mass or wavelength, whereas Bayesians stipulate that probability exists in the mind of scientists, as any scientific construct (Parmigiani and Inoue 2008). It seems that the understanding of the concept of probability for the common human being is more associated with “degrees of belief” rather than relative frequency. Peter Diggle, President of The Royal Statistical Society between 2014 and 2016, was asked in an interview, “A different trend which has surged upwards in statistics during Peter’s career is the popularity of Bayesian statistics. Does Peter consider himself a Bayesian?” He replied, “… you can’t not believe in Bayes’ theorem because it’s true. But that doesn’t make you a Bayesian in the philosophical sense. When people are making personal decisions – even if they don’t formally process Bayes’ theorem in their mind – they are adapting what they think they should believe in response to new evidence as it comes in. Bayes’ theorem is just the formal mathematical machinery for doing that.” However, we should mention that psychological experiments suggest that human beings suffer from anchoring, a cognitive bias that causes us to rely too heavily on previous information (the prior), so that the updating process (posterior) due to new information (likelihood) is not as strong as Bayes’ rule would suggest (Kahneman 2011). References "],["sec22.html", "2.2 Subjectivity is not the key", " 2.2 Subjectivity is not the key The concepts of subjectivity and objectivity indeed characterize both statistical paradigms in differing ways. Among Bayesians, there are those who are immersed in subjective rationality (Ramsey 1926; Finetti 1937; Savage 1954; D. V. Lindley 2000), but others who adopt objective prior distributions such as Jeffreys’, reference, empirical, or robust priors (T. Bayes 1763; P. Laplace 1812; Jeffreys 1961; J. Berger 2006) to operationalize Bayes’ rule and thereby weight quantitative (data-based) evidence. Among Frequentists, there are choices made about significance levels which, if not explicitly subjective, are typically not grounded in any objective and documented assessment of the relative losses of Type I and Type II errors.13 In addition, both Frequentist and Bayesian statisticians make decisions about the form of the data generating process, or “model”, which – if not subject to rigorous diagnostic assessment – retains a subjective element that potentially influences the final inferential outcome. Although we all know that by definition, a model is a schematic and simplified approximation to reality, “Since all models are wrong, the scientist cannot obtain a correct one by excessive elaboration. On the contrary, following William of Occam, he should seek an economical description of natural phenomena.” (G. E. P. Box 1976). We also know that “All models are wrong, but some are useful” (G. E. Box 1979), which is why model diagnostics are important. This task can be performed in both approaches. Particularly, the Bayesian framework can use predictive p-values for absolute testing (A. Gelman and Meng 1996; M. Bayarri and Berger 2000) or posterior odds ratios for relative statements (Jeffreys 1935; R. E. Kass and Raftery 1995). This is because the marginal likelihood, conditional on data, is interpreted as the evidence for the prior distribution (J. Berger 1993). In addition, what does objectivity mean in a Frequentist approach? For example, why should we use a 5% or 1% significance level rather than any other value? As someone said, the apparent objectivity is really a consensus (D. V. Lindley 2000). In fact, “Student” (William Gosset) saw statistical significance at any level as being “nearly valueless” in itself (Ziliak 2008). But, this is not just a situation in the Frequentist approach. The cut-offs used to “establish” scientific evidence against a null hypothesis, in terms of \\(log_{10}\\) scale (Jeffreys 1961) or \\(log_{e}\\) scale (R. E. Kass and Raftery 1995) as shown in Table 1.1, are also ad hoc. Although the true state of nature in Bayesian inference is expressed in “degrees of belief”, the distinction between the two paradigms does not reside in one being more, or less, subjective than the other. Rather, the differences are philosophical, pedagogical, and methodological. References "],["sec23.html", "2.3 Estimation, hypothesis testing and prediction", " 2.3 Estimation, hypothesis testing and prediction All that is required to perform estimation, hypothesis testing (model selection), and prediction in the Bayesian approach is to apply Bayes’ rule. This ensures coherence under a probabilistic view. However, there is no free lunch: coherence reduces flexibility. On the other hand, the Frequentist approach may not be coherent from a probabilistic point of view, but it is highly flexible. This approach can be seen as a toolkit that offers inferential solutions under the umbrella of understanding probability as relative frequency. For instance, a point estimator in a Frequentist approach is found such that it satisfies good sampling properties like unbiasedness, efficiency, or a large sample property such as consistency. A notable difference is that optimal Bayesian decisions are calculated by minimizing the expected value of the loss function with respect to the posterior distribution, i.e., conditional on observed data. In contrast, Frequentist “optimal” actions are based on the expected values over the distribution of the estimator (a function of data), conditional on the unknown parameters. This involves considering sampling variability. The Bayesian approach allows for the derivation of the posterior distribution of any unknown object, such as parameters, latent variables, future or unobserved variables, or models. A major advantage is that predictions can account for estimation error, and predictive distributions (probabilistic forecasts) can be easily derived. Hypothesis testing (model selection) in the Bayesian framework is based on inductive logic reasoning (inverse probability). Based on observed data, we evaluate which hypothesis is most tenable, performing this evaluation using posterior odds. These odds are in turn based on Bayes factors, which assess the evidence in favor of a null hypothesis while explicitly considering the alternative (R. E. Kass and Raftery 1995), following the rules of probability (D. V. Lindley 2000). This approach compares how well hypotheses predict data (Goodman 1999), minimizes the weighted sum of type I and type II error probabilities (DeGroot 1975; Pericchi and Pereira 2015), and takes into account the implicit balance of losses (Jeffreys 1961; Bernardo and Smith 1994). Posterior odds allow for the use of the same framework to analyze nested and non-nested models and perform model averaging. However, Bayes factors cannot be based on improper or vague priors (Koop 2003), the practical interplay between model selection and posterior distributions is not as straightforward as it may be in the Frequentist approach, and the computational burden can be more demanding due to the need to solve potentially difficult integrals. On the other hand, the Frequentist approach establishes most of its estimators as the solution to a system of equations. Observe that optimization problems often reduce to solving systems. We can potentially obtain the distribution of these estimators, but most of the time, asymptotic arguments or resampling techniques are required. Hypothesis testing relies on pivotal quantities and/or resampling, and prediction is typically based on a plug-in approach, which means that estimation error is not taken into account.14 In addition, ancillary statistics can be used to build prediction intervals.15 Comparing models depends on their structure. For instance, there are different Frequentist statistical approaches to compare nested and non-nested models. A nice feature in some situations is that there is a practical interplay between hypothesis testing and confidence intervals. For example, in the normal population mean hypothesis framework, you cannot reject a null hypothesis \\(H_0: \\mu = \\mu^0\\) at the \\(\\alpha\\) significance level (Type I error) if \\(\\mu^0\\) is in the \\(1-\\alpha\\) confidence interval. Specifically, \\[ P\\left( \\mu \\in \\left[\\hat{\\mu} - |t_{N-1}^{\\alpha/2}| \\times \\hat{\\sigma}_{\\hat{\\mu}}, \\hat{\\mu} + |t_{N-1}^{\\alpha/2}| \\times \\hat{\\sigma}_{\\hat{\\mu}}\\right] \\right) = 1 - \\alpha, \\] where \\(\\hat{\\mu}\\) and \\(\\hat{\\sigma}_{\\hat{\\mu}}\\) are the maximum likelihood estimators of the mean and standard error, \\(t_{N-1}^{\\alpha/2}\\) is the quantile value of the Student’s \\(t\\)-distribution at the \\(\\alpha/2\\) probability level with \\(N-1\\) degrees of freedom, and \\(N\\) is the sample size. A remarkable difference between the Bayesian and Frequentist inferential frameworks is the interpretation of credible/confidence intervals. Observe that once we have estimates, such that, for example, the previous interval is \\([0.2, 0.4]\\) given a 95% confidence level, we cannot say that \\(P(\\mu \\in [0.2, 0.4]) = 0.95\\) in the Frequentist framework. In fact, this probability is either 0 or 1 in this approach, as \\(\\mu\\) is either in the interval or it is not. The problem is that we will never know for certain in applied settings. This is because \\[ P(\\mu \\in [\\hat{\\mu} - |t_{N-1}^{0.025}| \\times \\hat{\\sigma}_{\\hat{\\mu}}, \\hat{\\mu} + |t_{N-1}^{0.025}| \\times \\hat{\\sigma}_{\\hat{\\mu}}]) = 0.95 \\] is interpreted in the context of repeated sampling. On the other hand, once we have the posterior distribution in the Bayesian framework, we can say that \\(P(\\mu \\in [0.2, 0.4]) = 0.95\\). Following common practice, most researchers and practitioners conduct hypothesis testing based on the p-value in the Frequentist framework. But what is a p-value? Most users do not know the answer, as statistical inference is often not performed by statisticians (J. Berger 2006).16 A p-value is the probability of obtaining a statistical summary of the data equal to or more extreme than what was actually observed, assuming that the null hypothesis is true. Therefore, p-value calculations involve not just the observed data, but also more extreme hypothetical observations. Thus, “What the use of p implies, therefore, is that a hypothesis that may be true may be rejected because it has not predicted observable results that have not occurred.” (Jeffreys 1961) It seems that common Frequentist inferential practice intertwines two different logical reasoning arguments: the p-value (Fisher 1958) and the significance level (Neyman and Pearson 1933). The former is an informal short-run criterion, whose philosophical foundation is reduction to absurdity, which measures the discrepancy between the data and the null hypothesis. Therefore, the p-value is not a direct measure of the probability that the null hypothesis is false. The latter, whose philosophical foundation is deduction, is based on long-run performance and controls the overall number of incorrect inferences in repeated sampling, without regard to individual cases. The p-value fallacy consists of interpreting the p-value as the strength of evidence against the null hypothesis and using it simultaneously with the frequency of Type I error under the null hypothesis (Goodman 1999). The American Statistical Association has several concerns regarding the use of the p-value as a cornerstone for hypothesis testing in science. This concern motivates the ASA’s statement on p-values (Wasserstein and Lazar 2016), which can be summarized in the following principles: “P-values can indicate how incompatible the data are with a specified statistical model.” “P-values do not measure the probability that the studied hypothesis is true, or the probability that the data were produced by random chance alone.” “Scientific conclusions and business or policy decisions should not be based solely on whether a p-value passes a specific threshold.” “Proper inference requires full reporting and transparency.” “A p-value, or statistical significance, does not measure the size of an effect or the importance of a result.” “By itself, a p-value does not provide a good measure of evidence regarding a model or hypothesis.” To sum up, Fisher proposed the p-value as a witness rather than a judge. So, a p-value lower than the significance level means more inspection of the null hypothesis, but it is not a final conclusion about it. Another difference between the Frequentists and the Bayesians is the way in which scientific hypotheses are tested. The former use the p-value, whereas the latter use the Bayes factor. Observe that the p-value is associated with the probability of the data given the hypothesis, whereas the Bayes factor is associated with the probability of the hypothesis given the data. However, there is an approximate link between the \\(t\\) statistic and the Bayes factor for regression coefficients (A. Raftery 1995). In particular, \\[ |t|&gt;(\\log(N)+6)^{1/2} \\] corresponds to strong evidence in favor of rejecting the null hypothesis of no relevance of a control in a regression. Observe that, in this setting, the threshold of the \\(t\\) statistic, and as a consequence the significance level, depends on the sample size. This setting agrees with the idea in experimental designs of selecting the sample size such that we control Type I and Type II errors. In observational studies, we cannot control the sample size, but we can select the significance level. See also Sellke, Bayarri, and Berger (2001) and Benjamin et al. (2018) for exercises that reveal potential flaws of the p-value (\\(p\\)) due to \\(p \\sim U[0,1]\\) under the null hypothesis,17 and calibrations of the p-value to interpret it as the odds ratio and the error probability. In particular, \\[ B(p)=-e \\times p \\times \\log(p) \\quad \\text{when} \\quad p &lt; e^{-1} \\] and interpret this as the Bayes factor of \\(H_0\\) to \\(H_1\\), where \\(H_1\\) denotes the unspecified alternative to \\(H_0\\), and \\[ \\alpha(p) = \\left(1 + \\left[-e \\times p \\times \\log(p)\\right]^{-1}\\right)^{-1} \\] as the error probability \\(\\alpha\\) in rejecting \\(H_0\\). Take into account that \\(B(p)\\) and \\(\\alpha(p)\\) are lower bounds. The logic of argumentation in the Frequentist approach is based on deductive logic, which means that it starts from a statement about the true state of nature (null hypothesis) and predicts what should be observed if this statement were true. On the other hand, the Bayesian approach is based on inductive logic, which means that it defines which hypothesis is more consistent with what is observed. The former inferential approach establishes that the truth of the premises implies the truth of the conclusion, which is why we reject or fail to reject hypotheses. The latter establishes that the premises supply some evidence, but not full assurance, of the truth of the conclusion, which is why we get probabilistic statements. Here, there is a distinction between the effects of causes (forward causal inference) and the causes of effects (reverse causal inference) (Andrew Gelman and Imbens 2013; Dawid, Musio, and Fienberg 2016). To illustrate this point, imagine that a firm increases the price of a specific good. Economic theory would suggest that, as a result, demand for the good decreases. In this case, the premise (null hypothesis) is the price increase, and the consequence is the decrease in the firm’s demand. Alternatively, one could observe a reduction in a firm’s demand and attempt to identify the cause behind it. For example, a reduction in quantity could be due to a negative supply shock. The Frequentist approach typically follows the first view (effects of causes), while Bayesian reasoning focuses on determining the probability of potential causes (causes of effects). References "],["sec24.html", "2.4 The likelihood principle", " 2.4 The likelihood principle The likelihood principle states that in making inferences or decisions about the state of nature, all the relevant experimental information is given by the likelihood function. The Bayesian framework follows this statement, i.e., it is conditional on observed data. We follow J. Berger (1993), who in turn followed D. V. Lindley and Phillips (1976), to illustrate the likelihood principle. We are given a coin and are interested in the probability, \\(\\theta\\), of it landing heads when flipped. We wish to test \\(H_0: \\theta = 1/2\\) versus \\(H_1: \\theta &gt; 1/2\\). An experiment is conducted by flipping the coin (independently) in a series of trials, with the result being the observation of 9 heads and 3 tails. This is not yet enough information to specify \\(p(y|\\theta)\\), since the series of trials has not been explained. Two possibilities arise: The experiment consisted of a predetermined 12 flips, so that \\(Y = [ \\text{Heads} ]\\) follows a \\(B(12, \\theta)\\) distribution. In this case, \\[ p_1(y|\\theta) = \\binom{12}{y} \\theta^y (1 - \\theta)^{12 - y} = 220 \\times \\theta^9 (1 - \\theta)^3. \\] The experiment consisted of flipping the coin until 3 tails were observed (\\(r = 3\\)). In this case, \\(Y\\), the number of heads (failures) before obtaining 3 tails, follows a \\(NB(3, 1 - \\theta)\\) distribution. Here, \\[ p_2(y|\\theta) = \\binom{y + r - 1}{r - 1} (1 - (1 - \\theta)^y)(1 - \\theta)^r = 55 \\times \\theta^9 (1 - \\theta)^3. \\] Using a Frequentist approach, the significance level of \\(y=9\\) using the Binomial model against \\(\\theta=1/2\\) would be: \\[ \\alpha_1=P_{1/2}(Y\\geq 9)=p_1(9|1/2)+p_1(10|1/2)+p_1(11|1/2)+p_1(12|1/2)=0.073. \\] success &lt;- 9 # Number of observed success in n trials n &lt;- 12 # Number of trials siglevel &lt;- sum(sapply(9:n,function(y)dbinom(y,n,0.5))) siglevel ## [1] 0.07299805 For the Negative Binomial model, the significance level would be: \\[ \\alpha_2=P_{1/2}(Y\\geq 9)=p_2(9|1/2)+p_2(10|1/2)+\\ldots=0.0327. \\] success &lt;- 3 # Number of target success (tails) failures &lt;- 9 # Number of failures siglevel &lt;- 1 - pnbinom((failures - 1),success,0.5) siglevel ## [1] 0.03271484 We arrive at different conclusions using a significance level of 5%, whereas we obtain the same outcomes using a Bayesian approach because the kernels of both distributions are identical (\\(\\theta^9 \\times (1 - \\theta)^3\\)). References "],["sec25.html", "2.5 Why is not the Bayesian approach that popular?", " 2.5 Why is not the Bayesian approach that popular? At this stage, one might wonder why the Bayesian statistical framework is not the dominant inferential approach, despite its historical origin in 1763 (Thomas Bayes 1763), whereas the Frequentist statistical framework was largely developed in the early 20th century. The scientific debate over the Bayesian inferential approach lasted for 150 years, and this may be explained by some of the following factors. One issue is the apparent subjectivity of the Bayesian approach, which runs counter to the strong conviction that science demands objectivity. Bayesian probability is considered a measure of degrees of belief, where the initial prior may be just a guess. This was not accepted as objective and rigorous science. Initial critics argued that Bayes was quantifying ignorance by assigning equal probabilities to all potential outcomes. As a consequence, prior distributions were dismissed (McGrayne 2011). Bayes himself seemed not to have believed in his idea. Although it seems that Bayes made his breakthrough in the late 1740s, he did not submit it for publication to the Royal Society. It was his friend, Richard Price, another Presbyterian minister, who rediscovered Bayes’ idea, polished it, and published it. However, it was Laplace who independently generalized Bayes’ theorem in 1781. Initially, he applied it to gambling problems and soon thereafter to astronomy, combining various sources of information to advance research in situations where data was scarce. He later sought to apply his discovery to finding the probability of causes, which he thought required large datasets, thus turning to demography. In this field, he had to perform large-scale calculations, leading to the development of Laplace’s approximation and the central limit theorem (P. Laplace 1812). Unfortunately, this came at the cost of abandoning his research on Bayesian inference. Once Laplace passed away in 1827, Bayes’ rule disappeared from the scientific discourse for almost a century. In part, personal attacks against Laplace led to the rule being forgotten. Moreover, there was a prevailing belief that statistics should not address causation, and that the prior was too subjective to be compatible with science. Nonetheless, practitioners continued to use Bayes’ rule to solve problems in astronomy, communication, medicine, military affairs, and social issues with remarkable results. Thus, the concept of degrees of belief to operationalize probability was abandoned in favor of scientific objectivity. Probability was then defined as the frequency with which an event occurs in many repeatable trials, which became the accepted norm. Critics of Laplace argued that these two concepts were diametrically opposed, although Laplace considered them to be basically equivalent when large sample sizes are involved (McGrayne 2011). The era of Frequentists, or sampling theorists, began, led by Karl Pearson and his nemesis, Ronald Fisher. Both were brilliant and persuasive characters, opposing the inverse probability approach and making it nearly impossible to argue against their ideas. Pearson’s legacy was carried on by his son, Egon, and Egon’s friend, Jerzy Neyman. Both inherited the anti-Bayesian and anti-Fisher sentiments. Despite the anti-Bayesian campaign among statisticians, some independent thinkers continued to develop Bayesian ideas, including Borel, Ramsey, and de Finetti, who were isolated in different countries: France, England, and Italy. However, the anti-Bayesian trio of Fisher, Neyman, and Egon Pearson dominated the spotlight in the 1920s and 1930s. Only a geophysicist, Harold Jeffreys, kept Bayesian inference alive during the 1930s and 1940s. Jeffreys was a quiet, reserved gentleman working in the astronomy department at Cambridge. He was Fisher’s friend due to their shared character, although they were intellectual opposites when it came to Bayesian inference, leading to intense intellectual battles. Unfortunately for the Bayesian approach, Jeffreys lost. His work was highly technical, using confusing high-level mathematics. He focused on inference from scientific evidence, rather than guiding future actions based on decision theory, which was crucial in that era for mathematical statistics, especially during the Second World War. In contrast, Fisher was a dominant figure, persuasive in public and a master of practical applications, with his techniques written in a popular style with minimal mathematics. Nevertheless, Bayes’ rule achieved remarkable results in applied settings such as at AT&amp;T and the U.S. Social Security system. Bayesian inference also played a significant role during the Second World War and the Cold War. Alan Turing used inverse probability at Bletchley Park to crack German messages encoded using the Enigma machine, which was employed by U-boats. Andrei Kolmogorov used Bayesian methods to improve firing tables for Russian artillery. Bernard Koopman applied it for searching targets at sea, and the RAND Corporation used it during the Cold War. Unfortunately, these Bayesian developments remained top secret for almost 40 years, keeping the contribution of inverse probability hidden from modern history. In the 1950s and 1960s, three mathematicians led the resurgence of the Bayesian approach: Good, Savage, and Lindley. However, it seems that they were reluctant to apply their theories to real-world problems. Despite the fact that the Bayesian approach proved its worth in various areas such as business decisions, naval searches, and lung cancer detection, it was largely applied to simple models due to its mathematical complexity and requirement for large computations. However, some breakthroughs changed this. First, hierarchical models were introduced by Lindley and Smith, where a complex model is decomposed into many smaller, easier-to-solve models. Second, Markov chain Monte Carlo (MCMC) methods were developed by Hastings in the 1970s (Hastings 1970) and the Geman brothers in the 1980s (Geman and Geman 1984). These methods were incorporated into the Bayesian inferential framework in the 1990s by Gelfand and Smith (A. E. Gelfand and Smith 1990), and Tierney (Tierney 1994), when desktop computers gained sufficient computational power to solve complex models. Since then, the Bayesian inferential framework has gained increasing popularity among both practitioners and scientists. References "],["sec26.html", "2.6 A simple working example", " 2.6 A simple working example We will illustrate some conceptual differences between the Bayesian and Frequentist statistical approaches by performing inference on a random sample \\(\\mathbf{Y} = [Y_1, Y_2, \\dots, Y_N]\\), where \\(Y_i \\stackrel{iid}{\\sim} N(\\mu, \\sigma^2)\\) for \\(i = 1, 2, \\dots, N\\). In particular, we set \\(\\pi(\\mu, \\sigma) = \\pi(\\mu) \\pi(\\sigma) \\propto \\frac{1}{\\sigma}\\). This is a standard non-informative improper prior (Jeffreys prior, see Chapter 3). That is, this prior is perfectly compatible with the sample information. Additionally, we assume independent priors for \\(\\mu\\) and \\(\\sigma\\). \\[ \\begin{aligned} \\pi(\\mu,\\sigma|\\mathbf{y}) &amp;\\propto \\frac{1}{\\sigma}\\times (\\sigma^2)^{-N/2}\\exp\\left\\{-\\frac{1}{2\\sigma^2}\\sum_{i=1}^N (y_i-\\mu)^2\\right\\} \\\\ &amp;= \\frac{1}{\\sigma}\\times (\\sigma^2)^{-N/2}\\exp\\left\\{-\\frac{1}{2\\sigma^2}\\sum_{i=1}^N \\left((y_i-\\bar{y}) - (\\mu-\\bar{y})\\right)^2\\right\\} \\\\ &amp;= \\frac{1}{\\sigma}\\exp\\left\\{-\\frac{N}{2\\sigma^2}(\\mu-\\bar{y})^2\\right\\}\\times (\\sigma)^{-N}\\exp\\left\\{-\\frac{1}{2\\sigma^2}\\sum_{i=1}^N (y_i-\\bar{y})^2\\right\\} \\\\ &amp;= \\frac{1}{\\sigma}\\exp\\left\\{-\\frac{N}{2\\sigma^2}(\\mu-\\bar{y})^2\\right\\}\\times (\\sigma)^{-(\\alpha_n+1)}\\exp\\left\\{-\\frac{\\alpha_n\\hat{\\sigma}^2}{2\\sigma^2}\\right\\}, \\end{aligned} \\] where \\(\\bar{y} = \\frac{\\sum_{i=1}^N y_i}{N}\\), \\(\\alpha_n = N-1\\), and \\(\\hat{\\sigma}^2 = \\frac{\\sum_{i=1}^N (y_i-\\bar{y})^2}{N-1}\\). The first term in the last expression is the kernel of a normal density, \\(\\mu|\\sigma,\\mathbf{y} \\sim N(\\bar{y}, \\sigma^2 / N)\\). The second term is the kernel of an inverted gamma density (Zellner 1996), \\(\\sigma|\\mathbf{y} \\sim IG(\\alpha_n, \\hat{\\sigma}^2)\\). Therefore, \\[ \\pi(\\mu|\\sigma,\\mathbf{y}) = \\frac{1}{\\sqrt{2\\pi \\sigma^2 / N}} \\exp\\left\\{-\\frac{N}{2\\sigma^2}(\\mu-\\bar{y})^2\\right\\}, \\] and \\[ \\pi(\\sigma|\\mathbf{y}) = \\frac{2}{\\Gamma(\\alpha_n / 2)} \\left(\\frac{\\alpha_n \\hat{\\sigma}^2}{2}\\right)^{\\alpha_n / 2} \\frac{1}{\\sigma^{\\alpha_n+1}} \\exp\\left\\{-\\frac{\\alpha_n \\hat{\\sigma}^2}{2 \\sigma^2}\\right\\}. \\] Observe that \\(\\mathbb{E}[\\mu | \\sigma, \\mathbf{y}] = \\bar{y}\\); this is also the maximum likelihood (Frequentist) point estimate of \\(\\mu\\) in this setting. In addition, the Frequentist \\((1-\\alpha)\\%\\) confidence interval and the Bayesian \\((1-\\alpha)\\%\\) credible interval have exactly the same form, \\(\\bar{y} \\pm |z_{\\alpha/2}| \\frac{\\sigma}{\\sqrt{N}}\\), where \\(z_{\\alpha/2}\\) is the \\(\\alpha/2\\) percentile of a standard normal distribution. However, the interpretations are entirely different. The confidence interval has a probabilistic interpretation under sampling variability of \\(\\bar{Y}\\): in repeated sampling, \\((1-\\alpha)\\%\\) of the intervals \\(\\bar{Y} \\pm |z_{\\alpha/2}| \\frac{\\sigma}{\\sqrt{N}}\\) would include \\(\\mu\\). However, given an observed realization of \\(\\bar{Y}\\), say \\(\\bar{y}\\), the probability of \\(\\bar{y} \\pm |z_{\\alpha/2}| \\frac{\\sigma}{\\sqrt{N}}\\) including \\(\\mu\\) is either 1 or 0. This is why we refer to it as a \\((1-\\alpha)\\%\\) confidence interval. On the other hand, \\(\\bar{y} \\pm |z_{\\alpha/2}| \\frac{\\sigma}{\\sqrt{N}}\\) has a straightforward probabilistic interpretation in the Bayesian framework: there is a \\((1-\\alpha)\\%\\) probability that \\(\\mu\\) lies within this interval. If we want to get the marginal posterior density of \\(\\mu\\), \\[\\begin{align*} \\pi(\\mu|\\mathbf{y})&amp;=\\int_{0}^{\\infty} \\pi(\\mu,\\sigma|\\mathbf{y}) d\\sigma\\\\ &amp;\\propto \\int_{0}^{\\infty} \\frac{1}{\\sigma}\\times (\\sigma^2)^{-N/2}\\exp\\left\\{-\\frac{1}{2\\sigma^2}\\sum_{i=1}^N (y_i-\\mu)^2\\right\\} d\\sigma\\\\ &amp;= \\int_{0}^{\\infty} \\left(\\frac{1}{\\sigma}\\right)^{N+1} \\exp\\left\\{-\\frac{N}{2\\sigma^2}\\frac{\\sum_{i=1}^N (y_i-\\mu)^2}{N}\\right\\} d\\sigma\\\\ &amp;=\\left[\\frac{2}{\\Gamma(N/2)}\\left(\\frac{N\\sum_{i=1}^N (y_i-\\mu)^2}{2N}\\right)^{N/2}\\right]^{-1}\\\\ &amp;\\propto \\left[\\sum_{i=1}^N (y_i-\\mu)^2\\right]^{-N/2}\\\\ &amp;=\\left[\\sum_{i=1}^N ((y_i-\\bar{y})-(\\mu-\\bar{y}))^2\\right]^{-N/2}\\\\ &amp;=[\\alpha_n\\hat{\\sigma}^2+N(\\mu-\\bar{y})^2]^{-N/2}\\\\ &amp;\\propto \\left[1+\\frac{1}{\\alpha_n}\\left(\\frac{\\mu-\\bar{y}}{\\hat{\\sigma}/\\sqrt{N}}\\right)^2\\right]^{-(\\alpha_n+1)/2}. \\end{align*}\\] The fourth line arises from the kernel of an inverted gamma density with \\(N\\) degrees of freedom in the integral (Zellner 1996). The last expression represents the kernel of a Student’s \\(t\\)-distribution with \\(\\alpha_n = N - 1\\) degrees of freedom, expected value equal to \\(\\bar{y}\\), and variance \\(\\frac{\\hat{\\sigma}^2}{N} \\left( \\frac{\\alpha_n}{\\alpha_n - 2} \\right)\\). Therefore, \\(\\mu | \\mathbf{y} \\sim t \\left( \\bar{y}, \\frac{\\hat{\\sigma}^2}{N} \\left( \\frac{\\alpha_n}{\\alpha_n - 2} \\right), \\alpha_n \\right)\\). Observe that a \\((1-\\alpha)\\%\\) confidence interval and a \\((1-\\alpha)\\%\\) credible interval have exactly the same form, \\(\\bar{y} \\pm |t_{\\alpha/2}^{\\alpha_n}| \\frac{\\hat{\\sigma}}{\\sqrt{N}}\\), where \\(t_{\\alpha/2}^{\\alpha_n}\\) is the \\(\\alpha/2\\) percentile of a Student’s \\(t\\)-distribution. However, the interpretations are entirely different. The mathematical similarity between the Frequentist and Bayesian expressions in this example arises from the use of an improper prior. Example: Math test You have a random sample of math scores of size \\(N = 50\\) from a normal distribution, \\(Y_i \\sim N(\\mu, \\sigma^2)\\). The sample mean and variance are equal to 102 and 10, respectively. Assuming an improper prior equal to \\(\\frac{1}{\\sigma}\\), we proceed with the following tasks: Compute the 95% confidence and credible intervals for \\(\\mu\\). Determine the posterior probability that \\(\\mu &gt; 103\\). Using the fact that \\(\\mu | \\mathbf{y} \\sim t\\left(\\bar{y}, \\frac{\\hat{\\sigma}^2}{N} \\left( \\frac{\\alpha_n}{\\alpha_n - 2} \\right), \\alpha_n \\right)\\), which implies that the confidence and credible intervals for \\(\\mu\\) are given by: \\[ \\begin{aligned} \\bar{y} \\pm |t_{\\alpha/2}^{\\alpha_n}| \\frac{\\hat{\\sigma}}{\\sqrt{N}}, \\end{aligned} \\] where \\(\\bar{y} = 102\\), \\(\\hat{\\sigma}^2 = 10\\), and \\(\\alpha_n = 49\\). Thus, the 95% confidence and credible intervals for \\(\\mu\\) are the same, namely \\((101.1, 102.9)\\), and the posterior probability that \\(\\mu &gt; 103\\) is 1.49% given the sample information. N &lt;- 50 # Sample size y_bar &lt;- 102 # Sample mean s2 &lt;- 10 # Sample variance alpha &lt;- N - 1 serror &lt;- (s2/N)^0.5 LimInf &lt;- y_bar - abs(qt(0.025, alpha)) * serror LimInf ## [1] 101.1013 # Lower bound LimSup &lt;- y_bar + abs(qt(0.025, alpha)) * serror LimSup ## [1] 102.8987 # Upper bound y.cut &lt;- 103 P &lt;- 1-metRology::pt.scaled(y.cut, df = alpha, mean = y_bar, sd = serror) P ## [1] 0.01496694 # Probability of mu greater than y.cut References "],["sec27.html", "2.7 Summary", " 2.7 Summary The differences between the Bayesian and Frequentist inferential approaches are philosophical, particularly with regard to the role of probability; pedagogical, especially in relation to the use of inference for decision-making; and methodological, due to differences in their mathematical and computational frameworks. Although, at the methodological level, the debate has become considerably muted —except for certain aspects of inference— there is widespread recognition that each approach has much to contribute to statistical practice (Good (1992), M. J. Bayarri and Berger (2004), R. Kass (2011)). As Bradley Efron stated, “Computer-age statistical inference at its most successful combines elements of the two philosophies” (Bradley Efron and Hastie (2016)). References "],["sec28.html", "2.8 Exercises", " 2.8 Exercises Jeffreys-Lindley’s Paradox The Jeffreys-Lindley’s paradox (Jeffreys 1961; Dennis V. Lindley 1957) represents an apparent disagreement between the Bayesian and Frequentist frameworks in a hypothesis testing scenario. In particular, assume that in a city, 49,581 boys and 48,870 girls have been born over 20 years. Assume that the male births follow a Binomial distribution with probability \\(\\theta\\). We wish to test the null hypothesis \\(H_0: \\ \\theta = 0.5\\) versus the alternative hypothesis \\(H_1: \\ \\theta \\neq 0.5\\). Show that the posterior model probability for the null model is approximately 0.95. Assume \\(\\pi(H_0) = \\pi(H_1) = 0.5\\), and that \\(\\pi(\\theta)\\) follows a uniform distribution, i.e., \\({U}(0,1)\\), under \\(H_1\\). Show that the p-value for this hypothesis test is 0.0235 using the normal approximation, \\(Y \\sim N(N \\times \\theta, N \\times \\theta \\times (1 - \\theta))\\). We want to test \\(H_0: \\ \\mu = \\mu_0\\) versus \\(H_1: \\ \\mu \\neq \\mu_0\\) given \\(Y_i \\stackrel{iid}{\\sim} N(\\mu, \\sigma^2)\\). Assume \\(\\pi(H_0) = \\pi(H_1) = 0.5\\), and that \\(\\pi(\\mu, \\sigma) \\propto 1/\\sigma\\) under the alternative hypothesis. Show that \\[ p(\\mathbf{y}|\\mathcal{M}_1) = \\frac{\\pi^{-N/2}}{2} \\Gamma(N/2) 2^{N/2} \\left( \\frac{1}{\\alpha_n \\hat{\\sigma}^2} \\right)^{N/2} \\left( \\frac{N}{\\alpha_n \\hat{\\sigma}^2} \\right)^{-1/2} \\frac{\\Gamma(1/2) \\Gamma(\\alpha_n/2)}{\\Gamma((\\alpha_n+1)/2)} \\] and \\[ p(\\mathbf{y}|\\mathcal{M}_0) = (2\\pi)^{-N/2} \\left[ \\frac{2}{\\Gamma(N/2)} \\left( \\frac{N}{2} \\frac{\\sum_{i=1}^N (y_i - \\mu_0)^2}{N} \\right)^{N/2} \\right]^{-1}. \\] Then, the posterior odds ratio is: \\[ PO_{01} = \\frac{p(\\mathbf{y}|\\mathcal{M}_0)}{p(\\mathbf{y}|\\mathcal{M}_1)} = \\frac{\\Gamma((\\alpha_n+1)/2)}{\\Gamma(1/2)\\Gamma(\\alpha_n/2)} (\\alpha_n \\hat{\\sigma}^2 / N)^{-1/2} \\left[ 1 + \\frac{(\\mu_0 - \\bar{y})^2}{\\alpha_n \\hat{\\sigma}^2 / N} \\right]^{-\\left(\\frac{\\alpha_n + 1}{2}\\right)}, \\] where \\(\\alpha_n = N - 1\\) and \\(\\hat{\\sigma}^2 = \\frac{\\sum_{i=1}^N (y_i - \\bar{y})^2}{N-1}\\). Find the relationship between the posterior odds ratio and the classical test statistic for the null hypothesis. Math Test Continues Using the setting of the Example: Math Test in Subsection 2.6, test \\(H_0: \\ \\mu = \\mu_0\\) versus \\(H_1: \\ \\mu \\neq \\mu_0\\) where \\(\\mu_0 = \\{ 100, 100.5, 101, 101.5, 102 \\}\\). What is the p-value for these hypothesis tests? Find the posterior model probability of the null model for each \\(\\mu_0\\). References "],["Chap3.html", "Chapter 3 Cornerstone models: Conjugate families", " Chapter 3 Cornerstone models: Conjugate families We will introduce conjugate families in basic statistical models with examples, solving them analytically and computationally using R. We will have some mathematical, and computational exercises in R. "],["sec41.html", "3.1 Motivation of conjugate families", " 3.1 Motivation of conjugate families Observing three fundamental pieces of Bayesian analysis: the posterior distribution (parameter inference), the marginal likelihood (hypothesis testing), and the predictive distribution (prediction), equations (3.1), (3.2) and (3.3), respectively, \\[\\begin{align} \\pi(\\mathbf{\\theta}|\\mathbf{y})&amp;=\\frac{p(\\mathbf{y}|\\mathbf{\\theta}) \\times \\pi(\\mathbf{\\theta})}{p(\\mathbf{y})}, \\tag{3.1} \\end{align}\\] \\[\\begin{equation} p(\\mathbf{y})=\\int_{\\mathbf{\\Theta}}p(\\mathbf{y}|\\mathbf{\\theta})\\pi(\\mathbf{\\theta})d\\mathbf{\\theta}, \\tag{3.2} \\end{equation}\\] and \\[\\begin{equation} p(\\mathbf{Y}_0|\\mathbf{y})=\\int_{\\mathbf{\\Theta}}p(\\mathbf{Y}_0|\\mathbf{\\theta})\\pi(\\mathbf{\\theta}|\\mathbf{y})d\\mathbf{\\theta}, \\tag{3.3} \\end{equation}\\] we can understand that some of the initial limitations of the application of the Bayesian analysis were associated with the ausence of algorithms to draw from non-standard posterior distributions (equation (3.1)), and the lack of analytical solutions of the marginal likelihood (equation (3.2)) and the predictive distribution (equation (3.3)). Both issues requiring computational power. Although there were algorithms to sample from non-standard posterior distributions since the second half of the last century [Metropolis et al. (1953)](Hastings 1970),(Geman and Geman 1984), their particular application in the Bayesian framework emerged later (A. E. Gelfand and Smith 1990),(Tierney 1994), maybe until increasing computational power of desktop computers. However, it is also common practice nowadays to use models that have standard conditional posterior distributions to mitigate computational requirements. In addition, nice mathematical tricks plus computational algorithms (Alan E. Gelfand and Dey 1994), (Siddhartha Chib 1995),(Siddhartha Chib and Jeliazkov 2001) and approximations [Tierney and Kadane (1986)](Jordan and Saul 1999) are used to obtain the marginal likelihood (prior predictive). Despite these advances, there are two potentially conflicting desirable model specification features that we can see from equations (3.1), (3.2) and (3.3): analytical solutions and the posterior distribution in the same family as the prior distribution for a given likelihood. The latter is called conjugate priors, a family of priors that is closed under sampling (Schlaifer and Raiffa 1961, p.~ 43-57). These features are desirable as the former implies facility to perform hypothesis testing and predictive analysis, and the latter means invariance of the prior-to-posterior updating. Both feautures imply less computational burden. We can easily achieve each of these features independenly, for instance using improper priors for analytical tractability, and defining in a broad sense the family of prior distributions for prior conjugacy. However, these are in conflict. Fortunately, we can achieve these two nice features if we assume that the data generating process is given by a distribution function in the exponential family. That is, given a random sample \\(\\mathbf{y}=[y_1,y_2,\\dots,y_N]^{\\top}\\), a probability density function \\(p(\\mathbf{y}|\\mathbf{\\theta})\\) belongs to the exponential family if it has the form \\[\\begin{align} p(\\mathbf{y}|\\mathbf{\\theta})&amp;=\\prod_{i=1}^N h(y_i) C(\\mathbf{\\theta}) \\exp\\left\\{\\eta(\\mathbf{\\theta})^{\\top}\\mathbf{T}(y_i)\\right\\}\\\\ &amp;=h(\\mathbf{y}) C(\\mathbf{\\theta})^N\\exp\\left\\{\\eta(\\mathbf{\\theta})^{\\top}\\mathbf{T}(\\mathbf{y})\\right\\} \\tag{3.4}\\\\ &amp;=h(\\mathbf{y})\\exp\\left\\{\\eta(\\mathbf{\\theta})^{\\top}\\mathbf{T}(\\mathbf{y})-A(\\mathbf{\\theta})\\right\\}, \\end{align}\\] where \\(h(\\mathbf{y})=\\prod_{i=1}^N h(y_i)\\) is a non-negative function, \\(\\eta(\\mathbf{\\theta})\\) is a known function of the parameters, \\(A(\\mathbf{\\theta})=\\log\\left\\{\\int_{\\mathbf{Y}}h(\\mathbf{y})\\exp\\left\\{\\eta(\\mathbf{\\theta})^{\\top}\\mathbf{T}(\\mathbf{y})\\right\\}d\\mathbf{y}\\right\\}=-N\\log(C(\\mathbf{\\theta}))\\) is a normalization factor, and \\(\\mathbf{T}(\\mathbf{y})=\\sum_{i=1}^N\\mathbf{T}(y_i)\\) is the vector of sufficient statistics of the distribution (by the factorization theorem). If the support of \\(\\mathbf{y}\\) is independent of \\(\\mathbf{\\theta}\\), then the family is said to be regular, otherwise it is irregular. In addition, if we set \\(\\eta=\\eta(\\mathbf{\\theta})\\), then the exponential family is said to be in the canonical form \\[\\begin{align} p(\\mathbf{y}|\\mathbf{\\theta})&amp;=h(\\mathbf{y})D(\\mathbf{\\eta})^N\\exp\\left\\{\\eta^{\\top}\\mathbf{T}(\\mathbf{y})\\right\\}\\\\ &amp;=h(\\mathbf{y})\\exp\\left\\{\\eta^{\\top}\\mathbf{T}(\\mathbf{y})-B(\\mathbf{\\eta})\\right\\}. \\end{align}\\] A nice feature of this representation is that \\(\\mathbb{E}[\\mathbf{T}(\\mathbf{y})|\\mathbf{\\eta}]=\\nabla B(\\mathbf{\\eta})\\) and \\(Var[\\mathbf{T}(\\mathbf{y})|\\mathbf{\\eta}]=\\nabla^2 B(\\mathbf{\\eta})\\). Examples of exponential family distributions Discrete distributions Given a random sample \\(\\mathbf{y}=[y_1,y_2,\\dots,y_N]^{\\top}\\) from a Poisson distribution let’s show that \\(p(\\mathbf{y}|\\lambda)\\) is in the exponential family. \\[\\begin{align} p(\\mathbf{y}|\\lambda)&amp;=\\prod_{i=1}^N \\frac{\\lambda^{y_i} \\exp(-\\lambda)}{y_i!}\\\\ &amp;=\\frac{\\lambda^{\\sum_{i=1}^N y_i}\\exp(-N\\lambda)}{\\prod_{i=1}^N y_i!}\\\\ &amp;=\\frac{\\exp(-N\\lambda)\\exp(\\sum_{i=1}^Ny_i\\log(\\lambda))}{\\prod_{i=1}^N y_i!}, \\end{align}\\] then \\(h(\\mathbf{y})=\\left[\\prod_{i=1}^N y_i!\\right]^{-1}\\), \\(\\eta(\\lambda)=\\log(\\lambda)\\), \\(T(\\mathbf{y})=\\sum_{i=1}^N y_i\\) (sufficient statistic) and \\(C(\\lambda)=\\exp(-\\lambda)\\). If we set \\(\\eta=\\log(\\lambda)\\), then \\[\\begin{align} p(\\mathbf{y}|\\eta)&amp;=\\frac{\\exp(\\eta\\sum_{i=1}^Ny_i-N\\exp(\\eta))}{\\prod_{i=1}^N y_i!}, \\end{align}\\] such that \\(B(\\eta)=N\\exp(\\eta)\\), then \\(\\nabla(B(\\eta))=N\\exp(\\eta)=N\\lambda=\\mathbb{E}\\left[\\sum_{i=1}^N y_i\\biggr\\rvert\\lambda\\right]\\), that is, \\(\\mathbb{E}\\left[\\frac{\\sum_{i=1}^N y_i}{N}\\biggr\\rvert\\lambda\\right]=\\mathbb{E}[\\bar{y}|\\lambda]=\\lambda\\), and \\(\\nabla^2(B(\\eta))=N\\exp(\\eta)=N\\lambda=Var\\left[\\sum_{i=1}^N y_i\\biggr\\rvert\\lambda\\right]=N^2 \\times Var\\left[\\bar{y}\\rvert\\lambda\\right]\\), then \\(Var\\left[\\bar{y}\\rvert\\lambda\\right]=\\frac{\\lambda}{N}\\). Given a random sample \\(\\mathbf{y}=[y_1,y_2,\\dots,y_N]^{\\top}\\) from a Bernoulli distribution let’s show that \\(p(\\mathbf{y}|\\theta)\\) is in the exponential family. \\[\\begin{align} p(\\mathbf{y}|\\theta)&amp;=\\prod_{i=1}^N \\theta^{y_i}(1-\\theta)^{1-y_i}\\\\ &amp;=\\theta^{\\sum_{i=1}^N y_i}(1-\\theta)^{N-\\sum_{i=1}^N y_i}\\\\ &amp;=(1-\\theta)^N\\exp\\left\\{\\sum_{i=1}^N y_i\\log\\left(\\frac{\\theta}{1-\\theta}\\right)\\right\\}, \\end{align}\\] then \\(h(\\mathbf{y})=\\mathbb{I}[y_i\\in\\left\\{0,1\\right\\}]\\), \\(\\eta(\\theta)=\\log\\left(\\frac{\\theta}{1-\\theta}\\right)\\), \\(T(\\mathbf{y})=\\sum_{i=1}^N y_i\\) and \\(C(\\theta)=1-\\theta\\). Write this distribution in the canonical form, and find the mean and variance of the sufficient statistic (exercise 1). Given a random sample \\(\\mathbf{y}=[\\mathbf{y}_1,\\mathbf{y}_2,\\dots,\\mathbf{y}_N]\\) from a m-dimensional multinomial distribution, where \\(\\mathbf{y}_i=\\left[y_{i1},\\dots,y_{im}\\right]\\), \\(\\sum_{l=1}^m y_{il}=n\\), \\(n\\) independent trials each of which leads to a success for exactly one of \\(m\\) categories with probabilities \\(\\mathbf{\\theta}=[\\theta_1,\\theta_2,\\dots,\\theta_m]\\), \\(\\sum_{l=1}^m \\theta_l=1\\). Let’s show that \\(p(\\mathbf{y}|\\mathbf{\\theta})\\) is in the exponential family. \\[\\begin{align} p(\\mathbf{y}|\\mathbf{\\theta})&amp;=\\prod_{i=1}^N \\frac{n!}{\\prod_{l=1}^m y_{il}!} \\prod_{l=1}^m\\theta_l^{y_{il}}\\\\ &amp;=\\frac{(n!)^N}{\\prod_{i=1}^N\\prod_{l=1}^m y_{il}!}\\exp\\left\\{\\sum_{i=1}^N\\sum_{l=1}^m y_{il}\\log(\\theta_l)\\right\\}\\\\ &amp;=\\frac{(n!)^N}{\\prod_{i=1}^N\\prod_{l=1}^m y_{il}!}\\exp\\left\\{\\left(N\\times n-\\sum_{i=1}^N\\sum_{l=1}^{m-1}y_{il}\\right)\\log(\\theta_m)+\\sum_{i=1}^N\\sum_{l=1}^{m-1}y_{il}\\log(\\theta_l)\\right\\}\\\\ &amp;=\\frac{(n!)^N}{\\prod_{i=1}^N\\prod_{l=1}^m y_{il}!}\\theta_m^{N\\times n}\\exp\\left\\{\\sum_{i=1}^N\\sum_{l=1}^{m-1}y_{il}\\log(\\theta_l/\\theta_m)\\right\\}, \\end{align}\\] then \\(h(\\mathbf{y})=\\frac{(n!)^N}{\\prod_{i=1}^N\\prod_{l=1}^m y_{il}!}\\), \\(\\eta(\\mathbf{\\theta})=\\left[\\log\\left(\\frac{\\theta_1}{\\theta_m}\\right)\\dots \\log\\left(\\frac{\\theta_{m-1}}{\\theta_m}\\right)\\right]\\), \\(T(\\mathbf{y})=\\left[\\sum_{i=1}^N y_{i1}\\dots \\sum_{i=1}^N y_{im-1}\\right]\\) and \\(C(\\mathbf{\\theta})=\\theta_m^n\\). Continuous distributions Given a random sample \\(\\mathbf{y}=[y_1,y_2,\\dots,y_N]^{\\top}\\) from a normal distribution let’s show that \\(p(\\mathbf{y}|\\mu,\\sigma^2)\\) is in the exponential family. \\[\\begin{align} p(\\mathbf{y}|\\mu,\\sigma^2)&amp;=\\prod_{i=1}^N \\frac{1}{2\\pi\\sigma^2}\\exp\\left\\{-\\frac{1}{2\\sigma^2}\\left(y_i-\\mu\\right)^2\\right\\}\\\\ &amp;= (2\\pi)^{-N/2}(\\sigma^2)^{-N/2}\\exp\\left\\{-\\frac{1}{2\\sigma^2}\\sum_{i=1}^N\\left(y_i-\\mu\\right)^2\\right\\}\\\\ &amp;= (2\\pi)^{-N/2}\\exp\\left\\{-\\frac{1}{2\\sigma^2}\\sum_{i=1}^Ny_i^2+\\frac{\\mu}{\\sigma^2}\\sum_{i=1}^N y_i-N\\frac{\\mu^2}{2\\sigma^2}-\\frac{N}{2}\\log(\\sigma^2)\\right\\} \\end{align}\\] then \\(h(\\mathbf{y})=(2\\pi)^{-N/2}\\), \\(\\eta(\\mu,\\sigma^2)=\\left[\\frac{\\mu}{\\sigma^2} \\ \\frac{-1}{2\\sigma^2}\\right]\\), \\(T(\\mathbf{y})=\\left[\\sum_{i=1}^N y_i \\ \\sum_{i=1}^N y_i^2\\right]\\) and \\(C(\\mu,\\sigma^2)=\\exp\\left\\{-\\frac{\\mu^2}{2\\sigma^2}-\\frac{\\log(\\sigma^2)}{2}\\right\\}\\). Observe that \\[\\begin{align} p(\\mathbf{y}|\\mu,\\sigma^2)&amp;= (2\\pi)^{-N/2}\\exp\\left\\{\\eta_1\\sum_{i=1}^N y_i+\\eta_2\\sum_{i=1}^Ny_i^2-\\frac{N}{2}\\log(-2\\eta_2)+\\frac{N}{4}\\frac{\\eta_1^2}{\\eta_2}\\right\\}, \\end{align}\\] where \\(B(\\mathbf{\\eta})=\\frac{N}{2}\\log(-2\\eta_2)-\\frac{N}{4}\\frac{\\eta_1^2}{\\eta_2}\\). Then, \\[\\begin{align} \\nabla B(\\mathbf{\\eta}) &amp; = \\begin{bmatrix} -\\frac{N}{2}\\frac{\\eta_1}{\\eta_2}\\\\ -\\frac{N}{2}\\frac{1}{\\eta_2}+\\frac{N}{4}\\frac{\\eta_1^2}{\\eta_2^2} \\end{bmatrix} = \\begin{bmatrix} N\\times\\mu\\\\ N\\times(\\mu^2+\\sigma^2) \\end{bmatrix} = \\begin{bmatrix} \\mathbb{E}\\left[\\sum_{i=1}^N y_i\\bigr\\rvert \\mu,\\sigma^2\\right]\\\\ \\mathbb{E}\\left[\\sum_{i=1}^N y_i^2\\bigr\\rvert \\mu,\\sigma^2\\right] \\end{bmatrix}. \\end{align}\\] Given \\(\\mathbf{Y}=[\\mathbf{y}_1 \\ \\mathbf{y}_2 \\ \\dots \\ \\mathbf{y}_p]\\) a \\(N\\times p\\) matrix such that \\(\\mathbf{y}_i\\sim N_p(\\mathbf{\\mu},\\mathbf{\\Sigma})\\), \\(i=1,2,\\dots,N\\), that is, each \\(i\\)-th row of \\(\\mathbf{Y}\\) follows a multivariate normal distribution. Then, assuming independence between rows, let’s show that \\(p(\\mathbf{y}_1,\\mathbf{y}_2,\\dots,\\mathbf{y}_N|\\mathbf{\\mu},\\mathbf{\\Sigma})\\) is in the exponential family. \\[\\begin{align} p(\\mathbf{y}_1,\\mathbf{y}_2,\\dots,\\mathbf{y}_N|\\mathbf{\\mu},\\mathbf{\\Sigma})&amp;=\\prod_{i=1}^N (2\\pi)^{-p/2}|\\Sigma|^{-1/2}\\exp\\left\\{-\\frac{1}{2}\\left(\\mathbf{y}_i-\\mathbf{\\mu}\\right)^{\\top}\\mathbf{\\Sigma}^{-1}\\left(\\mathbf{y}_i-\\mathbf{\\mu}\\right)\\right\\}\\\\ &amp;= (2\\pi)^{-pN/2}|\\Sigma|^{-N/2}\\exp\\left\\{-\\frac{1}{2}tr\\left[\\sum_{i=1}^N\\left(\\mathbf{y}_i-\\mathbf{\\mu}\\right)^{\\top}\\mathbf{\\Sigma}^{-1}\\left(\\mathbf{y}_i-\\mathbf{\\mu}\\right)\\right]\\right\\}\\\\ &amp;= (2\\pi)^{-p N/2}|\\Sigma|^{-N/2}\\exp\\left\\{-\\frac{1}{2}tr\\left[\\left(\\mathbf{S}+N\\left(\\mathbf{\\mu}-\\hat{\\mathbf{\\mu}}\\right)\\left(\\mathbf{\\mu}-\\hat{\\mathbf{\\mu}}\\right)^{\\top}\\right)\\mathbf{\\Sigma}^{-1}\\right]\\right\\}\\\\ &amp;= (2\\pi)^{-p N/2}\\exp\\left\\{-\\frac{1}{2}\\left[\\left(vec\\left(\\mathbf{S}\\right)^{\\top}+N vec\\left(\\hat{\\mathbf{\\mu}}\\hat{\\mathbf{\\mu}}^{\\top}\\right)^{\\top}\\right)vec \\left(\\mathbf{\\Sigma}^{-1}\\right)\\right.\\right.\\\\ &amp;\\left.\\left.-2N\\hat{\\mathbf{\\mu}}^{\\top}vec\\left(\\mathbf{\\mu}^{\\top}\\mathbf{\\Sigma}^{-1}\\right)+N tr\\left(\\mathbf{\\mu}\\mathbf{\\mu}^{\\top}\\mathbf{\\Sigma}^{-1}\\right)+N\\log (|\\mathbf{\\Sigma}|)\\right]\\right\\}\\\\ \\end{align}\\] where the second line uses the trace operator (\\(tr\\)), and its invariability under cyclic permutation is used in the third line. In addition, we add and subtract \\(\\hat{\\mathbf{\\mu}}=\\frac{1}{N}\\sum_{i=1}^N\\mathbf{y}_i\\) in each parenthesis such that we get \\(\\mathbf{S}=\\sum_{i=1}^N\\left(\\mathbf{y}_i-\\hat{\\mathbf{\\mu}}\\right)\\left(\\mathbf{y}_i-\\hat{\\mathbf{\\mu}}\\right)^{\\top}\\). We get the fourth line after using some properties of the trace operator to introduce the vectorization operator (\\(vec\\)), and collecting terms. Then \\(h(\\mathbf{y})=(2\\pi)^{-pN/2}\\), \\(\\eta(\\mathbf{\\mu},\\mathbf{\\Sigma})^{\\top}=\\left[\\left(vec\\left(\\mathbf{\\Sigma}^{-1}\\right)\\right)^{\\top} \\ \\ \\left(vec\\left(\\mathbf{\\mu}^{\\top}\\mathbf{\\Sigma}^{-1}\\right)\\right)^{\\top}\\right]\\), \\(T(\\mathbf{y})=\\left[-\\frac{1}{2}\\left(vec\\left(\\mathbf{S}\\right)^{\\top}+N vec\\left(\\hat{\\mathbf{\\mu}}\\hat{\\mathbf{\\mu}}^{\\top}\\right)^{\\top}\\right) \\ \\ -N\\hat{\\mathbf{\\mu}}^{\\top}\\right]^{\\top}\\) and \\(C(\\mathbf{\\mu},\\mathbf{\\Sigma})=\\exp\\left\\{-\\frac{1}{2}\\left(tr\\left(\\mathbf{\\mu}\\mathbf{\\mu}^{\\top}\\mathbf{\\Sigma}^{-1}\\right)+\\log(|\\Sigma|)\\right)\\right\\}\\). References "],["sec42.html", "3.2 Conjugate prior to exponential family", " 3.2 Conjugate prior to exponential family Theorem 4.2.1 The prior distribution \\(\\pi(\\mathbf{\\theta})\\propto C(\\mathbf{\\theta})^{b_0}\\exp\\left\\{\\eta(\\mathbf{\\theta})^{\\top}\\mathbf{a}_0\\right\\}\\) is conjugate to the exponential family (equation (3.4)). Proof \\[\\begin{align} \\pi(\\mathbf{\\theta}|\\mathbf{y})&amp; \\propto C(\\mathbf{\\theta})^{b_0}\\exp\\left\\{\\eta(\\mathbf{\\theta})^{\\top}\\mathbf{a}_0\\right\\} \\times h(\\mathbf{y}) C(\\mathbf{\\theta})^N\\exp\\left\\{\\eta(\\mathbf{\\theta})^{\\top}\\mathbf{T}(\\mathbf{y})\\right\\}\\\\ &amp; \\propto C(\\mathbf{\\theta})^{N+b_0} \\exp\\left\\{\\eta(\\mathbf{\\theta})^{\\top}(\\mathbf{T}(\\mathbf{y})+\\mathbf{a}_0\\right\\}. \\end{align}\\] Observe that the posterior is in the exponential family, \\(\\pi(\\mathbf{\\theta}|\\mathbf{y})\\propto C(\\mathbf{\\theta})^{\\beta_n} \\exp\\left\\{\\eta(\\mathbf{\\theta})^{\\top}\\mathbf{\\alpha}_n\\right\\}\\), \\(\\beta_n=N+b_0\\) and \\(\\mathbf{\\alpha}_n=\\mathbf{T}(\\mathbf{y})+\\mathbf{a}_0\\). Remarks We see comparing the prior and the likelihood that \\(b_0\\) plays the role of a hypothetical sample size, and \\(\\mathbf{a}_0\\) plays the role of hypothetical sufficient statistics. This view helps the elicitation process. In addition, we stablished the result in the standard form of the exponential family. We can also stablish this result in the canonical form of the exponential family. Observe that given \\(\\mathbf{\\eta}=\\mathbf{\\eta}(\\mathbf{\\theta})\\) another way to get a prior for \\(\\mathbf{\\eta}\\) is to use the change of variables theorem given a bijective function. In the setting where there is a prior regular conjugate prior (Diaconis, Ylvisaker, et al. 1979) show that we obtain a posterior expectation of the sufficient statistics that is a weighted average between the prior expectation and the likelihood estimate. Examples: Theorem 4.2.1 Likelihood functions from discrete distributions The Poisson-gamma model Given a random sample \\(\\mathbf{y}=[y_1,y_2,\\dots,y_N]^{\\top}\\) from a Poisson distribution then a conjugate prior density for \\(\\lambda\\) has the form \\[\\begin{align} \\pi(\\lambda)&amp;\\propto \\left(\\exp(-\\lambda)\\right)^{b_0} \\exp\\left\\{a_0\\log(\\lambda)\\right\\}\\\\ &amp; = \\exp(-\\lambda b_0) \\lambda^{a_0}\\\\ &amp; = \\exp(-\\lambda \\beta_0) \\lambda^{\\alpha_0-1}. \\end{align}\\] This is the kernel of a gamma density in the rate parametrization, \\(G(\\alpha_0,\\beta_0)\\), \\(\\alpha_0=a_0+1\\) and \\(\\beta_0=b_0\\). 18 Then, a prior conjugate distribution for the Poisson likelihood is a gamma distribution. Taking into account that \\(\\sum_{i=1}^N y_i\\) is a sufficient statistic for the Poisson distribution, then we can think about \\(a_0\\) as the number of occurrences in \\(b_0\\) experiments. Observe that \\[\\begin{align} \\pi(\\lambda|\\mathbf{y})&amp;\\propto \\exp(-\\lambda \\beta_0) \\lambda^{\\alpha_0-1} \\times \\exp(-N\\lambda)\\lambda^{\\sum_{i=1}^Ny_i}\\\\ &amp;= \\exp(-\\lambda(N+\\beta_0)) \\lambda^{\\sum_{i=1}^Ny_i+\\alpha_0-1}. \\end{align}\\] As expected, this is the kernel of a gamma distribution, which means \\(\\lambda|\\mathbf{y}\\sim G(\\alpha_n,\\beta_n)\\), \\(\\alpha_n=\\sum_{i=1}^Ny_i+\\alpha_0\\) and \\(\\beta_n=N+\\beta_0\\). Observe that \\(\\alpha_0/\\beta_0\\) is the prior mean, and \\(\\alpha_0/\\beta_0^2\\) is the prior variance. Then, \\(\\alpha_0\\rightarrow 0\\) and \\(\\beta_0\\rightarrow 0\\) imply a non-informative prior such that the posterior mean converges to the maximum likelihood estimator \\(\\bar{y}=\\frac{\\sum_{i=1}^N y_i}{N}\\), \\[\\begin{align} \\mathbb{E}\\left[\\lambda|\\mathbf{y}\\right]&amp;=\\frac{\\alpha_n}{\\beta_n}\\\\ &amp;=\\frac{\\sum_{i=1}^Ny_i+\\alpha_0}{N+\\beta_0}\\\\ &amp;=\\frac{N\\bar{y}}{N+\\beta_0}+\\frac{\\alpha_0}{N+\\beta_0}. \\end{align}\\] The posterior mean is a weighted average between sample and prior information. This is a general result from regular conjugate priors (Diaconis, Ylvisaker, et al. 1979). Observe that \\(\\mathbb{E}\\left[\\lambda|\\mathbf{y}\\right]=\\bar{y}, \\lim N\\rightarrow\\infty\\). In addition, \\(\\alpha_0\\rightarrow 0\\) and \\(\\beta_0\\rightarrow 0\\) corresponds to \\(\\pi(\\lambda)\\propto \\frac{1}{\\lambda}\\), which is an improper prior. Improper priors have bad consequences on Bayes factors (hypothesis testing). In this setting, we can get analytical solutions for the marginal likelihood and the predictive distribution (see the health insurance example and exercise 3 in Chapter 1). The Bernoulli-beta model Given a random sample \\(\\mathbf{y}=[y_1,y_2,\\dots,y_N]^{\\top}\\) from a Bernoulli distribution then a conjugate prior density for \\(\\theta\\) has the form \\[\\begin{align} \\pi(\\theta)&amp;\\propto (1-\\theta)^{b_0} \\exp\\left\\{a_0\\log\\left(\\frac{\\theta}{1-\\theta}\\right)\\right\\}\\\\ &amp; = (1-\\theta)^{b_0-a_0}\\theta^{a_0}\\\\ &amp; = \\theta^{\\alpha_0-1}(1-\\theta)^{\\beta_0-1}. \\end{align}\\] This is the kernel of a beta density, \\(B(\\alpha_0,\\beta_0)\\), \\(\\alpha_0=a_0+1\\) and \\(\\beta_0=b_0-a_0+1\\). A prior conjugate distribution for the Bernoulli likelihood is a beta distribution. Given that \\(b_0\\) is the hypothetical sample size, and \\(a_0\\) is the hypothetical sufficient statistic, which is the number of successes, then \\(b_0-a_0\\) is the number of failures. This implies that \\(\\alpha_0\\) is the number of prior successes plus one, and \\(\\beta_0\\) is the number of prior failures plus one. Given that the mode of a beta distribuited random variable is \\(\\frac{\\alpha_0-1}{\\alpha_0+\\beta_0-2}=\\frac{a_0}{b_0}\\), then we have the a priori probability of success. Setting \\(\\alpha_0=1\\) and \\(\\beta_0=1\\), which implies a 0-1 uniform distribution, corresponds to a setting with 0 successes (and 0 failures) in 0 experiments. Observe that \\[\\begin{align} \\pi(\\theta|\\mathbf{y})&amp;\\propto \\theta^{\\alpha_0-1}(1-\\theta)^{\\beta_0-1} \\times \\theta^{\\sum_{i=1}^N y_i}(1-\\theta)^{N-\\sum_{i=1}^Ny_i}\\\\ &amp;= \\theta^{\\alpha_0+\\sum_{i=1}^N y_i-1}(1-\\theta)^{\\beta_0+N-\\sum_{i=1}^Ny_i-1}. \\end{align}\\] The posterior distribution is beta, \\(\\theta|\\mathbf{y}\\sim B(\\alpha_n,\\beta_n)\\), \\(\\alpha_n=\\alpha_0+\\sum_{i=1}^N y_i\\) and \\(\\beta_n=\\beta_0+N-\\sum_{i=1}^Ny_i\\), where the posterior mean \\(\\mathbf{E}[\\theta|\\mathbf{y}]=\\frac{\\alpha_n}{\\alpha_n+\\beta_n}=\\frac{\\alpha_0+N\\bar{y}}{\\alpha_0+\\beta_0+N}=\\frac{\\alpha_0+\\beta_0}{\\alpha_0+\\beta_0+N}\\frac{\\alpha_0}{\\alpha_0+\\beta_0}+\\frac{N}{\\alpha_0+\\beta_0+N}\\bar{y}\\). The posterior mean is a weighted average between the prior mean and the maximum likelihood estimate. El marginal likelihood in this setting is \\[\\begin{align} p(\\mathbf{y})=&amp;\\int_{0}^1 \\frac{\\theta^{\\alpha_0-1}(1-\\theta)^{\\beta_0-1}}{B(\\alpha_0,\\beta_0)}\\times \\theta^{\\sum_{i=1}^N y_i}(1-\\theta)^{N-\\sum_{i=1}^N y_i}d\\theta\\\\ =&amp; \\frac{B(\\alpha_n,\\beta_n)}{B(\\alpha_0,\\beta_0)}, \\end{align}\\] where \\(B(\\cdot ,\\cdot)\\) is the beta function. In addition, the predictive density is \\[\\begin{align} p(Y_0|\\mathbf{y})&amp;=\\int_0^1 \\theta^{y_0}(1-\\theta)^{1-y_0}\\times \\frac{\\theta^{\\alpha_n-1}(1-\\theta)^{\\beta_n-1}}{B(\\alpha_n,\\beta_n)}d\\theta\\\\ &amp;=\\frac{B(\\alpha_n+y_0,\\beta_n+1-y_0)}{B(\\alpha_n,\\beta_n)}\\\\ &amp;=\\frac{\\Gamma(\\alpha_n+\\beta_n)\\Gamma(\\alpha_n+y_0)\\Gamma(\\beta_n+1-y_0)}{\\Gamma(\\alpha_n+\\beta_n+1)\\Gamma(\\alpha_n)\\Gamma(\\beta_n)}\\\\ &amp;=\\begin{Bmatrix} \\frac{\\alpha_n}{\\alpha_n+\\beta_n}, &amp; y_0=1\\\\ \\frac{\\beta_n}{\\alpha_n+\\beta_n}, &amp; y_0=0\\\\ \\end{Bmatrix}. \\end{align}\\] This is a Bernoulli distribution with probability of success equal to \\(\\frac{\\alpha_n}{\\alpha_n+\\beta_n}\\). The multinomial-Dirichlet model Given a random sample \\(\\mathbf{y}=[y_1,y_2,\\dots,y_N]^{\\top}\\) from a multinomial distribution then a conjugate prior density for \\(\\mathbf{\\theta}=\\left[\\theta_1,\\theta_2,\\dots,\\theta_m\\right]\\) has the form \\[\\begin{align} \\pi(\\mathbf{\\theta})&amp;\\propto \\theta_m^{b_0} \\exp\\left\\{\\mathbf{\\eta}(\\mathbf{\\theta})^{\\top}\\mathbf{a}_0\\right\\}\\\\ &amp; = \\prod_{l=1}^{m-1}\\theta_l^{a_{0l}}\\theta_m^{b_0-\\sum_{l=1}^{m-1}a_{0l}}\\\\ &amp; = \\prod_{l=1}^{m}\\theta_l^{\\alpha_{0l}-1}, \\end{align}\\] where \\(\\mathbf{\\eta}(\\mathbf{\\theta})=\\left[\\log\\left(\\frac{\\theta_1}{\\theta_m}\\right),\\dots,\\log\\left(\\frac{\\theta_{m-1}}{\\theta_m}\\right)\\right]\\), \\(\\mathbf{a}_0=\\left[a_{01},\\dots,a_{am-1}\\right]^{\\top}\\), \\(\\mathbf{\\alpha}_0=\\left[\\alpha_{01},\\alpha_{02},\\dots,\\alpha_{0m}\\right]\\), \\(\\alpha_{0l}=a_{0l}+1\\), \\(l=1,2,\\dots,m-1\\) and \\(\\alpha_{0m}=b_0-\\sum_{l=1}^{m-1} a_{0l}+1\\). This is the kernel of a Dirichlet distribution, that is, the prior distribution is \\(D(\\mathbf{\\alpha}_0)\\). Observe that \\(a_{0l}\\) is the number of hypothetical number of times outcome \\(l\\) is observed over the hypothetical \\(b_0\\) trials. Setting \\(\\alpha_{0l}=1\\), that is a uniform distribution over the open standard simplex, implicitly we set \\(a_{0l}=0\\), which means that there are 0 occurrences of category \\(l\\) in \\(b_0=0\\) experiments. The posterior distribution of the multinomial-Dirichlet model is given by \\[\\begin{align} \\pi(\\mathbf{\\theta}|\\mathbf{y})&amp;\\propto \\prod_{l=1}^m \\theta_l^{\\alpha_{0l}-1}\\times\\prod_{l=1}^m \\theta_l^{\\sum_{i=1}^{N} y_{il}}\\\\ &amp;=\\prod_{l=1}^m \\theta_l^{\\alpha_{0l}+\\sum_{i=1}^{N} y_{il}-1} \\end{align}\\] This is the kernel of a Dirichlet distribution \\(D(\\mathbf{\\alpha}_n)\\), \\(\\mathbf{\\alpha}_n=\\left[\\alpha_{n1},\\alpha_{n2},\\dots,\\alpha_{nm}\\right]\\), \\(\\alpha_{nl}=\\alpha_{0l}+\\sum_{i=1}^{N}y_{il}\\), \\(l=1,2,\\dots,m\\). Observe that \\[\\begin{align} \\mathbb{E}[\\theta_{j}|\\mathbf{y}]&amp;=\\frac{\\alpha_{nj}}{\\sum_{l=1}^m \\left[\\alpha_{0l}+\\sum_{i=1}^N y_{il}\\right]}\\\\ &amp;=\\frac{\\sum_{l=1}^m \\alpha_{0l}}{\\sum_{l=1}^m \\left[\\alpha_{0l}+\\sum_{i=1}^N y_{il}\\right]}\\frac{\\alpha_{0j}}{\\sum_{l=1}^m \\alpha_{0l}}+\\frac{\\sum_{l=1}^m\\sum_{i=1}^N y_{il}}{\\sum_{l=1}^m \\left[\\alpha_{0l}+\\sum_{i=1}^N y_{il}\\right]}\\frac{\\sum_{i=1}^N y_{ij}}{\\sum_{l=1}^m\\sum_{i=1}^N y_{il}}. \\end{align}\\] We have again that the posterior mean is a weighted average between the prior mean and the maximum likelihood estimate. The marginal likelihood is \\[\\begin{align} p(\\mathbf{y})&amp;=\\int_{\\mathbf{\\Theta}}\\frac{\\prod_{l=1}^m \\theta_l^{\\alpha_{0l}-1}}{B(\\mathbf{\\alpha}_0)}\\times \\prod_{i=1}^N\\frac{n!}{\\prod_{l=1}^m y_{il}}\\prod_{l=1}^m \\theta_{l}^{y_{il}}d\\mathbf{\\theta}\\\\ &amp;=\\frac{N\\times n!}{B(\\mathbf{\\alpha}_0)\\prod_{i=1}^N\\prod_{l=1}^m y_{il}!}\\int_{\\mathbf{\\Theta}} \\prod_{l=1}^m \\theta_l^{\\alpha_{0l}+\\sum_{i=1}^N y_{il}-1} d\\mathbf{\\theta}\\\\ &amp;=\\frac{N\\times n!}{B(\\mathbf{\\alpha}_0)\\prod_{i=1}^N\\prod_{l=1}^m y_{il}!}B(\\mathbf{\\alpha}_n)\\\\ &amp;=\\frac{N\\times n! \\Gamma\\left(\\sum_{l=1}^n \\alpha_{0l}\\right)}{\\Gamma\\left(\\sum_{l=1}^n \\alpha_{0l}+N\\times n\\right)}\\prod_{l=1}^m \\frac{\\Gamma\\left( \\alpha_{nl}\\right)}{\\Gamma\\left(\\alpha_{0l}\\right)\\prod_{i=1}^N y_{il}!}, \\end{align}\\] where \\(B(\\mathbf{\\alpha})=\\frac{\\prod_{l=1}^m\\Gamma(\\alpha_l)}{\\Gamma\\left(\\sum_{l=1}^m \\alpha_l\\right)}\\). Following similar steps we get the predictive density \\[\\begin{align} p(Y_0|\\mathbf{y})&amp;=\\frac{ n! \\Gamma\\left(\\sum_{l=1}^n \\alpha_{nl}\\right)}{\\Gamma\\left(\\sum_{l=1}^n \\alpha_{nl}+ n\\right)}\\prod_{l=1}^m \\frac{\\Gamma\\left( \\alpha_{nl}+y_{0l}\\right)}{\\Gamma\\left(\\alpha_{nl}\\right) y_{0l}!}. \\end{align}\\] This is a Dirichlet-multinomial distribution with parameters \\(\\mathbf{\\alpha}_n\\). Likelihood functions from continuous distributions The normal-normal/inverse-gamma model Given a random sample \\(\\mathbf{y}=[y_1,y_2,\\dots,y_N]^{\\top}\\) from a normal distribution, then the conjugate prior density has the form \\[\\begin{align} \\pi(\\mu,\\sigma^2)&amp;\\propto \\exp\\left\\{b_0\\left(-\\frac{\\mu^2}{2\\sigma^2}-\\frac{\\log \\sigma^2}{2}\\right)\\right\\}\\exp\\left\\{a_{01}\\frac{\\mu}{\\sigma^2}-a_{02}\\frac{1}{\\sigma^2}\\right\\}\\\\ &amp;=\\exp\\left\\{b_0\\left(-\\frac{\\mu^2}{2\\sigma^2}-\\frac{\\log \\sigma^2}{2}\\right)\\right\\}\\exp\\left\\{a_{01}\\frac{\\mu}{\\sigma^2}-a_{02}\\frac{1}{\\sigma^2}\\right\\}\\exp\\left\\{-\\frac{a_{01}^2}{2\\sigma^2b_0}\\right\\}\\exp\\left\\{\\frac{a_{01}^2}{2\\sigma^2b_0}\\right\\}\\\\ &amp;=\\exp\\left\\{-\\frac{b_0}{2\\sigma^2}\\left(\\mu-\\frac{a_{01}}{b_0}\\right)^2\\right\\}\\left(\\frac{1}{\\sigma^2}\\right)^{\\frac{b_0+1-1}{2}}\\exp\\left\\{\\frac{1}{\\sigma^2}\\frac{-2b_0a_{02}+a_{01}^2}{2b_0}\\right\\}\\\\ &amp;=\\underbrace{\\left(\\frac{1}{\\sigma^2}\\right)^{\\frac{1}{2}}\\exp\\left\\{-\\frac{b_0}{2\\sigma^2}\\left(\\mu-\\frac{a_{01}}{b_0}\\right)^2\\right\\}}_{1}\\underbrace{\\left(\\frac{1}{\\sigma^2}\\right)^{\\frac{b_0-1}{2}}\\exp\\left\\{-\\frac{1}{\\sigma^2}\\frac{2b_0a_{02}-a_{01}^2}{2b_0}\\right\\}}_{2}. \\end{align}\\] The first part is the kernel of a normal density with mean \\(\\mu_0=a_{01}/\\beta_0\\) and variance \\(\\sigma^2/\\beta_0\\), \\(\\beta_0=b_0\\) that is, \\(\\mu|\\sigma^2\\sim N(\\mu_0,\\sigma^2/\\beta_0)\\). The second part is the kernel of an inverse gamma density with shape parameter \\(\\alpha_0/2=\\frac{\\beta_0-3}{2}\\), and scale parameter \\(\\delta_0/2=\\frac{2\\beta_0a_{02}-a_{01}^2}{2\\beta_0}\\), \\(\\sigma^2\\sim IG(\\alpha_0/2,\\delta_0/2)\\). Observe that \\(b_0=\\beta_0\\) is the hypothetical sample size, and \\(a_{01}\\) is the hypothetical sum of prior observations, then, it makes sense that \\(a_{01}/\\beta_0\\) and \\(\\sigma^2/\\beta_0\\) are the prior mean and variance, respectively. Therefore, the posterior distribution is also a normal-inverse gamma distribution, \\[\\begin{align} \\pi(\\mu,\\sigma^2|\\mathbf{y})&amp;\\propto \\left(\\frac{1}{\\sigma^2}\\right)^{1/2}\\exp\\left\\{-\\frac{\\beta_0}{2\\sigma^2}(\\mu-\\mu_0)^2\\right\\}\\left(\\frac{1}{\\sigma^2}\\right)^{\\alpha_0/2+1}\\exp\\left\\{-\\frac{\\delta_0}{2\\sigma^2}\\right\\}\\\\ &amp;\\times(\\sigma^2)^{-N/2}\\exp\\left\\{-\\frac{1}{2\\sigma^2}\\sum_{i=1}^N (y_i-\\mu)^2\\right\\}\\\\ &amp; = \\left(\\frac{1}{\\sigma^2}\\right)^{1/2}\\exp\\left\\{-\\frac{1}{2\\sigma^2}\\left(\\beta_0(\\mu-\\mu_0)^2+\\sum_{i=1}^N (y_i-\\bar{y})^2+N(\\mu-\\bar{y})^2+\\delta_0\\right)\\right\\}\\\\ &amp; \\left(\\frac{1}{\\sigma^2}\\right)^{\\frac{\\alpha_0+N}{2}+1} + \\frac{(\\beta_0\\mu_0+N\\bar{y})^2}{\\beta_0+N} - \\frac{(\\beta_0\\mu_0+N\\bar{y})^2}{\\beta_0+N}\\\\ &amp; = \\underbrace{\\left(\\frac{1}{\\sigma^2}\\right)^{1/2}\\exp\\left\\{-\\frac{1}{2\\sigma^2}\\left((\\beta_0+N)\\left(\\mu-\\left(\\frac{\\beta_0\\mu_0+N\\bar{y}}{\\beta_0+N}\\right)\\right)^2\\right)\\right\\}}_{1}\\\\ &amp; \\times \\underbrace{\\left(\\frac{1}{\\sigma^2}\\right)^{\\frac{\\alpha_0+N}{2}+1}\\exp\\left\\{-\\frac{1}{2\\sigma^2}\\left(\\sum_{i=1}^N (y_i-\\bar{y})^2+\\delta_0+\\frac{\\beta_0N}{\\beta_0+N}(\\bar{y}-\\mu_0)^2\\right)\\right\\}}_{2}. \\end{align}\\] The first term is the kernel of a normal density, \\(\\mu|\\sigma^2,\\mathbf{y}\\sim N \\left(\\mu_n, \\sigma_n^2\\right)\\), where \\(\\mu_n=\\frac{\\beta_0\\mu_0+N\\bar{y}}{\\beta_0+N}\\) and \\(\\sigma_n^2=\\frac{\\sigma^2}{\\beta_n}\\), \\(\\beta_n=\\beta_0+N\\). The second term is the kernel of an inverse gamma density, \\(\\sigma^2|\\mathbf{y}\\sim IG(\\alpha_n/2,\\delta_n/2)\\) where \\(\\alpha_n=\\alpha_0+N\\) and \\(\\delta_n=\\sum_{i=1}^N (y_i-\\bar{y})^2+\\delta_0+\\frac{\\beta_0N}{\\beta_0+N}(\\bar{y}-\\mu_0)^2\\). Observe that the posterior mean is a weighted average between prior and sample information. The weights depends on the sample sizes (\\(\\beta_0\\) and \\(N\\)). The marginal posterior for \\(\\sigma^2\\) is inverse gamma with shape and scale parameters \\(\\alpha_n/2\\) and \\(\\delta_n/2\\), respectively. The marginal posterior of \\(\\mu\\) is \\[\\begin{align} \\pi(\\mu|\\mathbf{y})&amp;\\propto \\int_{0}^{\\infty}\\left\\{ \\left(\\frac{1}{\\sigma^2}\\right)^{\\frac{\\alpha_n+1}{2}+1}\\exp\\left\\{-\\frac{1}{2\\sigma^2}(\\beta_n(\\mu-\\mu_n)^2+\\delta_n)\\right\\}\\right\\}d\\sigma^2\\\\ &amp;=\\frac{\\Gamma\\left(\\frac{\\alpha_n+1}{2}\\right)}{\\left[\\frac{\\beta_n(\\mu-\\mu_n)^2+\\delta_n}{2}\\right]^{\\frac{\\alpha_n+1}{2}}}\\\\ &amp;\\propto \\left[\\frac{\\beta_n(\\mu-\\mu_n)^2+\\delta_n}{2}\\right]^{-\\frac{\\alpha_n+1}{2}}\\left(\\frac{\\delta_n}{\\delta_n}\\right)^{-\\frac{\\alpha_n+1}{2}}\\\\ &amp;\\propto \\left[\\frac{\\alpha_n\\beta_n(\\mu-\\mu_n)^2}{\\alpha_n\\delta_n}+1\\right]^{-\\frac{\\alpha_n+1}{2}}, \\end{align}\\] where the second line due to having the kernel of an inverse gamma density with parameters \\((\\alpha_n+1)/2\\) and \\(-\\frac{1}{2\\sigma^2}(\\beta_n(\\mu-\\mu_n)^2+\\delta_n)\\). This is the kernel of a Student’s t distribution, \\(\\mu|\\mathbf{y}\\sim t(\\mu_n,\\delta_n/\\beta_n\\alpha_n,\\alpha_n)\\), where \\(\\mathbb{E}[\\mu|\\mathbf{y}]=\\mu_n\\) and \\(Var[\\mu|\\mathbf{y}]=\\frac{\\alpha_n}{\\alpha_n-2}\\left(\\frac{\\delta_n}{\\beta_n\\alpha_n}\\right)=\\frac{\\delta_n}{(\\alpha_n-2)\\beta_n}\\), \\(\\alpha_n&gt;2\\). Observe that the marginal posterior distribution for \\(\\mu\\) has heavier tails than the conditional posterior distribution due to incorporating uncertainty regarding \\(\\sigma^2\\). The marginal likelihood is \\[\\begin{align} p(\\mathbf{y})&amp;=\\int_{-\\infty}^{\\infty}\\int_{0}^{\\infty}\\left\\{ (2\\pi\\sigma^2/\\beta_0)^{-1/2}\\exp\\left\\{-\\frac{1}{2\\sigma^2/\\beta_0}(\\mu-\\mu_0)^2\\right\\}\\frac{(\\delta_0/2)^{\\alpha_0/2}}{\\Gamma(\\alpha_0/2)}\\left(\\frac{1}{\\sigma^2}\\right)^{\\alpha_0/2+1}\\right.\\\\ &amp;\\times\\left.\\exp\\left\\{-\\frac{\\delta_0}{2\\sigma^2}\\right\\}(2\\pi\\sigma^2)^{-N/2}\\exp\\left\\{-\\frac{1}{2\\sigma^2}\\sum_{i=1}^N(y_i-\\mu)^2\\right\\}\\right\\}d\\sigma^2d\\mu\\\\ &amp;=\\frac{(\\delta_0/2)^{\\alpha_0/2}}{\\Gamma(\\alpha_0/2)}(2\\pi)^{-\\left(\\frac{N+1}{2}\\right)}\\beta_0^{1/2}\\int_{-\\infty}^{\\infty}\\int_{0}^{\\infty}\\left\\{\\left(\\frac{1}{\\sigma^2}\\right)^{\\frac{\\alpha_0+N+1}{2}+1}\\right.\\\\ &amp;\\times\\left.\\exp\\left\\{-\\frac{1}{2\\sigma^2}(\\beta_0(\\mu-\\mu_0)^2+\\sum_{i=1}^N (y_i-\\mu)^2+\\delta_0)\\right\\}\\right\\}d\\sigma^2d\\mu\\\\ &amp;=\\frac{(\\delta_0/2)^{\\alpha_0/2}}{\\Gamma(\\alpha_0/2)}(2\\pi)^{-\\left(\\frac{N+1}{2}\\right)}\\beta_0^{1/2}\\Gamma\\left(\\frac{N+1+\\alpha_0}{2}\\right)\\\\ &amp;\\times \\int_{-\\infty}^{\\infty} \\left[\\frac{\\beta_0(\\mu-\\mu_0)^2+\\sum_{i=1}^N(y_i-\\mu)^2+\\delta_0}{2}\\right]^{-\\frac{\\alpha_0+N+1}{2}}d\\mu\\\\ &amp;=\\frac{(\\delta_0/2)^{\\alpha_0/2}}{\\Gamma(\\alpha_0/2)}(2\\pi)^{-\\left(\\frac{N+1}{2}\\right)}\\beta_0^{1/2}\\Gamma\\left(\\frac{N+1+\\alpha_0}{2}\\right)\\\\ &amp;\\times \\int_{-\\infty}^{\\infty} \\left[\\frac{\\beta_n(\\mu-\\mu_n)^2+\\delta_n}{2}\\right]^{-\\frac{\\alpha_n+1}{2}}d\\mu\\left(\\frac{\\delta_n/2}{\\delta_n/2}\\right)^{-\\frac{\\alpha_n+1}{2}}\\\\ &amp;=\\frac{(\\delta_0/2)^{\\alpha_0/2}}{\\Gamma(\\alpha_0/2)}(2\\pi)^{-\\left(\\frac{N+1}{2}\\right)}\\beta_0^{1/2}\\Gamma\\left(\\frac{\\alpha_n+1}{2}\\right)\\left(\\frac{\\delta_n}{2}\\right)^{-\\frac{\\alpha_n+1}{2}}\\frac{\\left(\\frac{\\delta_n\\pi}{\\beta_n}\\right)^{1/2}\\Gamma\\left(\\frac{\\alpha_n}{2}\\right)}{\\Gamma\\left(\\frac{\\alpha_n+1}{2}\\right)}\\\\ &amp;=\\frac{\\Gamma\\left(\\frac{\\alpha_n}{2}\\right)}{\\Gamma\\left(\\frac{\\alpha_0}{2}\\right)}\\frac{(\\delta_0/2)^{\\alpha_0/2}}{(\\delta_n/2)^{\\alpha_n/2}}\\left(\\frac{\\beta_0}{\\beta_n}\\right)^{1/2}(\\pi)^{-N/2}, \\end{align}\\] where we take into account that \\(\\int_{-\\infty}^{\\infty} \\left[\\frac{\\beta_n(\\mu-\\mu_n)^2+\\delta_n}{2}\\right]^{-\\frac{\\alpha_n+1}{2}}d\\mu\\left(\\frac{\\delta_n/2}{\\delta_n/2}\\right)^{-\\frac{\\alpha_n+1}{2}}=\\int_{-\\infty}^{\\infty} \\left[\\frac{\\beta_n\\alpha_n(\\mu-\\mu_n)^2}{\\delta_n\\alpha_n}+1\\right]^{-\\frac{\\alpha_n+1}{2}}d\\mu\\left(\\frac{\\delta_n}{2}\\right)^{-\\frac{\\alpha_n+1}{2}}\\). The term in the integral is the kernel of a Student’s t density, this means that the integral is equal to \\(\\frac{\\left(\\frac{\\delta_n\\pi}{\\beta_n}\\right)^{1/2}\\Gamma\\left(\\frac{\\alpha_n}{2}\\right)}{\\Gamma\\left(\\frac{\\alpha_n+1}{2}\\right)}\\). The predictive density is \\[\\begin{align} \\pi(Y_0|\\mathbf{y})&amp;\\propto\\int_{-\\infty}^{\\infty}\\int_0^{\\infty}\\left\\{ \\left(\\frac{1}{\\sigma^2}\\right)^{1/2}\\exp\\left\\{-\\frac{1}{2\\sigma^2}(y_0-\\mu)^2\\right\\}\\left(\\frac{1}{\\sigma^2}\\right)^{1/2}\\exp\\left\\{-\\frac{\\beta_n}{2\\sigma^2}(\\mu-\\mu_n)^2\\right\\}\\right.\\\\ &amp;\\times \\left.\\left(\\frac{1}{\\sigma^2}\\right)^{\\alpha_n/2+1}\\exp\\left\\{-\\frac{\\delta_n}{2\\sigma^2}\\right\\}\\right\\}d\\sigma^2d\\mu\\\\ &amp;=\\int_{-\\infty}^{\\infty}\\int_0^{\\infty}\\left\\{ \\left(\\frac{1}{\\sigma^2}\\right)^{\\frac{\\alpha_n+2}{2}+1}\\exp\\left\\{-\\frac{1}{2\\sigma^2}((y_0-\\mu)^2+\\beta_n(\\mu-\\mu_n)^2+\\delta_n)\\right\\}\\right\\}d\\sigma^2d\\mu\\\\ &amp;\\propto\\int_{-\\infty}^{\\infty}\\left[\\beta_n(\\mu-\\mu_n)^2+(y_0-\\mu)^2+\\delta_n\\right]^{-\\left(\\frac{\\alpha_n}{2}+1\\right)}d\\mu\\\\ &amp;=\\int_{-\\infty}^{\\infty}\\left[(\\beta_n+1)\\left(\\mu-\\left(\\frac{\\beta_n\\mu_n+y_0}{\\beta_n+1}\\right)\\right)^2+\\frac{\\beta_n(y_0-\\mu_n)^2}{\\beta_n+1}+\\delta_n\\right]^{-\\left(\\frac{\\alpha_n}{2}+1\\right)}d\\mu\\\\ &amp;=\\int_{-\\infty}^{\\infty}\\left[1+\\frac{(\\beta_n+1)^2\\left(\\mu-\\left(\\frac{\\beta_n\\mu_n+y_0}{\\beta_n+1}\\right)\\right)^2}{\\beta_n(y_0-\\mu_n)^2+(\\beta_n+1)\\delta_n}\\right]^{-\\left(\\frac{\\alpha_n}{2}+1\\right)}d\\mu\\\\ &amp;\\times\\left(\\frac{\\beta_n(y_0-\\mu_n)^2+(\\beta_n+1)\\delta_n}{\\beta_n+1}\\right)^{-\\left(\\frac{\\alpha_n}{2}+1\\right)}\\\\ &amp;\\propto\\left(\\frac{\\beta_n(y_0-\\mu_n)^2+(\\beta_n+1)\\delta_n}{(\\beta_n+1)^2(\\alpha_n+1)}\\right)^{\\frac{1}{2}}\\left(\\frac{\\beta_n(y_0-\\mu_n)^2+(\\beta_n+1)\\delta_n}{\\beta_n+1}\\right)^{-\\left(\\frac{\\alpha_n}{2}+1\\right)}\\\\ &amp;\\propto (\\beta_n(y_0-\\mu_n)^2+(\\beta_n+1)\\delta_n)^{\\left(\\frac{\\alpha_n+1}{2}\\right)}\\\\ &amp;\\propto\\left[1+\\frac{\\beta_n\\alpha_n}{(\\beta_n+1)\\delta_n\\alpha_n}(y_0-\\mu_n)^2\\right]^{-\\left(\\frac{\\alpha_n+1}{2}\\right)}, \\end{align}\\] where we have that \\(\\left[1+\\frac{(\\beta_n+1)^2\\left(\\mu-\\left(\\frac{\\beta_n\\mu_n+y_0}{\\beta_n+1}\\right)\\right)^2}{\\beta_n(y_0-\\mu_n)^2+(\\beta_n+1)\\delta_n}\\right]^{-\\left(\\frac{\\alpha_n}{2}+1\\right)}\\) is the kernel of a Student’s t density with degrees of freedom \\(\\alpha_n+1\\) and scale \\(\\frac{\\beta_n(y_0-\\mu_n)^2+(\\beta_n+1)\\delta_n}{(\\beta_n+1)^2(\\alpha_n+1)}\\). The last expression is the kernel of a Student’s t density, that is, \\(Y_0|\\mathbf{y}\\sim t\\left(\\mu_n,\\frac{(\\beta_n+1)\\delta_n}{\\beta_n\\alpha_n},\\alpha_n\\right)\\). The multivariate normal-normal/inverse-Wishart model We show in the subsection 3.1 that the multivariate normal distribution is in the exponential family where \\(h(\\mathbf{y})=(2\\pi)^{-pN/2}\\), \\(\\eta(\\mathbf{\\mu},\\mathbf{\\Sigma})^{\\top}=\\left[\\left(vec\\left(\\mathbf{\\Sigma}^{-1}\\right)\\right)^{\\top} \\ \\ \\left(vec\\left(\\mathbf{\\mu}^{\\top}\\mathbf{\\Sigma}^{-1}\\right)\\right)^{\\top}\\right]\\), \\(T(\\mathbf{y})=\\left[-\\frac{1}{2}\\left(vec\\left(\\mathbf{S}\\right)^{\\top}+N vec\\left(\\hat{\\mathbf{\\mu}}\\hat{\\mathbf{\\mu}}^{\\top}\\right)^{\\top}\\right) \\ \\ -N\\hat{\\mathbf{\\mu}}^{\\top}\\right]^{\\top}\\) and \\(C(\\mathbf{\\mu},\\mathbf{\\Sigma})=\\exp\\left\\{-\\frac{1}{2}\\left(tr\\left(\\mathbf{\\mu}\\mathbf{\\mu}^{\\top}\\mathbf{\\Sigma}^{-1}\\right)+\\log(|\\Sigma|)\\right)\\right\\}\\). Then, its conjugate prior distribution should have the form \\[\\begin{align} \\pi(\\mathbf{\\mu},\\mathbf{\\Sigma})&amp;\\propto \\exp\\left\\{-\\frac{b_0}{2}\\left(tr\\left(\\mathbf{\\mu}\\mathbf{\\mu}^{\\top}\\mathbf{\\Sigma}^{-1}\\right)+\\log(|\\Sigma|)\\right)\\right\\}\\\\ &amp;\\times \\exp\\left\\{\\mathbf{a}_{01}^{\\top} vec\\left(\\mathbf{\\Sigma}^{-1}\\right)+\\mathbf{a}_{02}^{\\top}vec\\left(\\mathbf{\\mu}^{\\top}\\mathbf{\\Sigma}^{-1}\\right)\\right\\}\\\\ &amp;=|\\Sigma|^{-b_0/2}\\exp\\left\\{-\\frac{b_0}{2}\\left(tr\\left(\\mathbf{\\mu}^{\\top}\\mathbf{\\Sigma}^{-1}\\mathbf{\\mu}\\right)\\right)+tr\\left(\\mathbf{a}_{02}^{\\top}\\mathbf{\\Sigma}^{-1}\\mathbf{\\mu}\\right)\\right\\}\\\\ &amp;\\times \\exp\\left\\{\\mathbf{a}_{01}^{\\top} vec\\left(\\mathbf{\\Sigma}^{-1}\\right)+\\frac{\\mathbf{a}_{02}^{\\top}\\mathbf{\\Sigma}^{-1}\\mathbf{a}_{02}}{2b_0}-\\frac{\\mathbf{a}_{02}^{\\top}\\mathbf{\\Sigma}^{-1}\\mathbf{a}_{02}}{2b_0}\\right\\}\\\\ &amp;=|\\Sigma|^{-b_0/2}\\exp\\left\\{-\\frac{b_0}{2}\\left(\\mathbf{\\mu}-\\frac{\\mathbf{a}_{02}}{b_0}\\right)^{\\top}\\mathbf{\\Sigma}^{-1}\\left(\\mathbf{\\mu}-\\frac{\\mathbf{a}_{02}}{b_0}\\right)\\right\\}\\\\ &amp;\\times \\exp\\left\\{-\\frac{1}{2}tr\\left(\\left(\\mathbf{A}_{01}-\\frac{\\mathbf{a}_{02}\\mathbf{a}_{02}^{\\top}}{b_0}\\right)\\mathbf{\\Sigma}^{-1}\\right)\\right\\}\\\\ &amp;=\\underbrace{|\\Sigma|^{-1/2}\\exp\\left\\{-\\frac{b_0}{2}\\left(\\mathbf{\\mu}-\\frac{\\mathbf{a}_{02}}{b_0}\\right)^{\\top}\\mathbf{\\Sigma}^{-1}\\left(\\mathbf{\\mu}-\\frac{\\mathbf{a}_{02}}{b_0}\\right)\\right\\}}_1\\\\ &amp;\\times \\underbrace{|\\Sigma|^{-(\\alpha_0+p+1)/2}\\exp\\left\\{-\\frac{1}{2}tr\\left(\\left(\\mathbf{A}_{01}-\\frac{\\mathbf{a}_{02}\\mathbf{a}_{02}^{\\top}}{b_0}\\right)\\mathbf{\\Sigma}^{-1}\\right)\\right\\}}_2, \\end{align}\\] where \\(b_0\\) is the hypothetical sample size, and \\(\\mathbf{a}_{01}\\) and \\(\\mathbf{a}_{02}\\) are \\(p^2\\) and \\(p\\) dimensional vectors of prior sufficient statistics, and \\(\\mathbf{a}_{01}=-\\frac{1}{2}vec(\\mathbf{A}_{01})\\) such that \\(\\mathbf{A}_{01}\\) is a \\(p\\times p\\) positive semi-definite matrix. Setting \\(b_0=1+\\alpha_0+p+1\\) we have that the first part in the last expression is the kernel of a multivariate normal density with mean \\(\\mathbf{\\mu}_0=\\mathbf{a}_{02}/b_0\\) and covariance \\(\\frac{\\mathbf{\\Sigma}}{b_0}\\), that is, \\(\\mathbf{\\mu}|\\mathbf{\\Sigma}\\sim N_p\\left(\\mathbf{\\mu}_0,\\frac{\\mathbf{\\Sigma}}{\\beta_0}\\right)\\), \\(b_0=\\beta_0\\). It makes sense these hyperparameters because \\(\\mathbf{a}_{02}\\) is the hypothetical sum of prior observations and \\(b_0\\) is the hypothetical prior sample size. On the other hand, the second expression in the last line is the kernel of a Inverse-Wishart distribution with scale matrix \\(\\mathbf{\\Psi}_0=\\left(\\mathbf{A}_{01}-\\frac{\\mathbf{a}_{02}\\mathbf{a}_{02}^{\\top}}{b_0}\\right)\\) and degrees of freedom \\(\\alpha_0\\), that is, \\(\\mathbf{\\Sigma}\\sim IW_p(\\mathbf{\\Psi}_0,\\alpha_0)\\). Observe that \\(\\mathbf{\\Psi}_0\\) has the same structure as the first part of the sufficient statistics in \\(T(\\mathbf{y})\\), just that it should be understood as coming from prior hypothetical observations. Therefore, the prior distribution in this setting is normal/inverse-Wishart, and given conjugacy, the posterior distribution is in the same family. \\[\\begin{align} \\pi(\\mathbf{\\mu},\\mathbf{\\Sigma}|\\mathbf{Y})&amp;\\propto (2\\pi)^{-p N/2}|\\Sigma|^{-N/2}\\exp\\left\\{-\\frac{1}{2}tr\\left[\\left(\\mathbf{S}+N\\left(\\mathbf{\\mu}-\\hat{\\mathbf{\\mu}}\\right)\\left(\\mathbf{\\mu}-\\hat{\\mathbf{\\mu}}\\right)^{\\top}\\right)\\mathbf{\\Sigma}^{-1}\\right]\\right\\}\\\\ &amp;\\times |\\mathbf{\\Sigma}|^{-1/2}\\exp\\left\\{-\\frac{\\beta_0}{2}tr\\left[(\\mathbf{\\mu}-\\mathbf{\\mu}_0)(\\mathbf{\\mu}-\\mathbf{\\mu}_0)^{\\top}\\mathbf{\\Sigma}^{-1}\\right]\\right\\}|\\mathbf{\\Sigma}|^{-(\\alpha_0+p+1)/2}\\exp\\left\\{-\\frac{1}{2}tr(\\mathbf{\\Psi}_0\\mathbf{\\Sigma}^{-1})\\right\\}. \\end{align}\\] Taking into account that \\[\\begin{align} N\\left(\\mathbf{\\mu}-\\hat{\\mathbf{\\mu}}\\right)\\left(\\mathbf{\\mu}-\\hat{\\mathbf{\\mu}}\\right)^{\\top}+\\beta_0\\left(\\mathbf{\\mu}-\\mathbf{\\mu}_0\\right)\\left(\\mathbf{\\mu}-\\mathbf{\\mu}_0\\right)^{\\top}&amp;=(N+\\beta_0)\\left(\\mathbf{\\mu}-\\mathbf{\\mu}_n\\right)\\left(\\mathbf{\\mu}-\\mathbf{\\mu}_n\\right)^{\\top}\\\\ &amp;+\\frac{N\\beta_0}{N+\\beta_0}\\left(\\hat{\\mathbf{\\mu}}-\\mathbf{\\mu}_0\\right)\\left(\\hat{\\mathbf{\\mu}}-\\mathbf{\\mu}_0\\right)^{\\top}, \\end{align}\\] where \\(\\mathbf{\\mu}_n=\\frac{N}{N+\\beta_0}\\hat{\\mathbf{\\mu}}+\\frac{\\beta_0}{N+\\beta_0}\\mathbf{\\mu}_0\\) is the posterior mean. We have \\[\\begin{align} \\pi(\\mathbf{\\mu},\\mathbf{\\Sigma}|\\mathbf{Y})&amp;\\propto |\\Sigma|^{-1/2}\\exp\\left\\{-\\frac{N+\\beta_0}{2}tr\\left[\\left(\\left(\\mathbf{\\mu}-\\mathbf{\\mu}_n\\right)\\left(\\mathbf{\\mu}-\\mathbf{\\mu}_n\\right)^{\\top}\\right)\\mathbf{\\Sigma}^{-1}\\right]\\right\\}\\\\ &amp;\\times |\\mathbf{\\Sigma}|^{-(N+\\alpha_0+p+1)/2}\\exp\\left\\{-\\frac{1}{2}tr\\left[\\left(\\mathbf{\\Psi}_0+\\mathbf{S}+\\frac{N\\beta_0}{N+\\beta_0}(\\hat{\\mathbf{\\mu}}-\\mathbf{\\mu}_0)(\\hat{\\mathbf{\\mu}}-\\mathbf{\\mu}_0)^{\\top}\\right)\\mathbf{\\Sigma}^{-1}\\right]\\right\\}. \\end{align}\\] Then, \\(\\mathbf{\\mu}|\\mathbf{\\Sigma},\\mathbf{Y}\\sim N_p\\left(\\mathbf{\\mu}_n,\\frac{1}{\\beta_n}\\mathbf{\\Sigma}\\right)\\), and \\(\\mathbf{\\Sigma}|\\mathbf{Y}\\sim W\\left(\\alpha_n,\\mathbf{\\Psi}_n\\right)\\) where \\(\\beta_n=N+\\beta_0\\), \\(\\alpha_n=N+\\alpha_0\\) and \\(\\mathbf{\\Psi}_n=\\mathbf{\\Psi}_0+\\mathbf{S}+\\frac{N\\beta_0}{N+\\beta_0}(\\hat{\\mathbf{\\mu}}-\\mathbf{\\mu}_0)(\\hat{\\mathbf{\\mu}}-\\mathbf{\\mu}_0)^{\\top}\\). The marginal posterior of \\(\\mathbf{\\mu}\\) is given by \\(\\int_{\\mathcal{S}} \\pi(\\mathbf{\\mu},\\mathbf{\\Sigma})d\\mathbf{\\Sigma}\\) where \\(\\mathcal{S}\\) is the space of positive semi-definite matrices. Then, \\[\\begin{align} \\pi(\\mathbf{\\mu}|\\mathbf{Y})&amp;\\propto\\int_{\\mathcal{S}}\\left\\{|\\mathbf{\\Sigma}|^{-(\\alpha_n+p+2)/2} \\exp\\left\\{-\\frac{1}{2}tr\\left[\\left(\\beta_n\\left(\\mathbf{\\mu}-\\mathbf{\\mu}_n\\right)\\left(\\mathbf{\\mu}-\\mathbf{\\mu}_n\\right)^{\\top}+\\mathbf{\\Psi}_n\\right)\\mathbf{\\Sigma}^{-1}\\right]\\right\\} \\right\\}d\\mathbf{\\Sigma}\\\\ &amp;\\propto \\big\\lvert\\left(\\beta_n\\left(\\mathbf{\\mu}-\\mathbf{\\mu}_n\\right)\\left(\\mathbf{\\mu}-\\mathbf{\\mu}_n\\right)^{\\top}+\\mathbf{\\Psi}_n\\right)\\big\\lvert^{-(\\alpha_n+1)/2}\\\\ &amp;=\\left[\\big\\lvert\\mathbf{\\Psi}_n\\big\\lvert\\times \\big\\lvert1+\\beta_n\\left(\\mathbf{\\mu}-\\mathbf{\\mu}_n\\right)^{\\top}\\mathbf{\\Psi}_n^{-1}\\left(\\mathbf{\\mu}-\\mathbf{\\mu}_n\\right)\\big\\lvert\\right]^{-(\\alpha_n+1)/2}\\\\ &amp;\\propto \\left(1+\\frac{1}{\\alpha_n+1-p}\\left(\\mathbf{\\mu}-\\mathbf{\\mu}_n\\right)^{\\top}\\left(\\frac{\\mathbf{\\Psi}_n}{(\\alpha_n+1-p)\\beta_n}\\right)^{-1}\\left(\\mathbf{\\mu}-\\mathbf{\\mu}_n\\right)\\right)^{-(\\alpha_n+1-p+p)/2}, \\end{align}\\] where the second line uses properties of the inverse Wishart distribution, and the third line uses a particular case of the Sylvester’s determinant theorem. We observe that the last line is the kernel of a Multivariate Student’s t distribution, that is, \\(\\mathbf{\\mu}|\\mathbf{Y}\\sim t_p(v_n,\\mathbf{\\mu}_n,\\mathbf{\\Sigma}_n)\\) where \\(v_n=\\alpha_n+1-p\\) and \\(\\mathbf{\\Sigma}_n=\\frac{\\mathbf{\\Psi}_n}{(\\alpha_n+1-p)\\beta_n}\\). The marginal likelihood is given by \\[\\begin{align} p(\\mathbf{Y})=\\frac{\\Gamma_p\\left(\\frac{\\alpha_n}{2}\\right)}{\\Gamma_p\\left(\\frac{\\alpha_0}{2}\\right)}\\frac{|\\mathbf{\\Psi}_0|^{\\alpha_0/2}}{|\\mathbf{\\Psi}_n|^{\\alpha_n/2}}\\left(\\frac{\\beta_0}{\\beta_n}\\right)^{p/2}(2\\pi)^{-Np/2}, \\end{align}\\] where \\(\\Gamma_p\\) is the multivariate gamma function (see Exercise 4). The posterior predictive distribution is \\(\\mathbf{Y}_0|\\mathbf{Y}\\sim t_p(v_n,\\mathbf{\\mu}_n,(\\beta_n+1)\\mathbf{\\Sigma}_n)\\) (see Exercise 5). References "],["sec43.html", "3.3 Linear regression: The conjugate normal-normal/inverse gamma model", " 3.3 Linear regression: The conjugate normal-normal/inverse gamma model In this setting we analyze the conjugate normal-normal/inverse gamma model which is the workhorse in econometrics. In this model, the dependent variable \\(y_i\\) is related to a set of regressors \\({\\mathbf{x}}_i=(x_{i1},x_{i2},\\ldots,x_{iK})^{\\top}\\) in a linear way, that is, \\(y_i=\\beta_1x_{i1}+\\beta_2x_{i2}+\\ldots+\\beta_Kx_{iK}+\\mu_i={\\bf{x}}_i^{\\top}\\beta+\\mu_i\\) where \\(\\mathbf{\\beta}=(\\beta_1,\\beta_2,\\ldots,\\beta_K)^{\\top}\\) and \\(\\mu_i\\stackrel{iid} {\\thicksim}N(0,\\sigma^2)\\) is an stochastic error that is independent of the regressors, \\({\\bf{x}}_i\\perp\\mu_i\\). Defining \\(\\mathbf{y}=\\begin{bmatrix} y_1\\\\ y_2\\\\ \\vdots \\\\ y_N \\end{bmatrix}\\), \\(\\mathbf{X}=\\begin{bmatrix} x_{11} &amp; x_{12} &amp; \\ldots &amp; x_{1K}\\\\ x_{21} &amp; x_{22} &amp; \\ldots &amp; x_{2K}\\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots\\\\ x_{N1} &amp; x_{N2} &amp; \\ldots &amp; x_{NK}\\\\ \\end{bmatrix}\\) and \\(\\mathbf{\\mu}=\\begin{bmatrix} \\mu_1\\\\ \\mu_2\\\\ \\vdots \\\\ \\mu_N \\end{bmatrix}\\), we can write the model in matrix form: \\({\\bf{y}}={\\bf{X}}\\beta+\\mu\\), where \\(\\mu\\sim N(\\bf{0},\\sigma^2{\\bf{I}})\\) which implies that \\({\\bf{y}}\\sim N({\\bf{X}}\\beta,\\sigma^2\\bf{I})\\). Then, the likelihood function is \\[\\begin{align} p({\\bf{y}}|\\beta, \\sigma^2, {{\\bf{X}}}) &amp; = (2\\pi\\sigma^2)^{-\\frac{N}{2}} \\exp \\left\\{-\\frac{1}{2\\sigma^2} ({\\bf{y}} - {\\bf{X}}\\beta)^{\\top}({\\bf{y}} - {\\bf{X}}\\beta) \\right\\} \\\\ &amp; \\propto (\\sigma^2)^{-\\frac{N}{2}} \\exp \\left\\{-\\frac{1}{2\\sigma^2} ({\\bf{y}} - {\\bf{X}}\\beta)^{\\top}({\\bf{y}} - {\\bf{X}}\\beta) \\right\\}. \\end{align}\\] The conjugate priors for the parameters are \\[\\begin{align} \\beta|\\sigma^2 &amp; \\sim N(\\beta_0, \\sigma^2 {\\bf{B}}_0),\\\\ \\sigma^2 &amp; \\sim IG(\\alpha_0/2, \\delta_0/2). \\end{align}\\] Then, the posterior distribution is \\[\\begin{align} \\pi(\\beta,\\sigma^2|\\mathbf{y},\\mathbf{X})&amp;\\propto (\\sigma^2)^{-\\frac{N}{2}} \\exp \\left\\{-\\frac{1}{2\\sigma^2} ({\\bf{y}} - {\\bf{X}}\\beta)^{\\top}({\\bf{y}} - {\\bf{X}}\\beta) \\right\\} \\\\ &amp; \\times (\\sigma^2)^{-\\frac{K}{2}} \\exp \\left\\{-\\frac{1}{2\\sigma^2} (\\beta - \\beta_0)^{\\top}{\\bf{B}}_0^{-1}(\\beta - \\beta_0)\\right\\} \\\\ &amp; \\times \\frac{(\\delta_0/2)^{\\alpha_0/2}}{\\Gamma(\\alpha_0/2)}\\left(\\frac{1}{\\sigma^2}\\right)^{\\alpha_0/2+1}\\exp \\left\\{-\\frac{\\delta_0}{2\\sigma^2} \\right\\} \\\\ &amp; \\propto (\\sigma^2)^{-\\frac{K}{2}} \\exp \\left\\{-\\frac{1}{2\\sigma^2} [\\beta^{\\top}({\\bf{B}}_0^{-1} + {\\bf{X}}^{\\top}{\\bf{X}})\\beta - 2\\beta^{\\top}({\\bf{B}}_0^{-1}\\beta_0 + {\\bf{X}}^{\\top}{\\bf{X}}\\hat{\\beta})] \\right\\} \\\\ &amp; \\times \\left(\\frac{1}{\\sigma^2}\\right)^{(\\alpha_0+N)/2+1}\\exp \\left\\{-\\frac{\\delta_0+ {\\bf{y}}^{\\top}{\\bf{y}} + \\beta_0^{\\top}{\\bf{B}}_0^{-1}\\beta_0}{2\\sigma^2} \\right\\}, \\end{align}\\] where \\(\\hat{\\beta}=({\\bf{X}}^{\\top}{\\bf{X}})^{-1}{\\bf{X}}^{\\top}{\\bf{y}}\\) is the maximum likelihood estimator. Adding and subtracting \\(\\beta_n^{\\top}{{\\bf{B}}}_n^{-1} \\beta_n\\) to complete the square, where \\({{\\bf{B}}}_n = ({\\bf{B}}_0^{-1} + {\\bf{X}}^{\\top}{\\bf{X}})^{-1}\\) and \\(\\beta_n = {{\\bf{B}}}_n({\\bf{B}}_0^{-1}\\beta_0 + {\\bf{X}}^{\\top}{\\bf{X}}\\hat{\\beta})\\), \\[\\begin{align} \\pi(\\beta,\\sigma^2|\\mathbf{y},\\mathbf{X})&amp;\\propto \\underbrace{(\\sigma^2)^{-\\frac{K}{2}} \\exp \\left\\{-\\frac{1}{2\\sigma^2} (\\beta-\\beta_n)^{\\top}{\\bf{B}}^{-1}_n(\\beta-\\beta_n) \\right\\}}_1 \\\\ &amp; \\times \\underbrace{(\\sigma^2)^{-\\left(\\frac{\\alpha_n}{2}+1 \\right)} \\exp \\left\\{-\\frac{\\delta_n}{2\\sigma^2} \\right\\}}_2. \\end{align}\\] The first expression is the kernel of a normal density function, \\(\\beta|\\sigma^2, {\\bf{y}}, {\\bf{X}} \\sim N(\\beta_n, \\sigma^2{\\bf{B}}_n)\\). The second expression is the kernel of a inverse gamma density, \\(\\sigma^2| {\\bf{y}}, {\\bf{X}}\\sim IG(\\alpha_n/2, \\delta_n/2)\\), where \\(\\alpha_n = \\alpha_0 + N\\) and \\(\\delta_n = \\delta_0 + {\\bf{y}}^{\\top}{\\bf{y}} + \\beta_0^{\\top}{\\bf{B}}_0^{-1}\\beta_0 - \\beta_n^{\\top}{\\bf{B}}_n^{-1}\\beta_n\\). Taking into account that \\[\\begin{align}\\beta_n &amp; = ({\\bf{B}}_0^{-1} + {\\bf{X}}^{\\top}{\\bf{X}})^{-1}({\\bf{B}}_0^{-1}\\beta_0 + {\\bf{X}}^{\\top}{\\bf{X}}\\hat{\\beta})\\\\ &amp; = ({\\bf{B}}_0^{-1} + {\\bf{X}}^{\\top}{\\bf{X}})^{-1}{\\bf{B}}_0^{-1}\\beta_0 + ({\\bf{B}}_0^{-1} + {\\bf{X}}^{\\top}{\\bf{X}})^{-1} {\\bf{X}}^{\\top}{\\bf{X}}\\hat{\\beta}, \\end{align}\\] where \\(({\\bf{B}}_0^{-1} + {\\bf{X}}^{\\top}{\\bf{X}})^{-1}{\\bf{B}}_0^{-1}=\\bf{I}_K-({\\bf{B}}_0^{-1} + {\\bf{X}}^{\\top}{\\bf{X}})^{-1}{\\bf{X}}^{\\top}{\\bf{X}}\\) (A. F. M. Smith 1973). Setting \\({\\bf{W}}=({\\bf{B}}_0^{-1} + {\\bf{X}}^{\\top}{\\bf{X}})^{-1}{\\bf{X}}^{\\top}{\\bf{X}}\\) we have \\(\\beta_n=(\\bf{I}_K-{\\bf{W}})\\beta_0+{\\bf{W}}\\hat{\\beta}\\), that is, the posterior mean of \\(\\beta\\) is a weighted average between the sample and prior information, where the weights depend on the precision of each piece of information. Observe that when the prior covariance matrix is highly vague (non–informative), such that \\({\\bf{B}}_0^{-1}\\rightarrow \\bf{0}_K\\), we obtain \\({\\bf{W}} \\rightarrow I_K\\), such that \\(\\beta_n \\rightarrow \\hat{\\beta}\\), that is, the posterior mean location parameter converges to the maximum likelihood estimator. In addition, we know that the posterior conditional covariance matrix of the location parameters \\(\\sigma^2({\\bf{B}}_0^{-1} + {\\bf{X}}^{\\top}{\\bf{X}})^{-1}=\\sigma^2({\\bf{X}}^{\\top}{\\bf{X}})^{-1}-\\sigma^2\\left(({\\bf{X}}^{\\top}{\\bf{X}})^{-1}({\\bf{B}}_0 + ({\\bf{X}}^{\\top}{\\bf{X}})^{-1})^{-1}({\\bf{X}}^{\\top}{\\bf{X}})^{-1}\\right)\\) is positive semi-definite.19 Given that \\(\\sigma^2({\\bf{X}}^{\\top}{\\bf{X}})^{-1}\\) is the covariance matrix of the maximum likelihood estimator, we observe that prior information reduces estimation uncertainty. Now, we calculate the posterior marginal distribution of \\(\\beta\\), \\[\\begin{align} \\pi(\\beta|{\\bf{y}},{\\bf{X}}) &amp; = \\int_0^{\\infty} \\pi(\\beta, \\sigma^2|{\\bf{y}},{\\bf{X}}) d\\sigma^2 \\\\ &amp; = \\int_0^{\\infty} \\left(\\frac{1}{\\sigma^2}\\right)^{\\frac{\\alpha_n+K}{2} + 1} \\exp \\left\\{-\\frac{s}{2\\sigma^2}\\right\\} d\\sigma^2, \\end{align}\\] where \\(s = \\delta_n + (\\beta - \\beta_n)^{\\top}{{\\bf{B}}}_n^{-1}(\\beta - \\beta_n)\\). Then we can write \\[\\begin{align} \\pi(\\beta|{\\bf{y}},{\\bf{X}}) &amp; = \\int_0^{\\infty} \\left(\\frac{1}{\\sigma^2}\\right)^{\\frac{\\alpha_n+K}{2} + 1} \\exp \\left\\{-\\frac{s}{2\\sigma^2}\\right\\} d\\sigma^2 \\\\ &amp; = \\frac{\\Gamma((\\alpha_n+K)/2)}{(s/2)^{(\\alpha_n+K)/2}} \\int_0^{\\infty} \\frac{(s/2)^{(\\alpha_n+K)/2}}{\\Gamma((\\alpha_n+K)/2)} (\\sigma^2)^{-(\\alpha_n+K)/2 - 1} \\exp \\left\\{-\\frac{s}{2\\sigma^2}\\right\\} d\\sigma^2. \\end{align}\\] The right term is the integral of the probability density function of an inverse gamma distribution with parameters \\(\\nu = (\\alpha_n+K)/2\\) and \\(\\tau = s/2\\). Since we are integrating over the whole support of \\(\\sigma^2\\), the integral is equal to 1, and therefore \\[\\begin{align*} \\pi(\\beta|{\\bf{y}},{\\bf{X}}) &amp; = \\frac{\\Gamma((\\alpha_n+K)/2)}{(s/2)^{(\\alpha_n+K)/2}} \\\\ &amp; \\propto s^{-(\\alpha_n+K)/2} \\\\ &amp; = [\\delta_n + (\\beta - \\beta_n)^{\\top}{{\\bf{B}}}_n^{-1}(\\beta - \\beta_n)]^{-(\\alpha_n+K)/2} \\\\ &amp; = \\left[1 + \\frac{(\\beta - \\beta_n)^{\\top}\\left(\\frac{\\delta_n}{\\alpha_n}{{\\bf{B}}}_n\\right)^{-1}(\\beta - \\beta_n)}{\\alpha_n}\\right]^{-(\\alpha_n+K)/2}(\\delta_n)^{-(\\alpha_N+K)/2} \\\\ &amp; \\propto \\left[1 + \\frac{(\\beta - \\beta_n)^{\\top}{\\bf{H}}_n^{-1}(\\beta - \\beta_n)}{\\alpha_n}\\right]^{-(\\alpha_n+K)/2}, \\end{align*}\\] where \\({\\bf{H}}_n = \\frac{\\delta_n}{\\alpha_n}{\\bf{B}}_n\\). This last expression is a multivariate Student’s \\(t\\) distribution for \\(\\beta\\), \\(\\beta|{\\bf{y}},{\\bf{X}} \\sim t_K(\\alpha_n, \\beta_n, {\\bf{H}}_n)\\). Observe that as we have incorporated the uncertainty of the variance, the posterior for \\(\\beta\\) changes from a normal to a Students’ t distribution, which has heavier tails. The marginal likelihood of this model is \\[\\begin{align} p({\\bf{y}})=\\int_0^{\\infty}\\int_{R^K}\\pi (\\beta | \\sigma^2,{\\bf{B}}_0,\\beta_0 )\\pi(\\sigma^2| \\alpha_0/2, \\delta_0/2)p({\\bf{y}}|\\beta, \\sigma^2, {\\bf{X}})d\\sigma^2 d\\beta. \\end{align}\\] Taking into account that \\(({\\bf{y}}-{\\bf{X}}\\beta)^{\\top}({\\bf{y}}-{\\bf{X}}\\beta)+(\\beta-\\beta_0)^{\\top}{\\bf{B}}_0^{-1}(\\beta-\\beta_0)=(\\beta-\\beta_n)^{\\top}{\\bf{B}}_n^{-1}(\\beta-\\beta_n)+m\\), where \\(m={\\bf{y}}^{\\top}{\\bf{y}}+\\beta_0^{\\top}{\\bf{B}}_0^{-1}\\beta_0-\\beta_n^{\\top}{\\bf{B}}_n^{-1}\\beta_n\\), we have that \\[\\begin{align} p({\\bf{y}})&amp;=\\int_0^{\\infty}\\int_{R^K}\\pi (\\beta | \\sigma^2)\\pi(\\sigma^2)p({\\bf{y}}|\\beta, \\sigma^2, {\\bf{X}})d\\sigma^2 d\\beta\\\\ &amp;=\\int_0^{\\infty}\\pi(\\sigma^2) \\frac{1}{(2\\pi\\sigma^2)^{N/2}}\\exp\\left\\{-\\frac{1}{2\\sigma^2}m \\right\\} \\frac{1}{(2\\pi\\sigma^2)^{K/2}|{\\bf{B}}_0|^{1/2}}\\\\ &amp;\\times\\int_{R^K}\\exp\\left\\{-\\frac{1}{2\\sigma^2}(\\beta-\\beta_n)^{\\top}{\\bf{B}}_n^{-1}(\\beta-\\beta_n)\\right\\}d\\sigma^2 d\\beta\\\\ &amp;=\\int_0^{\\infty}\\pi(\\sigma^2) \\frac{1}{(2\\pi\\sigma^2)^{N/2}}\\exp\\left\\{-\\frac{1}{2\\sigma^2}m \\right\\} \\frac{|{\\bf{B}}_n|^{1/2}}{|{\\bf{B}}_0|^{1/2}}d\\sigma^2\\\\ &amp;=\\int_{0}^{\\infty} \\frac{(\\delta_0/2)^{\\alpha_0/2}}{\\Gamma(\\alpha_0/2)}\\left(\\frac{1}{\\sigma^2}\\right)^{\\alpha_0/2+1}\\exp\\left\\{\\left(-\\frac{\\delta_0}{2\\sigma^2}\\right)\\right\\} \\frac{1}{(2\\pi\\sigma^2)^{N/2}}\\exp\\left\\{-\\frac{1}{2\\sigma^2}m \\right\\} \\frac{|{\\bf{B}}_n|^{1/2}}{|{\\bf{B}}_0|^{1/2}} d\\sigma^2\\\\ &amp;= \\frac{1}{(2\\pi)^{N/2}}\\frac{(\\delta_0/2)^{\\alpha_0/2}}{\\Gamma(\\alpha_0/2)}\\frac{|{\\bf{B}}_n|^{1/2}}{|{\\bf{B}}_0|^{1/2}}\\int_{0}^{\\infty}\\left(\\frac{1}{\\sigma^2}\\right)^{\\frac{\\alpha_0+N}{2}+1}\\exp\\left\\{\\left(-\\frac{\\delta_0+m}{2\\sigma^2}\\right)\\right\\}d\\sigma^2\\\\ &amp;= \\frac{1}{\\pi^{N/2}}\\frac{\\delta_0^{\\alpha_0/2}}{\\delta_n^{\\alpha_n/2}}\\frac{|{\\bf{B}}_n|^{1/2}}{|{\\bf{B}}_0|^{1/2}}\\frac{\\Gamma(\\alpha_n/2)}{\\Gamma(\\alpha_0/2)}. \\end{align}\\] The posterior predictive is equal to \\[\\begin{align} \\pi({\\bf{Y}}_0|{\\bf{y}})&amp;=\\int_{0}^{\\infty}\\int_{R^K}p({\\bf{Y}}_0|\\beta,\\sigma^2,{\\bf{y}})\\pi(\\beta|\\sigma^2,{\\bf{y}})\\pi(\\sigma^2|{\\bf{y}})d\\beta d\\sigma^2\\\\ &amp;=\\int_{0}^{\\infty}\\int_{R^K}p({\\bf{Y}}_0|\\beta,\\sigma^2)\\pi(\\beta|\\sigma^2,{\\bf{y}})\\pi(\\sigma^2|{\\bf{y}})d\\beta d\\sigma^2, \\end{align}\\] where we take into account independence between \\({\\bf{Y}}_0\\) and \\({\\bf{Y}}\\). Given \\({\\bf{X}}_0\\), which is the \\(N_0\\times K\\) matrix of regressors associated with \\({\\bf{Y}}_0\\), Then, \\[\\begin{align} \\pi({\\bf{Y}}_0|{\\bf{y}})&amp;=\\int_{0}^{\\infty}\\int_{R^K}\\left\\{ (2\\pi\\sigma^2)^{-\\frac{N_0}{2}} \\exp \\left\\{-\\frac{1}{2\\sigma^2} ({\\bf{Y}}_0 - {\\bf{X}}_0\\beta)^{\\top}({\\bf{Y}}_0 - {\\bf{X}}_0\\beta)^{\\top} \\right\\}\\right. \\\\ &amp; \\times (2\\pi\\sigma^2)^{-\\frac{K}{2}} |{\\bf{B}}_n|^{-1/2} \\exp \\left\\{-\\frac{1}{2\\sigma^2} (\\beta - \\beta_n)^{\\top}{\\bf{B}}_n^{-1}(\\beta - \\beta_n)\\right\\} \\\\ &amp; \\left. \\times \\frac{(\\delta_n/2)^{\\alpha_n/2}}{\\Gamma(\\alpha_n/2)}\\left(\\frac{1}{\\sigma^2}\\right)^{\\alpha_n/2+1}\\exp \\left\\{-\\frac{\\delta_n}{2\\sigma^2} \\right\\}\\right\\}d\\beta d\\sigma^2. \\\\ \\end{align}\\] Setting \\({\\bf{M}}=({\\bf{X}}_0^{\\top}{\\bf{X}}_0+{\\bf{B}}_n^{-1})\\) and \\(\\beta_*={\\bf{M}}^{-1}({\\bf{B}}_n^{-1}\\beta_n+{\\bf{X}}_0^{\\top}{\\bf{Y}}_0)\\), we have \\[\\begin{align} ({\\bf{Y}}_0 - {\\bf{X}}_0\\beta)^{\\top}({\\bf{Y}}_0 - {\\bf{X}}_0\\beta)^{\\top}+(\\beta - \\beta_n)^{\\top}{\\bf{B}}_n^{-1}(\\beta - \\beta_n)&amp;=(\\beta - \\beta_*)^{\\top}{\\bf{M}}(\\beta - \\beta_*)\\\\ &amp;+\\beta_n^{\\top}{\\bf{B}}_n^{-1}\\beta_n+{\\bf{Y}}_0^{\\top}{\\bf{Y}}_0-\\beta_*^{\\top}{\\bf{M}}\\beta_*, \\end{align}\\] Thus, \\[\\begin{align} \\pi({\\bf{Y}}_0|{\\bf{y}})&amp;\\propto\\int_{0}^{\\infty}\\left\\{\\left(\\frac{1}{\\sigma^2}\\right)^{-\\frac{K+N_0+\\alpha_n}{2}+1}\\exp\\left\\{-\\frac{1}{2\\sigma^2}(\\beta_n^{\\top}{\\bf{B}}_n^{-1}\\beta_n+{\\bf{Y}}_0^{\\top}{\\bf{Y}}_0-\\beta_*^{\\top}{\\bf{M}}\\beta_*+\\delta_n)\\right\\}\\right.\\\\ &amp;\\times\\left.\\int_{R^K}\\exp\\left\\{-\\frac{1}{2\\sigma^2}(\\beta - \\beta_*)^{\\top}{\\bf{M}}(\\beta - \\beta_*)\\right\\}d\\beta\\right\\} d\\sigma^2,\\\\ \\end{align}\\] where the term in the second integral is the kernel of a multivariate normal density with mean \\(\\beta_*\\) and covariance matrix \\(\\sigma^2{\\bf{M}}^{-1}\\). Then, \\[\\begin{align} \\pi({\\bf{Y}}_0|{\\bf{y}})&amp;\\propto\\int_{0}^{\\infty}\\left(\\frac{1}{\\sigma^2}\\right)^{\\frac{N_0+\\alpha_n}{2}+1}\\exp\\left\\{-\\frac{1}{2\\sigma^2}(\\beta_n^{\\top}{\\bf{B}}_n^{-1}\\beta_n+{\\bf{Y}}_0^{\\top}{\\bf{Y}}_0-\\beta_*^{\\top}{\\bf{M}}\\beta_*+\\delta_n)\\right\\}d\\sigma^2,\\\\ \\end{align}\\] which is the kernel of an inverse gamma density. Thus, \\[\\begin{align} \\pi({\\bf{Y}}_0|{\\bf{y}})&amp;\\propto \\left[\\frac{\\beta_n^{\\top}{\\bf{B}}_n^{-1}\\beta_n+{\\bf{Y}}_0^{\\top}{\\bf{Y}}_0-\\beta_*^{\\top}{\\bf{M}}\\beta_*+\\delta_n}{2}\\right]^{-\\frac{\\alpha_n+N_0}{2}}. \\end{align}\\] Setting \\({\\bf{C}}^{-1}={\\bf{I}}_{N_0}+{\\bf{X}}_0{\\bf{B}}_n{\\bf{X}}_0^{\\top}\\) such that \\({\\bf{C}}={\\bf{I}}_{N_0}-{\\bf{X}}_0({\\bf{B}}_n^{-1}+{\\bf{X}}_0^{\\top}{\\bf{X}}_0)^{-1}{\\bf{X}}_0^{\\top}={\\bf{I}}_{N_0}-{\\bf{X}}_0{\\bf{M}}^{-1}{\\bf{X}}_0^{\\top}\\),20 and \\({\\bf{\\beta}}_{**}={\\bf{C}}^{-1}{\\bf{X}}_0{\\bf{M}}^{-1}{\\bf{B}}_n^{-1}\\beta_n\\), then \\[\\begin{align} \\beta_n^{\\top}{\\bf{B}}_n^{-1}\\beta_n+{\\bf{Y}}_0^{\\top}{\\bf{Y}}_0-\\beta_*^{\\top}{\\bf{M}}\\beta_*&amp;= \\beta_n^{\\top}{\\bf{B}}_n^{-1}\\beta_n+{\\bf{Y}}_0^{\\top}{\\bf{Y}}_0-(\\beta_n^{\\top}{\\bf{B}}_n^{-1}+{\\bf{Y}}_0^{\\top}{\\bf{X}}_0){\\bf{M}}^{-1}({\\bf{B}}_n^{-1}\\beta_n+{\\bf{X}}_0^{\\top}{\\bf{Y}}_0)\\\\ &amp;=\\beta_n^{\\top}({\\bf{B}}_n^{-1}-{\\bf{B}}_n^{-1}{\\bf{M}}^{-1}{\\bf{B}}_n^{-1})\\beta_n+{\\bf{Y}}_0^{\\top}{\\bf{C}}{\\bf{Y}}_0\\\\ &amp;-2{\\bf{Y}}_0^{\\top}{\\bf{C}}{\\bf{C}}^{-1}{\\bf{X}}_0{\\bf{M}}^{-1}{\\bf{B}}_n^{-1}\\beta_n+{\\bf{\\beta}}_{**}^{\\top}{\\bf{C}}{\\bf{\\beta}}_{**}-{\\bf{\\beta}}_{**}^{\\top}{\\bf{C}}{\\bf{\\beta}}_{**}\\\\ &amp;=\\beta_n^{\\top}({\\bf{B}}_n^{-1}-{\\bf{B}}_n^{-1}{\\bf{M}}^{-1}{\\bf{B}}_n^{-1})\\beta_n+({\\bf{Y}}_0-{\\bf{\\beta}}_{**})^{\\top}{\\bf{C}}({\\bf{Y}}_0-{\\bf{\\beta}}_{**})\\\\ &amp;-{\\bf{\\beta}}_{**}^{\\top}{\\bf{C}}{\\bf{\\beta}}_{**}, \\end{align}\\] where \\(\\beta_n^{\\top}({\\bf{B}}_n^{-1}-{\\bf{B}}_n^{-1}{\\bf{M}}^{-1}{\\bf{B}}_n^{-1})\\beta_n={\\bf{\\beta}}_{**}^{\\top}{\\bf{C}}{\\bf{\\beta}}_{**}\\) and \\(\\beta_{**}={\\mathbf{X}}_0\\beta_n\\) (see Exercise 6). Then, \\[\\begin{align} \\pi({\\bf{Y}}_0|{\\bf{y}})&amp;\\propto\\left[\\frac{({\\bf{Y}}_0-{\\mathbf{X}}_0\\beta_n)^{\\top}{\\bf{C}}({\\bf{Y}}_0-{\\mathbf{X}}_0\\beta_n)+\\delta_n}{2}\\right]^{-\\frac{\\alpha_n+N_0}{2}}\\\\ &amp;\\propto\\left[\\frac{({\\bf{Y}}_0-{\\mathbf{X}}_0\\beta_n)^{\\top}\\left(\\frac{{\\bf{C}}\\alpha_n}{\\delta_n}\\right)({\\bf{Y}}_0-{\\mathbf{X}}_0\\beta_n)}{\\alpha_n}+1\\right]^{-\\frac{\\alpha_n+N_0}{2}}. \\end{align}\\] Then, the posterior predictive is a multivariate Student’s t, \\({\\bf{Y}}_0|{\\bf{y}}\\sim t\\left({\\bf{X}}_0\\beta_n,\\frac{\\delta_n({\\bf{I}}_{N_0}+{\\bf{X}}_0{\\bf{B}}_n{\\bf{X}}_0^{\\top})}{\\alpha_n},\\alpha_n\\right)\\). References "],["sec44.html", "3.4 Multivariate linear regression: The conjugate normal-normal/inverse Wishart model", " 3.4 Multivariate linear regression: The conjugate normal-normal/inverse Wishart model Let’s study the multivariate regression setting where there are \\(M\\) \\(N\\)-dimensional vectors \\({\\bf{y}}_m\\), \\(m=1,2,\\dots,M\\) such that \\({\\bf{y}}_m={\\bf{X}}\\beta_m+\\mu_m\\), \\({\\bf{X}}\\) is the set of common regressors, and \\(\\mu_m\\) is the \\(N\\)-dimensional vector of stochastic errors for each equation such that \\({\\bf{U}}=[\\mu_1 \\ \\mu_2 \\ \\dots \\ \\mu_M]\\sim MN_{N,M}({\\bf{0}}, {\\bf{I}}_N, {\\bf\\Sigma})\\), that is, a matrix variate normal distribution where \\(\\bf\\Sigma\\) is the covariance matrix of each \\(i\\)-th row of \\({\\bf{U}}\\), \\(i=1,2,\\dots,N\\), and we are assuming independece between the rows. Then, \\(vec({\\bf U})\\sim N_{N\\times M}({\\bf 0}, \\bf{\\Sigma}\\otimes {\\bf{I}}_N)\\).21 This framework can be written in matricial form \\[\\begin{align} \\underbrace{ \\begin{bmatrix} y_{11} &amp; y_{12} &amp; \\dots &amp; y_{1M}\\\\ y_{21} &amp; y_{22} &amp; \\dots &amp; y_{2M}\\\\ \\vdots &amp; \\vdots &amp; \\dots &amp; \\vdots\\\\ y_{N1} &amp; y_{N2} &amp; \\dots &amp; y_{NM}\\\\ \\end{bmatrix}}_{\\bf{Y}} &amp;= \\underbrace{\\begin{bmatrix} x_{11} &amp; x_{12} &amp; \\dots &amp; x_{1K}\\\\ x_{21} &amp; x_{22} &amp; \\dots &amp; x_{2K}\\\\ \\vdots &amp; \\vdots &amp; \\dots &amp; \\vdots\\\\ x_{N1} &amp; x_{N2} &amp; \\dots &amp; x_{NK}\\\\ \\end{bmatrix}}_{\\bf{X}} \\underbrace{ \\begin{bmatrix} \\beta_{11} &amp; \\beta_{12} &amp; \\dots &amp; \\beta_{1M}\\\\ \\beta_{21} &amp; \\beta_{22} &amp; \\dots &amp; \\beta_{2M}\\\\ \\vdots &amp; \\vdots &amp; \\dots &amp; \\vdots\\\\ \\beta_{K1} &amp; \\beta_{K2} &amp; \\dots &amp; \\beta_{KM}\\\\ \\end{bmatrix}}_{\\bf{B}}\\\\ &amp;+ \\underbrace{\\begin{bmatrix} \\mu_{11} &amp; \\mu_{12} &amp; \\dots &amp; \\mu_{1M}\\\\ \\mu_{21} &amp; \\mu_{22} &amp; \\dots &amp; \\mu_{2M}\\\\ \\vdots &amp; \\vdots &amp; \\dots &amp; \\vdots\\\\ \\mu_{N1} &amp; \\mu_{N2} &amp; \\dots &amp; \\mu_{NM}\\\\ \\end{bmatrix}}_{\\bf{U}} \\end{align}\\] Therefore, \\({\\bf{Y}}\\sim N_{N\\times M}({\\bf{X}}{\\bf{B}},\\bf{\\Sigma}\\otimes {\\bf{I}}_N)\\),22 \\[\\begin{align} p({\\bf{Y}}| {\\bf{B}},{\\bf\\Sigma})&amp;\\propto |{{\\bf \\Sigma}}|^{-N/2}\\exp\\left\\lbrace -\\frac{1}{2}tr\\left[({\\bf{Y}}-{\\bf{X}}{\\bf{B}})^{\\top}({\\bf{Y}}-{\\bf{X}}{\\bf{B}}){{\\bf \\Sigma}}^{-1}\\right]\\right\\rbrace \\\\ &amp;=|{{\\bf \\Sigma}}|^{-N/2}\\exp\\left\\lbrace -\\frac{1}{2}tr\\left[{\\bf{S}}+({\\bf{B}}-\\widehat{\\bf{B}})^{\\top}{\\bf{X}}^{\\top}{\\bf{X}}({\\bf{B}}-\\widehat{\\bf{B}})\\right]{{\\bf \\Sigma}}^{-1}\\right\\rbrace, \\end{align}\\] where \\({\\bf{S}}= ({\\bf{Y}}-{\\bf{X}}\\widehat{\\bf{B}})^{\\top}({\\bf{Y}}-{\\bf{X}}\\widehat{\\bf{B}})\\), \\(\\widehat{\\bf{B}}= ({\\bf{X}}^{\\top}{\\bf{X}})^{-1}{\\bf{X}}^{\\top}{\\bf{Y}}\\) (see Exercise 7). The conjugate prior for this models is \\(\\pi({\\bf{B}},{\\bf{\\Sigma}})=\\pi({\\bf{B}}|{\\bf{\\Sigma}})\\pi({\\bf{\\Sigma}})\\) where \\(\\pi({\\bf{B}}|{\\bf \\Sigma})\\sim N_{K\\times M}({\\bf{B}}_{0},{\\bf\\Sigma} \\otimes {\\bf{V}}_{0})\\) and \\(\\pi({\\bf\\Sigma})\\sim IW({\\bf{\\Psi}}_{0},\\alpha_{0})\\), that is, \\[\\begin{align} \\pi ({\\bf{B}},{\\bf\\Sigma})\\propto &amp;\\left|{\\bf\\Sigma} \\right|^{-K/2}\\exp\\left\\lbrace -\\frac{1}{2}tr\\left[({\\bf{B}}-{\\bf{B}}_{0})^{\\top}{\\bf{V}}_{0}^{-1}({\\bf{B}}-{\\bf{B}}_{0})\\right] {\\bf \\Sigma}^{-1}\\right\\rbrace \\\\ &amp; \\times \\left|{\\bf \\Sigma} \\right|^{-(\\alpha_{0}+M+1)/2}\\exp\\left\\lbrace -\\frac{1}{2}tr \\left[ {\\bf{\\Psi}}_{0} {\\bf \\Sigma}^{-1}\\right] \\right\\rbrace. \\end{align}\\] The posterior distribution is given by \\[\\begin{align} \\pi({\\bf{B}},{\\bf\\Sigma}|{\\bf{Y}},{\\bf{X}})&amp;\\propto p({\\bf{Y}}|{\\bf{B}},{\\bf\\Sigma},{\\bf{X}}) \\pi({\\bf{B}}| {\\bf \\Sigma})\\pi({\\bf\\Sigma})\\\\ &amp;\\propto \\left|{\\bf\\Sigma} \\right|^{-\\frac{N+K+\\alpha_{0}+M+1}{2}}\\\\ &amp;\\times\\exp\\left\\lbrace -\\frac{1}{2}tr\\left[(\\bf{\\Psi}_{0}+{\\bf{S}} +({\\bf{B}}-{\\bf{B}}_{0})^{\\top}{\\bf{V}}_{0}^{-1}({\\bf{B}}-{\\bf{B}}_{0})\\right.\\right.\\\\ &amp;\\left.\\left. +({\\bf{B}}-\\widehat{\\bf{B}})^{\\top}{\\bf{X}}^{\\top}{\\bf{X}}({\\bf{B}}-\\widehat{\\bf{B}}))\\bf{\\Sigma}^{-1}\\right]\\right\\rbrace . \\end{align}\\] Completing the squares on \\({\\bf{B}}\\) and collecting the remaining terms in the bracket yields \\[\\begin{align} {\\bf{\\Psi}}_{0}+{\\bf{S}} +({\\bf{B}}-{\\bf{B}}_{0})^{\\top}{\\bf{V}}_{0}^{-1}({\\bf{B}}-{\\bf{B}}_{0})+({\\bf{B}}-\\widehat{\\bf{B}})^{\\top}{\\bf{X}}^{\\top}{\\bf{X}}({\\bf{B}}-\\widehat{\\bf{B}}) &amp; = ({\\bf{B}}-{\\bf{B}}_n)^{\\top}{\\bf{V}}_n^{-1}({\\bf{B}}-{\\bf{B}}_n)+{\\bf{\\Psi}}_n, \\end{align}\\] where \\[\\begin{align} {\\bf{B}}_n = &amp;({\\bf{V}}_{0}^{-1}+{\\bf{X}}^{\\top}{\\bf{X}})^{-1}({\\bf{V}}_{0}^{-1}{\\bf{B}}_{0}+{\\bf{X}}^{\\top}{\\bf{Y}})=({\\bf{V}}_{0}^{-1}+{\\bf{X}}^{\\top}{\\bf{X}})^{-1}({\\bf{V}}_{0}^{-1}{\\bf{B}}_{0}+{\\bf{X}}^{\\top}{\\bf{X}}\\widehat{\\bf{B}}),\\\\ {\\bf{V}}_n = &amp;({\\bf{V}}_{0}^{-1}+{\\bf{X}}^{\\top}{\\bf{X}})^{-1},\\\\ {\\bf{\\Psi}}_n= &amp;{\\bf{\\Psi}}_{0}+{\\bf{S}}+{\\bf{B}}_{0}^{\\top}{\\bf{V}}_{0}^{-1}{\\bf{B}}_{0}+\\widehat{\\bf{B}}^{\\top}{\\bf{X}}^{\\top}{\\bf{X}}\\widehat{\\bf{B}}-{\\bf{B}}_n^{\\top}{\\bf{V}}_n^{-1}{\\bf{B}}_n. \\end{align}\\] Thus, the posterior distribution can be written as \\[\\begin{align} \\pi({\\bf{B}},{\\bf \\Sigma}| {\\bf{Y}}, {\\bf{X}})\\propto &amp;\\left|{\\bf \\Sigma} \\right|^{-K/2}\\exp\\left\\lbrace -\\frac{1}{2} tr\\left[({\\bf{B}}-{\\bf{B}}_n)^{\\top}{\\bf{V}}_n^{-1}({\\bf{B}}-{\\bf{B}}_n) \\right] {\\bf \\Sigma}^{-1}\\right\\rbrace \\\\ \\times &amp; \\left|{\\bf \\Sigma} \\right|^{-\\frac{N+\\alpha_{0}+M+1}{2}}\\exp\\left\\lbrace -\\frac{1}{2} tr \\left[ {\\bf{\\Psi}}_n{\\bf \\Sigma}^{-1}\\right] \\right\\rbrace . \\end{align}\\] That is \\(\\pi({\\bf{B}},{\\bf \\Sigma}| {\\bf{Y}}, {\\bf{X}})=\\pi ({\\bf{B}}| {\\bf \\Sigma},{\\bf{Y}},{\\bf{X}})\\pi({\\bf \\Sigma}| {\\bf{Y}},{\\bf{X}})\\) where \\(\\pi({\\bf{B}}| {\\bf \\Sigma},{\\bf{Y}}, {\\bf{X}}) \\sim N_{K\\times M}({\\bf{B}}_n,{\\bf \\Sigma}\\otimes {\\bf{V}}_n )\\) and \\(\\pi({\\bf \\Sigma}| {\\bf{Y}},{\\bf{X}}) \\sim IW({\\bf{\\Psi}}_n,{\\alpha}_n)\\), where \\(\\alpha_n= N+\\alpha_{0}\\). The marginal posterior for \\({\\bf{B}}\\) is … The marginal likelihood is … The predictive density is … \\(vec\\) denotes the vectorization operation, and \\(\\otimes\\) denotes the kronecker product↩︎ We can write down the former expression in a more familiar way using vectorization properties, \\(\\underbrace{vec(Y)}_{\\bf{y}}=\\underbrace{({\\bf{I}}_M\\otimes {\\bf{X}})}_{{\\bf{Z}}}\\underbrace{vec({\\bf{B}})}_{\\beta}+\\underbrace{vec({\\bf{U}})}_{\\mu}\\), where \\({\\bf{y}}\\sim N_{N\\times M}({\\bf{Z}}\\beta,\\bf{\\Sigma}\\otimes {\\bf{I}}_N)\\).↩︎ "],["computational-examples.html", "3.5 Computational examples", " 3.5 Computational examples What is the probability that the Sun will rise tomorrow? This is the most famaous Ricard Price^{}s example developed in the Appendix of the Bayes^{} theorem paper (Thomas Bayes 1763). Here, we implicitly use Laplace^{}s Rule of Succession to solve this question. In perticular, if we were a priori uncertain about the probability the Sun will on a specified day rise, that is, a prior uniform distribution over (0,1), that is, a beta (1,1) distribution… References "],["summary-chapter-4.html", "3.6 Summary: Chapter 4", " 3.6 Summary: Chapter 4 "],["exercises-chapter-4.html", "3.7 Exercises: Chapter 4", " 3.7 Exercises: Chapter 4 Write in the canonical form the distribution of the Bernoulli example, and find the mean and variance of the sufficient statistic. Given a random sample \\(\\mathbf{y}=[\\mathbf{y}_1,\\mathbf{y}_2,\\dots,\\mathbf{y}_N]^{\\top}\\) from a binomial distribution where the number of trials (\\(n\\)) is known. Show that \\(p(\\mathbf{y}|\\theta)\\) is in the exponential family, and find the posterior distribution, the marginal likelihood and the predictive distribution of the binomial-beta model assuming the number of trials is known. Given a random sample \\(\\mathbf{y}=[y_1,y_2,\\dots,y_N]^{\\top}\\) from a exponential distribution. Show that \\(p(\\mathbf{y}|\\alpha,\\beta)\\) is in the exponential family, and find the posterior distribution, marginal likelihood and predictive distribution of the exponential-gamma model. Find the marginal likelihood in the normal/inverse-Wishart model. Find the posterior predictive distribution in the normal/inverse-Wishart model. Show that in the linear regression model \\(\\beta_n^{\\top}({\\bf{B}}_n^{-1}-{\\bf{B}}_n^{-1}{\\bf{M}}^{-1}{\\bf{B}}_n^{-1})\\beta_n={\\bf{\\beta}}_{**}^{\\top}{\\bf{C}}{\\bf{\\beta}}_{**}\\) and \\(\\beta_{**}={\\mathbf{X}}_0\\beta_n\\). Show that \\(({\\bf{Y}}-{\\bf{X}}{\\bf{B}})^{\\top}({\\bf{Y}}-{\\bf{X}}{\\bf{B}})={\\bf{S}}+({\\bf{B}}-\\widehat{\\bf{B}})^{\\top}{\\bf{X}}^{\\top}{\\bf{X}}({\\bf{B}}-\\widehat{\\bf{B}})\\) where \\({\\bf{S}}= ({\\bf{Y}}-{\\bf{X}}\\widehat{\\bf{B}})^{\\top}({\\bf{Y}}-{\\bf{X}}\\widehat{\\bf{B}})\\), \\(\\widehat{\\bf{B}}= ({\\bf{X}}^{\\top}{\\bf{X}})^{-1}{\\bf{X}}^{\\top}{\\bf{Y}}\\). "],["Chap4.html", "Chapter 4 Simulation methods", " Chapter 4 Simulation methods In the previous chapters, we focused on conjugate families, where the posterior and predictive distributions have standard analytical forms (e.g., normal, Student’s t, gamma, binomial, Poisson, etc.) and where the marginal likelihood has a closed-form analytical solution. However, realistic models are often more complex and lack such closed-form solutions. To address this complexity, we rely on simulation (stochastic) methods to draw samples from posterior and predictive distributions. This chapter introduces posterior simulation, a cornerstone of Bayesian inference. We discuss Markov Chain Monte Carlo (MCMC) methods, including Gibbs sampling, Metropolis-Hastings, and Hamiltonian Monte Carlo, as well as other techniques like importance sampling and particle filtering (sequential Monte Carlo). The simulation methods discussed in this chapter are specifically applied throughout this book. However, we do not delve into deterministic methods, such as numerical integration (quadrature), or other simulation methods, including discrete approximation, the probability integral transform, the method of composition, accept-reject sampling, and slice sampling algorithms. While these methods are also widely used, they are not as common as the approaches explicitly employed in this book. For readers interested in these alternative methods, we recommend exploring Christian P. Robert, Casella, and Casella (2010), Christian P. Robert and Casella (2011), Greenberg (2012), and Andrew Gelman et al. (2021). References "],["sec51.html", "4.1 Markov Chain Monte Carlo methods", " 4.1 Markov Chain Monte Carlo methods Markov Chain Monte Carlo (MCMC) methods are algorithms used to approximate complex probability distributions by constructing a Markov chain. This chain is a sequence of random samples where each sample depends only on the previous one. The goal of MCMC methods is to obtain draws from the posterior distribution as the equilibrium distribution. The key point in MCMC methods is the transition kernel or density, \\(q(\\boldsymbol{\\theta}^{(s)}\\mid \\boldsymbol{\\theta}^{(s-1)})\\), which generates a draw \\(\\boldsymbol{\\theta}^{(s)}\\) at stage \\(s\\) that depends solely on \\(\\boldsymbol{\\theta}^{(s-1)}\\). This transition distribution must be designed such that the Markov chain converges to a unique stationary distribution, which, in our case, is the posterior distribution, that is, \\[ \\pi(\\boldsymbol{\\theta}^{(s)}\\mid \\boldsymbol{y})=\\int_{\\boldsymbol{\\Theta}}q(\\boldsymbol{\\theta}^{(s)}\\mid \\boldsymbol{\\theta}^{(s-1)})\\pi(\\boldsymbol{\\theta}^{(s-1)}\\mid \\boldsymbol{y})d\\boldsymbol{\\theta}^{(s-1)}. \\] Given that we start at an arbitrary point, \\(\\boldsymbol{\\theta}^{(0)}\\), the algorithm requires that the Markov chain be irreducible, meaning that the process can reach any other state with positive probability. Additionally, the process must be aperiodic, meaning that for each state, the greatest common divisor of the number of steps it takes to return to the state is 1, ensuring that there are no cycles forcing the system to return to a state only after a fixed number of steps. Furthermore, the process must be recurrent, meaning that it will return to any state an infinite number of times with probability one. However, to ensure convergence to the stationary distribution, a stronger condition is required: the process must be positive recurrent, meaning that the expected return time to a state is finite. Given an irreducible, aperiodic, and positive recurrent transition density, the Markov chain algorithm will asymptotically converge to the stationary posterior distribution we are seeking. For more details, see Christian P. Robert and Casella (2011). 4.1.1 Gibbs sampler The Gibbs sampler algorithm is one of the most widely used MCMC methods for sampling from non-standard distributions in Bayesian analysis. While it is a special case of the Metropolis-Hastings (MH) algorithm, it originated from a different theoretical background (Geman and Geman 1984; A. E. Gelfand and Smith 1990). The key requirement for implementing the Gibbs sampling algorithm is the availability of conditional posterior distributions. The algorithm works by cycling through the conditional posterior distributions corresponding to different blocks of the parameter space under inference. To simplify concepts, let’s focus on a parameter space composed of two blocks, \\(\\boldsymbol{\\theta} = [\\boldsymbol{\\theta}_1 \\ \\boldsymbol{\\theta}_2]^{\\top}\\). The Gibbs sampling algorithm uses the transition kernel \\[ q(\\boldsymbol{\\theta}_1^{(s)},\\boldsymbol{\\theta}_2^{(s)}\\mid \\boldsymbol{\\theta}_1^{(s-1)},\\boldsymbol{\\theta}_2^{(s-1)})=\\pi(\\boldsymbol{\\theta}_1^{(s)}\\mid \\boldsymbol{\\theta}_2^{(s-1)},\\boldsymbol{y})\\pi(\\boldsymbol{\\theta}_2^{(s)}\\mid \\boldsymbol{\\theta}_1^{(s)},\\boldsymbol{y}). \\] Thus, \\[ \\begin{aligned} \\int_{\\boldsymbol{\\Theta}}q(\\boldsymbol{\\theta}^{(s)}\\mid \\boldsymbol{\\theta}^{(s-1)})\\pi(\\boldsymbol{\\theta}^{(s-1)}\\mid \\boldsymbol{y})d\\boldsymbol{\\theta}^{(s-1)} &amp;=\\int_{\\boldsymbol{\\Theta}_2}\\int_{\\boldsymbol{\\Theta}_1}\\pi(\\boldsymbol{\\theta}_1^{(s)}\\mid \\boldsymbol{\\theta}_2^{(s-1)},\\boldsymbol{y})\\pi(\\boldsymbol{\\theta}_2^{(s)}\\mid \\boldsymbol{\\theta}_1^{(s)},\\boldsymbol{y})\\pi(\\boldsymbol{\\theta}^{(s-1)}_1,\\boldsymbol{\\theta}^{(s-1)}_2\\mid \\boldsymbol{y})d\\boldsymbol{\\theta}^{(s-1)}_1d\\boldsymbol{\\theta}^{(s-1)}_2\\\\ &amp;=\\pi(\\boldsymbol{\\theta}_2^{(s)}\\mid \\boldsymbol{\\theta}_1^{(s)},\\boldsymbol{y})\\int_{\\boldsymbol{\\Theta}_2}\\int_{\\boldsymbol{\\Theta}_1}\\pi(\\boldsymbol{\\theta}_1^{(s)}\\mid \\boldsymbol{\\theta}_2^{(s-1)},\\boldsymbol{y})\\pi(\\boldsymbol{\\theta}^{(s-1)}_1,\\boldsymbol{\\theta}^{(s-1)}_2\\mid \\boldsymbol{y})d\\boldsymbol{\\theta}^{(s-1)}_1d\\boldsymbol{\\theta}^{(s-1)}_2\\\\ &amp;=\\pi(\\boldsymbol{\\theta}_2^{(s)}\\mid \\boldsymbol{\\theta}_1^{(s)},\\boldsymbol{y})\\int_{\\boldsymbol{\\Theta}_2}\\pi(\\boldsymbol{\\theta}_1^{(s)}\\mid \\boldsymbol{\\theta}_2^{(s-1)},\\boldsymbol{y})\\pi(\\boldsymbol{\\theta}^{(s-1)}_2\\mid \\boldsymbol{y})d\\boldsymbol{\\theta}^{(s-1)}_2\\\\ &amp;=\\pi(\\boldsymbol{\\theta}_2^{(s)}\\mid \\boldsymbol{\\theta}_1^{(s)},\\boldsymbol{y})\\int_{\\boldsymbol{\\Theta}_2}\\pi(\\boldsymbol{\\theta}_1^{(s)},\\boldsymbol{\\theta}_2^{(s-1)}\\mid \\boldsymbol{y})d\\boldsymbol{\\theta}^{(s-1)}_2\\\\ &amp;=\\pi(\\boldsymbol{\\theta}_2^{(s)}\\mid \\boldsymbol{\\theta}_1^{(s)},\\boldsymbol{y})\\pi(\\boldsymbol{\\theta}_1^{(s)}\\mid \\boldsymbol{y})\\\\ &amp;=\\pi(\\boldsymbol{\\theta}_1^{(s)},\\boldsymbol{\\theta}_2^{(s)}\\mid \\boldsymbol{y}). \\end{aligned} \\] Then, \\(\\pi(\\boldsymbol{\\theta}\\mid \\boldsymbol{y})\\) is the stationary distribution for the Gibbs transition kernel. A word of caution! Even if we have well-defined conditional posterior distributions \\(\\pi(\\boldsymbol{\\theta}_1^{(s)} \\mid \\boldsymbol{\\theta}_2^{(s-1)}, \\boldsymbol{y})\\) and \\(\\pi(\\boldsymbol{\\theta}_2^{(s)} \\mid \\boldsymbol{\\theta}_1^{(s)}, \\boldsymbol{y})\\), and we can simulate from them, the joint posterior distribution \\(\\pi(\\boldsymbol{\\theta}_1^{(s)}, \\boldsymbol{\\theta}_2^{(s)} \\mid \\boldsymbol{y})\\) may not correspond to any proper distribution. We should be mindful of this situation, especially when dealing with improper prior distributions (see Christian P. Robert and Casella (2011) for details). Algorithm 1 demonstrates the implementation of a Gibbs sampler with \\(d\\) blocks. The number of iterations (\\(S\\)) is chosen to ensure convergence to the stationary distribution. In Section 4.4, we review several convergence diagnostics to assess whether the posterior draws have reached convergence. Algorithm: Gibbs sampling Set θ2(0), θ3(0), ..., θd(0), For s=1,2,...,S do Draw θ1(s) from π(θ1(s)|θ2(s-1),...,θd(s-1),y) Draw θ2(s) from π(θ2(s)|θ1(s),...,θd(s-1),y) ... Draw θd(s) from π(θd(s)|θ1(s),...,θd-1(s),y) End for Example: Mining disaster change point Let’s use the dataset Mining.csv provided by Carlin, Gelfand, and Smith (1992). This dataset records the number of mining disasters per year from 1851 to 1962 in British coal mines. We assume there is an unknown structural change point in the number of mining disasters, where the parameters of the Poisson distributions change. In particular: \\[ \\begin{align*} p(y_t) = \\begin{cases} \\frac{\\exp(-\\lambda_1) \\lambda_1^{y_t}}{y_t!}, &amp; t = 1, 2, \\dots, H \\\\ \\frac{\\exp(-\\lambda_2) \\lambda_2^{y_t}}{y_t!}, &amp; t = H+1, \\dots, T \\end{cases} \\end{align*} \\] where \\(H\\) is the changing point. We use conjugate families for \\(\\lambda_l\\), \\(l = 1, 2\\), where \\(\\lambda_l \\sim G(\\alpha_{l0}, \\beta_{l0})\\), and set \\(\\pi(H) = 1 / T\\), which corresponds to a discrete uniform distribution for the change point. This implies that, a priori, we assume equal probability for any time to be the change point. The posterior distribution is: \\[ \\begin{align*} \\pi(\\lambda_1, \\lambda_2, H \\mid \\mathbf{y}) &amp;\\propto \\prod_{t=1}^{H} \\frac{\\exp(-\\lambda_1) \\lambda_1^{y_t}}{y_t!} \\prod_{t=H+1}^{T} \\frac{\\exp(-\\lambda_2) \\lambda_2^{y_t}}{y_t!} \\\\ &amp;\\times \\exp(-\\beta_{10} \\lambda_1) \\lambda_1^{\\alpha_{10}-1} \\exp(-\\beta_{20} \\lambda_2) \\lambda_2^{\\alpha_{20}-1} \\frac{1}{T} \\\\ &amp;\\propto \\exp(-H \\lambda_1) \\lambda_1^{\\sum_{t=1}^{H} y_t} \\exp(-(T-H) \\lambda_2) \\lambda_2^{\\sum_{t=H+1}^{T} y_t} \\\\ &amp;\\times \\exp(-\\beta_{10} \\lambda_1) \\lambda_1^{\\alpha_{10}-1} \\exp(-\\beta_{20} \\lambda_2) \\lambda_2^{\\alpha_{20}-1} \\end{align*} \\] Then, the conditional posterior distribution of \\(\\lambda_1 \\mid \\lambda_2, H, \\mathbf{y}\\) is: \\[ \\begin{align*} \\pi(\\lambda_1 \\mid \\lambda_2, H, \\mathbf{y}) &amp;\\propto \\exp(-(H + \\beta_{10}) \\lambda_1) \\lambda_1^{\\sum_{t=1}^{H} y_t + \\alpha_{10} - 1} \\end{align*} \\] That is, \\(\\lambda_1 \\mid \\lambda_2, H, \\mathbf{y} \\sim G(\\alpha_{1n}, \\beta_{1n})\\), \\(\\beta_{1n} = H + \\beta_{10}\\) and \\(\\alpha_{1n} = \\sum_{t=1}^{H} y_t + \\alpha_{10}\\). The conditional posterior distribution of \\(\\lambda_2\\mid \\lambda_1,H,y\\) is \\[\\begin{align*} \\pi(\\lambda_2\\mid \\lambda_1,H,y)&amp;\\propto\\exp(-((T-H)+\\beta_{20})\\lambda_2)\\lambda_2^{\\sum_{t=H+1}^T y_t+\\alpha_{20}-1}, \\end{align*}\\] that is, \\(\\lambda_2\\mid \\lambda_1,H,y\\sim G(\\alpha_{2n},\\beta_{2n})\\), \\(\\beta_{2n}=(T-H)+\\beta_{20}\\) and \\(\\alpha_{2n}=\\sum_{t=H+1}^T y_t+\\alpha_{20}\\). The conditional posterior distribution of the change point is \\[\\begin{align*} \\pi(H\\mid \\lambda_1,\\lambda_2,y)&amp;\\propto\\exp(-H\\lambda_1)\\lambda_1^{\\sum_{t=1}^H y_t}\\exp(-(T-H)\\lambda_2)\\lambda_2^{\\sum_{t=H+1}^T y_t}\\\\ &amp;\\propto \\exp(-H(\\lambda_1-\\lambda_2))\\lambda_1^{\\sum_{t=1}^H y_t}\\lambda_2^{\\sum_{t=H+1}^T y_t} \\exp(-T\\lambda_2) \\frac{\\lambda_2^{\\sum_{t=1}^H}}{\\lambda_2^{\\sum_{t=1}^H} y_t}\\\\ &amp;\\propto \\exp(-H(\\lambda_1-\\lambda_2))\\left(\\frac{\\lambda_1}{\\lambda_2}\\right)^{\\sum_{t=1}^H y_t}. \\end{align*}\\] Thus, the conditional posterior distribution of \\(H\\) is \\[\\begin{align*} \\pi(H\\mid \\lambda_1,\\lambda_2,y)=&amp; \\frac{\\exp(-H(\\lambda_1-\\lambda_2))\\left(\\frac{\\lambda_1}{\\lambda_2}\\right)^{\\sum_{t=1}^H y_t}}{\\sum_{H=1}^T \\exp(-H(\\lambda_1-\\lambda_2))\\left(\\frac{\\lambda_1}{\\lambda_2}\\right)^{\\sum_{t=1}^H y_t}}, &amp; H=1,2,\\dots,T. \\end{align*}\\] The following code shows how to do a Gibbs sampling algorithm to perform inference of this model using the hyperparameters suggested by Greenberg (2012), \\(\\alpha_{l0}=0.5\\) and \\(\\beta_{l0}=1\\), \\(l=1,2\\). rm(list = ls()); set.seed(010101) dataset&lt;-read.csv(&quot;https://raw.githubusercontent.com/besmarter/BSTApp/refs/heads/master/DataApp/MiningDataCarlin.csv&quot;,header=T) attach(dataset); str(dataset) ## &#39;data.frame&#39;: 112 obs. of 2 variables: ## $ year : int 1851 1852 1853 1854 1855 1856 1857 1858 1859 1860 ... ## $ Count: int 4 5 4 1 0 4 3 4 0 6 ... a10&lt;-0.5; a20&lt;-0.5 b10&lt;-1; b20&lt;-1 y&lt;-Count sumy&lt;-sum(Count); N&lt;-length(Count) theta1&lt;-NULL; theta2&lt;-NULL kk&lt;-NULL; k&lt;-60; S&lt;-10000 for(i in 1:S){ a1&lt;-a10+sum(y[1:k]); b1&lt;-b10+k theta11&lt;-rgamma(1,a1,b1) theta1&lt;-c(theta1,theta11) a2&lt;-a20+sum(y[(1+k):N]); b2&lt;-b20+N-k theta22&lt;-rgamma(1,a2,b2) theta2&lt;-c(theta2,theta22) pp&lt;-NULL for(l in 1:N){ p&lt;-exp(l*(theta22-theta11))*(theta11/theta22)^(sum(y[1:l])) pp&lt;-c(pp,p) } prob&lt;-pp/sum(pp); k&lt;-sample(1:N,1,prob=prob) kk&lt;-c(kk,k) } library(coda); summary(mcmc(theta1)); summary(mcmc(theta2)) ## ## Iterations = 1:10000 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 10000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## 3.051805 0.283456 0.002835 0.003054 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## 2.513 2.856 3.046 3.237 3.632 ## ## Iterations = 1:10000 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 10000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## 0.915383 0.117658 0.001177 0.001268 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## 0.6996 0.8341 0.9117 0.9932 1.1570 summary(mcmc(kk)); hist(kk, main = &quot;Histogram: Posterior mean change point&quot;, xlab = &quot;Posterior mean&quot;, col = &quot;blue&quot;, breaks = 25) ## ## Iterations = 1:10000 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 10000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## 40.15020 2.48875 0.02489 0.02903 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## 36 39 40 41 46 The posterior results indicate that the rate of disasters decrease from 3.1 to 0.92 per year in 1890. The figure shows the histogram of the posterior draws of the change point in mining disasters. 4.1.2 Metropolis-Hastings The Metropolis-Hastings (M-H) algorithm (Metropolis et al. 1953; Hastings 1970) is a general MCMC method that does not require standard closed-form solutions for the conditional posterior distributions. The key idea is to use a transition kernel whose unique invariant distribution is \\(\\pi(\\boldsymbol{\\theta} \\mid \\mathbf{y})\\). This kernel must satisfy the balancing condition, meaning that, given a realization \\(\\boldsymbol{\\theta}^{(s-1)}\\) at stage \\(s-1\\) from the stationary distribution \\(\\pi(\\boldsymbol{\\theta} \\mid \\mathbf{y})\\), we generate a candidate draw \\(\\boldsymbol{\\theta}^{c}\\) from the proposal distribution \\(q(\\boldsymbol{\\theta}^{c} \\mid \\boldsymbol{\\theta}^{(s-1)})\\) at stage \\(s\\) such that: \\[ q(\\boldsymbol{\\theta}^{c} \\mid \\boldsymbol{\\theta}^{(s-1)}) \\pi(\\boldsymbol{\\theta}^{(s-1)} \\mid \\mathbf{y}) = q(\\boldsymbol{\\theta}^{(s-1)} \\mid \\boldsymbol{\\theta}^{c}) \\pi(\\boldsymbol{\\theta}^{c} \\mid \\mathbf{y}), \\] which implies that the probability of moving from \\(\\boldsymbol{\\theta}^{(s-1)}\\) to \\(\\boldsymbol{\\theta}^{c}\\) is equal to the probability of moving from \\(\\boldsymbol{\\theta}^{c}\\) to \\(\\boldsymbol{\\theta}^{(s-1)}\\). In general, the balancing condition is not automatically satisfied, and we must introduce an acceptance probability \\(\\alpha(\\boldsymbol{\\theta}^{(s-1)}, \\boldsymbol{\\theta}^{c})\\) to ensure that the condition holds: \\[ q(\\boldsymbol{\\theta}^{c} \\mid \\boldsymbol{\\theta}^{(s-1)}) \\pi(\\boldsymbol{\\theta}^{(s-1)} \\mid \\mathbf{y}) \\alpha(\\boldsymbol{\\theta}^{(s-1)}, \\boldsymbol{\\theta}^{c}) = q(\\boldsymbol{\\theta}^{(s-1)} \\mid \\boldsymbol{\\theta}^{c}) \\pi(\\boldsymbol{\\theta}^{c} \\mid \\mathbf{y}). \\] Thus, the acceptance probability is given by: \\[ \\alpha(\\boldsymbol{\\theta}^{(s-1)}, \\boldsymbol{\\theta}^{c}) = \\min\\left\\{\\frac{q(\\boldsymbol{\\theta}^{(s-1)} \\mid \\boldsymbol{\\theta}^{c}) \\pi(\\boldsymbol{\\theta}^{c} \\mid \\mathbf{y})}{q(\\boldsymbol{\\theta}^{c} \\mid \\boldsymbol{\\theta}^{(s-1)}) \\pi(\\boldsymbol{\\theta}^{(s-1)} \\mid \\mathbf{y})}, 1\\right\\}, \\] where \\(q(\\boldsymbol{\\theta}^{c} \\mid \\boldsymbol{\\theta}^{(s-1)})\\) and \\(\\pi(\\boldsymbol{\\theta}^{(s-1)} \\mid \\mathbf{y})\\) must be nonzero, as transitioning from \\(\\boldsymbol{\\theta}^{(s-1)}\\) to \\(\\boldsymbol{\\theta}^{c}\\) is only possible under these conditions. Algorithm 2 shows how to implement a Metropolis-Hastings algorithm. The number of iterations (\\(S\\)) is chosen to ensure convergence to the stationary distribution. Algorithm: Metropolis-Hastings Set θ(0) in the support of π(θ|y) For s=1,2,...,S do Draw θc from q(θc|θ(s-1)) Calculate α(θ(s-1),θc)=min((q(θ(s-1)|θc)π(θc|y))/(q(θc|θ(s-1))π(θ(s-1)|y)),1) Draw U from U(0,1) θ(s)= θc if U (s-1),θc) θ(s)= θ(s-1) otherwise End for Some remarks: First, we do not need to know the marginal likelihood to implement the M-H algorithm, as it cancels out when calculating the acceptance probability. Specifically, given that \\(\\pi(\\boldsymbol{\\theta} \\mid \\boldsymbol{y}) \\propto \\pi(\\boldsymbol{\\theta}) \\times p(\\boldsymbol{y} \\mid \\boldsymbol{\\theta})\\), we can use the right-hand side expression to compute the acceptance probability. Second, the Gibbs sampling algorithm is a particular case of the M-H algorithm where the acceptance probability is equal to 1 (Andrew Gelman and Rubin (1992) and Christian P. Robert and Casella (2011), see Exercise 2). Third, we can combine the M-H and Gibbs sampling algorithms when dealing with relatively complex posterior distributions. Specifically, the Gibbs sampling algorithm can be used for blocks with conditional posterior distributions in standard closed forms, while the M-H algorithm is applied to sample from conditional posterior distributions that do not have standard forms. This approach is known as the M-H within Gibbs sampling algorithm. Fourth, we can note that the transition kernel in the M-H algorithm is a mixture of a continuous density (\\(q(\\boldsymbol{\\theta}^c \\mid \\boldsymbol{\\theta}^{(s-1)})\\)) and a probability mass function (\\(\\alpha(\\boldsymbol{\\theta}^{(s-1)}, \\boldsymbol{\\theta}^c)\\)) Siddhartha Chib and Greenberg (1995). Fifth, a crucial point associated with the proposal densities is the acceptance probability. Low or high acceptance probabilities are not ideal. A low rate implies poor mixing, meaning the chain does not move effectively through the support of the posterior distribution. Conversely, a high acceptance rate implies that the chain will converge too slowly. A sensible value depends on the dimension of the parameter space. A rule of thumb is that if the dimension is less than or equal to 2, the acceptance rate should be around 0.50. If the dimension is greater than 2, the acceptance rate should be approximately 0.25 Roberts, Gelman, and Gilks (1997). For technical details of the Metropolis-Hastings algorithm, see Christian P. Robert and Casella (2011), Chap. 7. Regarding the proposal density, it must be positive everywhere the posterior distribution is positive. This ensures that the Markov chain can explore the entire support of the posterior distribution. Additionally, the proposal density must allow the Markov chain to reach any region of the posterior distribution’s support. There are three standard approaches for choosing the proposal density: the independent proposal, the random walk proposal, and the tailored proposal. In the independent proposal, \\(q(\\boldsymbol{\\theta}^c \\mid \\boldsymbol{\\theta}^{(s-1)}) = q(\\boldsymbol{\\theta}^c)\\), which implies that \\[ \\alpha(\\boldsymbol{\\theta}^{(s-1)}, \\boldsymbol{\\theta}^c) = \\min\\left\\{\\frac{q(\\boldsymbol{\\theta}^{(s-1)}) \\pi(\\boldsymbol{\\theta}^c \\mid \\boldsymbol{y})}{q(\\boldsymbol{\\theta}^c) \\pi(\\boldsymbol{\\theta}^{(s-1)} \\mid \\boldsymbol{y})}, 1\\right\\}. \\] In this case, a move from \\(\\boldsymbol{\\theta}^{(s-1)}\\) to \\(\\boldsymbol{\\theta}^c\\) is always accepted if \\(q(\\boldsymbol{\\theta}^{(s-1)}) \\pi(\\boldsymbol{\\theta}^c \\mid \\boldsymbol{y}) \\geq q(\\boldsymbol{\\theta}^c) \\pi(\\boldsymbol{\\theta}^{(s-1)} \\mid \\boldsymbol{y})\\). In the random walk proposal, \\(\\boldsymbol{\\theta}^c = \\boldsymbol{\\theta}^{(s-1)} + \\boldsymbol{\\epsilon}\\), where \\(\\boldsymbol{\\epsilon}\\) is a random perturbation. If \\(p(\\boldsymbol{\\epsilon}) = p(-\\boldsymbol{\\epsilon})\\), meaning the distribution \\(p(\\boldsymbol{\\epsilon})\\) is symmetric around zero, then \\(q(\\boldsymbol{\\theta}^c \\mid \\boldsymbol{\\theta}^{(s-1)}) = q(\\boldsymbol{\\theta}^{(s-1)} \\mid \\boldsymbol{\\theta}^c)\\). This was the original Metropolis algorithm Metropolis et al. (1953). Thus, the acceptance rate is \\[ \\alpha(\\boldsymbol{\\theta}^{(s-1)}, \\boldsymbol{\\theta}^c) = \\min\\left\\{\\frac{\\pi(\\boldsymbol{\\theta}^c \\mid \\boldsymbol{y})}{\\pi(\\boldsymbol{\\theta}^{(s-1)} \\mid \\boldsymbol{y})}, 1\\right\\}. \\] In this case, a move from \\(\\boldsymbol{\\theta}^{(s-1)}\\) to \\(\\boldsymbol{\\theta}^c\\) is always accepted if \\(\\pi(\\boldsymbol{\\theta}^c \\mid \\boldsymbol{y}) \\geq \\pi(\\boldsymbol{\\theta}^{(s-1)} \\mid \\boldsymbol{y})\\). In the tailored proposal, the density is designed to have fat tails, is centered at the mode of the posterior distribution, and its scale matrix is given by the negative inverse Hessian matrix evaluated at the mode. Specifically, for two blocks, the log posterior distribution is maximized with respect to \\(\\boldsymbol{\\theta}_1\\) given \\(\\boldsymbol{\\theta}_2\\). This process is repeated at each iteration of the algorithm because \\(\\boldsymbol{\\theta}_2\\) changes at different stages. As a result, the algorithm can be slow since the optimization process is computationally demanding (see Greenberg (2012), Chaps. 7 and 9 for examples). A sensible recommendation when performing the M-H algorithm is to use a random walk proposal such that \\(\\boldsymbol{\\epsilon} \\sim N(\\boldsymbol{0}, c^2 \\boldsymbol{\\Sigma})\\), where \\(\\boldsymbol{\\Sigma}\\) is the negative inverse Hessian matrix evaluated at the mode, that is, maximize with respect to all parameters, and set \\(c \\approx 2.4 / \\sqrt{\\text{dim}(\\boldsymbol{\\theta})}\\), which is the most efficient scale compared to independent sampling Andrew Gelman et al. (2021), Chap. 12. After some iterations of the algorithm, adjust the scale matrix \\(\\boldsymbol{\\Sigma}\\) as before, and increase or decrease \\(c\\) if the acceptance rate of the simulations is too high or low, respectively. The objective is to bring the acceptance rate to the stated rule of thumb: if the dimension is less than or equal to 2, the acceptance rate should be around 0.50, and if the dimension is greater than 2, the acceptance rate should be around 0.25. Once this is achieved, we should run the algorithm without modifications and use this part of the algorithm to perform inference. Example: Ph.D. students sleeping hours continues In the Ph.D. students sleeping hours exercise of Chapter 3 we get a posterior distribution that is Beta with parameters 16.55 and 39.57. We can sample from this posterior distribution using the function rbeta from R. However, we want to compare the performance of a M-H algorithm using as proposal density a \\(U(0,1)\\) distribution. The following code shows how to do a M-H algorithm to sample from the beta distribution using the uniform distribution. rm(list = ls()); set.seed(010101) an &lt;- 16.55; bn &lt;- 39.57 S &lt;- 100000; p &lt;- runif(S); accept &lt;- rep(0, S) for (s in 2:S){ pc &lt;- runif(1) # Candidate a &lt;- dbeta(pc, an, bn)/dbeta(p[s-1], an, bn) # Acceptance rate U &lt;- runif(1) if(U &lt;= a){ p[s] &lt;- pc accept[s] &lt;- 1 }else{ p[s] &lt;- p[s-1] accept[s] &lt;- 0 } } mean(accept); mean(p); sd(p) ## [1] 0.19378 ## [1] 0.2949128 ## [1] 0.06087849 an/(an + bn); (an*bn/((an+bn)^2*(an+bn+1)))^0.5 # Population values ## [1] 0.2949038 ## [1] 0.06033513 h &lt;- hist(p, breaks=50, col=&quot;blue&quot;, xlab=&quot;Proportion Ph.D. students sleeping at least 6 hours&quot;, main=&quot;Beta draws from a Metropolis-Hastings algorithm&quot;) pfit &lt;- seq(min(p),max(p),length=50) yfit&lt;-dbeta(pfit, an, bn) yfit &lt;- yfit*diff(h$mids[1:2])*length(p) lines(pfit, yfit, col=&quot;red&quot;, lwd=2) The results indicate that the mean and standard deviation obtained from the posterior draws are similar to the population values. Furthermore, this figure presents the histogram of the posterior draws alongside the density of the beta distribution, demonstrating a good match between them. 4.1.3 Hamiltonian Monte Carlo Hamiltonian Monte Carlo (HMC) was proposed by Duane et al. (1987) and later introduced to the statistical community by Neal (1996). HMC extends the Metropolis algorithm to efficiently explore the parameter space by introducing momentum variables, which help overcome the random walk behavior of Gibbs sampling and the Metropolis-Hastings algorithm. Known also as hybrid Monte Carlo, HMC is particularly advantageous for high-dimensional posterior distributions, as it reduces the risk of getting stuck in local modes and significantly improves mixing (Neal 2011). However, HMC is designed to work with strictly positive target densities. Therefore, transformations are required to handle bounded parameters, such as variances and proportions. For example, logarithmic and logit transformations can be applied. These transformations necessitate the use of the change-of-variable theorem to compute the log posterior density and its gradient, which are essential for implementing the HMC algorithm. HMC leverages concepts from physics, specifically Hamiltonian mechanics, to propose transitions in the Markov chain. In Hamiltonian mechanics, two key variables define the total energy of the system: the position (\\(\\boldsymbol{\\theta}\\)) and the momentum (\\(\\boldsymbol{\\delta}\\)). The Hamiltonian represents the total energy of the system, consisting of potential energy (energy due to position) and kinetic energy (energy associated with motion). The objective is to identify trajectories that preserve the system’s total energy, meaning the Hamiltonian remains invariant, while avoiding trajectories that do not. This approach enhances the acceptance rate of proposed transitions. To implement HMC, we solve the differential equations derived from the Hamiltonian, which involve derivatives with respect to position and momentum. However, these equations rarely have analytical solutions, requiring numerical methods for approximation. This necessitates discretizing Hamilton’s equations, which introduces errors. To mitigate these errors, HMC uses the leapfrog integrator, a numerical method with smaller errors compared to simpler approaches like the Euler method. HMC uses a momentum variable (\\(\\delta_k\\)) for each \\(\\theta_k\\), so that the transition kernel of \\(\\boldsymbol{\\theta}\\) is determined by \\(\\boldsymbol{\\delta}\\). Both vectors are updated using a Metropolis algorithm at each stage such that the distribution of \\(\\boldsymbol{\\theta}\\) remains invariant (Neal 2011). The joint density in HMC is given by \\(p(\\boldsymbol{\\theta}, \\boldsymbol{\\delta} \\mid \\boldsymbol{y}) = \\pi(\\boldsymbol{\\theta} \\mid \\boldsymbol{y}) \\times p(\\boldsymbol{\\delta})\\), where \\(\\boldsymbol{\\delta} \\sim N(\\boldsymbol{0}, \\boldsymbol{M})\\), and \\(\\boldsymbol{M}\\) is a diagonal matrix such that \\(\\delta_k \\sim N(0, M_{kk})\\). Algorithm 3 outlines the HMC implementation. The gradient vector \\(\\frac{d \\log(\\pi(\\boldsymbol{\\theta} \\mid \\boldsymbol{y}))}{d \\boldsymbol{\\theta}}\\) must be computed analytically, as using finite differences can be computationally expensive. However, it is advisable to verify the analytical calculations by evaluating the gradient at the maximum posterior estimate, where the function should return values close to 0, or by comparing results with finite differences at a few points. Algorithm: Hamiltonian Monte Carlo Set θ(0) in the support of π(θ|y), and set step size ε, number of leapfrog steps L, and total iterations S Draw δ(0) from N(0, M) For s=1,2,...,S do For l=1,2,...,L do if l=1 then δc ← δ(s-1) + 0.5 ε dlog(π(θ|y))/dθ θc ← θ(s-1) + ε M-1 δc else if l=2,...,L-1 then δc ← δc + ε dlog(π(θ|y))/dθ θc ← θc + ε M-1 δc else δc ← δc + 0.5 ε dlog(π(θ|y))/dθ θc ← θc + ε M-1 δc End if End if End for Calculate α([θ, δ](s-1),[θ, δ]c)=min((p(δc)π(θc|y))/(p(δ(s-1))π(θ(s-1)|y)),1) Draw U from U(0,1) θ(s)= θc if U (s-1),[θ, δ]c) θ(s)= θ(s-1) otherwise End for Note that HMC does not require the marginal likelihood, as neither the gradient vector \\(\\frac{d \\log(\\pi(\\boldsymbol{\\theta} \\mid \\boldsymbol{y}))}{d \\boldsymbol{\\theta}}\\) nor the acceptance rate depend on it. That is, we can use only \\(\\pi(\\boldsymbol{\\theta}) \\times p(\\boldsymbol{y} \\mid \\boldsymbol{\\theta})\\) to implement HMC. In addition, we do not retain \\(\\boldsymbol{\\delta}\\) after it is updated at the beginning of each iteration, as it is not required subsequently. To begin, the step size (\\(\\epsilon\\)) can be drawn randomly from a uniform distribution between 0 and \\(2\\epsilon_0\\), and the number of leapfrog steps (\\(L\\)) is set as the largest integer near \\(1/\\epsilon\\), ensuring \\(\\epsilon \\times L \\approx 1\\). We need to set \\(\\boldsymbol{M}\\) to be the inverse of the posterior covariance matrix evaluated at the maximum a posteriori estimate under this setting. The acceptance rate should be checked, with the optimal rate around 65% (Andrew Gelman et al. 2021). If the acceptance rate is much higher than 65%, increase \\(\\epsilon_0\\); if it is much lower, decrease it. This strategy may not always work, and alternative strategies can be tested, such as setting \\(\\boldsymbol{M} = \\boldsymbol{I}\\) and fine-tuning \\(\\epsilon\\) and \\(L\\) to achieve an acceptance rate near 65%. Finally, the number of iterations (\\(S\\)) is chosen to ensure convergence to the stationary distribution. Example: Sampling from a bi-variate Gaussian distribution As a toy example, let’s compare the Gibbs sampling, M-H, and HMC algorithms when the posterior distribution is a bi-variate Gaussian distribution with mean \\(\\boldsymbol{0}\\) and covariance matrix \\(\\boldsymbol{\\Sigma} = \\begin{bmatrix} 1 &amp; \\rho \\\\ \\rho &amp; 1 \\end{bmatrix}\\). Let’s set \\(\\rho = 0.98\\). The Gibbs sampler requires the conditional posterior distributions, which in this case are \\(\\theta_1 \\mid \\theta_2 \\sim N(\\rho \\theta_2, 1 - \\rho^2)\\) and \\(\\theta_2 \\mid \\theta_1 \\sim N(\\rho \\theta_1, 1 - \\rho^2)\\). We use the random walk proposal distribution for the M-H algorithm, where \\(\\boldsymbol{\\theta}^c \\sim N(\\boldsymbol{\\theta}^{(s-1)}, \\text{diag}\\left\\{0.18^2\\right\\})\\). We set \\(\\epsilon = 0.05\\), \\(L = 20\\), and \\(\\boldsymbol{M} = \\boldsymbol{I}_2\\) for the HMC algorithm, and given that \\(\\pi(\\boldsymbol{\\theta} \\mid \\boldsymbol{y}) \\propto \\exp\\left\\{-\\frac{1}{2} \\boldsymbol{\\theta}^{\\top} \\boldsymbol{\\Sigma}^{-1} \\boldsymbol{\\theta}\\right\\}\\), then \\(\\frac{d \\log(\\pi(\\boldsymbol{\\theta} \\mid \\boldsymbol{y}))}{d \\boldsymbol{\\theta}} = -\\boldsymbol{\\Sigma}^{-1} \\boldsymbol{\\theta}\\). The following code shows how to implement the Gibbs sampler, the random walk M-H algorithm, and the HMC in this example such that the effective number of posterior draws is 400. rm(list = ls()); set.seed(010101) # Gibbs sampler Gibbs &lt;- function(theta, rho){ thetal &lt;- rnorm(1, mean = rho*theta, sd = (1- rho^2)^0.5) return(thetal) } # Metropolis-Hastings MH &lt;- function(theta, rho, sig2){ SIGMA &lt;- matrix(c(1, rho, rho, 1), 2, 2) SIGMAc &lt;- matrix(c(1, sig2, sig2, 1), 2, 2) thetac &lt;- MASS::mvrnorm(1, mu = theta, Sigma = SIGMAc) a &lt;- mvtnorm::dmvnorm(thetac, c(0, 0), SIGMA)/mvtnorm::dmvnorm(theta, c(0, 0), SIGMA) U &lt;- runif(1) if(U &lt;= a){ theta &lt;- thetac accept &lt;- 1 }else{ theta &lt;- theta accept &lt;- 0 } return(list(theta = theta, accept = accept)) } # Hamiltonian Monte Carlo HMC &lt;- function(theta, rho, epsilon, M){ SIGMA &lt;- matrix(c(1, rho, rho, 1), 2, 2) L &lt;- ceiling(1/epsilon) Minv &lt;- solve(M); thetat &lt;- theta K &lt;- length(thetat) mom &lt;- t(mvtnorm::rmvnorm(1, rep(0, K), M)) logPost_Mom_t &lt;- mvtnorm::dmvnorm(t(theta), rep(0, K), SIGMA, log = TRUE) + mvtnorm::dmvnorm(t(mom), rep(0, K), M, log = TRUE) for(l in 1:L){ if(l == 1 | l == L){ mom &lt;- mom + 0.5*epsilon*(-solve(SIGMA)%*%theta) theta &lt;- theta + epsilon*Minv%*%mom }else{ mom &lt;- mom + epsilon*(-solve(SIGMA)%*%theta) theta &lt;- theta + epsilon*Minv%*%mom } } logPost_Mom_star &lt;- mvtnorm::dmvnorm(t(theta), rep(0, K), SIGMA, log = TRUE) + mvtnorm::dmvnorm(t(mom), rep(0, K), M, log = TRUE) alpha &lt;- min(1, exp(logPost_Mom_star-logPost_Mom_t)) u &lt;- runif(1) if(u &lt;= alpha){ thetaNew &lt;- c(theta) }else{ thetaNew &lt;- thetat } rest &lt;- list(theta = thetaNew, Prob = alpha) return(rest) } # Hyperparameters rho &lt;- 0.98; sig2 &lt;- 0.18^2 # Posterior draws Gibbs and M-H S &lt;- 8000; thin &lt;- 20; K &lt;- 2 thetaPostGibbs &lt;- matrix(NA, S, K) thetaPostMH &lt;- matrix(NA, S, K) AcceptMH &lt;- rep(NA, S) thetaGibbs &lt;- c(-2, 3); thetaMH &lt;- c(-2, 3) for(s in 1:S){ theta1 &lt;- Gibbs(thetaGibbs[2], rho) theta2 &lt;- Gibbs(theta1, rho) thetaGibbs &lt;- c(theta1, theta2) ResMH &lt;- MH(thetaMH, rho, sig2) thetaMH &lt;- ResMH$theta thetaPostGibbs[s,] &lt;- thetaGibbs thetaPostMH[s,] &lt;- thetaMH AcceptMH[s] &lt;- ResMH$accept } keep &lt;- seq(0, S, thin) mean(AcceptMH[keep[-1]]) ## [1] 0.165 thetaPostGibbsMCMC &lt;- coda::mcmc(thetaPostGibbs[keep[-1],]) summary(thetaPostGibbsMCMC) ## ## Iterations = 1:400 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 400 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## [1,] 0.09561 0.9230 0.04615 0.06976 ## [2,] 0.09338 0.9258 0.04629 0.07029 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## var1 -1.748 -0.4606 0.07596 0.6520 1.937 ## var2 -1.652 -0.5319 0.10553 0.6702 1.881 coda::autocorr.plot(thetaPostGibbsMCMC) thetaPostMHMCMC &lt;- coda::mcmc(thetaPostMH[keep[-1],]) plot(thetaPostMHMCMC) coda::autocorr.plot(thetaPostMHMCMC) # Posterior draws HMC S &lt;- 400;epsilon &lt;- 0.05; L &lt;- ceiling(1/epsilon); M &lt;- diag(2) thetaPostHMC &lt;- matrix(NA, S, K) ProbAcceptHMC &lt;- rep(NA, S) thetaHMC &lt;- c(-2, 3) for(s in 1:S){ ResHMC &lt;- HMC(theta = thetaHMC, rho, epsilon, M) thetaHMC &lt;- ResHMC$theta thetaPostHMC[s,] &lt;- thetaHMC ProbAcceptHMC[s] &lt;- ResHMC$Prob } thetaPostHMCMCMC &lt;- coda::mcmc(thetaPostHMC) plot(thetaPostHMCMCMC); coda::autocorr.plot(thetaPostHMCMCMC) summary(ProbAcceptHMC) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.2422 0.8005 0.9705 0.8747 1.0000 1.0000 #Figure df &lt;- as.data.frame(cbind(1:S, thetaPostHMC[,1], thetaPostMH[keep[-1],1], thetaPostGibbs[keep[-1],1])) colnames(df) &lt;- c(&quot;Iter&quot;, &quot;HMC&quot;, &quot;MH&quot;, &quot;Gibbs&quot;) library(latex2exp); library(ggpubr) g1 &lt;- ggplot(df, aes(x= Iter)) + geom_point(aes(y=HMC), colour=&quot;black&quot;) + labs(x = &quot;Iteration&quot;, y = TeX(&quot;$\\\\theta_{1}$&quot;), title = &quot;HMC algorithm&quot;) g2 &lt;- ggplot(df, aes(x= Iter)) + geom_point(aes(y=MH), colour=&quot;black&quot;) + labs(x = &quot;Iteration&quot;, y = TeX(&quot;$\\\\theta_{1}$&quot;), title = &quot;M-H algorithm&quot;) g3 &lt;- ggplot(df, aes(x= Iter)) + geom_point(aes(y=Gibbs), colour=&quot;black&quot;) + labs(x = &quot;Iteration&quot;, y = TeX(&quot;$\\\\theta_{1}$&quot;), title = &quot;Gibbs sampling&quot;) ggarrange(g3, g2, g1, labels = c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;), ncol = 3, nrow = 1) The figure shows the posterior draws of \\(\\theta_1\\) using the Gibbs sampler (Panel A, left), the Metropolis-Hastings algorithm (Panel B, middle), and the Hamiltonian Monte Carlo (Panel C, right). The convergence diagnostic plots (no shown) suggests that the three algorithms perform a good job. Although, the acceptance rate in HMC is higher than the M-H due to the HMC producing larger changes in \\(\\boldsymbol{\\theta}\\) than a corresponding number of random-walk M-H iterations (Neal 2011). References "],["sec52.html", "4.2 Importance sampling", " 4.2 Importance sampling Up to this section, we have introduced MCMC methods for sampling from the posterior distribution when it does not have a standard closed form. However, MCMC methods have some limitations. First, the samples are generated sequentially, which complicates parallel computing. Although multiple MCMC chains can be run simultaneously, this approach—often referred to as brute-force parallelization—does not fully address the sequential nature of individual chains. Second, consecutive samples are correlated, which reduces the effective sample size and complicates convergence diagnostics. Thus, in this section, we introduce importance sampling (IS), a simulation method for drawing samples from the posterior distribution that avoids these limitations. Unlike MCMC, IS does not require satisfying the balancing condition, making it conceptually and mathematically simpler to implement in certain situations. Moreover, importance weights can be reused to analyze posterior quantities, compute marginal likelihoods, compare models, approximate new target distributions, and allow for straightforward parallelization in large-scale problems. However, the critical challenge in IS lies in selecting an appropriate proposal distribution. This involves satisfying both support and stability conditions, which can be difficult to achieve, particularly in high-dimensional problems. In such cases, MCMC methods may be more suitable. The starting point is evaluating the integral: \\[\\begin{align} \\mathbb{E}_{\\pi}[h(\\boldsymbol{\\theta})] &amp;= \\int_{\\Theta} h(\\boldsymbol{\\theta}) \\pi(\\boldsymbol{\\theta} \\mid y) d\\boldsymbol{\\theta}, \\tag{4.1} \\end{align}\\] where \\(\\mathbb{E}_{\\pi}\\) denotes expected value under the posterior distribution. Thus, we can approximate Equation (4.1) by \\[\\begin{align} \\bar{h}(\\boldsymbol{\\theta})_S &amp;= \\frac{1}{S} \\sum_{s=1}^S h(\\boldsymbol{\\theta}^{(s)}), \\tag{4.2} \\end{align}\\] where \\(\\boldsymbol{\\theta}^{(s)}\\) are draws from \\(\\pi(\\boldsymbol{\\theta} \\mid y)\\). The strong law of large numbers shows that \\(\\bar{h}(\\boldsymbol{\\theta})_S\\) converges (almost surely) to \\(\\mathbb{E}_{\\pi}[h(\\boldsymbol{\\theta})]\\) as \\(S \\to \\infty\\). The challenge arises when we do not know how to obtain samples from \\(\\pi(\\boldsymbol{\\theta}\\mid \\boldsymbol{y})\\). The ingenious idea is to express Equation (4.1) in a different way using the importance sampling fundamental identity (Christian P. Robert and Casella 2011): \\[\\begin{align} \\mathbb{E}_{\\pi}[h(\\boldsymbol{\\theta})] &amp;= \\int_{\\boldsymbol{\\Theta}} h(\\boldsymbol{\\theta}) \\pi(\\boldsymbol{\\theta}\\mid \\boldsymbol{y})\\frac{q(\\boldsymbol{\\theta})}{q(\\boldsymbol{\\theta})}d\\boldsymbol{\\theta} \\nonumber \\\\ &amp;= \\mathbb{E}_{q}\\left[\\frac{h(\\boldsymbol{\\theta})\\pi(\\boldsymbol{\\theta}\\mid \\boldsymbol{y})}{q(\\boldsymbol{\\theta})}\\right], \\tag{4.3} \\end{align}\\] where \\(q(\\boldsymbol{\\theta})\\) is the proposal distribution. Thus, we have \\[\\begin{align} \\frac{1}{S}\\sum_{s=1}^S \\left[\\frac{h(\\boldsymbol{\\theta}^{(s)})\\pi(\\boldsymbol{\\theta}^{(s)}\\mid \\boldsymbol{y})}{q(\\boldsymbol{\\theta}^{(s)})}\\right] &amp;= \\frac{1}{S}\\sum_{s=1}^S h(\\boldsymbol{\\theta}^{(s)})w(\\boldsymbol{\\theta}^{(s)}), \\end{align}\\] where \\(w(\\boldsymbol{\\theta}^{(s)})= \\left[\\frac{\\pi(\\boldsymbol{\\theta}^{(s)}\\mid \\boldsymbol{y})}{q(\\boldsymbol{\\theta}^{(s)})}\\right]\\) are called the importance weights, and \\(\\boldsymbol{\\theta}^{(s)}\\) are samples from the proposal distribution. This expression converges to \\(\\mathbb{E}_{\\pi}[h(\\boldsymbol{\\theta})]\\) given that the support of \\(q(\\boldsymbol{\\theta})\\) includes the support of \\(\\pi(\\boldsymbol{\\theta}\\mid \\boldsymbol{y})\\). There are many proposal distributions that satisfy the support condition. However, the stability of the method depends heavily on the variability of the importance weights. In particular, the variance of \\[\\begin{align} \\frac{1}{S}\\sum_{s=1}^S h(\\boldsymbol{\\theta}^{(s)})w(\\boldsymbol{\\theta}^{(s)}) \\end{align}\\] can be large if the proposal distribution has lighter tails than the posterior distribution. In this case, the weights \\(w(\\boldsymbol{\\theta}^{(s)})\\) will vary widely, assigning too much importance to a few values of \\(\\boldsymbol{\\theta}^{(s)}\\). Thus, it is important to use proposals that have thicker tails than the posterior distribution. In any case, we should check the adequacy of the proposal distribution by analyzing the behavior of the importance weights. If they are distributed more or less uniformly over the support, it is a good sign. Consider, for instance, the extreme case where \\(q(\\boldsymbol{\\theta}) = \\pi(\\boldsymbol{\\theta}\\mid \\boldsymbol{y})\\), then \\(w(\\boldsymbol{\\theta}^{(s)}) = 1\\) everywhere. A natural choice in Bayesian inference is to use the prior distribution as the proposal, given that it is a proper density function. The prior distribution typically has heavier tails than the posterior by construction, and it is usually a distribution that allows for easy sampling. The most relevant point for us is that importance sampling provides a way to simulate from the posterior distribution when there is no closed-form solution. The method generates samples \\(\\boldsymbol{\\theta}^{(s)}\\) from \\(q(\\boldsymbol{\\theta})\\) and computes the importance weights \\(w(\\boldsymbol{\\theta}^{(s)})\\). Thus, if we resample with replacement from \\(\\boldsymbol{\\theta}^{(1)},\\boldsymbol{\\theta}^{(2)},\\dots,\\boldsymbol{\\theta}^{(S)}\\), selecting \\(\\boldsymbol{\\theta}^{(s)}\\) with probability proportional to \\(w(\\boldsymbol{\\theta}^{(s)})\\), we would get a sample \\(\\boldsymbol{\\theta}^{*(1)},\\boldsymbol{\\theta}^{*(2)},\\dots,\\boldsymbol{\\theta}^{*(L)}\\) of size \\(L\\) from \\(\\pi(\\boldsymbol{\\theta}\\mid \\boldsymbol{y})\\) (A. F. Smith and Gelfand 1992; Donald B. Rubin 1988). This is named sampling/importance resampling (SIR) algorithm. Observe that the number of times \\(L^{(s)}\\) each particular point \\(\\boldsymbol{\\theta}^{(s)}\\) is selected follows a binomial distribution with size \\(L\\), and probabilities proportional to \\(w^{(s)}\\). Consequently, the vector \\(L_{\\boldsymbol{\\theta}} = \\left\\{L_{\\boldsymbol{\\theta}^1}, L_{\\boldsymbol{\\theta}^2}, \\dots, L_{\\boldsymbol{\\theta}^S}\\right\\}\\) follows a multinomial distribution with \\(L\\) trials and probabilities proportional to \\(w(\\boldsymbol{\\theta}^{(s)})\\), \\(s = 1, 2, \\dots, S\\) (Olivier Cappé, Godsill, and Moulines 2007). Therefore, the resampling step ensures that points in the first-stage sample with small importance weights are more likely to be discarded, while points with high weights are replicated in proportion to their importance weights. In most applications, it is typical to have \\(S \\gg L\\). The intuition is that importance weights are scaling factors that correct for the bias introduced by drawing from \\(q(\\boldsymbol{\\theta}^{(s)})\\) instead of \\(\\pi(\\boldsymbol{\\theta}^{(s)}\\mid \\boldsymbol{y})\\); thus, when combined, the samples and weights effectively recreate the posterior distribution, ensuring the resampled data set reflects the posterior. Let’s prove this: \\[\\begin{align*} P(\\boldsymbol{\\theta}^*\\in A) &amp;=\\frac{1}{S}\\sum_{s=1}^S{w}^{(s)}\\mathbb{1}_{A}(\\boldsymbol{\\theta}^{(s)})\\\\ &amp;\\rightarrow \\mathbb{E}_q\\left[\\mathbb{1}_{\\in A}(\\boldsymbol{\\theta})\\frac{\\pi(\\boldsymbol{\\theta}\\mid \\boldsymbol{y})}{q(\\boldsymbol{\\theta})}\\right]\\\\ &amp;=\\int_{A}\\left[\\frac{\\pi(\\boldsymbol{\\theta}\\mid \\boldsymbol{y})}{q(\\boldsymbol{\\theta})}\\right]q(\\boldsymbol{\\theta})d\\boldsymbol{\\theta}\\\\ &amp;=\\int_{A}\\pi(\\boldsymbol{\\theta}\\mid \\boldsymbol{y})d\\boldsymbol{\\theta}. \\end{align*}\\] Thus, \\(\\boldsymbol{\\theta}^*\\) is approximately distributed as an observation from \\(\\pi(\\boldsymbol{\\theta}\\mid \\boldsymbol{y})\\). However, the weights \\(\\pi(\\boldsymbol{\\theta}^{(s)}\\mid \\boldsymbol{y})/(S q(\\boldsymbol{\\theta}^{(s)}))\\) do not sum up to 1, and we need to standardize them: \\[ w^*(\\boldsymbol{\\theta}^{(s)})=\\frac{\\frac{1}{S} w(\\boldsymbol{\\theta}^{(s)})}{\\frac{1}{S}\\sum_{s=1}^S w(\\boldsymbol{\\theta}^{(s)})}. \\] Note that we could alternatively arrive at these weights as follows: \\[\\begin{align*} \\mathbb{E}_{\\pi}[h(\\boldsymbol{\\theta})]&amp;=\\int_{\\boldsymbol{\\Theta}} \\left[\\frac{h(\\boldsymbol{\\theta}) \\pi(\\boldsymbol{\\theta}\\mid \\boldsymbol{y})}{q(\\boldsymbol{\\theta})}\\right]q(\\boldsymbol{\\theta})d\\boldsymbol{\\theta}\\\\ &amp;=\\frac{\\int_{\\boldsymbol{\\Theta}}\\left[\\frac{h(\\boldsymbol{\\theta}) \\pi(\\boldsymbol{\\theta}\\mid \\boldsymbol{y})}{q(\\boldsymbol{\\theta})}\\right] q(\\boldsymbol{\\theta})d\\boldsymbol{\\theta}}{\\int_{\\boldsymbol{\\Theta}}\\left[\\frac{ \\pi(\\boldsymbol{\\theta}\\mid \\boldsymbol{y})}{q(\\boldsymbol{\\theta})}\\right] q(\\boldsymbol{\\theta})d\\boldsymbol{\\theta}}. \\end{align*}\\] Then, \\[ \\frac{\\frac{1}{S}\\sum_{s=1}^S h(\\boldsymbol{\\theta}^{(s)})w(\\boldsymbol{\\theta}^{(s)})}{\\frac{1}{S}\\sum_{s=1}^S w(\\boldsymbol{\\theta}^{(s)})}= \\sum_{s=1}^S h(\\boldsymbol{\\theta}^{(s)})w^*(\\boldsymbol{\\theta}^{(s)}). \\] This alternative expression also converges (almost surely) to \\(\\mathbb{E}_{\\pi}[h(\\boldsymbol{\\theta})]\\). In addition, this expression is very useful because if we do not have the marginal likelihood in the posterior distribution, this constant cancels out in \\(w^*(\\boldsymbol{\\theta}^{(s)})\\). Although this estimator is biased, the bias is small and provides good gains in variance reduction compared with the non-standardized option (Christian P. Robert and Casella 2011). A nice by-product of implementing IS is that it easily allows the calculation of the marginal likelihood. In particular, we know from Bayes’ rule that \\[ p(\\boldsymbol{y})^{-1}=\\frac{\\pi(\\boldsymbol{\\theta}\\mid \\boldsymbol{y})}{p(\\boldsymbol{y}\\mid \\boldsymbol{\\theta})\\times \\pi(\\boldsymbol{\\theta})}, \\] then, \\[\\begin{align*} \\int_{\\boldsymbol{\\Theta}}p(\\boldsymbol{y})^{-1}q(\\boldsymbol{\\theta})d\\boldsymbol{\\theta} &amp;=\\int_{{\\Theta}}\\frac{q(\\boldsymbol{\\theta})}{p(\\boldsymbol{y}\\mid \\boldsymbol{\\theta})\\times \\pi(\\boldsymbol{\\theta})}\\pi(\\boldsymbol{\\theta}\\mid \\boldsymbol{y})d\\boldsymbol{\\theta}\\\\ &amp;=\\mathbb{E}_{\\pi}\\left[\\frac{q(\\boldsymbol{\\theta})}{p(\\boldsymbol{y}\\mid \\boldsymbol{\\theta})\\times \\pi(\\boldsymbol{\\theta})}\\right]. \\end{align*}\\] Thus, an estimate of the marginal likelihood is \\[ \\left[\\frac{1}{S}\\sum_{s=1}^S\\frac{q(\\boldsymbol{\\theta}^{*(s)})}{p(\\boldsymbol{y}\\mid \\boldsymbol{\\theta}^{*(s)})\\times\\pi(\\boldsymbol{\\theta}^{*(s)})}\\right]^{-1}. \\] This is the Gelfand-Dey method to calculate the marginal likelihood (Alan E. Gelfand and Dey 1994). Example: Cauchy distribution Let’s assume that the posterior distribution is Cauchy with parameters 0 and 1. We perform an importance sampling algorithm using as proposals a standard normal distribution and a Student’s t distribution with 3 degrees of freedom. The following code shows how to do this. rm(list = ls()); set.seed(010101) S &lt;- 20000 # Size proposal # Importance sampling from standard normal proposal thetaNs &lt;- rnorm(S) wNs &lt;- dcauchy(thetaNs)/dnorm(thetaNs) wNstars &lt;- wNs/sum(wNs) L &lt;- 10000 # Size posterior thetaCauchyN &lt;- sample(thetaNs, L, replace = TRUE, prob = wNstars) h &lt;- hist(thetaCauchyN, breaks=50, col=&quot;blue&quot;, xlab=&quot;x&quot;, main=&quot;Cauchy draws from importance sampling: Normal standard proposal&quot;) pfit &lt;- seq(min(thetaCauchyN),max(thetaCauchyN),length=50) yfit&lt;-dcauchy(pfit) yfit &lt;- yfit*diff(h$mids[1:2])*length(thetaCauchyN) lines(pfit, yfit, col=&quot;red&quot;, lwd=2) # Importance sampling from Student&#39;s t proposal df &lt;- 3 thetaTs &lt;- rt(S, df = df) wTs &lt;- dcauchy(thetaTs)/dt(thetaTs, df = df) wTstars &lt;- wTs/sum(wTs) thetaCauchyT &lt;- sample(thetaTs, L, replace = TRUE, prob = wTstars) h &lt;- hist(thetaCauchyT, breaks=50, col=&quot;blue&quot;, xlab=&quot;x&quot;, main=&quot;Cauchy draws from importance sampling: Student&#39;s t proposal&quot;) pfit &lt;- seq(min(thetaCauchyT),max(thetaCauchyT),length=50) yfit&lt;-dcauchy(pfit) yfit &lt;- yfit*diff(h$mids[1:2])*length(thetaCauchyT) lines(pfit, yfit, col=&quot;red&quot;, lwd=2) plot(wNstars, main = &quot;Importance sampling: Cauchy distribution&quot;, ylab = &quot;Weights&quot;, xlab = &quot;Iterations&quot;) points(wTstars, col = &quot;blue&quot;) legend(&quot;topright&quot;, legend = c(&quot;Normal&quot;, &quot;Student&#39;s t&quot;), col = c(&quot;black&quot;, &quot;blue&quot;), pch = c(1, 1)) The first and second figures show the histograms of the posterior draws using the normal and Student’s t-distributions, respectively, along with the density of the Cauchy distribution. The spike in the posterior draws from the standard normal proposal arises due to the lighter tails of the standard normal compared to the Cauchy distribution, consequently assigning too much weight to a specific draw from the normal distribution. The third figure shows the weights using the standard normal distribution (black dots) and the Student’s t-distribution with 3 degrees of freedom (blue dots) as proposals. We observe that a few draws carry too much weight when using the normal proposal; this occurs because the normal distribution has much lighter tails compared to the Cauchy distribution. In contrast, using the Student’s t-distribution with 3 degrees of freedom improves this situation. References "],["sec53.html", "4.3 Particle filtering", " 4.3 Particle filtering Now, we consider the scenario where we need to sample from a posterior distribution whose dimension increases over time, \\(\\pi(\\boldsymbol{\\theta}_{0:t}\\mid \\boldsymbol{y}_{0:t})\\), for \\(t = 0, 1, \\dots\\). The challenge arises from the fact that, even if this posterior distribution is known, the computational complexity of implementing a sampling scheme in this context increases linearly with \\(t\\). This makes MCMC methods, which operate in batch mode and require a complete re-run whenever new information becomes available, less optimal. Consequently, we present sequential algorithms, which operate incrementally as new data becomes available, and are often a better alternative. These algorithms are typically faster and are well-suited for scenarios requiring real-time updates, commonly referred to as online mode. Specifically, we consider the dynamic system in the state-space representation. This is a system where there is an unobservable state vector \\(\\boldsymbol{\\theta}_t\\in\\mathbb{R}^K\\), and an observed variable \\(\\boldsymbol{Y}_t\\), \\(t=0,1,\\dots\\) such that: \\(\\boldsymbol{\\theta}_t\\) is a Markov process, that is, \\[ \\pi(\\boldsymbol{\\theta}_{t}\\mid \\boldsymbol{\\theta}_{1:t-1})=\\pi(\\boldsymbol{\\theta}_{t}\\mid \\boldsymbol{\\theta}_{t-1}), \\] for \\(t=1,2,\\dots\\). All the relevant information to define \\(\\boldsymbol{\\theta}_{t}\\) is in \\(\\boldsymbol{\\theta}_{t-1}\\).23 \\(\\boldsymbol{Y}_t\\perp \\boldsymbol{Y}_s\\mid \\boldsymbol{\\theta}_{t}\\), for \\(s&lt;t\\). That is, there is independence between observable variables regarding their history conditional on the actual state vector. We can see in the next figure a graphical representation of the dynamic system. Formally, \\[ \\begin{aligned} \\boldsymbol{\\theta}_t &amp;= h(\\boldsymbol{\\theta}_{t-1}, \\boldsymbol{w}_t) &amp; \\text{(State equations)}\\\\ Y_t &amp; = f(\\boldsymbol{\\theta}_t, \\mu_t)&amp; \\text{(Observation equation)}, \\end{aligned} \\] where \\(\\boldsymbol{w}_t\\) and \\(\\mu_t\\) are stochastic errors such that their probability distributions define the transition density \\(\\pi(\\boldsymbol{\\theta}_t\\mid \\boldsymbol{\\theta}_{t-1})\\) and observation density \\(p(Y_t\\mid \\boldsymbol{\\theta}_t)\\). We present particle filtering, a specific case of sequential Monte Carlo (SMC), which is one of the most commonly used algorithms for scenarios requiring sequential updates of the posterior distribution as described by the state-space model. The starting point is sequential importance sampling (SIS), originally proposed by Handschin and Mayne (1969), which is a modification of IS to compute an estimate of \\(\\pi(\\boldsymbol{\\theta}_{0:t}\\mid \\boldsymbol{y}_{0:t})\\) without altering the past trajectories \\(\\left\\{\\boldsymbol{\\theta}^{(s)}_{1:t-1}, s=1,2,\\dots,S\\right\\}\\). The key idea is to use a proposal density that takes the form \\[ \\begin{aligned} q(\\boldsymbol{\\theta}_{0:t}\\mid \\boldsymbol{y}_{0:t}) &amp;= q(\\boldsymbol{\\theta}_{0:t-1}\\mid \\boldsymbol{y}_{1:t-1})q(\\boldsymbol{\\theta}_t\\mid \\boldsymbol{\\theta}_{t-1},\\boldsymbol{y}_{t}) \\\\ &amp;= q(\\boldsymbol{\\theta}_0)\\prod_{h=1}^{t}q(\\boldsymbol{\\theta}_h\\mid \\boldsymbol{\\theta}_{h-1},\\boldsymbol{y}_{h}). \\end{aligned} \\] This proposal density allows calculating the weights sequentially, \\[ \\begin{aligned} w_{t}(\\boldsymbol{\\theta}^{(s)}_{0:t})&amp;=\\frac{\\pi(\\boldsymbol{\\theta}_{0:t}^{(s)}\\mid \\boldsymbol{y}_{0:t})}{q(\\boldsymbol{\\theta}_{0:t}^{(s)}\\mid \\boldsymbol{y}_{0:t})}\\\\ &amp;=\\frac{p(\\boldsymbol{y}_{0:t}\\mid \\boldsymbol{\\theta}_{0:t}^{(s)})\\pi(\\boldsymbol{\\theta}_{0:t}^{(s)})}{p(\\boldsymbol{y}_{0:t})q(\\boldsymbol{\\theta}_{0:t}^{(s)}\\mid \\boldsymbol{y}_{0:t})}\\\\ &amp;=\\frac{p(\\boldsymbol{y}_{t}\\mid \\boldsymbol{\\theta}_{t}^{(s)})p(\\boldsymbol{y}_{1:t-1}\\mid \\boldsymbol{\\theta}_{0:t-1}^{(s)})\\pi(\\boldsymbol{\\theta}_{t}^{(s)}\\mid \\boldsymbol{\\theta}_{t-1}^{(s)})\\pi(\\boldsymbol{\\theta}_{0:t-1}^{(s)})}{p(\\boldsymbol{y}_{0:t})q(\\boldsymbol{\\theta}_{t}^{(s)}\\mid \\boldsymbol{\\theta}_{t-1},\\boldsymbol{y}_{t}^{(s)})q(\\boldsymbol{\\theta}_{0:t-1}^{(s)}\\mid \\boldsymbol{y}_{1:t-1})}\\\\ &amp;\\propto w_{t-1}^*(\\boldsymbol{\\theta}^{(s)}_{0:t-1})\\frac{p(\\boldsymbol{y}_{t}\\mid \\boldsymbol{\\theta}_{t}^{(s)})\\pi(\\boldsymbol{\\theta}_{t}\\mid \\boldsymbol{\\theta}_{t-1}^{(s)})}{q(\\boldsymbol{\\theta}_t^{(s)}\\mid \\boldsymbol{\\theta}_{t-1}^{(s)},\\boldsymbol{y}_{t})}. \\end{aligned} \\] Take into account that \\(p(\\boldsymbol{y}_{0:t})\\) does not depend on \\(\\boldsymbol{\\theta}^{(s)}_{0:t}\\). The term \\(\\alpha_t(\\boldsymbol{\\theta}_{0:t}^{(s)})=\\frac{p(\\boldsymbol{y}_{t}\\mid \\boldsymbol{\\theta}_{t}^{(s)})\\pi(\\boldsymbol{\\theta}_{t}\\mid \\boldsymbol{\\theta}_{t-1}^{(s)})}{q(\\boldsymbol{\\theta}_t^{(s)}\\mid \\boldsymbol{\\theta}_{t-1}^{(s)},\\boldsymbol{y}_{t})}\\) is called the incremental importance weight, and implies that \\[ w_t(\\boldsymbol{\\theta}^{s}_{0:t})=w_0(\\boldsymbol{\\theta}^{s}_{0})\\prod_{h=1}^{t}\\alpha_h(\\boldsymbol{\\theta}_{1:h}^{(s)}). \\] This algorithm possesses the desirable property of maintaining fixed computational complexity. Consequently, we sequentially obtain draws \\(\\boldsymbol{\\theta}_t^{(s)}\\), referred to as particles: \\(\\boldsymbol{\\theta}_0^{(s)}\\) is drawn from \\(q(\\boldsymbol{\\theta}_0)\\) at \\(t=0\\), and subsequently, \\(\\boldsymbol{\\theta}_h^{(s)}\\) is drawn from \\(q(\\boldsymbol{\\theta}_h\\mid \\boldsymbol{\\theta}_{h-1},\\boldsymbol{y}_{h})\\) at \\(t=h\\) (Doucet, De Freitas, and Gordon 2001; Olivier Cappé, Godsill, and Moulines 2007). A relevant case is when the proposal distribution takes the form of the prior distribution, that is, \\[ q(\\boldsymbol{\\theta}_{0:t}\\mid \\boldsymbol{y}_{0:t}) = \\pi(\\boldsymbol{\\theta}_{0:t}) = \\pi(\\boldsymbol{\\theta}_0)\\prod_{h=1}^{t}\\pi(\\boldsymbol{\\theta}_h\\mid \\boldsymbol{\\theta}_{h-1}). \\] This implies that \\[ w_{t}(\\boldsymbol{\\theta}^{(s)}_{0:t})\\propto w_{t-1}^*(\\boldsymbol{\\theta}^{(s)}_{0:t-1})p(\\boldsymbol{y}_{t}\\mid \\boldsymbol{\\theta}_{t}^{(s)}), \\] which means that the incremental importance weight is given by \\(p(\\boldsymbol{y}_{t}\\mid \\boldsymbol{\\theta}_{t}^{(s)})\\). Algorithm 4 shows how to perform SIS (Olivier Cappé, Godsill, and Moulines 2007). We set \\(w_t^{(s)}:=w_t(\\boldsymbol{\\theta}_{0:t}^{(s)})\\) to simplify notation. Algorithm: Sequential importance sampling For s=1,2,...,S do Sample θ0(s) from q(θ0|y0) Calculate the importance weights w0(s) ∝(p(y0|θ0(s))π(θ0(s)))/q(θ0(s)|y0) End for for t=1,2,...,T do for s=1,2,...,S do Draw particles θt(s) from qt(θt|θt-1,y0) Compute the weights wt(s) ∝ wt-1*(s) (p(yt|θt(s))π(θt(s)|θt-1(s)))/q(θt(s)|θt-1(s),yt) End for Standardize the weights wt*(s) = wt(s)/(∑hwt(h)), s=1,2,...,S End for Example: Dynamic linear model Let’s assume that the state-space representation is \\[ \\theta_t = \\theta_{t-1} + w_t \\quad \\text{(State equation)} \\\\ Y_t = \\phi \\theta_t + \\mu_t \\quad \\text{(Observation equation)}, \\] where \\(w_t \\sim N(0, \\sigma_w^2)\\) and \\(\\mu_t \\sim N(0, \\sigma_{\\mu}^2)\\), \\(t = 1, 2, \\dots, 50\\). In addition, we use the proposal distribution \\(q(\\theta_t \\mid y_t) = \\pi(\\theta_t)\\), which is normal with mean \\(\\theta_{t-1}\\) and variance \\(\\sigma_w^2\\). Then, the weights are given by the recursion \\[ w_t^{(s)} \\propto w_{t-1}^{*(s)} p(y_t \\mid \\theta_t, \\sigma_{\\mu}^2), \\] where \\(p(y_t \\mid \\theta_t, \\sigma_{\\mu}^2)\\) is \\(N(\\phi \\theta_t, \\sigma_{\\mu}^2)\\). We can compute the mean and standard deviation of the state at each \\(t\\) using \\[ \\hat{\\theta}_t = \\sum_{s=1}^S w_t^{*(s)} \\theta_t^{(s)} \\] and \\[ \\hat{\\sigma}_{\\theta} = \\left(\\sum_{s=1}^S w_t^{*(s)} \\theta_t^{2(s)} - \\hat{\\theta}_t^2\\right)^{1/2}. \\] The following code demonstrates the implementation of this algorithm, setting \\(\\sigma_w^2 = \\sigma_{\\mu}^2 = 1\\) and \\(\\phi = 0.5\\). First, we simulate the process, and then we implement the SIS algorithm. rm(list = ls()); set.seed(010101) S &lt;- 50000 # Number of particles sigma_w &lt;- 1 # State noise sigma_mu &lt;- 1 # Observation noise phi &lt;- 0.5 # Coefficient in observation equation T &lt;- 50 # Sample size # Simulate true states and observations theta_true &lt;- numeric(T); y_obs &lt;- numeric(T) theta_true[1] &lt;- rnorm(1, mean = 0, sd = sigma_w) # Initial state for (t in 2:T) { theta_true[t] &lt;- rnorm(1, mean = theta_true[t-1], sd = sigma_w) } y_obs &lt;- rnorm(T, mean = phi*theta_true, sd = sigma_mu) # Sequential Importance Sampling (SIS) particles &lt;- matrix(0, nrow = S, ncol = T) weights &lt;- matrix(0, nrow = S, ncol = T) weightsSt &lt;- matrix(0, nrow = S, ncol = T) # Initialization particles[, 1] &lt;- rnorm(S, mean = 0, sd = sigma_w) # Sample initial particles weights[, 1] &lt;- dnorm(y_obs[1], mean = phi*particles[, 1], sd = sigma_mu) # Importance weights weightsSt[, 1] &lt;- weights[, 1] / sum(weights[, 1]) # Standardized weights # Sequential updating for (t in 2:T) { # Propagate particles particles[, t] &lt;- rnorm(S, mean = particles[, t-1], sd = sigma_w) # Compute weights weights[, t] &lt;- weightsSt[, t-1] * dnorm(y_obs[t], mean = phi*particles[, t], sd = sigma_mu) # Recursive weight update weightsSt[, t] &lt;- weights[, t] / sum(weights[, t]) # Normalize weights } # Estimate the states (weighted mean) FilterDist &lt;- colSums(particles * weightsSt) SDFilterDist &lt;- (colSums(particles^2 * weightsSt) - FilterDist^2)^0.5 library(dplyr); library(ggplot2); library(latex2exp) ## ## Attaching package: &#39;dplyr&#39; ## The following objects are masked from &#39;package:stats&#39;: ## ## filter, lag ## The following objects are masked from &#39;package:base&#39;: ## ## intersect, setdiff, setequal, union ggplot2::theme_set(theme_bw()) df &lt;- tibble(t = 1:T, mean = FilterDist, lower = FilterDist - 2*SDFilterDist, upper = FilterDist + 2*SDFilterDist, theta_true = theta_true) # Function to plot plot_filtering_estimates &lt;- function(df) { p &lt;- ggplot(data = df, aes(x = t)) + geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 1, fill = &quot;lightblue&quot;) + geom_line(aes(y = theta_true), colour = &quot;black&quot;, alpha = 1, linewidth = 0.5) + geom_line(aes(y = mean), colour = &quot;blue&quot;, linewidth = 0.5) + ylab(TeX(&quot;$\\\\theta_{t}$&quot;)) + xlab(&quot;Time&quot;) print(p) } plot_filtering_estimates(df) The figure shows the trajectory of the true state vector (black line), the posterior mean (blue line), and the area defined by \\(\\pm2\\hat{\\sigma}_{\\theta}\\) (light blue shaded area). Sequential importance sampling is effective for sampling from the posterior distribution in the short term. However, it is important to note that SIS is a particular case of IS and, consequently, inherits the drawbacks of importance sampling. In particular, the variance of the weights increases exponentially with \\(t\\) (Kong, Liu, and Wong 1994). This implies that, as \\(t\\) increases, the importance weights tend to degenerate in the long run; that is, all probability mass concentrates on a few weights, a phenomenon known as sample impoverishment or weight degeneracy. This is because it is impossible to accurately represent a distribution on a space of arbitrarily high dimension with a sample of fixed, finite size. This phenomenon can be observed, for instance, in the dynamic linear model example, where the highest standardized weight at \\(t = 50\\) is 53%, and 7 out of 50,000 particles account for 87% of the total probability. Given that, in practice, we are often interested in lower-dimensional marginal distributions, ideas from sampling/importance resampling can be employed. This strategy avoids the accumulation of errors due to resetting the system, although resampling introduces some additional Monte Carlo variation. Gordon, Salmond, and Smith (1993) proposed the Bootstrap filter, where, at each time step, resampling is performed by drawing \\(S\\) particles from the current set using the standardized weights as probabilities of selection. This ensures that particles with small weights have a low probability of being selected. After resampling, the standardized weights are set equal to \\(1/S\\). Note that the Bootstrap filter involves multiple iterations of the SIR algorithm, which implies that the resampled trajectories are no longer independent. This multinomial resampling provides an unbiased approximation to the posterior distribution obtained by SIS (Doucet, Johansen, et al. 2009). Algorithm 5 shows how to perform the particle filter. We set \\(w_t^{(s)} := w_t(\\boldsymbol{\\theta}_{0:t}^{(s)})\\) to simplify notation (Doucet, Johansen, et al. 2009). Algorithm: Particle filter For s=1,2,...,S do Sample θ0(s) from q(θ0|y0) Calculate the importance weights w0(s) ∝(p(y0|θ0(s))π(θ0(s)))/q(θ0(s)|y0) End for Standardize the weights w0*(s) = w0(s)/(∑hw0(h)), s=1,2,...,S Select S particle from {θ0(s),w0*(s)} to obtain {θ0r(s),1/S} for t=1,2,...,T do for s=1,2,...,S do Draw particles θt(s) from qt(θt|θt-1,y0) Set θ1:t(s) ← (θ1:t-1r(s), θt(s)) Compute the weights αt(s) = (p(yt|θt(s))π(θt(s)|θt-1(s)))/q(θt(s)|θt-1(s),yt) End for Standardize the weights wt*(s) = wt(s)/(∑hwt(h)), s=1,2,...,S Select S particle from {θ1:t(s),wt*(s)} to obtain {θ1:tr(s),1/S} End for Example: Dynamic linear model continues If we apply the SIS algorithm to the dynamic linear model with a sample size of 200, the algorithm’s performance deteriorates as \\(t\\) increases. This is due to particle degeneration; at \\(t=200\\), a single particle holds a weight close to 100%. Let’s perform particle filtering in this example. The following code illustrate the procedure. The figure shows the performance of particle filtering in this example. There is the true state vector (black line), the means based on \\(\\left\\{\\boldsymbol{\\theta}_{1:t}^{(s)},w_t^{*(s)}\\right\\}\\) (blue line) and \\(\\left\\{\\boldsymbol{\\theta}_{1:t}^{r(s)},1/S\\right\\}\\) (purple line), and the area defined by \\(\\pm2\\hat{\\sigma}_{\\theta}\\) based on the former (light blue shaded area). Note that the particle filtering algorithm has better performance than the SIS algorithm. rm(list = ls()); set.seed(010101) S &lt;- 50000 # Number of particles sigma_w &lt;- 1; sigma_mu &lt;- 1 # # State and observation noises phi &lt;- 0.5 # Coefficient in observation equation T &lt;- 200 # Sample size # Simulate true states and observations theta_true &lt;- numeric(T); y_obs &lt;- numeric(T) theta_true[1] &lt;- rnorm(1, mean = 0, sd = sigma_w) for (t in 2:T) { theta_true[t] &lt;- rnorm(1, mean = theta_true[t-1], sd = sigma_w) } y_obs &lt;- rnorm(T, mean = phi*theta_true, sd = sigma_mu) # Particle filtering particles &lt;- matrix(0, nrow = S, ncol = T) # Store particles particlesT &lt;- matrix(0, nrow = S, ncol = T) # Store resampling particles weights &lt;- matrix(0, nrow = S, ncol = T) # Store weights weightsSt &lt;- matrix(0, nrow = S, ncol = T) # Store standardized weights weightsSTT &lt;- matrix(1/S, nrow = S, ncol = T) # Store standardized weights logalphas &lt;- matrix(0, nrow = S, ncol = T) # Store log incremental weights particles[, 1] &lt;- rnorm(S, mean = 0, sd = sigma_w) weights[, 1] &lt;- dnorm(y_obs[1], mean = phi*particles[, 1], sd = sigma_mu) # Importance weights weightsSt[, 1] &lt;- weights[, 1] / sum(weights[, 1]) # Normalize weights ind &lt;- sample(1:S, size = S, replace = TRUE, prob = weightsSt[, 1]) # Resample particles[, 1] &lt;- particles[ind, 1] # Resampled particles particlesT[, 1] &lt;- particles[, 1] # Resampled particles # Sequential updating pb &lt;- winProgressBar(title = &quot;progress bar&quot;, min = 0, max = T, width = 300) for (t in 2:T) { particles[, t] &lt;- rnorm(S, mean = particles[, t-1], sd = sigma_w) logalphas[, t] &lt;- dnorm(y_obs[t], mean = phi*particles[, t], sd = sigma_mu, log = TRUE) weights[, t] &lt;- exp(logalphas[, t]) weightsSt[, t] &lt;- weights[, t] / sum(weights[, t]) if(t &lt; T){ ind &lt;- sample(1:S, size = S, replace = TRUE, prob = weightsSt[, t]) particles[, 1:t] &lt;- particles[ind, 1:t] }else{ ind &lt;- sample(1:S, size = S, replace = TRUE, prob = weightsSt[, t]) particlesT[, 1:t] &lt;- particles[ind, 1:t] } setWinProgressBar(pb, t, title=paste( round(t/T*100, 0), &quot;% done&quot;)) } close(pb) ## NULL FilterDist &lt;- colSums(particles * weightsSt) SDFilterDist &lt;- (colSums(particles^2 * weightsSt) - FilterDist^2)^0.5 FilterDistT &lt;- colSums(particlesT * weightsSTT) SDFilterDistT &lt;- (colSums(particlesT^2 * weightsSTT) - FilterDistT^2)^0.5 MargLik &lt;- colMeans(weights) plot(MargLik, type = &quot;l&quot;) library(dplyr) library(ggplot2) require(latex2exp) ggplot2::theme_set(theme_bw()) df &lt;- tibble(t = 1:T, mean = FilterDist, lower = FilterDist - 2*SDFilterDist, upper = FilterDist+ 2*SDFilterDist, meanT = FilterDistT, lowerT = FilterDistT - 2*SDFilterDistT, upperT = FilterDistT + 2*SDFilterDistT, x_true = theta_true) plot_filtering_estimates &lt;- function(df) { p &lt;- ggplot(data = df, aes(x = t)) + geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 1, fill = &quot;lightblue&quot;) + geom_line(aes(y = x_true), colour = &quot;black&quot;, alpha = 1, linewidth = 0.5) + geom_line(aes(y = mean), colour = &quot;blue&quot;, linewidth = 0.5) + geom_line(aes(y = meanT), colour = &quot;purple&quot;, linewidth = 0.5) + ylab(TeX(&quot;$\\\\theta_{t}$&quot;)) + xlab(&quot;Time&quot;) print(p) } plot_filtering_estimates(df) Algorithm 5 performs resampling at every time step. However, it is common to perform resampling only when the effective sample size of the particles (\\(ESS = (\\sum_{s=1}^S (w_t^{*(s)})^{2})^{-1}\\)) falls below a specific threshold, such as 50% of the initial number of particles. Note that when \\(w_t^{*(s)} = 1/S\\), the effective sample size is \\(S\\), the total number of particles. Additionally, we should use \\(\\left\\{\\boldsymbol{\\theta}_{1:t}^{(s)}, w_t^{*(s)}\\right\\}\\) to estimate the posterior distribution, as it results in lower Monte Carlo error compared to calculations based on \\(\\left\\{\\boldsymbol{\\theta}_{1:t}^{r(s)}, 1/S\\right\\}\\) (Olivier Cappé, Godsill, and Moulines 2007). Finally, an estimate of the marginal likelihood can be obtained using \\[ \\hat{p}(y_t) = \\frac{1}{S}\\sum_{s=1}^S w_t^{(s)}. \\] Particle filtering offers several advantages, such as being quick and easy to implement, its modularity—allowing one to simply adjust the expressions for the importance distribution and weights when changing the problem—and its suitability for parallel algorithms. Moreover, it enables straightforward sequential inference for very complex models. However, there are also disadvantages. The resampling step introduces extra Monte Carlo variability. Using the state transition (prior) density as the importance distribution often leads to poor performance, manifested in a lack of robustness with respect to the observed sequence. For instance, performance deteriorates when outliers occur in the data or when the variance of the observation noise is small. Furthermore, the procedure is not well suited for sampling from \\(\\pi(\\boldsymbol{\\theta}_{0:t} \\mid y_{1:t})\\) because most particles originate from the same ancestor. Alternative resampling approaches, such as residual resampling (Liu and Chen 1995) and systematic resampling (Carpenter, Clifford, and Fearnhead 1999), preserve unbiasedness while reducing variance. Additionally, auxiliary particle filtering (O. Cappé, Godsill, and Moulines 2007) can help decrease Monte Carlo variability. Lastly, estimating fixed parameters such as \\(\\sigma_w^2\\), \\(\\sigma_{\\mu}^2\\), and \\(\\phi\\) in the dynamic linear model poses a challenge. Various methods exist to address this issue; see N. Kantas et al. (2009), Nikolas Kantas et al. (2015) for a comprehensive review and Andrieu, Doucet, and Holenstein (2010) for a seminal work in particle MCMC methods. References "],["sec54.html", "4.4 Convergence diagnostics", " 4.4 Convergence diagnostics MCMC methods rely on irreducibility, positive recurrence, and aperiodicity, ensuring that, after a sufficient burn-in (warm-up) period, the posterior draws are sampled from the invariant stationary posterior distribution. This can be achieved by running multiple chains initiated at different points and then mixing them, or by running a single longer chain. In this book, we follow the latter approach, as suggested by Geyer (1992). In this section, we present diagnostics to assess whether the sample draws come from the stationary posterior distribution. First, we calculate the numerical standard error associated with the MCMC algorithm. Next, we review the effective number of simulation draws and various convergence tests. Finally, we examine potential errors in the posterior simulator. 4.4.1 Numerical standard error Many times, the goal in Bayesian inference is to obtain a set of independent draws \\(\\boldsymbol{\\theta}^{(s)}\\), \\(s = 1, 2, \\dots, S\\), from the posterior distribution, such that a measure of interest can be estimated with reasonable precision. In particular, we approximate Equation (4.1) using Equation (4.2). By the central limit theorem, we know that \\[ \\begin{equation} \\frac{\\bar{h}(\\boldsymbol{\\theta})_S - \\mathbb{E}_{\\pi}[h(\\boldsymbol{\\theta})]}{\\sigma_h(\\boldsymbol{\\theta})/\\sqrt{S}} \\stackrel{d}{\\rightarrow} N(0, 1), \\tag{4.4} \\end{equation} \\] where \\(\\sigma^2_h(\\boldsymbol{\\theta})\\) is the variance of \\(h(\\boldsymbol{\\theta})\\). If we have independent draws, we can estimate \\(\\sigma^2_h(\\boldsymbol{\\theta})\\) using the posterior draws as follows: \\[ \\hat{\\sigma}^2_{Sh}(\\boldsymbol{\\theta}) = \\frac{1}{S} \\sum_{s=1}^S \\left[h(\\boldsymbol{\\theta}^{(s)})\\right]^2 - \\left[\\bar{h}(\\boldsymbol{\\theta})_S\\right]^2. \\] However, if there are dependent draws, we have \\[ \\hat{\\sigma}^{2*}_{Sh}(\\boldsymbol{\\theta}) = \\frac{1}{S} \\left\\{\\sum_{s=1}^S \\left[h(\\boldsymbol{\\theta}^{(s)})-\\bar{h}(\\boldsymbol{\\theta})_S\\right]^2 + 2\\sum_{l=k+1}^K \\big(h(\\boldsymbol{\\theta}^{(l)}) - \\bar{h}(\\boldsymbol{\\theta})\\big)\\big(h(\\boldsymbol{\\theta}^{(l-k)}) - \\bar{h}(\\boldsymbol{\\theta})\\big)\\right\\}. \\] The numerical standard error is given by \\(\\sigma_h(\\boldsymbol{\\theta})/\\sqrt{S}\\) and serves as a measure of the approximation error in the Monte Carlo integration. Note that this error can be decreased by increasing \\(S\\). For instance, \\(S = 1000\\) implies an error proportional to 3.2%, while \\(S = 10000\\) reduces the error to approximately 1%. 4.4.2 Effective number of simulation draws MCMC posterior draws are not independent; therefore, the effective sample size of the posterior chains is not equal to \\(S\\). To assess the effective sample size of the posterior draws, we use the following measure: \\[ S_{\\text{ef}} = \\frac{S}{1 + 2\\sum_{k=1}^{\\infty} \\rho_k(h)}, \\] where \\(\\rho_k(h)\\) is the autocorrelation of the sequence \\(h(\\boldsymbol{\\theta})\\) at lag \\(k\\). The sample counterpart of this expression is: \\[ \\hat{S}_{\\text{ef}} = \\frac{S}{1 + 2\\sum_{k=1}^{K} \\hat{\\rho}_k(h)}, \\] where \\[ \\hat{\\rho}_k(h) = \\frac{\\sum_{l=k+1}^K \\big(h(\\boldsymbol{\\theta}^{(l)}) - \\bar{h}(\\boldsymbol{\\theta})\\big)\\big(h(\\boldsymbol{\\theta}^{(l-k)}) - \\bar{h}(\\boldsymbol{\\theta})\\big)}{\\sum_{s=1}^K \\big(h(\\boldsymbol{\\theta}^{(s)}) - \\bar{h}(\\boldsymbol{\\theta})\\big)^2}. \\] If \\(\\hat{\\rho}_k(h)\\) declines to zero slowly as \\(k\\) increases, it indicates significant memory in the draws. Consequently, the effective sample size of the posterior draws is small, and it becomes necessary to either decrease the autocorrelation or increase the number of posterior draws. Note that \\[ \\hat{\\sigma}^{2*}_{Sh}(\\boldsymbol{\\theta}) = \\hat{\\sigma}^2_{Sh}\\left(\\boldsymbol{\\theta}\\right) (1+2\\sum_{k=1}^K \\hat{\\rho}_k(h)), \\] where \\(\\hat{\\sigma}^{2*}_{Sh}(\\boldsymbol{\\theta})\\) and \\(\\hat{\\sigma}^2_{Sh}\\) are the simulation variances using dependent and independent draws, and \\(\\hat{\\kappa}(h) = (1+2\\sum_{k=1}^K \\hat{\\rho}_k(h))\\) is called the inefficiency factor, which represents the inflation of the simulation variance due to autocorrelation in the draws. Values near one indicate draws with little correlation. 4.4.3 Tests of convergence Regarding convergence issues, there are several diagnostics to assess the adequacy of the posterior chains. In particular, graphical approaches such as trace plots and autocorrelation plots are widely used. Trace plots display the sampled values of a parameter (or multiple parameters) as a function of the iteration number, while autocorrelation plots graphically represent \\(\\hat{\\rho}_k\\). The latter shows how correlated the values of \\(\\boldsymbol{\\theta}\\), or functions of \\(\\boldsymbol{\\theta}\\), are at different lags. Trace plots should fluctuate around a stable mean, exploring the entire parameter space without becoming stuck in any particular region. Autocorrelation plots, on the other hand, should exhibit values close to zero or diminish quickly as the lag increases. Additionally, Geweke’s test (J. Geweke 1992) provides a simple two-sample test of means. If the mean of the first window (10% of the chain) is not significantly different from the mean of the second window (50% of the chain), we do not reject the null hypothesis that the two segments of the chain are drawn from the same stationary distribution. The Raftery and Lewis test (A. E. Raftery and Lewis 1992) is designed to calculate the approximate number of iterations (\\(S\\)), burn-in (\\(b\\)), and thinning parameter (\\(d\\)) required to estimate \\(p\\left[H(\\boldsymbol{\\theta}) \\leq h\\right]\\), where \\(H(\\boldsymbol{\\theta}): \\mathcal{R}^K \\rightarrow \\mathcal{R}\\). This calculation is based on a specific quantile of interest (\\(q\\)), precision (\\(r\\)), and probability (\\(p\\)). The diagnostic is based on the dependence factor, \\(I = \\frac{S + b}{S_{\\text{Min}}}\\), where \\(S_{\\text{Min}} = \\Phi^{-1}\\left(\\frac{1}{2}(p+1)\\right)^2 q(1-q) / r^2\\), and \\(\\Phi(\\cdot)\\) is the standard normal cumulative distribution function. Values of \\(I\\) much greater than 5 indicate a high level of dependence. Heidelberger and Welch’s test (Heidelberger and Welch 1983) uses a Cramér-von Mises statistic to test the null hypothesis that the sampled values, \\(\\boldsymbol{\\theta}^{(s)}\\), are drawn from a stationary distribution. The statistic is given by: \\[ \\text{CVM}(B_S) = \\int_0^1 B_S(t)^2 \\, dt, \\] where \\(B_S(t) = \\frac{S_{\\left[St\\right]} - \\left[St\\right] \\bar{\\boldsymbol{\\theta}}^S}{\\sqrt{S p(0)}}\\), \\(S_S = \\sum_{s=1}^S \\boldsymbol{\\theta}^{(s)}\\), \\(\\bar{\\boldsymbol{\\theta}}^S = S_S / S\\), and \\(p(0)\\) is the spectral density at 0, with \\(0 \\leq t \\leq 1\\). Under the null hypothesis, \\(B_S(t)\\) converges in distribution to a Brownian bridge. This test is recursively applied until either the null hypothesis is not rejected, or \\(s = 50\\%\\) of the chain has been discarded. Subsequently, the half-width test calculates a 95% confidence interval for the mean using the portion of the chain that passed the stationarity test. If the ratio of the half-width of this interval to the mean is less than 0.1, the test is considered passed. This indicates no evidence to reject the null hypothesis that the estimated mean is accurate and stable. There are other diagnostics in Bayesian inference that we do not mention here, such as the Gelman and Rubin test (Andrew Gelman and Rubin 1992). This is because we focus on the available diagnostics in our Graphical User Interface (GUI). 4.4.4 Checking for errors in the posterior simulator In this book, we provide basic code templates to get posterior draws for performing inference under the Bayesian framework when there is no closed-form solution. We are prone to making mistakes and greatly appreciate your feedback to help improve our code and identify any other potential issues. One way to check if our code works correctly is to perform simulations where the population parameters are known. If the code is functioning properly, the posterior estimates should converge to these values as the sample size increases due to the Bayesian consistency. This is an informal approach to identifying potential mistakes. John Geweke (2004) offers a more formal method for code validation. The starting point is the joint density \\(p(\\boldsymbol{y}, \\boldsymbol{\\theta}) = p(\\boldsymbol{y} \\mid \\boldsymbol{\\theta}) \\pi(\\boldsymbol{\\theta})\\) and a test function \\(h(\\boldsymbol{y}, \\boldsymbol{\\theta})\\) such that \\(\\sigma_h^2 = \\text{Var}[h(\\boldsymbol{y}, \\boldsymbol{\\theta})] &lt; \\infty\\). Assume that there is a marginal-conditional simulator for the joint distribution of \\(\\boldsymbol{y}\\) and \\(\\boldsymbol{\\theta}\\): \\[\\begin{align} \\boldsymbol{\\theta}^{(s)} &amp;\\sim \\pi(\\boldsymbol{\\theta}) \\\\ \\boldsymbol{y}^{(s)} &amp;\\sim p(\\boldsymbol{y} \\mid \\boldsymbol{\\theta}^{(s)}) \\\\ h^{(s)} &amp;= h(\\boldsymbol{y}^{(s)}, \\boldsymbol{\\theta}^{(s)}). \\end{align}\\] The sequence \\(\\left\\{\\boldsymbol{y}^{(s)}, \\boldsymbol{\\theta}^{(s)}\\right\\}\\) is i.i.d., \\(\\bar{h}_S\\) converges almost surely to \\(\\mathbb{E}[h(\\boldsymbol{y}, \\boldsymbol{\\theta})]\\), and there is convergence in distribution when \\(\\bar{h}_S\\) is well standardized (see Equation (4.4)) and \\(\\hat{\\sigma}^2_{Sh}(\\boldsymbol{\\theta})\\) converges to \\({\\sigma}^2_h(\\boldsymbol{\\theta})\\) almost surely. A posterior simulator produces draws \\(\\boldsymbol{\\theta}^{(s)}\\) given a particular realization \\(\\boldsymbol{y}_{\\text{Obs}}\\), using the transition density \\(q(\\boldsymbol{\\theta} \\mid \\boldsymbol{\\theta}^{(s-1)}, \\boldsymbol{y}_{\\text{Obs}})\\). Thus, a successive-conditional simulator consists of an initial draw \\(\\boldsymbol{\\theta}^{(0)}\\) from \\(\\pi(\\boldsymbol{\\theta})\\) followed by: \\[\\begin{align} \\boldsymbol{y}^{(l)} &amp;\\sim p(\\boldsymbol{y} \\mid \\boldsymbol{\\theta}^{(l-1)}) \\\\ \\boldsymbol{\\theta}^{(l)} &amp;\\sim q(\\boldsymbol{\\theta} \\mid \\boldsymbol{y}^{(l)}, \\boldsymbol{\\theta}^{(l-1)}) \\\\ h^{(l)} &amp;= h(\\boldsymbol{y}^{(l)}, \\boldsymbol{\\theta}^{(l)}), \\end{align}\\] where \\(\\bar{h}_L = L^{-1} \\sum_{l=1}^L h(\\boldsymbol{y}^{(l)}, \\boldsymbol{\\theta}^{(l)})\\) converges almost surely to \\(\\mathbb{E}[h(\\boldsymbol{y}, \\boldsymbol{\\theta})]\\), and there is convergence in distribution when \\(\\bar{h}_L\\) is well standardized, and \\(\\hat{\\sigma}^{*2}_{Lh}(\\boldsymbol{\\theta})\\) converges to \\({\\sigma}^2_h(\\boldsymbol{\\theta})\\) almost surely, for \\(l = 1, 2, \\dots, L\\). Thus, \\[\\begin{align} \\frac{\\bar{h}_S - \\bar{h}_L}{\\left( S^{-1} \\hat{\\sigma}^2_{Sh}(\\boldsymbol{\\theta}) + L^{-1} \\hat{\\sigma}^{*2}_{Lh}(\\boldsymbol{\\theta}) \\right)^{1/2}} &amp;\\stackrel{d}{\\rightarrow} N(0, 1). \\end{align}\\] Thus, we can test \\(H_0. \\ \\bar{h}_S - \\bar{h}_L = 0\\) versus \\(H_1. \\ \\bar{h}_S - \\bar{h}_L \\neq 0\\). Rejection of the null indicates potential errors in implementing the posterior simulator. Example: Mining disaster change point continues Let’s revisit the mining disaster change point example from subsection 4.1.1 and examine some convergence diagnostics for the posterior draws of the rate of disasters after the change point (\\(\\lambda_2\\)). The following code demonstrates how to perform these diagnostics using the R package coda. For clarity and replicability of the results, we present the Gibbs sampler again. The following two figures show the trace and autocorrelation plots. We observe that the posterior draws of \\(\\lambda_2\\) appear stationary around their mean, and the autocorrelation decreases rapidly to zero. The mean and standard deviation of the rate after the change point are 0.92 and 0.12, respectively. The naive and time series standard errors are 0.0008245 and 0.0008945, respectively. The naive standard error assumes iid posterior draws, whereas the time series standard error accounts for autocorrelation. Both standard errors are very similar, indicating a low level of autocorrelation, which is consistent with the results shown in the second figure. The effective sample size of the posterior draws is 16,991, while the total number of posterior draws is 20,000 after a burn-in period of 1,000. The Geweke test statistic is 1.43, which implies no statistical evidence to reject the null hypothesis of equal means in the two segments of the posterior draws. The Raftery and Lewis test yields a dependence factor near 1, indicating a low level of dependence. The Heidelberger and Welch test does not reject the null hypothesis of stationarity for the posterior draws and also confirms that the mean is accurate and stable. In summary, all posterior diagnostics indicate that the posterior draws originate from an invariant stationary distribution. The second part of the code implements the proposal by John Geweke (2004) to assess the reliability of the posterior simulator. The parameter vector is defined as \\(\\boldsymbol{\\theta} = [\\lambda_1 \\ \\lambda_2 \\ H]\\), and the first moments of these parameters are used as test functions. We do not reject the null hypothesis of equal means across the three test functions, indicating that the posterior simulator is functioning correctly. To evaluate the effectiveness of the test, we run the marginal-conditional simulator with prior parameters \\(\\alpha_{l0} = 0.5\\) and \\(\\beta_{l0} = 1\\), \\(l = 1, 2\\). In contrast, for the successive-conditional simulator, we use prior parameters \\(\\alpha_{l0} = 1\\) and \\(\\beta_{l0} = 0.5\\), \\(l = 1, 2\\). In this case, we reject the null hypothesis in two out of three test functions, suggesting that the test performs well in this example. rm(list = ls()) set.seed(010101) dataset&lt;-read.csv(&quot;https://raw.githubusercontent.com/besmarter/BSTApp/refs/heads/master/DataApp/MiningDataCarlin.csv&quot;,header=T) attach(dataset) ## The following objects are masked from dataset (pos = 5): ## ## Count, year str(dataset) ## &#39;data.frame&#39;: 112 obs. of 2 variables: ## $ year : int 1851 1852 1853 1854 1855 1856 1857 1858 1859 1860 ... ## $ Count: int 4 5 4 1 0 4 3 4 0 6 ... a10 &lt;- 0.5; a20 &lt;- 0.5 b10 &lt;- 1; b20 &lt;- 1 y &lt;- Count sumy &lt;- sum(Count); T &lt;- length(Count) theta1 &lt;- NULL; theta2 &lt;- NULL kk &lt;- NULL; H &lt;- 60 MCMC &lt;- 20000; burnin &lt;- 1000; S &lt;- MCMC + burnin; keep &lt;- (burnin+1):S pb &lt;- winProgressBar(title = &quot;progress bar&quot;, min = 0, max = S, width = 300) for(s in 1:S){ a1 &lt;- a10 + sum(y[1:H]) b1 &lt;- b10+H theta11 &lt;- rgamma(1,a1,b1) theta1 &lt;- c(theta1,theta11) a2 &lt;- a20 + sum(y[(1+H):T]) b2 &lt;- b20 + T-H theta22 &lt;- rgamma(1,a2,b2) theta2 &lt;- c(theta2,theta22) pp&lt;-NULL for(l in 1:T){ p &lt;- exp(l*(theta22-theta11))*(theta11/theta22)^(sum(y[1:l])) pp &lt;- c(pp,p) } prob &lt;- pp/sum(pp) H &lt;- sample(1:T,1,prob=prob) kk &lt;- c(kk,H) setWinProgressBar(pb, s, title=paste( round(s/S*100, 0),&quot;% done&quot;)) } close(pb) ## NULL library(coda); library(latex2exp) theta1Post &lt;- mcmc(theta1[keep]); summary(theta1Post) ## ## Iterations = 1:20000 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 20000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## 3.049150 0.282297 0.001996 0.002155 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## 2.517 2.855 3.042 3.235 3.625 HPost &lt;- mcmc(kk); summary(HPost) ## ## Iterations = 1:21000 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 21000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## 40.15843 2.48171 0.01713 0.01973 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## 36 39 40 41 46 theta2Post &lt;- mcmc(theta2[keep]); summary(theta2Post) ## ## Iterations = 1:20000 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 20000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## 0.9151697 0.1165952 0.0008245 0.0008945 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## 0.7010 0.8343 0.9104 0.9914 1.1564 plot(theta2Post, density = FALSE, main = &quot;Trace plot&quot;, ylab = TeX(&quot;$\\\\theta_{2}$&quot;)) autocorr.plot(theta2Post, main = &quot;Autocorrelation plot&quot;) raftery.diag(theta2Post, q = 0.025, r = 0.005, s = 0.95) ## ## Quantile (q) = 0.025 ## Accuracy (r) = +/- 0.005 ## Probability (s) = 0.95 ## ## Burn-in Total Lower bound Dependence ## (M) (N) (Nmin) factor (I) ## 2 3865 3746 1.03 geweke.diag(theta2Post, frac1 = 0.1, frac2 = 0.5) ## ## Fraction in 1st window = 0.1 ## Fraction in 2nd window = 0.5 ## ## var1 ## 1.431 heidel.diag(theta2Post, eps = 0.1, pvalue = 0.05) ## ## Stationarity start p-value ## test iteration ## var1 passed 1 0.196 ## ## Halfwidth Mean Halfwidth ## test ## var1 passed 0.915 0.00175 effectiveSize(theta2Post) ## var1 ## 16990.59 # Marginal-conditional simulator Theta1Prior &lt;- rgamma(MCMC,a10,b10); Theta2Prior &lt;- rgamma(MCMC,a20,b20) kPrior &lt;- sample(1:T, MCMC, replace = TRUE, prob = rep(1/T,T)) ytPrior &lt;- function(par){ y1t &lt;- rpois(par[3], par[1]) if(par[3] == T){y2t &lt;- NULL }else{y2t &lt;- rpois(T-par[3], par[2]) } yt &lt;- c(y1t, y2t) return(yt) } pars1 &lt;- cbind(Theta1Prior, Theta2Prior, kPrior); Yt &lt;- apply(pars1, 1, ytPrior) parsmcmc1 &lt;- coda::mcmc(pars1); Summ1 &lt;- summary(parsmcmc1) # Successive-conditional simulator SucConSim &lt;- function(a10, b10, a20, b20, par){ y &lt;- ytPrior(par) theta1 &lt;- par[1]; theta2 &lt;- par[2]; H &lt;- par[3] a1 &lt;- a10 + sum(y[1:H]); b1 &lt;- b10+H theta11 &lt;- rgamma(1,a1,b1) if(H == T){ a2 &lt;- a20 }else{ a2 &lt;- a20 + sum(y[(1+H):T]) } b2 &lt;- b20 + T-H; theta22 &lt;- rgamma(1,a2,b2); pp&lt;-NULL for(l in 1:T){ p &lt;- l*(theta22-theta11) + (sum(y[1:l]))*log(theta11/theta22) pp &lt;- c(pp,p) } pps &lt;- exp(pp - max(pp)); prob &lt;- pps/sum(pps) H &lt;- sample(1:T, 1, prob=prob) parNew &lt;- list(y = y, pars = c(theta11, theta22, H)) return(parNew) } a10 &lt;- 0.5; b10 &lt;- 1; a20 &lt;- 0.5; b20 &lt;- 1 # a10 &lt;- 1; b10 &lt;- 0.5; a20 &lt;- 1; b20 &lt;- 0.5 par1 &lt;- rgamma(1,a10,b10); par2 &lt;- rgamma(1,a20,b20) par3 &lt;- sample(1:T, 1, replace = TRUE, prob = rep(1/T,T)) pars2 &lt;- matrix(NA, MCMC, 3); pars2[1,] &lt;- c(par1, par2, par3) for(s in 2:MCMC){ Res &lt;- SucConSim(a10 = a10, b10 = b10, a20 = a20, b20 = b20, par = pars2[s-1,]) pars2[s, ] &lt;- Res$pars } parsmcmc2 &lt;- coda::mcmc(pars2); Summ2 &lt;- summary(parsmcmc2) TestGeweke &lt;- function(j){ Test &lt;- (Summ1[[&quot;statistics&quot;]][j,1] - Summ2[[&quot;statistics&quot;]][j,1])/(Summ1[[&quot;statistics&quot;]][j,4]+Summ2[[&quot;statistics&quot;]][j,4])^0.5 Reject &lt;- abs(Test) &gt; qnorm(0.975) return(list(Test = Test, Reject = Reject)) } TestGeweke(1); TestGeweke(2); TestGeweke(3) ## $Test ## Mean ## -0.0966628 ## ## $Reject ## Mean ## FALSE ## $Test ## Mean ## -0.2038595 ## ## $Reject ## Mean ## FALSE ## $Test ## Mean ## 0.7029845 ## ## $Reject ## Mean ## FALSE References "],["sec55.html", "4.5 Summary", " 4.5 Summary In this chapter, we present the most popular methods for obtaining posterior draws when the posterior distribution does not have a standard closed-form solution. In particular, Markov chain Monte Carlo (MCMC) methods, such as Gibbs sampling and the Metropolis-Hastings algorithm, are the most commonly used approaches in this book. However, Hamiltonian Monte Carlo is gaining particular relevance in high-dimensional problems, while particle filtering (Sequential Monte Carlo) is widely applied in time series models. Each problem requires careful consideration to determine the most appropriate method, and in many cases, a combination of methods is necessary. For instance, estimating fixed parameters in state-space models typically requires MCMC methods, while recursion of the state vector requires particle filtering. Additionally, convergence diagnostics are crucial because MCMC methods rely on technical assumptions that must be verified. "],["sec56.html", "4.6 Exercises", " 4.6 Exercises Example: The normal model with independent priors Let’s recap the math test exercise in Chapter 3, this time assuming independent priors. Specifically, let \\(Y_i \\sim N(\\mu, \\sigma^2)\\), where \\(\\mu \\sim N(\\mu_0, \\sigma_0^2)\\) and \\(\\sigma^2 \\sim IG(\\alpha_0 / 2, \\delta_0 / 2)\\). The sample size is 50, and the mean and standard deviation of the math scores are 102 and 10, respectively. We set \\(\\mu_0 = 100\\), \\(\\sigma_0^2 = 100\\), and \\(\\alpha_0 = \\delta_0 = 0.001\\). Find the posterior distribution of \\(\\mu\\) and \\(\\sigma^2\\). Program a Gibbs sampler algorithm and plot the histogram of the posterior draws of \\(\\mu\\). Show that the Gibbs sampler is a particular case of the Metropolis-Hastings where the acceptance probability is equal to 1. Implement a Metropolis-Hastings to sample from the Cauchy distribution, \\(C(0,1)\\), using as proposals a standard normal distribution and a Student’s t distribution with 5 degrees of freedom. This exercise was proposed by Professor Hedibert Freitas Lopes, who cites Thomas and Tu (2021) as a useful reference for an introduction to Hamiltonian Monte Carlo in R and the hmclearn package. The task is to obtain posterior draws using the Metropolis-Hastings and Hamiltonian Monte Carlo algorithms for the posterior distribution given by \\[ \\pi(\\theta_1,\\theta_2\\mid \\mathbf{y}) \\propto \\exp\\left\\{-\\frac{1}{2}(\\theta_1^2\\theta_2^2 + \\theta_1^2 + \\theta_2^2 - 8\\theta_1 - 8\\theta_2)\\right\\}. \\] Ph.D. students sleeping hours continues Use importance sampling based on a \\(U(0,1)\\) proposal to obtain draws of \\(\\boldsymbol{\\theta}\\mid \\mathbf{y} \\sim B(16.55,39.57)\\) in the Ph.D. students’ sleeping hours example in Chapter 3. Note that, based on Exercise 15 in Chapter 3, \\(\\alpha_0 = 1.44\\) and \\(\\beta_0 = 2.57\\). Compute the marginal likelihood in this context (Bernoulli-Beta model) and compare it to the result obtained using the Gelfand-Dey method. Example 4.1 in Gordon, Salmond, and Smith (1993) is \\[\\begin{align*} \\theta_t &amp;= 0.5\\theta_{t-1} + 25\\frac{\\theta_{t-1}}{1+\\theta_{t-1}^2} + 8 \\cos(1.2t) + w_t \\\\ y_t &amp;= \\frac{\\theta_{t}^2}{20} + \\mu_t, \\end{align*}\\] where \\(\\theta_0 \\sim N(0, \\sqrt{10})\\), \\(w_t \\sim \\mathcal{N}(0, \\sqrt{10})\\) and \\(\\mu_t \\sim N(0, \\sqrt{1})\\). Perform sequential importance sampling in this example. Perform particle (Bootstrap) filtering in this example. Estimate the marginal likelihood in this example. Ph.D. students sleeping hours continues Perform the diagnostics of Section 4.4 in this example. Check if there are errors in the posterior simulator of the Metropolis-Hastings algorithm in this example using the Geweke approach using as test functions the first moments of \\(p\\) and \\(p^2\\). Remember from Exercise 15 in Chapter 3 that the sample size is 52, and \\(\\alpha_0 = 1.22\\) and \\(\\beta_0 = 2.57\\). Run the Geweke test using \\(\\alpha_0 = 2.57\\) and \\(\\beta_0 = 1.22\\), and check the results. References "],["Chap5.html", "Chapter 5 Graphical user interface", " Chapter 5 Graphical user interface This chapter presents our graphical user interface (GUI) to carry out Bayesian regression analysis in a very friendly environment without any programming skills (drag and drop). Our GUI is based on an interactive web application using shiny (Chang 2018), and packages like MCMCpack (Martin, Quinn, and Park 2018) and bayesm (P. Rossi 2017) from R software (R Core Team 2023), and is designed for teaching and applied purposes at an introductory level. In the next chapters of the second part of this book, we carry out some applications to highlight the potential of our GUI for applied researchers and practitioners. References "],["Chap6.html", "Chapter 6 Univariate regression", " Chapter 6 Univariate regression We describe how to perform Bayesian inference in some of the most common univariate models: normal-inverse gamma, logit, probit, multinomial probit and logit, ordered probit, negative binomial, tobit, quantile regression, and Bayesian bootstrap in linear models. The point of departure is assuming a random sample of cross-sectional units. We then show the posterior distributions of the parameters and some applications. In addition, we show how to perform inference in various models using three levels of programming skills: our graphical user interface (GUI), packages from R, and programming the posterior distributions. The first requires no programming skills, the second requires an intermediate level, and the third demands more advanced skills. We also include mathematical and computational exercises. We can run our GUI typingshiny::runGitHub(\"besmarter/BSTApp\", launch.browser=T) in the R console or any R code editor and execute it. However, users should see Chapter 5 for details. "],["sec61.html", "6.1 The Gaussian linear model", " 6.1 The Gaussian linear model The Gaussian linear model specifies \\[ \\mathbf{y} = \\mathbf{X} \\boldsymbol{\\beta} + \\mu \\] such that \\(\\mu \\sim N(\\mathbf{0}, \\sigma^2 \\mathbf{I}_N)\\) is a stochastic error, \\(\\mathbf{X}\\) is an \\(N \\times K\\) matrix of regressors, \\(\\boldsymbol{\\beta}\\) is a \\(K\\)-dimensional vector of location coefficients, \\(\\sigma^2\\) is the variance of the model (scale parameter), \\(\\mathbf{y}\\) is an \\(N\\)-dimensional vector of a dependent variable, and \\(N\\) is the sample size. We describe this model using the conjugate family in 3.3, that is, \\[ \\pi(\\boldsymbol{\\beta},\\sigma^2) = \\pi(\\boldsymbol{\\beta} \\mid \\sigma^2) \\times \\pi(\\sigma^2), \\] which allows obtaining the posterior marginal distribution for \\(\\boldsymbol{\\beta}\\) and \\(\\sigma^2\\). We assume independent priors in this section, that is, \\[ \\pi(\\boldsymbol{\\beta},\\sigma^2) = \\pi(\\boldsymbol{\\beta}) \\times \\pi(\\sigma^2), \\] where \\(\\boldsymbol{\\beta} \\sim N(\\boldsymbol{\\beta}_0, \\mathbf{B}_0)\\) and \\(\\sigma^2 \\sim IG(\\alpha_0/2, \\delta_0/2)\\), with \\(\\alpha_0/2\\) and \\(\\delta_0/2\\) as the shape and rate parameters. This setting allows deriving the posterior conditional distributions, \\[ \\pi(\\boldsymbol{\\beta} \\mid \\sigma^2, \\mathbf{y}, \\mathbf{X}) \\] and \\[ \\pi(\\sigma^2 \\mid \\boldsymbol{\\beta}, \\mathbf{y}, \\mathbf{X}), \\] which in turn enables the use of the Gibbs sampler algorithm to perform posterior inference on \\(\\boldsymbol{\\beta}\\) and \\(\\sigma^2\\). The likelihood function in this model is \\[\\begin{align} p(\\mathbf{y} \\mid \\boldsymbol{\\beta}, \\sigma^2, \\mathbf{X}) = (2\\pi\\sigma^2)^{-\\frac{N}{2}} \\exp \\left\\{-\\frac{1}{2\\sigma^2} (\\mathbf{y} - \\mathbf{X} \\boldsymbol{\\beta})^{\\top}(\\mathbf{y} - \\mathbf{X} \\boldsymbol{\\beta}) \\right\\}. \\end{align}\\] Then, the conditional posterior distributions are \\[\\begin{align} \\boldsymbol{\\beta} \\mid \\sigma^2, \\mathbf{y}, \\mathbf{X} \\sim N(\\boldsymbol{\\beta}_n, \\mathbf{B}_n), \\end{align}\\] and \\[\\begin{align} \\sigma^2 \\mid \\boldsymbol{\\beta}, \\mathbf{y}, \\mathbf{X} \\sim IG(\\alpha_n/2, \\delta_n/2), \\end{align}\\] where \\[ \\mathbf{B}_n = (\\mathbf{B}_0^{-1} + \\sigma^{-2} \\mathbf{X}^{\\top} \\mathbf{X})^{-1}, \\] \\[ \\boldsymbol{\\beta}_n= \\mathbf{B}_n (\\mathbf{B}_0^{-1} \\boldsymbol{\\beta}_0 + \\sigma^{-2} \\mathbf{X}^{\\top} \\mathbf{y}), \\] \\[ \\alpha_n = \\alpha_0 + N, \\] \\[ \\delta_n = \\delta_0 + (\\mathbf{y} - \\mathbf{X} \\boldsymbol{\\beta})^{\\top} (\\mathbf{y} - \\mathbf{X} \\boldsymbol{\\beta}). \\] This model can be extended to consider heteroskedasticity such that \\(y_i \\sim N(\\mathbf{x}_i^{\\top} \\boldsymbol{\\beta}, \\sigma^2/\\tau_i)\\), where \\(\\tau_i \\sim G(v/2,v/2)\\). See Exercise 2 for details. Example: The market value of soccer players in Europe Let’s analyze the determinants of the market value of soccer players in Europe. In particular, we use the dataset 1ValueFootballPlayers.csv, which is in the folder DataApp in our GitHub repository: https://github.com/besmarter/BSTApp. This dataset was used by Serna Rodríguez, Ramírez Hassan, and Coad (2019) to find the determinants of high-performance soccer players in the five most important national leagues in Europe. The specification of the model is \\[\\begin{align} \\log(\\text{Value}_i) &amp;= \\beta_1 + \\beta_2 \\text{Perf}_i + \\beta_3 \\text{Age}_i + \\beta_4 \\text{Age}^2_i + \\beta_5 \\text{NatTeam}_i \\\\ &amp;\\quad + \\beta_6 \\text{Goals}_i + \\beta_7 \\text{Exp}_i + \\beta_8 \\text{Exp}^2_i + \\mu_i, \\end{align}\\] where Value is the market value in Euros (2017), Perf is a measure of performance, Age is the player’s age in years, NatTeam is an indicator variable that takes the value of 1 if the player has been on the national team, Goals is the number of goals scored by the player during his career, and Exp is his experience in years. We assume that the dependent variable follows a normal distribution, so we use a normal-inverse gamma model with vague conjugate priors where \\[ \\mathbf{B}_0 = 1000 \\mathbf{I}_{8}, \\quad \\boldsymbol{\\beta}_0 = \\mathbf{0}_{8}, \\quad \\alpha_0 = 0.001, \\quad \\delta_0 = 0.001. \\] We perform a Gibbs sampler with 5,000 MCMC iterations, plus a burn-in of 5,000, and a thinning parameter equal to 1. Once our GUI is displayed (see the beginning of this chapter), we should follow the next Algorithm to run linear Gaussian models in our GUI (see Chapter 5 for details). Algorithm: Gaussian linear model in the GUI Select Univariate Models on the top panel Choose the Normal model using the left radio button Upload the dataset by selecting if there is a header and specifying the separator (comma, semicolon, or tab) Use the Browse button to select the file and preview the dataset Adjust MCMC iterations, burn-in, and thinning using the Range sliders Specify dependent and independent variables using the Formula builder Click the Build formula button to generate the model formula in R Modify the formula in the Main equation box if necessary Set hyperparameters (mean vector, covariance matrix, shape, and scale parameters) if needed Click the Go! button Analyze results Download posterior chains and diagnostic plots using the Download Posterior Chains and Download Posterior Graphs buttons We can see in the following R code examples how to perform the linear Gaussian model using the MCMCregress command from the MCMCpack package, as well as how to program the Gibbs sampler ourselves. We should obtain similar results using all three approaches: GUI, package, and our function. In fact, our GUI relies on the MCMCregress command. For instance, the value of a top soccer player in Europe increases by 134% (\\(\\exp(0.85)-1\\)) on average when he has played for the national team, with a 95% credible interval of (86%, 197%). rm(list = ls()) set.seed(010101) ########################## Linear regression: Value of soccer players ########################## Data &lt;- read.csv(&quot;https://raw.githubusercontent.com/besmarter/BSTApp/refs/heads/master/DataApp/1ValueFootballPlayers.csv&quot;, sep = &quot;,&quot;, header = TRUE, quote = &quot;&quot;) attach(Data) y &lt;- log(Value) # Value: Market value in Euros (2017) of soccer players # Regressors quantity including intercept X &lt;- cbind(1, Perf, Age, Age2, NatTeam, Goals, Exp, Exp2) # Perf: Performance. Perf2: Performance squared. Age: Age; Age: Age squared. # NatTeam: Indicator of national team. Goals: Scored goals. Goals2: Scored goals squared # Exp: Years of experience. Exp2: Years of experience squared. Assists: Number of assists k &lt;- dim(X)[2] N &lt;- dim(X)[1] # Hyperparameters d0 &lt;- 0.001/2 a0 &lt;- 0.001/2 b0 &lt;- rep(0, k) c0 &lt;- 1000 B0 &lt;- c0*diag(k) B0i &lt;- solve(B0) # MCMC parameters mcmc &lt;- 5000 burnin &lt;- 5000 tot &lt;- mcmc + burnin thin &lt;- 1 # Posterior distributions using packages: MCMCpack sets the model in terms of the precision matrix posterior &lt;- MCMCpack::MCMCregress(y~X-1, b0=b0, B0 = B0i, c0 = a0, d0 = d0, burnin = burnin, mcmc = mcmc, thin = thin) summary(coda::mcmc(posterior)) ## ## Iterations = 1:5000 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 5000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## X 3.695499 2.228060 3.151e-02 3.151e-02 ## XPerf 0.035445 0.004299 6.079e-05 6.079e-05 ## XAge 0.778410 0.181362 2.565e-03 2.565e-03 ## XAge2 -0.016617 0.003380 4.781e-05 4.781e-05 ## XNatTeam 0.850362 0.116861 1.653e-03 1.689e-03 ## XGoals 0.009097 0.001603 2.266e-05 2.266e-05 ## XExp 0.206208 0.062713 8.869e-04 8.428e-04 ## XExp2 -0.006992 0.002718 3.844e-05 3.719e-05 ## sigma2 0.969590 0.076091 1.076e-03 1.076e-03 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## X -0.545746 2.174460 3.653373 5.171463 8.177948 ## XPerf 0.026933 0.032570 0.035421 0.038368 0.043817 ## XAge 0.419057 0.656975 0.779534 0.902753 1.125442 ## XAge2 -0.022967 -0.018928 -0.016651 -0.014366 -0.009919 ## XNatTeam 0.627228 0.771339 0.852420 0.928765 1.075360 ## XGoals 0.005914 0.007984 0.009108 0.010180 0.012272 ## XExp 0.082206 0.164290 0.206742 0.248716 0.329809 ## XExp2 -0.012290 -0.008829 -0.007002 -0.005188 -0.001762 ## sigma2 0.832320 0.915580 0.965122 1.018776 1.127566 # Posterior distributions programming the Gibbs sampling # Auxiliary parameters XtX &lt;- t(X)%*%X bhat &lt;- solve(XtX)%*%t(X)%*%y an &lt;- a0 + N # Gibbs sampling functions PostSig2 &lt;- function(Beta){ dn &lt;- d0 + t(y - X%*%Beta)%*%(y - X%*%Beta) sig2 &lt;- invgamma::rinvgamma(1, shape = an/2, rate = dn/2) return(sig2) } PostBeta &lt;- function(sig2){ Bn &lt;- solve(B0i + sig2^(-1)*XtX) bn &lt;- Bn%*%(B0i%*%b0 + sig2^(-1)*XtX%*%bhat) Beta &lt;- MASS::mvrnorm(1, bn, Bn) return(Beta) } PostBetas &lt;- matrix(0, mcmc+burnin, k) PostSigma2 &lt;- rep(0, mcmc+burnin) Beta &lt;- rep(0, k) for(s in 1:tot){ sig2 &lt;- PostSig2(Beta = Beta) PostSigma2[s] &lt;- sig2 Beta &lt;- PostBeta(sig2 = sig2) PostBetas[s,] &lt;- Beta } keep &lt;- seq((burnin+1), tot, thin) PosteriorBetas &lt;- PostBetas[keep,] colnames(PosteriorBetas) &lt;- c(&quot;Intercept&quot;, &quot;Perf&quot;, &quot;Age&quot;, &quot;Age2&quot;, &quot;NatTeam&quot;, &quot;Goals&quot;, &quot;Exp&quot;, &quot;Exp2&quot;) summary(coda::mcmc(PosteriorBetas)) ## ## Iterations = 1:5000 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 5000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## Intercept 3.663230 2.194363 3.103e-02 3.103e-02 ## Perf 0.035361 0.004315 6.102e-05 6.102e-05 ## Age 0.780374 0.178530 2.525e-03 2.525e-03 ## Age2 -0.016641 0.003332 4.713e-05 4.713e-05 ## NatTeam 0.850094 0.119093 1.684e-03 1.684e-03 ## Goals 0.009164 0.001605 2.270e-05 2.270e-05 ## Exp 0.205965 0.062985 8.907e-04 8.596e-04 ## Exp2 -0.007006 0.002731 3.862e-05 3.701e-05 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## Intercept -0.579087 2.169333 3.651261 5.108860 8.023949 ## Perf 0.027018 0.032474 0.035346 0.038165 0.044079 ## Age 0.429084 0.662879 0.781856 0.901172 1.126256 ## Age2 -0.023079 -0.018883 -0.016662 -0.014410 -0.010018 ## NatTeam 0.621226 0.769287 0.848137 0.930096 1.088729 ## Goals 0.006026 0.008065 0.009176 0.010249 0.012240 ## Exp 0.080559 0.163623 0.206094 0.248598 0.327669 ## Exp2 -0.012354 -0.008885 -0.007009 -0.005166 -0.001629 PosteriorSigma2 &lt;- PostSigma2[keep] summary(coda::mcmc(PosteriorSigma2)) ## ## Iterations = 1:5000 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 5000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## 0.973309 0.077316 0.001093 0.001116 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## 0.8361 0.9189 0.9685 1.0228 1.1421 References "],["sec62.html", "6.2 The logit model", " 6.2 The logit model In the logit model, the dependent variable is binary, \\(y_i=\\left\\{1,0\\right\\}\\), which follows a Bernoulli distribution, \\(y_i \\stackrel{ind}{\\sim} B(\\pi_i)\\), such that \\(p(y_i=1)=\\pi_i\\), where \\(\\pi_i = \\frac{\\exp\\left\\{{\\mathbf{x}}_i^{\\top}\\boldsymbol{\\beta}\\right\\}}{1 + \\exp\\left\\{{\\mathbf{x}}_i^{\\top}\\boldsymbol{\\beta}\\right\\}}\\), and \\(\\mathbf{x}_i\\) is a \\(K\\)-dimensional vector of regressors. The likelihood function of the logit model is: \\[ p({\\mathbf{y}} \\mid \\boldsymbol{\\beta}, {\\mathbf{X}}) = \\prod_{i=1}^N \\pi_i^{y_i}(1 - \\pi_i)^{1 - y_i} \\] \\[ = \\prod_{i=1}^N \\left( \\frac{\\exp\\left\\{{\\mathbf{x}}_i^{\\top}\\boldsymbol{\\beta}\\right\\}}{1 + \\exp\\left\\{{\\mathbf{x}}_i^{\\top}\\boldsymbol{\\beta}\\right\\}} \\right)^{y_i} \\left( \\frac{1}{1 + \\exp\\left\\{{\\mathbf{x}}_i^{\\top}\\boldsymbol{\\beta}\\right\\}} \\right)^{1 - y_i}. \\] We can specify a Normal distribution as a prior, \\(\\boldsymbol{\\beta} \\sim N({\\boldsymbol{\\beta}}_0, {\\mathbf{B}}_0)\\). Then, the posterior distribution is: \\[ \\pi(\\boldsymbol{\\beta} \\mid {\\mathbf{y}}, {\\mathbf{X}}) \\propto \\prod_{i=1}^N \\left( \\frac{\\exp\\left\\{{\\mathbf{x}}_i^{\\top}\\boldsymbol{\\beta}\\right\\}}{1 + \\exp\\left\\{{\\mathbf{x}}_i^{\\top}\\boldsymbol{\\beta}\\right\\}} \\right)^{y_i} \\left( \\frac{1}{1 + \\exp\\left\\{{\\mathbf{x}}_i^{\\top}\\boldsymbol{\\beta}\\right\\}} \\right)^{1 - y_i} \\] \\[ \\times \\exp\\left\\{-\\frac{1}{2}(\\boldsymbol{\\beta} - \\boldsymbol{\\beta}_0)^{\\top} {\\mathbf{B}}_0^{-1} (\\boldsymbol{\\beta} - \\boldsymbol{\\beta}_0)\\right\\}. \\] The logit model does not have a standard posterior distribution. Therefore, a random walk Metropolis–Hastings algorithm can be used to obtain draws from the posterior distribution. A potential proposal distribution is a multivariate normal, centered at the current value, with covariance matrix \\(\\tau^2({\\mathbf{B}}_0^{-1} + \\widehat{{\\mathbf{\\Sigma}}}^{-1})^{-1}\\), where \\(\\tau &gt; 0\\) is a tuning parameter and \\(\\widehat{\\mathbf{\\Sigma}}\\) is the sample covariance matrix obtained from the maximum likelihood estimation (Martin, Quinn, and Park 2011). Tuning parameters should be set in a way that ensures reasonable diagnostic criteria and acceptance rates. Observe that: \\[ \\log(p({\\mathbf{y}} \\mid \\boldsymbol{\\beta}, {\\mathbf{X}})) = \\sum_{i=1}^N y_i {\\mathbf{x}}_i^{\\top} \\boldsymbol{\\beta} - \\log(1 + \\exp({\\mathbf{x}}_i^{\\top} \\boldsymbol{\\beta})). \\] This expression can be used when calculating the acceptance parameter in the computational implementation of the Metropolis-Hastings algorithm. In particular, the acceptance parameter is: \\[ \\alpha = \\min\\left\\{1, \\exp\\left(\\log(p({\\mathbf{y}} \\mid \\boldsymbol{\\beta}^{c}, {\\mathbf{X}})) + \\log(\\pi(\\boldsymbol{\\beta}^c)) - \\left(\\log(p({\\mathbf{y}} \\mid \\boldsymbol{\\beta}^{(s-1)}, {\\mathbf{X}})) + \\log(\\pi(\\boldsymbol{\\beta}^{(s-1)}))\\right)\\right)\\right\\}, \\] where \\(\\boldsymbol{\\beta}^c\\) and \\(\\boldsymbol{\\beta}^{(s-1)}\\) are the draws from the proposal distribution and the previous iteration of the Markov chain, respectively. Formulating the acceptance rate using \\(\\log\\) helps mitigate computational problems. Example: Simulation exercise Let’s do a simulation exercise to check the performance of the algorithm. Set \\(\\boldsymbol{\\beta} = \\begin{bmatrix}0.5 &amp; 0.8 &amp; -1.2\\end{bmatrix}^{\\top}\\), \\(x_{ik} \\sim N(0,1)\\), \\(k=2,3\\) and \\(i=1,2,\\dots,10000\\). We set as hyperparameters \\(\\boldsymbol{\\beta}_0 = [0 \\ 0 \\ 0]^{\\top}\\) and \\({\\mathbf{B}}_0 = 1000 {\\mathbf{I}}_3\\). The tuning parameter for the Metropolis-Hastings algorithm is equal to 1. Once our GUI is displayed (see beginning of this chapter), we should follow the next Algorithm to run logit models in our GUI (see Chapter 5 for details): Algorithm: Logit model in the GUI Select Univariate Models on the top panel Select Logit model using the left radio button Upload the dataset by first selecting whether there is a header in the file, and the kind of separator in the csv file of the dataset (comma, semicolon, or tab). Then, use the Browse button under the Choose File legend. You should see a preview of the dataset Select MCMC iterations, burn-in, and thinning parameters using the Range sliders Select dependent and independent variables using the Formula builder table Click the Build formula button to generate the formula in R syntax. You can modify the formula in the Main equation box using valid arguments of the formula command structure in R Set the hyperparameters: mean vector and covariance matrix. This step is not necessary as by default our GUI uses non-informative priors Select the tuning parameter for the Metropolis-Hastings algorithm. This step is not necessary as by default our GUI sets the tuning parameter at 1.1 Click the Go! button Analyze results Download posterior chains and diagnostic plots using the Download Posterior Chains and Download Posterior Graphs buttons We can see in the following R code how to perform the logit model using the MCMClogit command from the MCMCpack package, as well as by programming the Metropolis-Hastings algorithm ourselves. We should obtain similar results using the three approaches: GUI, package, and our function. Our GUI relies on the MCMClogit command. In particular, we achieve an acceptance rate of 0.46, and the diagnostics suggest that the posterior chains behave well. In general, the 95% credible intervals encompass the population values, and both the mean and median are very close to these values. ########################## Logit: Simulation ########################## # Simulate data rm(list = ls()) set.seed(010101) N &lt;- 10000 # Sample size B &lt;- c(0.5, 0.8, -1.2) # Population location parameters x2 &lt;- rnorm(N) # Regressor x3 &lt;- rnorm(N) # Regressor X &lt;- cbind(1, x2, x3) # Regressors XB &lt;- X%*%B PY &lt;- exp(XB)/(1 + exp(XB)) # Probability of Y = 1 Y &lt;- rbinom(N, 1, PY) # Draw Y&#39;s table(Y) # Frequency ## Y ## 0 1 ## 4115 5885 # write.csv(cbind(Y, x2, x3), file = &quot;DataSimulations/LogitSim.csv&quot;) # Export data # MCMC parameters iter &lt;- 5000; burnin &lt;- 1000; thin &lt;- 5; tune &lt;- 1 # Hyperparameters K &lt;- dim(X)[2] b0 &lt;- rep(0, K) c0 &lt;- 1000 B0 &lt;- c0*diag(K) B0i &lt;- solve(B0) # Posterior distributions using packages: MCMCpack sets the model in terms of the precision matrix RegLog &lt;- MCMCpack::MCMClogit(Y~X-1, mcmc = iter, burnin = burnin, thin = thin, b0 = b0, B0 = B0i, tune = tune) summary(RegLog) ## ## Iterations = 1001:5996 ## Thinning interval = 5 ## Number of chains = 1 ## Sample size per chain = 1000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## X 0.4896 0.02550 0.0008064 0.001246 ## Xx2 0.8330 0.02730 0.0008632 0.001406 ## Xx3 -1.2104 0.03049 0.0009643 0.001536 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## X 0.4424 0.4728 0.4894 0.5072 0.5405 ## Xx2 0.7787 0.8159 0.8327 0.8505 0.8852 ## Xx3 -1.2758 -1.2296 -1.2088 -1.1902 -1.1513 # Posterior distributions programming the Metropolis-Hastings algorithm MHfunc &lt;- function(y, X, b0 = rep(0, dim(X)[2] + 1), B0 = 1000*diag(dim(X)[2] + 1), tau = 1, iter = 6000, burnin = 1000, thin = 5){ Xm &lt;- cbind(1, X) # Regressors K &lt;- dim(Xm)[2] # Number of location parameters BETAS &lt;- matrix(0, iter + burnin, K) # Space for posterior chains Reg &lt;- glm(y ~ Xm - 1, family = binomial(link = &quot;logit&quot;)) # Maximum likelihood estimation BETA &lt;- Reg$coefficients # Maximum likelihood parameter estimates tot &lt;- iter + burnin # Total iterations M-H algorithm COV &lt;- vcov(Reg) # Maximum likelihood covariance matrix COVt &lt;- tau^2*solve(solve(B0) + solve(COV)) # Covariance matrix for the proposal distribution Accep &lt;- rep(0, tot) # Space for calculating the acceptance rate # Create progress bar in case that you want to see iterations progress pb &lt;- winProgressBar(title = &quot;progress bar&quot;, min = 0, max = tot, width = 300) for(it in 1:tot){ BETAc &lt;- BETA + MASS::mvrnorm(n = 1, mu = rep(0, K), Sigma = COVt) # Candidate location parameter likecand &lt;- sum((Xm%*%BETAc) * Y - apply(Xm%*%BETAc, 1, function(x) log(1 + exp(x)))) # Log likelihood for the candidate likepast &lt;- sum((Xm%*%BETA) * Y - apply((Xm%*%BETA), 1, function(x) log(1 + exp(x)))) # Log likelihood for the actual draw priorcand &lt;- (-1/2)*crossprod((BETAc - b0), solve(B0))%*%(BETAc - b0) # Log prior for candidate priorpast &lt;- (-1/2)*crossprod((BETA - b0), solve(B0))%*%(BETA - b0) # Log prior for actual draw alpha &lt;- min(1, exp((likecand + priorcand) - (likepast + priorpast))) #Probability of selecting candidate u &lt;- runif(1) # Decision rule for selecting candidate if(u &lt; alpha){ BETA &lt;- BETAc # Changing reference for candidate if selected Accep[it] &lt;- 1 # Indicator if the candidate is accepted } BETAS[it, ] &lt;- BETA # Saving draws setWinProgressBar(pb, it, title=paste( round(it/tot*100, 0), &quot;% done&quot;)) } close(pb) keep &lt;- seq(burnin, tot, thin) return(list(Bs = BETAS[keep[-1], ], AceptRate = mean(Accep[keep[-1]]))) } Posterior &lt;- MHfunc(y = Y, X = cbind(x2, x3), iter = iter, burnin = burnin, thin = thin) # Running our M-H function changing some default parameters. paste(&quot;Acceptance rate equal to&quot;, round(Posterior$AceptRate, 2), sep = &quot; &quot;) ## [1] &quot;Acceptance rate equal to 0.46&quot; &quot;Acceptance rate equal to 0.46&quot; ## [1] &quot;Acceptance rate equal to 0.46&quot; PostPar &lt;- coda::mcmc(Posterior$Bs) # Names colnames(PostPar) &lt;- c(&quot;Cte&quot;, &quot;x1&quot;, &quot;x2&quot;) # Summary posterior draws summary(PostPar) ## ## Iterations = 1:1000 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 1000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## Cte 0.4893 0.02427 0.0007674 0.001223 ## x1 0.8309 0.02699 0.0008536 0.001440 ## x2 -1.2107 0.02943 0.0009308 0.001423 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## Cte 0.4431 0.4721 0.4899 0.5059 0.5344 ## x1 0.7817 0.8123 0.8305 0.8505 0.8833 ## x2 -1.2665 -1.2309 -1.2107 -1.1911 -1.1538 # Trace and density plots plot(PostPar) # Autocorrelation plots coda::autocorr.plot(PostPar) # Convergence diagnostics coda::geweke.diag(PostPar) ## ## Fraction in 1st window = 0.1 ## Fraction in 2nd window = 0.5 ## ## Cte x1 x2 ## -0.975 -3.112 1.326 coda::raftery.diag(PostPar,q=0.5,r=0.05,s = 0.95) ## ## Quantile (q) = 0.5 ## Accuracy (r) = +/- 0.05 ## Probability (s) = 0.95 ## ## Burn-in Total Lower bound Dependence ## (M) (N) (Nmin) factor (I) ## Cte 6 731 385 1.90 ## x1 6 703 385 1.83 ## x2 6 725 385 1.88 coda::heidel.diag(PostPar) ## ## Stationarity start p-value ## test iteration ## Cte passed 1 0.4436 ## x1 passed 101 0.3470 ## x2 passed 1 0.0872 ## ## Halfwidth Mean Halfwidth ## test ## Cte passed 0.489 0.00240 ## x1 passed 0.832 0.00268 ## x2 passed -1.211 0.00279 References "],["sec63.html", "6.3 The probit model", " 6.3 The probit model The probit model also has a binary dependent variable. In this case, there is a latent variable (\\(y_i^*\\), which is unobserved) that defines the structure of the estimation problem. In particular, \\[ y_i = \\begin{cases} 0, &amp; \\text{if } y_i^* \\leq 0, \\\\ 1, &amp; \\text{if } y_i^* &gt; 0. \\end{cases} \\] such that \\(y_i^* = \\mathbf{x}_i^{\\top}\\boldsymbol{\\beta} + \\mu_i\\), where \\(\\mu_i \\stackrel{i.i.d.}{\\sim} N(0,1)\\).24 This implies \\(P(y_i = 1) = \\pi_i = \\Phi(\\mathbf{x}_i^{\\top} \\boldsymbol{\\beta})\\), where \\(\\mathbf{x}_i\\) is a \\(K\\)-dimensional vector of regressors. Albert and Chib (1993) implemented data augmentation (Tanner and Wong 1987) to apply a Gibbs sampling algorithm to this model. Augmenting this model with \\(y_i^*\\), we can express the likelihood contribution from observation \\(i\\) as: \\[ p(y_i \\mid y_i^*) = \\mathbb{1}({y_i = 0}) \\mathbb{1}({y_i^* \\leq 0}) + \\mathbb{1}({y_i = 1}) \\mathbb{1}({y_i^* &gt; 0}), \\] where \\(\\mathbb{1}(A)\\) is an indicator function that takes the value of 1 when the condition \\(A\\) is satisfied. The posterior distribution is: \\[ \\pi(\\boldsymbol{\\beta}, \\mathbf{y^*} \\mid \\mathbf{y}, \\mathbf{X}) \\propto \\prod_{i=1}^N \\left[\\mathbb{1}({y_i = 0}) \\mathbb{1}({y_i^* \\leq 0}) + \\mathbb{1}({y_i = 1}) \\mathbb{1}({y_i^* &gt; 0}) \\right] \\] \\[ \\times N_N(\\mathbf{y^*} \\mid \\mathbf{X\\boldsymbol{\\beta}}, \\mathbf{I}_n) \\times N_K(\\boldsymbol{\\beta} \\mid \\boldsymbol{\\beta}_0, \\mathbf{B}_0), \\] where we assume a Gaussian prior for \\(\\boldsymbol{\\beta}\\): \\(\\boldsymbol{\\beta} \\sim N_K(\\boldsymbol{\\beta}_0, \\mathbf{B}_0)\\). This implies \\[ y_i^* \\mid \\boldsymbol{\\beta}, \\mathbf{y}, \\mathbf{X} \\sim \\begin{cases} TN_{(-\\infty,0]}(\\mathbf{x}_i^{\\top} \\boldsymbol{\\beta}, 1) &amp; \\text{if } y_i = 0, \\\\ TN_{(0,\\infty)}(\\mathbf{x}_i^{\\top} \\boldsymbol{\\beta}, 1) &amp; \\text{if } y_i = 1, \\end{cases}, \\] where \\(TN\\) denotes a truncated normal density. \\[ \\boldsymbol{\\beta} \\mid \\mathbf{y}^*, \\mathbf{X} \\sim N(\\boldsymbol{\\beta}_n, \\mathbf{B}_n), \\] where \\(\\mathbf{B}_n = (\\mathbf{B}_0^{-1} + \\mathbf{X}^{\\top} \\mathbf{X})^{-1}\\), and \\(\\boldsymbol{\\beta}_n = \\mathbf{B}_n (\\mathbf{B}_0^{-1} \\boldsymbol{\\beta}_0 + \\mathbf{X}^{\\top} \\mathbf{y}^*)\\). Example: Determinants of hospitalization We use the dataset named 2HealthMed.csv, which is located in the DataApp folder of our GitHub repository (https://github.com/besmarter/BSTApp), and was used by Ramírez Hassan, Cardona Jiménez, and Cadavid Montoya (2013). The dependent variable is a binary indicator, taking the value 1 if an individual was hospitalized in 2007, and 0 otherwise. The specification of the model is \\[ \\text{Hosp}_i = \\boldsymbol{\\beta}_1 + \\boldsymbol{\\beta}_2 \\text{SHI}_i + \\boldsymbol{\\beta}_3 \\text{Female}_i + \\boldsymbol{\\beta}_4 \\text{Age}_i + \\boldsymbol{\\beta}_5 \\text{Age}_i^2 + \\boldsymbol{\\beta}_6 \\text{Est2}_i + \\boldsymbol{\\beta}_7 \\text{Est3}_i + \\boldsymbol{\\beta}_8 \\text{Fair}_i + \\boldsymbol{\\beta}_9 \\text{Good}_i + \\boldsymbol{\\beta}_{10} \\text{Excellent}_i, \\] where SHI is a binary variable equal to 1 if the individual is enrolled in a subsidized health care program and 0 otherwise, Female is an indicator of gender, Age is in years, Est2 and Est3 are indicators of socioeconomic status, with Est1 being the reference category (the lowest status), and HealthStatus is a self-perception of health status, where bad is the reference category. We set \\(\\boldsymbol{\\beta}_0 = {\\boldsymbol{0}}_{10}\\), \\({\\boldsymbol{B}}_0 = {\\boldsymbol{I}}_{10}\\), with iterations, burn-in, and thinning parameters equal to 10000, 1000, and 1, respectively. We can use the next Algorithm to run the probit model in our GUI. Our GUI relies on the rbprobitGibbs command from the bayesm package to perform inference in the probit model. The following R code shows how to run this example using the rbprobitGibbs command. We also asked you to implement a Gibbs sampler algorithm to perform inference in the probit model in the exercises. Algorithm: Probit model in the GUI Select Univariate Models on the top panel Select Probit model using the left radio button Upload the dataset by first selecting whether there is a header in the file, and the kind of separator in the csv file of the dataset (comma, semicolon, or tab). Then, use the Browse button under the Choose File legend. You should see a preview of the dataset Select MCMC iterations, burn-in, and thinning parameters using the Range sliders Select dependent and independent variables using the Formula builder table Click the Build formula button to generate the formula in R syntax. You can modify the formula in the Main equation box using valid arguments of the formula command structure in R Set the hyperparameters: mean vector and covariance matrix. This step is not necessary as by default our GUI uses non-informative priors Select the tuning parameter for the Metropolis-Hastings algorithm. This step is not necessary as by default our GUI sets the tuning parameter at 1.1 Click the Go! button Analyze results Download posterior chains and diagnostic plots using the Download Posterior Chains and Download Posterior Graphs buttons Our analysis finds evidence that gender and self-perceived health status significantly affect the probability of hospitalization. Women have a higher probability of being hospitalized than men, and individuals with a better perception of their health status have a lower probability of hospitalization. mydata &lt;- read.csv(&quot;https://raw.githubusercontent.com/besmarter/BSTApp/refs/heads/master/DataApp/2HealthMed.csv&quot;, sep = &quot;,&quot;, header = TRUE, quote = &quot;&quot;) attach(mydata) ## The following objects are masked from Data: ## ## Age, Age2 str(mydata) ## &#39;data.frame&#39;: 12975 obs. of 22 variables: ## $ id : int 1 2 3 4 5 6 7 8 9 10 ... ## $ MedVisPrev : int 0 0 0 0 0 0 0 0 0 0 ... ## $ MedVisPrevOr: int 1 1 1 1 1 1 1 1 1 1 ... ## $ Hosp : int 0 0 0 0 0 0 0 0 0 0 ... ## $ SHI : int 1 1 1 1 0 0 1 1 0 0 ... ## $ Female : int 0 1 1 1 0 1 0 1 0 1 ... ## $ Age : int 7 39 23 15 8 54 64 40 6 7 ... ## $ Age2 : int 49 1521 529 225 64 2916 4096 1600 36 49 ... ## $ FemaleAge : int 0 39 23 15 0 54 0 40 0 7 ... ## $ Est1 : int 1 0 0 0 0 0 0 0 0 0 ... ## $ Est2 : int 0 1 1 1 0 1 1 1 0 0 ... ## $ Est3 : int 0 0 0 0 1 0 0 0 1 1 ... ## $ Bad : int 0 0 0 0 0 0 0 0 0 0 ... ## $ Fair : int 0 0 0 0 0 0 1 0 0 0 ... ## $ Good : int 1 1 1 1 0 0 0 1 1 1 ... ## $ Excellent : int 0 0 0 0 1 1 0 0 0 0 ... ## $ NoEd : int 1 0 0 0 1 0 0 0 1 1 ... ## $ PriEd : int 0 0 0 0 0 1 1 1 0 0 ... ## $ HighEd : int 0 1 1 1 0 0 0 0 0 0 ... ## $ VocEd : int 0 0 0 0 0 0 0 0 0 0 ... ## $ UnivEd : int 0 0 0 0 0 0 0 0 0 0 ... ## $ PTL : num 0.43 0 0 0 0 0.06 0 0.38 0 1 ... K &lt;- 10 # Number of regressors b0 &lt;- rep(0, K) # Prio mean B0i &lt;- diag(K) # Prior precision (inverse of covariance) Prior &lt;- list(betabar = b0, A = B0i) # Prior list y &lt;- Hosp # Dependent variables X &lt;- cbind(1, SHI, Female, Age, Age2, Est2, Est3, Fair, Good, Excellent) # Regressors Data &lt;- list(y = y, X = X) # Data list Mcmc &lt;- list(R = 10000, keep = 1, nprint = 0) # MCMC parameters RegProb &lt;- bayesm::rbprobitGibbs(Data = Data, Prior = Prior, Mcmc = Mcmc) # Inference using bayesm package ## ## Starting Gibbs Sampler for Binary Probit Model ## with 12975 observations ## Table of y Values ## y ## 0 1 ## 12571 404 ## ## Prior Parms: ## betabar ## [1] 0 0 0 0 0 0 0 0 0 0 ## A ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] ## [1,] 1 0 0 0 0 0 0 0 0 0 ## [2,] 0 1 0 0 0 0 0 0 0 0 ## [3,] 0 0 1 0 0 0 0 0 0 0 ## [4,] 0 0 0 1 0 0 0 0 0 0 ## [5,] 0 0 0 0 1 0 0 0 0 0 ## [6,] 0 0 0 0 0 1 0 0 0 0 ## [7,] 0 0 0 0 0 0 1 0 0 0 ## [8,] 0 0 0 0 0 0 0 1 0 0 ## [9,] 0 0 0 0 0 0 0 0 1 0 ## [10,] 0 0 0 0 0 0 0 0 0 1 ## ## MCMC parms: ## R= 10000 keep= 1 nprint= 0 ## PostPar &lt;- coda::mcmc(RegProb$betadraw) # Posterior draws colnames(PostPar) &lt;- c(&quot;Cte&quot;, &quot;SHI&quot;, &quot;Female&quot;, &quot;Age&quot;, &quot;Age2&quot;, &quot;Est2&quot;, &quot;Est3&quot;, &quot;Fair&quot;, &quot;Good&quot;, &quot;Excellent&quot;) # Names summary(PostPar) # Posterior summary ## ## Iterations = 1:10000 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 10000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## Cte -9.443e-01 1.347e-01 1.347e-03 3.413e-03 ## SHI -7.227e-03 5.934e-02 5.934e-04 2.229e-03 ## Female 1.260e-01 4.807e-02 4.807e-04 1.780e-03 ## Age 1.112e-04 3.551e-03 3.551e-05 1.164e-04 ## Age2 4.078e-05 4.222e-05 4.222e-07 1.249e-06 ## Est2 -8.658e-02 5.370e-02 5.370e-04 1.898e-03 ## Est3 -4.254e-02 8.112e-02 8.112e-04 2.774e-03 ## Fair -4.961e-01 1.119e-01 1.119e-03 2.013e-03 ## Good -1.204e+00 1.114e-01 1.114e-03 2.205e-03 ## Excellent -1.061e+00 1.316e-01 1.316e-03 3.136e-03 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## Cte -1.210e+00 -1.034e+00 -9.450e-01 -8.523e-01 -0.6839311 ## SHI -1.207e-01 -4.742e-02 -8.527e-03 3.225e-02 0.1125873 ## Female 3.273e-02 9.359e-02 1.261e-01 1.585e-01 0.2219169 ## Age -6.849e-03 -2.343e-03 6.224e-05 2.535e-03 0.0071123 ## Age2 -4.198e-05 1.215e-05 4.177e-05 6.976e-05 0.0001213 ## Est2 -1.911e-01 -1.235e-01 -8.634e-02 -4.971e-02 0.0168394 ## Est3 -2.018e-01 -9.709e-02 -4.153e-02 1.256e-02 0.1129273 ## Fair -7.141e-01 -5.704e-01 -4.971e-01 -4.218e-01 -0.2752697 ## Good -1.419e+00 -1.279e+00 -1.205e+00 -1.131e+00 -0.9832597 ## Excellent -1.323e+00 -1.147e+00 -1.062e+00 -9.730e-01 -0.8028882 References "],["sec64.html", "6.4 The multinomial probit model", " 6.4 The multinomial probit model The multinomial probit model is used to model the choice of the \\(l\\)-th alternative over a set of \\(L\\) mutually exclusive options. We observe the following: \\[ y_{il} = \\begin{cases} 1, &amp; \\text{if } y_{il}^* \\geq \\max\\left\\{\\boldsymbol{y}_i^*\\right\\}, \\\\ 0, &amp; \\text{otherwise,} \\end{cases} \\] where \\(\\boldsymbol{y}_i^* = \\boldsymbol{X}_{i} \\boldsymbol{\\delta} + \\boldsymbol{\\mu}_i\\), with \\(\\boldsymbol{\\mu}_i \\stackrel{i.i.d.}{\\sim} N(\\boldsymbol{0}, \\boldsymbol{\\Sigma})\\). The vector \\(\\boldsymbol{y}_i^*\\) is an unobserved latent vector of dimension \\(L\\). The matrix \\(\\boldsymbol{X}_i = \\left[(1 \\ \\boldsymbol{c}_i^{\\top}) \\otimes \\boldsymbol{I}_L \\ \\boldsymbol{A}_i\\right]\\) is an \\(L \\times j\\) matrix of regressors for each alternative, where \\(l = 1, 2, \\dots, L\\), and \\(j = L \\times (1 + \\text{dim}(\\boldsymbol{c}_i)) + a\\). Here, \\(\\boldsymbol{c}_i\\) is a vector of individual-specific characteristics, \\(\\boldsymbol{A}_i\\) is an \\(L \\times a\\) matrix of alternative-varying regressors, \\(a\\) is the number of alternative-varying regressors, and \\(\\boldsymbol{\\delta}\\) is a \\(j\\)-dimensional vector of parameters. We take into account simultaneously the alternative-varying regressors (alternative attributes) and alternative-invariant regressors (individual characteristics).25 The vector \\(\\boldsymbol{y}_i^*\\) can be stacked into a multiple regression model with correlated stochastic errors, i.e., \\(\\boldsymbol{y}^* = \\boldsymbol{X} \\boldsymbol{\\delta} + \\boldsymbol{\\mu}\\), where \\(\\boldsymbol{y}^* = \\left[\\boldsymbol{y}_1^{*\\top} \\ \\boldsymbol{y}_2^{*\\top} \\ \\dots \\ \\boldsymbol{y}_N^{*\\top}\\right]\\), \\(\\boldsymbol{X} = \\left[\\boldsymbol{X}_1^{\\top} \\ \\boldsymbol{X}_2^{\\top} \\ \\dots \\ \\boldsymbol{X}_N^{\\top}\\right]^{\\top}\\), and \\(\\boldsymbol{\\mu} = \\left[\\boldsymbol{\\mu}_1^{\\top} \\ \\boldsymbol{\\mu}_2^{\\top} \\ \\dots \\ \\boldsymbol{\\mu}_N^{\\top}\\right]^{\\top}\\). Following the practice of expressing \\(y_{il}^*\\) relative to \\(y_{iL}^*\\) by letting \\(\\boldsymbol{w}_i = \\left[w_{i1} \\ w_{i2} \\ \\dots \\ w_{iL-1}\\right]^{\\top}\\), where \\(w_{il} = y_{il}^* - y_{iL}^*\\), we can write \\(\\boldsymbol{w}_i = \\boldsymbol{R}_i \\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}_i\\), with \\(\\boldsymbol{\\epsilon}_i \\sim N(\\boldsymbol{0}, \\boldsymbol{\\Omega})\\), where \\(\\boldsymbol{R}_i = \\left[(1 \\ \\boldsymbol{c}_i^{\\top}) \\otimes \\boldsymbol{I}_{L-1} \\ \\boldsymbol{\\Delta A}_i\\right]\\) is an \\((L-1) \\times K\\) matrix, with \\(\\Delta \\boldsymbol{A}_i = \\boldsymbol{A}_{li} - \\boldsymbol{A}_{Li}\\), for \\(l = 1, 2, \\dots, L-1\\). That is, the last row of \\(\\boldsymbol{A}_i\\) is subtracted from each row of \\(\\boldsymbol{A}_i\\), and \\(\\boldsymbol{\\beta}\\) is a \\(K\\)-dimensional vector, where \\(K = (L-1) \\times (1 + \\text{dim}(\\boldsymbol{c}_i)) + a\\). Observe that \\(\\boldsymbol{\\beta}\\) contains the same last \\(a\\) elements as \\(\\boldsymbol{\\delta}\\), that is, the alternative-specific attribute coefficients. However, the first \\((L-1) \\times (1 + \\text{dim}(\\boldsymbol{c}_i))\\) elements of \\(\\boldsymbol{\\beta}\\) are the differences \\(\\delta_{jl} - \\delta_{jL}\\), for \\(j = 1, \\dots, \\text{dim}(\\boldsymbol{c}_i)\\) and \\(l = 1, 2, \\dots, L-1\\). That is, these elements represent the difference between the coefficients of each qualitative response and the \\(L\\)-th alternative for the individuals’ characteristics. This makes it difficult to interpret the multinomial probit coefficients. Note that in multinomial models, for each alternative-specific attribute, it is only necessary to estimate one coefficient for all alternatives. However, for individuals’ characteristics (non-alternative-specific regressors), it is required to estimate \\(L-1\\) coefficients, since the coefficient for the base alternative is set equal to 0. The likelihood function in this model is given by \\[ p(\\boldsymbol{\\beta}, \\boldsymbol{\\Omega} \\mid \\boldsymbol{y}, \\boldsymbol{R}) = \\prod_{i=1}^N \\prod_{l=1}^L p_{il}^{y_{il}}, \\] where \\(p_{il} = p(y_{il}^* \\geq \\max(\\boldsymbol{y}_i^*))\\). We assume independent priors for the parameters: \\[ \\boldsymbol{\\beta} \\sim N(\\boldsymbol{\\beta}_0, \\boldsymbol{B}_0) \\quad \\text{and} \\quad \\boldsymbol{\\Omega}^{-1} \\sim W(\\alpha_0, \\boldsymbol{\\Sigma}_0), \\] where \\(W\\) denotes the Wishart density. We can employ Gibbs sampling in this model, as it is a standard Bayesian linear regression model when data augmentation is used for \\(\\boldsymbol{w}\\). The posterior conditional distributions are given by \\[\\begin{equation*} \\boldsymbol{\\beta}\\mid \\boldsymbol{\\Omega},\\boldsymbol{w}\\sim{N}(\\boldsymbol{\\beta}_n,\\boldsymbol{B}_n), \\end{equation*}\\] \\[\\begin{equation*} \\boldsymbol{\\Omega}^{-1}\\mid \\boldsymbol{\\beta},\\boldsymbol{w}\\sim{W}(\\alpha_n,\\boldsymbol{\\Sigma}_n), \\end{equation*}\\] where \\(\\boldsymbol{B}_n=(\\boldsymbol{B}_0^{-1}+\\boldsymbol{X}^{*\\top}\\boldsymbol{X}^*)^{-1}\\), \\(\\boldsymbol{\\beta}_n=\\boldsymbol{B}_n(\\boldsymbol{B}_0^{-1}\\boldsymbol{\\beta}_0+\\boldsymbol{X}^{*\\top}\\boldsymbol{w}^*)\\), \\(\\boldsymbol{\\Omega}^{-1}=\\boldsymbol{C}^{\\top}\\boldsymbol{C}\\), \\(\\boldsymbol{X}_i^{*\\top}=\\boldsymbol{C}^{\\top}\\boldsymbol{R}_i\\), \\(\\boldsymbol{w}_i^*=\\boldsymbol{C}^{\\top}\\boldsymbol{w}_i\\), \\(\\boldsymbol{X}^*=\\begin{bmatrix}\\boldsymbol{X}_1^*\\\\ \\boldsymbol{X}_2^*\\\\ \\vdots\\\\ \\boldsymbol{X}_N^* \\end{bmatrix}\\), \\(\\alpha_n=\\alpha_0+N\\), \\(\\boldsymbol{\\Sigma}_n=(\\boldsymbol{\\Sigma}_0+\\sum_{i=1}^N (\\boldsymbol{w}_i-\\boldsymbol{R}_i\\boldsymbol{\\beta})^{\\top}(\\boldsymbol{w}_i-\\boldsymbol{R}_i\\boldsymbol{\\beta}))^{-1}\\). We can collapse the multinomial vector \\(\\boldsymbol{y}_i\\) into the indicator variable \\(d_i=\\sum_{l=1}^{L-1}l\\times \\mathbb{1}({\\max(\\boldsymbol{w}_{l})=w_{il}})\\).26 Then the distribution of \\(\\boldsymbol{w}_i\\mid \\boldsymbol{\\beta},\\boldsymbol{\\Omega}^{-1},d_i\\) is an \\(L-1\\) dimensional Gaussian distribution truncated over the appropriate cone in \\(\\mathcal{R}^{L-1}\\). R. McCulloch and Rossi (1994) propose drawing from the univariate conditional distributions \\(w_{il}\\mid \\boldsymbol{w}_{i,-l},\\boldsymbol{\\beta},\\boldsymbol{\\Omega}^{-1},d_i\\sim TN_{I_{il}}(m_{il},\\tau_{ll}^2)\\), where \\[\\begin{equation*} I_{il}=\\begin{Bmatrix} w_{il}&gt;\\max(\\boldsymbol{w}_{i,-l},0), &amp; d_i=l\\\\ w_{il}&lt;\\max(\\boldsymbol{w}_{i,-l},0), &amp; d_i\\neq l\\\\ \\end{Bmatrix}, \\end{equation*}\\] and permuting the columns and rows of \\(\\boldsymbol{\\Omega}^{-1}\\) so that the \\(l\\)-th column and row is the last, \\[\\begin{equation*} \\boldsymbol{\\Omega}^{-1}=\\begin{bmatrix} \\boldsymbol{\\Omega}_{-l,-l} &amp; \\boldsymbol\\omega_{-l,l}\\\\ \\boldsymbol\\omega_{l,-1} &amp; \\omega_{l,l}\\\\ \\end{bmatrix}^{-1} =\\begin{bmatrix} \\boldsymbol{\\Omega}_{-l,-l}^{-1}+{\\tau}^{-2}_{ll}\\boldsymbol{f}_l\\boldsymbol{f}_l^{\\top} &amp; -\\boldsymbol{f}_l\\tau^{-2}_{ll}\\\\ -{\\tau}^{-2}_{ll}\\boldsymbol{f}_l^{\\top} &amp; {\\tau}^{-2}_{ll}\\\\ \\end{bmatrix} \\end{equation*}\\] where \\(\\boldsymbol{f}_l=\\boldsymbol{\\Omega}_{-l,-l}^{-1}\\boldsymbol{\\omega}_{-l,l}\\), \\(\\tau_{ll}^2= \\omega_{ll}-\\boldsymbol{\\omega}_{l,-l}\\boldsymbol{\\Omega}^{-1}_{-l,-1}\\boldsymbol{\\omega}_{-l,l}\\), \\(m_{il}=\\boldsymbol{r}_{il}^{\\top}\\boldsymbol{\\beta}+\\boldsymbol{f}_l^{\\top}(\\boldsymbol{w}_{i,-l}-\\boldsymbol{R}_{i,-l}\\boldsymbol{\\beta})\\), \\(\\boldsymbol{w}_{i,-l}\\) is an \\(L-2\\) dimensional vector of all components of \\(\\boldsymbol{w}_i\\) excluding \\(w_{il}\\), \\(\\boldsymbol{r}_{il}\\) is the \\(l\\)-th row of \\(\\boldsymbol{R}_i\\), \\(l=1,2,\\dots,L-1\\). The identified parameters are obtained by normalizing with respect to one of the diagonal elements \\(\\frac{1}{\\omega_{1,1}^{0.5}}\\boldsymbol{\\beta}\\) and \\(\\frac{1}{\\omega_{1,1}}\\boldsymbol{\\Omega}\\).27 Warning: This model is an example where decisions must be made about setting the model in an identified parameter space versus an unidentified parameter space. The mixing properties of the posterior draws can be better in the latter case (R. E. McCulloch, Polson, and Rossi 2000), which typically results in less computational burden. However, it is important to recover the identified space in a final stage. Additionally, defining priors in the unidentified space may have unintended consequences on the posterior distributions in the identified space (Nobile 2000). The multinomial probit model presented in this section is set in the unidentified space (R. McCulloch and Rossi 1994), while a version of the multinomial probit in the identified space is presented by R. E. McCulloch, Polson, and Rossi (2000). Example: Choice of fishing mode We used in this application the dataset 3Fishing.csv from Cameron and Trivedi (2005). The dependent variable is mutually exclusive alternatives regarding fishing modes (mode), where beach is equal to 1, pier is equal to 2, private boat is equal to 3, and chartered boat (baseline alternative) is equal to 4. In this model, we have \\[ \\mathbf{X}_i = \\begin{bmatrix} 1 &amp; 0 &amp; 0 &amp; 0 &amp; \\text{Income}_i &amp; 0 &amp; 0 &amp; 0 &amp; \\text{Price}_{i,1} &amp; \\text{Catch rate}_{i,1}\\\\ 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; \\text{Income}_i &amp; 0 &amp; 0 &amp; \\text{Price}_{i,2} &amp; \\text{Catch rate}_{i,2}\\\\ 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; \\text{Income}_i &amp; 0 &amp; \\text{Price}_{i,3} &amp; \\text{Catch rate}_{i,3}\\\\ 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; \\text{Income}_i &amp; \\text{Price}_{i,4} &amp; \\text{Catch rate}_{i,4}\\\\ \\end{bmatrix} \\] In this example, chartered boat is the base category, the number of choice categories is four, there are two alternative-specific regressors (price and catch rate), and one non-alternative-specific regressor (income). This setting involves the estimation of eight location parameters (\\(\\boldsymbol{\\beta}\\)): three intercepts, three for income, one for price, and one for catch rate. This is the order of the posterior chains in our GUI. Note that the location coefficients are set equal to 0 for the baseline category. For multinomial models, we strongly recommend using the last category as the baseline. We also get posterior estimates for a \\(3\\times 3\\) covariance matrix (four alternatives minus one), where the element (1,1) is equal to 1 due to identification restrictions, and elements 2 and 4 are the same, as well as 3 and 7, and 6 and 8, due to symmetry. Observe that this identification restriction implies NaN values in J. Geweke (1992) and Heidelberger and Welch (1983) tests for element (1,1) of the covariance matrix, and just eight dependence factors associated with the remaining elements of the covariance matrix. Once our GUI is displayed (see beginning of this chapter), we should follow the next Algorithm to run multinomial probit models in our GUI (see Chapter 5 for details), which in turn uses the command rmnpGibbs from the bayesm package. Algorithm: Multinomial Probit model in the GUI Select Univariate Models on the top panel Select Multinomial Probit model using the left radio button Upload the dataset by first selecting whether there is a header in the file, and the kind of separator in the csv file of the dataset (comma, semicolon, or tab). Then, use the Browse button under the Choose File legend. You should see a preview of the dataset Select MCMC iterations, burn-in, and thinning parameters using the Range sliders Select dependent and independent variables using the Formula builder table Select the number of the Base Alternative Select the Number of choice categorical alternatives Select the Number of alternative specific variables Select the Number of Non-alternative specific variables Click the Build formula button to generate the formula in R syntax. Set the hyperparameters: mean vector, covariance matrix, scale matrix, and degrees of freedom. This step is not necessary as by default our GUI uses non-informative priors Click the Go! button Analyze results Download posterior chains and diagnostic plots using the Download Posterior Chains and Download Posterior Graphs buttons We ran 100,000 MCMC iterations plus 10,000 as burn-in with a thinning parameter equal to 5, where all priors use default values for the hyperparameters in our GUI. We found that the 95% credible intervals of the coefficient associated with income for beach and private boat alternatives are equal to (8.58e-06, 8.88e-05) and (3.36e-05, 1.45e-04). This suggests that the probability of choosing these alternatives increases compared to a chartered boat when income increases. In addition, an increase in the price or a decrease in the catch rate for specific fishing alternatives imply lower probabilities of choosing them as the 95% credible intervals are (-9.91e-03, -3.83e-03) and (1.40e-01, 4.62e-01), respectively. However, the posterior chain diagnostics suggest there are convergence issues with the posterior draws (see Exercise 5). References "],["sec65.html", "6.5 The multinomial logit model", " 6.5 The multinomial logit model The multinomial logit model is used to model mutually exclusive discrete outcomes or qualitative response variables. However, this model assumes the independence of irrelevant alternatives (IIA), meaning that the choice between two alternatives does not depend on a third alternative. We consider the multinomial mixed logit model (not to be confused with the random parameters logit model), which accounts for both alternative-varying regressors (conditional) and alternative-invariant regressors (multinomial) simultaneously.28 In this setting, there are \\(L\\) mutually exclusive alternatives, and the dependent variable \\(y_{il}\\) is equal to 1 if the \\(l\\)th alternative is chosen by individual \\(i\\), and 0 otherwise, where \\(l=\\left\\{1,2,\\dots,L\\right\\}\\). The likelihood function is \\[ p(\\boldsymbol{\\beta} \\mid \\boldsymbol{y}, \\boldsymbol{X}) = \\prod_{i=1}^{N} \\prod_{l=1}^{L} p_{il}^{y_{il}}, \\] where the probability that individual \\(i\\) chooses the alternative \\(l\\) is given by \\[ p_{il} := p(y_i = l \\mid \\boldsymbol{\\beta}, \\boldsymbol{X}) = \\frac{\\exp\\left\\{\\boldsymbol{x}_{il}^{\\top} \\boldsymbol{\\beta}_l\\right\\}}{\\sum_{j=1}^{L} \\exp\\left\\{\\boldsymbol{x}_{ij}^{\\top} \\boldsymbol{\\beta}_j\\right\\}}, \\] \\(\\boldsymbol{y}\\) and \\(\\boldsymbol{X}\\) are the vector and matrix of the dependent variable and regressors, respectively, and \\(\\boldsymbol{\\beta}\\) is the vector containing all the coefficients. Remember that coefficients associated with alternative-invariant regressors are set to 0 for the baseline category, and the coefficients associated with the alternative-varying regressors are the same for all the categories. In addition, we assume \\(\\boldsymbol{\\beta} \\sim N(\\boldsymbol{\\beta}_0, \\boldsymbol{B}_0)\\) as the prior distribution. Thus, the posterior distribution is \\[ \\pi(\\boldsymbol{\\beta} \\mid \\boldsymbol{y}, \\boldsymbol{X}) \\propto p(\\boldsymbol{\\beta} \\mid \\boldsymbol{y}, \\boldsymbol{X}) \\times \\pi(\\boldsymbol{\\beta}). \\] As the multinomial logit model does not have a standard posterior distribution, P. E. Rossi, Allenby, and McCulloch (2012) propose a “tailored” independent Metropolis-Hastings algorithm where the proposal distribution is a multivariate Student’s \\(t\\) distribution with \\(v\\) degrees of freedom (tuning parameter), mean equal to the maximum likelihood estimator, and scale equal to the inverse of the Hessian matrix. Example: Simulation exercise Let’s conduct a simulation exercise to evaluate the performance of the Metropolis-Hastings algorithm for inference in the multinomial logit model. We consider a scenario with three alternatives, one alternative-invariant regressor (plus the intercept), and three alternative-varying regressors. The population parameters are given by \\(\\boldsymbol{\\beta}_1 = [1 \\ -2.5 \\ 0.5 \\ 0.8 \\ -3]^{\\top}\\), \\(\\boldsymbol{\\beta}_2 = [1 \\ -3.5 \\ 0.5 \\ 0.8 \\ -3]^{\\top}\\), and \\(\\boldsymbol{\\beta}_3 = [0 \\ 0 \\ 0.5 \\ 0.8 \\ -3]^{\\top}\\), where the first two elements of each vector correspond to the intercept and the alternative-invariant regressor, while the last three elements correspond to the alternative-varying regressors. The sample size is 1000, and all regressors are simulated from standard normal distributions. We can deploy our GUI using the command line at the beginning of this chapter. We should follow the next Algorithm to run multinomial logit models in our GUI (see Chapter 5 for details). Algorithm: Multinomial logit models Select Univariate Models on the top panel Select Multinomial Logit model using the left radio button Upload the dataset by first selecting whether there is a header in the file, and the kind of separator in the csv file of the dataset (comma, semicolon, or tab). Then, use the Browse button under the Choose File legend. You should see a preview of the dataset Select MCMC iterations, burn-in, and thinning parameters using the Range sliders Select dependent and independent variables using the Formula builder table Select the Base Alternative Select the Number of choice categorical alternatives Select the Number of alternative specific variables Select the Number of Non-alternative specific variables Click the Build formula button to generate the formula in R syntax. Set the hyperparameters: mean vector and covariance matrix. This step is not necessary as by default our GUI uses non-informative priors Select the tuning parameter for the Metropolis-Hastings algorithm, that is, the Degrees of freedom: Multivariate Student’s t distribution Click the Go! button Analyze results Download posterior chains and diagnostic plots using the Download Posterior Chains and Download Posterior Graphs buttons The following code in R demonstrates how to implement the M-H algorithm from scratch. The first part simulates the dataset, the second part constructs the log-likelihood function, and the third part implements the M-H algorithm. We use vague priors centered at zero, with a covariance matrix of \\(1000\\mathbf{I}_7\\). We observe that the posterior estimates closely match the population parameters, and all 95% credible intervals contain the population parameters. remove(list = ls()) set.seed(12345) # Simulation of data N&lt;-1000 # Sample Size B&lt;-c(0.5,0.8,-3); B1&lt;-c(-2.5,-3.5,0); B2&lt;-c(1,1,0) # Alternative specific attributes of choice 1, for instance, price, quality and duration of choice 1 X1&lt;-matrix(cbind(rnorm(N,0,1),rnorm(N,0,1),rnorm(N,0,1)),N,length(B)) # Alternative specific attributes of choice 2, for instance, price, quality and duration of choice 2 X2&lt;-matrix(cbind(rnorm(N,0,1),rnorm(N,0,1),rnorm(N,0,1)),N,length(B)) # Alternative specific attributes of choice 3, for instance, price, quality and duration of choice 3 X3&lt;-matrix(cbind(rnorm(N,0,1),rnorm(N,0,1),rnorm(N,0,1)),N,length(B)) X4&lt;-matrix(rnorm(N,1,1),N,1) V1&lt;-B2[1]+X1%*%B+B1[1]*X4; V2&lt;-B2[2]+X2%*%B+B1[2]*X4; V3&lt;-B2[3]+X3%*%B+B1[3]*X4 suma&lt;-exp(V1)+exp(V2)+exp(V3) p1&lt;-exp(V1)/suma; p2&lt;-exp(V2)/suma; p3&lt;-exp(V3)/suma p&lt;-cbind(p1,p2,p3) y&lt;- apply(p,1, function(x)sample(1:3, 1, prob = x, replace = TRUE)) y1&lt;-y==1; y2&lt;-y==2; y3&lt;-y==3 # Log likelihood log.L&lt;- function(Beta){ V1&lt;-Beta[1]+Beta[3]*X4+X1%*%Beta[5:7] V2&lt;-Beta[2]+Beta[4]*X4+X2%*%Beta[5:7] V3&lt;- X3%*%Beta[5:7] suma&lt;-exp(V1)+exp(V2)+exp(V3) p11&lt;-exp(V1)/suma; p22&lt;-exp(V2)/suma; p33&lt;-exp(V3)/suma suma2&lt;-NULL for(i in 1:N){ suma1&lt;-y1[i]*log(p11[i])+y2[i]*log(p22[i])+y3[i]*log(p33[i]) suma2&lt;-c(suma2,suma1)} logL&lt;-sum(suma2) return(-logL) } # Parameters: Proposal k &lt;- 7 res.optim&lt;-optim(rep(0, k), log.L, method=&quot;BFGS&quot;, hessian=TRUE) MeanT &lt;- res.optim$par ScaleT &lt;- as.matrix(Matrix::forceSymmetric(solve(res.optim$hessian))) # Force this matrix to be symmetric # Hyperparameters: Priors B0 &lt;- 1000*diag(k); b0 &lt;- rep(0, k) MHfunction &lt;- function(iter, tuning){ Beta &lt;- rep(0, k); Acept &lt;- NULL BetasPost &lt;- matrix(NA, iter, k) pb &lt;- winProgressBar(title = &quot;progress bar&quot;, min = 0, max = iter, width = 300) for(s in 1:iter){ LogPostBeta &lt;- -log.L(Beta) + mvtnorm::dmvnorm(Beta, mean = b0, sigma = B0, log = TRUE) BetaC &lt;- c(LaplacesDemon::rmvt(n=1, mu = MeanT, S = ScaleT, df = tuning)) LogPostBetaC &lt;- -log.L(BetaC) + mvtnorm::dmvnorm(BetaC, mean = b0, sigma = B0, log = TRUE) alpha &lt;- min(exp((LogPostBetaC-mvtnorm::dmvt(BetaC, delta = MeanT, sigma = ScaleT, df = tuning, log = TRUE))-(LogPostBeta-mvtnorm::dmvt(Beta, delta = MeanT, sigma = ScaleT, df = tuning, log = TRUE))) ,1) u &lt;- runif(1) if(u &lt;= alpha){ Acepti &lt;- 1; Beta &lt;- BetaC }else{ Acepti &lt;- 0; Beta &lt;- Beta } BetasPost[s, ] &lt;- Beta; Acept &lt;- c(Acept, Acepti) setWinProgressBar(pb, s, title=paste( round(s/iter*100, 0),&quot;% done&quot;)) } close(pb); AcepRate &lt;- mean(Acept) Results &lt;- list(AcepRate = AcepRate, BetasPost = BetasPost) return(Results) } # MCMC parameters mcmc &lt;- 10000; burnin &lt;- 1000; thin &lt;- 5; iter &lt;- mcmc + burnin; keep &lt;- seq(burnin, iter, thin); tuning &lt;- 6 # Degrees of freedom ResultsPost &lt;- MHfunction(iter = iter, tuning = tuning) summary(coda::mcmc(ResultsPost$BetasPost[keep[-1], ])) ## ## Iterations = 1:2000 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 2000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## [1,] 0.9711 0.20162 0.004508 0.004508 ## [2,] 0.9742 0.20934 0.004681 0.004681 ## [3,] -2.4350 0.18950 0.004237 0.004137 ## [4,] -3.4195 0.24656 0.005513 0.005513 ## [5,] 0.5253 0.07396 0.001654 0.001654 ## [6,] 0.8061 0.08007 0.001790 0.001790 ## [7,] -3.0853 0.17689 0.003955 0.003955 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## var1 0.5862 0.8367 0.9650 1.1017 1.3683 ## var2 0.5679 0.8310 0.9681 1.1151 1.3761 ## var3 -2.8239 -2.5607 -2.4291 -2.3050 -2.0812 ## var4 -3.9176 -3.5806 -3.4074 -3.2496 -2.9423 ## var5 0.3840 0.4761 0.5250 0.5759 0.6647 ## var6 0.6555 0.7494 0.8064 0.8616 0.9604 ## var7 -3.4476 -3.1991 -3.0777 -2.9641 -2.7500 References "],["sec66.html", "6.6 Ordered probit model", " 6.6 Ordered probit model The ordered probit model is used when there is a natural order in the categorical response variable. In this case, there is a latent variable \\(y_i^* = \\mathbf{x}_i^{\\top}\\boldsymbol{\\beta} + \\mu_i\\), where \\(\\mathbf{x}_i\\) is a \\(K\\)-dimensional vector of regressors, \\(\\mu_i \\stackrel{i.i.d.}{\\sim} N(0,1)\\), such that \\(y_i = l\\) if and only if \\(\\alpha_{l-1} &lt; y_i^* \\leq \\alpha_l\\), for \\(l \\in \\{1, 2, \\dots, L\\}\\), where \\(\\alpha_0 = -\\infty\\), \\(\\alpha_1 = 0\\), and \\(\\alpha_L = \\infty\\).29 Then, the probability of observing \\(y_i = l\\) is given by: \\[ p(y_i = l) = \\Phi(\\alpha_l - \\mathbf{x}_i^{\\top}\\boldsymbol{\\beta}) - \\Phi(\\alpha_{l-1} - \\mathbf{x}_i^{\\top}\\boldsymbol{\\beta}), \\] and the likelihood function is: \\[ p(\\boldsymbol{\\beta}, \\boldsymbol{\\alpha} \\mid \\mathbf{y}, \\mathbf{X}) = \\prod_{i=1}^{N} p(y_i = l \\mid \\boldsymbol{\\beta}, \\boldsymbol{\\alpha}, \\mathbf{X}). \\] The priors in this model are independent, i.e., \\(\\pi(\\boldsymbol{\\beta}, \\boldsymbol{\\gamma}) = \\pi(\\boldsymbol{\\beta}) \\times \\pi(\\boldsymbol{\\gamma})\\), where \\(\\boldsymbol{\\beta} \\sim N(\\boldsymbol{\\beta}_0, \\boldsymbol{B}_0)\\) and \\(\\boldsymbol{\\gamma} \\sim N(\\boldsymbol{\\gamma}_0, \\boldsymbol{\\Gamma}_0)\\), and \\(\\boldsymbol{\\gamma} = \\left[ \\gamma_2 \\ \\gamma_3 \\ \\dots \\ \\gamma_{L-1} \\right]^{\\top}\\), such that: \\[ \\boldsymbol{\\alpha} = \\left[ \\exp\\left\\{\\gamma_2\\right\\} \\ \\sum_{l=2}^{3} \\exp\\left\\{\\gamma_l\\right\\} \\ \\dots \\ \\sum_{l=2}^{L-1} \\exp\\left\\{\\gamma_l\\right\\} \\right]^{\\top}. \\] This structure imposes the ordinal condition on the cut-offs. This model does not have a standard conditional posterior distribution for \\(\\boldsymbol{\\gamma}\\) (\\(\\boldsymbol{\\alpha}\\)), but it does have a standard conditional distribution for \\(\\boldsymbol{\\beta}\\) once data augmentation is used. We can then use a Metropolis-within-Gibbs sampling algorithm. In particular, we use Gibbs sampling to draw \\(\\boldsymbol{\\beta}\\) and \\(\\boldsymbol{y}^*\\), where: \\[ \\boldsymbol{\\beta} \\mid \\boldsymbol{y}^*, \\boldsymbol{\\alpha}, \\boldsymbol{X} \\sim N(\\boldsymbol{\\beta}_n, \\boldsymbol{B}_n), \\] with \\(\\boldsymbol{B}_n = (\\boldsymbol{B}_0^{-1} + \\boldsymbol{X}^{\\top}\\boldsymbol{X})^{-1}\\), \\(\\boldsymbol{\\beta}_n = \\boldsymbol{B}_n(\\boldsymbol{B}_0^{-1}\\boldsymbol{\\beta}_0 + \\boldsymbol{X}^{\\top}\\boldsymbol{y}^*)\\), and: \\[ y_i^* \\mid \\boldsymbol{\\beta}, \\boldsymbol{\\alpha}, \\boldsymbol{y}, \\boldsymbol{X} \\sim TN_{(\\alpha_{y_i-1}, \\alpha_{y_i})}(\\boldsymbol{x}_i^{\\top}\\boldsymbol{\\beta}, 1). \\] We use a random-walk Metropolis–Hastings algorithm for \\(\\boldsymbol{\\gamma}\\) with a proposal distribution that is Gaussian with mean equal to the current value and covariance matrix \\(s^2(\\boldsymbol{\\Gamma}_0^{-1} + \\hat{\\boldsymbol{\\Sigma}}_{\\gamma}^{-1})^{-1}\\), where \\(s &gt; 0\\) is a tuning parameter and \\(\\hat{\\boldsymbol{\\Sigma}}_{\\gamma}\\) is the sample covariance matrix associated with \\(\\gamma\\) from the maximum likelihood estimation. Example: Determinants of preventive health care visits We used the file named 2HealthMed.csv in this application. In particular, the dependent variable is MedVisPrevOr, which is an ordered variable equal to 1 if the individual did not visit a physician for preventive reasons, 2 if the individual visited once in that year, and so on, until it is equal to 6 for visiting five or more times. The latter category represents 1.6% of the sample. Observe that the dependent variable has six categories. In this example, the set of regressors is given by SHI, which is an indicator of being in the subsidized health care system (1 means being in the system), sex (Female), age (both linear and squared), socioeconomic conditions indicator (Est2 and Est3), with the lowest being the baseline category, self-perception of health status (Fair, Good, and Excellent), where Bad is the baseline, and education level (PriEd, HighEd, VocEd, UnivEd), with no education as the baseline category. We ran this application with 50,000 MCMC iterations plus 10,000 as burn-in, and a thinning parameter equal to 5. This setting means 10,000 effective posterior draws. We set \\(\\boldsymbol{\\beta}_0 = \\boldsymbol{0}_{11}\\), \\(\\boldsymbol{B}_0 = 1000\\boldsymbol{I}_{11}\\), \\(\\boldsymbol{\\gamma}_0 = \\boldsymbol{0}_4\\), \\(\\boldsymbol{\\Gamma}_0 = \\boldsymbol{I}_4\\), and the tuning parameter is 1. We can run the ordered probit models in our GUI following the steps in the next Algorithm. Algorithm: Ordered probit models Select Univariate Models on the top panel Select Ordered Probit model using the left radio button Upload the dataset by first selecting whether there is a header in the file, and the kind of separator in the csv file of the dataset (comma, semicolon, or tab). Then, use the Browse button under the Choose File legend. You should see a preview of the dataset Select MCMC iterations, burn-in, and thinning parameters using the Range sliders Select dependent and independent variables using the Formula builder table Click the Build formula button to generate the formula in R syntax. Remember that this formula must have -1 to omit the intercept in the specification. Set the hyperparameters: mean vectors and covariance matrices. This step is not necessary as by default our GUI uses non-informative priors Select the number of ordered alternatives Set the hyperparameters: mean and covariance matrix of the cutoffs. This step is not necessary as by default our GUI uses non-informative prior Select the tuning parameter for the Metropolis-Hastings algorithm Click the Go! button Analyze results Download posterior chains and diagnostic plots using the Download Posterior Chains and Download Posterior Graphs buttons The following R code shows how to perform inference in this model using the command rordprobitGibbs from the bayesm library, which is the command that our GUI uses. rm(list = ls()) set.seed(010101) Data &lt;- read.csv(&quot;https://raw.githubusercontent.com/besmarter/BSTApp/refs/heads/master/DataApp/2HealthMed.csv&quot;, sep = &quot;,&quot;, header = TRUE, quote = &quot;&quot;) attach(Data) ## The following objects are masked from mydata: ## ## Age, Age2, Bad, Est1, Est2, Est3, Excellent, Fair, Female, ## FemaleAge, Good, HighEd, Hosp, id, MedVisPrev, MedVisPrevOr, NoEd, ## PriEd, PTL, SHI, UnivEd, VocEd ## The following objects are masked from Data (pos = 4): ## ## Age, Age2 y &lt;- MedVisPrevOr # MedVisPrevOr: Oredered variable for preventive visits to doctors in one year: 1 (none), 2 (once), ... 6 (five or more) X &lt;- cbind(SHI, Female, Age, Age2, Est2, Est3, Fair, Good, Excellent, PriEd, HighEd, VocEd, UnivEd) k &lt;- dim(X)[2] L &lt;- length(table(y)) # Hyperparameters b0 &lt;- rep(0, k); c0 &lt;- 1000; B0 &lt;- c0*diag(k) gamma0 &lt;- rep(0, L-2); Gamma0 &lt;- diag(L-2) # MCMC parameters mcmc &lt;- 60000+1; thin &lt;- 5; tuningPar &lt;- 1/(L-2)^0.5 DataApp &lt;- list(y = y, X = X, k = L) Prior &lt;- list(betabar = b0, A = solve(B0), dstarbar = gamma0, Ad = Gamma0) mcmcpar &lt;- list(R = mcmc, keep = 5, s = tuningPar, nprint = 0) PostBeta &lt;- bayesm::rordprobitGibbs(Data = DataApp, Prior = Prior, Mcmc = mcmcpar) ## ## Starting Gibbs Sampler for Ordered Probit Model ## with 12975 observations ## ## Table of y values ## y ## 1 2 3 4 5 6 ## 1935 2837 1241 2043 4711 208 ## ## Prior Parms: ## betabar ## [1] 0 0 0 0 0 0 0 0 0 0 0 0 0 ## ## A ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] ## [1,] 0.001 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 ## [2,] 0.000 0.001 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 ## [3,] 0.000 0.000 0.001 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 ## [4,] 0.000 0.000 0.000 0.001 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 ## [5,] 0.000 0.000 0.000 0.000 0.001 0.000 0.000 0.000 0.000 0.000 0.000 0.000 ## [6,] 0.000 0.000 0.000 0.000 0.000 0.001 0.000 0.000 0.000 0.000 0.000 0.000 ## [7,] 0.000 0.000 0.000 0.000 0.000 0.000 0.001 0.000 0.000 0.000 0.000 0.000 ## [8,] 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.001 0.000 0.000 0.000 0.000 ## [9,] 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.001 0.000 0.000 0.000 ## [10,] 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.001 0.000 0.000 ## [11,] 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.001 0.000 ## [12,] 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.001 ## [13,] 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 ## [,13] ## [1,] 0.000 ## [2,] 0.000 ## [3,] 0.000 ## [4,] 0.000 ## [5,] 0.000 ## [6,] 0.000 ## [7,] 0.000 ## [8,] 0.000 ## [9,] 0.000 ## [10,] 0.000 ## [11,] 0.000 ## [12,] 0.000 ## [13,] 0.001 ## ## dstarbar ## [1] 0 0 0 0 ## ## Ad ## [,1] [,2] [,3] [,4] ## [1,] 1 0 0 0 ## [2,] 0 1 0 0 ## [3,] 0 0 1 0 ## [4,] 0 0 0 1 ## ## MCMC parms: ## R= 60001 keep= 5 nprint= 0 s= 0.5 ## BetasPost &lt;- coda::mcmc(PostBeta[[&quot;betadraw&quot;]]) colnames(BetasPost) &lt;- c(&quot;SHI&quot;, &quot;Female&quot;, &quot;Age&quot;, &quot;Age2&quot;, &quot;Est2&quot;, &quot;Est3&quot;, &quot;Fair&quot;, &quot;Good&quot;, &quot;Excellent&quot;, &quot;PriEd&quot;, &quot;HighEd&quot;, &quot;VocEd&quot;, &quot;UnivEd&quot;) summary(BetasPost) ## ## Iterations = 1:12000 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 12000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## SHI 0.0654824 2.281e-02 2.082e-04 3.357e-04 ## Female -0.0374788 1.908e-02 1.742e-04 1.742e-04 ## Age 0.0190336 1.869e-03 1.706e-05 4.576e-05 ## Age2 -0.0002328 2.438e-05 2.225e-07 6.690e-07 ## Est2 0.0949445 2.226e-02 2.032e-04 4.659e-04 ## Est3 -0.1383965 3.411e-02 3.114e-04 3.459e-04 ## Fair 0.6451828 5.375e-02 4.907e-04 3.924e-03 ## Good 0.7343932 4.955e-02 4.523e-04 4.491e-03 ## Excellent 0.9826531 6.393e-02 5.836e-04 5.261e-03 ## PriEd 0.0309418 2.376e-02 2.169e-04 2.221e-04 ## HighEd -0.1805753 2.910e-02 2.656e-04 3.456e-04 ## VocEd 0.1395760 9.640e-02 8.800e-04 9.291e-04 ## UnivEd -0.2218120 1.189e-01 1.086e-03 1.086e-03 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## SHI 0.0209045 0.0499525 0.0654041 0.0808572 0.1102130 ## Female -0.0746364 -0.0504288 -0.0377778 -0.0245643 0.0002350 ## Age 0.0155088 0.0178114 0.0190228 0.0202305 0.0226864 ## Age2 -0.0002804 -0.0002479 -0.0002328 -0.0002168 -0.0001864 ## Est2 0.0514963 0.0800442 0.0948246 0.1096800 0.1393326 ## Est3 -0.2055927 -0.1614479 -0.1381575 -0.1156348 -0.0717986 ## Fair 0.5579955 0.6129584 0.6414878 0.6726800 0.7439563 ## Good 0.6669005 0.7080863 0.7303217 0.7540621 0.8106430 ## Excellent 0.8891998 0.9477048 0.9783661 1.0102615 1.0846084 ## PriEd -0.0158405 0.0149388 0.0310167 0.0471892 0.0773202 ## HighEd -0.2378212 -0.2003574 -0.1802174 -0.1607329 -0.1243538 ## VocEd -0.0491123 0.0747424 0.1381100 0.2041479 0.3333107 ## UnivEd -0.4538119 -0.3023902 -0.2219313 -0.1414801 0.0086323 # Convergence diagnostics coda::geweke.diag(BetasPost) ## ## Fraction in 1st window = 0.1 ## Fraction in 2nd window = 0.5 ## ## SHI Female Age Age2 Est2 Est3 Fair Good ## 1.9824 0.1488 1.6564 -1.5988 0.9782 -1.9159 1.2891 1.2890 ## Excellent PriEd HighEd VocEd UnivEd ## 1.3675 2.2458 -1.3570 1.0199 -0.6709 coda::raftery.diag(BetasPost,q=0.5,r=0.05,s = 0.95) ## ## Quantile (q) = 0.5 ## Accuracy (r) = +/- 0.05 ## Probability (s) = 0.95 ## ## Burn-in Total Lower bound Dependence ## (M) (N) (Nmin) factor (I) ## SHI 2 393 385 1.020 ## Female 2 382 385 0.992 ## Age 2 401 385 1.040 ## Age2 2 399 385 1.040 ## Est2 2 409 385 1.060 ## Est3 1 385 385 1.000 ## Fair 6 1227 385 3.190 ## Good 12 1792 385 4.650 ## Excellent 6 1233 385 3.200 ## PriEd 2 392 385 1.020 ## HighEd 2 392 385 1.020 ## VocEd 2 390 385 1.010 ## UnivEd 2 393 385 1.020 coda::heidel.diag(BetasPost) ## ## Stationarity start p-value ## test iteration ## SHI passed 1201 0.8026 ## Female passed 1 0.5041 ## Age passed 1201 0.0812 ## Age2 passed 1201 0.0928 ## Est2 passed 1201 0.1970 ## Est3 passed 1201 0.4047 ## Fair failed NA 0.0360 ## Good failed NA 0.0156 ## Excellent failed NA 0.0403 ## PriEd passed 1 0.1479 ## HighEd passed 1201 0.0870 ## VocEd passed 1 0.5223 ## UnivEd passed 1 0.6614 ## ## Halfwidth Mean Halfwidth ## test ## SHI passed 0.065098 4.19e-04 ## Female passed -0.037479 3.41e-04 ## Age passed 0.018970 3.38e-05 ## Age2 passed -0.000232 4.40e-07 ## Est2 passed 0.094472 4.10e-04 ## Est3 passed -0.138067 6.42e-04 ## Fair &lt;NA&gt; NA NA ## Good &lt;NA&gt; NA NA ## Excellent &lt;NA&gt; NA NA ## PriEd passed 0.030942 4.35e-04 ## HighEd passed -0.180255 5.47e-04 ## VocEd passed 0.139576 1.82e-03 ## UnivEd passed -0.221812 2.13e-03 # Cut offs Cutoffs &lt;- PostBeta[[&quot;cutdraw&quot;]] summary(Cutoffs) ## Summary of Posterior Marginal Distributions ## Moments ## mean std dev num se rel eff sam size ## 1 0.00 0.000 -1.0e+04 -9999 -9999 ## 2 0.71 0.013 1.3e-03 108 99 ## 3 0.96 0.014 1.3e-03 96 112 ## 4 1.37 0.015 1.3e-03 85 127 ## 5 3.20 0.030 1.8e-03 38 277 ## ## Quantiles ## 2.5% 5% 50% 95% 97.5% ## 1 0.00 0.00 0.00 0.00 0.00 ## 2 0.68 0.69 0.71 0.73 0.73 ## 3 0.93 0.94 0.96 0.98 0.98 ## 4 1.33 1.34 1.37 1.39 1.39 ## 5 3.14 3.15 3.20 3.25 3.26 ## based on 10800 valid draws (burn-in=1200) coda::geweke.diag(Cutoffs) ## ## Fraction in 1st window = 0.1 ## Fraction in 2nd window = 0.5 ## ## var1 var2 var3 var4 var5 ## NaN 0.5305 1.2222 1.2512 1.6850 coda::heidel.diag(Cutoffs) ## ## Stationarity start p-value ## test iteration ## [,1] failed NA NA ## [,2] passed 1201 0.2060 ## [,3] passed 1201 0.1192 ## [,4] passed 1201 0.1004 ## [,5] passed 1201 0.0681 ## ## Halfwidth Mean Halfwidth ## test ## [,1] &lt;NA&gt; NA NA ## [,2] passed 0.71 0.00399 ## [,3] passed 0.96 0.00349 ## [,4] passed 1.37 0.00300 ## [,5] passed 3.20 0.00295 coda::raftery.diag(Cutoffs[,-1],q=0.5,r=0.05,s = 0.95) ## ## Quantile (q) = 0.5 ## Accuracy (r) = +/- 0.05 ## Probability (s) = 0.95 ## ## Burn-in Total Lower bound Dependence ## (M) (N) (Nmin) factor (I) ## 390 49320 385 128.0 ## 340 43214 385 112.0 ## 224 28504 385 74.0 ## 64 7432 385 19.3 The results suggest that older individuals (at a decreasing rate) in the subsidized health program, characterized by being in the second socioeconomic status, with an increasing self-perception of good health, and not having high school as their highest education degree, have a higher probability of visiting a physician for preventive health purposes. Convergence diagnostics look well, except for the self-health perception draws. We also obtained the posterior estimates of the cutoffs in the ordered probit model. These estimates are necessary to calculate the probability that an individual is in a specific category of physician visits. Due to identification restrictions, the first cutoff is set equal to 0. This is why we observe NaN values in J. Geweke (1992) and Heidelberger and Welch (1983) tests, and only four values in the A. E. Raftery and Lewis (1992) test, which correspond to the remaining free cutoffs. It seems that these cutoff estimates have some convergence issues when using the A. E. Raftery and Lewis (1992) test as a diagnostic tool. Furthermore, their dependence factors are also very high. References "],["negative-binomial-model.html", "6.7 Negative binomial model", " 6.7 Negative binomial model The dependent variable in the negative binomial model is a nonnegative integer or count. In contrast to the Poisson model, the negative binomial model accounts for over-dispersion. The Poisson model assumes equi-dispersion, meaning the mean and variance are equal. We assume that \\(y_i \\stackrel{i.i.d.} {\\sim} \\text{NB}(\\gamma, \\theta_i)\\), where the density function for individual \\(i\\) is \\[ \\frac{\\Gamma(y_i + \\gamma)}{\\Gamma(\\gamma) y_i!} (1 - \\theta_i)^{y_i} \\theta_i^{\\gamma}, \\] with the success probability \\(\\theta_i = \\frac{\\gamma}{\\lambda_i + \\gamma}\\), where \\(\\lambda_i = \\exp\\left\\{\\mathbf{x}_i^{\\top} \\boldsymbol{\\beta}\\right\\}\\) is the mean, and \\(\\gamma = \\exp\\left\\{\\alpha \\right\\}\\) is the target for the number of successful trials, or the dispersion parameter, and \\(\\mathbf{x}_i\\) is a \\(K\\)-dimensional vector of regressors. We assume independent priors for this model: \\(\\boldsymbol{\\beta} \\sim N(\\boldsymbol{\\beta}_0, \\mathbf{B}_0)\\) and \\(\\alpha \\sim G(\\alpha_0, \\delta_0)\\). This model does not have standard conditional posterior distributions. Therefore, P. E. Rossi, Allenby, and McCulloch (2012) propose using a random-walk Metropolis–Hastings algorithm where the proposal distribution for \\(\\boldsymbol{\\beta}\\) is Gaussian, centered at the current stage, with covariance matrix \\(s_{\\boldsymbol{\\beta}}^2 \\hat{\\mathbf{\\Sigma}}_{\\boldsymbol{\\beta}}\\), where \\(s_{\\boldsymbol{\\beta}}\\) is a tuning parameter and \\(\\hat{\\mathbf{\\Sigma}}_{\\boldsymbol{\\beta}}\\) is the maximum likelihood covariance estimator. Additionally, the proposal for \\(\\alpha\\) is normal, centered at the current value, with variance \\(s_{\\alpha}^2 \\hat{\\sigma}_{\\alpha}^2\\), where \\(s_{\\alpha}\\) is a tuning parameter and \\(\\hat{\\sigma}_{\\alpha}^2\\) is the maximum likelihood variance estimator. Example: Simulation exercise Let’s do a simulation exercise to check the performance of the M-H algorithms in the negative binomial model. There are two regressors, \\(x_{i1} \\sim U(0,1)\\) and \\(x_{i2} \\sim N(0,1)\\), and the intercept. The dispersion parameter is \\(\\gamma = \\exp\\left\\{1.2\\right\\}\\), and \\(\\boldsymbol{\\beta} = \\left[1 \\ 1 \\ 1\\right]^{\\top}\\). The sample size is 1,000. We run this simulation using 10,000 MCMC iterations, a burn-in equal to 1,000, and a thinning parameter equal to 5. We set vague priors for the location parameters, particularly, \\(\\boldsymbol{\\beta}_0 = \\boldsymbol{0}_{3}\\) and \\(\\boldsymbol{B}_0 = 1000\\boldsymbol{I}_{3}\\), and \\(\\alpha_0 = 0.5\\) and \\(\\delta_0 = 0.1\\), which are the default values in the rnegbinRw command from the bayesm package in R. In addition, the tuning parameters of the Metropolis–Hastings algorithms are \\(s_{\\boldsymbol{\\beta}} = 2.93/k^{1/2}\\) and \\(s_{\\alpha} = 2.93\\), which are also the default parameters in rnegbinRw, where \\(k\\) is the number of location parameters. We can run the negative binomial models in our GUI following the steps in the next Algorithm. Algorithm: Negative binomial models Select Univariate Models on the top panel Select Negative Binomial (Poisson) model using the left radio button Upload the dataset by first selecting whether there is a header in the file, and the kind of separator in the csv file of the dataset (comma, semicolon, or tab). Then, use the Browse button under the Choose File legend. You should see a preview of the dataset Select MCMC iterations, burn-in, and thinning parameters using the Range sliders Select dependent and independent variables using the Formula builder table Click the Build formula button to generate the formula in R syntax. You can modify the formula in the Main equation box using valid arguments of the formula command structure in R Set the hyperparameters: mean vector, covariance matrix, shape, and scale parameters. This step is not necessary as by default our GUI uses non-informative priors Select the tuning parameters for the Metropolis-Hastings algorithms Click the Go! button Analyze results Download posterior chains and diagnostic plots using the Download Posterior Chains and Download Posterior Graphs buttons The following R code shows how to perform inference in the negative binomial model programming the M-H algorithms from scratch. We ask to estimate this example using the rnegbinRw command in Exercise 8. We observe from the results that all 95% credible intervals encompass the population parameters, and the posterior means are very close to the population parameters. rm(list = ls()) set.seed(010101) N &lt;- 2000 # Sample size x1 &lt;- runif(N); x2 &lt;- rnorm(N) X &lt;- cbind(1, x1, x2); k &lt;- dim(X)[2]; B &lt;- rep(1, k) alpha &lt;- 1.2; gamma &lt;- exp(alpha); lambda &lt;- exp(X%*%B) y &lt;- rnbinom(N, mu = lambda, size = gamma) # log likelihood logLik &lt;- function(par){ alpha &lt;- par[1]; beta &lt;- par[2:(k+1)] gamma &lt;- exp(alpha) lambda &lt;- exp(X%*%beta) logLikNB &lt;- sum(sapply(1:N, function(i){dnbinom(y[i], size = gamma, mu = lambda[i], log = TRUE)})) return(-logLikNB) } # Parameters: Proposal par0 &lt;- rep(0.5, k+1) res.optim &lt;- suppressWarnings(optim(par0, logLik, method=&quot;BFGS&quot;, hessian=TRUE)) res.optim$par ## [1] 1.3173049 1.0267103 0.9981069 0.9669848 res.optim$convergence ## [1] 0 Covar &lt;- solve(res.optim$hessian) CovarBetas &lt;- Covar[2:(k+1),2:(k+1)] VarAlpha &lt;- Covar[1:1] # Hyperparameters: Priors B0 &lt;- 1000*diag(k); b0 &lt;- rep(0, k) alpha0 &lt;- 0.5; delta0 &lt;- 0.1 # Metropolis-Hastings function MHfunction &lt;- function(iter, sbeta, salpha){ Beta &lt;- rep(0, k); Acept1 &lt;- NULL; Acept2 &lt;- NULL BetasPost &lt;- matrix(NA, iter, k); alpha &lt;- 1 alphaPost &lt;- rep(NA, iter); par &lt;- c(alpha, Beta) pb &lt;- winProgressBar(title = &quot;progress bar&quot;, min = 0, max = iter, width = 300) for(s in 1:iter){ LogPostBeta &lt;- -logLik(par) + dgamma(alpha, shape = alpha0, scale = delta0, log = TRUE) + mvtnorm::dmvnorm(Beta, mean = b0, sigma = B0, log = TRUE) BetaC &lt;- c(MASS::mvrnorm(1, mu = Beta, Sigma = sbeta^2*CovarBetas)) parC &lt;- c(alpha, BetaC) LogPostBetaC &lt;- -logLik(parC) + dgamma(alpha, shape = alpha0, scale = delta0, log = TRUE) + mvtnorm::dmvnorm(BetaC, mean = b0, sigma = B0, log = TRUE) alpha1 &lt;- min(exp((LogPostBetaC - mvtnorm::dmvnorm(BetaC, mean = Beta, sigma = sbeta^2*CovarBetas, log = TRUE))-(LogPostBeta - mvtnorm::dmvnorm(Beta, mean = Beta, sigma = sbeta^2*CovarBetas, log = TRUE))),1) u1 &lt;- runif(1) if(u1 &lt;= alpha1){Acept1i &lt;- 1; Beta &lt;- BetaC}else{ Acept1i &lt;- 0; Beta &lt;- Beta } par &lt;- c(alpha, Beta) LogPostBeta &lt;- -logLik(par) + dgamma(alpha, shape = alpha0, scale = delta0, log = TRUE) + mvtnorm::dmvnorm(Beta, mean = b0, sigma = B0, log = TRUE) alphaC &lt;- rnorm(1, mean = alpha, sd = salpha*VarAlpha^0.5) parC &lt;- c(alphaC, Beta) LogPostBetaC &lt;- -logLik(parC) + dgamma(alphaC, shape = alpha0, scale = delta0, log = TRUE) + mvtnorm::dmvnorm(Beta, mean = b0, sigma = B0, log = TRUE) alpha2 &lt;- min(exp((LogPostBetaC - dnorm(alphaC, mean = alpha, sd = salpha*VarAlpha^0.5, log = TRUE))-(LogPostBeta - dnorm(alpha, mean = alpha, sd = salpha*VarAlpha^0.5, log = TRUE))),1) u2 &lt;- runif(1) if(u2 &lt;= alpha2){Acept2i &lt;- 1; alpha &lt;- alphaC}else{ Acept2i &lt;- 0; alpha &lt;- alpha } BetasPost[s, ] &lt;- Beta; alphaPost[s] &lt;- alpha Acept1 &lt;- c(Acept1, Acept1i); Acept2 &lt;- c(Acept2, Acept2i) setWinProgressBar(pb, s, title=paste( round(s/iter*100, 0),&quot;% done&quot;)) } close(pb) AcepRateBeta &lt;- mean(Acept1); AcepRateAlpha &lt;- mean(Acept2) Results &lt;- list(AcepRateBeta = AcepRateBeta, AcepRateAlpha = AcepRateAlpha, BetasPost = BetasPost, alphaPost = alphaPost) return(Results) } # MCMC parameters mcmc &lt;- 10000 burnin &lt;- 1000 thin &lt;- 5 iter &lt;- mcmc + burnin keep &lt;- seq(burnin, iter, thin) sbeta &lt;- 2.93/sqrt(k); salpha &lt;- 2.93 # Run M-H ResultsPost &lt;- MHfunction(iter = iter, sbeta = sbeta, salpha = salpha) ResultsPost$AcepRateBeta ## [1] 0.3892727 ResultsPost$AcepRateAlpha ## [1] 0.4021818 summary(coda::mcmc(ResultsPost$BetasPost[keep[-1], ])) ## ## Iterations = 1:2000 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 2000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## [1,] 1.0269 0.04612 0.0010314 0.0014371 ## [2,] 0.9973 0.07593 0.0016978 0.0023584 ## [3,] 0.9676 0.02343 0.0005239 0.0006485 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## var1 0.9429 0.9946 1.0276 1.0567 1.118 ## var2 0.8529 0.9454 0.9967 1.0525 1.138 ## var3 0.9221 0.9525 0.9677 0.9831 1.014 summary(coda::mcmc(ResultsPost$alphaPost[keep[-1]])) ## ## Iterations = 1:2000 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 2000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## 1.280156 0.058052 0.001298 0.001491 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## 1.169 1.242 1.279 1.317 1.396 References "],["sec68.html", "6.8 Tobit model", " 6.8 Tobit model The dependent variable is partially observed in Tobit models due to sampling schemes, whereas the regressors are completely observed. In particular, \\[\\begin{equation} y_i = \\begin{Bmatrix} L, &amp; \\quad y_i^* &lt; L, \\\\ y_i^*, &amp; \\quad L \\leq y_i^* &lt; U, \\\\ U, &amp; \\quad y_i^* \\geq U, \\end{Bmatrix} \\end{equation}\\] where \\(y_i^* \\stackrel{i.i.d.}{\\sim} N(\\mathbf{x}_i^{\\top} \\boldsymbol{\\beta}, \\sigma^2)\\), \\(\\mathbf{x}_i\\) is a \\(K\\)-dimensional vector of regressors.30 We use conjugate independent priors \\(\\boldsymbol{\\beta} \\sim N(\\boldsymbol{\\beta}_0, \\mathbf{B}_0)\\) and \\(\\sigma^2 \\sim IG(\\alpha_0/2, \\delta_0/2)\\), and data augmentation using \\(\\mathbf{y}^*_C\\) such that \\(y_{C_i}^* \\stackrel{i.n.d.}{\\thicksim} N(\\mathbf{x}_i^{\\top} \\boldsymbol{\\beta}, \\sigma^2)\\), \\(y_{C_i} = \\left\\{ y_{C_i^L}^* \\cup y_{C_i^U}^* \\right\\}\\) are lower and upper censored data. This allows implementing the Gibbs sampling algorithm (S. Chib 1992). Then, \\[\\begin{align} \\pi(\\boldsymbol{\\beta}, \\sigma^2, \\mathbf{y^*} \\mid \\mathbf{y}, \\mathbf{X}) &amp;\\propto \\prod_{i=1}^N \\left[ \\mathbb{1}({y_i = L}) \\mathbb{1}({y_{C_i^L}^* &lt; L}) + \\mathbb{1}({L \\leq y_i &lt; U}) + \\mathbb{1}({y_i = U}) \\mathbb{1}({y_{C_i^U}^* \\geq U}) \\right] \\\\ &amp;\\times N(y_i^* \\mid \\mathbf{x}_i^{\\top} \\boldsymbol{\\beta}, \\sigma^2) \\times N(\\boldsymbol{\\beta} \\mid \\boldsymbol{\\beta}_0, \\mathbf{B}_0) \\times IG(\\sigma^2 \\mid \\alpha_0/2, \\delta_0/2) \\end{align}\\] The posterior distributions are: \\[\\begin{equation} y_{C_i}^* \\mid \\boldsymbol{\\beta}, \\sigma^2, \\mathbf{y}, \\mathbf{X} \\sim \\begin{Bmatrix} TN_{(-\\infty,L)}(\\mathbf{x}_i^{\\top}\\boldsymbol{\\beta}, \\sigma^2) \\ , \\ y_i = L \\\\ TN_{[U, \\infty)}(\\mathbf{x}_i^{\\top}\\boldsymbol{\\beta}, \\sigma^2) \\ \\ , \\ y_i = U \\end{Bmatrix} \\end{equation}\\] \\[\\begin{equation} \\boldsymbol{\\beta} \\mid \\sigma^2, \\mathbf{y}, \\mathbf{X} \\sim N(\\boldsymbol{\\beta}_n, \\sigma^2 \\mathbf{B}_n) \\end{equation}\\] \\[\\begin{equation} \\sigma^2 \\mid \\boldsymbol{\\beta}, \\mathbf{y}, \\mathbf{X} \\sim IG(\\alpha_n/2, \\delta_n/2) \\end{equation}\\] where \\(\\mathbf{B}_n = (\\mathbf{B}_0^{-1} + \\sigma^{-2} \\mathbf{X}^{\\top} \\mathbf{X})^{-1}\\), \\(\\boldsymbol{\\beta}_n = \\mathbf{B}_n(\\mathbf{B}_0^{-1} \\boldsymbol{\\beta}_0 + \\sigma^{-2} \\mathbf{X}^{\\top} \\mathbf{y}^*)\\), \\(\\alpha_n = \\alpha_0 + N\\), and \\(\\delta_n = \\delta_0 + (\\mathbf{y}^* - \\mathbf{X} \\boldsymbol{\\beta})^{\\top}(\\mathbf{y}^* - \\mathbf{X} \\boldsymbol{\\beta})\\). Example: The market value of soccer players in Europe continues We continue with the example of the market value of soccer players from Section 6.1. We specify the same equation but assume that the sample is censored from below, such that we only have information for soccer players whose market value is higher than one million euros. The dependent variable is log(ValueCens), and the left censoring point is 13.82. The following Algorithm illustrates how to estimate Tobit models in our GUI. Our GUI utilizes the MCMCtobit command from the MCMCpack package. Algorithm: Tobit models Select Univariate Models on the top panel Select Tobit model using the left radio button Upload the dataset by first selecting whether there is a header in the file, and the kind of separator in the csv file of the dataset (comma, semicolon, or tab). Then, use the Browse button under the Choose File legend. You should see a preview of the dataset Select MCMC iterations, burn-in, and thinning parameters using the Range sliders Select dependent and independent variables using the Formula builder table Click the Build formula button to generate the formula in R syntax. You can modify the formula in the Main equation box using valid arguments of the formula command structure in R Set the left and right censoring points. To censor above only, specify -Inf in the left censoring box, and to censor below only, specify Inf in the right censoring box Set the hyperparameters: mean vector, covariance matrix, shape, and scale parameters. This step is not necessary as by default our GUI uses non-informative priors Click the Go! button Analyze results Download posterior chains and diagnostic plots using the Download Posterior Chains and Download Posterior Graphs buttons We run this application using the same hyperparameters that we set in the example of Section 6.1. All results seem similar to those in the example of linear models. In addition, the posterior chains seem to achieve good diagnostics. rm(list = ls()); set.seed(010101) Data &lt;- read.csv(&quot;https://raw.githubusercontent.com/besmarter/BSTApp/refs/heads/master/DataApp/1ValueFootballPlayers.csv&quot;, sep = &quot;,&quot;, header = TRUE, quote = &quot;&quot;) attach(Data) ## The following objects are masked from Data (pos = 3): ## ## Age, Age2 ## The following objects are masked from mydata: ## ## Age, Age2 ## The following objects are masked from Data (pos = 5): ## ## Age, Age2, Assists, Exp, Exp2, Goals, Goals2, NatTeam, Perf, Perf2, ## Player, Value, ValueCens y &lt;- log(ValueCens) X &lt;- cbind(1, Perf, Age, Age2, NatTeam, Goals, Exp, Exp2) k &lt;- dim(X)[2] N &lt;- dim(X)[1] # Hyperparameters d0 &lt;- 0.001; a0 &lt;- 0.001 b0 &lt;- rep(0, k); c0 &lt;- 1000; B0 &lt;- c0*diag(k) B0i &lt;- solve(B0) # MCMC parameters mcmc &lt;- 50000 burnin &lt;- 10000 tot &lt;- mcmc + burnin thin &lt;- 1 # Posterior distributions using packages: MCMCpack sets the model in terms of the precision matrix posterior &lt;- MCMCpack::MCMCtobit(y~X-1, b0=b0, B0 = B0i, c0 = a0, d0 = d0, burnin = burnin, mcmc = mcmc, thin = thin, below = 13.82, above = Inf) summary(coda::mcmc(posterior)) ## ## Iterations = 1:50000 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 50000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## X 1.049702 2.639780 1.181e-02 1.676e-02 ## XPerf 0.033979 0.004512 2.018e-05 2.288e-05 ## XAge 1.024758 0.213319 9.540e-04 1.337e-03 ## XAge2 -0.021861 0.004002 1.790e-05 2.546e-05 ## XNatTeam 0.847758 0.126113 5.640e-04 6.463e-04 ## XGoals 0.010091 0.001649 7.376e-06 7.688e-06 ## XExp 0.174196 0.070237 3.141e-04 3.808e-04 ## XExp2 -0.005652 0.002977 1.331e-05 1.555e-05 ## sigma2 0.982768 0.095944 4.291e-04 6.698e-04 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## X -4.192313 -0.713326 1.071600 2.841806 6.1771087 ## XPerf 0.025131 0.030948 0.033967 0.036976 0.0428691 ## XAge 0.609991 0.880679 1.023709 1.167147 1.4480407 ## XAge2 -0.029803 -0.024542 -0.021820 -0.019162 -0.0141026 ## XNatTeam 0.603262 0.762408 0.847351 0.932705 1.0950039 ## XGoals 0.006877 0.008975 0.010094 0.011193 0.0133502 ## XExp 0.037752 0.126722 0.173706 0.221290 0.3127266 ## XExp2 -0.011525 -0.007632 -0.005642 -0.003657 0.0001633 ## sigma2 0.811752 0.915417 0.976781 1.042729 1.1887701 # Gibbs sampling functions XtX &lt;- t(X)%*%X PostBeta &lt;- function(Yl, sig2){ Bn &lt;- solve(B0i + sig2^(-1)*XtX) bn &lt;- Bn%*%(B0i%*%b0 + sig2^(-1)*t(X)%*%Yl) Beta &lt;- MASS::mvrnorm(1, bn, Bn) return(Beta) } PostYl &lt;- function(Beta, L, U, i){ Ylmean &lt;- X[i,]%*%Beta if(y[i] == L){ Yli &lt;- truncnorm::rtruncnorm(1, a = -Inf, b = L, mean = Ylmean, sd = sig2^0.5) }else{ if(y[i] == U){ Yli &lt;- truncnorm::rtruncnorm(1, a = U, b = Inf, mean = Ylmean, sd = sig2^0.5) }else{ Yli &lt;- y[i] } } return(Yli) } PostSig2 &lt;- function(Beta, Yl){ an &lt;- a0 + length(y) dn &lt;- d0 + t(Yl - X%*%Beta)%*%(Yl - X%*%Beta) sig2 &lt;- invgamma::rinvgamma(1, shape = an/2, rate = dn/2) return(sig2) } PostBetas &lt;- matrix(0, mcmc+burnin, k); Beta &lt;- rep(0, k) PostSigma2 &lt;- rep(0, mcmc+burnin); sig2 &lt;- 1 L &lt;- log(1000000); U &lt;- Inf # create progress bar in case that you want to see iterations progress pb &lt;- winProgressBar(title = &quot;progress bar&quot;, min = 0, max = tot, width = 300) for(s in 1:tot){ Yl &lt;- sapply(1:N, function(i){PostYl(Beta = Beta, L = L, U = U, i)}) Beta &lt;- PostBeta(Yl = Yl, sig2) sig2 &lt;- PostSig2(Beta = Beta, Yl = Yl) PostBetas[s,] &lt;- Beta; PostSigma2[s] &lt;- sig2 setWinProgressBar(pb, s, title=paste( round(s/tot*100, 0), &quot;% done&quot;)) } close(pb) ## NULL keep &lt;- seq((burnin+1), tot, thin) PosteriorBetas &lt;- PostBetas[keep,] colnames(PosteriorBetas) &lt;- c(&quot;Intercept&quot;, &quot;Perf&quot;, &quot;Age&quot;, &quot;Age2&quot;, &quot;NatTeam&quot;, &quot;Goals&quot;, &quot;Exp&quot;, &quot;Exp2&quot;) summary(coda::mcmc(PosteriorBetas)) ## ## Iterations = 1:50000 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 50000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## Intercept 1.023783 2.640151 1.181e-02 1.649e-02 ## Perf 0.033982 0.004496 2.011e-05 2.198e-05 ## Age 1.026527 0.213505 9.548e-04 1.322e-03 ## Age2 -0.021902 0.004005 1.791e-05 2.520e-05 ## NatTeam 0.849435 0.125673 5.620e-04 6.394e-04 ## Goals 0.010093 0.001652 7.390e-06 7.745e-06 ## Exp 0.175137 0.070498 3.153e-04 3.877e-04 ## Exp2 -0.005685 0.002985 1.335e-05 1.578e-05 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## Intercept -4.218202 -0.737377 1.048790 2.818320 6.1265295 ## Perf 0.025253 0.030947 0.033956 0.036986 0.0428926 ## Age 0.612543 0.881473 1.024929 1.169122 1.4478207 ## Age2 -0.029837 -0.024583 -0.021874 -0.019170 -0.0141402 ## NatTeam 0.603543 0.764706 0.849179 0.933046 1.0994449 ## Goals 0.006808 0.008979 0.010097 0.011208 0.0133334 ## Exp 0.038449 0.127461 0.174294 0.223045 0.3138970 ## Exp2 -0.011563 -0.007695 -0.005659 -0.003663 0.0001001 summary(coda::mcmc(PostSigma2[keep])) ## ## Iterations = 1:50000 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 50000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## 0.9860750 0.0963754 0.0004310 0.0006757 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## 0.8156 0.9186 0.9792 1.0469 1.1937 References "],["sec69.html", "6.9 Quantile regression", " 6.9 Quantile regression In quantile regression, the location parameters vary according to the quantile of the dependent variable. Let \\(q_{\\tau}(\\boldsymbol{x}_i) = \\boldsymbol{x}_i^{\\top} \\boldsymbol{\\beta}_{\\tau}\\) denote the \\(\\tau\\)-th quantile regression function of \\(y_i\\) given \\(\\boldsymbol{x}_i\\), where \\(\\boldsymbol{x}_i\\) is a \\(K\\)-dimensional vector of regressors, and \\(0 &lt; \\tau &lt; 1\\). Specifically, we have the model \\(y_i = \\boldsymbol{x}_i^{\\top} \\boldsymbol{\\beta}_{\\tau} + \\mu_i\\), with the condition \\(\\int_{-\\infty}^{0} f_{\\tau}(\\mu_i) \\, d\\mu_i = \\tau\\), meaning that the \\(\\tau\\)-th quantile of \\(\\mu_i\\) is 0. In particular, Kozumi and Kobayashi (2011) propose the asymmetric Laplace distribution for \\(f_{\\tau}(\\mu_i)\\), given by \\[ f_{\\tau}(\\mu_i) = \\tau(1 - \\tau) \\exp\\left\\{- \\mu_i(\\tau - \\mathbb{1}({\\mu_i &lt; 0})) \\right\\}, \\] where \\(\\mu_i(\\tau - \\mathbb{1}({\\mu_i &lt; 0}))\\) is the check (loss) function. These authors also propose a location-scale mixture of normals representation, given by \\[ \\mu_i = \\theta e_i + \\psi \\sqrt{e_i} z_i, \\] where \\(\\theta = \\frac{1 - 2\\tau}{\\tau(1 - \\tau)}\\), \\(\\psi^2 = \\frac{2}{\\tau(1 - \\tau)}\\), \\(e_i \\sim E(1)\\), and \\(z_i \\sim N(0,1)\\), with \\(e_i \\perp z_i\\).31 As a result of this representation and the fact that the sample is i.i.d., the likelihood function is \\[ p(\\boldsymbol{y} \\mid \\boldsymbol{\\beta}_{\\tau}, \\boldsymbol{e}, \\boldsymbol{X}) \\propto \\left( \\prod_{i=1}^{N} e_i^{-1/2} \\right) \\exp\\left\\{- \\sum_{i=1}^{N} \\frac{(y_i - \\boldsymbol{x}_i^{\\top} \\boldsymbol{\\beta}_{\\tau} - \\theta e_i)^2}{2 \\psi^2 e_i} \\right\\}. \\] Assuming a normal prior for \\(\\boldsymbol{\\beta}_{\\tau}\\), i.e., \\(\\boldsymbol{\\beta}_{\\tau} \\sim N(\\boldsymbol{\\beta}_{\\tau 0}, \\boldsymbol{B}_{\\tau 0})\\), and using data augmentation for \\(\\boldsymbol{e}\\), we can implement a Gibbs sampling algorithm for this model. The posterior distributions are as follows: \\[\\begin{equation*} \\boldsymbol{\\beta}_{\\tau} \\mid \\boldsymbol{e}, \\boldsymbol{y}, \\boldsymbol{X} \\sim N(\\boldsymbol{\\beta}_{n\\tau}, \\boldsymbol{B}_{n\\tau}), \\end{equation*}\\] \\[\\begin{equation*} e_i \\mid \\boldsymbol{\\beta}_{\\tau}, \\boldsymbol{y}, \\boldsymbol{X} \\sim \\text{GIG}\\left( \\frac{1}{2}, \\alpha_{ni}, \\delta_{ni} \\right), \\end{equation*}\\] where \\[\\begin{align*} \\boldsymbol{B}_{n\\tau} &amp;= \\left( \\boldsymbol{B}_{\\tau 0}^{-1} + \\sum_{i=1}^{N} \\frac{\\boldsymbol{x}_i \\boldsymbol{x}_i^{\\top}}{\\psi^2 e_i} \\right)^{-1}, \\\\ \\boldsymbol{\\beta}_{n\\tau} &amp;= \\boldsymbol{B}_{n\\tau} \\left( \\boldsymbol{B}_{\\tau 0}^{-1} \\boldsymbol{\\beta}_{\\tau 0} + \\sum_{i=1}^{N} \\frac{\\boldsymbol{x}_i (y_i - \\theta e_i)}{\\psi^2 e_i} \\right), \\\\ \\alpha_{ni} &amp;= \\frac{(y_i - \\boldsymbol{x}_i^{\\top} \\boldsymbol{\\beta}_{\\tau})^2}{\\psi^2}, \\quad \\delta_{ni} = 2 + \\frac{\\theta^2}{\\psi^2}. \\end{align*}\\] Example: The market value of soccer players in Europe continues We continue the example of the market value of soccer players from Section 6.1. Now, we want to examine whether the marginal effect of having been on the national team varies with the quantile of the market value of top soccer players in Europe. Thus, we use the same regressors as in the previous example, but analyze the effects at the 0.5-th and 0.9-th quantiles of NatTeam. The following Algorithm shows how to estimate quantile regression models in our GUI. Our GUI uses the command MCMCquantreg from the package MCMCpack. The following code demonstrates how to perform this analysis using the package. The results show that at the median market value (0.5-th quantile), the 95% credible interval for the coefficient associated with national team is (0.34, 1.02), with a posterior mean of 0.69. At the 0.9-th quantile, these values are (0.44, 1.59) and 1.03, respectively. It appears that being on the national team increases the market value of more expensive players more significantly on average, although there is some overlap in the credible intervals. Algorithm: Quantile regression Select Univariate Models on the top panel Select Quantile model using the left radio button Upload the dataset by first selecting whether there is a header in the file, and the kind of separator in the csv file of the dataset (comma, semicolon, or tab). Then, use the Browse button under the Choose File legend. You should see a preview of the dataset Select MCMC iterations, burn-in, and thinning parameters using the Range sliders Select dependent and independent variables using the Formula builder table Click the Build formula button to generate the formula in R syntax. You can modify the formula in the Main equation box using valid arguments of the formula command structure in R Set the quantile to be analyzed, by default it is 0.5 Set the hyperparameters: mean vector and covariance matrix. This step is not necessary as by default our GUI uses non-informative priors Click the Go! button Analyze results Download posterior chains and diagnostic plots using the Download Posterior Chains and Download Posterior Graphs buttons rm(list = ls()); set.seed(010101) Data &lt;- read.csv(&quot;https://raw.githubusercontent.com/besmarter/BSTApp/refs/heads/master/DataApp/1ValueFootballPlayers.csv&quot;, sep = &quot;,&quot;, header = TRUE, quote = &quot;&quot;) attach(Data) ## The following objects are masked from Data (pos = 3): ## ## Age, Age2, Assists, Exp, Exp2, Goals, Goals2, NatTeam, Perf, Perf2, ## Player, Value, ValueCens ## The following objects are masked from Data (pos = 4): ## ## Age, Age2 ## The following objects are masked from mydata: ## ## Age, Age2 ## The following objects are masked from Data (pos = 6): ## ## Age, Age2, Assists, Exp, Exp2, Goals, Goals2, NatTeam, Perf, Perf2, ## Player, Value, ValueCens y &lt;- log(ValueCens) X &lt;- cbind(1, Perf, Age, Age2, NatTeam, Goals, Exp, Exp2) k &lt;- dim(X)[2]; N &lt;- dim(X)[1] # Hyperparameters b0 &lt;- rep(0, k); c0 &lt;- 1000; B0 &lt;- c0*diag(k); B0i &lt;- solve(B0) # MCMC parameters mcmc &lt;- 50000; burnin &lt;- 10000 tot &lt;- mcmc + burnin; thin &lt;- 1 # Quantile q &lt;- 0.5 posterior05 &lt;- MCMCpack::MCMCquantreg(y~X-1, tau = q, b0=b0, B0 = B0i, burnin = burnin, mcmc = mcmc, thin = thin, below = 13.82, above = Inf) summary(coda::mcmc(posterior05)) ## ## Iterations = 1:50000 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 50000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## X 7.380881 2.922415 1.307e-02 2.305e-02 ## XPerf 0.029380 0.005972 2.671e-05 5.269e-05 ## XAge 0.550080 0.242058 1.083e-03 1.911e-03 ## XAge2 -0.012009 0.004607 2.061e-05 3.665e-05 ## XNatTeam 0.681238 0.170806 7.639e-04 1.564e-03 ## XGoals 0.010642 0.002415 1.080e-05 1.958e-05 ## XExp 0.091802 0.085777 3.836e-04 6.821e-04 ## XExp2 -0.002962 0.003874 1.733e-05 2.930e-05 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## X 1.721153 5.421451 7.355579 9.3156087 13.189612 ## XPerf 0.017526 0.025434 0.029410 0.0333849 0.040987 ## XAge 0.070621 0.389228 0.552940 0.7121539 1.020032 ## XAge2 -0.020951 -0.015103 -0.012073 -0.0089386 -0.002859 ## XNatTeam 0.341558 0.568023 0.682516 0.7949333 1.017583 ## XGoals 0.005849 0.009081 0.010586 0.0122120 0.015472 ## XExp -0.068241 0.032809 0.088512 0.1472835 0.269448 ## XExp2 -0.010951 -0.005446 -0.002856 -0.0003978 0.004471 q &lt;- 0.9 posterior09 &lt;- MCMCpack::MCMCquantreg(y~X-1, tau = q, b0=b0, B0 = B0i, burnin = burnin, mcmc = mcmc, thin = thin, below = 13.82, above = Inf) summary(coda::mcmc(posterior09)) ## ## Iterations = 1:50000 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 50000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## X 8.871556 5.825738 2.605e-02 6.605e-02 ## XPerf 0.019617 0.010110 4.521e-05 1.127e-04 ## XAge 0.531550 0.473922 2.119e-03 5.320e-03 ## XAge2 -0.012324 0.008689 3.886e-05 9.523e-05 ## XNatTeam 1.039941 0.295468 1.321e-03 3.453e-03 ## XGoals 0.008703 0.004295 1.921e-05 4.799e-05 ## XExp 0.136201 0.176328 7.886e-04 2.064e-03 ## XExp2 -0.002835 0.007613 3.405e-05 8.450e-05 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## X -2.4546594 4.890189 8.838894 12.807759 20.296222 ## XPerf -0.0001067 0.012859 0.019580 0.026298 0.039655 ## XAge -0.3889773 0.210175 0.531298 0.850672 1.462811 ## XAge2 -0.0295151 -0.018080 -0.012278 -0.006447 0.004438 ## XNatTeam 0.4437112 0.845176 1.045862 1.241973 1.600731 ## XGoals 0.0018928 0.005572 0.008122 0.011280 0.018537 ## XExp -0.2241036 0.019995 0.142557 0.258915 0.461877 ## XExp2 -0.0163570 -0.008121 -0.003296 0.001949 0.013474 References "],["sec610.html", "6.10 Bayesian bootstrap regression", " 6.10 Bayesian bootstrap regression We implement the Bayesian bootstrap (Donnald B. Rubin 1981) for linear regression models. In particular, the Bayesian bootstrap simulates the posterior distributions by assuming that the sample cumulative distribution function (CDF) is the population CDF (this assumption is also implicit in the frequentist bootstrap (B. Efron 1979)). Given \\(y_i \\stackrel{i.i.d.}{\\sim} \\mathcal{F}\\), where \\(\\mathcal{F}\\) does not specify a particular parametric family of distributions, but instead sets \\(\\mathbb{E}(y_i \\mid \\boldsymbol{x}_i) = \\boldsymbol{x}_i^{\\top} \\boldsymbol{\\beta}\\), with \\(\\boldsymbol{x}_i\\) being a \\(K\\)-dimensional vector of regressors and \\(\\boldsymbol{\\beta}\\) a \\(K\\)-dimensional vector of parameters, the Bayesian bootstrap generates posterior probabilities for each \\(y_i\\), where the values of \\(\\boldsymbol{y}\\) that are not observed have zero posterior probability. The algorithm to implement the Bayesian bootstrap is the following: Algorithm: Bayesian bootstrap Draw g ∼ Dir(α1, α2, ..., αN) such that αi=1 for all i g=(g1, g2, ..., gN) is the vector of probabilities to attach to (y1,x1), (y2,x2), ..., (yN,xN) for each Bayesian bootstrap replication. Sample (yi,xi) N times with replacement and probabilities gi, i=1,2, ...,N. Estimate β using ordinary least squares in the model E(y|X)=Xβ, y being a S1 dimensional vector, and X a S1 X K matrix from the previous stage. Repeat this process S times. The distribution of β(s) is the Bayesian distribution of β. Example: Simulation exercise Let’s perform a simulation exercise to evaluate the performance of the previous Algorithm for inference using the Bayesian bootstrap. The data-generating process is defined by two regressors, each distributed as standard normal. The location vector is \\(\\boldsymbol{\\beta} = \\left[1 \\ 1 \\ 1\\right]^{\\top}\\), with a variance of \\(\\sigma^2 = 1\\), and the sample size is 1,000. The following Algorithm illustrates how to use our GUI to run the Bayesian bootstrap. Our GUI is based on the bayesboot command from the bayesboot package in R. Exercise 11 asks about using this package to perform inference in this simulation and compares the results with those obtained using our GUI with \\(S = 10000\\). Algorithm: Bayesian Bootstrap in Linear Regression Select Univariate Models on the top panel Select Bootstrap model using the left radio button Upload the dataset by first selecting whether there is a header in the file, and the kind of separator in the csv file of the dataset (comma, semicolon, or tab). Then, use the Browse button under the Choose File legend. You should see a preview of the dataset Select number of bootstrap replications using the Range sliders Select dependent and independent variables using the Formula builder table Click the Build formula button to generate the formula in R syntax. You can modify the formula in the Main equation box using valid arguments of the formula command structure in R Click the Go! button Analyze results Download posterior chains and diagnostic plots using the Download Posterior Chains and Download Posterior Graphs buttons The following R code shows how to program the Bayesian bootstrap from scratch. We observe from the results that all 95% credible intervals encompass the population parameters, and the posterior means are close to the population parameters. rm(list = ls()); set.seed(010101) N &lt;- 1000; x1 &lt;- runif(N); x2 &lt;- rnorm(N) X &lt;- cbind(x1, x2); k &lt;- dim(X)[2] B &lt;- rep(1, k+1); sig2 &lt;- 1 u &lt;- rnorm(N, 0, sig2); y &lt;- cbind(1, X)%*%B + u data &lt;- as.data.frame(cbind(y, X)) names(data) &lt;- c(&quot;y&quot;, &quot;x1&quot;, &quot;x2&quot;) Reg &lt;- function(d){ Reg &lt;- lm(y ~ x1 + x2, data = d) Bhat &lt;- Reg$coef return(Bhat) } S &lt;- 10000; alpha &lt;- 1 BB &lt;- function(S, df, alpha){ Betas &lt;- matrix(NA, S, dim(df)[2]) N &lt;- dim(df)[1] pb &lt;- winProgressBar(title = &quot;progress bar&quot;, min = 0, max = S, width = 300) for(s in 1:S){ g &lt;- LaplacesDemon::rdirichlet(N, alpha) ids &lt;- sample(1:N, size = N, replace = TRUE, prob = g) datas &lt;- df[ids,] names(datas) &lt;- names(df) Bs &lt;- Reg(d = datas) Betas[s, ] &lt;- Bs setWinProgressBar(pb, s, title=paste( round(s/S*100, 0), &quot;% done&quot;)) } close(pb) return(Betas) } BBs &lt;- BB(S = S, df = data, alpha = alpha) summary(coda::mcmc(BBs)) ## ## Iterations = 1:10000 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 10000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## [1,] 0.9182 0.06475 0.0006475 0.0006475 ## [2,] 1.1735 0.10948 0.0010948 0.0010948 ## [3,] 1.0133 0.03359 0.0003359 0.0003359 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## var1 0.7882 0.8755 0.9178 0.9612 1.045 ## var2 0.9560 1.1009 1.1738 1.2467 1.391 ## var3 0.9467 0.9902 1.0134 1.0362 1.079 References "],["sec611.html", "6.11 Summary", " 6.11 Summary In this chapter, we present the core univariate regression models and demonstrate how to perform Bayesian inference using Markov Chain Monte Carlo (MCMC) methods. Specifically, we cover a range of algorithms: Gibbs sampling, Metropolis-Hastings, nested Metropolis-Hastings, and Metropolis-Hastings-within-Gibbs. These algorithms form the foundation for performing Bayesian inference in more complex settings using cross-sectional datasets. "],["sec612.html", "6.12 Exercises", " 6.12 Exercises Get the posterior conditional distributions of the Gaussian linear model assuming independent priors \\(\\pi(\\boldsymbol{\\beta}, \\sigma^2) = \\pi(\\boldsymbol{\\beta}) \\times \\pi(\\sigma^2)\\), where \\(\\boldsymbol{\\beta} \\sim N(\\boldsymbol{\\beta}_0, \\boldsymbol{B}_0)\\) and \\(\\sigma^2 \\sim IG(\\alpha_0/2, \\delta_0/2)\\). Given the model \\(y_i \\sim N(\\boldsymbol{x}_i^{\\top} \\boldsymbol{\\beta}, \\sigma^2/\\tau_i)\\) (Gaussian linear model with heteroskedasticity) with independent priors, \\(\\pi(\\boldsymbol{\\beta}, \\sigma^2, \\boldsymbol{\\tau}) = \\pi(\\boldsymbol{\\beta}) \\times \\pi(\\sigma^2) \\times \\prod_{i=1}^N \\pi(\\tau_i)\\), where \\(\\boldsymbol{\\beta} \\sim N(\\boldsymbol{\\beta}_0, \\boldsymbol{B}_0)\\), \\(\\sigma^2 \\sim IG(\\alpha_0/2, \\delta_0/2)\\), and \\(\\tau_i \\sim G(v/2, v/2)\\). Show that \\[ \\boldsymbol{\\beta} \\mid \\sigma^2, \\boldsymbol{\\tau}, \\boldsymbol{y}, \\boldsymbol{X} \\sim N(\\boldsymbol{\\beta}_n, \\boldsymbol{B}_n), \\quad \\sigma^2 \\mid \\boldsymbol{\\beta}, \\boldsymbol{\\tau}, \\boldsymbol{y}, \\boldsymbol{X} \\sim IG(\\alpha_n/2, \\delta_n/2), \\] and \\[ \\tau_i \\mid \\boldsymbol{\\beta}, \\sigma^2, \\boldsymbol{y}, \\boldsymbol{X} \\sim G(v_{1n}/2, v_{2in}/2), \\] where \\(\\boldsymbol{\\tau} = [\\tau_1 \\dots \\tau_n]^{\\top}\\), \\(\\boldsymbol{B}_n = (\\boldsymbol{B}_0^{-1} + \\sigma^{-2} \\boldsymbol{X}^{\\top} \\Psi \\boldsymbol{X})^{-1}\\), \\[ \\boldsymbol{\\beta}_n = \\boldsymbol{B}_n (\\boldsymbol{B}_0^{-1} \\boldsymbol{\\beta}_0 + \\sigma^{-2} \\boldsymbol{X}^{\\top} \\Psi \\boldsymbol{y}), \\] \\(\\alpha_n = \\alpha_0 + N\\), \\(\\delta_n = \\delta_0 + (\\boldsymbol{y} - \\boldsymbol{X} \\boldsymbol{\\beta})^{\\top} \\Psi (\\boldsymbol{y} - \\boldsymbol{X} \\boldsymbol{\\beta})\\), \\(v_{1n} = v + 1\\), \\(v_{2in} = v + \\sigma^{-2}(y_i - \\boldsymbol{x}_i^{\\top} \\boldsymbol{\\beta})^2\\), and \\(\\Psi = \\text{diagonal}\\{\\tau_i\\}\\). The market value of soccer players in Europe continues Use the setting of the previous exercise to perform inference using a Gibbs sampling algorithm of the market value of soccer players in Europe, setting \\(v = 5\\) and the same other hyperparameters as the homoscedastic case. Is there any meaningful difference for the coefficient associated with the national team compared to the application in the homoscedastic case? Example: Determinants of hospitalization continues Program a Gibbs sampling algorithm in the application of determinants of hospitalization. Choice of the fishing mode continues Run the Algorithm of the Multinomial Probit of the book to show the results of the Geweke (J. Geweke 1992), Raftery (A. E. Raftery and Lewis 1992), and Heidelberger (Heidelberger and Welch 1983) tests using our GUI. Use the command rmnpGibbs to do the example of the choice of the fishing mode. Simulation exercise of the multinomial logit model continues Perform inference in the simulation of the multinomial logit model using the command rmnlIndepMetrop from the bayesm package of R and using our GUI. Simulation of the ordered probit model Simulate an ordered probit model where the first regressor distributes \\(N(6, 5)\\) and the second distributes \\(G(1, 1)\\), the location vector is \\(\\boldsymbol{\\beta} = \\left[ 0.5, -0.25, 0.5 \\right]^{\\top}\\), and the cutoffs are in the vector \\(\\boldsymbol{\\alpha} = \\left[ 0, 1, 2.5 \\right]^{\\top}\\). Program from scratch a Metropolis-within-Gibbs sampling algorithm to perform inference in this simulation. Simulation of the negative binomial model continues Perform inference in the simulation of the negative binomial model using the bayesm package in R software. The market value of soccer players in Europe continues Perform the application of the value of soccer players with left censoring at one million Euros in our GUI using the Algorithm of the Tobit models, and the hyperparameters of the example. The market value of soccer players in Europe continues Program from scratch the Gibbs sampling algorithm in the example of the market value of soccer players at the 0.75 quantile. Use the bayesboot package to perform inference in the simulation exercise of Section 6.10, and compare the results with the ones that we get using our GUI, setting \\(S = 10000\\). References "],["Chap7.html", "Chapter 7 Multivariate regression", " Chapter 7 Multivariate regression We describe how to perform Bayesian inference in multivariate response models, including multivariate regression, seemingly unrelated regression, instrumental variables, and the multivariate probit model. In particular, we present the posterior distributions of the parameters and demonstrate several applications and simulations. Additionally, we show how to perform inference in these models using three levels of programming skills: GUI, packages, and programming the algorithms from scratch. Finally, we provide some mathematical and computational exercises. Remember that we can run our GUI typing shiny::runGitHub(\"besmarter/BSTApp\", launch.browser=T) in the R console or any R code editor and execute it. However, users should see Chapter 5 for details. "],["sec71.html", "7.1 Multivariate regression", " 7.1 Multivariate regression A complete presentation of this model is given in Section 3.4. We show here the setting, and the posterior distributions for facility in exposition. In particular, there are \\(M\\) multiply dependent variables which share the same set of regressors, and their stochastic errors are contemporaneously correlated. In particular, \\(\\boldsymbol{Y} = \\left[ \\boldsymbol{y_{1}} \\ \\boldsymbol{y_{2}} \\ \\ldots \\ \\boldsymbol{y_{M}} \\right]\\) is an \\(N \\times M\\) matrix that is generated by \\(\\boldsymbol{Y} = \\boldsymbol{X} \\boldsymbol{B} + \\boldsymbol{U}\\) where \\(\\boldsymbol{X}\\) is an \\(N \\times K\\) matrix of regressors, \\(\\boldsymbol{B} = \\left[ \\boldsymbol{\\beta}_{1} \\ \\boldsymbol{\\beta}_{2} \\ldots \\boldsymbol{\\beta}_{M} \\right]\\) is a \\(K \\times M\\) matrix of parameters, and \\(\\boldsymbol{U} = \\left[ \\boldsymbol{\\mu}_{1} \\ \\boldsymbol{\\mu}_{2} \\ldots \\boldsymbol{\\mu}_{M} \\right]\\) is a matrix of stochastic random errors such that \\(\\boldsymbol{\\mu}_i \\sim N(\\boldsymbol{0}, \\boldsymbol{\\Sigma})\\), for \\(i = 1, 2, \\dots, N\\), each row of \\(\\boldsymbol{U}\\). The prior is given by \\(\\boldsymbol{B} \\mid \\boldsymbol{\\Sigma} \\sim N(\\boldsymbol{B}_0, \\boldsymbol{V}_0, \\boldsymbol{\\Sigma})\\) and \\(\\boldsymbol{\\Sigma} \\sim IW(\\boldsymbol{\\Psi}_0, \\alpha_0)\\). Therefore, the conditional posterior distributions are: \\[ \\boldsymbol{B} \\mid \\boldsymbol{\\Sigma}, \\boldsymbol{Y}, \\boldsymbol{X} \\sim N(\\boldsymbol{B}_n, \\boldsymbol{V}_n, \\boldsymbol{\\Sigma}), \\] \\[ \\boldsymbol{\\Sigma} \\mid \\boldsymbol{Y}, \\boldsymbol{X} \\sim IW(\\boldsymbol{\\Psi}_n, \\alpha_n), \\] where \\[ \\boldsymbol{V}_n = (\\boldsymbol{X}^{\\top} \\boldsymbol{X} + \\boldsymbol{V}_0^{-1})^{-1}, \\quad \\boldsymbol{B}_n = \\boldsymbol{V}_n (\\boldsymbol{V}_0^{-1} \\boldsymbol{B}_0 + \\boldsymbol{X}^{\\top} \\boldsymbol{X} \\hat{\\boldsymbol{B}}), \\] \\[ \\hat{\\boldsymbol{B}} = (\\boldsymbol{X}^{\\top} \\boldsymbol{X})^{-1} \\boldsymbol{X}^{\\top} \\boldsymbol{Y}, \\quad \\boldsymbol{\\Psi}_n = \\boldsymbol{\\Psi}_{0} + \\boldsymbol{S} + \\boldsymbol{B}_{0}^{\\top} \\boldsymbol{V}_{0}^{-1} \\boldsymbol{B}_{0} + \\hat{\\boldsymbol{B}}^{\\top} \\boldsymbol{X}^{\\top} \\boldsymbol{X} \\hat{\\boldsymbol{B}} - \\boldsymbol{B}_n^{\\top} \\boldsymbol{V}_n^{-1} \\boldsymbol{B}_n, \\] and \\[ \\alpha_n = \\alpha_0 + N. \\] We can use a Gibbs sampling algorithm in this model since the conditional posterior distributions are standard. Example: The effect of institutions on per capita gross domestic product To illustrate multivariate regression models, we use the dataset provided by Acemoglu, Johnson, and Robinson (2001), who analyzed the effect of property rights on economic growth. We begin with the following simultaneous structural economic model:32 \\[\\begin{align} \\log(\\text{pcGDP95}_i) &amp;= \\beta_1 + \\beta_2 \\text{PAER}_i + \\beta_3 \\text{Africa} + \\beta_4 \\text{Asia} + \\beta_5 \\text{Other} + u_{1i}, \\tag{7.1} \\end{align}\\] \\[\\begin{align} \\text{PAER}_i &amp;= \\alpha_1 + \\alpha_2 \\log(\\text{pcGDP95}_i) + \\alpha_3 \\log(\\text{Mort}_i) + u_{2i}, \\tag{7.2} \\end{align}\\] where pcGDP95, PAER, and Mort represent the per capita gross domestic product (GDP) in 1995, the average index of protection against expropriation between 1985 and 1995, and the settler mortality rate during the period of colonization, respectively. Africa, Asia, and Other are indicator variables for continents, with America serving as the baseline group. In this model, there is reverse (simultaneous) causality due to the contemporaneous effect of GDP on PAER, and vice versa.33 Therefore, estimating Equations (7.1) and (7.2) without accounting for this phenomenon results in posterior mean estimates that are biased and inconsistent from a sampling (frequentist) perspective.34 A potential strategy to address this issue is to estimate the reduced-form model, i.e., a model without simultaneous causality, where all endogenous variables are functions of exogenous variables. The former are determined within the model (e.g., \\(\\log(\\text{pcGDP95}_i)\\) and PAER in this example), while the latter are determined outside the model (e.g., \\(\\log(\\text{Mort}_i)\\), Africa, Asia, and Other in this example). Replacing Equation (7.2) into Equation (7.1), and solving for \\(\\log(\\textit{pcGDP95})\\), \\[\\begin{align} \\log(\\text{pcGDP95}_i)=\\pi_1+\\pi_2\\log(\\text{Mort}_i)+\\pi_3 \\text{Africa}+\\pi_4 \\text{Asia}+\\pi_5 \\text{Other}+e_{1i}. \\tag{7.3} \\end{align}\\] Then, by substituting Equation (7.3) into Equation (7.2), and solving for PAER, we obtain \\[\\begin{align} \\text{PAER}_i = \\gamma_1 + \\gamma_2 \\log(\\text{Mort}_i) + \\gamma_3 \\text{Africa} + \\gamma_4 \\text{Asia} + \\gamma_5 \\text{Other} + e_{2i}, \\tag{7.4} \\end{align}\\] where \\(\\pi_2 = \\frac{\\beta_2\\alpha_3}{1 - \\beta_2\\alpha_2}\\) and \\(\\gamma_2 = \\frac{\\alpha_3}{1 - \\beta_2\\alpha_2}\\), given that \\(\\beta_2 \\alpha_2 \\neq 1\\), i.e., independent equations (see Exercise 2). Observe that Equations (7.3) and (7.4) have the form of a multivariate regression model, where the common set of regressors is \\[ \\boldsymbol{X} = \\left[\\log(\\text{Mort}) \\ \\text{Africa} \\ \\text{Asia} \\ \\text{Other}\\right] \\] and the common set of dependent variables is \\[ \\boldsymbol{Y} = \\left[\\log(\\text{pcGDP95}) \\ \\text{PAER}\\right]. \\] Therefore, we can estimate this model using the setup outlined in this section. In the first stage, we estimate the parameters of the reduced-form model (Equations (7.3) and (7.4)), but the main interest lies in estimating the parameters of the structural model (Equations (7.1) and (7.2)). A valid question is whether we can recover (identify) the structural parameters from the reduced-form parameters. There are two criteria to answer this question: the order condition, which is necessary, and the rank condition, which is both necessary and sufficient. The order condition Given a system of equations with \\(M\\) endogenous variables, and \\(K\\) exogenous variables (including the intercept), there are two ways to assess the order condition: The parameters of an equation in the system are identified if there are at least \\(M-1\\) variables excluded from the equation (exclusion restrictions). The equation is exactly identified if the number of excluded variables is \\(M-1\\), and is over identified if the number of excluded variables is greater than \\(M-1\\). The parameters of equation \\(m\\) in the system are identified if \\(K-K_m\\geq M_m-1\\), where \\(K_m\\) and \\(M_m\\) are the number of exogenous and endogenous variables in equation \\(m\\), respectively. The \\(m\\)-th equation is exactly identified if \\(K-K_m = M_m-1\\), and over identified if \\(K-K_m &gt; M_m-1\\). We can see from Equations (7.1) and (7.2) in this example that \\(K=5\\), \\(M=2\\), \\(K_1=4\\), \\(K_2=2\\), \\(M_1=2\\), and \\(M_2=2\\). This means that \\(K-K_1=1=M-1\\) and \\(K-K_2=3&gt;M-1=1\\), that is, the order condition says that both equations satisfy the necessary condition of identification, the first equation would be exactly identified, and the second equation would be over identified. Observe that there is one excluded variable from the first equation, and there are three excluded variables from the second equation. The rank condition The rank condition (necessary and sufficient) says that given a structural model with \\(M\\) equations (\\(M\\) endogenous variables), an equation is identified if and only if there is at least one determinant different from zero from a \\((M-1)\\times(M-1)\\) matrix built using the excluded variables in the analyzed equation, but included in any other equation of the system. It is useful to build the identification matrix to implement the rank condition. The next Table shows this matrix in this example. Table 7.1: Example: Rank condition \\(\\log(\\text{pcGDP95})\\) \\(\\text{PAER}\\) Constant \\(\\log(\\text{Mort})\\) Africa Asia Other 1 \\(-\\beta_2\\) \\(-\\beta_1\\) 0 \\(-\\beta_3\\) \\(-\\beta_4\\) \\(-\\beta_5\\) \\(-\\alpha_2\\) 1 \\(-\\alpha_1\\) \\(-\\alpha_3\\) 0 0 0 The only excluded variable in the \\(\\log(\\text{pcGDP95})\\) equation is \\(\\log(\\text{Mort})\\). Therefore, there is only one matrix that can be constructed using the excluded variables from this equation, which is \\([-\\alpha_3]\\) (see column 4 in the Table). The determinant of this matrix is \\(-\\alpha_3\\), and as long as this coefficient is nonzero (i.e., \\(\\alpha_3 \\neq 0\\)), meaning that the mortality rate is relevant in the PAER equation, the coefficients in the \\(\\log(\\text{pcGDP95})\\) equation are exactly identified. For example, \\(\\beta_2 = \\frac{\\pi_2}{\\gamma_2}\\), which represents the effect of property rights on GDP, is exactly identified. It is crucial to observe the importance of excluding \\(\\log(\\text{Mort})\\) from the \\(\\log(\\text{pcGDP95})\\) equation, while including \\(\\log(\\text{Mort})\\) in the PAER equation. This is known as the exclusion restriction, which requires the presence of an exogenous source of variability in the PAER equation to help identify the \\(\\log(\\text{pcGDP95})\\) equation. The presence of relevant exogenous sources of variability is an essential factor in the identification, estimation, and inference of structural parameters. As for the identification of the structural parameters in the PAER equation, there are three potential matrices that can be constructed: \\([-\\beta_3]\\), \\([-\\beta_4]\\), and \\([-\\beta_5]\\) (see columns 5, 6, and 7 in the Table). As long as any of these parameters are relevant in the \\(\\log(\\text{pcGDP95})\\) equation, the PAER equation is identified. In this case, the PAER equation is over-identified, meaning there are multiple ways to estimate the parameters in this equation. For example, \\(\\alpha_2 = \\gamma_3/\\pi_3 = \\gamma_4/\\pi_4 = \\gamma_5/\\pi_5\\) (see Exercise 2). In general, recovering the structural parameters from the reduced-form parameters can be challenging due to the need for relevant identification restrictions, which can be difficult to find in some applications.35 For this example, we set non-informative priors: \\(\\boldsymbol{B}_0 = \\left[\\boldsymbol{0}_5 \\ \\boldsymbol{0}_5\\right]\\), \\(\\boldsymbol{V}_0 = 100 \\boldsymbol{I}_K\\), \\(\\boldsymbol{\\Psi}_0 = 5 \\boldsymbol{I}_2\\), and \\(\\alpha_0 = 5\\).36 Once our GUI is displayed (see the beginning of this chapter), we should follow the next Algorithm to run multivariate linear models in the GUI (see Chapter 5 for details, particularly on how to set the data set). Algorithm: Multivariate Linear Model Select Multivariate Models on the top panel Select Simple Multivariate model using the left radio button Upload the dataset selecting first if there is header in the file, and the kind of separator in the csv file of the dataset (comma, semicolon, or tab). Then, use the Browse button under the Choose File legend Select MCMC iterations, burn-in, and thinning parameters using the Range sliders Select the number of dependent variables in the box Number of endogenous variables: m Select the number of independent variables (including the intercept) in the box Number of exogenous variables: k Set the hyperparameters: mean vectors, covariance matrix, degrees of freedom, and the scale matrix. This step is not necessary as by default our GUI uses non-informative priors Click the Go! button Analyze results Download posterior chains and diagnostic plots using the Download Posterior Chains and Download Posterior Graphs buttons The following R code shows how to perform the Gibss sampling algorithm in this example using the dataset 4Institutions.csv. We ask to run this example using the rmultireg command from the bayesm package as an exercise. We find that the posterior mean structural effect of property rights on GDP is 0.98, and the 95% credible interval is (0.56, 2.87). This means that there is evidence supporting a positive effect of property rights on gross domestic product. rm(list = ls()) set.seed(12345) DataInst &lt;- read.csv(&quot;https://raw.githubusercontent.com/besmarter/BSTApp/refs/heads/master/DataApp/4Institutions.csv&quot;, sep = &quot;,&quot;, header = TRUE, quote = &quot;&quot;) attach(DataInst) Y &lt;- cbind(logpcGDP95, PAER) X &lt;- cbind(1, logMort, Africa, Asia, Other) M &lt;- dim(Y)[2] K &lt;- dim(X)[2] N &lt;- dim(Y)[1] # Hyperparameters B0 &lt;- matrix(0, K, M) c0 &lt;- 100 V0 &lt;- c0*diag(K) Psi0 &lt;- 5*diag(M) a0 &lt;- 5 # Posterior parameters Bhat &lt;- solve(t(X)%*%X)%*%t(X)%*%Y S &lt;- t(Y - X%*%Bhat)%*%(Y - X%*%Bhat) Vn &lt;- solve(solve(V0) + t(X)%*%X) Bn &lt;- Vn%*%(solve(V0)%*%B0 + t(X)%*%X%*%Bhat) Psin &lt;- Psi0 + S + t(B0)%*%solve(V0)%*%B0 + t(Bhat)%*%t(X)%*%X%*%Bhat - t(Bn)%*%solve(Vn)%*%Bn an &lt;- a0 + N #Posterior draws s &lt;- 10000 #Number of posterior draws SIGs &lt;- replicate(s, LaplacesDemon::rinvwishart(an, Psin)) BsCond &lt;- sapply(1:s, function(s) {MixMatrix::rmatrixnorm(n = 1, mean=Bn, U = Vn,V = SIGs[,,s])}) summary(coda::mcmc(t(BsCond))) ## ## Iterations = 1:10000 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 10000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## [1,] 10.3789 0.44935 0.0044935 0.0044935 ## [2,] -0.4170 0.09972 0.0009972 0.0009972 ## [3,] -0.7318 0.24032 0.0024032 0.0024032 ## [4,] -0.5840 0.28959 0.0028959 0.0028959 ## [5,] 0.2972 0.48248 0.0048248 0.0048248 ## [6,] 8.5156 0.75222 0.0075222 0.0075222 ## [7,] -0.4283 0.16725 0.0016725 0.0016725 ## [8,] -0.2677 0.40099 0.0040099 0.0040361 ## [9,] 0.3475 0.48749 0.0048749 0.0048749 ## [10,] 1.2454 0.81787 0.0081787 0.0081787 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## var1 9.4953 10.07783 10.3766 10.6768666 11.27717 ## var2 -0.6136 -0.48366 -0.4158 -0.3496649 -0.22143 ## var3 -1.1985 -0.89381 -0.7327 -0.5695042 -0.25578 ## var4 -1.1527 -0.77805 -0.5827 -0.3900056 -0.01057 ## var5 -0.6587 -0.02514 0.2945 0.6224207 1.24241 ## var6 7.0210 8.01999 8.5116 9.0111246 10.00396 ## var7 -0.7558 -0.53971 -0.4285 -0.3165409 -0.10184 ## var8 -1.0600 -0.53703 -0.2676 0.0002646 0.52081 ## var9 -0.6090 0.02377 0.3500 0.6740956 1.30291 ## var10 -0.3446 0.69699 1.2418 1.7939884 2.86752 SIGMs &lt;- t(sapply(1:s, function(l) {gdata::lowerTriangle(SIGs[,,l], diag=TRUE, byrow=FALSE)})) summary(coda::mcmc(SIGMs)) ## ## Iterations = 1:10000 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 10000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## [1,] 0.5381 0.09524 0.0009524 0.0009813 ## [2,] 0.5372 0.13144 0.0013144 0.0013144 ## [3,] 1.5225 0.26763 0.0026763 0.0026763 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## var1 0.3853 0.4695 0.5267 0.5942 0.7545 ## var2 0.3181 0.4449 0.5234 0.6137 0.8359 ## var3 1.0863 1.3324 1.4924 1.6799 2.1354 hdiBs &lt;- HDInterval::hdi(t(BsCond), credMass = 0.95) # Highest posterior density credible interval hdiBs ## [,1] [,2] [,3] [,4] [,5] [,6] ## lower 9.44900 -0.6131229 -1.1769984 -1.16535714 -0.670223 7.041383 ## upper 11.22169 -0.2212954 -0.2393919 -0.02786525 1.227650 10.017329 ## [,7] [,8] [,9] [,10] ## lower -0.74678771 -1.0419989 -0.6358514 -0.3253181 ## upper -0.09525447 0.5322414 1.2748474 2.8767518 ## attr(,&quot;credMass&quot;) ## [1] 0.95 hdiSIG &lt;- HDInterval::hdi(SIGMs, credMass = 0.95) # Highest posterior density credible interval hdiSIG ## [,1] [,2] [,3] ## lower 0.3735344 0.2960049 1.023421 ## upper 0.7318534 0.8022998 2.034439 ## attr(,&quot;credMass&quot;) ## [1] 0.95 beta2 &lt;- BsCond[2,]/BsCond[7,] summary(coda::mcmc(beta2)) # Effect of property rights on GDP ## ## Iterations = 1:10000 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 10000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## 0.9796 16.8430 0.1684 0.1684 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## 0.5604 0.7984 0.9677 1.2329 2.8709 References "],["sec72.html", "7.2 Seemingly Unrelated Regression", " 7.2 Seemingly Unrelated Regression In seemingly unrelated regression (SUR) models, there are \\(M\\) dependent variables, each with potentially different regressors, such that the stochastic errors are contemporaneously correlated. The model is given by: \\[ \\boldsymbol{y}_m = \\boldsymbol{X}_m \\boldsymbol{\\beta}_m + \\boldsymbol{\\mu}_m, \\] where \\(\\boldsymbol{y}_m\\) is an \\(N\\)-dimensional vector of observations, \\(\\boldsymbol{X}_m\\) is an \\(N \\times K_m\\) matrix of regressors, \\(\\boldsymbol{\\beta}_m\\) is a \\(K_m\\)-dimensional vector of location parameters, and \\(\\boldsymbol{\\mu}_m\\) is an \\(N\\)-dimensional vector of stochastic errors, for \\(m = 1, 2, \\dots, M\\). Let \\(\\boldsymbol{\\mu}_i = \\left[\\mu_{i1} \\ \\mu_{i2} \\ \\dots \\ \\mu_{iM}\\right]^{\\top}\\), where \\(\\boldsymbol{\\mu}_i \\sim \\mathcal{N}(\\boldsymbol{0}, \\boldsymbol{\\Sigma})\\). Stacking the \\(M\\) equations, we can write the model as: \\[ \\boldsymbol{y} = \\boldsymbol{X} \\boldsymbol{\\beta} + \\boldsymbol{\\mu}, \\] where \\(\\boldsymbol{y} = \\left[\\boldsymbol{y}_1^{\\top} \\ \\boldsymbol{y}_2^{\\top} \\ \\dots \\ \\boldsymbol{y}_M^{\\top}\\right]^{\\top}\\) is an \\(MN\\)-dimensional vector, \\(\\boldsymbol{\\beta} = \\left[\\boldsymbol{\\beta}_1^{\\top} \\ \\boldsymbol{\\beta}_2^{\\top} \\ \\dots \\ \\boldsymbol{\\beta}_M^{\\top}\\right]^{\\top}\\) is a \\(K\\)-dimensional vector with \\(K = \\sum_{m=1}^M K_m\\), and \\(\\boldsymbol{X}\\) is an \\(MN \\times K\\) block-diagonal matrix composed of the individual \\(\\boldsymbol{X}_m\\), i.e., \\[ \\boldsymbol{X} = \\begin{bmatrix} \\boldsymbol{X}_1 &amp; \\boldsymbol{0} &amp; \\dots &amp; \\boldsymbol{0} \\\\ \\boldsymbol{0} &amp; \\boldsymbol{X}_2 &amp; \\dots &amp; \\boldsymbol{0} \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ \\boldsymbol{0} &amp; \\boldsymbol{0} &amp; \\dots &amp; \\boldsymbol{X}_M \\end{bmatrix}. \\] Similarly, the vector of errors is given by \\(\\boldsymbol{\\mu} = \\left[\\boldsymbol{\\mu}_1^{\\top} \\ \\boldsymbol{\\mu}_2^{\\top} \\ \\dots \\ \\boldsymbol{\\mu}_M^{\\top}\\right]^{\\top}\\), which is an \\(MN\\)-dimensional vector of stochastic errors, with \\(\\boldsymbol{\\mu} \\sim \\mathcal{N}(\\boldsymbol{0}, \\boldsymbol{\\Sigma} \\otimes \\boldsymbol{I}_N)\\). The likelihood function for the parameters is then: \\[ p(\\boldsymbol{\\beta}, \\boldsymbol{\\Sigma} \\mid \\boldsymbol{y}, \\boldsymbol{X}) \\propto |\\boldsymbol{\\Sigma}|^{-N/2} \\exp\\left\\{ -\\frac{1}{2} (\\boldsymbol{y} - \\boldsymbol{X} \\boldsymbol{\\beta})^{\\top} (\\boldsymbol{\\Sigma}^{-1} \\otimes \\boldsymbol{I}_N) (\\boldsymbol{y} - \\boldsymbol{X} \\boldsymbol{\\beta}) \\right\\}. \\] Using independent priors \\(\\pi(\\boldsymbol{\\beta}) \\sim \\mathcal{N}(\\boldsymbol{\\beta}_0, \\boldsymbol{B}_0)\\) and \\(\\pi(\\boldsymbol{\\Sigma}^{-1}) \\sim W(\\alpha_0, \\boldsymbol{\\Psi}_0)\\), the posterior distributions are \\[ \\boldsymbol{\\beta} \\mid \\boldsymbol{\\Sigma}, \\boldsymbol{y}, \\boldsymbol{X} \\sim \\mathcal{N}(\\boldsymbol{\\beta}_n, \\boldsymbol{B}_n), \\] \\[ \\boldsymbol{\\Sigma}^{-1} \\mid \\boldsymbol{\\beta}, \\boldsymbol{y}, \\boldsymbol{X} \\sim W(\\alpha_n, \\boldsymbol{\\Psi}_n), \\] where \\(\\boldsymbol{B}_n = (\\boldsymbol{X}^{\\top} (\\boldsymbol{\\Sigma}^{-1} \\otimes \\boldsymbol{I}_N) \\boldsymbol{X} + \\boldsymbol{B}_0^{-1})^{-1}\\), \\(\\boldsymbol{\\beta}_n = \\boldsymbol{B}_n (\\boldsymbol{B}_0^{-1} \\boldsymbol{\\beta}_0 + \\boldsymbol{X}^{\\top} (\\boldsymbol{\\Sigma}^{-1} \\otimes \\boldsymbol{I}_N) \\boldsymbol{y})\\), \\(\\alpha_n = \\alpha_0 + N\\) and \\(\\boldsymbol{\\Psi}_n = (\\boldsymbol{\\Psi}_0^{-1} + \\boldsymbol{U}^{\\top} \\boldsymbol{U})^{-1}\\), where \\(\\boldsymbol{U}\\) is an \\(N \\times M\\) matrix whose columns are \\(\\boldsymbol{y}_m - \\boldsymbol{X}_m \\boldsymbol{\\beta}_m\\). We can demonstrate, through straightforward yet tedious algebra, that by defining \\(\\boldsymbol{y}_i = [y_{i1} \\ y_{i2} \\ \\dots \\ y_{iM}]\\) and \\[ \\boldsymbol{X}_i = \\begin{bmatrix} x_{1i}^{\\top} &amp; \\boldsymbol{0} &amp; \\dots &amp; \\boldsymbol{0} \\\\ \\boldsymbol{0} &amp; x_{2i}^{\\top} &amp; \\dots &amp; \\boldsymbol{0} \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ \\boldsymbol{0} &amp; \\boldsymbol{0} &amp; \\dots &amp; x_{Mi}^{\\top} \\end{bmatrix}, \\] we alternatively have \\(\\boldsymbol{B}_n = (\\boldsymbol{B}_0^{-1} + \\sum_{i=1}^N \\boldsymbol{X}_i^{\\top} \\boldsymbol{\\Sigma}^{-1} \\boldsymbol{X}_i)^{-1}\\), \\(\\boldsymbol{\\beta}_n = \\boldsymbol{B}_n (\\boldsymbol{B}_0^{-1} \\boldsymbol{\\beta}_0 + \\sum_{i=1}^N \\boldsymbol{X}_i^{\\top} \\boldsymbol{\\Sigma}^{-1} \\boldsymbol{y}_i)\\) and \\(\\boldsymbol{\\Psi}_n = (\\boldsymbol{\\Psi}_0^{-1} + \\sum_{i=1}^N (\\boldsymbol{y}_i - \\boldsymbol{X}_i^{\\top} \\boldsymbol{\\beta}) (\\boldsymbol{y}_i - \\boldsymbol{X}_i^{\\top} \\boldsymbol{\\beta})^{\\top})^{-1}\\). Observe that we have standard conditional posteriors, thus, we can employ a Gibbs sampling algorithm to get the posterior draws. Example: Utility demand Let’s use the dataset Utilities.csv to estimate a seemingly unrelated regression (SUR) model for utilities. We adopt the same setting as in Exercise 14 of Chapter 3, where we estimate a multivariate regression model while omitting households with no consumption in any utility. In this exercise, we observe that not all regressors are relevant for the demand of electricity, water, and gas. Thus, we estimate the following model: \\[\\begin{align*} \\log(\\text{electricity}_i) &amp; = \\beta_1 + \\beta_2\\log(\\text{electricity price}_i) + \\beta_3\\log(\\text{water price}_i) \\\\ &amp; + \\beta_4\\log(\\text{gas price}_i) + \\beta_5\\text{IndSocio1}_i + \\beta_6\\text{IndSocio2}_i + \\beta_7\\text{Altitude}_i \\\\ &amp; + \\beta_8\\text{Nrooms}_i + \\beta_9\\text{HouseholdMem}_i + \\beta_{10}\\log(\\text{Income}_i) + \\mu_{i1} \\\\ \\log(\\text{water}_i) &amp; = \\alpha_1 + \\alpha_2\\log(\\text{electricity price}_i) + \\alpha_3\\log(\\text{water price}_i) \\\\ &amp; + \\alpha_4\\log(\\text{gas price}_i) + \\alpha_5\\text{IndSocio1}_i + \\alpha_6\\text{IndSocio2}_i \\\\ &amp; + \\alpha_7\\text{Nrooms}_i + \\alpha_8\\text{HouseholdMem}_i + \\mu_{i2} \\\\ \\log(\\text{gas}_i) &amp; = \\gamma_1 + \\gamma_2\\log(\\text{electricity price}_i) + \\gamma_3\\log(\\text{water price}_i) \\\\ &amp; + \\gamma_4\\log(\\text{gas price}_i) + \\gamma_5\\text{IndSocio1}_i + \\gamma_6\\text{IndSocio2}_i + \\gamma_7\\text{Altitude}_i \\\\ &amp; + \\gamma_8\\text{Nrooms}_i + \\gamma_9\\text{HouseholdMem}_i + \\mu_{i3}, \\end{align*}\\] where electricity, water, and gas represent the monthly consumption of electricity (kWh), water (m\\(^3\\)), and gas (m\\(^3\\)) of Colombian households. The dataset includes information on 2,103 households, with details on the average prices of electricity (USD/kWh), water (USD/m\\(^3\\)), and gas (USD/m\\(^3\\)), as well as indicators of the socioeconomic conditions of the neighborhood where the household is located (IndSocio1 being the lowest and IndSocio3 the highest). Additionally, there is information on whether the household is located in a municipality situated at over 1,000 meters above sea level, the number of rooms in the house, the number of household members, and monthly income (USD). Since each equation has a different set of regressors, and we suspect correlation between the stochastic errors of the three equations, we should estimate a seemingly unrelated regression (SUR) model. We expect unobserved correlation across these equations because we are modeling utilities, and in some cases, a single provider handles all three services and issues one bill. The following Algorithm demonstrates how to estimate SUR models using our GUI. Our GUI utilizes the command rsurGibbs from the bayesm package in R software. See Chapter 5 for further details, including instructions on how to set up the dataset, and check the templates available in our GitHub repository (https://github.com/besmarter/BSTApp) in the DataApp and DataSim folders. Algorithm: Seemingly Unrelated Regression (SUR) Select Multivariate Models on the top panel Select Seemingly Unrelated Regression model using the left radio button Upload the dataset, selecting first if there is a header in the file, and the kind of separator in the csv file of the dataset (comma, semicolon, or tab). Then, use the Browse button under the Choose File legend Select MCMC iterations, burn-in, and thinning parameters using the Range sliders Select the number of dependent variables in the box Number of endogenous variables: m Select the number of independent variables in the box TOTAL number of Exogenous Variables: k. This is the sum of all exogenous variables over all equations, including intercepts. In the example of Utility demand, it is equal to 27 Set the hyperparameters: mean vectors, covariance matrix, degrees of freedom, and the scale matrix. This step is not necessary as by default our GUI uses non-informative priors Click the Go! button Analyze results Download posterior chains and diagnostic plots using the Download Posterior Chains and Download Posterior Graphs buttons The following code shows how to program this application using this package. We use 10,000 MCMC iterations, \\(\\boldsymbol{\\beta}_0 = \\boldsymbol{0}_{27}\\), \\(\\boldsymbol{B}_0 = 100\\boldsymbol{I}_{27}\\), \\(\\alpha_0 = 5\\) and \\(\\boldsymbol{\\Psi} = 5\\boldsymbol{I}_3\\). We find that the posterior median estimates of the own-price elasticities of demand for electricity, water, and gas are -1.88, -0.36, and -0.62, respectively, and none of the 95% credible intervals encompass 0. This means that a 1% increase in the prices of electricity, water, and gas results in a 1.88%, 0.36%, and 0.62% decrease in the monthly consumption of these utilities, respectively.37 In general, there is evidence supporting the relevance of all regressors in these equations, with a few exceptions, and unobserved correlation in the demand for these services, which further supports the use of a SUR model in this application. rm(list = ls()) set.seed(010101) library(dplyr) DataUt &lt;- read.csv(&quot;https://raw.githubusercontent.com/besmarter/BSTApp/refs/heads/master/DataApp/Utilities.csv&quot;, sep = &quot;,&quot;, header = TRUE, quote = &quot;&quot;) DataUtEst &lt;- DataUt %&gt;% filter(Electricity != 0 &amp; Water !=0 &amp; Gas != 0) attach(DataUtEst) ## The following object is masked from Data (pos = 7): ## ## id ## The following object is masked from mydata: ## ## id y1 &lt;- log(Electricity); y2 &lt;- log(Water); y3 &lt;- log(Gas) X1 &lt;- cbind(1, LnPriceElect, LnPriceWater, LnPriceGas, IndSocio1, IndSocio2, Altitude, Nrooms, HouseholdMem, Lnincome) X2 &lt;- cbind(1, LnPriceElect, LnPriceWater, LnPriceGas, IndSocio1, IndSocio2, Nrooms, HouseholdMem) X3 &lt;- cbind(1, LnPriceElect, LnPriceWater, LnPriceGas, IndSocio1, IndSocio2, Altitude, Nrooms, HouseholdMem) regdata &lt;- NULL regdata[[1]] &lt;- list(y = y1, X = X1); regdata[[2]] &lt;- list(y = y2, X = X2); regdata[[3]] &lt;- list(y = y3, X = X3) M &lt;- length(regdata); K1 &lt;- dim(X1)[2]; K2 &lt;- dim(X2)[2]; K3 &lt;- dim(X3)[2] K &lt;- K1 + K2 + K3 # Hyperparameters b0 &lt;- rep(0, K); c0 &lt;- 100; B0 &lt;- c0*diag(K); V &lt;- 5*diag(M); a0 &lt;- M Prior &lt;- list(betabar = b0, A = solve(B0), nu = a0, V = V) #Posterior draws S &lt;- 10000; keep &lt;- 1; Mcmc &lt;- list(R = S, keep = keep, nprint = 0) PosteriorDraws &lt;- bayesm::rsurGibbs(Data = list(regdata = regdata), Mcmc = Mcmc, Prior = Prior) ## ## Starting Gibbs Sampler for SUR Regression Model ## with 3 regressions ## and 1574 observations for each regression ## ## Prior Parms: ## betabar ## [1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## A ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] ## [1,] 0.01 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [2,] 0.00 0.01 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [3,] 0.00 0.00 0.01 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [4,] 0.00 0.00 0.00 0.01 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [5,] 0.00 0.00 0.00 0.00 0.01 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [6,] 0.00 0.00 0.00 0.00 0.00 0.01 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [7,] 0.00 0.00 0.00 0.00 0.00 0.00 0.01 0.00 0.00 0.00 0.00 0.00 0.00 ## [8,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.01 0.00 0.00 0.00 0.00 0.00 ## [9,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.01 0.00 0.00 0.00 0.00 ## [10,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.01 0.00 0.00 0.00 ## [11,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.01 0.00 0.00 ## [12,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.01 0.00 ## [13,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.01 ## [14,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [15,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [16,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [17,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [18,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [19,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [20,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [21,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [22,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [23,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [24,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [25,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [26,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [27,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [,14] [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] [,25] ## [1,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [2,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [3,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [4,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [5,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [6,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [7,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [8,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [9,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [10,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [11,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [12,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [13,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [14,] 0.01 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [15,] 0.00 0.01 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [16,] 0.00 0.00 0.01 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [17,] 0.00 0.00 0.00 0.01 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [18,] 0.00 0.00 0.00 0.00 0.01 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [19,] 0.00 0.00 0.00 0.00 0.00 0.01 0.00 0.00 0.00 0.00 0.00 0.00 ## [20,] 0.00 0.00 0.00 0.00 0.00 0.00 0.01 0.00 0.00 0.00 0.00 0.00 ## [21,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.01 0.00 0.00 0.00 0.00 ## [22,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.01 0.00 0.00 0.00 ## [23,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.01 0.00 0.00 ## [24,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.01 0.00 ## [25,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.01 ## [26,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [27,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [,26] [,27] ## [1,] 0.00 0.00 ## [2,] 0.00 0.00 ## [3,] 0.00 0.00 ## [4,] 0.00 0.00 ## [5,] 0.00 0.00 ## [6,] 0.00 0.00 ## [7,] 0.00 0.00 ## [8,] 0.00 0.00 ## [9,] 0.00 0.00 ## [10,] 0.00 0.00 ## [11,] 0.00 0.00 ## [12,] 0.00 0.00 ## [13,] 0.00 0.00 ## [14,] 0.00 0.00 ## [15,] 0.00 0.00 ## [16,] 0.00 0.00 ## [17,] 0.00 0.00 ## [18,] 0.00 0.00 ## [19,] 0.00 0.00 ## [20,] 0.00 0.00 ## [21,] 0.00 0.00 ## [22,] 0.00 0.00 ## [23,] 0.00 0.00 ## [24,] 0.00 0.00 ## [25,] 0.00 0.00 ## [26,] 0.01 0.00 ## [27,] 0.00 0.01 ## nu = 3 ## V = ## [,1] [,2] [,3] ## [1,] 5 0 0 ## [2,] 0 5 0 ## [3,] 0 0 5 ## ## MCMC parms: ## R= 10000 keep= 1 nprint= 0 ## Bs &lt;- PosteriorDraws[[&quot;betadraw&quot;]] Names &lt;- c(&quot;Const&quot;, &quot;LnPriceElect&quot;, &quot;LnPriceWater&quot;, &quot;LnPriceGas&quot;, &quot;IndSocio1&quot;, &quot;IndSocio2&quot;, &quot;Altitude&quot;, &quot;Nrooms&quot;, &quot;HouseholdMem&quot;, &quot;Lnincome&quot;, &quot;Const&quot;, &quot;LnPriceElect&quot;, &quot;LnPriceWater&quot;, &quot;LnPriceGas&quot;, &quot;IndSocio1&quot;, &quot;IndSocio2&quot;, &quot;Nrooms&quot;, &quot;HouseholdMem&quot;,&quot;Const&quot;, &quot;LnPriceElect&quot;, &quot;LnPriceWater&quot;, &quot;LnPriceGas&quot;, &quot;IndSocio1&quot;, &quot;IndSocio2&quot;, &quot;Altitude&quot;, &quot;Nrooms&quot;, &quot;HouseholdMem&quot;) colnames(Bs) &lt;- Names summary(coda::mcmc(Bs)) ## ## Iterations = 1:10000 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 10000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## Const 1.343420 0.45854 0.0045854 0.0045854 ## LnPriceElect -1.883221 0.26486 0.0026486 0.0026100 ## LnPriceWater -0.356765 0.04423 0.0004423 0.0004423 ## LnPriceGas -0.098387 0.05960 0.0005960 0.0006046 ## IndSocio1 -0.737529 0.07192 0.0007192 0.0006969 ## IndSocio2 -0.151118 0.04787 0.0004787 0.0004859 ## Altitude -0.220988 0.02531 0.0002531 0.0002531 ## Nrooms 0.070102 0.01236 0.0001236 0.0001236 ## HouseholdMem 0.086989 0.01057 0.0001057 0.0001057 ## Lnincome 0.062892 0.01244 0.0001244 0.0001223 ## Const 2.177612 0.65917 0.0065917 0.0065917 ## LnPriceElect -0.050723 0.39241 0.0039241 0.0039241 ## LnPriceWater -0.364801 0.06656 0.0006656 0.0006656 ## LnPriceGas 0.226759 0.08681 0.0008681 0.0008681 ## IndSocio1 -0.427636 0.11136 0.0011136 0.0011334 ## IndSocio2 -0.359542 0.07427 0.0007427 0.0007427 ## Nrooms 0.093014 0.01868 0.0001868 0.0001868 ## HouseholdMem 0.131650 0.01612 0.0001612 0.0001612 ## Const -1.215735 0.54177 0.0054177 0.0054177 ## LnPriceElect -1.794509 0.31960 0.0031960 0.0031960 ## LnPriceWater -0.003921 0.05257 0.0005257 0.0005257 ## LnPriceGas -0.625445 0.07270 0.0007270 0.0007270 ## IndSocio1 -0.744103 0.08706 0.0008706 0.0008706 ## IndSocio2 -0.203635 0.05893 0.0005893 0.0005893 ## Altitude 0.311631 0.03136 0.0003136 0.0003136 ## Nrooms 0.089361 0.01481 0.0001481 0.0001488 ## HouseholdMem 0.169882 0.01264 0.0001264 0.0001264 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## Const 0.44452 1.03120 1.342407 1.65192 2.25376 ## LnPriceElect -2.39679 -2.06328 -1.882706 -1.70369 -1.36996 ## LnPriceWater -0.44221 -0.38678 -0.356850 -0.32669 -0.26969 ## LnPriceGas -0.21655 -0.13777 -0.098191 -0.05902 0.01872 ## IndSocio1 -0.87630 -0.78653 -0.737701 -0.68840 -0.59675 ## IndSocio2 -0.24601 -0.18286 -0.151440 -0.11896 -0.05681 ## Altitude -0.27080 -0.23838 -0.220742 -0.20385 -0.17259 ## Nrooms 0.04596 0.06178 0.070023 0.07835 0.09422 ## HouseholdMem 0.06600 0.07994 0.086857 0.09411 0.10785 ## Lnincome 0.03836 0.05421 0.062957 0.07165 0.08717 ## Const 0.88957 1.73496 2.169638 2.62170 3.47216 ## LnPriceElect -0.81956 -0.31624 -0.054075 0.21132 0.71842 ## LnPriceWater -0.49559 -0.40995 -0.364248 -0.32026 -0.23639 ## LnPriceGas 0.06075 0.16754 0.226690 0.28570 0.39476 ## IndSocio1 -0.64203 -0.50302 -0.427819 -0.35226 -0.21315 ## IndSocio2 -0.50401 -0.40949 -0.359821 -0.31063 -0.21199 ## Nrooms 0.05688 0.08023 0.093139 0.10555 0.12968 ## HouseholdMem 0.10041 0.12065 0.131506 0.14260 0.16314 ## Const -2.28569 -1.58566 -1.220078 -0.84612 -0.14787 ## LnPriceElect -2.42484 -2.01228 -1.797269 -1.57889 -1.16396 ## LnPriceWater -0.10684 -0.03923 -0.004088 0.03153 0.09905 ## LnPriceGas -0.76526 -0.67445 -0.625899 -0.57734 -0.48125 ## IndSocio1 -0.91381 -0.80243 -0.744909 -0.68577 -0.57341 ## IndSocio2 -0.31791 -0.24388 -0.203300 -0.16415 -0.09012 ## Altitude 0.24896 0.29099 0.311668 0.33256 0.37278 ## Nrooms 0.06050 0.07921 0.089386 0.09943 0.11793 ## HouseholdMem 0.14467 0.16144 0.170024 0.17843 0.19431 summary(PosteriorDraws[[&quot;Sigmadraw&quot;]]) ## Posterior Means of Std Deviations and Correlation Matrix ## Std Dev 1 2 3 ## 1 0.46 1.00 0.30 0.25 ## 2 0.72 0.30 1.00 0.23 ## 3 0.56 0.25 0.23 1.00 ## ## Upper Triangle of Var-Cov Matrix ## Summary of Posterior Marginal Distributions ## Moments ## mean std dev num se rel eff sam size ## 1,1 0.214 0.0077 7.1e-05 0.78 9000 ## 1,2 0.099 0.0087 9.2e-05 1.01 4500 ## 2,2 0.512 0.0182 1.9e-04 0.95 9000 ## 1,3 0.064 0.0068 6.6e-05 0.84 9000 ## 2,3 0.094 0.0105 1.1e-04 1.02 4500 ## 3,3 0.317 0.0114 1.2e-04 0.94 9000 ## based on 9000 valid draws (burn-in=1000) We ask in the Exercise 5 to run this application using our GUI and the information in the dataset Utilities.csv. Observe that this file should be modified to agree the structure that requires our GUI (see the dataset 5Institutions.csv in the folder DataApp of our GitHub repository -https://github.com/besmarter/BSTApp- for a template). In addition, we ask to program from scratch the Gibbs sampler algorithm in this application. References "],["sec73.html", "7.3 Instrumental variable", " 7.3 Instrumental variable This inferential approach is used when there are endogeneity issues, that is, when the stochastic error is not independent of the regressors. This, in turn, generates bias in posterior mean estimates when we use an inferential approach that does not account for this issue. Endogeneity can be caused by reverse causality, omitting relevant correlated variables, or measurement error in the regressors.38 Let’s specify the dependent variable as a linear function of one endogenous regressor and some exogenous regressors. That is, \\[ y_{i} = \\boldsymbol{x}_{ei}^{\\top} \\boldsymbol{\\beta}_1 + \\beta_s x_{si} + \\mu_{i} \\] where \\[ x_{si} = \\boldsymbol{x}_{ei}^{\\top} \\boldsymbol{\\gamma}_1 + \\boldsymbol{z}_i^{\\top} \\boldsymbol{\\gamma}_2 + v_{i}, \\] \\(x_s\\) is the variable that generates the endogeneity issues (\\(\\mathbb{E}[\\mu \\mid x_{s}] \\neq 0\\)), \\(\\boldsymbol{x}_e\\) are \\(K_1\\) exogenous regressors (\\(\\mathbb{E}[\\mu \\mid \\boldsymbol{x}_{e}] = \\boldsymbol{0}\\)), and \\(\\boldsymbol{z}\\) are \\(K_2\\) instruments. The instruments are regressors that drive \\(x_s\\) (\\(\\mathbb{E}[x_{s} \\boldsymbol{z}] \\neq \\boldsymbol{0}\\)), but do not have a direct effect on \\(y\\) (\\(\\mathbb{E}[y \\boldsymbol{z} \\mid x_s] = \\boldsymbol{0}\\)). The equation for \\(y\\) is called the structural equation, and it is the equation that the researcher is ultimately interested in. Assuming \\[ (u_{i},v_i)^{\\top} \\stackrel{i.i.d.}{\\thicksim} N(0,\\boldsymbol{\\Sigma}), \\] where \\(\\boldsymbol{\\Sigma}=[\\sigma_{lm}]\\), \\(l,m=1,2\\), the likelihood function is \\[ p(\\boldsymbol{\\beta},\\boldsymbol{\\gamma},\\boldsymbol{\\Sigma} \\mid \\boldsymbol{y},\\boldsymbol{X},\\boldsymbol{Z}) = \\frac{1}{(2\\pi)^\\frac{N}{2}|\\boldsymbol{\\Sigma}|^\\frac{N}{2}} \\exp\\left\\{-\\frac{1}{2} \\sum_{i=1}^N (y_i-\\boldsymbol{x}_i^{\\top} \\boldsymbol{\\beta}, x_{si} -\\boldsymbol{w}_i^{\\top} \\boldsymbol{\\gamma}) \\boldsymbol{\\Sigma}^{-1} \\begin{pmatrix} y_i - \\boldsymbol{x}_i^{\\top} \\boldsymbol{\\beta} \\\\ x_{si} - \\boldsymbol{w}_i^{\\top} \\boldsymbol{\\gamma} \\end{pmatrix} \\right\\}, \\] where \\[ \\boldsymbol{\\beta}=\\begin{bmatrix} \\boldsymbol{\\beta}_1^{\\top} &amp; \\beta_s \\end{bmatrix}^{\\top}, \\quad \\boldsymbol{\\gamma}=\\begin{bmatrix} \\boldsymbol{\\gamma}_1^{\\top} &amp; \\boldsymbol{\\gamma}_2^{\\top} \\end{bmatrix}^{\\top}, \\quad \\boldsymbol{x}_i=\\begin{bmatrix} \\boldsymbol{x}_{ei}^{\\top} &amp; x_{si} \\end{bmatrix}^{\\top}, \\quad \\boldsymbol{w}_i=\\begin{bmatrix} \\boldsymbol{x}_{ei}^{\\top} &amp; \\boldsymbol{z}_{i}^{\\top} \\end{bmatrix}^{\\top}. \\] We obtain the standard conditional posterior densities by specifying the following independent priors: \\[ \\boldsymbol{\\gamma} \\sim N(\\boldsymbol{\\gamma}_0, \\boldsymbol{G}_0), \\quad \\boldsymbol{\\beta} \\sim N(\\boldsymbol{\\beta}_0, \\boldsymbol{B}_0), \\quad \\boldsymbol{\\Sigma}^{-1} \\sim W(\\alpha_0, \\boldsymbol{\\Psi}_0). \\] In particular, the conditional distributions are: \\[ \\boldsymbol{\\beta} \\mid \\boldsymbol{\\gamma}, \\boldsymbol{\\Sigma}, \\boldsymbol{y}, \\boldsymbol{X}, \\boldsymbol{Z} \\sim N(\\boldsymbol{\\beta}_n, \\boldsymbol{B}_n), \\] \\[ \\boldsymbol{\\gamma} \\mid \\boldsymbol{\\beta}, \\boldsymbol{\\Sigma}, \\boldsymbol{y}, \\boldsymbol{X}, \\boldsymbol{Z} \\sim N(\\boldsymbol{\\gamma}_n, \\boldsymbol{G}_n), \\] \\[ \\boldsymbol{\\Sigma}^{-1} \\mid \\boldsymbol{\\beta}, \\boldsymbol{\\gamma}, \\boldsymbol{y}, \\boldsymbol{X}, \\boldsymbol{Z} \\sim W(\\alpha_n, \\boldsymbol{\\Psi}_n), \\] where \\[ \\boldsymbol{\\beta}_n = \\boldsymbol{B}_n \\left( \\boldsymbol{B}_0^{-1} \\boldsymbol{\\beta}_0 + \\omega_1^{-1} \\sum_{i=1}^{N} \\left[ \\boldsymbol{x}_i \\left( y_i - \\frac{\\sigma_{12}(x_{si} - \\boldsymbol{w}_i^{\\top} \\boldsymbol{\\gamma})}{\\sigma_{22}} \\right) \\right] \\right), \\] \\[ \\boldsymbol{B}_n = \\left( \\omega_1^{-1} \\sum_{i=1}^{N} \\boldsymbol{x}_i \\boldsymbol{x}_i^{\\top} + \\boldsymbol{B}_0^{-1} \\right)^{-1}, \\quad \\omega_1 = \\sigma_{11} - \\frac{\\sigma_{12}^2}{\\sigma_{22}}, \\] \\[ \\boldsymbol{G}_n = \\left( \\omega_2^{-1} \\sum_{i=1}^{N} \\boldsymbol{w}_i \\boldsymbol{w}_i^{\\top} + \\boldsymbol{G}_0^{-1} \\right)^{-1}, \\quad \\boldsymbol{\\gamma}_n = \\boldsymbol{G}_n \\left( \\boldsymbol{G}_0^{-1} \\boldsymbol{\\gamma}_0 + \\omega_2^{-1} \\sum_{i=1}^{N} \\left[ \\boldsymbol{w}_i \\left( x_{si} - \\frac{\\sigma_{12} (y_i - \\boldsymbol{x}_i^{\\top} \\boldsymbol{\\beta})}{\\sigma_{11}} \\right) \\right] \\right), \\] \\[ \\omega_2 = \\sigma_{22} - \\frac{\\sigma_{12}^2}{\\sigma_{11}}, \\quad \\boldsymbol{\\Psi}_n = \\left[ \\boldsymbol{\\Psi}_0^{-1} + \\sum_{i=1}^N \\begin{pmatrix} y_i - \\boldsymbol{x}_i^{\\top} \\boldsymbol{\\beta} \\\\ x_{si} - \\boldsymbol{w}_i^{\\top} \\boldsymbol{\\gamma} \\end{pmatrix} (y_i - \\boldsymbol{x}_i^{\\top} \\boldsymbol{\\beta}, x_{si} - \\boldsymbol{w}_i^{\\top} \\boldsymbol{\\gamma}) \\right]^{-1}, \\] \\[ \\alpha_n = \\alpha_0 + N, \\quad \\sigma_{lj} \\text{ are the elements of } \\boldsymbol{\\Sigma}. \\] We also use a Gibbs sampling algorithm in this model since we have standard conditional posterior distributions. Example: Simulation exercise Let’s simulate the simple process \\(y_i=\\beta_1+\\beta_2x_{si}+\\mu_i\\) and \\(x_{si}=\\gamma_1+\\gamma_2z_i+v_i\\) where \\([\\mu_i \\ v_i]^{\\top} \\sim N(\\boldsymbol{0},\\boldsymbol{\\Sigma})\\), \\(\\boldsymbol{\\Sigma}=[\\sigma_{lj}]\\) such that \\(\\sigma_{12} \\neq 0\\), \\(i=1,2,\\dots,100\\). Observe that \\(\\mu\\mid v\\sim N\\left(\\frac{\\sigma_{12}}{\\sigma_{22}}v,\\sigma_{11}-\\frac{\\sigma_{21}^2}{\\sigma_{22}}\\right)\\), this implies that \\(\\mathbb{E}[\\mu\\mid x_s]=\\mathbb{E}[\\mu\\mid v]=\\frac{\\sigma_{12}}{\\sigma_{22}}v\\neq 0\\) given \\(\\sigma_{12}\\neq 0\\) and \\(\\mathbb{E}[\\mu\\mid z]=0\\). Let’s set all location parameters equal to 1, and \\(\\sigma_{11}=\\sigma_{22}=1\\), \\(\\sigma_{12}=0.8\\), and \\(z\\sim N(0,1)\\). We know from the large sampling properties of the posterior mean that this converges to the maximum likelihood estimator (see Section 1.1, and Lehmann and Casella (2003), Van der Vaart (2000)), which in this setting is \\[ \\hat{\\beta}_2=\\frac{\\widehat{\\text{Cov}}(x_s,y)}{\\widehat{\\text{Var}}(x_s)} \\] which converges in probability to \\[ \\beta_2+\\frac{\\sigma_{12}}{\\sigma_{22}\\text{Var}(x_s)}=\\beta_2+\\frac{\\sigma_{12}}{\\sigma_{22}(\\gamma_2^2\\text{Var}(z)+\\sigma_{22})}=1.4, \\] that is, the asymptotic bias when using the posterior mean of a linear regression without taking into account endogeneity is 0.4 in this example. We assess the sampling performance of the Bayesian estimators by simulating this setting 100 times. The following code demonstrates how to do this using a linear model that does not account for the endogeneity issue (see Section 6.1), as well as how to implement the instrumental variable model. In this setup, we use \\(\\boldsymbol{B}_0 = 1000 \\mathbf{I}_2\\), \\(\\boldsymbol{\\beta}_0 = \\mathbf{0}_2\\), and the parameters of the inverse gamma distribution are set to 0.0005. For the instrumental variable model, we additionally set \\(\\boldsymbol{\\gamma}_0 = \\mathbf{0}_2\\), \\(\\boldsymbol{G}_0 = 1000 \\mathbf{I}_2\\), \\(\\alpha_0 = 3\\), and \\(\\boldsymbol{\\Psi}_0 = 3 \\mathbf{I}_2\\). rm(list = ls()); set.seed(010101) N &lt;- 100; k &lt;- 2 B &lt;- rep(1, k); G &lt;- rep(1, 2); s12 &lt;- 0.8 SIGMA &lt;- matrix(c(1, s12, s12, 1), 2, 2) z &lt;- rnorm(N); Z &lt;- cbind(1, z); w &lt;- matrix(1,N,1); S &lt;- 100 U &lt;- replicate(S, MASS::mvrnorm(n = N, mu = rep(0, 2), SIGMA)) x &lt;- G[1] + G[2]*z + U[,2,]; y &lt;- B[1] + B[2]*x + U[,1,] # Hyperparameters d0 &lt;- 0.001/2; a0 &lt;- 0.001/2 b0 &lt;- rep(0, k); c0 &lt;- 1000; B0 &lt;- c0*diag(k) B0i &lt;- solve(B0); g0 &lt;- rep(0, 2) G0 &lt;- 1000*diag(2); G0i &lt;- solve(G0) nu &lt;- 3; Psi0 &lt;- nu*diag(2) # MCMC parameters mcmc &lt;- 5000; burnin &lt;- 1000 tot &lt;- mcmc + burnin; thin &lt;- 1 # Gibbs sampling Gibbs &lt;- function(x, y){ Data &lt;- list(y = y, x = x, w = w, z = Z) Mcmc &lt;- list(R = mcmc, keep = thin, nprint = 0) Prior &lt;- list(md = g0, Ad = G0i, mbg = b0, Abg = B0i, nu = nu, V = Psi0) RestIV &lt;- bayesm::rivGibbs(Data = Data, Mcmc = Mcmc, Prior = Prior) PostBIV &lt;- mean(RestIV[[&quot;betadraw&quot;]]) ResLM &lt;- MCMCpack::MCMCregress(y ~ x + w - 1, b0 = b0, B0 = B0i, c0 = a0, d0 = d0) PostB &lt;- mean(ResLM[,1]); Res &lt;- c(PostB,PostBIV) return(Res) } PosteriorMeans &lt;- sapply(1:S, function(s) {Gibbs(x = x[,s], y = y[,s])}) ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## ## ## Starting Gibbs Sampler for Linear IV Model ## ## nobs= 100 ; 2 instruments; 1 included exog vars ## Note: the numbers above include intercepts if in z or w ## ## Prior Parms: ## mean of delta ## [1] 0 0 ## Adelta ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## mean of beta/gamma ## [1] 0 0 ## Abeta/gamma ## [,1] [,2] ## [1,] 0.001 0.000 ## [2,] 0.000 0.001 ## Sigma Prior Parms ## nu= 3 V= ## [,1] [,2] ## [1,] 3 0 ## [2,] 0 3 ## ## MCMC parms: ## R= 5000 keep= 1 nprint= 0 ## rowMeans(PosteriorMeans) ## [1] 1.408272 1.035428 Model &lt;- c(replicate(S, &quot;Ordinary&quot;), replicate(S, &quot;Instrumental&quot;)) postmeans &lt;- c(t(PosteriorMeans)) df &lt;- data.frame(postmeans, Model, stringsAsFactors = FALSE) library(ggplot2); library(latex2exp) histExo &lt;- ggplot(df, aes(x = postmeans, fill = Model)) + geom_histogram(bins = 40, position = &quot;identity&quot;, color = &quot;black&quot;, alpha = 0.5) + labs(title = &quot;Overlayed Histograms&quot;, x = &quot;Value&quot;, y = &quot;Count&quot;) + scale_fill_manual(values = c(&quot;blue&quot;, &quot;red&quot;)) + geom_vline(aes(xintercept = mean(postmeans[1:S])), color = &quot;black&quot;, linewidth = 1, linetype = &quot;dashed&quot;) + geom_vline(aes(xintercept = mean(postmeans[101:200])), color = &quot;black&quot;, linewidth = 1, linetype = &quot;dashed&quot;) + geom_vline(aes(xintercept = B[2]), color = &quot;green&quot;, linewidth = 1, linetype = &quot;dashed&quot;) + xlab(TeX(&quot;$E[\\\\beta_2]$&quot;)) + ylab(&quot;Frequency&quot;) + ggtitle(&quot;Histogram: Posterior means simulating 100 samples&quot;) histExo The Figure displays the histograms of the posterior means of \\(\\beta_2\\) using the ordinary model, which does not account for endogeneity, and the instrumental variable model. On one hand, the mean of the posterior means for the ordinary model is 1.41 (black dashed line in the red histogram), implying a bias of 0.41, which is very close to the population bias of 0.40. On the other hand, the mean of the posterior means for the instrumental variable model is 1.04 (black dashed line in the blue histogram), which is close to the population value of \\(\\beta_2 = 1\\) (green dashed line). We also observe that the histogram of the posterior means for the ordinary model is less dispersed. That is, this estimator is more efficient, which is a well-known result in the Frequentist inferential approach when comparing ordinary least squares and two-stage least squares (see Jeffrey M. Wooldridge (2010)). Two very important aspects in the instrumental variables literature are the weakness and exogeneity of the instruments. The former refers to how strong the relationship is between the instruments and the endogenous regressors, while the latter refers to the independence of the instruments from the stochastic error in the structural equation. In Exercise 6, we ask you to use the previous code as a baseline to study these two aspects. Observe the link between the weakness and exogeneity of the instrument, and the exclusion restrictions (\\(\\mathbb{E}[x_s \\boldsymbol{z}] \\neq \\boldsymbol{0}\\) and \\(\\mathbb{E}[y \\boldsymbol{z} \\mid x_s] = \\boldsymbol{0}\\)). This is the point of departure of Conley, Hansen, and Rossi (2012), who propose assessing the plausibility of the exclusion restrictions by defining plausible exogeneity as having prior information that the effect of the instrument in the structural equation is near zero, but perhaps not exactly zero. The following Algorithm can be used to estimate the instrumental variable model using our GUI. We ask in Exercise 8 to replicate the example of the effect of institutions on per capita GDP using our GUI. Algorithm: Instrumental Variable Model Select Multivariate Models on the top panel Select Variable instrumental (two equations) model using the left radio button Upload the dataset, selecting first if there is a header in the file, and the kind of separator in the csv file of the dataset (comma, semicolon, or tab). Then, use the Browse button under the Choose File legend Select MCMC iterations, burn-in, and thinning parameters using the Range sliders Write down the formula of the structural equation in the Main Equation box. This formula must be written using the syntax of the formula command of R software. This equation includes the intercept by default, do not include it in the equation Write down the formula of the endogenous regressor in the Instrumental Equation box. This formula must be written using the syntax of the formula command of R software. This equation includes the intercept by default, do not include it in the equation Set the hyperparameters: mean vectors, covariance matrices, degrees of freedom, and the scale matrix. This step is not necessary as by default our GUI uses non-informative priors Click the Go! button Analyze results Download posterior chains and diagnostic plots using the Download Posterior Chains and Download Posterior Graphs buttons References "],["sec74.html", "7.4 Multivariate probit model", " 7.4 Multivariate probit model In the multivariate probit model Edwards and Allenby (2003), the response variable \\(y_{il} = \\{0, 1\\}\\) indicates that individual \\(i\\) makes binary choices among \\(L\\) mutually exclusive alternatives, where \\(l = 1, 2, \\dots, L\\) and \\(i = 1, 2, \\dots, N\\). Specifically, \\[ y_{il} = \\begin{cases} 0, &amp; \\quad y_{il}^* \\leq 0 \\\\ 1, &amp; \\quad y_{il}^* &gt; 0 \\end{cases} \\] where \\(\\boldsymbol{y}_i^* = \\boldsymbol{X}_i \\boldsymbol{\\beta} + \\boldsymbol{\\mu}_i \\sim \\text{i.i.d.} \\, N(\\boldsymbol{0}, \\boldsymbol{\\Sigma})\\). Here, \\(\\boldsymbol{y}_i^*\\) is an unobserved latent \\(L\\)-dimensional vector, \\(\\boldsymbol{X}_i = \\boldsymbol{x}_i^\\top \\otimes \\mathbf{I}_L\\) is an \\(L \\times K\\) design matrix of regressors, with \\(K = L \\times k\\), where \\(k\\) is the number of regressors (i.e., the length of \\(\\boldsymbol{x}_i\\)). In addition, \\(\\boldsymbol{\\beta} = \\left[\\boldsymbol{\\beta}_1^\\top \\ \\boldsymbol{\\beta}_2^\\top \\dots \\boldsymbol{\\beta}_k^\\top\\right]^\\top\\), where \\(\\boldsymbol{\\beta}_j\\) forms an \\(L\\)-dimensional vector of coefficients for \\(j = 1, 2, \\dots, k\\). The likelihood function for this model is given by \\[ p(\\boldsymbol{\\beta}, \\boldsymbol{\\Sigma} \\mid \\boldsymbol{y}, \\boldsymbol{X}) = \\prod_{i=1}^N \\prod_{l=1}^L p_{il}^{y_{il}}, \\] where \\(p_{il} = p(y_{il}^* \\geq 0)\\). Observe that \\(p({y}_{il}^*\\geq 0)=p({\\lambda}_{ll}{y}_{il}^*\\geq 0)\\), \\(\\lambda_{ll}&gt;0\\). This generates identification issues because only the correlation matrix can be identified, similar to the univariate probit model where the variance of the model is fixed to 1. We follow the post-processing strategy proposed by Edwards and Allenby (2003) to obtain identified parameters, that is, \\(\\tilde{\\boldsymbol{\\beta}}=\\text{vec}\\left\\{\\boldsymbol{\\Lambda}\\mathbf{B}\\right\\}\\) and the correlation matrix \\(\\boldsymbol{R}=\\boldsymbol{\\Lambda}\\boldsymbol{\\Sigma}\\boldsymbol{\\Lambda}\\), where \\(\\boldsymbol{\\Lambda}=\\text{diag}\\left\\{\\sigma_{ll}\\right\\}^{-1/2}\\) and \\(\\mathbf{B}=\\left[\\boldsymbol{\\beta}_1 \\ \\boldsymbol{\\beta}_2 \\dots \\boldsymbol{\\beta}_k\\right]\\).39 We assume independent priors: \\(\\boldsymbol{\\beta} \\sim N(\\boldsymbol{\\beta}_0, \\boldsymbol{B}_0)\\) and \\(\\boldsymbol{\\Sigma}^{-1} \\sim W(\\alpha_0, \\boldsymbol{\\Psi}_0)\\). We can apply Gibbs sampling to this model, as it is a standard Bayesian linear regression model when data augmentation in \\(\\boldsymbol{y}^*\\) is used. The posterior conditional distributions are \\[\\begin{equation} \\boldsymbol{\\beta}\\mid \\boldsymbol{\\Sigma},\\boldsymbol{w} \\sim N(\\boldsymbol{\\beta}_n,\\boldsymbol{B}_n), \\end{equation}\\] \\[\\begin{equation} \\boldsymbol{\\Sigma}^{-1} \\mid \\boldsymbol{\\beta},\\boldsymbol{w} \\sim W(\\alpha_n,\\boldsymbol{\\Psi}_n), \\end{equation}\\] \\[\\begin{equation} y_{il}^* \\mid \\boldsymbol{y}_{i,-l}^*,\\boldsymbol{\\beta},\\boldsymbol{\\Sigma}^{-1},\\boldsymbol{y_i} \\sim TN_{I_{il}}(m_{il},\\tau_{ll}^2) \\end{equation}\\] where \\(\\boldsymbol{B}_n=(\\boldsymbol{B}_0^{-1}+\\boldsymbol{X}^{*\\top}\\boldsymbol{X}^*)^{-1}\\), \\(\\boldsymbol{\\beta}_n=\\boldsymbol{B}_n(\\boldsymbol{B}_0^{-1}\\boldsymbol{\\beta}_0+\\boldsymbol{X}^{*\\top}\\boldsymbol{y}^{**})\\), \\(\\boldsymbol{\\Sigma}^{-1}=\\boldsymbol{C}^{\\top}\\boldsymbol{C}\\), \\(\\boldsymbol{X}_i^{*}=\\boldsymbol{C}^{\\top}\\boldsymbol{X}_i\\), \\(\\boldsymbol{y}_i^{**}=\\boldsymbol{C}^{\\top}\\boldsymbol{y}_i^*\\), \\(\\alpha_n=\\alpha_0+N\\), \\(\\boldsymbol{\\Psi}_n=(\\boldsymbol{\\Psi}_0+\\sum_{i=1}^N (\\boldsymbol{y}_i^*-\\boldsymbol{X}_i\\boldsymbol{\\beta})(\\boldsymbol{y}_i^*-\\boldsymbol{X}_i\\boldsymbol{\\beta})^{\\top})^{-1}\\), \\[ m_{il}=\\boldsymbol{x}_{il}^{\\top}\\boldsymbol{\\beta}+\\boldsymbol{f}_l^{\\top}(\\boldsymbol{y}_{i,-l}^*-\\boldsymbol{X}_{i,-l}\\boldsymbol{\\beta}), \\] where \\(\\boldsymbol{y}_{i,-l}^*\\) is an \\(L-1\\) dimensional vector of all components of \\(\\boldsymbol{y}_i^*\\) excluding \\(y_{il}^*\\), \\(\\boldsymbol{x}_{il}^{\\top}\\) is the \\(l\\)-th row of \\(\\boldsymbol{X}_i\\), \\(\\boldsymbol{X}_{i,-l}\\) is \\(\\boldsymbol{X}_{i}\\) after deleting the \\(l\\)-th row, \\[ \\boldsymbol{f}_l^{\\top}=\\boldsymbol{\\omega}_{l,-l}^{\\top}\\boldsymbol{\\Sigma}_{-l,-l}^{-1}, \\] where \\(\\boldsymbol{\\omega}_{l,-l}^{\\top}\\) and \\(\\boldsymbol{\\Sigma}_{-l,-l}\\) are the \\(l\\)-th row of \\(\\boldsymbol{\\Sigma}\\) extracting the \\(l\\)-th element, and the sub-matrix of \\(\\boldsymbol{\\Sigma}\\) extracting the \\(l,l\\) element, and \\[ \\tau_{ll}^2=\\sigma_{l,l}-\\boldsymbol{\\omega}_{l,-l}^{\\top}\\boldsymbol{\\Sigma}_{-l,-l}^{-1}\\boldsymbol{\\omega}_{-l,l}, \\] and \\[ \\boldsymbol{X}^*= \\begin{bmatrix} \\boldsymbol{X}_1^*\\\\ \\boldsymbol{X}_2^*\\\\ \\vdots\\\\ \\boldsymbol{X}_N^* \\end{bmatrix}, \\quad I_{il}= \\begin{Bmatrix} y_{il}^*&gt; 0, &amp; y_{il}=1\\\\ y_{il}^*\\leq 0 , &amp; y_{il}=0 \\end{Bmatrix}, \\quad \\boldsymbol{\\Sigma}= \\begin{bmatrix} \\boldsymbol{\\omega}_1^{\\top} \\\\ \\boldsymbol{\\omega}_2^{\\top} \\\\ \\vdots \\\\ \\boldsymbol{\\omega}_{L}^{\\top} \\end{bmatrix}. \\] The setting in our GUI has the same regressors in each binary decision. However, we can see that the multivariate probit model is similar to a SUR model in latent variables. We ask in Exercise 9 to implement a Gibbs sampling algorithm for a multivariate probit model with different regressors in each equation. Example: Self selection in hospitalization due to a subsidized health care program We use the dataset 7HealthMed.csv, where the dependent variable is \\(y = \\left[\\text{Hosp} \\ \\text{SHI}\\right]^{\\top}\\), with \\(\\text{Hosp} = 1\\) if an individual was hospitalized in the year prior to the survey (0 otherwise), and \\(\\text{SHI} = 1\\) if the individual had subsidized health insurance (0 otherwise). Recall that our application of binary response models aimed to uncover the determinants of hospitalization in Medellín (Colombia), where one of the regressors was a binary indicator of participation in a subsidized health care program (Section 6.3). We can use a bivariate probit model if we suspect there is dependence between the decisions regarding these two variables. A priori, we would expect that being in a subsidized health care program increases the probability of hospitalization ceteris paribus, due to reduced costs for the patient. However, if an individual expects to be hospitalized in the future, and the factors influencing this decision are unobserved by the modeler, a feedback effect may exist from hospitalization to enrollment in the subsidized health care program. We considered seven regressors: a constant, gender (female), age, self-perception of health status (with categories fair, good, and excellent, using bad as the reference category), and the proportion of the individual’s age spent living in their neighborhood. The last variable attempts to account for social capital, which can affect enrollment in the subsidized health insurance program, as the target population is identified by the local government (Ramírez-Hassan and Guerra-Urzola 2021). The dataset includes 12,975 individuals who can “choose” two options: hospitalization and enrollment in the subsidized health insurance regime. The following Algorithm shows how to run a multivariate probit model using our GUI. Algorithm: Multivariate Probit Model Select Multivariate Models on the top panel Select Multivariate Probit model using the left radio button Upload the dataset, selecting first if there is a header in the file, and the kind of separator in the csv file of the dataset (comma, semicolon, or tab). Then, use the Browse button under the Choose File legend Select MCMC iterations, burn-in, and thinning parameters using the Range sliders Write down the number of cross-sectional units in the Number of individuals: n box Write down the number of exogenous variables in the Number of exogenous variables: k box Write down the number of choices in the Number of choices: l box Set the hyperparameters: mean vectors, covariance matrix, degrees of freedom, and the scale matrix. This step is not necessary as by default our GUI uses non-informative priors Click the Go! button Analyze results Download posterior chains and diagnostic plots using the Download Posterior Chains and Download Posterior Graphs buttons We set 20,000 MCMC iterations with a thinning parameter equal to 5. The hyperparameters are \\(\\boldsymbol{\\beta}_0 = \\boldsymbol{0}_{14}\\), \\(\\boldsymbol{B}_0 = 100\\boldsymbol{I}_{14}\\), \\(\\alpha_0 = 4\\), and \\(\\boldsymbol{\\Psi}_0 = 4\\boldsymbol{I}_2\\).40 rm(list = ls()); set.seed(010101) Data &lt;- read.csv(&quot;https://raw.githubusercontent.com/besmarter/BSTApp/refs/heads/master/DataApp/7HealthMed.csv&quot;, sep = &quot;,&quot;, header = TRUE, quote = &quot;&quot;) attach(Data); str(Data) ## The following object is masked from DataUtEst: ## ## id ## The following object is masked from Data (pos = 6): ## ## Age ## The following object is masked from Data (pos = 7): ## ## Age ## The following objects are masked from Data (pos = 8): ## ## Age, Excellent, Fair, Female, Good, id, PTL ## The following objects are masked from mydata: ## ## Age, Excellent, Fair, Female, Good, id, PTL ## The following object is masked from Data (pos = 10): ## ## Age ## &#39;data.frame&#39;: 25950 obs. of 9 variables: ## $ id : int 1 1 2 2 3 3 4 4 5 5 ... ## $ y : int 0 1 0 1 0 1 0 1 0 0 ... ## $ Constant : int 1 1 1 1 1 1 1 1 1 1 ... ## $ Female : int 0 0 1 1 1 1 1 1 0 0 ... ## $ Age : int 7 7 39 39 23 23 15 15 8 8 ... ## $ Fair : int 0 0 0 0 0 0 0 0 0 0 ... ## $ Good : int 1 1 1 1 1 1 1 1 0 0 ... ## $ Excellent: int 0 0 0 0 0 0 0 0 1 1 ... ## $ PTL : num 0.43 0.43 0 0 0 0 0 0 0 0 ... p &lt;- 2; nd &lt;- 7; N &lt;- length(y)/p; y &lt;- y Xd &lt;- as.matrix(Data[seq(1, p*N, 2),3:9]) XcreateMP&lt;-function(p,nxs,nind,Data){ pandterm = function(message) { stop(message, call. = FALSE) } if (missing(nxs)) pandterm(&quot;requires number of regressors: include intercept if required&quot;) if (missing(nind)) pandterm(&quot;requires number of units (individuals)&quot;) if (missing(Data)) pandterm(&quot;requires dataset&quot;) if (nrow(Data)!=nind*2) pandterm(&quot;check dataset! number of units times number alternatives should be equal to dataset rows&quot;) XXDat&lt;-array(0,c(p,1+nxs,nind)) XX&lt;-array(0,c(p,nxs*p,nind)) YY&lt;-array(0,c(p,1,nind)) is&lt;- seq(p,nind*p,p) cis&lt;- seq(nxs,nxs*p+1,nxs) for(i in is){ j&lt;-which(i==is) XXDat[,,j]&lt;-as.matrix(Data[c((i-(p-1)):i),-1]) YY[,,j]&lt;-XXDat[,1,j] for(l in 1:p){ XX[l,((cis[l]-(nxs-1)):cis[l]),j]&lt;-XXDat[l,-1,j] } } return(list(y=YY,X=XX)) } Dat &lt;- XcreateMP(p = p, nxs = nd, nind = N, Data = Data) y&lt;-NULL; X&lt;-NULL for(i in 1:dim(Dat$y)[3]){ y&lt;-c(y,Dat$y[,,i]) X&lt;-rbind(X,Dat$X[,,i]) } DataMP = list(p=p, y=y, X=X) # Hyperparameters k &lt;- dim(X)[2]; b0 &lt;- rep(0, k); c0 &lt;- 1000 B0 &lt;- c0*diag(k); B0i &lt;- solve(B0) a0 &lt;- p - 1 + 3; Psi0 &lt;- a0*diag(p) Prior &lt;- list(betabar = b0, A = B0i, nu = a0, V = Psi0) # MCMC parameters mcmc &lt;- 20000; thin &lt;- 5; Mcmc &lt;- list(R = mcmc, keep = thin, nprint = 0) Results &lt;- bayesm::rmvpGibbs(Data = DataMP, Mcmc = Mcmc, Prior = Prior) ## Table of y values ## y ## 0 1 ## 15653 10297 ## ## Starting Gibbs Sampler for MVP ## 12975 obs of 2 binary indicators; 14 indep vars (including intercepts) ## ## Prior Parms: ## betabar ## [1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## A ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] ## [1,] 0.001 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 ## [2,] 0.000 0.001 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 ## [3,] 0.000 0.000 0.001 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 ## [4,] 0.000 0.000 0.000 0.001 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 ## [5,] 0.000 0.000 0.000 0.000 0.001 0.000 0.000 0.000 0.000 0.000 0.000 0.000 ## [6,] 0.000 0.000 0.000 0.000 0.000 0.001 0.000 0.000 0.000 0.000 0.000 0.000 ## [7,] 0.000 0.000 0.000 0.000 0.000 0.000 0.001 0.000 0.000 0.000 0.000 0.000 ## [8,] 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.001 0.000 0.000 0.000 0.000 ## [9,] 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.001 0.000 0.000 0.000 ## [10,] 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.001 0.000 0.000 ## [11,] 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.001 0.000 ## [12,] 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.001 ## [13,] 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 ## [14,] 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 ## [,13] [,14] ## [1,] 0.000 0.000 ## [2,] 0.000 0.000 ## [3,] 0.000 0.000 ## [4,] 0.000 0.000 ## [5,] 0.000 0.000 ## [6,] 0.000 0.000 ## [7,] 0.000 0.000 ## [8,] 0.000 0.000 ## [9,] 0.000 0.000 ## [10,] 0.000 0.000 ## [11,] 0.000 0.000 ## [12,] 0.000 0.000 ## [13,] 0.001 0.000 ## [14,] 0.000 0.001 ## nu ## [1] 4 ## V ## [,1] [,2] ## [1,] 4 0 ## [2,] 0 4 ## ## MCMC Parms: ## 20000 reps; keeping every 5 th draw nprint= 0 ## initial beta= 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## initial sigma= ## [,1] [,2] ## [1,] 1 0 ## [2,] 0 1 ## betatilde1 &lt;- Results$betadraw[,1:7] / sqrt(Results$sigmadraw[,1]) summary(coda::mcmc(betatilde1)) ## ## Iterations = 1:4000 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 4000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## [1,] -0.973678 0.12756 0.0020170 2.414e-03 ## [2,] 0.122745 0.04872 0.0007704 1.326e-03 ## [3,] 0.002941 0.00110 0.0000174 2.577e-05 ## [4,] -0.522298 0.11435 0.0018080 1.781e-03 ## [5,] -1.234641 0.11131 0.0017599 1.859e-03 ## [6,] -1.093871 0.13165 0.0020816 2.591e-03 ## [7,] -0.064123 0.05942 0.0009395 1.619e-03 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## var1 -1.2247602 -1.059257 -0.970870 -0.889741 -0.733411 ## var2 0.0269885 0.090098 0.121863 0.155585 0.220662 ## var3 0.0007652 0.002207 0.002925 0.003685 0.005049 ## var4 -0.7477149 -0.598898 -0.522549 -0.445173 -0.296718 ## var5 -1.4520842 -1.309922 -1.234633 -1.160468 -1.018396 ## var6 -1.3503717 -1.182381 -1.092511 -1.005472 -0.837939 ## var7 -0.1791758 -0.103506 -0.064418 -0.024499 0.051849 betatilde2 &lt;- Results$betadraw[,8:14] / sqrt(Results$sigmadraw[,4]) summary(coda::mcmc(betatilde2)) ## ## Iterations = 1:4000 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 4000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## [1,] 0.567199 0.1346170 2.128e-03 2.409e-03 ## [2,] 0.306014 0.0242202 3.830e-04 3.672e-04 ## [3,] 0.009125 0.0006758 1.068e-05 1.109e-05 ## [4,] -0.221882 0.1347631 2.131e-03 2.447e-03 ## [5,] -0.421087 0.1307593 2.067e-03 2.364e-03 ## [6,] -0.435578 0.1370951 2.168e-03 2.449e-03 ## [7,] 0.224500 0.0304865 4.820e-04 4.829e-04 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## var1 0.306343 0.477265 0.564698 0.656616 0.82932 ## var2 0.258347 0.289819 0.305902 0.322116 0.35284 ## var3 0.007848 0.008656 0.009124 0.009591 0.01045 ## var4 -0.488810 -0.313532 -0.218459 -0.130373 0.04144 ## var5 -0.677686 -0.511529 -0.418139 -0.332415 -0.17322 ## var6 -0.703355 -0.527642 -0.433378 -0.341355 -0.16989 ## var7 0.164388 0.203623 0.224533 0.245306 0.28513 sigmadraw12 &lt;- Results$sigmadraw[,3] / (Results$sigmadraw[,1]*Results$sigmadraw[,4])^0.5 summary(coda::mcmc(sigmadraw12)) ## ## Iterations = 1:4000 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 4000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## -0.003338 0.033076 0.000523 0.001288 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## -0.070515 -0.025009 -0.002895 0.018432 0.060986 The previous R code demonstrates how to obtain the posterior draws using the rmvpGibbs command from the bayesm package. The results suggest that females, older individuals, and those who self-assess their health as poor are more likely to be hospitalized. Furthermore, females, older individuals, and those with a poor or fair self-perception of health, who have lived a larger proportion of their life in their current neighborhood, are more likely to be enrolled in the subsidized health care system. However, the results indicate that there is no unobserved correlation between the two equations, as the 95% credible interval for the correlation is (-0.07, 0.06). References "],["sec75.html", "7.5 Summary", " 7.5 Summary In this chapter, we present the setting and posterior distributions of the most common multivariate models. The multivariate framework allows us to address endogeneity issues by using the conditional distribution of a multivariate normal vector. Moreover, we always obtain posterior conditional distributions that belong to standard families (multivariate normal, Wishart, and truncated normal) in these models. This property enables the implementation of the Gibbs sampling algorithm for all these models. "],["sec76.html", "7.6 Exercises", " 7.6 Exercises Show that \\(\\mathbb{E}[u_1\\text{PAER}] = \\frac{\\alpha_1}{1 - \\beta_1\\alpha_1} \\sigma_1^2\\), assuming that \\(\\mathbb{E}[u_1 u_2] = 0\\), where \\(\\text{Var}(u_1) = \\sigma_1^2\\), in the example of the effect of institutions on per capita GDP. Show that \\(\\beta_1=\\pi_1/\\gamma_1\\), in the example of the effect of institutions on per capita GDP. The effect of institutions on per capita gross domestic product continues I Use the rmultireg command from the bayesm package to perform inference in the example of the effect of institutions on per capita GDP. Demand and supply simulation Given the structural demand-supply model: \\[ \\begin{aligned} q_i^d &amp;= \\beta_1 + \\beta_2 p_i + \\beta_3 y_i + \\beta_4 pc_i + \\beta_5 ps_i + u_{i1}, \\\\ q_i^s &amp;= \\alpha_1 + \\alpha_2 p_i + \\alpha_3 er_i + u_{i2}, \\end{aligned} \\] where \\(q^d\\) is demand, \\(q^s\\) is supply, \\(p\\), \\(y\\), \\(pc\\), \\(ps\\), and \\(er\\) are price, income, complementary price, substitute price, and exchange rate, respectively. Complementary and substitute prices refer to the prices of complementary and substitute goods for \\(q\\). Assume that \\[ \\boldsymbol{\\beta} = \\begin{bmatrix} 5 \\\\ -0.5 \\\\ 0.8 \\\\ -0.4 \\\\ 0.7 \\end{bmatrix}, \\quad \\boldsymbol{\\alpha} = \\begin{bmatrix} -2 \\\\ 0.5 \\\\ -0.4 \\end{bmatrix}, \\] \\(u_1 \\sim N(0, 0.5^2)\\), and \\(u_2 \\sim N(0, 0.5^2)\\). Additionally, assume that \\(y \\sim N(10, 1)\\), \\(pc \\sim N(5, 1)\\), \\(ps \\sim N(5, 1)\\), and \\(er \\sim N(15, 1)\\). Find the reduced-form model by using the condition that in equilibrium, demand and supply are equal, i.e., \\(q^d = q^s\\). This condition defines the observable quantity, \\(q\\). Simulate \\(p\\) and \\(q\\) from the reduced-form equations. Perform inference for the reduced-form model using the rmultireg command from the bayesm package. Use the posterior draws of the reduced-form parameters to perform inference for the structural parameters. Any issues? Hint: Are all structural parameters exactly identified? Utility demand continues Run the Utility demand application using our GUI and the information in the dataset Utilities.csv. Hint: This file should be modified to agree with the structure that our GUI requires (see the dataset 5Institutions.csv in the folder DataApp of our GitHub repository - https://github.com/besmarter/BSTApp - for a template). Program from scratch the Gibbs sampler algorithm in this application. Simulation exercise of instrumental variables continues I Use the setting of the simulation exercise with instrumental variables to analyze the impact of a weak instrument. For instance, set \\(\\gamma_2 = 0.2\\) and compare the performance of the posterior means of the ordinary and instrumental variable models. Perform a simulation to analyze how the degree of exogeneity of the instrument affects the performance of the posterior mean in the instrumental variable model. Simulation exercise of instrumental variables continues II Program from scratch the Gibbs sampling algorithm of the instrumental model for the simulation exercise of the instrumental variables. The effect of institutions on per capita gross domestic product continues II Estimate the structural Equation (7.1) using the instrumental variable model where the instrument of PAER is \\(\\log(\\textit{Mort})\\). Compare the effect of property rights on per capita GDP of this model with the effect estimated in the example of the effect of institutions on per capita gross domestic product. Use the file 6Institutions.csv to do this exercise in our GUI, and set \\[ \\boldsymbol{B}_0=100\\boldsymbol{I}_5, \\quad \\boldsymbol{\\beta}_0=\\boldsymbol{0}_5, \\quad \\boldsymbol{\\gamma}_0=\\boldsymbol{0}_2, \\quad \\boldsymbol{G}_0=100\\boldsymbol{I}_2, \\quad \\alpha_0=3, \\quad \\boldsymbol{\\Psi}_0=3\\boldsymbol{I}_2. \\] The MCMC iterations, burn-in, and thinning parameters are 50000, 1000, and 5, respectively. Multivariate probit with different regressors Let’s do a simulation exercise where \\[ \\begin{aligned} y_{i1}^* &amp;= 0.5 - 1.2x_{i11} + 0.7x_{i12} + 0.8x_{i3} + \\mu_{i1}, \\\\ y_{i2}^* &amp;= 1.5 - 0.8x_{i21} + 0.5x_{i22} + \\mu_{i2}, \\end{aligned} \\] with \\[ \\boldsymbol{\\Sigma}= \\begin{bmatrix} 1 &amp; 0.5 \\\\ 0.5 &amp; 1 \\end{bmatrix}, \\] where all regressors follow a standard normal distribution, and \\(N=5000\\). Use \\[ \\boldsymbol{\\beta}_0=\\boldsymbol{0}, \\quad \\boldsymbol{B}_0=1000\\boldsymbol{B}, \\quad \\alpha_0=4, \\quad \\boldsymbol{\\Psi}_0=4\\boldsymbol{I}_2. \\] Set the number of iterations to 2000 and a thinning parameter equal to 5. Perform inference using the setting of Section 7.4, that is, assuming that \\(x_{i3}\\) could have an effect on \\(y_{i2}\\). Program a Gibbs sampling algorithm taking into account that there are different regressors in each binary decision, that is, \\(x_{i3}\\) does not have an effect on \\(y_{i2}\\). "],["Chap8.html", "Chapter 8 Time series", " Chapter 8 Time series We will show the state-space representation of time series models with their theory foundation, and perform applications using R and our GUI. We will have mathematical and computational exercises in our GUI and in R. "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
