<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>1.1 The Bayes’ rule | Introduction to Bayesian Econometrics</title>
  <meta name="description" content="The subject of this textbook is Bayesian data modeling, with the primary aim of providing an introduction to its theoretical foundations and facilitating the application of Bayesian inference using a GUI." />
  <meta name="generator" content="bookdown 0.43 and GitBook 2.6.7" />

  <meta property="og:title" content="1.1 The Bayes’ rule | Introduction to Bayesian Econometrics" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="The subject of this textbook is Bayesian data modeling, with the primary aim of providing an introduction to its theoretical foundations and facilitating the application of Bayesian inference using a GUI." />
  <meta name="github-repo" content="https://github.com/aramir21/IntroductionBayesianEconometricsBook" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="1.1 The Bayes’ rule | Introduction to Bayesian Econometrics" />
  
  <meta name="twitter:description" content="The subject of this textbook is Bayesian data modeling, with the primary aim of providing an introduction to its theoretical foundations and facilitating the application of Bayesian inference using a GUI." />
  

<meta name="author" content="Andrés Ramírez-Hassan" />


<meta name="date" content="2025-11-14" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="Chap1.html"/>
<link rel="next" href="sec12.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Introduction to Bayesian Econometrics: A GUIded toolkit using R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction</a>
<ul>
<li class="chapter" data-level="" data-path="to-instructors-and-students.html"><a href="to-instructors-and-students.html"><i class="fa fa-check"></i>To instructors and students</a></li>
<li class="chapter" data-level="" data-path="acknowledgments.html"><a href="acknowledgments.html"><i class="fa fa-check"></i>Acknowledgments</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="Chap1.html"><a href="Chap1.html"><i class="fa fa-check"></i><b>1</b> Basic formal concepts</a>
<ul>
<li class="chapter" data-level="1.1" data-path="sec11.html"><a href="sec11.html"><i class="fa fa-check"></i><b>1.1</b> The Bayes’ rule</a></li>
<li class="chapter" data-level="1.2" data-path="sec12.html"><a href="sec12.html"><i class="fa fa-check"></i><b>1.2</b> Bayesian framework: A brief summary of theory</a></li>
<li class="chapter" data-level="1.3" data-path="sec14.html"><a href="sec14.html"><i class="fa fa-check"></i><b>1.3</b> Bayesian reports: Decision theory under uncertainty</a></li>
<li class="chapter" data-level="1.4" data-path="summary.html"><a href="summary.html"><i class="fa fa-check"></i><b>1.4</b> Summary</a></li>
<li class="chapter" data-level="1.5" data-path="exercises.html"><a href="exercises.html"><i class="fa fa-check"></i><b>1.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="Chap2.html"><a href="Chap2.html"><i class="fa fa-check"></i><b>2</b> Conceptual differences between the Bayesian and Frequentist approaches</a>
<ul>
<li class="chapter" data-level="2.1" data-path="sec21.html"><a href="sec21.html"><i class="fa fa-check"></i><b>2.1</b> The concept of probability</a></li>
<li class="chapter" data-level="2.2" data-path="sec22.html"><a href="sec22.html"><i class="fa fa-check"></i><b>2.2</b> Subjectivity is not the key</a></li>
<li class="chapter" data-level="2.3" data-path="sec23.html"><a href="sec23.html"><i class="fa fa-check"></i><b>2.3</b> Estimation, hypothesis testing and prediction</a></li>
<li class="chapter" data-level="2.4" data-path="sec24.html"><a href="sec24.html"><i class="fa fa-check"></i><b>2.4</b> The likelihood principle</a></li>
<li class="chapter" data-level="2.5" data-path="sec25.html"><a href="sec25.html"><i class="fa fa-check"></i><b>2.5</b> Why is not the Bayesian approach that popular?</a></li>
<li class="chapter" data-level="2.6" data-path="sec26.html"><a href="sec26.html"><i class="fa fa-check"></i><b>2.6</b> A simple working example</a></li>
<li class="chapter" data-level="2.7" data-path="sec27.html"><a href="sec27.html"><i class="fa fa-check"></i><b>2.7</b> Summary</a></li>
<li class="chapter" data-level="2.8" data-path="sec28.html"><a href="sec28.html"><i class="fa fa-check"></i><b>2.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="Chap3.html"><a href="Chap3.html"><i class="fa fa-check"></i><b>3</b> Cornerstone models: Conjugate families</a>
<ul>
<li class="chapter" data-level="3.1" data-path="sec41.html"><a href="sec41.html"><i class="fa fa-check"></i><b>3.1</b> Motivation of conjugate families</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="sec41.html"><a href="sec41.html#examples-of-exponential-family-distributions"><i class="fa fa-check"></i><b>3.1.1</b> Examples of exponential family distributions</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="sec42.html"><a href="sec42.html"><i class="fa fa-check"></i><b>3.2</b> Conjugate prior to exponential family</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="sec42.html"><a href="sec42.html#sec421"><i class="fa fa-check"></i><b>3.2.1</b> Examples: Theorem 4.2.1</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="sec43.html"><a href="sec43.html"><i class="fa fa-check"></i><b>3.3</b> Linear regression: The conjugate normal-normal/inverse gamma model</a></li>
<li class="chapter" data-level="3.4" data-path="sec44.html"><a href="sec44.html"><i class="fa fa-check"></i><b>3.4</b> Multivariate linear regression: The conjugate normal-normal/inverse Wishart model</a></li>
<li class="chapter" data-level="3.5" data-path="sec45.html"><a href="sec45.html"><i class="fa fa-check"></i><b>3.5</b> Summary</a></li>
<li class="chapter" data-level="3.6" data-path="sec46.html"><a href="sec46.html"><i class="fa fa-check"></i><b>3.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="Chap4.html"><a href="Chap4.html"><i class="fa fa-check"></i><b>4</b> Simulation methods</a>
<ul>
<li class="chapter" data-level="4.1" data-path="sec51.html"><a href="sec51.html"><i class="fa fa-check"></i><b>4.1</b> Markov Chain Monte Carlo methods</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="sec51.html"><a href="sec51.html#sec511"><i class="fa fa-check"></i><b>4.1.1</b> Gibbs sampler</a></li>
<li class="chapter" data-level="4.1.2" data-path="sec51.html"><a href="sec51.html#sec512"><i class="fa fa-check"></i><b>4.1.2</b> Metropolis-Hastings</a></li>
<li class="chapter" data-level="4.1.3" data-path="sec51.html"><a href="sec51.html#sec513"><i class="fa fa-check"></i><b>4.1.3</b> Hamiltonian Monte Carlo</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="sec52.html"><a href="sec52.html"><i class="fa fa-check"></i><b>4.2</b> Importance sampling</a></li>
<li class="chapter" data-level="4.3" data-path="sec53.html"><a href="sec53.html"><i class="fa fa-check"></i><b>4.3</b> Particle filtering</a></li>
<li class="chapter" data-level="4.4" data-path="sec54.html"><a href="sec54.html"><i class="fa fa-check"></i><b>4.4</b> Convergence diagnostics</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="sec54.html"><a href="sec54.html#numerical-standard-error"><i class="fa fa-check"></i><b>4.4.1</b> Numerical standard error</a></li>
<li class="chapter" data-level="4.4.2" data-path="sec54.html"><a href="sec54.html#effective-number-of-simulation-draws"><i class="fa fa-check"></i><b>4.4.2</b> Effective number of simulation draws</a></li>
<li class="chapter" data-level="4.4.3" data-path="sec54.html"><a href="sec54.html#tests-of-convergence"><i class="fa fa-check"></i><b>4.4.3</b> Tests of convergence</a></li>
<li class="chapter" data-level="4.4.4" data-path="sec54.html"><a href="sec54.html#checking-for-errors-in-the-posterior-simulator"><i class="fa fa-check"></i><b>4.4.4</b> Checking for errors in the posterior simulator</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="sec55.html"><a href="sec55.html"><i class="fa fa-check"></i><b>4.5</b> Summary</a></li>
<li class="chapter" data-level="4.6" data-path="sec56.html"><a href="sec56.html"><i class="fa fa-check"></i><b>4.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="Chap5.html"><a href="Chap5.html"><i class="fa fa-check"></i><b>5</b> Graphical user interface</a>
<ul>
<li class="chapter" data-level="5.1" data-path="secGUI1.html"><a href="secGUI1.html"><i class="fa fa-check"></i><b>5.1</b> Introduction</a></li>
<li class="chapter" data-level="5.2" data-path="secGUI2.html"><a href="secGUI2.html"><i class="fa fa-check"></i><b>5.2</b> Univariate models</a></li>
<li class="chapter" data-level="5.3" data-path="secGUI3.html"><a href="secGUI3.html"><i class="fa fa-check"></i><b>5.3</b> Multivariate models</a></li>
<li class="chapter" data-level="5.4" data-path="secGUI4.html"><a href="secGUI4.html"><i class="fa fa-check"></i><b>5.4</b> Time series models</a></li>
<li class="chapter" data-level="5.5" data-path="secGUI5.html"><a href="secGUI5.html"><i class="fa fa-check"></i><b>5.5</b> Longitudinal/panel models</a></li>
<li class="chapter" data-level="5.6" data-path="secGUI6.html"><a href="secGUI6.html"><i class="fa fa-check"></i><b>5.6</b> Bayesian model averaging</a></li>
<li class="chapter" data-level="5.7" data-path="secGUI7.html"><a href="secGUI7.html"><i class="fa fa-check"></i><b>5.7</b> Help</a></li>
<li class="chapter" data-level="5.8" data-path="secGUI8.html"><a href="secGUI8.html"><i class="fa fa-check"></i><b>5.8</b> Warning</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="Chap6.html"><a href="Chap6.html"><i class="fa fa-check"></i><b>6</b> Univariate models</a>
<ul>
<li class="chapter" data-level="6.1" data-path="sec61.html"><a href="sec61.html"><i class="fa fa-check"></i><b>6.1</b> The Gaussian linear model</a></li>
<li class="chapter" data-level="6.2" data-path="sec62.html"><a href="sec62.html"><i class="fa fa-check"></i><b>6.2</b> The logit model</a></li>
<li class="chapter" data-level="6.3" data-path="sec63.html"><a href="sec63.html"><i class="fa fa-check"></i><b>6.3</b> The probit model</a></li>
<li class="chapter" data-level="6.4" data-path="sec64.html"><a href="sec64.html"><i class="fa fa-check"></i><b>6.4</b> The multinomial probit model</a></li>
<li class="chapter" data-level="6.5" data-path="sec65.html"><a href="sec65.html"><i class="fa fa-check"></i><b>6.5</b> The multinomial logit model</a></li>
<li class="chapter" data-level="6.6" data-path="sec66.html"><a href="sec66.html"><i class="fa fa-check"></i><b>6.6</b> Ordered probit model</a></li>
<li class="chapter" data-level="6.7" data-path="negative-binomial-model.html"><a href="negative-binomial-model.html"><i class="fa fa-check"></i><b>6.7</b> Negative binomial model</a></li>
<li class="chapter" data-level="6.8" data-path="sec68.html"><a href="sec68.html"><i class="fa fa-check"></i><b>6.8</b> Tobit model</a></li>
<li class="chapter" data-level="6.9" data-path="sec69.html"><a href="sec69.html"><i class="fa fa-check"></i><b>6.9</b> Quantile regression</a></li>
<li class="chapter" data-level="6.10" data-path="sec610.html"><a href="sec610.html"><i class="fa fa-check"></i><b>6.10</b> Bayesian bootstrap regression</a></li>
<li class="chapter" data-level="6.11" data-path="sec611.html"><a href="sec611.html"><i class="fa fa-check"></i><b>6.11</b> Summary</a></li>
<li class="chapter" data-level="6.12" data-path="sec612.html"><a href="sec612.html"><i class="fa fa-check"></i><b>6.12</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="Chap7.html"><a href="Chap7.html"><i class="fa fa-check"></i><b>7</b> Multivariate models</a>
<ul>
<li class="chapter" data-level="7.1" data-path="sec71.html"><a href="sec71.html"><i class="fa fa-check"></i><b>7.1</b> Multivariate regression</a></li>
<li class="chapter" data-level="7.2" data-path="sec72.html"><a href="sec72.html"><i class="fa fa-check"></i><b>7.2</b> Seemingly Unrelated Regression</a></li>
<li class="chapter" data-level="7.3" data-path="sec73.html"><a href="sec73.html"><i class="fa fa-check"></i><b>7.3</b> Instrumental variable</a></li>
<li class="chapter" data-level="7.4" data-path="sec74.html"><a href="sec74.html"><i class="fa fa-check"></i><b>7.4</b> Multivariate probit model</a></li>
<li class="chapter" data-level="7.5" data-path="sec75.html"><a href="sec75.html"><i class="fa fa-check"></i><b>7.5</b> Summary</a></li>
<li class="chapter" data-level="7.6" data-path="sec76.html"><a href="sec76.html"><i class="fa fa-check"></i><b>7.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="Chap8.html"><a href="Chap8.html"><i class="fa fa-check"></i><b>8</b> Time series models</a>
<ul>
<li class="chapter" data-level="8.1" data-path="sec81.html"><a href="sec81.html"><i class="fa fa-check"></i><b>8.1</b> State-space representation</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="sec81.html"><a href="sec81.html#gaussian-linear-state-space-models"><i class="fa fa-check"></i><b>8.1.1</b> Gaussian linear state-space models</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="sec82.html"><a href="sec82.html"><i class="fa fa-check"></i><b>8.2</b> ARMA processes</a></li>
<li class="chapter" data-level="8.3" data-path="sec83.html"><a href="sec83.html"><i class="fa fa-check"></i><b>8.3</b> Stochastic volatility models</a></li>
<li class="chapter" data-level="8.4" data-path="sec84.html"><a href="sec84.html"><i class="fa fa-check"></i><b>8.4</b> Vector Autoregressive models</a></li>
<li class="chapter" data-level="8.5" data-path="sec85.html"><a href="sec85.html"><i class="fa fa-check"></i><b>8.5</b> Summary</a></li>
<li class="chapter" data-level="8.6" data-path="sec86.html"><a href="sec86.html"><i class="fa fa-check"></i><b>8.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="Chap9.html"><a href="Chap9.html"><i class="fa fa-check"></i><b>9</b> Longitudinal/Panel data models</a>
<ul>
<li class="chapter" data-level="9.1" data-path="sec91.html"><a href="sec91.html"><i class="fa fa-check"></i><b>9.1</b> Normal model</a></li>
<li class="chapter" data-level="9.2" data-path="sec92.html"><a href="sec92.html"><i class="fa fa-check"></i><b>9.2</b> Logit model</a></li>
<li class="chapter" data-level="9.3" data-path="sec93.html"><a href="sec93.html"><i class="fa fa-check"></i><b>9.3</b> Poisson model</a></li>
<li class="chapter" data-level="9.4" data-path="sec94.html"><a href="sec94.html"><i class="fa fa-check"></i><b>9.4</b> Summary</a></li>
<li class="chapter" data-level="9.5" data-path="sec95.html"><a href="sec95.html"><i class="fa fa-check"></i><b>9.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="Chap10.html"><a href="Chap10.html"><i class="fa fa-check"></i><b>10</b> Bayesian model averaging</a>
<ul>
<li class="chapter" data-level="10.1" data-path="sec10_1.html"><a href="sec10_1.html"><i class="fa fa-check"></i><b>10.1</b> Foundation</a></li>
<li class="chapter" data-level="10.2" data-path="sec102.html"><a href="sec102.html"><i class="fa fa-check"></i><b>10.2</b> The Gaussian linear model</a></li>
<li class="chapter" data-level="10.3" data-path="sec103.html"><a href="sec103.html"><i class="fa fa-check"></i><b>10.3</b> Generalized linear models</a></li>
<li class="chapter" data-level="10.4" data-path="sec10_4.html"><a href="sec10_4.html"><i class="fa fa-check"></i><b>10.4</b> Calculating the marginal likelihood</a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="sec10_4.html"><a href="sec10_4.html#sec10_4_1"><i class="fa fa-check"></i><b>10.4.1</b> Savage-Dickey density ratio</a></li>
<li class="chapter" data-level="10.4.2" data-path="sec10_4.html"><a href="sec10_4.html#sec10_4_2"><i class="fa fa-check"></i><b>10.4.2</b> Chib’s methods</a></li>
<li class="chapter" data-level="10.4.3" data-path="sec10_4.html"><a href="sec10_4.html#sec10_4_3"><i class="fa fa-check"></i><b>10.4.3</b> Gelfand-Dey method</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="sec10_5.html"><a href="sec10_5.html"><i class="fa fa-check"></i><b>10.5</b> Summary</a></li>
<li class="chapter" data-level="10.6" data-path="sec10_6.html"><a href="sec10_6.html"><i class="fa fa-check"></i><b>10.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="Chap11.html"><a href="Chap11.html"><i class="fa fa-check"></i><b>11</b> Semi-parametric and non-parametric models</a>
<ul>
<li class="chapter" data-level="11.1" data-path="sec11_1.html"><a href="sec11_1.html"><i class="fa fa-check"></i><b>11.1</b> Mixture models</a>
<ul>
<li class="chapter" data-level="11.1.1" data-path="sec11_1.html"><a href="sec11_1.html#sec11_11"><i class="fa fa-check"></i><b>11.1.1</b> Finite Gaussian mixtures</a></li>
<li class="chapter" data-level="11.1.2" data-path="sec11_1.html"><a href="sec11_1.html#sec11_12"><i class="fa fa-check"></i><b>11.1.2</b> Direchlet processes</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="sec11_2.html"><a href="sec11_2.html"><i class="fa fa-check"></i><b>11.2</b> Splines</a></li>
<li class="chapter" data-level="11.3" data-path="sec11_3.html"><a href="sec11_3.html"><i class="fa fa-check"></i><b>11.3</b> Summary</a></li>
<li class="chapter" data-level="11.4" data-path="sec11_4.html"><a href="sec11_4.html"><i class="fa fa-check"></i><b>11.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="Chap12.html"><a href="Chap12.html"><i class="fa fa-check"></i><b>12</b> Bayesian machine learning</a>
<ul>
<li class="chapter" data-level="12.1" data-path="sec12_1.html"><a href="sec12_1.html"><i class="fa fa-check"></i><b>12.1</b> Cross-validation and Bayes factors</a></li>
<li class="chapter" data-level="12.2" data-path="sec12_2.html"><a href="sec12_2.html"><i class="fa fa-check"></i><b>12.2</b> Regularization</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="sec12_2.html"><a href="sec12_2.html#sec12_21"><i class="fa fa-check"></i><b>12.2.1</b> Bayesian LASSO</a></li>
<li class="chapter" data-level="12.2.2" data-path="sec12_2.html"><a href="sec12_2.html#sec12_22"><i class="fa fa-check"></i><b>12.2.2</b> Stochastic search variable selection</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="sec12_3.html"><a href="sec12_3.html"><i class="fa fa-check"></i><b>12.3</b> Bayesian additive regression trees</a></li>
<li class="chapter" data-level="12.4" data-path="sec12_4.html"><a href="sec12_4.html"><i class="fa fa-check"></i><b>12.4</b> Gaussian processes</a></li>
<li class="chapter" data-level="12.5" data-path="sec12_5.html"><a href="sec12_5.html"><i class="fa fa-check"></i><b>12.5</b> Tall data problems</a>
<ul>
<li class="chapter" data-level="12.5.1" data-path="sec12_5.html"><a href="sec12_5.html#sec12_51"><i class="fa fa-check"></i><b>12.5.1</b> Divide-and-conquer methods</a></li>
<li class="chapter" data-level="12.5.2" data-path="sec12_5.html"><a href="sec12_5.html#sec12_52"><i class="fa fa-check"></i><b>12.5.2</b> Subsampling-based algorithms</a></li>
</ul></li>
<li class="chapter" data-level="12.6" data-path="id_13_6.html"><a href="id_13_6.html"><i class="fa fa-check"></i><b>12.6</b> Summary</a></li>
<li class="chapter" data-level="12.7" data-path="id_13_7.html"><a href="id_13_7.html"><i class="fa fa-check"></i><b>12.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="Chap13.html"><a href="Chap13.html"><i class="fa fa-check"></i><b>13</b> Causal inference</a>
<ul>
<li class="chapter" data-level="13.1" data-path="sec13_1.html"><a href="sec13_1.html"><i class="fa fa-check"></i><b>13.1</b> Identification setting</a></li>
<li class="chapter" data-level="13.2" data-path="sec13_2.html"><a href="sec13_2.html"><i class="fa fa-check"></i><b>13.2</b> Randomized controlled trial (RCT)</a></li>
<li class="chapter" data-level="13.3" data-path="sec13_3.html"><a href="sec13_3.html"><i class="fa fa-check"></i><b>13.3</b> Conditional independence assumption (CIA)</a></li>
<li class="chapter" data-level="13.4" data-path="sec13_4.html"><a href="sec13_4.html"><i class="fa fa-check"></i><b>13.4</b> Instrumental variables (IV)</a></li>
<li class="chapter" data-level="13.5" data-path="sec13_5.html"><a href="sec13_5.html"><i class="fa fa-check"></i><b>13.5</b> Difference-in-differences design (DiD)</a>
<ul>
<li class="chapter" data-level="13.5.1" data-path="sec13_5.html"><a href="sec13_5.html#sec13_51"><i class="fa fa-check"></i><b>13.5.1</b> Classic DiD: two-group and two-period (<span class="math inline">\(2\times2\)</span>) setup</a></li>
<li class="chapter" data-level="13.5.2" data-path="sec13_5.html"><a href="sec13_5.html#sec13_52"><i class="fa fa-check"></i><b>13.5.2</b> Staggered (SDiD): G-group and T-period (<span class="math inline">\(G\times T\)</span>) setup</a></li>
</ul></li>
<li class="chapter" data-level="13.6" data-path="sec13_6.html"><a href="sec13_6.html"><i class="fa fa-check"></i><b>13.6</b> Regression discontinuity design (RD)</a>
<ul>
<li class="chapter" data-level="13.6.1" data-path="sec13_6.html"><a href="sec13_6.html#sec13_61"><i class="fa fa-check"></i><b>13.6.1</b> Sharp regression discontinuity design (SRD)</a></li>
<li class="chapter" data-level="13.6.2" data-path="sec13_6.html"><a href="sec13_6.html#sec13_62"><i class="fa fa-check"></i><b>13.6.2</b> Fuzzy regression discontinuity design (FRD)</a></li>
</ul></li>
<li class="chapter" data-level="13.7" data-path="sec13_7.html"><a href="sec13_7.html"><i class="fa fa-check"></i><b>13.7</b> Sample selection</a></li>
<li class="chapter" data-level="13.8" data-path="sec13_8.html"><a href="sec13_8.html"><i class="fa fa-check"></i><b>13.8</b> Bayesian exponentially tilted empirical likelihood</a></li>
<li class="chapter" data-level="13.9" data-path="sec13_9.html"><a href="sec13_9.html"><i class="fa fa-check"></i><b>13.9</b> General Bayes posteriors</a></li>
<li class="chapter" data-level="13.10" data-path="sec13_10.html"><a href="sec13_10.html"><i class="fa fa-check"></i><b>13.10</b> Doubly robust Bayesian inferential framework (DRB)</a></li>
<li class="chapter" data-level="13.11" data-path="sec13_11.html"><a href="sec13_11.html"><i class="fa fa-check"></i><b>13.11</b> Summary</a></li>
<li class="chapter" data-level="13.12" data-path="sec13_12.html"><a href="sec13_12.html"><i class="fa fa-check"></i><b>13.12</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="Chap14.html"><a href="Chap14.html"><i class="fa fa-check"></i><b>14</b> Approximate Bayesian methods</a>
<ul>
<li class="chapter" data-level="14.1" data-path="sec14_1.html"><a href="sec14_1.html"><i class="fa fa-check"></i><b>14.1</b> Simulation-based approaches</a>
<ul>
<li class="chapter" data-level="14.1.1" data-path="sec14_1.html"><a href="sec14_1.html#sec14_11"><i class="fa fa-check"></i><b>14.1.1</b> Approximate Bayesian computation</a></li>
<li class="chapter" data-level="14.1.2" data-path="sec14_1.html"><a href="sec14_1.html#sec14_12"><i class="fa fa-check"></i><b>14.1.2</b> Bayesian synthetic likelihood</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="sec14_2.html"><a href="sec14_2.html"><i class="fa fa-check"></i><b>14.2</b> Optimization approaches</a>
<ul>
<li class="chapter" data-level="14.2.1" data-path="sec14_2.html"><a href="sec14_2.html#sec14_21"><i class="fa fa-check"></i><b>14.2.1</b> Integrated nested Laplace approximations</a></li>
<li class="chapter" data-level="14.2.2" data-path="sec14_2.html"><a href="sec14_2.html#sec14_22"><i class="fa fa-check"></i><b>14.2.2</b> Variational Bayes</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="summary-1.html"><a href="summary-1.html"><i class="fa fa-check"></i><b>14.3</b> Summary</a></li>
<li class="chapter" data-level="14.4" data-path="sec14_4.html"><a href="sec14_4.html"><i class="fa fa-check"></i><b>14.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i>Appendix</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to Bayesian Econometrics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="sec11" class="section level2 hasAnchor" number="1.1">
<h2><span class="header-section-number">1.1</span> The Bayes’ rule<a href="sec11.html#sec11" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>As expected, the starting point for performing Bayesian inference is Bayes’ rule, which provides the solution to the inverse problem of determining causes from observed effects. This rule combines prior beliefs with objective probabilities based on repeatable experiments, allowing us to move from observations to probable causes.<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a></p>
<p>Formally, the conditional probability of <span class="math inline">\(A_i\)</span> given <span class="math inline">\(B\)</span> is equal to the conditional probability of <span class="math inline">\(B\)</span> given <span class="math inline">\(A_i\)</span>, multiplied by the marginal probability of <span class="math inline">\(A_i\)</span>, divided by the marginal probability of <span class="math inline">\(B\)</span>:</p>
<p><span class="math display" id="eq:111">\[\begin{align}
  P(A_i|B)&amp;=\frac{P(A_i,B)}{P(B)}\\
        &amp;=\frac{P(B|A_i) \times P(A_i)}{P(B)},
  \tag{1.1}
\end{align}\]</span>
where equation <a href="sec11.html#eq:111">(1.1)</a> is Bayes’ rule.</p>
<p>By the law of total probability, <span class="math inline">\(P(B) = \sum_i P(B \mid A_i) P(A_i) \neq 0\)</span>, and <span class="math inline">\(\{ A_i, i = 1, 2, \dots \}\)</span> is a finite or countably infinite partition of the sample space.</p>
<p>In the Bayesian framework, <span class="math inline">\(B\)</span> represents sample information that updates a probabilistic statement about an unknown object <span class="math inline">\(A_i\)</span> according to probability rules. This is done using Bayes’ rule, which incorporates prior “beliefs” about <span class="math inline">\(A_i\)</span>, i.e., <span class="math inline">\(P(A_i)\)</span>, sample information relating <span class="math inline">\(B\)</span> to the particular state of nature <span class="math inline">\(A_i\)</span> through a probabilistic statement, <span class="math inline">\(P(B \mid A_i)\)</span>, and the probability of observing that specific sample information, <span class="math inline">\(P(B)\)</span>.</p>
<p>Let’s consider a simple example, <em>the base rate fallacy</em>:</p>
<p>Assume that the sample information comes from a positive result from a test whose true positive rate (sensitivity) is 98%, i.e., <span class="math inline">\(P(+ \mid \text{disease}) = 0.98\)</span>. In addition, the false positive rate is 2%, i.e., <span class="math inline">\(P(+ \mid \lnot\text{disease}) = 0.02\)</span>. On the other hand, the prior probability of being infected with the disease is given by the base incidence rate, <span class="math inline">\(P(\text{disease}) = 0.002\)</span>. The question is: <em>What is the probability of actually being infected, given a positive test result?</em></p>
<p>This is an example of <em>the base rate fallacy</em>, where a positive test result for a disease with a very low base incidence rate still gives a low probability of actually having the disease.</p>
<p>The key to answering this question lies in understanding the difference between the probability of having the disease given a positive test result, <span class="math inline">\(P(\text{disease} \mid +)\)</span>, and the probability of a positive result given the disease, <span class="math inline">\(P(+ \mid \text{disease})\)</span>. The former is the crucial result, and Bayes’ rule helps us to compute it. Using Bayes’ rule (equation <a href="sec11.html#eq:111">(1.1)</a>):</p>
<p><span class="math display">\[
P(\text{disease} \mid +) = \frac{P(+ \mid \text{disease}) \times P(\text{disease})}{P(+)} = \frac{0.98 \times 0.002}{0.98 \times 0.002 + 0.02 \times (1-0.002)} = 0.09
\]</span></p>
<p>where <span class="math inline">\(P(+) = P(+ \mid \text{disease}) \times P(\text{disease}) + P(+ \mid \lnot \text{disease}) \times P(\lnot \text{disease})\)</span>.<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a></p>
<p>The following code shows how to perform this exercise in <strong>R</strong>.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="sec11.html#cb1-1" tabindex="-1"></a><span class="co"># Define known probabilities</span></span>
<span id="cb1-2"><a href="sec11.html#cb1-2" tabindex="-1"></a>prob_disease <span class="ot">&lt;-</span> <span class="fl">0.002</span>        <span class="co"># P(Disease)</span></span>
<span id="cb1-3"><a href="sec11.html#cb1-3" tabindex="-1"></a>sensitivity <span class="ot">&lt;-</span> <span class="fl">0.98</span>          <span class="co"># P(Positive test | Disease) - True Positive Rate</span></span>
<span id="cb1-4"><a href="sec11.html#cb1-4" tabindex="-1"></a>false_positive_rate <span class="ot">&lt;-</span> <span class="fl">0.02</span>  <span class="co"># P(Positive test | No disease) - False Positive Rate</span></span>
<span id="cb1-5"><a href="sec11.html#cb1-5" tabindex="-1"></a></span>
<span id="cb1-6"><a href="sec11.html#cb1-6" tabindex="-1"></a><span class="co"># Compute posterior using Bayes&#39; theorem</span></span>
<span id="cb1-7"><a href="sec11.html#cb1-7" tabindex="-1"></a>posterior_prob <span class="ot">&lt;-</span> (prob_disease <span class="sc">*</span> sensitivity) <span class="sc">/</span></span>
<span id="cb1-8"><a href="sec11.html#cb1-8" tabindex="-1"></a>  (prob_disease <span class="sc">*</span> sensitivity <span class="sc">+</span> (<span class="dv">1</span> <span class="sc">-</span> prob_disease) <span class="sc">*</span> false_positive_rate)</span>
<span id="cb1-9"><a href="sec11.html#cb1-9" tabindex="-1"></a></span>
<span id="cb1-10"><a href="sec11.html#cb1-10" tabindex="-1"></a><span class="co"># Print the result</span></span>
<span id="cb1-11"><a href="sec11.html#cb1-11" tabindex="-1"></a><span class="fu">message</span>(<span class="fu">sprintf</span>(<span class="st">&quot;Probability of disease given a positive test is %.2f&quot;</span>, posterior_prob))</span></code></pre></div>
<pre><code>## Probability of disease given a positive test is 0.09</code></pre>
<p>We observe that despite having a positive result, the probability of actually having the disease remains low. This is due to the base rate being so small.</p>
<p>Another interesting example—one that lies at the heart of the origin of Bayes’ theorem <span class="citation">(<a href="#ref-bayes1763lii">Bayes 1763</a>)</span>—concerns the existence of God <span class="citation">(<a href="#ref-stigler2018richard">Stigler 2018</a>)</span>. In Section X of David Hume’s <em>An Inquiry concerning Human Understanding</em> (1748), titled <em>Of Miracles</em>, Hume argues that when someone claims to have witnessed a miracle, the claim provides weak evidence that the event actually occurred, since it contradicts our everyday experience. In response, Richard Price—who edited and published <em>An Essay Towards Solving a Problem in the Doctrine of Chances</em> in 1763 (following Bayes’ death in 1761)—criticizes Hume’s argument by distinguishing between <em>logical</em> and <em>physical</em> impossibility. He illustrates this with the example of a die with a million sides: while rolling a specific number might seem impossible, it is merely <em>improbable</em>, whereas rolling a number not present on the die is <em>physically impossible</em>. The former may occur with enough trials; the latter never will.</p>
<blockquote>
<p><strong>Note on the following example</strong>:<br />
The next example is adapted from a modern blog post that illustrates the base rate fallacy using a resurrection scenario. While it is not taken from the original writings of Hume or Price, it reflects themes central to their philosophical debate on probability and miracles. It is included here to demonstrate how Bayes’ rule behaves in cases involving extremely low prior probabilities. References to figures such as Jesus and Elvis are used purely for illustrative and pedagogical purposes. The goal is to explore the statistical reasoning—not to make any theological claims. Readers are encouraged to focus on the mathematical and conceptual content of the example.</p>
</blockquote>
<p>To illustrate the statistical implications of this discussion, let us consider the following scenario.<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a></p>
<p>The scenario involves two reported cases of resurrection: Jesus Christ and Elvis Presley. The base rate is therefore two out of the total number of people who have ever lived—estimated at approximately 117 billion,<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a>—that is,<br />
<span class="math inline">\(P(\text{Res}) = \frac{2}{117 \times 10^9}\)</span>.</p>
<p>Suppose now that the sample information comes from a highly reliable witness, with a true positive rate of 0.9999999. Unlike the original blog post, we assume a more conservative false positive rate of 50%.</p>
<p>We ask: <em>What is the probability that a resurrection actually occurred, given that a witness claims it did?</em></p>
<p>Using Bayes’ rule, and letting <em>Res</em> denote the event of resurrection, and <em>Witness</em> the event of a witness declaring a resurrection:</p>
<p><span class="math display">\[\begin{align*}
    P(\text{Res} \mid \text{Witness}) &amp;= \frac{P(\text{Witness} \mid \text{Res}) \times P(\text{Res})}{P(\text{Witness})} \\
    &amp;= \frac{0.9999999 \times \frac{2}{117 \times 10^9}}{0.9999999 \times \frac{2}{117 \times 10^9} + 0.5 \times \left(1 - \frac{2}{117 \times 10^9} \right)} \\
    &amp;\approx 3.42 \times 10^{-11}
\end{align*}\]</span></p>
<p>Here, the denominator is the marginal probability of a witness reporting a resurrection:</p>
<p><span class="math display">\[
P(\text{Witness}) = P(\text{Witness} \mid \text{Res}) \times P(\text{Res}) + P(\text{Witness} \mid \lnot\text{Res}) \times (1 - P(\text{Res}))
\]</span></p>
<p>Thus, the probability that a resurrection actually occurred—even when reported by an extremely reliable witness—is approximately <span class="math inline">\(3.42 \times 10^{-11}\)</span>. This value is exceedingly small, but importantly, it is not zero. A value of zero would imply <em>impossibility</em>, whereas this result reflects <em>extremely low probability</em>.</p>
<p>The following code shows how to perform this exercise in <strong>R</strong>.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="sec11.html#cb3-1" tabindex="-1"></a><span class="co"># Define known probabilities</span></span>
<span id="cb3-2"><a href="sec11.html#cb3-2" tabindex="-1"></a>prior_resurrection <span class="ot">&lt;-</span> <span class="dv">2</span> <span class="sc">/</span> (<span class="dv">117</span> <span class="sc">*</span> <span class="fl">1e9</span>)  <span class="co"># P(Resurrection)</span></span>
<span id="cb3-3"><a href="sec11.html#cb3-3" tabindex="-1"></a>true_positive_rate <span class="ot">&lt;-</span> <span class="fl">0.9999999</span>         <span class="co"># P(Witness | Resurrection)</span></span>
<span id="cb3-4"><a href="sec11.html#cb3-4" tabindex="-1"></a></span>
<span id="cb3-5"><a href="sec11.html#cb3-5" tabindex="-1"></a><span class="co"># Assume a 50% false positive rate as implied in earlier context</span></span>
<span id="cb3-6"><a href="sec11.html#cb3-6" tabindex="-1"></a>false_positive_rate <span class="ot">&lt;-</span> <span class="fl">0.5</span>              <span class="co"># P(Witness | No Resurrection)</span></span>
<span id="cb3-7"><a href="sec11.html#cb3-7" tabindex="-1"></a></span>
<span id="cb3-8"><a href="sec11.html#cb3-8" tabindex="-1"></a><span class="co"># Compute posterior probability using Bayes&#39; rule</span></span>
<span id="cb3-9"><a href="sec11.html#cb3-9" tabindex="-1"></a>posterior_resurrection <span class="ot">&lt;-</span> (prior_resurrection <span class="sc">*</span> true_positive_rate) <span class="sc">/</span></span>
<span id="cb3-10"><a href="sec11.html#cb3-10" tabindex="-1"></a>  (prior_resurrection <span class="sc">*</span> true_positive_rate <span class="sc">+</span></span>
<span id="cb3-11"><a href="sec11.html#cb3-11" tabindex="-1"></a>   (<span class="dv">1</span> <span class="sc">-</span> prior_resurrection) <span class="sc">*</span> false_positive_rate)</span>
<span id="cb3-12"><a href="sec11.html#cb3-12" tabindex="-1"></a></span>
<span id="cb3-13"><a href="sec11.html#cb3-13" tabindex="-1"></a><span class="co"># Print result</span></span>
<span id="cb3-14"><a href="sec11.html#cb3-14" tabindex="-1"></a><span class="fu">message</span>(<span class="fu">sprintf</span>(<span class="st">&quot;Probability of resurrection given a witness is %.2e&quot;</span>, posterior_resurrection))</span></code></pre></div>
<pre><code>## Probability of resurrection given a witness is 3.42e-11</code></pre>
<p>Observe that we can condition on multiple events in Bayes’ rule. Let’s consider two conditioning events, <span class="math inline">\(B\)</span> and <span class="math inline">\(C\)</span>. Then, equation <a href="sec11.html#eq:111">(1.1)</a> becomes</p>
<p><span class="math display" id="eq:112">\[\begin{align}
    P(A_i\mid B,C)&amp;=\frac{P(A_i,B,C)}{P(B,C)}\nonumber\\
    &amp;=\frac{P(B\mid A_i,C) \times P(A_i\mid C) \times P(C)}{P(B\mid C)P(C)}.
    \tag{1.2}
\end{align}\]</span></p>
<p>Let’s use this rule in one of the most intriguing statistical puzzles, <em>the Monty Hall problem</em>, to illustrate how to use equation <a href="sec11.html#eq:112">(1.2)</a> <span class="citation">(<a href="#ref-selvin1975problem">Selvin 1975</a>; <a href="#ref-morgan1991let">Morgan et al. 1991</a>)</span>. This was the situation faced by a contestant in the American television game show <em>Let’s Make a Deal</em>. In this game, the contestant was asked to choose a door, behind one of which there is a car, and behind the others, goats.</p>
<p>Let’s say the contestant picks door No. 1, and the host (Monty Hall), who knows what is behind each door, opens door No. 3, revealing a goat. Then, the host asks the tricky question: <em>Do you want to pick door No. 2?</em></p>
<p><img src="figures/MHproblemNew.png" width="400" style="display: block; margin: auto;" /></p>
<p>Let’s define the following events:</p>
<ul>
<li><span class="math inline">\(P_i\)</span>: the event <em>contestant picks door No. <span class="math inline">\(i\)</span></em>, which stays closed,</li>
<li><span class="math inline">\(H_i\)</span>: the event <em>host picks door No. <span class="math inline">\(i\)</span></em>, which is open and contains a goat,</li>
<li><span class="math inline">\(C_i\)</span>: the event <em>car is behind door No. <span class="math inline">\(i\)</span></em>.</li>
</ul>
<p>In this particular setting, the contestant is interested in the probability of the event <span class="math inline">\(P(C_2 \mid H_3, P_1)\)</span>. A naive answer would be that it is irrelevant, as initially, <span class="math inline">\(P(C_i) = \frac{1}{3}, \ i = 1, 2, 3\)</span>, and now <span class="math inline">\(P(C_i \mid H_3) = \frac{1}{2}, \ i = 1, 2\)</span>, since the host opened door No. 3. So, why bother changing the initial guess if the odds are the same (1:1)?</p>
<p>The important point here is that the host knows what is behind each door and always picks a door where there is a goat, given the contestant’s choice. In this particular setting:</p>
<p><span class="math display">\[
P(H_3 \mid C_3, P_1) = 0, \quad P(H_3 \mid C_2, P_1) = 1, \quad P(H_3 \mid C_1, P_1) = \frac{1}{2}.
\]</span></p>
<p>Then, using equation <a href="sec11.html#eq:112">(1.2)</a>, we can calculate the posterior probability.</p>
<p><span class="math display">\[\begin{align*}
    P(C_2\mid H_3,P_1)&amp;= \frac{P(C_2,H_3,P_1)}{P(H_3,P_1)}\\
    &amp;= \frac{P(H_3\mid C_2,P_1)P(C_2\mid P_1)P(P_1)}{P(H_3\mid P_1)\times P(P_1)}\\
    &amp;= \frac{P(H_3\mid C_2,P_1)P(C_2)}{P(H_3\mid P_1)}\\
    &amp;=\frac{1\times 1/3}{1/2},
\end{align*}\]</span></p>
<p>Where the third equation uses the fact that <span class="math inline">\(C_i\)</span> and <span class="math inline">\(P_i\)</span> are independent events, and <span class="math inline">\(P(H_3 \mid P_1) = \frac{1}{2}\)</span> because this depends only on <span class="math inline">\(P_1\)</span> (not on <span class="math inline">\(C_2\)</span>).</p>
<p>Therefore, changing the initial decision increases the probability of getting the car from <span class="math inline">\(\frac{1}{3}\)</span> to <span class="math inline">\(\frac{2}{3}\)</span>! Thus, it is always a good idea to change the door.</p>
<p>Let’s see a simulation exercise in <strong>R</strong> to check this answer:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="sec11.html#cb5-1" tabindex="-1"></a><span class="co"># Set simulation seed for reproducibility</span></span>
<span id="cb5-2"><a href="sec11.html#cb5-2" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">10101</span>)</span>
<span id="cb5-3"><a href="sec11.html#cb5-3" tabindex="-1"></a></span>
<span id="cb5-4"><a href="sec11.html#cb5-4" tabindex="-1"></a><span class="co"># Number of simulations</span></span>
<span id="cb5-5"><a href="sec11.html#cb5-5" tabindex="-1"></a>num_simulations <span class="ot">&lt;-</span> <span class="dv">100000</span></span>
<span id="cb5-6"><a href="sec11.html#cb5-6" tabindex="-1"></a></span>
<span id="cb5-7"><a href="sec11.html#cb5-7" tabindex="-1"></a><span class="co"># Monty Hall game function</span></span>
<span id="cb5-8"><a href="sec11.html#cb5-8" tabindex="-1"></a>simulate_game <span class="ot">&lt;-</span> <span class="cf">function</span>(<span class="at">switch_door =</span> <span class="cn">FALSE</span>) {</span>
<span id="cb5-9"><a href="sec11.html#cb5-9" tabindex="-1"></a>  doors <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">3</span></span>
<span id="cb5-10"><a href="sec11.html#cb5-10" tabindex="-1"></a>  car_location <span class="ot">&lt;-</span> <span class="fu">sample</span>(doors, <span class="dv">1</span>)</span>
<span id="cb5-11"><a href="sec11.html#cb5-11" tabindex="-1"></a>  first_guess <span class="ot">&lt;-</span> <span class="fu">sample</span>(doors, <span class="dv">1</span>)</span>
<span id="cb5-12"><a href="sec11.html#cb5-12" tabindex="-1"></a></span>
<span id="cb5-13"><a href="sec11.html#cb5-13" tabindex="-1"></a>  <span class="co"># Host reveals a goat</span></span>
<span id="cb5-14"><a href="sec11.html#cb5-14" tabindex="-1"></a>  <span class="cf">if</span> (car_location <span class="sc">!=</span> first_guess) {</span>
<span id="cb5-15"><a href="sec11.html#cb5-15" tabindex="-1"></a>    host_opens <span class="ot">&lt;-</span> doors[<span class="sc">!</span>doors <span class="sc">%in%</span> <span class="fu">c</span>(car_location, first_guess)]</span>
<span id="cb5-16"><a href="sec11.html#cb5-16" tabindex="-1"></a>  } <span class="cf">else</span> {</span>
<span id="cb5-17"><a href="sec11.html#cb5-17" tabindex="-1"></a>    host_opens <span class="ot">&lt;-</span> <span class="fu">sample</span>(doors[doors <span class="sc">!=</span> first_guess], <span class="dv">1</span>)</span>
<span id="cb5-18"><a href="sec11.html#cb5-18" tabindex="-1"></a>  }</span>
<span id="cb5-19"><a href="sec11.html#cb5-19" tabindex="-1"></a></span>
<span id="cb5-20"><a href="sec11.html#cb5-20" tabindex="-1"></a>  <span class="co"># Determine second guess if player switches</span></span>
<span id="cb5-21"><a href="sec11.html#cb5-21" tabindex="-1"></a>  second_guess <span class="ot">&lt;-</span> doors[<span class="sc">!</span>doors <span class="sc">%in%</span> <span class="fu">c</span>(first_guess, host_opens)]</span>
<span id="cb5-22"><a href="sec11.html#cb5-22" tabindex="-1"></a></span>
<span id="cb5-23"><a href="sec11.html#cb5-23" tabindex="-1"></a>  win_if_no_switch <span class="ot">&lt;-</span> (first_guess <span class="sc">==</span> car_location)</span>
<span id="cb5-24"><a href="sec11.html#cb5-24" tabindex="-1"></a>  win_if_switch <span class="ot">&lt;-</span> (second_guess <span class="sc">==</span> car_location)</span>
<span id="cb5-25"><a href="sec11.html#cb5-25" tabindex="-1"></a></span>
<span id="cb5-26"><a href="sec11.html#cb5-26" tabindex="-1"></a>  <span class="cf">if</span> (switch_door) {</span>
<span id="cb5-27"><a href="sec11.html#cb5-27" tabindex="-1"></a>    <span class="fu">return</span>(win_if_switch)</span>
<span id="cb5-28"><a href="sec11.html#cb5-28" tabindex="-1"></a>  } <span class="cf">else</span> {</span>
<span id="cb5-29"><a href="sec11.html#cb5-29" tabindex="-1"></a>    <span class="fu">return</span>(win_if_no_switch)</span>
<span id="cb5-30"><a href="sec11.html#cb5-30" tabindex="-1"></a>  }</span>
<span id="cb5-31"><a href="sec11.html#cb5-31" tabindex="-1"></a>}</span>
<span id="cb5-32"><a href="sec11.html#cb5-32" tabindex="-1"></a></span>
<span id="cb5-33"><a href="sec11.html#cb5-33" tabindex="-1"></a><span class="co"># Simulate without switching</span></span>
<span id="cb5-34"><a href="sec11.html#cb5-34" tabindex="-1"></a>prob_no_switch <span class="ot">&lt;-</span> <span class="fu">mean</span>(<span class="fu">replicate</span>(num_simulations, <span class="fu">simulate_game</span>(<span class="at">switch_door =</span> <span class="cn">FALSE</span>)))</span>
<span id="cb5-35"><a href="sec11.html#cb5-35" tabindex="-1"></a><span class="fu">message</span>(<span class="fu">sprintf</span>(<span class="st">&quot;Winning probability without switching: %.3f&quot;</span>, prob_no_switch))</span></code></pre></div>
<pre><code>## Winning probability without switching: 0.331</code></pre>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="sec11.html#cb7-1" tabindex="-1"></a><span class="co"># Simulate with switching</span></span>
<span id="cb7-2"><a href="sec11.html#cb7-2" tabindex="-1"></a>prob_with_switch <span class="ot">&lt;-</span> <span class="fu">mean</span>(<span class="fu">replicate</span>(num_simulations, <span class="fu">simulate_game</span>(<span class="at">switch_door =</span> <span class="cn">TRUE</span>)))</span>
<span id="cb7-3"><a href="sec11.html#cb7-3" tabindex="-1"></a><span class="fu">message</span>(<span class="fu">sprintf</span>(<span class="st">&quot;Winning probability with switching: %.3f&quot;</span>, prob_with_switch))</span></code></pre></div>
<pre><code>## Winning probability with switching: 0.667</code></pre>
</div>
<h3>References<a href="references.html#references" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-bayes1763lii" class="csl-entry">
Bayes, Thomas. 1763. <span>“LII. An Essay Towards Solving a Problem in the Doctrine of Chances. By the Late Rev. Mr. Bayes, <span>FRS</span> Communicated by <span>M</span>r. <span>P</span>rice, in a Letter to <span>J</span>ohn <span>C</span>anton, <span>AMFR S</span>.”</span> <em>Philosophical Transactions of the Royal Society of London</em>, no. 53: 370–418.
</div>
<div id="ref-laplace1774memoire" class="csl-entry">
Laplace, Pierre Simon. 1774. <span>“M<span>é</span>moire Sur La Probabilit<span>é</span> de Causes Par Les <span class="nocase">é</span>venements.”</span> <em>M<span>é</span>moire de l’acad<span>é</span>mie Royale Des Sciences</em>.
</div>
<div id="ref-morgan1991let" class="csl-entry">
Morgan, John P, N Rao Chaganty, Ram C Dahiya, and Michael J Doviak. 1991. <span>“Let’s Make a Deal: The Player’s Dilemma.”</span> <em>The American Statistician</em> 45 (4): 284–87.
</div>
<div id="ref-selvin1975problem" class="csl-entry">
Selvin, Steve. 1975. <span>“A Problem in Probability (Letter to the Editor).”</span> <em>The American Statistician</em> 11 (1): 67–71.
</div>
<div id="ref-stigler2018richard" class="csl-entry">
Stigler, Stephen. 2018. <span>“Richard Price, the First Bayesian.”</span> <em>Statistical Science</em> 33 (1): 117–25.
</div>
</div>
<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p>Note that I use the term “Bayes’ rule” rather than “Bayes’ theorem.” It was Laplace <span class="citation">(<a href="#ref-laplace1774memoire">Laplace 1774</a>)</span> who generalized Bayes’ theorem <span class="citation">(<a href="#ref-bayes1763lii">Bayes 1763</a>)</span>, and his generalization is referred to as Bayes’ rule.<a href="sec11.html#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p><span class="math inline">\(\lnot\)</span> is the negation symbol.<a href="sec11.html#fnref2" class="footnote-back">↩︎</a></p></li>
<li id="fn3"><p><a href="https://blog.ephorie.de/base-rate-fallacy-or-why-no-one-is-justified-to-believe-that-jesus-rose">Source</a><a href="sec11.html#fnref3" class="footnote-back">↩︎</a></p></li>
<li id="fn4"><p><a href="https://www.prb.org/articles/how-many-people-have-ever-lived-on-earth/?utm_source=chatgpt.com">Source</a><a href="sec11.html#fnref4" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="Chap1.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="sec12.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": true,
    "facebook": true,
    "twitter": true,
    "linkedin": false,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": false,
    "all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
  },
  "fontsettings": {
    "theme": "white",
    "family": "sans",
    "size": 2
  },
  "edit": {
    "link": "https://github.com/aramir21/IntroductionBayesianEconometricsBook/01-Basics.Rmd",
    "text": "Edit"
  },
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": null,
    "text": null
  },
  "download": null,
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "subsection"
  }
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
