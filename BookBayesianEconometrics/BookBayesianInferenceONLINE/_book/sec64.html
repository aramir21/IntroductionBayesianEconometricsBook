<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>6.4 The multinomial probit model | Introduction to Bayesian Data Modeling</title>
  <meta name="description" content="The subject of this textbook is Bayesian data modeling, with the primary aim of providing an introduction to its theoretical foundations and facilitating the application of Bayesian inference using a GUI." />
  <meta name="generator" content="bookdown 0.40 and GitBook 2.6.7" />

  <meta property="og:title" content="6.4 The multinomial probit model | Introduction to Bayesian Data Modeling" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="The subject of this textbook is Bayesian data modeling, with the primary aim of providing an introduction to its theoretical foundations and facilitating the application of Bayesian inference using a GUI." />
  <meta name="github-repo" content="https://github.com/aramir21/IntroductionBayesianEconometricsBook" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="6.4 The multinomial probit model | Introduction to Bayesian Data Modeling" />
  
  <meta name="twitter:description" content="The subject of this textbook is Bayesian data modeling, with the primary aim of providing an introduction to its theoretical foundations and facilitating the application of Bayesian inference using a GUI." />
  

<meta name="author" content="Andrés Ramírez-Hassan" />


<meta name="date" content="2025-02-18" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="sec63.html"/>
<link rel="next" href="sec65.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Introduction to Bayesian Econometrics: A GUIded tour using R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="to-instructors-and-students.html"><a href="to-instructors-and-students.html"><i class="fa fa-check"></i>To instructors and students</a></li>
<li class="chapter" data-level="" data-path="acknowledgments.html"><a href="acknowledgments.html"><i class="fa fa-check"></i>Acknowledgments</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="Chap1.html"><a href="Chap1.html"><i class="fa fa-check"></i><b>1</b> Basic formal concepts</a>
<ul>
<li class="chapter" data-level="1.1" data-path="sec11.html"><a href="sec11.html"><i class="fa fa-check"></i><b>1.1</b> The Bayes’ rule</a></li>
<li class="chapter" data-level="1.2" data-path="sec12.html"><a href="sec12.html"><i class="fa fa-check"></i><b>1.2</b> Bayesian framework: A brief summary of theory</a></li>
<li class="chapter" data-level="1.3" data-path="sec14.html"><a href="sec14.html"><i class="fa fa-check"></i><b>1.3</b> Bayesian reports: Decision theory under uncertainty</a></li>
<li class="chapter" data-level="1.4" data-path="summary.html"><a href="summary.html"><i class="fa fa-check"></i><b>1.4</b> Summary</a></li>
<li class="chapter" data-level="1.5" data-path="exercises.html"><a href="exercises.html"><i class="fa fa-check"></i><b>1.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="Chap2.html"><a href="Chap2.html"><i class="fa fa-check"></i><b>2</b> Conceptual differences between the Bayesian and Frequentist approaches</a>
<ul>
<li class="chapter" data-level="2.1" data-path="sec21.html"><a href="sec21.html"><i class="fa fa-check"></i><b>2.1</b> The concept of probability</a></li>
<li class="chapter" data-level="2.2" data-path="sec22.html"><a href="sec22.html"><i class="fa fa-check"></i><b>2.2</b> Subjectivity is not the key</a></li>
<li class="chapter" data-level="2.3" data-path="sec23.html"><a href="sec23.html"><i class="fa fa-check"></i><b>2.3</b> Estimation, hypothesis testing and prediction</a></li>
<li class="chapter" data-level="2.4" data-path="sec24.html"><a href="sec24.html"><i class="fa fa-check"></i><b>2.4</b> The likelihood principle</a></li>
<li class="chapter" data-level="2.5" data-path="sec25.html"><a href="sec25.html"><i class="fa fa-check"></i><b>2.5</b> Why is not the Bayesian approach that popular?</a></li>
<li class="chapter" data-level="2.6" data-path="sec26.html"><a href="sec26.html"><i class="fa fa-check"></i><b>2.6</b> A simple working example</a></li>
<li class="chapter" data-level="2.7" data-path="sec27.html"><a href="sec27.html"><i class="fa fa-check"></i><b>2.7</b> Summary</a></li>
<li class="chapter" data-level="2.8" data-path="sec28.html"><a href="sec28.html"><i class="fa fa-check"></i><b>2.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="Chap3.html"><a href="Chap3.html"><i class="fa fa-check"></i><b>3</b> Cornerstone models: Conjugate families</a>
<ul>
<li class="chapter" data-level="3.1" data-path="sec41.html"><a href="sec41.html"><i class="fa fa-check"></i><b>3.1</b> Motivation of conjugate families</a></li>
<li class="chapter" data-level="3.2" data-path="sec42.html"><a href="sec42.html"><i class="fa fa-check"></i><b>3.2</b> Conjugate prior to exponential family</a></li>
<li class="chapter" data-level="3.3" data-path="sec43.html"><a href="sec43.html"><i class="fa fa-check"></i><b>3.3</b> Linear regression: The conjugate normal-normal/inverse gamma model</a></li>
<li class="chapter" data-level="3.4" data-path="sec44.html"><a href="sec44.html"><i class="fa fa-check"></i><b>3.4</b> Multivariate linear regression: The conjugate normal-normal/inverse Wishart model</a></li>
<li class="chapter" data-level="3.5" data-path="computational-examples.html"><a href="computational-examples.html"><i class="fa fa-check"></i><b>3.5</b> Computational examples</a></li>
<li class="chapter" data-level="3.6" data-path="summary-chapter-4.html"><a href="summary-chapter-4.html"><i class="fa fa-check"></i><b>3.6</b> Summary: Chapter 4</a></li>
<li class="chapter" data-level="3.7" data-path="exercises-chapter-4.html"><a href="exercises-chapter-4.html"><i class="fa fa-check"></i><b>3.7</b> Exercises: Chapter 4</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="Chap4.html"><a href="Chap4.html"><i class="fa fa-check"></i><b>4</b> Simulation methods</a>
<ul>
<li class="chapter" data-level="4.1" data-path="sec51.html"><a href="sec51.html"><i class="fa fa-check"></i><b>4.1</b> Markov Chain Monte Carlo methods</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="sec51.html"><a href="sec51.html#sec511"><i class="fa fa-check"></i><b>4.1.1</b> Gibbs sampler</a></li>
<li class="chapter" data-level="4.1.2" data-path="sec51.html"><a href="sec51.html#sec512"><i class="fa fa-check"></i><b>4.1.2</b> Metropolis-Hastings</a></li>
<li class="chapter" data-level="4.1.3" data-path="sec51.html"><a href="sec51.html#sec513"><i class="fa fa-check"></i><b>4.1.3</b> Hamiltonian Monte Carlo</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="sec52.html"><a href="sec52.html"><i class="fa fa-check"></i><b>4.2</b> Importance sampling</a></li>
<li class="chapter" data-level="4.3" data-path="sec53.html"><a href="sec53.html"><i class="fa fa-check"></i><b>4.3</b> Particle filtering</a></li>
<li class="chapter" data-level="4.4" data-path="sec54.html"><a href="sec54.html"><i class="fa fa-check"></i><b>4.4</b> Convergence diagnostics</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="sec54.html"><a href="sec54.html#numerical-standard-error"><i class="fa fa-check"></i><b>4.4.1</b> Numerical standard error</a></li>
<li class="chapter" data-level="4.4.2" data-path="sec54.html"><a href="sec54.html#effective-number-of-simulation-draws"><i class="fa fa-check"></i><b>4.4.2</b> Effective number of simulation draws</a></li>
<li class="chapter" data-level="4.4.3" data-path="sec54.html"><a href="sec54.html#tests-of-convergence"><i class="fa fa-check"></i><b>4.4.3</b> Tests of convergence</a></li>
<li class="chapter" data-level="4.4.4" data-path="sec54.html"><a href="sec54.html#checking-for-errors-in-the-posterior-simulator"><i class="fa fa-check"></i><b>4.4.4</b> Checking for errors in the posterior simulator</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="sec55.html"><a href="sec55.html"><i class="fa fa-check"></i><b>4.5</b> Summary</a></li>
<li class="chapter" data-level="4.6" data-path="sec56.html"><a href="sec56.html"><i class="fa fa-check"></i><b>4.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="Chap5.html"><a href="Chap5.html"><i class="fa fa-check"></i><b>5</b> Graphical user interface</a></li>
<li class="chapter" data-level="6" data-path="Chap6.html"><a href="Chap6.html"><i class="fa fa-check"></i><b>6</b> Univariate regression</a>
<ul>
<li class="chapter" data-level="6.1" data-path="sec61.html"><a href="sec61.html"><i class="fa fa-check"></i><b>6.1</b> The Gaussian linear model</a></li>
<li class="chapter" data-level="6.2" data-path="sec62.html"><a href="sec62.html"><i class="fa fa-check"></i><b>6.2</b> The logit model</a></li>
<li class="chapter" data-level="6.3" data-path="sec63.html"><a href="sec63.html"><i class="fa fa-check"></i><b>6.3</b> The probit model</a></li>
<li class="chapter" data-level="6.4" data-path="sec64.html"><a href="sec64.html"><i class="fa fa-check"></i><b>6.4</b> The multinomial probit model</a></li>
<li class="chapter" data-level="6.5" data-path="sec65.html"><a href="sec65.html"><i class="fa fa-check"></i><b>6.5</b> The multinomial logit model</a></li>
<li class="chapter" data-level="6.6" data-path="sec66.html"><a href="sec66.html"><i class="fa fa-check"></i><b>6.6</b> Ordered probit model</a></li>
<li class="chapter" data-level="6.7" data-path="negative-binomial-model.html"><a href="negative-binomial-model.html"><i class="fa fa-check"></i><b>6.7</b> Negative binomial model</a></li>
<li class="chapter" data-level="6.8" data-path="sec68.html"><a href="sec68.html"><i class="fa fa-check"></i><b>6.8</b> Tobit model</a></li>
<li class="chapter" data-level="6.9" data-path="sec69.html"><a href="sec69.html"><i class="fa fa-check"></i><b>6.9</b> Quantile regression</a></li>
<li class="chapter" data-level="6.10" data-path="sec610.html"><a href="sec610.html"><i class="fa fa-check"></i><b>6.10</b> Bayesian bootstrap regression</a></li>
<li class="chapter" data-level="6.11" data-path="sec611.html"><a href="sec611.html"><i class="fa fa-check"></i><b>6.11</b> Summary</a></li>
<li class="chapter" data-level="6.12" data-path="sec612.html"><a href="sec612.html"><i class="fa fa-check"></i><b>6.12</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="Chap7.html"><a href="Chap7.html"><i class="fa fa-check"></i><b>7</b> Multivariate regression</a>
<ul>
<li class="chapter" data-level="7.1" data-path="sec71.html"><a href="sec71.html"><i class="fa fa-check"></i><b>7.1</b> Multivariate regression</a></li>
<li class="chapter" data-level="7.2" data-path="sec72.html"><a href="sec72.html"><i class="fa fa-check"></i><b>7.2</b> Seemingly Unrelated Regression</a></li>
<li class="chapter" data-level="7.3" data-path="sec73.html"><a href="sec73.html"><i class="fa fa-check"></i><b>7.3</b> Instrumental variable</a></li>
<li class="chapter" data-level="7.4" data-path="sec74.html"><a href="sec74.html"><i class="fa fa-check"></i><b>7.4</b> Multivariate probit model</a></li>
<li class="chapter" data-level="7.5" data-path="sec75.html"><a href="sec75.html"><i class="fa fa-check"></i><b>7.5</b> Summary</a></li>
<li class="chapter" data-level="7.6" data-path="sec76.html"><a href="sec76.html"><i class="fa fa-check"></i><b>7.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="Chap8.html"><a href="Chap8.html"><i class="fa fa-check"></i><b>8</b> Time series</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to Bayesian Data Modeling</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="sec64" class="section level2 hasAnchor" number="6.4">
<h2><span class="header-section-number">6.4</span> The multinomial probit model<a href="sec64.html#sec64" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The multinomial probit model is used to model the choice of the <span class="math inline">\(l\)</span>-th alternative over a set of <span class="math inline">\(L\)</span> mutually exclusive options. We observe the following:</p>
<p><span class="math display">\[
y_{il} =
\begin{cases}
1, &amp; \text{if } y_{il}^* \geq \max\left\{\boldsymbol{y}_i^*\right\}, \\
0, &amp; \text{otherwise,}
\end{cases}
\]</span></p>
<p>where <span class="math inline">\(\boldsymbol{y}_i^* = \boldsymbol{X}_{i} \boldsymbol{\delta} + \boldsymbol{\mu}_i\)</span>, with <span class="math inline">\(\boldsymbol{\mu}_i \stackrel{i.i.d.}{\sim} N(\boldsymbol{0}, \boldsymbol{\Sigma})\)</span>. The vector <span class="math inline">\(\boldsymbol{y}_i^*\)</span> is an unobserved latent vector of dimension <span class="math inline">\(L\)</span>. The matrix <span class="math inline">\(\boldsymbol{X}_i = \left[(1 \ \boldsymbol{c}_i^{\top}) \otimes \boldsymbol{I}_L \ \boldsymbol{A}_i\right]\)</span> is an <span class="math inline">\(L \times j\)</span> matrix of regressors for each alternative, where <span class="math inline">\(l = 1, 2, \dots, L\)</span>, and <span class="math inline">\(j = L \times (1 + \text{dim}(\boldsymbol{c}_i)) + a\)</span>. Here, <span class="math inline">\(\boldsymbol{c}_i\)</span> is a vector of individual-specific characteristics, <span class="math inline">\(\boldsymbol{A}_i\)</span> is an <span class="math inline">\(L \times a\)</span> matrix of alternative-varying regressors, <span class="math inline">\(a\)</span> is the number of alternative-varying regressors, and <span class="math inline">\(\boldsymbol{\delta}\)</span> is a <span class="math inline">\(j\)</span>-dimensional vector of parameters.</p>
<p>We take into account simultaneously the alternative-varying regressors (alternative attributes) and alternative-invariant regressors (individual characteristics).<a href="#fn25" class="footnote-ref" id="fnref25"><sup>25</sup></a> The vector <span class="math inline">\(\boldsymbol{y}_i^*\)</span> can be stacked into a multiple regression model with correlated stochastic errors, i.e., <span class="math inline">\(\boldsymbol{y}^* = \boldsymbol{X} \boldsymbol{\delta} + \boldsymbol{\mu}\)</span>, where <span class="math inline">\(\boldsymbol{y}^* = \left[\boldsymbol{y}_1^{*\top} \ \boldsymbol{y}_2^{*\top} \ \dots \ \boldsymbol{y}_N^{*\top}\right]\)</span>, <span class="math inline">\(\boldsymbol{X} = \left[\boldsymbol{X}_1^{\top} \ \boldsymbol{X}_2^{\top} \ \dots \ \boldsymbol{X}_N^{\top}\right]^{\top}\)</span>, and <span class="math inline">\(\boldsymbol{\mu} = \left[\boldsymbol{\mu}_1^{\top} \ \boldsymbol{\mu}_2^{\top} \ \dots \ \boldsymbol{\mu}_N^{\top}\right]^{\top}\)</span>.</p>
<p>Following the practice of expressing <span class="math inline">\(y_{il}^*\)</span> relative to <span class="math inline">\(y_{iL}^*\)</span> by letting <span class="math inline">\(\boldsymbol{w}_i = \left[w_{i1} \ w_{i2} \ \dots \ w_{iL-1}\right]^{\top}\)</span>, where <span class="math inline">\(w_{il} = y_{il}^* - y_{iL}^*\)</span>, we can write <span class="math inline">\(\boldsymbol{w}_i = \boldsymbol{R}_i \boldsymbol{\beta} + \boldsymbol{\epsilon}_i\)</span>, with <span class="math inline">\(\boldsymbol{\epsilon}_i \sim N(\boldsymbol{0}, \boldsymbol{\Omega})\)</span>, where <span class="math inline">\(\boldsymbol{R}_i = \left[(1 \ \boldsymbol{c}_i^{\top}) \otimes \boldsymbol{I}_{L-1} \ \boldsymbol{\Delta A}_i\right]\)</span> is an <span class="math inline">\((L-1) \times K\)</span> matrix, with <span class="math inline">\(\Delta \boldsymbol{A}_i = \boldsymbol{A}_{li} - \boldsymbol{A}_{Li}\)</span>, for <span class="math inline">\(l = 1, 2, \dots, L-1\)</span>. That is, the last row of <span class="math inline">\(\boldsymbol{A}_i\)</span> is subtracted from each row of <span class="math inline">\(\boldsymbol{A}_i\)</span>, and <span class="math inline">\(\boldsymbol{\beta}\)</span> is a <span class="math inline">\(K\)</span>-dimensional vector, where <span class="math inline">\(K = (L-1) \times (1 + \text{dim}(\boldsymbol{c}_i)) + a\)</span>.</p>
<p>Observe that <span class="math inline">\(\boldsymbol{\beta}\)</span> contains the same last <span class="math inline">\(a\)</span> elements as <span class="math inline">\(\boldsymbol{\delta}\)</span>, that is, the alternative-specific attribute coefficients. However, the first <span class="math inline">\((L-1) \times (1 + \text{dim}(\boldsymbol{c}_i))\)</span> elements of <span class="math inline">\(\boldsymbol{\beta}\)</span> are the differences <span class="math inline">\(\delta_{jl} - \delta_{jL}\)</span>, for <span class="math inline">\(j = 1, \dots, \text{dim}(\boldsymbol{c}_i)\)</span> and <span class="math inline">\(l = 1, 2, \dots, L-1\)</span>. That is, these elements represent the difference between the coefficients of each qualitative response and the <span class="math inline">\(L\)</span>-th alternative for the individuals’ characteristics. This makes it difficult to interpret the multinomial probit coefficients.</p>
<p>Note that in multinomial models, for each alternative-specific attribute, it is only necessary to estimate one coefficient for all alternatives. However, for individuals’ characteristics (non-alternative-specific regressors), it is required to estimate <span class="math inline">\(L-1\)</span> coefficients, since the coefficient for the base alternative is set equal to 0.</p>
<p>The likelihood function in this model is given by
<span class="math display">\[
p(\boldsymbol{\beta}, \boldsymbol{\Omega} \mid \boldsymbol{y}, \boldsymbol{R}) = \prod_{i=1}^N \prod_{l=1}^L p_{il}^{y_{il}},
\]</span>
where <span class="math inline">\(p_{il} = p(y_{il}^* \geq \max(\boldsymbol{y}_i^*))\)</span>.</p>
<p>We assume independent priors for the parameters:
<span class="math display">\[
\boldsymbol{\beta} \sim N(\boldsymbol{\beta}_0, \boldsymbol{B}_0) \quad \text{and} \quad \boldsymbol{\Omega}^{-1} \sim W(\alpha_0, \boldsymbol{\Sigma}_0),
\]</span>
where <span class="math inline">\(W\)</span> denotes the Wishart density.</p>
<p>We can employ Gibbs sampling in this model, as it is a standard Bayesian linear regression model when data augmentation is used for <span class="math inline">\(\boldsymbol{w}\)</span>. The posterior conditional distributions are given by</p>
<p><span class="math display">\[\begin{equation*}
    \boldsymbol{\beta}\mid \boldsymbol{\Omega},\boldsymbol{w}\sim{N}(\boldsymbol{\beta}_n,\boldsymbol{B}_n),
\end{equation*}\]</span>
<span class="math display">\[\begin{equation*}
    \boldsymbol{\Omega}^{-1}\mid \boldsymbol{\beta},\boldsymbol{w}\sim{W}(\alpha_n,\boldsymbol{\Sigma}_n),
\end{equation*}\]</span></p>
<p>where <span class="math inline">\(\boldsymbol{B}_n=(\boldsymbol{B}_0^{-1}+\boldsymbol{X}^{*\top}\boldsymbol{X}^*)^{-1}\)</span>, <span class="math inline">\(\boldsymbol{\beta}_n=\boldsymbol{B}_n(\boldsymbol{B}_0^{-1}\boldsymbol{\beta}_0+\boldsymbol{X}^{*\top}\boldsymbol{w}^*)\)</span>, <span class="math inline">\(\boldsymbol{\Omega}^{-1}=\boldsymbol{C}^{\top}\boldsymbol{C}\)</span>, <span class="math inline">\(\boldsymbol{X}_i^{*\top}=\boldsymbol{C}^{\top}\boldsymbol{R}_i\)</span>, <span class="math inline">\(\boldsymbol{w}_i^*=\boldsymbol{C}^{\top}\boldsymbol{w}_i\)</span>, <span class="math inline">\(\boldsymbol{X}^*=\begin{bmatrix}\boldsymbol{X}_1^*\\  \boldsymbol{X}_2^*\\  \vdots\\  \boldsymbol{X}_N^* \end{bmatrix}\)</span>, <span class="math inline">\(\alpha_n=\alpha_0+N\)</span>, <span class="math inline">\(\boldsymbol{\Sigma}_n=(\boldsymbol{\Sigma}_0+\sum_{i=1}^N (\boldsymbol{w}_i-\boldsymbol{R}_i\boldsymbol{\beta})^{\top}(\boldsymbol{w}_i-\boldsymbol{R}_i\boldsymbol{\beta}))^{-1}\)</span>.</p>
<p>We can collapse the multinomial vector <span class="math inline">\(\boldsymbol{y}_i\)</span> into the indicator variable <span class="math inline">\(d_i=\sum_{l=1}^{L-1}l\times \mathbb{1}({\max(\boldsymbol{w}_{l})=w_{il}})\)</span>.<a href="#fn26" class="footnote-ref" id="fnref26"><sup>26</sup></a> Then the distribution of <span class="math inline">\(\boldsymbol{w}_i\mid \boldsymbol{\beta},\boldsymbol{\Omega}^{-1},d_i\)</span> is an <span class="math inline">\(L-1\)</span> dimensional Gaussian distribution truncated over the appropriate cone in <span class="math inline">\(\mathcal{R}^{L-1}\)</span>.
<span class="citation">R. McCulloch and Rossi (<a href="#ref-McCulloch1994">1994</a>)</span> propose drawing from the univariate conditional distributions <span class="math inline">\(w_{il}\mid \boldsymbol{w}_{i,-l},\boldsymbol{\beta},\boldsymbol{\Omega}^{-1},d_i\sim TN_{I_{il}}(m_{il},\tau_{ll}^2)\)</span>, where
<span class="math display">\[\begin{equation*}
I_{il}=\begin{Bmatrix} w_{il}&gt;\max(\boldsymbol{w}_{i,-l},0), &amp; d_i=l\\
    w_{il}&lt;\max(\boldsymbol{w}_{i,-l},0), &amp; d_i\neq l\\
\end{Bmatrix},
\end{equation*}\]</span>
and permuting the columns and rows of <span class="math inline">\(\boldsymbol{\Omega}^{-1}\)</span> so that the <span class="math inline">\(l\)</span>-th column and row is the last,
<span class="math display">\[\begin{equation*}
    \boldsymbol{\Omega}^{-1}=\begin{bmatrix}
        \boldsymbol{\Omega}_{-l,-l} &amp; \boldsymbol\omega_{-l,l}\\
        \boldsymbol\omega_{l,-1} &amp; \omega_{l,l}\\
    \end{bmatrix}^{-1}
    =\begin{bmatrix}
        \boldsymbol{\Omega}_{-l,-l}^{-1}+{\tau}^{-2}_{ll}\boldsymbol{f}_l\boldsymbol{f}_l^{\top} &amp; -\boldsymbol{f}_l\tau^{-2}_{ll}\\
        -{\tau}^{-2}_{ll}\boldsymbol{f}_l^{\top} &amp; {\tau}^{-2}_{ll}\\
    \end{bmatrix}
\end{equation*}\]</span>
where <span class="math inline">\(\boldsymbol{f}_l=\boldsymbol{\Omega}_{-l,-l}^{-1}\boldsymbol{\omega}_{-l,l}\)</span>, <span class="math inline">\(\tau_{ll}^2= \omega_{ll}-\boldsymbol{\omega}_{l,-l}\boldsymbol{\Omega}^{-1}_{-l,-1}\boldsymbol{\omega}_{-l,l}\)</span>, <span class="math inline">\(m_{il}=\boldsymbol{r}_{il}^{\top}\boldsymbol{\beta}+\boldsymbol{f}_l^{\top}(\boldsymbol{w}_{i,-l}-\boldsymbol{R}_{i,-l}\boldsymbol{\beta})\)</span>, <span class="math inline">\(\boldsymbol{w}_{i,-l}\)</span> is an <span class="math inline">\(L-2\)</span> dimensional vector of all components of <span class="math inline">\(\boldsymbol{w}_i\)</span> excluding <span class="math inline">\(w_{il}\)</span>, <span class="math inline">\(\boldsymbol{r}_{il}\)</span> is the <span class="math inline">\(l\)</span>-th row of <span class="math inline">\(\boldsymbol{R}_i\)</span>, <span class="math inline">\(l=1,2,\dots,L-1\)</span>.</p>
<p>The identified parameters are obtained by normalizing with respect to one of the diagonal elements <span class="math inline">\(\frac{1}{\omega_{1,1}^{0.5}}\boldsymbol{\beta}\)</span> and <span class="math inline">\(\frac{1}{\omega_{1,1}}\boldsymbol{\Omega}\)</span>.<a href="#fn27" class="footnote-ref" id="fnref27"><sup>27</sup></a></p>
<p><strong>Warning:</strong> This model is an example where decisions must be made about setting the model in an identified parameter space versus an unidentified parameter space. The mixing properties of the posterior draws can be better in the latter case <span class="citation">(<a href="#ref-mcculloch2000bayesian">R. E. McCulloch, Polson, and Rossi 2000</a>)</span>, which typically results in less computational burden. However, it is important to recover the identified space in a final stage. Additionally, defining priors in the unidentified space may have unintended consequences on the posterior distributions in the identified space <span class="citation">(<a href="#ref-nobile2000comment">Nobile 2000</a>)</span>. The multinomial probit model presented in this section is set in the unidentified space <span class="citation">(<a href="#ref-McCulloch1994">R. McCulloch and Rossi 1994</a>)</span>, while a version of the multinomial probit in the identified space is presented by <span class="citation">R. E. McCulloch, Polson, and Rossi (<a href="#ref-mcculloch2000bayesian">2000</a>)</span>.</p>
<p><strong>Example: Choice of fishing mode</strong></p>
<p>We used in this application the dataset <em>3Fishing.csv</em> from <span class="citation">Cameron and Trivedi (<a href="#ref-cameron05">2005</a>)</span>. The dependent variable is mutually exclusive alternatives regarding fishing modes (mode), where beach is equal to 1, pier is equal to 2, private boat is equal to 3, and chartered boat (baseline alternative) is equal to 4. In this model, we have</p>
<p><span class="math display">\[
\mathbf{X}_i = \begin{bmatrix}
1 &amp; 0 &amp; 0 &amp; 0 &amp; \text{Income}_i &amp; 0 &amp; 0 &amp; 0 &amp; \text{Price}_{i,1} &amp; \text{Catch rate}_{i,1}\\
0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; \text{Income}_i &amp; 0 &amp; 0 &amp; \text{Price}_{i,2} &amp; \text{Catch rate}_{i,2}\\
0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; \text{Income}_i &amp; 0 &amp; \text{Price}_{i,3} &amp; \text{Catch rate}_{i,3}\\
0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; \text{Income}_i &amp; \text{Price}_{i,4} &amp; \text{Catch rate}_{i,4}\\
\end{bmatrix}
\]</span></p>
<p>In this example, chartered boat is the base category, the number of choice categories is four, there are two alternative-specific regressors (price and catch rate), and one non-alternative-specific regressor (income). This setting involves the estimation of eight location parameters (<span class="math inline">\(\boldsymbol{\beta}\)</span>): three intercepts, three for income, one for price, and one for catch rate. This is the order of the posterior chains in our GUI. Note that the location coefficients are set equal to 0 for the baseline category. For multinomial models, we strongly recommend using the last category as the baseline.</p>
<p>We also get posterior estimates for a <span class="math inline">\(3\times 3\)</span> covariance matrix (four alternatives minus one), where the element (1,1) is equal to 1 due to identification restrictions, and elements 2 and 4 are the same, as well as 3 and 7, and 6 and 8, due to symmetry.</p>
<p>Observe that this identification restriction implies <em>NaN</em> values in <span class="citation">J. Geweke (<a href="#ref-Geweke1992">1992</a>)</span> and <span class="citation">Heidelberger and Welch (<a href="#ref-Heidelberger1983">1983</a>)</span> tests for element (1,1) of the covariance matrix, and just eight dependence factors associated with the remaining elements of the covariance matrix.</p>
<p>Once our GUI is displayed (see beginning of this chapter), we should follow the next Algorithm to run multinomial probit models in our GUI (see Chapter <a href="Chap5.html#Chap5">5</a> for details), which in turn uses the command <em>rmnpGibbs</em> from the <em>bayesm</em> package.</p>
<div class="algorithm">
<div style="background-color: #f8f9fa; padding: 15px; border-left: 5px solid #343a40; box-shadow: 4px 4px 10px rgba(0, 0, 0, 0.1); border-radius: 5px;">
<p><strong>Algorithm: Multinomial Probit model in the GUI</strong></p>
<ol style="list-style-type: decimal">
<li>Select <em>Univariate Models</em> on the top panel<br />
</li>
<li>Select <em>Multinomial Probit</em> model using the left radio button<br />
</li>
<li>Upload the dataset by first selecting whether there is a header in the file, and the kind of separator in the <em>csv</em> file of the dataset (comma, semicolon, or tab). Then, use the <em>Browse</em> button under the <strong>Choose File</strong> legend. You should see a preview of the dataset<br />
</li>
<li>Select MCMC iterations, burn-in, and thinning parameters using the <em>Range sliders</em><br />
</li>
<li>Select dependent and independent variables using the <em>Formula builder</em> table<br />
</li>
<li>Select the number of the <strong>Base Alternative</strong><br />
</li>
<li>Select the <strong>Number of choice categorical alternatives</strong><br />
</li>
<li>Select the <strong>Number of alternative specific variables</strong><br />
</li>
<li>Select the <strong>Number of Non-alternative specific variables</strong><br />
</li>
<li>Click the <em>Build formula</em> button to generate the formula in <strong>R</strong> syntax.<br />
</li>
<li>Set the hyperparameters: mean vector, covariance matrix, scale matrix, and degrees of freedom. This step is not necessary as by default our GUI uses non-informative priors<br />
</li>
<li>Click the <em>Go!</em> button<br />
</li>
<li>Analyze results<br />
</li>
<li>Download posterior chains and diagnostic plots using the <em>Download Posterior Chains</em> and <em>Download Posterior Graphs</em> buttons</li>
</ol>
</div>
</div>
<p>We ran 100,000 MCMC iterations plus 10,000 as burn-in with a thinning parameter equal to 5, where all priors use default values for the hyperparameters in our GUI. We found that the 95% credible intervals of the coefficient associated with income for beach and private boat alternatives are equal to (8.58e-06, 8.88e-05) and (3.36e-05, 1.45e-04). This suggests that the probability of choosing these alternatives increases compared to a chartered boat when income increases. In addition, an increase in the price or a decrease in the catch rate for specific fishing alternatives imply lower probabilities of choosing them as the 95% credible intervals are (-9.91e-03, -3.83e-03) and (1.40e-01, 4.62e-01), respectively. However, the posterior chain diagnostics suggest there are convergence issues with the posterior draws (see Exercise 5).</p>
</div>
<h3>References<a href="references.html#references" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-cameron05" class="csl-entry">
Cameron, Colin, and Pravin Trivedi. 2005. <em>Microeconometrics: Methods and Applications</em>. Cambridge.
</div>
<div id="ref-Geweke1992" class="csl-entry">
Geweke, J. 1992. <span>“Bayesian Statistics.”</span> In. Clarendon Press, Oxford, UK.
</div>
<div id="ref-Heidelberger1983" class="csl-entry">
Heidelberger, P., and P. D. Welch. 1983. <span>“Simulation Run Length Control in the Presence of an Initial Transient.”</span> <em>Operations Research</em> 31 (6): 1109–44.
</div>
<div id="ref-mcculloch2000bayesian" class="csl-entry">
McCulloch, Robert E, Nicholas G Polson, and Peter E Rossi. 2000. <span>“A Bayesian Analysis of the Multinomial Probit Model with Fully Identified Parameters.”</span> <em>Journal of Econometrics</em> 99 (1): 173–93.
</div>
<div id="ref-McCulloch1994" class="csl-entry">
McCulloch, R., and P. Rossi. 1994. <span>“An Exact Likelihood Analysis of the Multinomial Probit Model.”</span> <em>Journal of Econometrics</em> 64: 207–40.
</div>
<div id="ref-nobile2000comment" class="csl-entry">
Nobile, Agostino. 2000. <span>“Comment: Bayesian Multinomial Probit Models with a Normalization Constraint.”</span> <em>Journal of Econometrics</em> 99 (2): 335–45.
</div>
</div>
<div class="footnotes">
<hr />
<ol start="25">
<li id="fn25"><p>Note that this model is not identified if <span class="math inline">\(\boldsymbol{\Sigma}\)</span> is unrestricted. The likelihood function remains the same if a scalar random variable is added to each of the <span class="math inline">\(L\)</span> latent regressions.<a href="sec64.html#fnref25" class="footnote-back">↩︎</a></p></li>
<li id="fn26"><p>Observe that the identification issue in this model is due to scaling <span class="math inline">\(w_{il}\)</span> by a positive constant does not change the value of <span class="math inline">\(d_i\)</span>.<a href="sec64.html#fnref26" class="footnote-back">↩︎</a></p></li>
<li id="fn27"><p>Our GUI is based on the <em>bayesm</em> package that takes into account this identification restriction to display the outcomes of the posterior chains.<a href="sec64.html#fnref27" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="sec63.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="sec65.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/aramir21/IntroductionBayesianEconometricsBook/06-Univariatereg.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
