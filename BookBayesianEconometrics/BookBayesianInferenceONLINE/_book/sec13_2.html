<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>13.2 Randomized controlled trial (RCT) | Introduction to Bayesian Econometrics</title>
  <meta name="description" content="The subject of this textbook is Bayesian data modeling, with the primary aim of providing an introduction to its theoretical foundations and facilitating the application of Bayesian inference using a GUI." />
  <meta name="generator" content="bookdown 0.43 and GitBook 2.6.7" />

  <meta property="og:title" content="13.2 Randomized controlled trial (RCT) | Introduction to Bayesian Econometrics" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="The subject of this textbook is Bayesian data modeling, with the primary aim of providing an introduction to its theoretical foundations and facilitating the application of Bayesian inference using a GUI." />
  <meta name="github-repo" content="https://github.com/aramir21/IntroductionBayesianEconometricsBook" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="13.2 Randomized controlled trial (RCT) | Introduction to Bayesian Econometrics" />
  
  <meta name="twitter:description" content="The subject of this textbook is Bayesian data modeling, with the primary aim of providing an introduction to its theoretical foundations and facilitating the application of Bayesian inference using a GUI." />
  

<meta name="author" content="Andrés Ramírez-Hassan" />


<meta name="date" content="2025-12-06" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="sec13_1.html"/>
<link rel="next" href="sec13_3.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Introduction to Bayesian Econometrics: A GUIded toolkit using R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="to-instructors-and-students.html"><a href="to-instructors-and-students.html"><i class="fa fa-check"></i>To instructors and students</a></li>
<li class="chapter" data-level="" data-path="acknowledgments.html"><a href="acknowledgments.html"><i class="fa fa-check"></i>Acknowledgments</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="Chap1.html"><a href="Chap1.html"><i class="fa fa-check"></i><b>1</b> Basic formal concepts</a>
<ul>
<li class="chapter" data-level="1.1" data-path="sec11.html"><a href="sec11.html"><i class="fa fa-check"></i><b>1.1</b> The Bayes’ rule</a></li>
<li class="chapter" data-level="1.2" data-path="sec12.html"><a href="sec12.html"><i class="fa fa-check"></i><b>1.2</b> Bayesian framework: A brief summary of theory</a></li>
<li class="chapter" data-level="1.3" data-path="sec14.html"><a href="sec14.html"><i class="fa fa-check"></i><b>1.3</b> Bayesian reports: Decision theory under uncertainty</a></li>
<li class="chapter" data-level="1.4" data-path="summary.html"><a href="summary.html"><i class="fa fa-check"></i><b>1.4</b> Summary</a></li>
<li class="chapter" data-level="1.5" data-path="exercises.html"><a href="exercises.html"><i class="fa fa-check"></i><b>1.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="Chap2.html"><a href="Chap2.html"><i class="fa fa-check"></i><b>2</b> Conceptual differences between the Bayesian and Frequentist approaches</a>
<ul>
<li class="chapter" data-level="2.1" data-path="sec21.html"><a href="sec21.html"><i class="fa fa-check"></i><b>2.1</b> The concept of probability</a></li>
<li class="chapter" data-level="2.2" data-path="sec22.html"><a href="sec22.html"><i class="fa fa-check"></i><b>2.2</b> Subjectivity is not the key</a></li>
<li class="chapter" data-level="2.3" data-path="sec23.html"><a href="sec23.html"><i class="fa fa-check"></i><b>2.3</b> Estimation, hypothesis testing and prediction</a></li>
<li class="chapter" data-level="2.4" data-path="sec24.html"><a href="sec24.html"><i class="fa fa-check"></i><b>2.4</b> The likelihood principle</a></li>
<li class="chapter" data-level="2.5" data-path="sec25.html"><a href="sec25.html"><i class="fa fa-check"></i><b>2.5</b> Why is not the Bayesian approach that popular?</a></li>
<li class="chapter" data-level="2.6" data-path="sec26.html"><a href="sec26.html"><i class="fa fa-check"></i><b>2.6</b> A simple working example</a></li>
<li class="chapter" data-level="2.7" data-path="sec27.html"><a href="sec27.html"><i class="fa fa-check"></i><b>2.7</b> Summary</a></li>
<li class="chapter" data-level="2.8" data-path="sec28.html"><a href="sec28.html"><i class="fa fa-check"></i><b>2.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="Chap3.html"><a href="Chap3.html"><i class="fa fa-check"></i><b>3</b> Cornerstone models: Conjugate families</a>
<ul>
<li class="chapter" data-level="3.1" data-path="sec41.html"><a href="sec41.html"><i class="fa fa-check"></i><b>3.1</b> Motivation of conjugate families</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="sec41.html"><a href="sec41.html#examples-of-exponential-family-distributions"><i class="fa fa-check"></i><b>3.1.1</b> Examples of exponential family distributions</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="sec42.html"><a href="sec42.html"><i class="fa fa-check"></i><b>3.2</b> Conjugate prior to exponential family</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="sec42.html"><a href="sec42.html#sec421"><i class="fa fa-check"></i><b>3.2.1</b> Examples: Theorem 4.2.1</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="sec43.html"><a href="sec43.html"><i class="fa fa-check"></i><b>3.3</b> Linear regression: The conjugate normal-normal/inverse gamma model</a></li>
<li class="chapter" data-level="3.4" data-path="sec44.html"><a href="sec44.html"><i class="fa fa-check"></i><b>3.4</b> Multivariate linear regression: The conjugate normal-normal/inverse Wishart model</a></li>
<li class="chapter" data-level="3.5" data-path="sec45.html"><a href="sec45.html"><i class="fa fa-check"></i><b>3.5</b> Summary</a></li>
<li class="chapter" data-level="3.6" data-path="sec46.html"><a href="sec46.html"><i class="fa fa-check"></i><b>3.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="Chap4.html"><a href="Chap4.html"><i class="fa fa-check"></i><b>4</b> Simulation methods</a>
<ul>
<li class="chapter" data-level="4.1" data-path="sec51.html"><a href="sec51.html"><i class="fa fa-check"></i><b>4.1</b> Markov Chain Monte Carlo methods</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="sec51.html"><a href="sec51.html#sec511"><i class="fa fa-check"></i><b>4.1.1</b> Gibbs sampler</a></li>
<li class="chapter" data-level="4.1.2" data-path="sec51.html"><a href="sec51.html#sec512"><i class="fa fa-check"></i><b>4.1.2</b> Metropolis-Hastings</a></li>
<li class="chapter" data-level="4.1.3" data-path="sec51.html"><a href="sec51.html#sec513"><i class="fa fa-check"></i><b>4.1.3</b> Hamiltonian Monte Carlo</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="sec52.html"><a href="sec52.html"><i class="fa fa-check"></i><b>4.2</b> Importance sampling</a></li>
<li class="chapter" data-level="4.3" data-path="sec53.html"><a href="sec53.html"><i class="fa fa-check"></i><b>4.3</b> Particle filtering</a></li>
<li class="chapter" data-level="4.4" data-path="sec54.html"><a href="sec54.html"><i class="fa fa-check"></i><b>4.4</b> Convergence diagnostics</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="sec54.html"><a href="sec54.html#numerical-standard-error"><i class="fa fa-check"></i><b>4.4.1</b> Numerical standard error</a></li>
<li class="chapter" data-level="4.4.2" data-path="sec54.html"><a href="sec54.html#effective-number-of-simulation-draws"><i class="fa fa-check"></i><b>4.4.2</b> Effective number of simulation draws</a></li>
<li class="chapter" data-level="4.4.3" data-path="sec54.html"><a href="sec54.html#tests-of-convergence"><i class="fa fa-check"></i><b>4.4.3</b> Tests of convergence</a></li>
<li class="chapter" data-level="4.4.4" data-path="sec54.html"><a href="sec54.html#checking-for-errors-in-the-posterior-simulator"><i class="fa fa-check"></i><b>4.4.4</b> Checking for errors in the posterior simulator</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="sec55.html"><a href="sec55.html"><i class="fa fa-check"></i><b>4.5</b> Summary</a></li>
<li class="chapter" data-level="4.6" data-path="sec56.html"><a href="sec56.html"><i class="fa fa-check"></i><b>4.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="Chap5.html"><a href="Chap5.html"><i class="fa fa-check"></i><b>5</b> Graphical user interface</a>
<ul>
<li class="chapter" data-level="5.1" data-path="secGUI1.html"><a href="secGUI1.html"><i class="fa fa-check"></i><b>5.1</b> Introduction</a></li>
<li class="chapter" data-level="5.2" data-path="secGUI2.html"><a href="secGUI2.html"><i class="fa fa-check"></i><b>5.2</b> Univariate models</a></li>
<li class="chapter" data-level="5.3" data-path="secGUI3.html"><a href="secGUI3.html"><i class="fa fa-check"></i><b>5.3</b> Multivariate models</a></li>
<li class="chapter" data-level="5.4" data-path="secGUI4.html"><a href="secGUI4.html"><i class="fa fa-check"></i><b>5.4</b> Time series models</a></li>
<li class="chapter" data-level="5.5" data-path="secGUI5.html"><a href="secGUI5.html"><i class="fa fa-check"></i><b>5.5</b> Longitudinal/panel models</a></li>
<li class="chapter" data-level="5.6" data-path="secGUI6.html"><a href="secGUI6.html"><i class="fa fa-check"></i><b>5.6</b> Bayesian model averaging</a></li>
<li class="chapter" data-level="5.7" data-path="secGUI7.html"><a href="secGUI7.html"><i class="fa fa-check"></i><b>5.7</b> Help</a></li>
<li class="chapter" data-level="5.8" data-path="secGUI8.html"><a href="secGUI8.html"><i class="fa fa-check"></i><b>5.8</b> Warning</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="Chap6.html"><a href="Chap6.html"><i class="fa fa-check"></i><b>6</b> Univariate models</a>
<ul>
<li class="chapter" data-level="6.1" data-path="sec61.html"><a href="sec61.html"><i class="fa fa-check"></i><b>6.1</b> The Gaussian linear model</a></li>
<li class="chapter" data-level="6.2" data-path="sec62.html"><a href="sec62.html"><i class="fa fa-check"></i><b>6.2</b> The logit model</a></li>
<li class="chapter" data-level="6.3" data-path="sec63.html"><a href="sec63.html"><i class="fa fa-check"></i><b>6.3</b> The probit model</a></li>
<li class="chapter" data-level="6.4" data-path="sec64.html"><a href="sec64.html"><i class="fa fa-check"></i><b>6.4</b> The multinomial probit model</a></li>
<li class="chapter" data-level="6.5" data-path="sec65.html"><a href="sec65.html"><i class="fa fa-check"></i><b>6.5</b> The multinomial logit model</a></li>
<li class="chapter" data-level="6.6" data-path="sec66.html"><a href="sec66.html"><i class="fa fa-check"></i><b>6.6</b> Ordered probit model</a></li>
<li class="chapter" data-level="6.7" data-path="negative-binomial-model.html"><a href="negative-binomial-model.html"><i class="fa fa-check"></i><b>6.7</b> Negative binomial model</a></li>
<li class="chapter" data-level="6.8" data-path="sec68.html"><a href="sec68.html"><i class="fa fa-check"></i><b>6.8</b> Tobit model</a></li>
<li class="chapter" data-level="6.9" data-path="sec69.html"><a href="sec69.html"><i class="fa fa-check"></i><b>6.9</b> Quantile regression</a></li>
<li class="chapter" data-level="6.10" data-path="sec610.html"><a href="sec610.html"><i class="fa fa-check"></i><b>6.10</b> Bayesian bootstrap regression</a></li>
<li class="chapter" data-level="6.11" data-path="sec611.html"><a href="sec611.html"><i class="fa fa-check"></i><b>6.11</b> Summary</a></li>
<li class="chapter" data-level="6.12" data-path="sec612.html"><a href="sec612.html"><i class="fa fa-check"></i><b>6.12</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="Chap7.html"><a href="Chap7.html"><i class="fa fa-check"></i><b>7</b> Multivariate models</a>
<ul>
<li class="chapter" data-level="7.1" data-path="sec71.html"><a href="sec71.html"><i class="fa fa-check"></i><b>7.1</b> Multivariate regression</a></li>
<li class="chapter" data-level="7.2" data-path="sec72.html"><a href="sec72.html"><i class="fa fa-check"></i><b>7.2</b> Seemingly Unrelated Regression</a></li>
<li class="chapter" data-level="7.3" data-path="sec73.html"><a href="sec73.html"><i class="fa fa-check"></i><b>7.3</b> Instrumental variable</a></li>
<li class="chapter" data-level="7.4" data-path="sec74.html"><a href="sec74.html"><i class="fa fa-check"></i><b>7.4</b> Multivariate probit model</a></li>
<li class="chapter" data-level="7.5" data-path="sec75.html"><a href="sec75.html"><i class="fa fa-check"></i><b>7.5</b> Summary</a></li>
<li class="chapter" data-level="7.6" data-path="sec76.html"><a href="sec76.html"><i class="fa fa-check"></i><b>7.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="Chap8.html"><a href="Chap8.html"><i class="fa fa-check"></i><b>8</b> Time series models</a>
<ul>
<li class="chapter" data-level="8.1" data-path="sec81.html"><a href="sec81.html"><i class="fa fa-check"></i><b>8.1</b> State-space representation</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="sec81.html"><a href="sec81.html#gaussian-linear-state-space-models"><i class="fa fa-check"></i><b>8.1.1</b> Gaussian linear state-space models</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="sec82.html"><a href="sec82.html"><i class="fa fa-check"></i><b>8.2</b> ARMA processes</a></li>
<li class="chapter" data-level="8.3" data-path="sec83.html"><a href="sec83.html"><i class="fa fa-check"></i><b>8.3</b> Stochastic volatility models</a></li>
<li class="chapter" data-level="8.4" data-path="sec84.html"><a href="sec84.html"><i class="fa fa-check"></i><b>8.4</b> Vector Autoregressive models</a></li>
<li class="chapter" data-level="8.5" data-path="sec85.html"><a href="sec85.html"><i class="fa fa-check"></i><b>8.5</b> Summary</a></li>
<li class="chapter" data-level="8.6" data-path="sec86.html"><a href="sec86.html"><i class="fa fa-check"></i><b>8.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="Chap9.html"><a href="Chap9.html"><i class="fa fa-check"></i><b>9</b> Longitudinal/Panel data models</a>
<ul>
<li class="chapter" data-level="9.1" data-path="sec91.html"><a href="sec91.html"><i class="fa fa-check"></i><b>9.1</b> Normal model</a></li>
<li class="chapter" data-level="9.2" data-path="sec92.html"><a href="sec92.html"><i class="fa fa-check"></i><b>9.2</b> Logit model</a></li>
<li class="chapter" data-level="9.3" data-path="sec93.html"><a href="sec93.html"><i class="fa fa-check"></i><b>9.3</b> Poisson model</a></li>
<li class="chapter" data-level="9.4" data-path="sec94.html"><a href="sec94.html"><i class="fa fa-check"></i><b>9.4</b> Summary</a></li>
<li class="chapter" data-level="9.5" data-path="sec95.html"><a href="sec95.html"><i class="fa fa-check"></i><b>9.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="Chap10.html"><a href="Chap10.html"><i class="fa fa-check"></i><b>10</b> Bayesian model averaging</a>
<ul>
<li class="chapter" data-level="10.1" data-path="sec10_1.html"><a href="sec10_1.html"><i class="fa fa-check"></i><b>10.1</b> Foundation</a></li>
<li class="chapter" data-level="10.2" data-path="sec102.html"><a href="sec102.html"><i class="fa fa-check"></i><b>10.2</b> The Gaussian linear model</a></li>
<li class="chapter" data-level="10.3" data-path="sec103.html"><a href="sec103.html"><i class="fa fa-check"></i><b>10.3</b> Generalized linear models</a></li>
<li class="chapter" data-level="10.4" data-path="sec10_4.html"><a href="sec10_4.html"><i class="fa fa-check"></i><b>10.4</b> Calculating the marginal likelihood</a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="sec10_4.html"><a href="sec10_4.html#sec10_4_1"><i class="fa fa-check"></i><b>10.4.1</b> Savage-Dickey density ratio</a></li>
<li class="chapter" data-level="10.4.2" data-path="sec10_4.html"><a href="sec10_4.html#sec10_4_2"><i class="fa fa-check"></i><b>10.4.2</b> Chib’s methods</a></li>
<li class="chapter" data-level="10.4.3" data-path="sec10_4.html"><a href="sec10_4.html#sec10_4_3"><i class="fa fa-check"></i><b>10.4.3</b> Gelfand-Dey method</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="sec10_5.html"><a href="sec10_5.html"><i class="fa fa-check"></i><b>10.5</b> Summary</a></li>
<li class="chapter" data-level="10.6" data-path="sec10_6.html"><a href="sec10_6.html"><i class="fa fa-check"></i><b>10.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="Chap11.html"><a href="Chap11.html"><i class="fa fa-check"></i><b>11</b> Semi-parametric and non-parametric models</a>
<ul>
<li class="chapter" data-level="11.1" data-path="sec11_1.html"><a href="sec11_1.html"><i class="fa fa-check"></i><b>11.1</b> Mixture models</a>
<ul>
<li class="chapter" data-level="11.1.1" data-path="sec11_1.html"><a href="sec11_1.html#sec11_11"><i class="fa fa-check"></i><b>11.1.1</b> Finite Gaussian mixtures</a></li>
<li class="chapter" data-level="11.1.2" data-path="sec11_1.html"><a href="sec11_1.html#sec11_12"><i class="fa fa-check"></i><b>11.1.2</b> Direchlet processes</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="sec11_2.html"><a href="sec11_2.html"><i class="fa fa-check"></i><b>11.2</b> Splines</a></li>
<li class="chapter" data-level="11.3" data-path="sec11_3.html"><a href="sec11_3.html"><i class="fa fa-check"></i><b>11.3</b> Summary</a></li>
<li class="chapter" data-level="11.4" data-path="sec11_4.html"><a href="sec11_4.html"><i class="fa fa-check"></i><b>11.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="Chap12.html"><a href="Chap12.html"><i class="fa fa-check"></i><b>12</b> Bayesian machine learning</a>
<ul>
<li class="chapter" data-level="12.1" data-path="sec12_1.html"><a href="sec12_1.html"><i class="fa fa-check"></i><b>12.1</b> Cross-validation and Bayes factors</a></li>
<li class="chapter" data-level="12.2" data-path="sec12_2.html"><a href="sec12_2.html"><i class="fa fa-check"></i><b>12.2</b> Regularization</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="sec12_2.html"><a href="sec12_2.html#sec12_21"><i class="fa fa-check"></i><b>12.2.1</b> Bayesian LASSO</a></li>
<li class="chapter" data-level="12.2.2" data-path="sec12_2.html"><a href="sec12_2.html#sec12_22"><i class="fa fa-check"></i><b>12.2.2</b> Stochastic search variable selection</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="sec12_3.html"><a href="sec12_3.html"><i class="fa fa-check"></i><b>12.3</b> Bayesian additive regression trees</a></li>
<li class="chapter" data-level="12.4" data-path="sec12_4.html"><a href="sec12_4.html"><i class="fa fa-check"></i><b>12.4</b> Gaussian processes</a></li>
<li class="chapter" data-level="12.5" data-path="sec12_5.html"><a href="sec12_5.html"><i class="fa fa-check"></i><b>12.5</b> Tall data problems</a>
<ul>
<li class="chapter" data-level="12.5.1" data-path="sec12_5.html"><a href="sec12_5.html#sec12_51"><i class="fa fa-check"></i><b>12.5.1</b> Divide-and-conquer methods</a></li>
<li class="chapter" data-level="12.5.2" data-path="sec12_5.html"><a href="sec12_5.html#sec12_52"><i class="fa fa-check"></i><b>12.5.2</b> Subsampling-based algorithms</a></li>
</ul></li>
<li class="chapter" data-level="12.6" data-path="id_13_6.html"><a href="id_13_6.html"><i class="fa fa-check"></i><b>12.6</b> Summary</a></li>
<li class="chapter" data-level="12.7" data-path="id_13_7.html"><a href="id_13_7.html"><i class="fa fa-check"></i><b>12.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="Chap13.html"><a href="Chap13.html"><i class="fa fa-check"></i><b>13</b> Causal inference</a>
<ul>
<li class="chapter" data-level="13.1" data-path="sec13_1.html"><a href="sec13_1.html"><i class="fa fa-check"></i><b>13.1</b> Identification setting</a></li>
<li class="chapter" data-level="13.2" data-path="sec13_2.html"><a href="sec13_2.html"><i class="fa fa-check"></i><b>13.2</b> Randomized controlled trial (RCT)</a></li>
<li class="chapter" data-level="13.3" data-path="sec13_3.html"><a href="sec13_3.html"><i class="fa fa-check"></i><b>13.3</b> Conditional independence assumption (CIA)</a></li>
<li class="chapter" data-level="13.4" data-path="sec13_4.html"><a href="sec13_4.html"><i class="fa fa-check"></i><b>13.4</b> Instrumental variables (IV)</a></li>
<li class="chapter" data-level="13.5" data-path="sec13_5.html"><a href="sec13_5.html"><i class="fa fa-check"></i><b>13.5</b> Difference-in-differences design (DiD)</a>
<ul>
<li class="chapter" data-level="13.5.1" data-path="sec13_5.html"><a href="sec13_5.html#sec13_51"><i class="fa fa-check"></i><b>13.5.1</b> Classic DiD: two-group and two-period (<span class="math inline">\(2\times2\)</span>) setup</a></li>
<li class="chapter" data-level="13.5.2" data-path="sec13_5.html"><a href="sec13_5.html#sec13_52"><i class="fa fa-check"></i><b>13.5.2</b> Staggered (SDiD): G-group and T-period (<span class="math inline">\(G\times T\)</span>) setup</a></li>
</ul></li>
<li class="chapter" data-level="13.6" data-path="sec13_6.html"><a href="sec13_6.html"><i class="fa fa-check"></i><b>13.6</b> Regression discontinuity design (RD)</a>
<ul>
<li class="chapter" data-level="13.6.1" data-path="sec13_6.html"><a href="sec13_6.html#sec13_61"><i class="fa fa-check"></i><b>13.6.1</b> Sharp regression discontinuity design (SRD)</a></li>
<li class="chapter" data-level="13.6.2" data-path="sec13_6.html"><a href="sec13_6.html#sec13_62"><i class="fa fa-check"></i><b>13.6.2</b> Fuzzy regression discontinuity design (FRD)</a></li>
</ul></li>
<li class="chapter" data-level="13.7" data-path="sec13_7.html"><a href="sec13_7.html"><i class="fa fa-check"></i><b>13.7</b> Sample selection</a></li>
<li class="chapter" data-level="13.8" data-path="sec13_8.html"><a href="sec13_8.html"><i class="fa fa-check"></i><b>13.8</b> Bayesian exponentially tilted empirical likelihood</a></li>
<li class="chapter" data-level="13.9" data-path="sec13_9.html"><a href="sec13_9.html"><i class="fa fa-check"></i><b>13.9</b> General Bayes posteriors</a></li>
<li class="chapter" data-level="13.10" data-path="sec13_10.html"><a href="sec13_10.html"><i class="fa fa-check"></i><b>13.10</b> Doubly robust Bayesian inferential framework (DRB)</a></li>
<li class="chapter" data-level="13.11" data-path="sec13_11.html"><a href="sec13_11.html"><i class="fa fa-check"></i><b>13.11</b> Summary</a></li>
<li class="chapter" data-level="13.12" data-path="sec13_12.html"><a href="sec13_12.html"><i class="fa fa-check"></i><b>13.12</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="Chap14.html"><a href="Chap14.html"><i class="fa fa-check"></i><b>14</b> Approximate Bayesian methods</a>
<ul>
<li class="chapter" data-level="14.1" data-path="sec14_1.html"><a href="sec14_1.html"><i class="fa fa-check"></i><b>14.1</b> Simulation-based approaches</a>
<ul>
<li class="chapter" data-level="14.1.1" data-path="sec14_1.html"><a href="sec14_1.html#sec14_11"><i class="fa fa-check"></i><b>14.1.1</b> Approximate Bayesian computation</a></li>
<li class="chapter" data-level="14.1.2" data-path="sec14_1.html"><a href="sec14_1.html#sec14_12"><i class="fa fa-check"></i><b>14.1.2</b> Bayesian synthetic likelihood</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="sec14_2.html"><a href="sec14_2.html"><i class="fa fa-check"></i><b>14.2</b> Optimization approaches</a>
<ul>
<li class="chapter" data-level="14.2.1" data-path="sec14_2.html"><a href="sec14_2.html#sec14_21"><i class="fa fa-check"></i><b>14.2.1</b> Integrated nested Laplace approximations</a></li>
<li class="chapter" data-level="14.2.2" data-path="sec14_2.html"><a href="sec14_2.html#sec14_22"><i class="fa fa-check"></i><b>14.2.2</b> Variational Bayes</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="summary-1.html"><a href="summary-1.html"><i class="fa fa-check"></i><b>14.3</b> Summary</a></li>
<li class="chapter" data-level="14.4" data-path="sec14_4.html"><a href="sec14_4.html"><i class="fa fa-check"></i><b>14.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i>Appendix</a>
<ul>
<li class="chapter" data-level="" data-path="packages-and-commands-in-besmarter-gui.html"><a href="packages-and-commands-in-besmarter-gui.html"><i class="fa fa-check"></i>Packages and commands in BEsmarter GUI</a></li>
<li class="chapter" data-level="" data-path="datasets-templates-in-folder-datasim.html"><a href="datasets-templates-in-folder-datasim.html"><i class="fa fa-check"></i>Datasets templates in folder DataSim</a></li>
<li class="chapter" data-level="" data-path="real-datasets-in-folder-dataapp.html"><a href="real-datasets-in-folder-dataapp.html"><i class="fa fa-check"></i>Real datasets in folder DataApp</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to Bayesian Econometrics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="sec13_2" class="section level2 hasAnchor" number="13.2">
<h2><span class="header-section-number">13.2</span> Randomized controlled trial (RCT)<a href="sec13_2.html#sec13_2" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Two of the most relevant estimands in the causal inference literature are the average treatment effect (ATE),
<span class="math display">\[
\text{ATE} = \mathbb{E}[Y_i(1) - Y_i(0)],
\]</span>
and the average treatment effect on the treated (ATT),
<span class="math display">\[
\text{ATT} = \mathbb{E}[Y_i(1) - Y_i(0) \mid D_i = 1].
\]</span></p>
<p>However, these estimands are not directly identifiable without additional assumptions because we never observe the same unit under both treatment states simultaneously. Therefore, identification restrictions are required to express these causal quantities in terms of the observed data.</p>
<p>Note that the observed mean difference between treated and untreated units can be decomposed as:
<span class="math display">\[\begin{align*}
\mathbb{E}[Y_i \mid D_i = 1] - \mathbb{E}[Y_i \mid D_i = 0]
&amp; = \underbrace{\mathbb{E}[Y_i(1) - Y_i(0) \mid D_i = 1]}_{\text{ATT}}\\
&amp; + \underbrace{\Big( \mathbb{E}[Y_i(0) \mid D_i = 1] - \mathbb{E}[Y_i(0) \mid D_i = 0]\Big)}_{\textit{Selection Bias}},
\end{align*}\]</span></p>
<p>that is, the observed mean difference equals the ATT plus the <em>selection bias</em>, which captures the difference between the expected potential outcome of treated individuals had they not been treated (unobserved) and the expected outcome of untreated individuals (observed).</p>
<p>The sign of the selection bias depends on the nature of self-selection into treatment. Two illustrative examples are:</p>
<table>
<caption><span id="tab:1x1">Table 13.1: </span> Simple example of selection bias</caption>
<colgroup>
<col width="23%" />
<col width="29%" />
<col width="29%" />
<col width="17%" />
</colgroup>
<thead>
<tr class="header">
<th>Scenario</th>
<th align="center"><span class="math inline">\(\mathbb{E}[Y(0)\mid D=1]\)</span></th>
<th align="center"><span class="math inline">\(\mathbb{E}[Y(0)\mid D=0]\)</span></th>
<th align="center">Selection Bias</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><em>Training Program</em></td>
<td align="center">80</td>
<td align="center">70</td>
<td align="center">+10</td>
</tr>
<tr class="even">
<td><em>Remedial Education</em></td>
<td align="center">60</td>
<td align="center">70</td>
<td align="center">-10</td>
</tr>
</tbody>
</table>
<p>In the first scenario, motivated individuals self-select into a training program and would have higher earnings even without participation, producing a positive selection bias and causing the observed mean difference to overestimate the ATT. In the second scenario, disadvantaged individuals are more likely to enroll in a remedial education program and would have lower outcomes without the program, resulting in a negative selection bias and causing the observed mean difference to underestimate the ATT.</p>
<p>Note that if we assume that <em>assignment to treatment is random</em>,
<span class="math display">\[
\{ Y_i(1), Y_i(0) \} \perp D_i,
\]</span>
then the selection bias becomes zero,
<span class="math display">\[
\mathbb{E}[Y_i(0) \mid D_i = 1] - \mathbb{E}[Y_i(0) \mid D_i = 0] = 0,
\]</span>
which means there is no selection bias under random assignment.</p>
<p>Moreover, under random assignment, ATT equals ATE:
<span class="math display">\[
\tau = \underbrace{\mathbb{E}[Y_i(1)\mid D_i=1]-\mathbb{E}[Y_i(0)\mid D_i=1]}_{\text{ATT}}
= \underbrace{\mathbb{E}[Y_i(1)-Y_i(0)]}_{\text{ATE}}.
\]</span></p>
<p>Consequently,
<span class="math display">\[\begin{equation*}
\tau = \mathbb{E}[Y_i \mid D_i = 1] - \mathbb{E}[Y_i \mid D_i = 0],
\end{equation*}\]</span></p>
<p>that is, the average causal effect is a function of the data under random assignment to treatment.</p>
<p><em>Randomized controlled trials</em> (RCTs) are characterized by <em>random assignment to treatment</em>. The identification of causal effects in RCTs additionally relies on two key assumptions: <em>overlap</em>, which requires that every unit has a positive probability of being assigned to both treatment and control groups (<span class="math inline">\(0 &lt; P(D_i = 1) &lt; 1\)</span>), and the <em>Stable Unit Treatment Value Assumption</em> (SUTVA). The latter consists of two components: (i) <em>no interference</em>, meaning one unit’s potential outcome is unaffected by another unit’s treatment, and (ii) <em>consistency</em>, meaning the observed outcome equals the potential outcome corresponding to the received treatment.</p>
<p>We can represent the causal mechanism in an RCT using <em>causal diagrams</em> <span class="citation">(<a href="#ref-pearl1995causal">Pearl 1995</a>; <a href="#ref-pearl2018book">Pearl and Mackenzie 2018</a>)</span>. These diagrams provide a powerful framework for visualizing and analyzing the underlying structures that enable causal identification. It is important to note that causal diagrams do not impose specific functional forms, such as those assumed in linear regression models, and are closely related to structural equation models (SEMs). SEMs offer an alternative perspective on causal inference in econometrics, which is closely connected to the potential outcomes approach <span class="citation">(<a href="#ref-haavelmo1943statistical">Haavelmo 1943</a>; <a href="#ref-marschak1944random">Marschak and Andrews 1944</a>; <a href="#ref-imbens2014ivperspective">Guido W. Imbens 2014</a>)</span>.</p>
<p>In particular, we can depict the causal mechanism using a <em>Directed Acyclic Graph (DAG)</em>, which is a graphical representation of a set of variables and their assumed causal relationships. A DAG consists of <em>nodes</em>, representing variables, and <em>directed edges (arrows)</em>, representing direct causal effects from one variable to another. The graph is <em>acyclic</em>, meaning it contains no directed cycles: starting from any node and following the arrows, it is impossible to return to the same node. A defining property of causal DAGs is that, conditional on its direct causes, any variable on the DAG is independent of any other variable for which it is not a cause (<em>causal Markov assumption</em>). See <span class="citation">Hernán and Robins (<a href="#ref-hernan2020causal">2020</a>)</span> for a nice introduction, and the package <em>dagitty</em> in <strong>R</strong> software to perform visualization and analysis of DAGs. The following figure illustrates the causal structure underlying RCTs.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:unnamed-chunk-77"></span>
<img src="figures/FigChap13_1.png" alt="Directed Acyclic Graph (DAG) implied by a Randomized Controlled Trial (RCT)." width="200px" />
<p class="caption">
Figure 13.1: Directed Acyclic Graph (DAG) implied by a Randomized Controlled Trial (RCT).
</p>
</div>
<p>The counterfactual representation of the DAG, known as the <em>Single-World Intervention Graph</em> (SWIG), is shown in the following figure. In this figure, the treatment variable <span class="math inline">\(D\)</span> is split to reflect the intervention: we fix <span class="math inline">\(D\)</span> at a specific value <span class="math inline">\(d\)</span> (the intervention), and replace the outcome <span class="math inline">\(Y\)</span> with its counterfactual representation <span class="math inline">\(Y(d)\)</span>, which denotes the value of <span class="math inline">\(Y\)</span> if <span class="math inline">\(D\)</span> were set to <span class="math inline">\(d\)</span>. The natural value of <span class="math inline">\(D\)</span> is also shown but becomes irrelevant for the outcome once the intervention is imposed.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:unnamed-chunk-78"></span>
<img src="figures/FigChap13_2.png" alt="Single-World Intervention Graph (SWIG) for intervention $do(D=d)$: $Y$ is replaced by the counterfactual $Y(d)$, and $D$ is split into the fixed value $D=d$ and its natural value $D$. The dashed arrow indicates the fixed causal assignment." width="200px" />
<p class="caption">
Figure 13.2: Single-World Intervention Graph (SWIG) for intervention <span class="math inline">\(do(D=d)\)</span>: <span class="math inline">\(Y\)</span> is replaced by the counterfactual <span class="math inline">\(Y(d)\)</span>, and <span class="math inline">\(D\)</span> is split into the fixed value <span class="math inline">\(D=d\)</span> and its natural value <span class="math inline">\(D\)</span>. The dashed arrow indicates the fixed causal assignment.
</p>
</div>
<p>Note that we can express the observed outcome in terms of the potential outcomes as:
<span class="math display">\[
Y_i = [Y_i(1) - Y_i(0)] D_i + Y_i(0),
\]</span>
which shows that the observed outcome equals the control potential outcome plus the treatment effect if treated.</p>
<p>Under the assumption of a constant treatment effect and a linear <em>Conditional Expectation Function</em> (CEF) <span class="math inline">\(\mathbb{E}[Y_i\mid D_i]\)</span>, this relationship can be represented as a linear regression model <span class="citation">(<a href="#ref-angrist2009mostly">Angrist and Pischke 2009</a>)</span>:
<span class="math display">\[
Y_i = \underbrace{\beta_0}_{\mathbb{E}[Y_i(0)]}
+ \underbrace{\tau}_{\text{constant treatment effect}} D_i
+ \underbrace{\mu_i}_{Y_i(0) - \mathbb{E}[Y_i(0)]},
\]</span>
where <span class="math inline">\(\tau\)</span> represents the common treatment effect across all units.</p>
<p>Under random assignment, we have
<span class="math display">\[\begin{equation*}
\mathbb{E}[\mu_i \mid D_i] = \mathbb{E}[Y_i(0) \mid D_i] - \mathbb{E}[Y_i(0)]
= \mathbb{E}[Y_i(0)] - \mathbb{E}[Y_i(0)] = 0,
\end{equation*}\]</span></p>
<p>that is, the error term is <em>mean-independent of treatment status</em>. This implies that a regression of <span class="math inline">\(Y_i\)</span> on <span class="math inline">\(D_i\)</span> consistently estimates the causal effect under random assignment.</p>
<p><strong>Example: Simple example</strong></p>
<p>Bayesian inference for causal effects in a completely randomized experiment without covariates can be illustrated using the normal model in <span class="citation">Donald B. Rubin (<a href="#ref-rubin1990neyman">1990</a>)</span>. Assume that <span class="math inline">\(Y_i(d) \sim N(\mu_d, \sigma_d^2)\)</span> for <span class="math inline">\(d \in \{1,0\}\)</span>. Then, the likelihood function given a random sample and independent treatment assignment is:
<span class="math display">\[\begin{align*}
p(\mathbf{y} \mid \mathbf{d}; \mu_1,\mu_0,\sigma^2_1,\sigma^2_0)
&amp;= \prod_{i:d_i=1}\phi(y_i \mid \mu_1,\sigma_1^2) \prod_{i:d_i=0}\phi(y_i \mid \mu_0,\sigma_0^2) \\
&amp;= \prod_{i}\phi(y_i \mid \mu_1,\sigma_1^2)^{d_i} \, \phi(y_i \mid \mu_0,\sigma_0^2)^{1-d_i},
\end{align*}\]</span>
where <span class="math inline">\(\mathbf{y}\)</span> and <span class="math inline">\(\mathbf{d}\)</span> collect the observations of the outcomes and treatments, and <span class="math inline">\(\phi(\cdot)\)</span> denotes the normal density function.</p>
<p>Assume conjugate priors:
<span class="math display">\[
\mu_d \mid \sigma^2_d \sim N\left(\mu_{0d}, \frac{\sigma^2_d}{\beta_{0d}}\right),
\qquad
\sigma^2_d \sim IG\left(\frac{\alpha_{0d}}{2}, \frac{\delta_{0d}}{2}\right).
\]</span></p>
<p>From the normal/inverse-gamma model in Chapter <a href="Chap3.html#Chap3">3</a>, the posterior conditional distributions are:
<span class="math display">\[
\mu_d \mid \sigma^2_d, \{y_i,d_i\}_{i:d_i=d} \sim N \left(\mu_{nd}, \frac{\sigma^2_d}{\beta_{nd}}\right),
\]</span>
where
<span class="math display">\[
\mu_{nd} = \frac{\beta_{0d}\mu_{0d} + N_d \bar{y}_d}{\beta_{0d} + N_d},
\qquad
\beta_{nd} = \beta_{0d} + N_d,
\]</span>
<span class="math inline">\(\bar{y}_d\)</span> and <span class="math inline">\(N_d\)</span> denote the sample mean and sample size of group <span class="math inline">\(d\)</span>. For the variance:
<span class="math display">\[
\sigma^2_d \mid \{y_i,d_i\}_{i:d_i=d} \sim IG\left(\frac{\alpha_{nd}}{2}, \frac{\delta_{nd}}{2}\right),
\]</span>
where
<span class="math display">\[
\alpha_{nd} = \alpha_{0d} + N_d,
\qquad
\delta_{nd} = \sum_{i:d_i=d} (y_i-\bar{y}_d)^2 + \delta_{0d} + \frac{\beta_{0d}N_d}{\beta_{0d}+N_d}(\bar{y}_d-\mu_{0d})^2.
\]</span></p>
<p>In addition, the predictive distribution is given by
<span class="math display">\[
Y(d)\mid \mathbf{y}\sim t\left(\mu_{nd},\frac{(\beta_{nd}+1)\delta_{nd}}{\beta_{nd}\alpha_{nd}},\alpha_{nd}\right).
\]</span></p>
<p>Therefore, given the definition of the average treatment effect,
<span class="math display">\[\begin{align*}
\text{ATE} &amp; = \mathbb{E}[Y(1) - Y(0)]\\
&amp; = \mathbb{E}[Y(1)] - \mathbb{E}[Y(0)]\\
&amp; = \int_{\mathcal{R}} y(1) f_{Y(1)}(y(1))dy(1) - \int_{\mathcal{R}} y(0) f_{Y(0)}(y(0))dy(0)\\
&amp; = \mu_{1} - \mu_{0}.
\end{align*}\]</span></p>
<p>Note that this expectation is taken with respect to the population distribution of the potential outcomes, not with respect to the posterior distribution.<a href="#fn74" class="footnote-ref" id="fnref74"><sup>74</sup></a> Thus, the posterior distribution of the ATE is given by
<span class="math display">\[
\pi(\text{ATE}\mid \mathbf{y}) = \pi(\mu_{1} - \mu_{0}\mid \mathbf{y}).
\]</span></p>
<p>We can obtain this posterior distribution by simulation, because the difference of two independent Student’s <span class="math inline">\(t\)</span>-distributed random variables does not follow a Student’s <span class="math inline">\(t\)</span> distribution. However, as the degrees of freedom increase, each posterior distribution of <span class="math inline">\(\mu_{d}\)</span> converges to a normal distribution, and the difference of two normals is also normal. Consequently, an approximate point estimate of the ATE is <span class="math inline">\(\mu_{n1} - \mu_{n0}\)</span>, which asymptotically equals <span class="math inline">\(\bar{y}_1 - \bar{y}_0\)</span> under non-informative priors. This is the classical <em>estimator</em> of the ATE.</p>
<p>Finally, note that we can also obtain the posterior distribution of the ATE using the simple linear regression framework by assuming non-informative prior distributions, in which case the posterior mean of the slope parameter coincides with the maximum likelihood estimator (see Exercise 1).</p>
<p>Let’s assume that <span class="math inline">\(\mu_1 = 15\)</span>, <span class="math inline">\(\mu_0 = 10\)</span>, <span class="math inline">\(\sigma_1^2 = 4\)</span>, <span class="math inline">\(\sigma_0^2 = 2\)</span>, and <span class="math inline">\(N_1=N_0=100\)</span>, and compute the posterior distribution of the ATE. The following code illustrates this procedure, while the following figures display the predictive densities of the potential outcomes and the posterior distribution of the ATE. The posterior mean is 4.60, and the 95% credible interval is (4.10, 5.12). Note that the population value is <span class="math inline">\(\mu_1-\mu_0=5\)</span>.</p>
<div class="sourceCode" id="cb759"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb759-1"><a href="sec13_2.html#cb759-1" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">10101</span>)</span>
<span id="cb759-2"><a href="sec13_2.html#cb759-2" tabindex="-1"></a><span class="co"># Parameters</span></span>
<span id="cb759-3"><a href="sec13_2.html#cb759-3" tabindex="-1"></a>mu1 <span class="ot">&lt;-</span> <span class="dv">15</span>; mu0 <span class="ot">&lt;-</span> <span class="dv">10</span></span>
<span id="cb759-4"><a href="sec13_2.html#cb759-4" tabindex="-1"></a>sigma1 <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="dv">4</span>); sigma0 <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="dv">2</span>)</span>
<span id="cb759-5"><a href="sec13_2.html#cb759-5" tabindex="-1"></a>N1 <span class="ot">&lt;-</span> <span class="dv">100</span>; N0 <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb759-6"><a href="sec13_2.html#cb759-6" tabindex="-1"></a><span class="co"># Simulate data</span></span>
<span id="cb759-7"><a href="sec13_2.html#cb759-7" tabindex="-1"></a>y1 <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N1, mu1, sigma1); y0 <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N0, mu0, sigma0)</span>
<span id="cb759-8"><a href="sec13_2.html#cb759-8" tabindex="-1"></a><span class="co"># Prior hyperparameters</span></span>
<span id="cb759-9"><a href="sec13_2.html#cb759-9" tabindex="-1"></a>alpha0 <span class="ot">&lt;-</span> <span class="fl">0.01</span>; delta0 <span class="ot">&lt;-</span> <span class="fl">0.01</span></span>
<span id="cb759-10"><a href="sec13_2.html#cb759-10" tabindex="-1"></a>simulate_t <span class="ot">&lt;-</span> <span class="cf">function</span>(y) {</span>
<span id="cb759-11"><a href="sec13_2.html#cb759-11" tabindex="-1"></a>    N <span class="ot">&lt;-</span> <span class="fu">length</span>(y); ybar <span class="ot">&lt;-</span> <span class="fu">mean</span>(y)</span>
<span id="cb759-12"><a href="sec13_2.html#cb759-12" tabindex="-1"></a>    sse <span class="ot">&lt;-</span> <span class="fu">sum</span>((y <span class="sc">-</span> ybar)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb759-13"><a href="sec13_2.html#cb759-13" tabindex="-1"></a>    alpha_n <span class="ot">&lt;-</span> alpha0 <span class="sc">+</span> N; delta_n <span class="ot">&lt;-</span> sse <span class="sc">+</span> delta0</span>
<span id="cb759-14"><a href="sec13_2.html#cb759-14" tabindex="-1"></a>    scale2 <span class="ot">&lt;-</span> ((N <span class="sc">+</span> <span class="dv">1</span>) <span class="sc">*</span> delta_n) <span class="sc">/</span> (N <span class="sc">*</span> alpha_n)</span>
<span id="cb759-15"><a href="sec13_2.html#cb759-15" tabindex="-1"></a>    df <span class="ot">&lt;-</span> alpha_n</span>
<span id="cb759-16"><a href="sec13_2.html#cb759-16" tabindex="-1"></a>    loc <span class="ot">&lt;-</span> ybar; scale <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(scale2)</span>
<span id="cb759-17"><a href="sec13_2.html#cb759-17" tabindex="-1"></a>    <span class="fu">rt</span>(<span class="dv">1</span>, <span class="at">df =</span> df) <span class="sc">*</span> scale <span class="sc">+</span> loc</span>
<span id="cb759-18"><a href="sec13_2.html#cb759-18" tabindex="-1"></a>}</span>
<span id="cb759-19"><a href="sec13_2.html#cb759-19" tabindex="-1"></a><span class="co"># Posterior predictive draws</span></span>
<span id="cb759-20"><a href="sec13_2.html#cb759-20" tabindex="-1"></a>ppd1 <span class="ot">&lt;-</span> <span class="fu">replicate</span>(<span class="dv">1000</span>, <span class="fu">simulate_t</span>(y1))</span>
<span id="cb759-21"><a href="sec13_2.html#cb759-21" tabindex="-1"></a>ppd0 <span class="ot">&lt;-</span> <span class="fu">replicate</span>(<span class="dv">1000</span>, <span class="fu">simulate_t</span>(y0))</span>
<span id="cb759-22"><a href="sec13_2.html#cb759-22" tabindex="-1"></a><span class="co"># Plot</span></span>
<span id="cb759-23"><a href="sec13_2.html#cb759-23" tabindex="-1"></a><span class="fu">hist</span>(ppd1, <span class="at">col =</span> <span class="fu">rgb</span>(<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="fl">0.4</span>), <span class="at">freq =</span> <span class="cn">FALSE</span>, <span class="at">main =</span> <span class="st">&quot;Posterior Predictive&quot;</span>,</span>
<span id="cb759-24"><a href="sec13_2.html#cb759-24" tabindex="-1"></a><span class="at">xlab =</span> <span class="st">&quot;Y&quot;</span>, <span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">5</span>, <span class="dv">25</span>))</span>
<span id="cb759-25"><a href="sec13_2.html#cb759-25" tabindex="-1"></a><span class="fu">hist</span>(ppd0, <span class="at">col =</span> <span class="fu">rgb</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="fl">0.4</span>), <span class="at">freq =</span> <span class="cn">FALSE</span>, <span class="at">add =</span> <span class="cn">TRUE</span>)</span>
<span id="cb759-26"><a href="sec13_2.html#cb759-26" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;topright&quot;</span>, <span class="at">legend =</span> <span class="fu">c</span>(<span class="st">&quot;Treatment&quot;</span>, <span class="st">&quot;Control&quot;</span>),</span>
<span id="cb759-27"><a href="sec13_2.html#cb759-27" tabindex="-1"></a><span class="at">fill =</span> <span class="fu">c</span>(<span class="fu">rgb</span>(<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="fl">0.4</span>), <span class="fu">rgb</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="fl">0.4</span>)))</span></code></pre></div>
<p><img src="BayesianEconometrics_files/figure-html/unnamed-chunk-79-1.svg" width="672" /></p>
<div class="sourceCode" id="cb760"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb760-1"><a href="sec13_2.html#cb760-1" tabindex="-1"></a><span class="co"># Posterior distribution of ATE</span></span>
<span id="cb760-2"><a href="sec13_2.html#cb760-2" tabindex="-1"></a>posterior_mu <span class="ot">&lt;-</span> <span class="cf">function</span>(y) {</span>
<span id="cb760-3"><a href="sec13_2.html#cb760-3" tabindex="-1"></a>    N <span class="ot">&lt;-</span> <span class="fu">length</span>(y); ybar <span class="ot">&lt;-</span> <span class="fu">mean</span>(y)</span>
<span id="cb760-4"><a href="sec13_2.html#cb760-4" tabindex="-1"></a>    sse <span class="ot">&lt;-</span> <span class="fu">sum</span>((y <span class="sc">-</span> ybar)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb760-5"><a href="sec13_2.html#cb760-5" tabindex="-1"></a>    alpha_n <span class="ot">&lt;-</span> alpha0 <span class="sc">+</span> N</span>
<span id="cb760-6"><a href="sec13_2.html#cb760-6" tabindex="-1"></a>    delta_n <span class="ot">&lt;-</span> sse <span class="sc">+</span> delta0</span>
<span id="cb760-7"><a href="sec13_2.html#cb760-7" tabindex="-1"></a>    <span class="co"># Posterior variance for mean</span></span>
<span id="cb760-8"><a href="sec13_2.html#cb760-8" tabindex="-1"></a>    var_mu <span class="ot">&lt;-</span> delta_n <span class="sc">/</span> (alpha_n <span class="sc">*</span> N)</span>
<span id="cb760-9"><a href="sec13_2.html#cb760-9" tabindex="-1"></a>    df <span class="ot">&lt;-</span> alpha_n</span>
<span id="cb760-10"><a href="sec13_2.html#cb760-10" tabindex="-1"></a>    loc <span class="ot">&lt;-</span> ybar; scale <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(var_mu)</span>
<span id="cb760-11"><a href="sec13_2.html#cb760-11" tabindex="-1"></a>    <span class="fu">rt</span>(<span class="dv">1</span>, <span class="at">df =</span> df) <span class="sc">*</span> scale <span class="sc">+</span> loc</span>
<span id="cb760-12"><a href="sec13_2.html#cb760-12" tabindex="-1"></a>}</span>
<span id="cb760-13"><a href="sec13_2.html#cb760-13" tabindex="-1"></a><span class="co"># Posterior draws for parameters</span></span>
<span id="cb760-14"><a href="sec13_2.html#cb760-14" tabindex="-1"></a>n_draws <span class="ot">&lt;-</span> <span class="dv">10000</span></span>
<span id="cb760-15"><a href="sec13_2.html#cb760-15" tabindex="-1"></a>mu1_draws <span class="ot">&lt;-</span> <span class="fu">replicate</span>(n_draws, <span class="fu">posterior_mu</span>(y1))</span>
<span id="cb760-16"><a href="sec13_2.html#cb760-16" tabindex="-1"></a>mu0_draws <span class="ot">&lt;-</span> <span class="fu">replicate</span>(n_draws, <span class="fu">posterior_mu</span>(y0))</span>
<span id="cb760-17"><a href="sec13_2.html#cb760-17" tabindex="-1"></a><span class="co"># Parameter uncertainty: difference of means</span></span>
<span id="cb760-18"><a href="sec13_2.html#cb760-18" tabindex="-1"></a>ate_draws <span class="ot">&lt;-</span> mu1_draws <span class="sc">-</span> mu0_draws</span>
<span id="cb760-19"><a href="sec13_2.html#cb760-19" tabindex="-1"></a><span class="fu">summary</span>(coda<span class="sc">::</span><span class="fu">mcmc</span>(ate_draws))</span></code></pre></div>
<pre><code>## 
## Iterations = 1:10000
## Thinning interval = 1 
## Number of chains = 1 
## Sample size per chain = 10000 
## 
## 1. Empirical mean and standard deviation for each variable,
##    plus standard error of the mean:
## 
##           Mean             SD       Naive SE Time-series SE 
##       4.607604       0.255213       0.002552       0.002552 
## 
## 2. Quantiles for each variable:
## 
##  2.5%   25%   50%   75% 97.5% 
## 4.100 4.440 4.604 4.778 5.117</code></pre>
<div class="sourceCode" id="cb762"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb762-1"><a href="sec13_2.html#cb762-1" tabindex="-1"></a><span class="co"># Summaries</span></span>
<span id="cb762-2"><a href="sec13_2.html#cb762-2" tabindex="-1"></a>ate_mean <span class="ot">&lt;-</span> <span class="fu">mean</span>(ate_draws)</span>
<span id="cb762-3"><a href="sec13_2.html#cb762-3" tabindex="-1"></a>ci <span class="ot">&lt;-</span> <span class="fu">quantile</span>(ate_draws, <span class="fu">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>))</span>
<span id="cb762-4"><a href="sec13_2.html#cb762-4" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">&quot;Posterior mean of ATE:&quot;</span>, ate_mean, <span class="st">&quot;</span><span class="sc">\n</span><span class="st">&quot;</span>)</span></code></pre></div>
<pre><code>## Posterior mean of ATE: 4.607604</code></pre>
<div class="sourceCode" id="cb764"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb764-1"><a href="sec13_2.html#cb764-1" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">&quot;95% Credible Interval:&quot;</span>, ci, <span class="st">&quot;</span><span class="sc">\n</span><span class="st">&quot;</span>)</span></code></pre></div>
<pre><code>## 95% Credible Interval: 4.100032 5.116916</code></pre>
<div class="sourceCode" id="cb766"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb766-1"><a href="sec13_2.html#cb766-1" tabindex="-1"></a><span class="co"># Plot posterior distribution of ATE</span></span>
<span id="cb766-2"><a href="sec13_2.html#cb766-2" tabindex="-1"></a><span class="fu">hist</span>(ate_draws, <span class="at">breaks =</span> <span class="dv">50</span>, <span class="at">freq =</span> <span class="cn">FALSE</span>,</span>
<span id="cb766-3"><a href="sec13_2.html#cb766-3" tabindex="-1"></a><span class="at">main =</span> <span class="st">&quot;Posterior Distribution of ATE&quot;</span>,</span>
<span id="cb766-4"><a href="sec13_2.html#cb766-4" tabindex="-1"></a><span class="at">xlab =</span> <span class="st">&quot;ATE (Y(1) - Y(0))&quot;</span>, <span class="at">col =</span> <span class="st">&quot;lightblue&quot;</span>, <span class="at">border =</span> <span class="st">&quot;white&quot;</span>)</span>
<span id="cb766-5"><a href="sec13_2.html#cb766-5" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> ate_mean, <span class="at">col =</span> <span class="st">&quot;red&quot;</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb766-6"><a href="sec13_2.html#cb766-6" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> ci, <span class="at">col =</span> <span class="st">&quot;darkgreen&quot;</span>, <span class="at">lty =</span> <span class="dv">2</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb766-7"><a href="sec13_2.html#cb766-7" tabindex="-1"></a></span>
<span id="cb766-8"><a href="sec13_2.html#cb766-8" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;topright&quot;</span>, <span class="at">legend =</span> <span class="fu">c</span>(<span class="st">&quot;Posterior Mean&quot;</span>, <span class="st">&quot;95% Credible Interval&quot;</span>), <span class="at">col =</span> <span class="fu">c</span>(<span class="st">&quot;red&quot;</span>, <span class="st">&quot;darkgreen&quot;</span>), <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">lty =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>), <span class="at">bty =</span> <span class="st">&quot;n&quot;</span>, <span class="at">cex =</span> <span class="fl">0.8</span>)  <span class="co"># Smaller legend using cex</span></span></code></pre></div>
<p><img src="BayesianEconometrics_files/figure-html/unnamed-chunk-79-2.svg" width="672" /></p>
<p>An RCT is considered the gold standard for identifying causal effects because it provides the strongest basis for satisfying the key identification assumption in causal inference: <em>independence between treatment assignment and potential outcomes</em>. However, RCTs may face challenges such as <em>non-compliance</em>, which occurs when individuals do not adhere to their assigned treatment in an experimental study. This matters because, in many real-world settings, some individuals do not take the treatment they were assigned, leading to deviations from the ideal randomized controlled trial design. In addition, RCTs are sometimes infeasible due to ethical, logistical, or financial constraints. Moreover, they can be too narrowly focused or localized to provide general conclusions about what works <span class="citation">(<a href="#ref-deaton2010instruments">Deaton 2010</a>)</span>. Thus, the <em>external validity</em> of causal effects from RCTs may be questionable.</p>
<p>It is also important to note that RCTs primarily identify the mean of the treatment effect distribution but do not capture other features, such as the median or higher-order moments. These additional aspects of the distribution of treatment effects can be highly relevant for policymakers and stakeholders. See <span class="citation">Deaton (<a href="#ref-deaton2010instruments">2010</a>)</span> for a detailed discussion of other potential shortcomings of RCTs.</p>
</div>
<h3>References<a href="references.html#references" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-angrist2009mostly" class="csl-entry">
Angrist, Joshua D., and Jörn-Steffen Pischke. 2009. <em>Mostly Harmless Econometrics: An Empiricist’s Companion</em>. Princeton, NJ: Princeton University Press.
</div>
<div id="ref-deaton2010instruments" class="csl-entry">
Deaton, Angus. 2010. <span>“Instruments, Randomization, and Learning about Development.”</span> <em>Journal of Economic Literature</em> 48 (2): 424–55. <a href="https://doi.org/10.1257/jel.48.2.424">https://doi.org/10.1257/jel.48.2.424</a>.
</div>
<div id="ref-haavelmo1943statistical" class="csl-entry">
Haavelmo, Trygve. 1943. <span>“The Statistical Implications of a System of Simultaneous Equations.”</span> <em>Econometrica</em> 11 (1): 1–12. <a href="https://doi.org/10.2307/1905714">https://doi.org/10.2307/1905714</a>.
</div>
<div id="ref-hernan2020causal" class="csl-entry">
Hernán, Miguel A., and James M. Robins. 2020. <em>Causal Inference: What If</em>. Boca Raton, FL: Chapman &amp; Hall/CRC. <a href="https://www.hsph.harvard.edu/miguel-hernan/causal-inference-book/">https://www.hsph.harvard.edu/miguel-hernan/causal-inference-book/</a>.
</div>
<div id="ref-imbens2014ivperspective" class="csl-entry">
Imbens, Guido W. 2014. <span>“Instrumental Variables: An Econometrician’s Perspective.”</span> <em>Statistical Science</em> 29 (3): 323–58. <a href="https://doi.org/10.1214/14-STS480">https://doi.org/10.1214/14-STS480</a>.
</div>
<div id="ref-marschak1944random" class="csl-entry">
Marschak, Jacob, and William H. Andrews. 1944. <span>“Random Simultaneous Equations and the Theory of Production.”</span> <em>Econometrica</em> 12 (3-4): 143–205. <a href="https://doi.org/10.2307/1905494">https://doi.org/10.2307/1905494</a>.
</div>
<div id="ref-pearl1995causal" class="csl-entry">
Pearl, Judea. 1995. <span>“Causal Diagrams for Empirical Research.”</span> <em>Biometrika</em> 82 (4): 669–710. <a href="https://doi.org/10.1093/biomet/82.4.669">https://doi.org/10.1093/biomet/82.4.669</a>.
</div>
<div id="ref-pearl2018book" class="csl-entry">
Pearl, Judea, and Dana Mackenzie. 2018. <em>The Book of Why: The New Science of Cause and Effect</em>. New York: Basic Books.
</div>
<div id="ref-rubin1990neyman" class="csl-entry">
———. 1990. <span>“Neyman (1923) and Causal Inference in Experiments and Observational Studies.”</span> <em>Statistical Science</em> 5 (4): 472–80. <a href="https://doi.org/10.1214/ss/1177012032">https://doi.org/10.1214/ss/1177012032</a>.
</div>
</div>
<div class="footnotes">
<hr />
<ol start="74">
<li id="fn74"><p>Other functions of the potential outcomes, such as <span class="math inline">\(P(Y(1)\geq Y(0))\)</span>, require the joint distribution of the potential outcomes rather than just the marginal distributions, as is the case for the ATE.<a href="sec13_2.html#fnref74" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="sec13_1.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="sec13_3.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": true,
    "facebook": true,
    "twitter": true,
    "linkedin": false,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": false,
    "all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
  },
  "fontsettings": {
    "theme": "white",
    "family": "sans",
    "size": 2
  },
  "edit": {
    "link": "https://github.com/aramir21/IntroductionBayesianEconometricsBook/10-Diagnostics.Rmd",
    "text": "Edit"
  },
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": null,
    "text": null
  },
  "download": null,
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "subsection"
  }
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
