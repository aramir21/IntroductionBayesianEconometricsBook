<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>13.7 Sample selection | Introduction to Bayesian Econometrics</title>
  <meta name="description" content="The subject of this textbook is Bayesian data modeling, with the primary aim of providing an introduction to its theoretical foundations and facilitating the application of Bayesian inference using a GUI." />
  <meta name="generator" content="bookdown 0.43 and GitBook 2.6.7" />

  <meta property="og:title" content="13.7 Sample selection | Introduction to Bayesian Econometrics" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="The subject of this textbook is Bayesian data modeling, with the primary aim of providing an introduction to its theoretical foundations and facilitating the application of Bayesian inference using a GUI." />
  <meta name="github-repo" content="https://github.com/aramir21/IntroductionBayesianEconometricsBook" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="13.7 Sample selection | Introduction to Bayesian Econometrics" />
  
  <meta name="twitter:description" content="The subject of this textbook is Bayesian data modeling, with the primary aim of providing an introduction to its theoretical foundations and facilitating the application of Bayesian inference using a GUI." />
  

<meta name="author" content="Andrés Ramírez-Hassan" />


<meta name="date" content="2025-09-17" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="sec_7.html"/>
<link rel="next" href="sec12_9.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Introduction to Bayesian Econometrics: A GUIded tour using R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction</a>
<ul>
<li class="chapter" data-level="" data-path="to-instructors-and-students.html"><a href="to-instructors-and-students.html"><i class="fa fa-check"></i>To instructors and students</a></li>
<li class="chapter" data-level="" data-path="acknowledgments.html"><a href="acknowledgments.html"><i class="fa fa-check"></i>Acknowledgments</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="Chap1.html"><a href="Chap1.html"><i class="fa fa-check"></i><b>1</b> Basic formal concepts</a>
<ul>
<li class="chapter" data-level="1.1" data-path="sec11.html"><a href="sec11.html"><i class="fa fa-check"></i><b>1.1</b> The Bayes’ rule</a></li>
<li class="chapter" data-level="1.2" data-path="sec12.html"><a href="sec12.html"><i class="fa fa-check"></i><b>1.2</b> Bayesian framework: A brief summary of theory</a></li>
<li class="chapter" data-level="1.3" data-path="sec14.html"><a href="sec14.html"><i class="fa fa-check"></i><b>1.3</b> Bayesian reports: Decision theory under uncertainty</a></li>
<li class="chapter" data-level="1.4" data-path="summary.html"><a href="summary.html"><i class="fa fa-check"></i><b>1.4</b> Summary</a></li>
<li class="chapter" data-level="1.5" data-path="exercises.html"><a href="exercises.html"><i class="fa fa-check"></i><b>1.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="Chap2.html"><a href="Chap2.html"><i class="fa fa-check"></i><b>2</b> Conceptual differences between the Bayesian and Frequentist approaches</a>
<ul>
<li class="chapter" data-level="2.1" data-path="sec21.html"><a href="sec21.html"><i class="fa fa-check"></i><b>2.1</b> The concept of probability</a></li>
<li class="chapter" data-level="2.2" data-path="sec22.html"><a href="sec22.html"><i class="fa fa-check"></i><b>2.2</b> Subjectivity is not the key</a></li>
<li class="chapter" data-level="2.3" data-path="sec23.html"><a href="sec23.html"><i class="fa fa-check"></i><b>2.3</b> Estimation, hypothesis testing and prediction</a></li>
<li class="chapter" data-level="2.4" data-path="sec24.html"><a href="sec24.html"><i class="fa fa-check"></i><b>2.4</b> The likelihood principle</a></li>
<li class="chapter" data-level="2.5" data-path="sec25.html"><a href="sec25.html"><i class="fa fa-check"></i><b>2.5</b> Why is not the Bayesian approach that popular?</a></li>
<li class="chapter" data-level="2.6" data-path="sec26.html"><a href="sec26.html"><i class="fa fa-check"></i><b>2.6</b> A simple working example</a></li>
<li class="chapter" data-level="2.7" data-path="sec27.html"><a href="sec27.html"><i class="fa fa-check"></i><b>2.7</b> Summary</a></li>
<li class="chapter" data-level="2.8" data-path="sec28.html"><a href="sec28.html"><i class="fa fa-check"></i><b>2.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="Chap3.html"><a href="Chap3.html"><i class="fa fa-check"></i><b>3</b> Cornerstone models: Conjugate families</a>
<ul>
<li class="chapter" data-level="3.1" data-path="sec41.html"><a href="sec41.html"><i class="fa fa-check"></i><b>3.1</b> Motivation of conjugate families</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="sec41.html"><a href="sec41.html#examples-of-exponential-family-distributions"><i class="fa fa-check"></i><b>3.1.1</b> Examples of exponential family distributions</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="sec42.html"><a href="sec42.html"><i class="fa fa-check"></i><b>3.2</b> Conjugate prior to exponential family</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="sec42.html"><a href="sec42.html#sec421"><i class="fa fa-check"></i><b>3.2.1</b> Examples: Theorem 4.2.1</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="sec43.html"><a href="sec43.html"><i class="fa fa-check"></i><b>3.3</b> Linear regression: The conjugate normal-normal/inverse gamma model</a></li>
<li class="chapter" data-level="3.4" data-path="sec44.html"><a href="sec44.html"><i class="fa fa-check"></i><b>3.4</b> Multivariate linear regression: The conjugate normal-normal/inverse Wishart model</a></li>
<li class="chapter" data-level="3.5" data-path="sec45.html"><a href="sec45.html"><i class="fa fa-check"></i><b>3.5</b> Summary</a></li>
<li class="chapter" data-level="3.6" data-path="sec46.html"><a href="sec46.html"><i class="fa fa-check"></i><b>3.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="Chap4.html"><a href="Chap4.html"><i class="fa fa-check"></i><b>4</b> Simulation methods</a>
<ul>
<li class="chapter" data-level="4.1" data-path="sec51.html"><a href="sec51.html"><i class="fa fa-check"></i><b>4.1</b> Markov Chain Monte Carlo methods</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="sec51.html"><a href="sec51.html#sec511"><i class="fa fa-check"></i><b>4.1.1</b> Gibbs sampler</a></li>
<li class="chapter" data-level="4.1.2" data-path="sec51.html"><a href="sec51.html#sec512"><i class="fa fa-check"></i><b>4.1.2</b> Metropolis-Hastings</a></li>
<li class="chapter" data-level="4.1.3" data-path="sec51.html"><a href="sec51.html#sec513"><i class="fa fa-check"></i><b>4.1.3</b> Hamiltonian Monte Carlo</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="sec52.html"><a href="sec52.html"><i class="fa fa-check"></i><b>4.2</b> Importance sampling</a></li>
<li class="chapter" data-level="4.3" data-path="sec53.html"><a href="sec53.html"><i class="fa fa-check"></i><b>4.3</b> Particle filtering</a></li>
<li class="chapter" data-level="4.4" data-path="sec54.html"><a href="sec54.html"><i class="fa fa-check"></i><b>4.4</b> Convergence diagnostics</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="sec54.html"><a href="sec54.html#numerical-standard-error"><i class="fa fa-check"></i><b>4.4.1</b> Numerical standard error</a></li>
<li class="chapter" data-level="4.4.2" data-path="sec54.html"><a href="sec54.html#effective-number-of-simulation-draws"><i class="fa fa-check"></i><b>4.4.2</b> Effective number of simulation draws</a></li>
<li class="chapter" data-level="4.4.3" data-path="sec54.html"><a href="sec54.html#tests-of-convergence"><i class="fa fa-check"></i><b>4.4.3</b> Tests of convergence</a></li>
<li class="chapter" data-level="4.4.4" data-path="sec54.html"><a href="sec54.html#checking-for-errors-in-the-posterior-simulator"><i class="fa fa-check"></i><b>4.4.4</b> Checking for errors in the posterior simulator</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="sec55.html"><a href="sec55.html"><i class="fa fa-check"></i><b>4.5</b> Summary</a></li>
<li class="chapter" data-level="4.6" data-path="sec56.html"><a href="sec56.html"><i class="fa fa-check"></i><b>4.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="Chap5.html"><a href="Chap5.html"><i class="fa fa-check"></i><b>5</b> Graphical user interface</a>
<ul>
<li class="chapter" data-level="5.1" data-path="secGUI1.html"><a href="secGUI1.html"><i class="fa fa-check"></i><b>5.1</b> Introduction</a></li>
<li class="chapter" data-level="5.2" data-path="secGUI2.html"><a href="secGUI2.html"><i class="fa fa-check"></i><b>5.2</b> Univariate models</a></li>
<li class="chapter" data-level="5.3" data-path="secGUI3.html"><a href="secGUI3.html"><i class="fa fa-check"></i><b>5.3</b> Multivariate models</a></li>
<li class="chapter" data-level="5.4" data-path="secGUI4.html"><a href="secGUI4.html"><i class="fa fa-check"></i><b>5.4</b> Time series models</a></li>
<li class="chapter" data-level="5.5" data-path="secGUI5.html"><a href="secGUI5.html"><i class="fa fa-check"></i><b>5.5</b> Longitudinal/panel models</a></li>
<li class="chapter" data-level="5.6" data-path="secGUI6.html"><a href="secGUI6.html"><i class="fa fa-check"></i><b>5.6</b> Bayesian model average</a></li>
<li class="chapter" data-level="5.7" data-path="secGUI7.html"><a href="secGUI7.html"><i class="fa fa-check"></i><b>5.7</b> Help</a></li>
<li class="chapter" data-level="5.8" data-path="secGUI8.html"><a href="secGUI8.html"><i class="fa fa-check"></i><b>5.8</b> Warning</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="Chap6.html"><a href="Chap6.html"><i class="fa fa-check"></i><b>6</b> Univariate regression</a>
<ul>
<li class="chapter" data-level="6.1" data-path="sec61.html"><a href="sec61.html"><i class="fa fa-check"></i><b>6.1</b> The Gaussian linear model</a></li>
<li class="chapter" data-level="6.2" data-path="sec62.html"><a href="sec62.html"><i class="fa fa-check"></i><b>6.2</b> The logit model</a></li>
<li class="chapter" data-level="6.3" data-path="sec63.html"><a href="sec63.html"><i class="fa fa-check"></i><b>6.3</b> The probit model</a></li>
<li class="chapter" data-level="6.4" data-path="sec64.html"><a href="sec64.html"><i class="fa fa-check"></i><b>6.4</b> The multinomial probit model</a></li>
<li class="chapter" data-level="6.5" data-path="sec65.html"><a href="sec65.html"><i class="fa fa-check"></i><b>6.5</b> The multinomial logit model</a></li>
<li class="chapter" data-level="6.6" data-path="sec66.html"><a href="sec66.html"><i class="fa fa-check"></i><b>6.6</b> Ordered probit model</a></li>
<li class="chapter" data-level="6.7" data-path="negative-binomial-model.html"><a href="negative-binomial-model.html"><i class="fa fa-check"></i><b>6.7</b> Negative binomial model</a></li>
<li class="chapter" data-level="6.8" data-path="sec68.html"><a href="sec68.html"><i class="fa fa-check"></i><b>6.8</b> Tobit model</a></li>
<li class="chapter" data-level="6.9" data-path="sec69.html"><a href="sec69.html"><i class="fa fa-check"></i><b>6.9</b> Quantile regression</a></li>
<li class="chapter" data-level="6.10" data-path="sec610.html"><a href="sec610.html"><i class="fa fa-check"></i><b>6.10</b> Bayesian bootstrap regression</a></li>
<li class="chapter" data-level="6.11" data-path="sec611.html"><a href="sec611.html"><i class="fa fa-check"></i><b>6.11</b> Summary</a></li>
<li class="chapter" data-level="6.12" data-path="sec612.html"><a href="sec612.html"><i class="fa fa-check"></i><b>6.12</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="Chap7.html"><a href="Chap7.html"><i class="fa fa-check"></i><b>7</b> Multivariate regression</a>
<ul>
<li class="chapter" data-level="7.1" data-path="sec71.html"><a href="sec71.html"><i class="fa fa-check"></i><b>7.1</b> Multivariate regression</a></li>
<li class="chapter" data-level="7.2" data-path="sec72.html"><a href="sec72.html"><i class="fa fa-check"></i><b>7.2</b> Seemingly Unrelated Regression</a></li>
<li class="chapter" data-level="7.3" data-path="sec73.html"><a href="sec73.html"><i class="fa fa-check"></i><b>7.3</b> Instrumental variable</a></li>
<li class="chapter" data-level="7.4" data-path="sec74.html"><a href="sec74.html"><i class="fa fa-check"></i><b>7.4</b> Multivariate probit model</a></li>
<li class="chapter" data-level="7.5" data-path="sec75.html"><a href="sec75.html"><i class="fa fa-check"></i><b>7.5</b> Summary</a></li>
<li class="chapter" data-level="7.6" data-path="sec76.html"><a href="sec76.html"><i class="fa fa-check"></i><b>7.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="Chap8.html"><a href="Chap8.html"><i class="fa fa-check"></i><b>8</b> Time series</a>
<ul>
<li class="chapter" data-level="8.1" data-path="sec81.html"><a href="sec81.html"><i class="fa fa-check"></i><b>8.1</b> State-space representation</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="sec81.html"><a href="sec81.html#gaussian-linear-state-space-models"><i class="fa fa-check"></i><b>8.1.1</b> Gaussian linear state-space models</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="sec82.html"><a href="sec82.html"><i class="fa fa-check"></i><b>8.2</b> ARMA processes</a></li>
<li class="chapter" data-level="8.3" data-path="sec83.html"><a href="sec83.html"><i class="fa fa-check"></i><b>8.3</b> Stochastic volatility models</a></li>
<li class="chapter" data-level="8.4" data-path="sec84.html"><a href="sec84.html"><i class="fa fa-check"></i><b>8.4</b> Vector Autoregressive models</a></li>
<li class="chapter" data-level="8.5" data-path="sec85.html"><a href="sec85.html"><i class="fa fa-check"></i><b>8.5</b> Summary</a></li>
<li class="chapter" data-level="8.6" data-path="sec86.html"><a href="sec86.html"><i class="fa fa-check"></i><b>8.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="Chap9.html"><a href="Chap9.html"><i class="fa fa-check"></i><b>9</b> Longitudinal regression</a>
<ul>
<li class="chapter" data-level="9.1" data-path="sec91.html"><a href="sec91.html"><i class="fa fa-check"></i><b>9.1</b> Normal model</a></li>
<li class="chapter" data-level="9.2" data-path="sec92.html"><a href="sec92.html"><i class="fa fa-check"></i><b>9.2</b> Logit model</a></li>
<li class="chapter" data-level="9.3" data-path="sec93.html"><a href="sec93.html"><i class="fa fa-check"></i><b>9.3</b> Poisson model</a></li>
<li class="chapter" data-level="9.4" data-path="sec94.html"><a href="sec94.html"><i class="fa fa-check"></i><b>9.4</b> Summary</a></li>
<li class="chapter" data-level="9.5" data-path="sec95.html"><a href="sec95.html"><i class="fa fa-check"></i><b>9.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="Chap10.html"><a href="Chap10.html"><i class="fa fa-check"></i><b>10</b> Bayesian model averaging in variable selection</a>
<ul>
<li class="chapter" data-level="10.1" data-path="sec10_1.html"><a href="sec10_1.html"><i class="fa fa-check"></i><b>10.1</b> Foundation</a></li>
<li class="chapter" data-level="10.2" data-path="sec102.html"><a href="sec102.html"><i class="fa fa-check"></i><b>10.2</b> The Gaussian linear model</a></li>
<li class="chapter" data-level="10.3" data-path="sec103.html"><a href="sec103.html"><i class="fa fa-check"></i><b>10.3</b> Generalized linear models</a></li>
<li class="chapter" data-level="10.4" data-path="sec10_4.html"><a href="sec10_4.html"><i class="fa fa-check"></i><b>10.4</b> Calculating the marginal likelihood</a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="sec10_4.html"><a href="sec10_4.html#sec10_4_1"><i class="fa fa-check"></i><b>10.4.1</b> Savage-Dickey density ratio</a></li>
<li class="chapter" data-level="10.4.2" data-path="sec10_4.html"><a href="sec10_4.html#sec10_4_2"><i class="fa fa-check"></i><b>10.4.2</b> Chib’s methods</a></li>
<li class="chapter" data-level="10.4.3" data-path="sec10_4.html"><a href="sec10_4.html#sec10_4_3"><i class="fa fa-check"></i><b>10.4.3</b> Gelfand-Dey method</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="sec10_5.html"><a href="sec10_5.html"><i class="fa fa-check"></i><b>10.5</b> Summary</a></li>
<li class="chapter" data-level="10.6" data-path="sec10_6.html"><a href="sec10_6.html"><i class="fa fa-check"></i><b>10.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="Chap11.html"><a href="Chap11.html"><i class="fa fa-check"></i><b>11</b> Semi-parametric and non-parametric models</a>
<ul>
<li class="chapter" data-level="11.1" data-path="sec11_1.html"><a href="sec11_1.html"><i class="fa fa-check"></i><b>11.1</b> Mixture models</a>
<ul>
<li class="chapter" data-level="11.1.1" data-path="sec11_1.html"><a href="sec11_1.html#sec11_11"><i class="fa fa-check"></i><b>11.1.1</b> Finite Gaussian mixtures</a></li>
<li class="chapter" data-level="11.1.2" data-path="sec11_1.html"><a href="sec11_1.html#sec11_12"><i class="fa fa-check"></i><b>11.1.2</b> Direchlet processes</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="sec11_2.html"><a href="sec11_2.html"><i class="fa fa-check"></i><b>11.2</b> Splines</a></li>
<li class="chapter" data-level="11.3" data-path="sec11_3.html"><a href="sec11_3.html"><i class="fa fa-check"></i><b>11.3</b> Summary</a></li>
<li class="chapter" data-level="11.4" data-path="sec11_4.html"><a href="sec11_4.html"><i class="fa fa-check"></i><b>11.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="Chap12.html"><a href="Chap12.html"><i class="fa fa-check"></i><b>12</b> Bayesian machine learning</a>
<ul>
<li class="chapter" data-level="12.1" data-path="sec12_1.html"><a href="sec12_1.html"><i class="fa fa-check"></i><b>12.1</b> Cross-validation and Bayes factors</a></li>
<li class="chapter" data-level="12.2" data-path="sec12_2.html"><a href="sec12_2.html"><i class="fa fa-check"></i><b>12.2</b> Regularization</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="sec12_2.html"><a href="sec12_2.html#sec12_21"><i class="fa fa-check"></i><b>12.2.1</b> Bayesian LASSO</a></li>
<li class="chapter" data-level="12.2.2" data-path="sec12_2.html"><a href="sec12_2.html#sec12_22"><i class="fa fa-check"></i><b>12.2.2</b> Stochastic search variable selection</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="sec12_3.html"><a href="sec12_3.html"><i class="fa fa-check"></i><b>12.3</b> Bayesian additive regression trees</a></li>
<li class="chapter" data-level="12.4" data-path="sec12_4.html"><a href="sec12_4.html"><i class="fa fa-check"></i><b>12.4</b> Gaussian processes</a></li>
<li class="chapter" data-level="12.5" data-path="sec12_5.html"><a href="sec12_5.html"><i class="fa fa-check"></i><b>12.5</b> Tall data problems</a>
<ul>
<li class="chapter" data-level="12.5.1" data-path="sec12_5.html"><a href="sec12_5.html#sec12_51"><i class="fa fa-check"></i><b>12.5.1</b> Divide-and-conquer methods</a></li>
<li class="chapter" data-level="12.5.2" data-path="sec12_5.html"><a href="sec12_5.html#sec12_52"><i class="fa fa-check"></i><b>12.5.2</b> Subsampling-based algorithms</a></li>
</ul></li>
<li class="chapter" data-level="12.6" data-path="id_13_6.html"><a href="id_13_6.html"><i class="fa fa-check"></i><b>12.6</b> Summary</a></li>
<li class="chapter" data-level="12.7" data-path="id_13_7.html"><a href="id_13_7.html"><i class="fa fa-check"></i><b>12.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="Chap13.html"><a href="Chap13.html"><i class="fa fa-check"></i><b>13</b> Causal inference</a>
<ul>
<li class="chapter" data-level="13.1" data-path="sec13_1.html"><a href="sec13_1.html"><i class="fa fa-check"></i><b>13.1</b> Identification setting</a></li>
<li class="chapter" data-level="13.2" data-path="sec13_2.html"><a href="sec13_2.html"><i class="fa fa-check"></i><b>13.2</b> Randomized controlled trial (RCT)</a></li>
<li class="chapter" data-level="13.3" data-path="sec13_3.html"><a href="sec13_3.html"><i class="fa fa-check"></i><b>13.3</b> Conditional independence assumption (CIA)</a></li>
<li class="chapter" data-level="13.4" data-path="sec13_4.html"><a href="sec13_4.html"><i class="fa fa-check"></i><b>13.4</b> Instrumental variables (IV)</a></li>
<li class="chapter" data-level="13.5" data-path="Chap13_5.html"><a href="Chap13_5.html"><i class="fa fa-check"></i><b>13.5</b> Difference-in-differences design (DiD)</a>
<ul>
<li class="chapter" data-level="13.5.1" data-path="Chap13_5.html"><a href="Chap13_5.html#sec13_51"><i class="fa fa-check"></i><b>13.5.1</b> Classic DiD: two-group and two-period (<span class="math inline">\(2\times2\)</span>) setup</a></li>
<li class="chapter" data-level="13.5.2" data-path="Chap13_5.html"><a href="Chap13_5.html#sec13_52"><i class="fa fa-check"></i><b>13.5.2</b> Staggered (SDiD): G-group and T-period (<span class="math inline">\(G\times T\)</span>) setup</a></li>
</ul></li>
<li class="chapter" data-level="13.6" data-path="sec_7.html"><a href="sec_7.html"><i class="fa fa-check"></i><b>13.6</b> Regression discontinuity design (RD)</a>
<ul>
<li class="chapter" data-level="13.6.1" data-path="sec_7.html"><a href="sec_7.html#sharp-regression-discontinuity-design-srd"><i class="fa fa-check"></i><b>13.6.1</b> Sharp regression discontinuity design (SRD)</a></li>
<li class="chapter" data-level="13.6.2" data-path="sec_7.html"><a href="sec_7.html#fuzzy-regression-discontinuity-design-frd"><i class="fa fa-check"></i><b>13.6.2</b> Fuzzy regression discontinuity design (FRD)</a></li>
</ul></li>
<li class="chapter" data-level="13.7" data-path="sec12_8.html"><a href="sec12_8.html"><i class="fa fa-check"></i><b>13.7</b> Sample selection</a></li>
<li class="chapter" data-level="13.8" data-path="sec12_9.html"><a href="sec12_9.html"><i class="fa fa-check"></i><b>13.8</b> Bayesian exponentially tilted empirical likelihood</a></li>
<li class="chapter" data-level="13.9" data-path="sec13_11.html"><a href="sec13_11.html"><i class="fa fa-check"></i><b>13.9</b> Doubly robust</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="Chap14.html"><a href="Chap14.html"><i class="fa fa-check"></i><b>14</b> Approximate Bayesian methods</a>
<ul>
<li class="chapter" data-level="14.1" data-path="sec14_1.html"><a href="sec14_1.html"><i class="fa fa-check"></i><b>14.1</b> Simulation-based approaches</a>
<ul>
<li class="chapter" data-level="14.1.1" data-path="sec14_1.html"><a href="sec14_1.html#sec14_11"><i class="fa fa-check"></i><b>14.1.1</b> Approximate Bayesian computation</a></li>
<li class="chapter" data-level="14.1.2" data-path="sec14_1.html"><a href="sec14_1.html#sec14_12"><i class="fa fa-check"></i><b>14.1.2</b> Bayesian synthetic likelihood</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="sec14_2.html"><a href="sec14_2.html"><i class="fa fa-check"></i><b>14.2</b> Optimization approaches</a>
<ul>
<li class="chapter" data-level="14.2.1" data-path="sec14_2.html"><a href="sec14_2.html#sec14_21"><i class="fa fa-check"></i><b>14.2.1</b> Integrated nested Laplace approximations</a></li>
<li class="chapter" data-level="14.2.2" data-path="sec14_2.html"><a href="sec14_2.html#sec14_22"><i class="fa fa-check"></i><b>14.2.2</b> Variational Bayes</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="summary-1.html"><a href="summary-1.html"><i class="fa fa-check"></i><b>14.3</b> Summary</a></li>
<li class="chapter" data-level="14.4" data-path="sec14_4.html"><a href="sec14_4.html"><i class="fa fa-check"></i><b>14.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i>Appendix</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to Bayesian Econometrics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="sec12_8" class="section level2 hasAnchor" number="13.7">
<h2><span class="header-section-number">13.7</span> Sample selection<a href="sec12_8.html#sec12_8" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We depict a situation of collider bias that induces selection bias in Section @ref(sec13_3). Specifically, conditioning on a particular subset of the population (<span class="math inline">\(D_i=1\)</span>), where <span class="math inline">\(D_i\)</span> is influenced by both the treatment and confounders, opens a back-door path and creates a spurious association between their causes. Placing this situation within the well-known sample selection framework <span class="citation">(<a href="#ref-heckman1979sample">Heckman 1979</a>)</span>, the observed outcome can be represented as</p>
<p><span class="math display">\[
Y_i = \begin{cases}
    Y_i(1) &amp; \text{if } D_i=1, \\
    \text{NA} &amp; \text{if } D_i=0,
\end{cases}
\]</span></p>
<p>that is, we only observe <span class="math inline">\(Y_i = Y_i(1)\)</span> for <span class="math inline">\(i=1,2,\dots,N\)</span>, while <span class="math inline">\(Y_i(0)\)</span> remains unobserved (“missing”).</p>
<p>In this setting, inference can be performed based on the likelihood of the observed outcomes together with the <em>selection (missingness) mechanism</em> <span class="math inline">\((Y_i(1),D_i)\)</span>, integrating out the unobserved <span class="math inline">\(Y_i(0)\)</span> from the joint distribution of <span class="math inline">\(\{Y_i(1),Y_i(0),D_i\}\)</span>. However, one must consider whether the missingness mechanism is <em>ignorable</em> or not. According to <span class="citation">Little and Rubin (<a href="#ref-little2019statistical">2019</a>)</span>, the missingness mechanism is ignorable in Bayesian inference if the following two conditions hold:</p>
<ol style="list-style-type: lower-roman">
<li>the likelihood can be factorized as</li>
</ol>
<p><span class="math display">\[
p(y_i, d_i\mid \boldsymbol{\theta},\boldsymbol{\gamma})
= p(y_i\mid \boldsymbol{\theta})\, p(y_i,d_i \mid \boldsymbol{\gamma}),
\]</span></p>
<p>and</p>
<ol start="2" style="list-style-type: lower-roman">
<li>the parameters <span class="math inline">\(\boldsymbol{\theta}\)</span> and <span class="math inline">\(\boldsymbol{\gamma}\)</span> are <em>a priori</em> independent,</li>
</ol>
<p><span class="math display">\[
\pi(\boldsymbol{\theta},\boldsymbol{\gamma})
= \pi(\boldsymbol{\theta})\,\pi(\boldsymbol{\gamma}).
\]</span></p>
<p>Under these conditions, posterior inference can be based on</p>
<p><span class="math display">\[
\pi(\boldsymbol{\theta}\mid \mathbf{y})
\propto \pi(\boldsymbol{\theta})\, p(\mathbf{y} \mid \boldsymbol{\theta}).
\]</span></p>
<p>Thus, if the missingness mechanism is <em>Missing At Random</em> (MAR) and the parameters are <em>a priori</em> independent, the missingness mechanism is ignorable for Bayesian inference (see Chapter 6 of <span class="citation">Little and Rubin (<a href="#ref-little2019statistical">2019</a>)</span>).</p>
<p>In contrast, when the missingness mechanism is non-ignorable (i.e., Not Missing At Random, NMAR), the probability of observing <span class="math inline">\(Y_i\)</span> depends on the unobserved values themselves. In this case, Bayesian inference must be performed using the full joint likelihood,</p>
<p><span class="math display">\[
p(y_i, d_i \mid \boldsymbol{\theta},\boldsymbol{\gamma}),
\]</span></p>
<p>which requires specifying and estimating both the outcome model and the selection model simultaneously (see Chapter 15 of <span class="citation">Little and Rubin (<a href="#ref-little2019statistical">2019</a>)</span>). In particular, the classical sample selection model of <span class="citation">Heckman (<a href="#ref-heckman1979sample">1979</a>)</span> establishes,</p>
<p><span class="math display">\[
Y_i = \begin{cases}
    \mathbf{X}_i^{\top}\boldsymbol{\beta}+\mu_i &amp; \text{if } D_i=1, \\
    \text{NA} &amp; \text{if } D_i=0,
\end{cases}
\]</span></p>
<p><span class="math display">\[
D_i = \begin{cases}
    1 &amp; \text{if } D_i^* = \mathbf{Z}_i^{\top}\boldsymbol{\gamma}+\nu_i &gt; 0, \\
    0 &amp; \text{if } D_i^* = \mathbf{Z}_i^{\top}\boldsymbol{\gamma}+\nu_i \leq 0,
\end{cases}
\]</span></p>
<p>where</p>
<p><span class="math display">\[
\begin{bmatrix}
    \mu_i \\[6pt]
    \nu_i
\end{bmatrix}
\sim N\!\left(
\begin{bmatrix}
    0 \\ 0
\end{bmatrix},
\begin{bmatrix}
    \sigma^2_{\mu} &amp; \sigma_{\mu\nu} \\
    \sigma_{\mu\nu} &amp; 1
\end{bmatrix}\right).
\]</span></p>
<p>The restriction <span class="math inline">\(\operatorname{Var}(\nu_i)=1\)</span> is imposed for identification. Without this normalization, the latent index <span class="math inline">\(D_i^*=\mathbf{Z}_i^{\top}\boldsymbol{\gamma}+\nu_i\)</span> is only identified up to scale, since</p>
<p><span class="math display">\[
P(D_i=1) = P(\mathbf{Z}_i^{\top}\boldsymbol{\gamma}+\nu_i &gt; 0)
= P\!\left(\frac{\nu_i}{c} &gt; -\frac{\mathbf{Z}_i^{\top}\boldsymbol{\gamma}}{c}\right),
\quad \forall\, c&gt;0.
\]</span></p>
<p>Thus, setting <span class="math inline">\(\sigma^2_{\nu}=1\)</span> yields point identification of the parameters.</p>
<p>Note that since <span class="math inline">\(D_i=1 \iff \nu_i&gt;-\mathbf Z_i^\top\boldsymbol\gamma\)</span>,</p>
<p><span class="math display">\[
\mathbb E[\mu_i\mid D_i=1,\mathbf Z_i]
=\mathbb E\!\big[\mathbb E(\mu_i\mid \nu_i)\,\big|\,\nu_i&gt;-\mathbf Z_i^\top\boldsymbol\gamma\big]
=\sigma_{\mu\nu}\,\mathbb E\!\big[\nu_i\mid \nu_i&gt;-\mathbf Z_i^\top\boldsymbol\gamma\big].
\]</span></p>
<p>This is because <span class="math inline">\(\mu_i\mid \nu_i\sim N(\sigma_{\mu\nu}\nu_i, \sigma^2_{\mu}-\sigma_{\mu\nu}^2)\)</span>.</p>
<p>If <span class="math inline">\(\nu\sim\mathcal N(0,1)\)</span>, then for <span class="math inline">\(a=\mathbf Z_i^\top\boldsymbol\gamma\)</span>,</p>
<p><span class="math display">\[
\mathbb E[\nu\mid \nu&gt;-a]=\frac{\phi(a)}{\Phi(a)}\equiv \lambda(a),
\]</span></p>
<p>where <span class="math inline">\(\phi\)</span> and <span class="math inline">\(\Phi\)</span> are the standard normal pdf and cdf. Hence</p>
<p><span class="math display">\[
\mathbb E[\mu_i\mid D_i=1,\mathbf Z_i]=\sigma_{\mu\nu}\,\lambda(\mathbf Z_i^\top\boldsymbol\gamma)
    =\rho\,\sigma_\mu\,\lambda(\mathbf Z_i^\top\boldsymbol\gamma),
\]</span></p>
<p>where <span class="math inline">\(\rho=\sigma_{\mu\nu}/\sigma_{\mu}\)</span>.</p>
<p>Then,</p>
<p><span class="math display">\[
\begin{aligned}
    \mathbb E[Y_i\mid D_i=1,\mathbf X_i,\mathbf Z_i]
    &amp;=\mathbf X_i^\top \boldsymbol\beta+\mathbb E[\mu_i\mid D_i=1,\mathbf Z_i]\\
    &amp;=\mathbf X_i^\top \boldsymbol\beta + \sigma_{\mu\nu}\,\lambda(\mathbf Z_i^\top\boldsymbol\gamma)\\
    &amp;=\mathbf X_i^\top \boldsymbol\beta + \rho\,\sigma_\mu\,\lambda(\mathbf Z_i^\top\boldsymbol\gamma).
\end{aligned}
\]</span></p>
<p>This is the Heckman selection-bias correction: the inverse Mills ratio <span class="math inline">\(\lambda(\mathbf Z_i^\top\boldsymbol\gamma)\)</span> enters as an additional regressor in the selected sample. Point identification can be achieved through functional form (since the inverse Mills ratio is non-linear) together with the normality assumption. This implies that, in principle, one may have <span class="math inline">\(\mathbf{X}_i=\mathbf{Z}_i\)</span>. However, such identification is weak, and it is preferable to include at least one variable in <span class="math inline">\(\mathbf{Z}_i\)</span> that is excluded from <span class="math inline">\(\mathbf{X}_i\)</span>, i.e., <span class="math inline">\(\mathbf{X}_i\neq\mathbf{Z}_i\)</span>, as this strengthens identification and also improves the precision of inference.</p>
<p>To perform Bayesian inference in this model, we use the augmented likelihood. Thus,</p>
<p><span class="math display">\[
\begin{aligned}
    \pi(\boldsymbol{\delta},\sigma^2_{\mu},\sigma_{\mu\nu},D_i^*\mid \mathbf{y},\mathbf{d})
    &amp; \propto \prod_{i\in I_{0}} \pi(D_i^*\mid \boldsymbol{\delta},\sigma^2_{\mu},\sigma_{\mu\nu})
    \, \mathbf{1}(d_i=0)\, \mathbf{1}(D_i^*\leq 0) \\
    &amp; \quad \times \prod_{i\in I_{1}} p(y_i,D_i^*\mid \boldsymbol{\delta},\sigma^2_{\mu},\sigma_{\mu\nu})
    \, \mathbf{1}(d_i=1)\, \mathbf{1}(D_i^*&gt; 0) \\
    &amp; \quad \times \pi(\boldsymbol{\delta},\sigma^2_{\mu},\sigma_{\mu\nu}),
\end{aligned}
\]</span></p>
<p>where <span class="math inline">\(\boldsymbol{\delta}=[\boldsymbol{\beta}^{\top} \ \boldsymbol{\gamma}^{\top}]^{\top}\)</span>,
<span class="math inline">\(I_0=\{i : d_i=0\}\)</span> and <span class="math inline">\(I_1=\{i : d_i=1\}\)</span>.</p>
<p>Following Chapter 11 in <span class="citation">Greenberg (<a href="#ref-greenberg2012introduction">2012</a>)</span>, we set</p>
<p><span class="math display">\[
\boldsymbol{\eta}_i=
\begin{cases}
    [0, \, D_i^*]^{\top}, &amp; i\in I_0\\
    [y_i, \, D_i^*]^{\top}, &amp; i\in I_1
\end{cases},
\qquad
\mathbf{W}_i=\begin{bmatrix}
    \mathbf{X}_i^{\top} &amp; \mathbf{0}\\
    \mathbf{0} &amp; \mathbf{Z}_i^{\top}
\end{bmatrix},
\qquad
\mathbf{J}=\begin{bmatrix}
    0 &amp; 0\\
    0 &amp; 1
\end{bmatrix}.
\]</span></p>
<p>Assuming <span class="math inline">\(\pi(\boldsymbol{\delta}) \sim N(\boldsymbol{\delta}_0,\mathbf{D}_0)\)</span>, the conditional posterior distribution of <span class="math inline">\(\boldsymbol{\delta}\)</span> is normal with mean</p>
<p><span class="math display">\[
\boldsymbol{\delta}_n=\mathbf{D}_n\left[\sum_{i\in I_0}\mathbf{W}_i^{\top}\mathbf{J}\boldsymbol{\eta}_i
+\sum_{i\in I_1}\mathbf{W}_i^{\top}\boldsymbol{\Sigma}^{-1}\boldsymbol{\eta}_i
+\mathbf{D}_0^{-1}\boldsymbol{\delta}_0\right],
\]</span></p>
<p>and variance matrix</p>
<p><span class="math display">\[
\mathbf{D}_n=\left[\sum_{i\in I_0}\mathbf{W}_i^{\top}\mathbf{J}\mathbf{W}_i
+\sum_{i\in I_1}\mathbf{W}_i^{\top}\boldsymbol{\Sigma}^{-1}\mathbf{W}_i
+\mathbf{D}_0^{-1}\right]^{-1},
\]</span></p>
<p>where</p>
<p><span class="math display">\[
\boldsymbol{\Sigma}=\begin{bmatrix}
    \sigma^2_{\mu} &amp; \sigma_{\mu\nu} \\[6pt]
    \sigma_{\mu\nu} &amp; 1
\end{bmatrix}.
\]</span></p>
<p>Let <span class="math inline">\(\omega=\sigma^2_{\mu}-\sigma^2_{\mu\nu}\)</span> denote the conditional variance of <span class="math inline">\(\mu_i \mid \nu_i\)</span>.
Assuming <span class="math inline">\(\omega^{-1}\sim G(\alpha_0/2,\delta_0/2)\)</span> and noting that</p>
<p><span class="math display">\[
p(y_i,D_i^*\mid \boldsymbol{\delta},\omega,\sigma_{\mu\nu})
= p(y_i\mid D_i^*, \boldsymbol{\delta},\omega,\sigma_{\mu\nu})
\times p(D_i^*\mid \boldsymbol{\delta},\omega,\sigma_{\mu\nu}),
\]</span></p>
<p>the conditional posterior distribution of <span class="math inline">\(\omega^{-1}\)</span> is Gamma,</p>
<p><span class="math display">\[
\omega^{-1}\mid \boldsymbol{\delta},\sigma_{\mu\nu}, \mathbf{y},\mathbf{d} \sim G(\alpha_n/2,\delta_n/2),
\]</span></p>
<p>with</p>
<p><span class="math display">\[
\alpha_n=\alpha_0+N_1,
\qquad
\delta_n=\delta_0+\sum_{i\in I_1}\Big[y_i-\mathbf{X}_i^{\top}\boldsymbol{\beta}
-\sigma_{\mu\nu}(D_i^*-\mathbf{Z}_i^{\top}\boldsymbol{\gamma})\Big]^2,
\]</span></p>
<p>where <span class="math inline">\(N_1\)</span> is the number of observations with <span class="math inline">\(D_i=1\)</span>.</p>
<p>In addition, assuming <span class="math inline">\(\sigma_{\mu\nu}\sim N(s_0,S_0)\)</span>, the conditional posterior distribution is normal with mean</p>
<p><span class="math display">\[
s_n=S_n\left(\omega^{-1}\sum_{i=1}^N(D_i^*-\mathbf{Z}_i^{\top}\boldsymbol{\gamma})(y_i-\mathbf{X}_i^{\top}\boldsymbol{\beta})
+S_0^{-1}s_0\right),
\]</span></p>
<p>and variance</p>
<p><span class="math display">\[
S_n=\left[\omega^{-1}\sum_{i=1}^N(D_i^*-\mathbf{Z}_i^{\top}\boldsymbol{\gamma})^2+S_0^{-1}\right]^{-1}.
\]</span></p>
<p>Finally, since</p>
<p><span class="math display">\[
p(y_i,D_i^*\mid \boldsymbol{\delta},\omega,\sigma_{\mu\nu})
= p(D_i^*\mid y_i, \boldsymbol{\delta},\omega,\sigma_{\mu\nu})
\times p(y_i\mid \boldsymbol{\delta},\omega,\sigma_{\mu\nu}),
\]</span></p>
<p>the conditional posterior distribution of <span class="math inline">\(D_i^*\)</span> is</p>
<p><span class="math display">\[
D_i^* \sim
\begin{cases}
    TN_{(-\infty,0]}(\mathbf{Z}_i^{\top}\boldsymbol{\gamma},\,1), &amp; i\in I_0,\\[6pt]
    TN_{(0,\infty)}\!\left(\mathbf{Z}_i^{\top}\boldsymbol{\gamma}
    +\dfrac{\sigma_{\mu\nu}}{\sigma_{\mu\nu}^2+\omega}\,(y_i-\mathbf{X}_i^{\top}\boldsymbol{\beta}),\,
    \dfrac{\omega}{\sigma_{\mu\nu}^2+\omega}\right), &amp; i\in I_1,
\end{cases}
\]</span></p>
<p>where <span class="math inline">\(TN_{A}(\mu,\sigma^2)\)</span> denotes a normal distribution with mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^2\)</span>, truncated to the set <span class="math inline">\(A\)</span>.</p>
<p><strong>Example: Simulation of the sample selection model</strong></p>
<p>We simulate the model
<span class="math display">\[
Y_i = 12 + X_{i1} + X_{i2} + \mu_i,
\]</span>
where <span class="math inline">\(X_{i1}\sim N(0,4)\)</span>, <span class="math inline">\(X_{i2}\sim \text{Bin}(1,0.5)\)</span>, and <span class="math inline">\(\mu_i\sim N(0,1.2)\)</span> for <span class="math inline">\(i=1,2,\dots,1000\)</span>.<br />
In addition,
<span class="math display">\[
D_i^* = 1 + Z_{i1} - X_{i2} + \nu_i,
\]</span>
where <span class="math inline">\(Z_{i1}\sim N(0,4)\)</span>.</p>
<p>The covariance between <span class="math inline">\(\mu_i\)</span> and <span class="math inline">\(\nu_i\)</span> is set to <span class="math inline">\(0.6\)</span>.</p>
<p>The hyperparameters are <span class="math inline">\(\boldsymbol{\delta}_0=[0 \ 0 \ 0 \ 0 \ 0 \ 0]^{\top}\)</span>, <span class="math inline">\(\mathbf{D}_0=1000\mathbf{I}_6\)</span>, <span class="math inline">\(\alpha_0=\delta_0=0.001\)</span>, <span class="math inline">\(s_0=0\)</span>, and <span class="math inline">\(S_0=1000\)</span>. We perform 1,500 iterations with a burn-in of 500. The following code illustrates the Gibbs sampler. Finally, we compare the results with an implementation that does not account for the sample selection issue.</p>
<p>The figure shows the posterior distributions of the second parameter in the outcome equation, whose population value is 1 (black dashed line). The posterior distribution of the model that accounts for selection encompasses the population value, whereas the model that ignores selection does not.</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="sec12_8.html#cb15-1" tabindex="-1"></a><span class="fu">rm</span>(<span class="at">list =</span> <span class="fu">ls</span>()); <span class="fu">set.seed</span>(<span class="dv">10101</span>)</span>
<span id="cb15-2"><a href="sec12_8.html#cb15-2" tabindex="-1"></a><span class="fu">library</span>(doParallel); <span class="fu">library</span>(snow)</span></code></pre></div>
<pre><code>## Loading required package: foreach</code></pre>
<pre><code>## Loading required package: iterators</code></pre>
<pre><code>## Loading required package: parallel</code></pre>
<pre><code>## 
## Attaching package: &#39;snow&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:parallel&#39;:
## 
##     closeNode, clusterApply, clusterApplyLB, clusterCall, clusterEvalQ,
##     clusterExport, clusterMap, clusterSplit, makeCluster, parApply,
##     parCapply, parLapply, parRapply, parSapply, recvData, recvOneData,
##     sendData, splitIndices, stopCluster</code></pre>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="sec12_8.html#cb21-1" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb21-2"><a href="sec12_8.html#cb21-2" tabindex="-1"></a>w1 <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(N, <span class="dv">1</span>, <span class="fl">0.5</span>) <span class="co"># rnorm(N, 0, sigExo); </span></span>
<span id="cb21-3"><a href="sec12_8.html#cb21-3" tabindex="-1"></a>delta <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">1</span>, <span class="sc">-</span><span class="dv">1</span>); beta <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">1</span>,<span class="dv">1</span>)</span>
<span id="cb21-4"><a href="sec12_8.html#cb21-4" tabindex="-1"></a>zx <span class="ot">&lt;-</span> MASS<span class="sc">::</span><span class="fu">mvrnorm</span>(N, <span class="at">mu =</span> <span class="fu">rep</span>(<span class="dv">0</span>, <span class="dv">2</span>), <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">1</span>,<span class="fl">0.7</span>,<span class="fl">0.7</span>,<span class="dv">1</span>),<span class="dv">2</span>,<span class="dv">2</span>))</span>
<span id="cb21-5"><a href="sec12_8.html#cb21-5" tabindex="-1"></a>z1 <span class="ot">&lt;-</span> zx[,<span class="dv">1</span>]</span>
<span id="cb21-6"><a href="sec12_8.html#cb21-6" tabindex="-1"></a>Z <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="dv">1</span>, z1, w1)</span>
<span id="cb21-7"><a href="sec12_8.html#cb21-7" tabindex="-1"></a>sig12 <span class="ot">&lt;-</span> <span class="fl">0.8</span>; sig11 <span class="ot">&lt;-</span> <span class="fl">1.2</span></span>
<span id="cb21-8"><a href="sec12_8.html#cb21-8" tabindex="-1"></a>SIGMA <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">c</span>(sig11, sig12, sig12, <span class="dv">1</span>), <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb21-9"><a href="sec12_8.html#cb21-9" tabindex="-1"></a>E <span class="ot">&lt;-</span> MASS<span class="sc">::</span><span class="fu">mvrnorm</span>(N, <span class="at">mu =</span> <span class="fu">rep</span>(<span class="dv">0</span>, <span class="dv">2</span>), SIGMA)</span>
<span id="cb21-10"><a href="sec12_8.html#cb21-10" tabindex="-1"></a>cl <span class="ot">&lt;-</span> Z<span class="sc">%*%</span>delta <span class="sc">+</span> E[,<span class="dv">2</span>]; c <span class="ot">&lt;-</span> cl <span class="sc">&gt;</span> <span class="dv">0</span></span>
<span id="cb21-11"><a href="sec12_8.html#cb21-11" tabindex="-1"></a>x1 <span class="ot">&lt;-</span> zx[,<span class="dv">2</span>]; X <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="dv">1</span>, x1, w1)</span>
<span id="cb21-12"><a href="sec12_8.html#cb21-12" tabindex="-1"></a>y <span class="ot">&lt;-</span> X<span class="sc">%*%</span>beta <span class="sc">+</span> E[,<span class="dv">1</span>]</span>
<span id="cb21-13"><a href="sec12_8.html#cb21-13" tabindex="-1"></a>y[c<span class="sc">==</span><span class="dv">0</span>] <span class="ot">&lt;-</span> <span class="cn">NA</span></span>
<span id="cb21-14"><a href="sec12_8.html#cb21-14" tabindex="-1"></a><span class="co"># Hyperparameters</span></span>
<span id="cb21-15"><a href="sec12_8.html#cb21-15" tabindex="-1"></a>b0 <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">0</span>, <span class="dv">6</span>); B0 <span class="ot">&lt;-</span> <span class="dv">1000</span><span class="sc">*</span><span class="fu">diag</span>(<span class="dv">6</span>); B0i <span class="ot">&lt;-</span> <span class="fu">solve</span>(B0)</span>
<span id="cb21-16"><a href="sec12_8.html#cb21-16" tabindex="-1"></a>a0 <span class="ot">&lt;-</span> <span class="fl">0.001</span>; d0 <span class="ot">&lt;-</span> <span class="fl">0.001</span></span>
<span id="cb21-17"><a href="sec12_8.html#cb21-17" tabindex="-1"></a>s0 <span class="ot">&lt;-</span> <span class="dv">0</span>; S0 <span class="ot">&lt;-</span> <span class="dv">1000</span>; S0i <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">/</span>S0</span>
<span id="cb21-18"><a href="sec12_8.html#cb21-18" tabindex="-1"></a><span class="co"># Location</span></span>
<span id="cb21-19"><a href="sec12_8.html#cb21-19" tabindex="-1"></a>idc1 <span class="ot">&lt;-</span> <span class="fu">which</span>(c<span class="sc">==</span><span class="dv">1</span>)</span>
<span id="cb21-20"><a href="sec12_8.html#cb21-20" tabindex="-1"></a>nc1 <span class="ot">&lt;-</span> <span class="fu">length</span>(idc1)</span>
<span id="cb21-21"><a href="sec12_8.html#cb21-21" tabindex="-1"></a>PostThetaNew <span class="ot">&lt;-</span> <span class="cf">function</span>(Sigma, clat){</span>
<span id="cb21-22"><a href="sec12_8.html#cb21-22" tabindex="-1"></a>    J <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">1</span>),<span class="dv">2</span>,<span class="dv">2</span>)</span>
<span id="cb21-23"><a href="sec12_8.html#cb21-23" tabindex="-1"></a>    WW <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="dv">0</span>, <span class="dv">6</span>, <span class="dv">6</span>)</span>
<span id="cb21-24"><a href="sec12_8.html#cb21-24" tabindex="-1"></a>    Wy <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="dv">0</span>, <span class="dv">6</span>, <span class="dv">1</span>)</span>
<span id="cb21-25"><a href="sec12_8.html#cb21-25" tabindex="-1"></a>    <span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>N){</span>
<span id="cb21-26"><a href="sec12_8.html#cb21-26" tabindex="-1"></a>        <span class="cf">if</span>(i <span class="sc">%in%</span> idc1){</span>
<span id="cb21-27"><a href="sec12_8.html#cb21-27" tabindex="-1"></a>            yclat <span class="ot">&lt;-</span> <span class="fu">c</span>(y[i], clat[i])</span>
<span id="cb21-28"><a href="sec12_8.html#cb21-28" tabindex="-1"></a>            Auxi <span class="ot">&lt;-</span> <span class="fu">solve</span>(Sigma)</span>
<span id="cb21-29"><a href="sec12_8.html#cb21-29" tabindex="-1"></a>        }<span class="cf">else</span>{</span>
<span id="cb21-30"><a href="sec12_8.html#cb21-30" tabindex="-1"></a>            yclat <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">0</span>, clat[i])</span>
<span id="cb21-31"><a href="sec12_8.html#cb21-31" tabindex="-1"></a>            Auxi <span class="ot">&lt;-</span> J</span>
<span id="cb21-32"><a href="sec12_8.html#cb21-32" tabindex="-1"></a>        }</span>
<span id="cb21-33"><a href="sec12_8.html#cb21-33" tabindex="-1"></a>        Wi <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(Matrix<span class="sc">::</span><span class="fu">bdiag</span>(X[i,], Z[i,]))</span>
<span id="cb21-34"><a href="sec12_8.html#cb21-34" tabindex="-1"></a>        WWi <span class="ot">&lt;-</span> Wi<span class="sc">%*%</span>Auxi<span class="sc">%*%</span><span class="fu">t</span>(Wi)</span>
<span id="cb21-35"><a href="sec12_8.html#cb21-35" tabindex="-1"></a>        Wyi <span class="ot">&lt;-</span> Wi<span class="sc">%*%</span>Auxi<span class="sc">%*%</span>yclat</span>
<span id="cb21-36"><a href="sec12_8.html#cb21-36" tabindex="-1"></a>        WW <span class="ot">&lt;-</span> WW <span class="sc">+</span> WWi</span>
<span id="cb21-37"><a href="sec12_8.html#cb21-37" tabindex="-1"></a>        Wy <span class="ot">&lt;-</span> Wy <span class="sc">+</span> Wyi</span>
<span id="cb21-38"><a href="sec12_8.html#cb21-38" tabindex="-1"></a>    }</span>
<span id="cb21-39"><a href="sec12_8.html#cb21-39" tabindex="-1"></a>    Bn <span class="ot">&lt;-</span> <span class="fu">solve</span>(B0i <span class="sc">+</span> WW)</span>
<span id="cb21-40"><a href="sec12_8.html#cb21-40" tabindex="-1"></a>    bn <span class="ot">&lt;-</span> Bn<span class="sc">%*%</span>(B0i<span class="sc">%*%</span>b0 <span class="sc">+</span> Wy)</span>
<span id="cb21-41"><a href="sec12_8.html#cb21-41" tabindex="-1"></a>    Beta <span class="ot">&lt;-</span> MASS<span class="sc">::</span><span class="fu">mvrnorm</span>(<span class="dv">1</span>, bn, Bn)</span>
<span id="cb21-42"><a href="sec12_8.html#cb21-42" tabindex="-1"></a>    <span class="fu">return</span>(Beta)</span>
<span id="cb21-43"><a href="sec12_8.html#cb21-43" tabindex="-1"></a>}</span>
<span id="cb21-44"><a href="sec12_8.html#cb21-44" tabindex="-1"></a>PostOmega11 <span class="ot">&lt;-</span> <span class="cf">function</span>(theta, sig12, clat){</span>
<span id="cb21-45"><a href="sec12_8.html#cb21-45" tabindex="-1"></a>    an <span class="ot">&lt;-</span> a0 <span class="sc">+</span> nc1</span>
<span id="cb21-46"><a href="sec12_8.html#cb21-46" tabindex="-1"></a>    mui <span class="ot">&lt;-</span> y[idc1] <span class="sc">-</span>X[idc1, ]<span class="sc">%*%</span>theta[<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>] <span class="sc">-</span> sig12<span class="sc">*</span>(clat[idc1] <span class="sc">-</span> Z[idc1,]<span class="sc">%*%</span>theta[<span class="dv">4</span><span class="sc">:</span><span class="dv">6</span>])</span>
<span id="cb21-47"><a href="sec12_8.html#cb21-47" tabindex="-1"></a>    dn <span class="ot">&lt;-</span> d0 <span class="sc">+</span> <span class="fu">t</span>(mui)<span class="sc">%*%</span>mui</span>
<span id="cb21-48"><a href="sec12_8.html#cb21-48" tabindex="-1"></a>    omega11 <span class="ot">&lt;-</span> LaplacesDemon<span class="sc">::</span><span class="fu">rinvgamma</span>(<span class="dv">1</span>, an<span class="sc">/</span><span class="dv">2</span>, dn<span class="sc">/</span><span class="dv">2</span>)</span>
<span id="cb21-49"><a href="sec12_8.html#cb21-49" tabindex="-1"></a>    <span class="fu">return</span>(omega11)</span>
<span id="cb21-50"><a href="sec12_8.html#cb21-50" tabindex="-1"></a>}</span>
<span id="cb21-51"><a href="sec12_8.html#cb21-51" tabindex="-1"></a>PostSig12 <span class="ot">&lt;-</span> <span class="cf">function</span>(omega11, theta, clat){</span>
<span id="cb21-52"><a href="sec12_8.html#cb21-52" tabindex="-1"></a>    Sn <span class="ot">&lt;-</span> (omega11<span class="sc">^</span>(<span class="sc">-</span><span class="dv">1</span>)<span class="sc">*</span><span class="fu">sum</span>((clat[idc1] <span class="sc">-</span> Z[idc1,]<span class="sc">%*%</span>theta[<span class="dv">4</span><span class="sc">:</span><span class="dv">6</span>])<span class="sc">^</span><span class="dv">2</span>) <span class="sc">+</span> S0i)<span class="sc">^</span>(<span class="sc">-</span><span class="dv">1</span>)</span>
<span id="cb21-53"><a href="sec12_8.html#cb21-53" tabindex="-1"></a>    sn <span class="ot">&lt;-</span> Sn<span class="sc">*</span>(omega11<span class="sc">^</span>(<span class="sc">-</span><span class="dv">1</span>)<span class="sc">*</span><span class="fu">sum</span>((clat[idc1] <span class="sc">-</span> Z[idc1,]<span class="sc">%*%</span>theta[<span class="dv">4</span><span class="sc">:</span><span class="dv">6</span>])<span class="sc">*</span>(y[idc1] <span class="sc">-</span> X[idc1,]<span class="sc">%*%</span>theta[<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>])) <span class="sc">+</span> s0<span class="sc">*</span>S0i)</span>
<span id="cb21-54"><a href="sec12_8.html#cb21-54" tabindex="-1"></a>    sig12 <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">1</span>, sn, <span class="at">sd =</span> Sn<span class="sc">^</span><span class="fl">0.5</span>)</span>
<span id="cb21-55"><a href="sec12_8.html#cb21-55" tabindex="-1"></a>    <span class="fu">return</span>(sig12)</span>
<span id="cb21-56"><a href="sec12_8.html#cb21-56" tabindex="-1"></a>}</span>
<span id="cb21-57"><a href="sec12_8.html#cb21-57" tabindex="-1"></a>PostClat <span class="ot">&lt;-</span> <span class="cf">function</span>(theta, sig12, omega11, i){</span>
<span id="cb21-58"><a href="sec12_8.html#cb21-58" tabindex="-1"></a>    <span class="cf">if</span>(i <span class="sc">%in%</span> idc1){</span>
<span id="cb21-59"><a href="sec12_8.html#cb21-59" tabindex="-1"></a>        mu <span class="ot">&lt;-</span> Z[i,]<span class="sc">%*%</span>theta[<span class="dv">4</span><span class="sc">:</span><span class="dv">6</span>] <span class="sc">+</span> (sig12<span class="sc">/</span>(omega11<span class="sc">+</span>sig12<span class="sc">^</span><span class="dv">2</span>))<span class="sc">*</span>(y[i] <span class="sc">-</span> X[i,]<span class="sc">%*%</span>theta[<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>])</span>
<span id="cb21-60"><a href="sec12_8.html#cb21-60" tabindex="-1"></a>        sig2 <span class="ot">&lt;-</span> omega11<span class="sc">/</span>(omega11<span class="sc">+</span>sig12<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb21-61"><a href="sec12_8.html#cb21-61" tabindex="-1"></a>        clat <span class="ot">&lt;-</span> EnvStats<span class="sc">::</span><span class="fu">rnormTrunc</span>(<span class="dv">1</span>, <span class="at">mean =</span> mu, <span class="at">sd =</span> sig2<span class="sc">^</span><span class="fl">0.5</span>, <span class="at">min =</span> <span class="dv">0</span>, <span class="at">max =</span> <span class="cn">Inf</span>)</span>
<span id="cb21-62"><a href="sec12_8.html#cb21-62" tabindex="-1"></a>    }<span class="cf">else</span>{</span>
<span id="cb21-63"><a href="sec12_8.html#cb21-63" tabindex="-1"></a>        mu <span class="ot">&lt;-</span> Z[i,]<span class="sc">%*%</span>theta[<span class="dv">4</span><span class="sc">:</span><span class="dv">6</span>]</span>
<span id="cb21-64"><a href="sec12_8.html#cb21-64" tabindex="-1"></a>        clat <span class="ot">&lt;-</span> EnvStats<span class="sc">::</span><span class="fu">rnormTrunc</span>(<span class="dv">1</span>, <span class="at">mean =</span> mu, <span class="at">sd =</span> <span class="dv">1</span>, <span class="at">min =</span> <span class="sc">-</span><span class="cn">Inf</span>, <span class="at">max =</span> <span class="dv">0</span>)</span>
<span id="cb21-65"><a href="sec12_8.html#cb21-65" tabindex="-1"></a>    }</span>
<span id="cb21-66"><a href="sec12_8.html#cb21-66" tabindex="-1"></a>    <span class="fu">return</span>(clat)</span>
<span id="cb21-67"><a href="sec12_8.html#cb21-67" tabindex="-1"></a>}</span>
<span id="cb21-68"><a href="sec12_8.html#cb21-68" tabindex="-1"></a><span class="co"># Sampler</span></span>
<span id="cb21-69"><a href="sec12_8.html#cb21-69" tabindex="-1"></a>S <span class="ot">&lt;-</span> <span class="dv">1500</span>; burnin <span class="ot">&lt;-</span> <span class="dv">500</span>; thin <span class="ot">&lt;-</span> <span class="dv">2</span></span>
<span id="cb21-70"><a href="sec12_8.html#cb21-70" tabindex="-1"></a>keep <span class="ot">&lt;-</span> <span class="fu">seq</span>(burnin<span class="sc">+</span>thin, S, thin)</span>
<span id="cb21-71"><a href="sec12_8.html#cb21-71" tabindex="-1"></a>PostThetasDraws <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="cn">NA</span>, S, <span class="dv">6</span>)</span>
<span id="cb21-72"><a href="sec12_8.html#cb21-72" tabindex="-1"></a>PostSigmaDraws <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="cn">NA</span>, S, <span class="dv">2</span>)</span>
<span id="cb21-73"><a href="sec12_8.html#cb21-73" tabindex="-1"></a><span class="co"># Initial parameters</span></span>
<span id="cb21-74"><a href="sec12_8.html#cb21-74" tabindex="-1"></a>Thetap <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">0</span>, <span class="dv">6</span>); Sigmap <span class="ot">&lt;-</span> <span class="fu">diag</span>(<span class="dv">2</span>) </span>
<span id="cb21-75"><a href="sec12_8.html#cb21-75" tabindex="-1"></a>Sig12p <span class="ot">&lt;-</span> <span class="dv">0</span>; Omega11p <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb21-76"><a href="sec12_8.html#cb21-76" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>N){</span>
<span id="cb21-77"><a href="sec12_8.html#cb21-77" tabindex="-1"></a>    <span class="cf">if</span>(c[i] <span class="sc">==</span> <span class="dv">0</span>){</span>
<span id="cb21-78"><a href="sec12_8.html#cb21-78" tabindex="-1"></a>        LatPost <span class="ot">&lt;-</span> EnvStats<span class="sc">::</span><span class="fu">rnormTrunc</span>(<span class="dv">1</span>, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="dv">1</span>, <span class="at">min =</span> <span class="sc">-</span><span class="cn">Inf</span>, <span class="at">max =</span> <span class="dv">0</span>)</span>
<span id="cb21-79"><a href="sec12_8.html#cb21-79" tabindex="-1"></a>    }<span class="cf">else</span>{</span>
<span id="cb21-80"><a href="sec12_8.html#cb21-80" tabindex="-1"></a>        LatPost <span class="ot">&lt;-</span> EnvStats<span class="sc">::</span><span class="fu">rnormTrunc</span>(<span class="dv">1</span>, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="dv">1</span>, <span class="at">min =</span> <span class="dv">0</span>, <span class="at">max =</span> <span class="cn">Inf</span>)</span>
<span id="cb21-81"><a href="sec12_8.html#cb21-81" tabindex="-1"></a>    }</span>
<span id="cb21-82"><a href="sec12_8.html#cb21-82" tabindex="-1"></a>}</span>
<span id="cb21-83"><a href="sec12_8.html#cb21-83" tabindex="-1"></a><span class="do">#### Parallel code ####</span></span>
<span id="cb21-84"><a href="sec12_8.html#cb21-84" tabindex="-1"></a>cn <span class="ot">&lt;-</span> <span class="fu">detectCores</span>() </span>
<span id="cb21-85"><a href="sec12_8.html#cb21-85" tabindex="-1"></a>ClusterHope <span class="ot">&lt;-</span> <span class="fu">makeCluster</span>(cn, <span class="at">type =</span> <span class="st">&quot;SOCK&quot;</span>)</span>
<span id="cb21-86"><a href="sec12_8.html#cb21-86" tabindex="-1"></a><span class="fu">registerDoParallel</span>(ClusterHope)</span>
<span id="cb21-87"><a href="sec12_8.html#cb21-87" tabindex="-1"></a><span class="fu">clusterExport</span>(ClusterHope, <span class="fu">list</span>(<span class="st">&quot;Z&quot;</span>, <span class="st">&quot;X&quot;</span>, <span class="st">&quot;c&quot;</span>, <span class="st">&quot;y&quot;</span>, <span class="st">&quot;N&quot;</span>, <span class="st">&quot;idc1&quot;</span>, <span class="st">&quot;nc1&quot;</span>, <span class="st">&quot;PostClat&quot;</span>,<span class="st">&quot;Thetap&quot;</span>, <span class="st">&quot;Sig12p&quot;</span>, <span class="st">&quot;Omega11p&quot;</span>))</span>
<span id="cb21-88"><a href="sec12_8.html#cb21-88" tabindex="-1"></a>pb <span class="ot">&lt;-</span> <span class="fu">txtProgressBar</span>(<span class="at">min =</span> <span class="dv">0</span>, <span class="at">max =</span> S, <span class="at">style =</span> <span class="dv">3</span>)</span></code></pre></div>
<pre><code>##   |                                                                              |                                                                      |   0%</code></pre>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="sec12_8.html#cb23-1" tabindex="-1"></a><span class="cf">for</span>(rep <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>S){</span>
<span id="cb23-2"><a href="sec12_8.html#cb23-2" tabindex="-1"></a>    LatPost <span class="ot">&lt;-</span> <span class="fu">t</span>(<span class="fu">parSapply</span>(ClusterHope, <span class="dv">1</span><span class="sc">:</span>N, <span class="cf">function</span>(i){<span class="fu">PostClat</span>(<span class="at">theta =</span> Thetap, <span class="at">sig12 =</span> Sig12p, <span class="at">omega11 =</span> Omega11p, i)}))</span>
<span id="cb23-3"><a href="sec12_8.html#cb23-3" tabindex="-1"></a>    Thetap <span class="ot">&lt;-</span> <span class="fu">PostThetaNew</span>(<span class="at">Sigma =</span> Sigmap, <span class="at">clat =</span> LatPost)</span>
<span id="cb23-4"><a href="sec12_8.html#cb23-4" tabindex="-1"></a>    Omega11p <span class="ot">&lt;-</span> <span class="fu">PostOmega11</span>(<span class="at">theta =</span> Thetap, <span class="at">sig12 =</span> Sig12p, <span class="at">clat =</span> LatPost)</span>
<span id="cb23-5"><a href="sec12_8.html#cb23-5" tabindex="-1"></a>    Sig12p <span class="ot">&lt;-</span> <span class="fu">PostSig12</span>(<span class="at">omega11 =</span> Omega11p, <span class="at">theta =</span> Thetap, <span class="at">clat =</span> LatPost)</span>
<span id="cb23-6"><a href="sec12_8.html#cb23-6" tabindex="-1"></a>    Sigmap <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">c</span>(Omega11p<span class="sc">+</span>Sig12p<span class="sc">^</span><span class="dv">2</span>, Sig12p, Sig12p, <span class="dv">1</span>),<span class="dv">2</span>,<span class="dv">2</span>)</span>
<span id="cb23-7"><a href="sec12_8.html#cb23-7" tabindex="-1"></a>    PostThetasDraws[rep,] <span class="ot">&lt;-</span> Thetap</span>
<span id="cb23-8"><a href="sec12_8.html#cb23-8" tabindex="-1"></a>    PostSigmaDraws[rep, ] <span class="ot">&lt;-</span> <span class="fu">c</span>(Omega11p<span class="sc">+</span>Sig12p<span class="sc">^</span><span class="dv">2</span>, Sig12p)</span>
<span id="cb23-9"><a href="sec12_8.html#cb23-9" tabindex="-1"></a>    <span class="fu">clusterExport</span>(ClusterHope, <span class="fu">list</span>(<span class="st">&quot;Thetap&quot;</span>, <span class="st">&quot;Sig12p&quot;</span>, <span class="st">&quot;Omega11p&quot;</span>))</span>
<span id="cb23-10"><a href="sec12_8.html#cb23-10" tabindex="-1"></a>    <span class="fu">setTxtProgressBar</span>(pb, rep)</span>
<span id="cb23-11"><a href="sec12_8.html#cb23-11" tabindex="-1"></a>}</span></code></pre></div>
<pre><code>##   |                                                                              |                                                                      |   1%  |                                                                              |=                                                                     |   1%  |                                                                              |=                                                                     |   2%  |                                                                              |==                                                                    |   2%  |                                                                              |==                                                                    |   3%  |                                                                              |==                                                                    |   4%  |                                                                              |===                                                                   |   4%  |                                                                              |===                                                                   |   5%  |                                                                              |====                                                                  |   5%  |                                                                              |====                                                                  |   6%  |                                                                              |=====                                                                 |   6%  |                                                                              |=====                                                                 |   7%  |                                                                              |=====                                                                 |   8%  |                                                                              |======                                                                |   8%  |                                                                              |======                                                                |   9%  |                                                                              |=======                                                               |   9%  |                                                                              |=======                                                               |  10%  |                                                                              |=======                                                               |  11%  |                                                                              |========                                                              |  11%  |                                                                              |========                                                              |  12%  |                                                                              |=========                                                             |  12%  |                                                                              |=========                                                             |  13%  |                                                                              |=========                                                             |  14%  |                                                                              |==========                                                            |  14%  |                                                                              |==========                                                            |  15%  |                                                                              |===========                                                           |  15%  |                                                                              |===========                                                           |  16%  |                                                                              |============                                                          |  16%  |                                                                              |============                                                          |  17%  |                                                                              |============                                                          |  18%  |                                                                              |=============                                                         |  18%  |                                                                              |=============                                                         |  19%  |                                                                              |==============                                                        |  19%  |                                                                              |==============                                                        |  20%  |                                                                              |==============                                                        |  21%  |                                                                              |===============                                                       |  21%  |                                                                              |===============                                                       |  22%  |                                                                              |================                                                      |  22%  |                                                                              |================                                                      |  23%  |                                                                              |================                                                      |  24%  |                                                                              |=================                                                     |  24%  |                                                                              |=================                                                     |  25%  |                                                                              |==================                                                    |  25%  |                                                                              |==================                                                    |  26%  |                                                                              |===================                                                   |  26%  |                                                                              |===================                                                   |  27%  |                                                                              |===================                                                   |  28%  |                                                                              |====================                                                  |  28%  |                                                                              |====================                                                  |  29%  |                                                                              |=====================                                                 |  29%  |                                                                              |=====================                                                 |  30%  |                                                                              |=====================                                                 |  31%  |                                                                              |======================                                                |  31%  |                                                                              |======================                                                |  32%  |                                                                              |=======================                                               |  32%  |                                                                              |=======================                                               |  33%  |                                                                              |=======================                                               |  34%  |                                                                              |========================                                              |  34%  |                                                                              |========================                                              |  35%  |                                                                              |=========================                                             |  35%  |                                                                              |=========================                                             |  36%  |                                                                              |==========================                                            |  36%  |                                                                              |==========================                                            |  37%  |                                                                              |==========================                                            |  38%  |                                                                              |===========================                                           |  38%  |                                                                              |===========================                                           |  39%  |                                                                              |============================                                          |  39%  |                                                                              |============================                                          |  40%  |                                                                              |============================                                          |  41%  |                                                                              |=============================                                         |  41%  |                                                                              |=============================                                         |  42%  |                                                                              |==============================                                        |  42%  |                                                                              |==============================                                        |  43%  |                                                                              |==============================                                        |  44%  |                                                                              |===============================                                       |  44%  |                                                                              |===============================                                       |  45%  |                                                                              |================================                                      |  45%  |                                                                              |================================                                      |  46%  |                                                                              |=================================                                     |  46%  |                                                                              |=================================                                     |  47%  |                                                                              |=================================                                     |  48%  |                                                                              |==================================                                    |  48%  |                                                                              |==================================                                    |  49%  |                                                                              |===================================                                   |  49%  |                                                                              |===================================                                   |  50%  |                                                                              |===================================                                   |  51%  |                                                                              |====================================                                  |  51%  |                                                                              |====================================                                  |  52%  |                                                                              |=====================================                                 |  52%  |                                                                              |=====================================                                 |  53%  |                                                                              |=====================================                                 |  54%  |                                                                              |======================================                                |  54%  |                                                                              |======================================                                |  55%  |                                                                              |=======================================                               |  55%  |                                                                              |=======================================                               |  56%  |                                                                              |========================================                              |  56%  |                                                                              |========================================                              |  57%  |                                                                              |========================================                              |  58%  |                                                                              |=========================================                             |  58%  |                                                                              |=========================================                             |  59%  |                                                                              |==========================================                            |  59%  |                                                                              |==========================================                            |  60%  |                                                                              |==========================================                            |  61%  |                                                                              |===========================================                           |  61%  |                                                                              |===========================================                           |  62%  |                                                                              |============================================                          |  62%  |                                                                              |============================================                          |  63%  |                                                                              |============================================                          |  64%  |                                                                              |=============================================                         |  64%  |                                                                              |=============================================                         |  65%  |                                                                              |==============================================                        |  65%  |                                                                              |==============================================                        |  66%  |                                                                              |===============================================                       |  66%  |                                                                              |===============================================                       |  67%  |                                                                              |===============================================                       |  68%  |                                                                              |================================================                      |  68%  |                                                                              |================================================                      |  69%  |                                                                              |=================================================                     |  69%  |                                                                              |=================================================                     |  70%  |                                                                              |=================================================                     |  71%  |                                                                              |==================================================                    |  71%  |                                                                              |==================================================                    |  72%  |                                                                              |===================================================                   |  72%  |                                                                              |===================================================                   |  73%  |                                                                              |===================================================                   |  74%  |                                                                              |====================================================                  |  74%  |                                                                              |====================================================                  |  75%  |                                                                              |=====================================================                 |  75%  |                                                                              |=====================================================                 |  76%  |                                                                              |======================================================                |  76%  |                                                                              |======================================================                |  77%  |                                                                              |======================================================                |  78%  |                                                                              |=======================================================               |  78%  |                                                                              |=======================================================               |  79%  |                                                                              |========================================================              |  79%  |                                                                              |========================================================              |  80%  |                                                                              |========================================================              |  81%  |                                                                              |=========================================================             |  81%  |                                                                              |=========================================================             |  82%  |                                                                              |==========================================================            |  82%  |                                                                              |==========================================================            |  83%  |                                                                              |==========================================================            |  84%  |                                                                              |===========================================================           |  84%  |                                                                              |===========================================================           |  85%  |                                                                              |============================================================          |  85%  |                                                                              |============================================================          |  86%  |                                                                              |=============================================================         |  86%  |                                                                              |=============================================================         |  87%  |                                                                              |=============================================================         |  88%  |                                                                              |==============================================================        |  88%  |                                                                              |==============================================================        |  89%  |                                                                              |===============================================================       |  89%  |                                                                              |===============================================================       |  90%  |                                                                              |===============================================================       |  91%  |                                                                              |================================================================      |  91%  |                                                                              |================================================================      |  92%  |                                                                              |=================================================================     |  92%  |                                                                              |=================================================================     |  93%  |                                                                              |=================================================================     |  94%  |                                                                              |==================================================================    |  94%  |                                                                              |==================================================================    |  95%  |                                                                              |===================================================================   |  95%  |                                                                              |===================================================================   |  96%  |                                                                              |====================================================================  |  96%  |                                                                              |====================================================================  |  97%  |                                                                              |====================================================================  |  98%  |                                                                              |===================================================================== |  98%  |                                                                              |===================================================================== |  99%  |                                                                              |======================================================================|  99%  |                                                                              |======================================================================| 100%</code></pre>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="sec12_8.html#cb25-1" tabindex="-1"></a><span class="fu">stopCluster</span>(ClusterHope)</span>
<span id="cb25-2"><a href="sec12_8.html#cb25-2" tabindex="-1"></a><span class="fu">close</span>(pb)</span></code></pre></div>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="sec12_8.html#cb26-1" tabindex="-1"></a>thetaHat <span class="ot">&lt;-</span> coda<span class="sc">::</span><span class="fu">mcmc</span>(PostThetasDraws[keep,])</span>
<span id="cb26-2"><a href="sec12_8.html#cb26-2" tabindex="-1"></a>PostDrawsSigma <span class="ot">&lt;-</span> coda<span class="sc">::</span><span class="fu">mcmc</span>(PostSigmaDraws[keep,])</span>
<span id="cb26-3"><a href="sec12_8.html#cb26-3" tabindex="-1"></a><span class="fu">summary</span>(thetaHat)</span></code></pre></div>
<pre><code>## 
## Iterations = 1:500
## Thinning interval = 1 
## Number of chains = 1 
## Sample size per chain = 500 
## 
## 1. Empirical mean and standard deviation for each variable,
##    plus standard error of the mean:
## 
##         Mean      SD Naive SE Time-series SE
## [1,]  2.0024 0.06627 0.002964       0.005361
## [2,]  1.0258 0.04519 0.002021       0.002601
## [3,]  0.9940 0.09020 0.004034       0.005913
## [4,]  0.9752 0.07649 0.003421       0.007188
## [5,]  1.0362 0.06203 0.002774       0.007439
## [6,] -0.9663 0.10289 0.004601       0.007471
## 
## 2. Quantiles for each variable:
## 
##         2.5%     25%     50%     75%   97.5%
## var1  1.8774  1.9564  2.0018  2.0471  2.1396
## var2  0.9408  0.9941  1.0244  1.0582  1.1107
## var3  0.8246  0.9342  0.9896  1.0604  1.1780
## var4  0.8306  0.9224  0.9715  1.0291  1.1185
## var5  0.9195  0.9934  1.0336  1.0785  1.1658
## var6 -1.1751 -1.0352 -0.9638 -0.8984 -0.7752</code></pre>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="sec12_8.html#cb28-1" tabindex="-1"></a><span class="fu">summary</span>(PostDrawsSigma)</span></code></pre></div>
<pre><code>## 
## Iterations = 1:500
## Thinning interval = 1 
## Number of chains = 1 
## Sample size per chain = 500 
## 
## 1. Empirical mean and standard deviation for each variable,
##    plus standard error of the mean:
## 
##        Mean      SD Naive SE Time-series SE
## [1,] 1.3227 0.09591 0.004289       0.008777
## [2,] 0.8719 0.08392 0.003753       0.012083
## 
## 2. Quantiles for each variable:
## 
##        2.5%    25%    50%    75% 97.5%
## var1 1.1732 1.2510 1.3174 1.3829 1.518
## var2 0.7196 0.8044 0.8758 0.9276 1.045</code></pre>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb30-1"><a href="sec12_8.html#cb30-1" tabindex="-1"></a>RegNOsel <span class="ot">&lt;-</span> MCMCpack<span class="sc">::</span><span class="fu">MCMCregress</span>(y <span class="sc">~</span> X <span class="sc">-</span> <span class="dv">1</span>)</span>
<span id="cb30-2"><a href="sec12_8.html#cb30-2" tabindex="-1"></a><span class="fu">summary</span>(RegNOsel)</span></code></pre></div>
<pre><code>## 
## Iterations = 1001:11000
## Thinning interval = 1 
## Number of chains = 1 
## Sample size per chain = 10000 
## 
## 1. Empirical mean and standard deviation for each variable,
##    plus standard error of the mean:
## 
##          Mean      SD  Naive SE Time-series SE
## X      2.2991 0.05380 0.0005380      0.0005390
## Xx1    0.8432 0.04265 0.0004265      0.0004265
## Xw1    1.2449 0.08532 0.0008532      0.0008698
## sigma2 1.0891 0.06178 0.0006178      0.0006178
## 
## 2. Quantiles for each variable:
## 
##          2.5%    25%    50%    75%  97.5%
## X      2.1947 2.2626 2.2987 2.3356 2.4050
## Xx1    0.7598 0.8145 0.8433 0.8714 0.9269
## Xw1    1.0740 1.1892 1.2461 1.3025 1.4096
## sigma2 0.9742 1.0464 1.0867 1.1289 1.2178</code></pre>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb32-1"><a href="sec12_8.html#cb32-1" tabindex="-1"></a><span class="fu">library</span>(coda)</span>
<span id="cb32-2"><a href="sec12_8.html#cb32-2" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb32-3"><a href="sec12_8.html#cb32-3" tabindex="-1"></a></span>
<span id="cb32-4"><a href="sec12_8.html#cb32-4" tabindex="-1"></a><span class="co"># 1) Extract the 2nd coefficient draws from each object</span></span>
<span id="cb32-5"><a href="sec12_8.html#cb32-5" tabindex="-1"></a>beta2_nosel <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(RegNOsel[, <span class="dv">2</span>])</span>
<span id="cb32-6"><a href="sec12_8.html#cb32-6" tabindex="-1"></a>beta2_sel   <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(thetaHat[, <span class="dv">2</span>])</span>
<span id="cb32-7"><a href="sec12_8.html#cb32-7" tabindex="-1"></a></span>
<span id="cb32-8"><a href="sec12_8.html#cb32-8" tabindex="-1"></a><span class="co"># 2) Put into a long data frame for ggplot</span></span>
<span id="cb32-9"><a href="sec12_8.html#cb32-9" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">rbind</span>(</span>
<span id="cb32-10"><a href="sec12_8.html#cb32-10" tabindex="-1"></a>  <span class="fu">data.frame</span>(<span class="at">value =</span> beta2_nosel, <span class="at">model =</span> <span class="st">&quot;No selection&quot;</span>),</span>
<span id="cb32-11"><a href="sec12_8.html#cb32-11" tabindex="-1"></a>  <span class="fu">data.frame</span>(<span class="at">value =</span> beta2_sel,   <span class="at">model =</span> <span class="st">&quot;With selection&quot;</span>)</span>
<span id="cb32-12"><a href="sec12_8.html#cb32-12" tabindex="-1"></a>)</span>
<span id="cb32-13"><a href="sec12_8.html#cb32-13" tabindex="-1"></a></span>
<span id="cb32-14"><a href="sec12_8.html#cb32-14" tabindex="-1"></a><span class="co"># 3) Compute summaries</span></span>
<span id="cb32-15"><a href="sec12_8.html#cb32-15" tabindex="-1"></a>summ <span class="ot">&lt;-</span> <span class="cf">function</span>(x) <span class="fu">c</span>(<span class="at">mean =</span> <span class="fu">mean</span>(x), <span class="fu">quantile</span>(x, <span class="fu">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>)))</span>
<span id="cb32-16"><a href="sec12_8.html#cb32-16" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">&quot;</span><span class="sc">\n</span><span class="st">Posterior summaries (2nd coefficient)</span><span class="sc">\n</span><span class="st">&quot;</span>)</span></code></pre></div>
<pre><code>## 
## Posterior summaries (2nd coefficient)</code></pre>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb34-1"><a href="sec12_8.html#cb34-1" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">&quot;No selection : &quot;</span>, <span class="fu">paste</span>(<span class="fu">round</span>(<span class="fu">summ</span>(beta2_nosel), <span class="dv">4</span>), <span class="at">collapse =</span> <span class="st">&quot;  &quot;</span>), <span class="st">&quot;</span><span class="sc">\n</span><span class="st">&quot;</span>)</span></code></pre></div>
<pre><code>## No selection :  0.8432  0.7598  0.9269</code></pre>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb36-1"><a href="sec12_8.html#cb36-1" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">&quot;With selection: &quot;</span>, <span class="fu">paste</span>(<span class="fu">round</span>(<span class="fu">summ</span>(beta2_sel),   <span class="dv">4</span>), <span class="at">collapse =</span> <span class="st">&quot;  &quot;</span>), <span class="st">&quot;</span><span class="sc">\n\n</span><span class="st">&quot;</span>)</span></code></pre></div>
<pre><code>## With selection:  1.0258  0.9408  1.1107</code></pre>
<div class="sourceCode" id="cb38"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb38-1"><a href="sec12_8.html#cb38-1" tabindex="-1"></a><span class="co"># 4) Plot both posteriors + true value line at 1</span></span>
<span id="cb38-2"><a href="sec12_8.html#cb38-2" tabindex="-1"></a><span class="fu">ggplot</span>(df, <span class="fu">aes</span>(<span class="at">x =</span> value, <span class="at">fill =</span> model, <span class="at">color =</span> model)) <span class="sc">+</span></span>
<span id="cb38-3"><a href="sec12_8.html#cb38-3" tabindex="-1"></a>  <span class="fu">geom_density</span>(<span class="at">alpha =</span> <span class="fl">0.25</span>, <span class="at">linewidth =</span> <span class="fl">0.8</span>) <span class="sc">+</span></span>
<span id="cb38-4"><a href="sec12_8.html#cb38-4" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="dv">1</span>, <span class="at">linetype =</span> <span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb38-5"><a href="sec12_8.html#cb38-5" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;Coefficient (2nd parameter)&quot;</span>, <span class="at">y =</span> <span class="st">&quot;Posterior density&quot;</span>,</span>
<span id="cb38-6"><a href="sec12_8.html#cb38-6" tabindex="-1"></a>       <span class="at">title =</span> <span class="st">&quot;Posterior of 2nd Coeff: No-Selection vs Selection Models&quot;</span>,</span>
<span id="cb38-7"><a href="sec12_8.html#cb38-7" tabindex="-1"></a>       <span class="at">subtitle =</span> <span class="st">&quot;Dashed line = population value (1)&quot;</span>) <span class="sc">+</span></span>
<span id="cb38-8"><a href="sec12_8.html#cb38-8" tabindex="-1"></a>  <span class="fu">theme_minimal</span>(<span class="at">base_size =</span> <span class="dv">12</span>) <span class="sc">+</span></span>
<span id="cb38-9"><a href="sec12_8.html#cb38-9" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">&quot;top&quot;</span>)</span></code></pre></div>
<p><img src="BayesianEconometrics_files/figure-html/unnamed-chunk-20-1.svg" width="672" /></p>
<p>The original Heckman selection model was not intended to calculate the ATE, since <span class="math inline">\(Y_i(0)\)</span> is not observed and, therefore, a treatment effect is not defined. Its main purpose is to correct the expected value of <span class="math inline">\(Y_i \mid D_i=1\)</span> by accounting for sample selection. Subsequently, <span class="citation">Heckman (<a href="#ref-heckman1990varieties">1990</a>)</span> and <span class="citation">Heckman and Vytlacil (<a href="#ref-heckman2005structural">2005</a>)</span> extended the sample selection framework to incorporate <span class="math inline">\(Y_i(0)\)</span>, framing the Roy model <span class="citation">(<a href="#ref-roy1951some">Roy 1951</a>)</span> within the treatment effect literature and establishing the identification conditions for different treatment parameters. In particular, <span class="citation">Heckman and Vytlacil (<a href="#ref-heckman2005structural">2005</a>)</span> introduced the marginal treatment effect (MTE),</p>
<p><span class="math display">\[
\tau_{MTE}(x,u_D) = \mathbb{E}[Y_i(1)-Y_i(0)\mid \mathbf{X}_i=\mathbf{x}, \, U_{Di}=u_D],
\]</span></p>
<p>which is the expected effect of treatment for individuals with observed characteristics <span class="math inline">\(\mathbf{X}_i=\mathbf{x}\)</span> and unobservable factors from the treatment assignment <span class="math inline">\(U_{Di}=u_D\)</span> <span class="citation">(<a href="#ref-heckman2005structural">Heckman and Vytlacil 2005</a>)</span>.</p>
<p>The MTE is a unifying concept that connects the treatment effect, selection, and matching literatures. Moreover, these authors show that many treatment effect parameters, such as the ATE, ATT, and LATE, can be expressed as weighted averages of the MTE (see Table IA in <span class="citation">Heckman and Vytlacil (<a href="#ref-heckman2005structural">2005</a>)</span>).</p>
<p>In the Bayesian literature, several authors have estimated different versions of selection models. In particular, <span class="citation">Van Hasselt (<a href="#ref-van2011bayesian">2011</a>)</span> and <span class="citation">Ding (<a href="#ref-ding2014bayesian">2014</a>)</span> analyze the sample selection model using flexible specifications for the error terms, while <span class="citation">Koop and Poirier (<a href="#ref-koop1997learning">1997</a>)</span> and <span class="citation">Chib (<a href="#ref-chib2007analysis">2007</a>)</span> estimate the Roy model. Furthermore, <span class="citation">Chib, Greenberg, and Jeliazkov (<a href="#ref-chib2009estimation">2009</a>)</span> extend the basic framework to a semiparametric setting that accounts for endogeneity, and <span class="citation">Heckman, Lopes, and Piatek (<a href="#ref-heckman2014treatment">2014</a>)</span> introduce latent factors to address the fundamental problem of causal inference in the Roy model. This approach allows researchers to learn about the otherwise unidentified covariance between <span class="math inline">\(Y_i(1)\)</span> and <span class="math inline">\(Y_i(0)\)</span>, which in turn enables the estimation of distributional versions of treatment effects that require the joint distribution of <span class="math inline">\(Y_i(1)\)</span> and <span class="math inline">\(Y_i(0)\)</span>.</p>
</div>
<h3>References<a href="references.html#references" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-chib2007analysis" class="csl-entry">
Chib, Siddhartha. 2007. <span>“Analysis of Treatment Response Data Without the Joint Distribution of Potential Outcomes.”</span> <em>Journal of Econometrics</em> 140 (2): 401–12.
</div>
<div id="ref-chib2009estimation" class="csl-entry">
Chib, Siddhartha, Edward Greenberg, and Ivan Jeliazkov. 2009. <span>“Estimation of Semiparametric Models in the Presence of Endogeneity and Sample Selection.”</span> <em>Journal of Computational and Graphical Statistics</em> 18 (2): 321–48.
</div>
<div id="ref-ding2014bayesian" class="csl-entry">
Ding, Peng. 2014. <span>“Bayesian Robust Inference of Sample Selection Using Selection-t Models.”</span> <em>Journal of Multivariate Analysis</em> 124: 451–64.
</div>
<div id="ref-greenberg2012introduction" class="csl-entry">
Greenberg, Edward. 2012. <em>Introduction to Bayesian Econometrics</em>. Cambridge University Press.
</div>
<div id="ref-heckman1979sample" class="csl-entry">
Heckman, James J. 1979. <span>“Sample Selection Bias as a Specification Error.”</span> <em>Econometrica</em> 47 (1): 153–61. <a href="https://doi.org/10.2307/1912352">https://doi.org/10.2307/1912352</a>.
</div>
<div id="ref-heckman1990varieties" class="csl-entry">
———. 1990. <span>“Varieties of Selection Bias.”</span> <em>American Economic Review</em> 80 (2): 313–18. <a href="http://www.jstor.org/stable/2006539">http://www.jstor.org/stable/2006539</a>.
</div>
<div id="ref-heckman2014treatment" class="csl-entry">
Heckman, James J., Hedibert F. Lopes, and Rémi Piatek. 2014. <span>“Treatment Effects: A Bayesian Perspective.”</span> <em>Econometric Reviews</em> 33 (1-4): 36–67. <a href="https://doi.org/10.1080/07474938.2013.807103">https://doi.org/10.1080/07474938.2013.807103</a>.
</div>
<div id="ref-heckman2005structural" class="csl-entry">
Heckman, James J., and Edward Vytlacil. 2005. <span>“Structural Equations, Treatment Effects, and Econometric Policy Evaluation.”</span> <em>Econometrica</em> 73 (3): 669–738. <a href="https://doi.org/10.1111/j.1468-0262.2005.00594.x">https://doi.org/10.1111/j.1468-0262.2005.00594.x</a>.
</div>
<div id="ref-koop1997learning" class="csl-entry">
Koop, Gary, and Dale J Poirier. 1997. <span>“Learning about the Across-Regime Correlation in Switching Regression Models.”</span> <em>Journal of Econometrics</em> 78 (2): 217–27.
</div>
<div id="ref-little2019statistical" class="csl-entry">
Little, Roderick J. A., and Donald B. Rubin. 2019. <em>Statistical Analysis with Missing Data</em>. 3rd ed. Wiley Series in Probability and Statistics. John Wiley &amp; Sons.
</div>
<div id="ref-roy1951some" class="csl-entry">
Roy, Andrew Donald. 1951. <span>“Some Thoughts on the Distribution of Earnings.”</span> <em>Oxford Economic Papers</em> 3 (2): 135–46.
</div>
<div id="ref-van2011bayesian" class="csl-entry">
Van Hasselt, Martijn. 2011. <span>“Bayesian Inference in a Sample Selection Model.”</span> <em>Journal of Econometrics</em> 165 (2): 221–32.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="sec_7.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="sec12_9.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": true,
    "facebook": true,
    "twitter": true,
    "linkedin": false,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": false,
    "all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
  },
  "fontsettings": {
    "theme": "white",
    "family": "sans",
    "size": 2
  },
  "edit": {
    "link": "https://github.com/aramir21/IntroductionBayesianEconometricsBook/10-Diagnostics.Rmd",
    "text": "Edit"
  },
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": null,
    "text": null
  },
  "download": null,
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "subsection"
  }
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
