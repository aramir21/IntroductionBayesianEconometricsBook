<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>13.5 Difference-in-differences design (DiD) | Introduction to Bayesian Econometrics</title>
  <meta name="description" content="The subject of this textbook is Bayesian data modeling, with the primary aim of providing an introduction to its theoretical foundations and facilitating the application of Bayesian inference using a GUI." />
  <meta name="generator" content="bookdown 0.43 and GitBook 2.6.7" />

  <meta property="og:title" content="13.5 Difference-in-differences design (DiD) | Introduction to Bayesian Econometrics" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="The subject of this textbook is Bayesian data modeling, with the primary aim of providing an introduction to its theoretical foundations and facilitating the application of Bayesian inference using a GUI." />
  <meta name="github-repo" content="https://github.com/aramir21/IntroductionBayesianEconometricsBook" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="13.5 Difference-in-differences design (DiD) | Introduction to Bayesian Econometrics" />
  
  <meta name="twitter:description" content="The subject of this textbook is Bayesian data modeling, with the primary aim of providing an introduction to its theoretical foundations and facilitating the application of Bayesian inference using a GUI." />
  

<meta name="author" content="Andrés Ramírez-Hassan" />


<meta name="date" content="2025-09-18" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="sec13_4.html"/>
<link rel="next" href="sec13_6.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Introduction to Bayesian Econometrics: A GUIded tour using R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction</a>
<ul>
<li class="chapter" data-level="" data-path="to-instructors-and-students.html"><a href="to-instructors-and-students.html"><i class="fa fa-check"></i>To instructors and students</a></li>
<li class="chapter" data-level="" data-path="acknowledgments.html"><a href="acknowledgments.html"><i class="fa fa-check"></i>Acknowledgments</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="Chap1.html"><a href="Chap1.html"><i class="fa fa-check"></i><b>1</b> Basic formal concepts</a>
<ul>
<li class="chapter" data-level="1.1" data-path="sec11.html"><a href="sec11.html"><i class="fa fa-check"></i><b>1.1</b> The Bayes’ rule</a></li>
<li class="chapter" data-level="1.2" data-path="sec12.html"><a href="sec12.html"><i class="fa fa-check"></i><b>1.2</b> Bayesian framework: A brief summary of theory</a></li>
<li class="chapter" data-level="1.3" data-path="sec14.html"><a href="sec14.html"><i class="fa fa-check"></i><b>1.3</b> Bayesian reports: Decision theory under uncertainty</a></li>
<li class="chapter" data-level="1.4" data-path="summary.html"><a href="summary.html"><i class="fa fa-check"></i><b>1.4</b> Summary</a></li>
<li class="chapter" data-level="1.5" data-path="exercises.html"><a href="exercises.html"><i class="fa fa-check"></i><b>1.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="Chap2.html"><a href="Chap2.html"><i class="fa fa-check"></i><b>2</b> Conceptual differences between the Bayesian and Frequentist approaches</a>
<ul>
<li class="chapter" data-level="2.1" data-path="sec21.html"><a href="sec21.html"><i class="fa fa-check"></i><b>2.1</b> The concept of probability</a></li>
<li class="chapter" data-level="2.2" data-path="sec22.html"><a href="sec22.html"><i class="fa fa-check"></i><b>2.2</b> Subjectivity is not the key</a></li>
<li class="chapter" data-level="2.3" data-path="sec23.html"><a href="sec23.html"><i class="fa fa-check"></i><b>2.3</b> Estimation, hypothesis testing and prediction</a></li>
<li class="chapter" data-level="2.4" data-path="sec24.html"><a href="sec24.html"><i class="fa fa-check"></i><b>2.4</b> The likelihood principle</a></li>
<li class="chapter" data-level="2.5" data-path="sec25.html"><a href="sec25.html"><i class="fa fa-check"></i><b>2.5</b> Why is not the Bayesian approach that popular?</a></li>
<li class="chapter" data-level="2.6" data-path="sec26.html"><a href="sec26.html"><i class="fa fa-check"></i><b>2.6</b> A simple working example</a></li>
<li class="chapter" data-level="2.7" data-path="sec27.html"><a href="sec27.html"><i class="fa fa-check"></i><b>2.7</b> Summary</a></li>
<li class="chapter" data-level="2.8" data-path="sec28.html"><a href="sec28.html"><i class="fa fa-check"></i><b>2.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="Chap3.html"><a href="Chap3.html"><i class="fa fa-check"></i><b>3</b> Cornerstone models: Conjugate families</a>
<ul>
<li class="chapter" data-level="3.1" data-path="sec41.html"><a href="sec41.html"><i class="fa fa-check"></i><b>3.1</b> Motivation of conjugate families</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="sec41.html"><a href="sec41.html#examples-of-exponential-family-distributions"><i class="fa fa-check"></i><b>3.1.1</b> Examples of exponential family distributions</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="sec42.html"><a href="sec42.html"><i class="fa fa-check"></i><b>3.2</b> Conjugate prior to exponential family</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="sec42.html"><a href="sec42.html#sec421"><i class="fa fa-check"></i><b>3.2.1</b> Examples: Theorem 4.2.1</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="sec43.html"><a href="sec43.html"><i class="fa fa-check"></i><b>3.3</b> Linear regression: The conjugate normal-normal/inverse gamma model</a></li>
<li class="chapter" data-level="3.4" data-path="sec44.html"><a href="sec44.html"><i class="fa fa-check"></i><b>3.4</b> Multivariate linear regression: The conjugate normal-normal/inverse Wishart model</a></li>
<li class="chapter" data-level="3.5" data-path="sec45.html"><a href="sec45.html"><i class="fa fa-check"></i><b>3.5</b> Summary</a></li>
<li class="chapter" data-level="3.6" data-path="sec46.html"><a href="sec46.html"><i class="fa fa-check"></i><b>3.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="Chap4.html"><a href="Chap4.html"><i class="fa fa-check"></i><b>4</b> Simulation methods</a>
<ul>
<li class="chapter" data-level="4.1" data-path="sec51.html"><a href="sec51.html"><i class="fa fa-check"></i><b>4.1</b> Markov Chain Monte Carlo methods</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="sec51.html"><a href="sec51.html#sec511"><i class="fa fa-check"></i><b>4.1.1</b> Gibbs sampler</a></li>
<li class="chapter" data-level="4.1.2" data-path="sec51.html"><a href="sec51.html#sec512"><i class="fa fa-check"></i><b>4.1.2</b> Metropolis-Hastings</a></li>
<li class="chapter" data-level="4.1.3" data-path="sec51.html"><a href="sec51.html#sec513"><i class="fa fa-check"></i><b>4.1.3</b> Hamiltonian Monte Carlo</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="sec52.html"><a href="sec52.html"><i class="fa fa-check"></i><b>4.2</b> Importance sampling</a></li>
<li class="chapter" data-level="4.3" data-path="sec53.html"><a href="sec53.html"><i class="fa fa-check"></i><b>4.3</b> Particle filtering</a></li>
<li class="chapter" data-level="4.4" data-path="sec54.html"><a href="sec54.html"><i class="fa fa-check"></i><b>4.4</b> Convergence diagnostics</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="sec54.html"><a href="sec54.html#numerical-standard-error"><i class="fa fa-check"></i><b>4.4.1</b> Numerical standard error</a></li>
<li class="chapter" data-level="4.4.2" data-path="sec54.html"><a href="sec54.html#effective-number-of-simulation-draws"><i class="fa fa-check"></i><b>4.4.2</b> Effective number of simulation draws</a></li>
<li class="chapter" data-level="4.4.3" data-path="sec54.html"><a href="sec54.html#tests-of-convergence"><i class="fa fa-check"></i><b>4.4.3</b> Tests of convergence</a></li>
<li class="chapter" data-level="4.4.4" data-path="sec54.html"><a href="sec54.html#checking-for-errors-in-the-posterior-simulator"><i class="fa fa-check"></i><b>4.4.4</b> Checking for errors in the posterior simulator</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="sec55.html"><a href="sec55.html"><i class="fa fa-check"></i><b>4.5</b> Summary</a></li>
<li class="chapter" data-level="4.6" data-path="sec56.html"><a href="sec56.html"><i class="fa fa-check"></i><b>4.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="Chap5.html"><a href="Chap5.html"><i class="fa fa-check"></i><b>5</b> Graphical user interface</a>
<ul>
<li class="chapter" data-level="5.1" data-path="secGUI1.html"><a href="secGUI1.html"><i class="fa fa-check"></i><b>5.1</b> Introduction</a></li>
<li class="chapter" data-level="5.2" data-path="secGUI2.html"><a href="secGUI2.html"><i class="fa fa-check"></i><b>5.2</b> Univariate models</a></li>
<li class="chapter" data-level="5.3" data-path="secGUI3.html"><a href="secGUI3.html"><i class="fa fa-check"></i><b>5.3</b> Multivariate models</a></li>
<li class="chapter" data-level="5.4" data-path="secGUI4.html"><a href="secGUI4.html"><i class="fa fa-check"></i><b>5.4</b> Time series models</a></li>
<li class="chapter" data-level="5.5" data-path="secGUI5.html"><a href="secGUI5.html"><i class="fa fa-check"></i><b>5.5</b> Longitudinal/panel models</a></li>
<li class="chapter" data-level="5.6" data-path="secGUI6.html"><a href="secGUI6.html"><i class="fa fa-check"></i><b>5.6</b> Bayesian model average</a></li>
<li class="chapter" data-level="5.7" data-path="secGUI7.html"><a href="secGUI7.html"><i class="fa fa-check"></i><b>5.7</b> Help</a></li>
<li class="chapter" data-level="5.8" data-path="secGUI8.html"><a href="secGUI8.html"><i class="fa fa-check"></i><b>5.8</b> Warning</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="Chap6.html"><a href="Chap6.html"><i class="fa fa-check"></i><b>6</b> Univariate regression</a>
<ul>
<li class="chapter" data-level="6.1" data-path="sec61.html"><a href="sec61.html"><i class="fa fa-check"></i><b>6.1</b> The Gaussian linear model</a></li>
<li class="chapter" data-level="6.2" data-path="sec62.html"><a href="sec62.html"><i class="fa fa-check"></i><b>6.2</b> The logit model</a></li>
<li class="chapter" data-level="6.3" data-path="sec63.html"><a href="sec63.html"><i class="fa fa-check"></i><b>6.3</b> The probit model</a></li>
<li class="chapter" data-level="6.4" data-path="sec64.html"><a href="sec64.html"><i class="fa fa-check"></i><b>6.4</b> The multinomial probit model</a></li>
<li class="chapter" data-level="6.5" data-path="sec65.html"><a href="sec65.html"><i class="fa fa-check"></i><b>6.5</b> The multinomial logit model</a></li>
<li class="chapter" data-level="6.6" data-path="sec66.html"><a href="sec66.html"><i class="fa fa-check"></i><b>6.6</b> Ordered probit model</a></li>
<li class="chapter" data-level="6.7" data-path="negative-binomial-model.html"><a href="negative-binomial-model.html"><i class="fa fa-check"></i><b>6.7</b> Negative binomial model</a></li>
<li class="chapter" data-level="6.8" data-path="sec68.html"><a href="sec68.html"><i class="fa fa-check"></i><b>6.8</b> Tobit model</a></li>
<li class="chapter" data-level="6.9" data-path="sec69.html"><a href="sec69.html"><i class="fa fa-check"></i><b>6.9</b> Quantile regression</a></li>
<li class="chapter" data-level="6.10" data-path="sec610.html"><a href="sec610.html"><i class="fa fa-check"></i><b>6.10</b> Bayesian bootstrap regression</a></li>
<li class="chapter" data-level="6.11" data-path="sec611.html"><a href="sec611.html"><i class="fa fa-check"></i><b>6.11</b> Summary</a></li>
<li class="chapter" data-level="6.12" data-path="sec612.html"><a href="sec612.html"><i class="fa fa-check"></i><b>6.12</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="Chap7.html"><a href="Chap7.html"><i class="fa fa-check"></i><b>7</b> Multivariate regression</a>
<ul>
<li class="chapter" data-level="7.1" data-path="sec71.html"><a href="sec71.html"><i class="fa fa-check"></i><b>7.1</b> Multivariate regression</a></li>
<li class="chapter" data-level="7.2" data-path="sec72.html"><a href="sec72.html"><i class="fa fa-check"></i><b>7.2</b> Seemingly Unrelated Regression</a></li>
<li class="chapter" data-level="7.3" data-path="sec73.html"><a href="sec73.html"><i class="fa fa-check"></i><b>7.3</b> Instrumental variable</a></li>
<li class="chapter" data-level="7.4" data-path="sec74.html"><a href="sec74.html"><i class="fa fa-check"></i><b>7.4</b> Multivariate probit model</a></li>
<li class="chapter" data-level="7.5" data-path="sec75.html"><a href="sec75.html"><i class="fa fa-check"></i><b>7.5</b> Summary</a></li>
<li class="chapter" data-level="7.6" data-path="sec76.html"><a href="sec76.html"><i class="fa fa-check"></i><b>7.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="Chap8.html"><a href="Chap8.html"><i class="fa fa-check"></i><b>8</b> Time series</a>
<ul>
<li class="chapter" data-level="8.1" data-path="sec81.html"><a href="sec81.html"><i class="fa fa-check"></i><b>8.1</b> State-space representation</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="sec81.html"><a href="sec81.html#gaussian-linear-state-space-models"><i class="fa fa-check"></i><b>8.1.1</b> Gaussian linear state-space models</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="sec82.html"><a href="sec82.html"><i class="fa fa-check"></i><b>8.2</b> ARMA processes</a></li>
<li class="chapter" data-level="8.3" data-path="sec83.html"><a href="sec83.html"><i class="fa fa-check"></i><b>8.3</b> Stochastic volatility models</a></li>
<li class="chapter" data-level="8.4" data-path="sec84.html"><a href="sec84.html"><i class="fa fa-check"></i><b>8.4</b> Vector Autoregressive models</a></li>
<li class="chapter" data-level="8.5" data-path="sec85.html"><a href="sec85.html"><i class="fa fa-check"></i><b>8.5</b> Summary</a></li>
<li class="chapter" data-level="8.6" data-path="sec86.html"><a href="sec86.html"><i class="fa fa-check"></i><b>8.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="Chap9.html"><a href="Chap9.html"><i class="fa fa-check"></i><b>9</b> Longitudinal regression</a>
<ul>
<li class="chapter" data-level="9.1" data-path="sec91.html"><a href="sec91.html"><i class="fa fa-check"></i><b>9.1</b> Normal model</a></li>
<li class="chapter" data-level="9.2" data-path="sec92.html"><a href="sec92.html"><i class="fa fa-check"></i><b>9.2</b> Logit model</a></li>
<li class="chapter" data-level="9.3" data-path="sec93.html"><a href="sec93.html"><i class="fa fa-check"></i><b>9.3</b> Poisson model</a></li>
<li class="chapter" data-level="9.4" data-path="sec94.html"><a href="sec94.html"><i class="fa fa-check"></i><b>9.4</b> Summary</a></li>
<li class="chapter" data-level="9.5" data-path="sec95.html"><a href="sec95.html"><i class="fa fa-check"></i><b>9.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="Chap10.html"><a href="Chap10.html"><i class="fa fa-check"></i><b>10</b> Bayesian model averaging in variable selection</a>
<ul>
<li class="chapter" data-level="10.1" data-path="sec10_1.html"><a href="sec10_1.html"><i class="fa fa-check"></i><b>10.1</b> Foundation</a></li>
<li class="chapter" data-level="10.2" data-path="sec102.html"><a href="sec102.html"><i class="fa fa-check"></i><b>10.2</b> The Gaussian linear model</a></li>
<li class="chapter" data-level="10.3" data-path="sec103.html"><a href="sec103.html"><i class="fa fa-check"></i><b>10.3</b> Generalized linear models</a></li>
<li class="chapter" data-level="10.4" data-path="sec10_4.html"><a href="sec10_4.html"><i class="fa fa-check"></i><b>10.4</b> Calculating the marginal likelihood</a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="sec10_4.html"><a href="sec10_4.html#sec10_4_1"><i class="fa fa-check"></i><b>10.4.1</b> Savage-Dickey density ratio</a></li>
<li class="chapter" data-level="10.4.2" data-path="sec10_4.html"><a href="sec10_4.html#sec10_4_2"><i class="fa fa-check"></i><b>10.4.2</b> Chib’s methods</a></li>
<li class="chapter" data-level="10.4.3" data-path="sec10_4.html"><a href="sec10_4.html#sec10_4_3"><i class="fa fa-check"></i><b>10.4.3</b> Gelfand-Dey method</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="sec10_5.html"><a href="sec10_5.html"><i class="fa fa-check"></i><b>10.5</b> Summary</a></li>
<li class="chapter" data-level="10.6" data-path="sec10_6.html"><a href="sec10_6.html"><i class="fa fa-check"></i><b>10.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="Chap11.html"><a href="Chap11.html"><i class="fa fa-check"></i><b>11</b> Semi-parametric and non-parametric models</a>
<ul>
<li class="chapter" data-level="11.1" data-path="sec11_1.html"><a href="sec11_1.html"><i class="fa fa-check"></i><b>11.1</b> Mixture models</a>
<ul>
<li class="chapter" data-level="11.1.1" data-path="sec11_1.html"><a href="sec11_1.html#sec11_11"><i class="fa fa-check"></i><b>11.1.1</b> Finite Gaussian mixtures</a></li>
<li class="chapter" data-level="11.1.2" data-path="sec11_1.html"><a href="sec11_1.html#sec11_12"><i class="fa fa-check"></i><b>11.1.2</b> Direchlet processes</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="sec11_2.html"><a href="sec11_2.html"><i class="fa fa-check"></i><b>11.2</b> Splines</a></li>
<li class="chapter" data-level="11.3" data-path="sec11_3.html"><a href="sec11_3.html"><i class="fa fa-check"></i><b>11.3</b> Summary</a></li>
<li class="chapter" data-level="11.4" data-path="sec11_4.html"><a href="sec11_4.html"><i class="fa fa-check"></i><b>11.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="Chap12.html"><a href="Chap12.html"><i class="fa fa-check"></i><b>12</b> Bayesian machine learning</a>
<ul>
<li class="chapter" data-level="12.1" data-path="sec12_1.html"><a href="sec12_1.html"><i class="fa fa-check"></i><b>12.1</b> Cross-validation and Bayes factors</a></li>
<li class="chapter" data-level="12.2" data-path="sec12_2.html"><a href="sec12_2.html"><i class="fa fa-check"></i><b>12.2</b> Regularization</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="sec12_2.html"><a href="sec12_2.html#sec12_21"><i class="fa fa-check"></i><b>12.2.1</b> Bayesian LASSO</a></li>
<li class="chapter" data-level="12.2.2" data-path="sec12_2.html"><a href="sec12_2.html#sec12_22"><i class="fa fa-check"></i><b>12.2.2</b> Stochastic search variable selection</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="sec12_3.html"><a href="sec12_3.html"><i class="fa fa-check"></i><b>12.3</b> Bayesian additive regression trees</a></li>
<li class="chapter" data-level="12.4" data-path="sec12_4.html"><a href="sec12_4.html"><i class="fa fa-check"></i><b>12.4</b> Gaussian processes</a></li>
<li class="chapter" data-level="12.5" data-path="sec12_5.html"><a href="sec12_5.html"><i class="fa fa-check"></i><b>12.5</b> Tall data problems</a>
<ul>
<li class="chapter" data-level="12.5.1" data-path="sec12_5.html"><a href="sec12_5.html#sec12_51"><i class="fa fa-check"></i><b>12.5.1</b> Divide-and-conquer methods</a></li>
<li class="chapter" data-level="12.5.2" data-path="sec12_5.html"><a href="sec12_5.html#sec12_52"><i class="fa fa-check"></i><b>12.5.2</b> Subsampling-based algorithms</a></li>
</ul></li>
<li class="chapter" data-level="12.6" data-path="id_13_6.html"><a href="id_13_6.html"><i class="fa fa-check"></i><b>12.6</b> Summary</a></li>
<li class="chapter" data-level="12.7" data-path="id_13_7.html"><a href="id_13_7.html"><i class="fa fa-check"></i><b>12.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="Chap13.html"><a href="Chap13.html"><i class="fa fa-check"></i><b>13</b> Causal inference</a>
<ul>
<li class="chapter" data-level="13.1" data-path="sec13_1.html"><a href="sec13_1.html"><i class="fa fa-check"></i><b>13.1</b> Identification setting</a></li>
<li class="chapter" data-level="13.2" data-path="sec13_2.html"><a href="sec13_2.html"><i class="fa fa-check"></i><b>13.2</b> Randomized controlled trial (RCT)</a></li>
<li class="chapter" data-level="13.3" data-path="sec13_3.html"><a href="sec13_3.html"><i class="fa fa-check"></i><b>13.3</b> Conditional independence assumption (CIA)</a></li>
<li class="chapter" data-level="13.4" data-path="sec13_4.html"><a href="sec13_4.html"><i class="fa fa-check"></i><b>13.4</b> Instrumental variables (IV)</a></li>
<li class="chapter" data-level="13.5" data-path="sec13_5.html"><a href="sec13_5.html"><i class="fa fa-check"></i><b>13.5</b> Difference-in-differences design (DiD)</a>
<ul>
<li class="chapter" data-level="13.5.1" data-path="sec13_5.html"><a href="sec13_5.html#sec13_51"><i class="fa fa-check"></i><b>13.5.1</b> Classic DiD: two-group and two-period (<span class="math inline">\(2\times2\)</span>) setup</a></li>
<li class="chapter" data-level="13.5.2" data-path="sec13_5.html"><a href="sec13_5.html#sec13_52"><i class="fa fa-check"></i><b>13.5.2</b> Staggered (SDiD): G-group and T-period (<span class="math inline">\(G\times T\)</span>) setup</a></li>
</ul></li>
<li class="chapter" data-level="13.6" data-path="sec13_6.html"><a href="sec13_6.html"><i class="fa fa-check"></i><b>13.6</b> Regression discontinuity design (RD)</a>
<ul>
<li class="chapter" data-level="13.6.1" data-path="sec13_6.html"><a href="sec13_6.html#sec13_61"><i class="fa fa-check"></i><b>13.6.1</b> Sharp regression discontinuity design (SRD)</a></li>
<li class="chapter" data-level="13.6.2" data-path="sec13_6.html"><a href="sec13_6.html#sec13_62"><i class="fa fa-check"></i><b>13.6.2</b> Fuzzy regression discontinuity design (FRD)</a></li>
</ul></li>
<li class="chapter" data-level="13.7" data-path="sec13_7.html"><a href="sec13_7.html"><i class="fa fa-check"></i><b>13.7</b> Sample selection</a></li>
<li class="chapter" data-level="13.8" data-path="sec13_8.html"><a href="sec13_8.html"><i class="fa fa-check"></i><b>13.8</b> Bayesian exponentially tilted empirical likelihood</a></li>
<li class="chapter" data-level="13.9" data-path="sec13_10.html"><a href="sec13_10.html"><i class="fa fa-check"></i><b>13.9</b> Doubly robust Bayesian inferential framework (DRB)</a></li>
<li class="chapter" data-level="13.10" data-path="sec13_11.html"><a href="sec13_11.html"><i class="fa fa-check"></i><b>13.10</b> Summary</a></li>
<li class="chapter" data-level="13.11" data-path="sec13_12.html"><a href="sec13_12.html"><i class="fa fa-check"></i><b>13.11</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="Chap14.html"><a href="Chap14.html"><i class="fa fa-check"></i><b>14</b> Approximate Bayesian methods</a>
<ul>
<li class="chapter" data-level="14.1" data-path="sec14_1.html"><a href="sec14_1.html"><i class="fa fa-check"></i><b>14.1</b> Simulation-based approaches</a>
<ul>
<li class="chapter" data-level="14.1.1" data-path="sec14_1.html"><a href="sec14_1.html#sec14_11"><i class="fa fa-check"></i><b>14.1.1</b> Approximate Bayesian computation</a></li>
<li class="chapter" data-level="14.1.2" data-path="sec14_1.html"><a href="sec14_1.html#sec14_12"><i class="fa fa-check"></i><b>14.1.2</b> Bayesian synthetic likelihood</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="sec14_2.html"><a href="sec14_2.html"><i class="fa fa-check"></i><b>14.2</b> Optimization approaches</a>
<ul>
<li class="chapter" data-level="14.2.1" data-path="sec14_2.html"><a href="sec14_2.html#sec14_21"><i class="fa fa-check"></i><b>14.2.1</b> Integrated nested Laplace approximations</a></li>
<li class="chapter" data-level="14.2.2" data-path="sec14_2.html"><a href="sec14_2.html#sec14_22"><i class="fa fa-check"></i><b>14.2.2</b> Variational Bayes</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="summary-1.html"><a href="summary-1.html"><i class="fa fa-check"></i><b>14.3</b> Summary</a></li>
<li class="chapter" data-level="14.4" data-path="sec14_4.html"><a href="sec14_4.html"><i class="fa fa-check"></i><b>14.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i>Appendix</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to Bayesian Econometrics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="sec13_5" class="section level2 hasAnchor" number="13.5">
<h2><span class="header-section-number">13.5</span> Difference-in-differences design (DiD)<a href="sec13_5.html#sec13_5" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In this section, we present how to perform inference and discuss the identification conditions when working with panel (longitudinal) data or repeated cross-sectional data in the <em>difference-in-differences</em> (DiD) framework. In DiD designs, we estimate causal effects by comparing changes over time between groups that receive the treatment and groups that do not (the “control” group). This approach is among the most widely used designs for identifying causal effects <span class="citation">(<a href="#ref-baker2025did_guide">Baker et al. 2025</a>)</span>. Its origins can be traced back to John Snow, the father of modern epidemiology, who in 1855 analyzed the spread of cholera through water in London <span class="citation">(<a href="#ref-chernozhukov2024applied">Chernozhukov et al. 2024</a>)</span>.</p>
<p>In what follows, we first present the basic two-group, two-period (<span class="math inline">\(2\times2\)</span>) DiD setup, and then introduce the staggered DiD design.</p>
<div id="sec13_51" class="section level3 hasAnchor" number="13.5.1">
<h3><span class="header-section-number">13.5.1</span> Classic DiD: two-group and two-period (<span class="math inline">\(2\times2\)</span>) setup<a href="sec13_5.html#sec13_51" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Following <span class="citation">Roth et al. (<a href="#ref-roth2023whats">2023</a>)</span>, we consider a setting with two time periods, <span class="math inline">\(t = 1, 2\)</span>, and two groups: a treated group (<span class="math inline">\(D_i = 1\)</span>) that receives the treatment between periods <span class="math inline">\(t = 1\)</span> and <span class="math inline">\(t = 2\)</span>, and a control group that never receives the treatment (<span class="math inline">\(D_i = 0\)</span>). We observe outcomes <span class="math inline">\(Y_{it}\)</span> and treatment status <span class="math inline">\(D_i\)</span> for units <span class="math inline">\(i = 1, 2, \dots, N\)</span>, assuming a balanced panel data structure.</p>
<p>Let <span class="math inline">\(Y_{it}(1)\)</span> denote the potential outcome for unit <span class="math inline">\(i\)</span> in period <span class="math inline">\(t\)</span> if it is untreated in the first period and treated in the second, while <span class="math inline">\(Y_{it}(0)\)</span> denotes the potential outcome if it is never treated. In the DiD framework, the primary estimand of interest is the average treatment effect on the treated (ATT),</p>
<p><span class="math display">\[
\tau_{2} = \mathbb{E}[Y_{i2}(1) - Y_{i2}(0) \mid D_i = 1].
\]</span></p>
<p>Note that we do not observe <span class="math inline">\(Y_{i2}(0) \mid D_i = 1\)</span>; that is, the outcome in the second period for treated units if they had not received the treatment. Thus, the identification conditions in DiD are designed to express this counterfactual outcome as a function of the data.</p>
<p>There are two key identification assumptions:</p>
<p><em>Parallel trends:</em></p>
<p><span class="math display">\[
\mathbb{E}[Y_{i2}(0) - Y_{i1}(0) \mid D_i = 1] = \mathbb{E}[Y_{i2}(0) - Y_{i1}(0) \mid D_i = 0],
\]</span></p>
<p>which states that, in the absence of treatment, the average change in outcomes for the treated and control groups would have evolved similarly over time.</p>
<p><em>No anticipation effects:</em></p>
<p><span class="math display">\[
\mathbb{E}[Y_{i1}(0)\mid D_i=1] = \mathbb{E}[Y_{i1}(1)\mid D_i=1],
\]</span></p>
<p>meaning that the treatment has no causal effect prior to its implementation.</p>
<p>Thus, we can use the parallel trends assumption to express <span class="math inline">\(\mathbb{E}[Y_{i2}(0) \mid D_i = 1]\)</span> as</p>
<p><span class="math display">\[
\begin{aligned}
\mathbb{E}[Y_{i2}(0)\mid D_i = 1]
&amp;= \mathbb{E}[Y_{i1}(0) \mid D_i = 1] + \mathbb{E}[Y_{i2}(0) - Y_{i1}(0) \mid D_i = 0] \\
&amp;= \mathbb{E}[Y_{i1}(1) \mid D_i = 1] + \mathbb{E}[Y_{i2}(0) - Y_{i1}(0) \mid D_i = 0] \\
&amp;= \mathbb{E}[Y_{i1} \mid D_i = 1] + \mathbb{E}[Y_{i2} - Y_{i1} \mid D_i = 0],
\end{aligned}
\]</span></p>
<p>where the second equality follows from the no anticipation effects assumption.</p>
<p>Therefore,</p>
<p><span class="math display" id="eq:DiD">\[\begin{equation}
\tau_2 = \mathbb{E}[Y_{i2} - Y_{i1} \mid D_i = 1] - \mathbb{E}[Y_{i2} - Y_{i1} \mid D_i = 0],
\tag{13.2}
\end{equation}\]</span></p>
<p>that is, the ATT is the difference in outcome differences between treated and control units.</p>
<p>The following figure shows a graphical representation of the identification assumptions in DiD <span class="citation">(<a href="#ref-chernozhukov2024applied">Chernozhukov et al. 2024</a>)</span>. <span class="citation">Normington et al. (<a href="#ref-normington2022bayesian">2022</a>)</span> show a DAG representation of DiD.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:unnamed-chunk-13"></span>
<img src="figures/FigChap13_8.png" alt="Difference-in-Differences: Identification strategy." width="600px" />
<p class="caption">
Figure 13.8: Difference-in-Differences: Identification strategy.
</p>
</div>
<p>Note that we can express the observed outcome in terms of potential outcomes as</p>
<p><span class="math display">\[
Y_{it} = Y_{it}(0) + \big[\,Y_{it}(1) - Y_{it}(0)\,\big] D_i.
\]</span></p>
<p>Therefore,</p>
<p><span class="math display">\[
Y_{i1} = Y_{i1}(0) + \big[\,Y_{i1}(1) - Y_{i1}(0)\,\big] D_i,
\]</span></p>
<p>and</p>
<p><span class="math display">\[
Y_{i2} = Y_{i2}(0) + \big[\,Y_{i2}(1) - Y_{i2}(0)\,\big] D_i.
\]</span></p>
<p>Subtracting the first equation from the second yields</p>
<p><span class="math display">\[
Y_{i2} - Y_{i1} = \underbrace{Y_{i2}(0) - Y_{i1}(0)}_{\text{common trend}}
+ \underbrace{\big[(Y_{i2}(1) - Y_{i1}(1)) - (Y_{i2}(0) - Y_{i1}(0))\,\big]}_{\text{treatment effect in changes}} D_i.
\]</span></p>
<p>Under the <em>parallel trends</em> assumption, the expected value of the common trend is the same for treated and control units. This assumption is compatible with the linear CEF function</p>
<p><span class="math display">\[
Y_{it} = \alpha_i + \phi_t + \tau_2 D_i + \mu_{it},
\]</span></p>
<p>which implies</p>
<p><span class="math display">\[
Y_{i2} - Y_{i1} = (\phi_2 - \phi_1) + \tau_2 D_i + (\mu_{i2} - \mu_{i1}).
\]</span></p>
<p>Comparing this expression with the one derived from the potential outcomes framework, it follows that regressing the time difference <span class="math inline">\(Y_{i2} - Y_{i1}\)</span> on a constant and the treatment indicator <span class="math inline">\(D_i\)</span> identifies <span class="math inline">\(\tau_2\)</span>, the ATT.</p>
<p>Another common formulation in the linear regression setting that recovers the ATT is the two-way fixed effects (TWFE) model</p>
<p><span class="math display">\[
Y_{it} = \alpha + \alpha_i + \phi_t + \tau_2 \,\big[ D_i \cdot \mathbf{1}(t = 2) \big] + \epsilon_{it},
\]</span></p>
<p>where <span class="math inline">\(\mathbf{1}(t = 2)\)</span> is an indicator for the post-treatment period <span class="citation">(<a href="#ref-roth2023whats">Roth et al. 2023</a>)</span>. The advantage of the regression setting is that it allows for the straightforward calculation of the standard error of the ATT, enabling the construction of confidence or credible intervals under the Frequentist and Bayesian approaches, respectively.</p>
<p>The DiD framework can be extended to condition on covariates. In this case, we assume that the underlying identification assumptions are more plausible among units that are similar in terms of observed characteristics. Thus, the identification assumptions are stated conditional on the exogenous variables.</p>
<p>Therefore, we can use covariates to assess the balance between control and treated groups in terms of levels (<span class="math inline">\(X\)</span>) or differences (<span class="math inline">\(\Delta X\)</span>) before and after treatment:</p>
<p><span class="math display">\[
\frac{\bar{X}_1-\bar{X}_2}{\sqrt{\hat{\sigma}_1^2+\hat{\sigma}_2^2}},
\]</span></p>
<p>where <span class="math inline">\(\hat{\sigma}_l^2\)</span> is the sample variance of <span class="math inline">\(X_l\)</span>, <span class="math inline">\(l=\{1,2\}\)</span>.<br />
As a rule of thumb, absolute standardized differences greater than 0.25 indicate potentially problematic imbalance <span class="citation">(<a href="#ref-baker2025did_guide">Baker et al. 2025</a>)</span>. Imbalance in covariates can lead to violations of the parallel trends assumption if these covariates would generate different outcomes under the counterfactual scenarios.</p>
<p>In this setting, the <em>conditional parallel trends</em> assumption becomes</p>
<p><span class="math display">\[\begin{equation}
\mathbb{E}[Y_{i2}(0) - Y_{i1}(0) \mid D_i = 1, \mathbf{X}_i]
= \mathbb{E}[Y_{i2}(0) - Y_{i1}(0) \mid D_i = 0, \mathbf{X}_i], \ \text{almost surely}
\end{equation}\]</span></p>
<p>and the <em>no anticipation</em> assumption becomes</p>
<p><span class="math display">\[\begin{equation}
\mathbb{E}[Y_{i1}(0) \mid D_i = 1, \mathbf{X}_i]
= \mathbb{E}[Y_{i1}(1) \mid D_i = 1, \mathbf{X}_i].
\end{equation}\]</span></p>
<p>In addition, the <em>overlap</em> assumption is required: there exists a treatment group whose characteristics overlap with those of the control group,</p>
<p><span class="math display">\[
P(D_i = 1 \mid \mathbf{X}_i) &lt; 1 - \epsilon, \ \epsilon &gt;0, \ \text{almost surely, and,} \ P(D_i=1)&gt;0.
\]</span></p>
<p>Following similar arguments as before, we obtain the <em>conditional average treatment effect on the treated</em> (CATT) <span class="citation">(<a href="#ref-baker2025did_guide">Baker et al. 2025</a>)</span>:</p>
<p><span class="math display">\[
\tau_2(\mathbf{X}_i)= \mathbb{E}[Y_{i2} - Y_{i1} \mid D_i = 1, \mathbf{X}_i] - \mathbb{E}[Y_{i2} - Y_{i1} \mid D_i = 0, \mathbf{X}_i].
\]</span></p>
<p>The overall ATT can then be recovered by averaging over the distribution of <span class="math inline">\(\mathbf{X}_i\)</span> in the treated population:</p>
<p><span class="math display">\[
\begin{aligned}
\tau_2 &amp; = \mathbb{E}_{\mathbf{X}}\left\{\mathbb{E}[Y_{i2} - Y_{i1} \mid D_i = 1, \mathbf{X}_i] - \mathbb{E}[Y_{i2} - Y_{i1} \mid D_i = 0, \mathbf{X}_i] \mid D_i = 1\right\}\\
&amp;=\mathbb{E}[Y_{i2} - Y_{i1} \mid D_i = 1]-\mathbb{E}_{\mathbf{X}}\left\{\mathbb{E}[Y_{i2} - Y_{i1} \mid D_i = 0, \mathbf{X}_i]\mid D_i=1\right\},
\end{aligned}
\]</span></p>
<p>where the second line uses the law of iterated expectations:</p>
<p><span class="math display">\[
\mathbb{E}_{\mathbf{X}\mid D=1}\!\left( \mathbb{E}[Y_{i2}-Y_{i1} \mid D=1, \mathbf{X}_i] \right)
= \mathbb{E}[Y_{i2}-Y_{i1} \mid D=1].
\]</span></p>
<p>Assuming a linear CEF and a homogeneous ATT, that is, treatment effects do not vary across <span class="math inline">\(\mathbf{X}_{it}\)</span>, we can use the first–difference specification,</p>
<p><span class="math display">\[
\Delta Y_{i2} = \alpha + \beta D_i + \sum_{k=1}^K \beta_k \Delta X_{ik2} + \Delta\mu_{i2},
\]</span></p>
<p>where <span class="math inline">\(\Delta Y_{i2} = Y_{i2} - Y_{i1}\)</span> and <span class="math inline">\(\Delta X_{ik2} = X_{ik2} - X_{ik1}\)</span>. This specification identifies the ATT under the homogeneity assumption, in which case <span class="math inline">\(\tau_2 = \beta\)</span>; otherwise, it identifies a weighted average of the conditional ATTs across covariates, with the possibility of negative weights that do not sum to one (<em>non-convex weights</em>) <span class="citation">(<a href="#ref-baker2025did_guide">Baker et al. 2025</a>)</span>.</p>
<p>An alternative specification is the TWFE</p>
<p><span class="math display">\[
\begin{aligned}
Y_{it} &amp; = \alpha + \alpha_i + \phi_t + \beta (\mathbf{1}(t=2)\cdot D_i) +   \sum_{k=1}^K \beta_k (\mathbf{1}(t=2)\cdot X_{ik1})\\
&amp; +  \sum_{k=1}^K \delta_k (\mathbf{1}(t=2)\cdot D_i \cdot X_{ik1}) + \epsilon_{it}.
\end{aligned}
\]</span></p>
<p>This specification can identify heterogeneous ATT under the assumption of a linear CEF.</p>
<p>However, alternative <em>semiparametric</em> and <em>nonparametric</em> approaches, such as <em>outcome regression adjustment</em>, <em>inverse probability weighting</em>, and <em>doubly robust</em> estimators (which combine the first two), are often preferable because they yield consistent estimates under conditional parallel trends without requiring a linear conditional expectation function (CEF) <span class="citation">(<a href="#ref-abadie2005semiparametric">Abadie 2005</a>; <a href="#ref-roth2023whats">Roth et al. 2023</a>)</span>. These approaches typically involve two stages: first, estimating either the conditional mean of the outcome or the propensity score (probability of treatment <span class="citation">(<a href="#ref-rosenbaum1983central">Rosenbaum and Rubin 1983</a>)</span>), and second, using these estimates in a plug-in step to perform inference on the ATT. For Bayesian doubly robust frameworks for average treatment effects, see <span class="citation">Saarela, Belzile, and Stephens (<a href="#ref-SaarelaBelzileStephens2016">2016</a>)</span>, <span class="citation">Yiu, Goudie, and Tom (<a href="#ref-YiuGoudieTom2020">2020</a>)</span>, <span class="citation">Luo, Graham, and McCoy (<a href="#ref-LuoGrahamMcCoy2023">2023</a>)</span>, <span class="citation">Breunig, Liu, and Yu (<a href="#ref-breunig2025double">2025</a>)</span>.</p>
<p>A point to be aware of when performing DiD identification strategies is that the parallel trends assumption is generally not robust to functional form transformations of the outcome. That is, it may hold when the outcome is measured in levels but fail when it is expressed in logarithms. This is because two groups can have the same absolute increase (parallel trends in levels) but different percentage increases (non-parallel in logs).</p>
<p>Note that the parallel trends and no anticipation assumptions in DiD are not fundamentally testable, since they are identifying restrictions about counterfactual outcomes that are never observed. However, we can examine pre-treatment dynamics to assess their plausibility. For instance, we can check for pre-existing differences in trends (“pre-trends”) as a diagnostic for the parallel trends assumption.</p>
<p>Given a pre-treatment period <span class="math inline">\(t=0\)</span>, the no anticipation assumption implies that</p>
<p><span class="math display">\[
\mathbb{E}[Y_{it}(0)] = \mathbb{E}[Y_{it}] \quad \text{for all } i \text{ and } t \leq 0.
\]</span></p>
<p>Thus, one can test whether</p>
<p><span class="math display">\[\begin{equation}
\mathbb{E}[Y_{i1}(0) - Y_{i0}(0) \mid D_i = 1]
= \mathbb{E}[Y_{i1}(0) - Y_{i0}(0) \mid D_i = 0],
\end{equation}\]</span></p>
<p>which corresponds to checking for differences in pre-treatment trends between treated and control groups.</p>
<p>The results of such tests should be interpreted with caution. Even if pre-trends are perfectly parallel, this does not guarantee that the parallel trends assumption will hold in the post-treatment period. Moreover, there may be power issues: a true pre-existing difference in trends may go undetected if pre-treatment estimates are imprecise due to high variability.</p>
<p>In addition, one can conduct placebo tests by pretending that the policy started earlier and checking whether a spurious effect is detected prior to the true start. This provides indirect evidence on the plausibility of the no anticipation assumption.</p>
<p>Therefore, it is advisable to complement pre-trend diagnostics with sensitivity analyses, incorporating context-specific knowledge about plausible confounding factors.</p>
</div>
<div id="sec13_52" class="section level3 hasAnchor" number="13.5.2">
<h3><span class="header-section-number">13.5.2</span> Staggered (SDiD): G-group and T-period (<span class="math inline">\(G\times T\)</span>) setup<a href="sec13_5.html#sec13_52" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Many empirical settings are more complex than the two-period, two-group (<span class="math inline">\(2\times 2\)</span>) design. Nevertheless, even in such settings we can view the design as an aggregation of <span class="math inline">\(2\times 2\)</span> comparisons between units that receive treatment and units that are not yet treated at the relevant time <span class="citation">(<a href="#ref-baker2025did_guide">Baker et al. 2025</a>)</span>.</p>
<p>In a setting with multiple periods and different groups, assuming that treatment is an absorbing state —that is, once treated, units remain treated— staggered DiD (SDiD) analyses seek to estimate a weighted average of heterogeneous ATTs, where the weights may be based on economic/policy relevance.</p>
<p>Given <span class="math inline">\(t = 1, 2, \dots, T\)</span>, a unit can be treated at <span class="math inline">\(t = g &gt; 1\)</span>,</p>
<p><span class="math display">\[
Y_{it}(g) := Y_{it}\big(\underbrace{0, \dots, 0}_{g-1}, \underbrace{1, \dots, 1}_{T-g+1}\big)
\]</span></p>
<p>denotes the potential outcome path for a unit treated at <span class="math inline">\(g\)</span>, and</p>
<p><span class="math display">\[
Y_{it}(\infty) := Y_{it}\big(\underbrace{0, \dots, 0}_{T}\big)
\]</span></p>
<p>denotes the potential outcome path for a never-treated unit.<br />
Under the absorbing treatment assumption, <span class="math inline">\(D_{it} = 1\)</span> for all <span class="math inline">\(t \geq g\)</span>. Let</p>
<p><span class="math display">\[
G_i = \min\left\{ t : D_{it} = 1 \right\}
\]</span></p>
<p>denote the first period in which unit <span class="math inline">\(i\)</span> is treated.</p>
<p>The average treatment effect for units first treated in period <span class="math inline">\(g\)</span> at time <span class="math inline">\(t\)</span> is</p>
<p><span class="math display">\[
ATT(g,t) = \mathbb{E}\left[ Y_{it}(g) - Y_{it}(\infty) \,\middle|\, G_i = g \right].
\]</span></p>
<p>Therefore, each cohort <span class="math inline">\(g\)</span> has its own <span class="math inline">\(T-1\)</span> ATT estimands. Each <span class="math inline">\(ATT(g,t)\)</span> represents the average treatment effect of initiating treatment in period <span class="math inline">\(g\)</span>, relative to never receiving treatment.</p>
<p>The identifying assumptions for <span class="math inline">\(ATT(g,t)\)</span> are:</p>
<p><em>1. Staggered parallel trends based on not-yet-treated units:</em></p>
<p><span class="math display" id="eq:SDiDNY">\[\begin{equation}
\mathbb{E}[Y_{it}(\infty) - Y_{it-1}(\infty) \mid G_i = g]
= \mathbb{E}[Y_{it}(\infty) - Y_{it-1}(\infty) \mid G_i = g&#39;], \quad \forall\, t \geq g, g&#39;&gt;t.
\tag{13.3}
\end{equation}\]</span></p>
<p>The <em>not-yet-treated</em> staggered parallel assumption establishes that the average change in potential outcomes for all treated groups would have evolved in parallel after treatment began, under the counterfactual scenario in which they had not received treatment.</p>
<p>Note that the <em>not-yet-treated</em> parallel trends assumption can be modified to use <em>never-treated</em> units as the comparison group (replace <span class="math inline">\(g&#39;\)</span> by <span class="math inline">\(\infty\)</span> in Equation <a href="sec13_5.html#eq:SDiDNY">(13.3)</a>), or to impose parallel trends across <em>all</em> groups and periods (no restrictions on <span class="math inline">\(g\)</span> and <span class="math inline">\(g&#39;\)</span>). The <em>all-groups, all-periods</em> version is more demanding but can yield more precise estimates because it exploits a larger set of observations. In contrast, the <em>never-treated</em> version requires fewer assumptions about parallel trends but is typically less precise. The <em>not-yet-treated</em> version represents a middle ground between these two. Ultimately, the choice of which parallel trends assumption to adopt is context-specific .</p>
<p><em>2. Staggered no anticipation:</em></p>
<p><span class="math display">\[
\mathbb{E}[Y_{it}(g)] = \mathbb{E}[Y_{it}(\infty)], \quad \forall\, i,\ t &lt; g.
\]</span></p>
<p>That is, treated units do not change their potential outcomes in anticipation of future treatment before treatment begins.</p>
<p>Thus, to identify long-term effects, the parallel trends assumption must hold for all periods after the earliest treatment period in the not-yet-treated case. If the goal is to estimate effects in a specific short-term period, parallel trends must hold in that period.</p>
<p>Note that under these assumptions, we can express <span class="math inline">\(ATT(g,t)\)</span> in terms of observable outcomes as <span class="citation">(<a href="#ref-roth2023whats">Roth et al. 2023</a>)</span></p>
<p><span class="math display">\[
ATT(g,t)
= \mathbb{E}\big[ Y_{it} - Y_{i, g-1} \mid G_i = g \big]
- \mathbb{E}\big[ Y_{it} - Y_{i, g-1} \mid G_i = g&#39;, \ g&#39; &gt; t \big].
\]</span></p>
<p>This formulation makes explicit the choice of the comparison group, either not-yet-treated or never-treated units in this setting. Moreover, cohorts are indexed by the first treatment date <span class="math inline">\(g\)</span>, and effects are evaluated at calendar time <span class="math inline">\(t\)</span>. Hence the object of interest is cohort–time specific, <span class="math inline">\(ATT(g,t)\)</span>, and staggered designs generally imply a multiplicity of ATT parameters, where each estimand can be seen as a multi-period version of a DiD causal effect (Equation <a href="sec13_5.html#eq:DiD">(13.2)</a>).</p>
<p>To study the dynamics of treatment effects, we can use <em>event study</em> plots. These involve estimating and reporting effects for a range of periods before and after treatment, allowing us to analyze the temporal pattern of the ATTs <span class="citation">(<a href="#ref-baker2025did_guide">Baker et al. 2025</a>)</span>.</p>
<p>An advantage of having multiple pre-treatment periods in the design is that it allows calculating <em>falsification/placebo tests</em>. Under the <em>no anticipation</em> assumption, any potential effect before <span class="math inline">\(G_i\)</span> must be zero. That is, given <span class="math inline">\(b &lt; \min\{g,g&#39;\}\)</span>, for all <span class="math inline">\(t\)</span> with <span class="math inline">\(b &lt; t &lt; \min\{g,g&#39;\}\)</span>:</p>
<p><span class="math display">\[
\mathbb{E}\!\left[\,Y_{it}-Y_{ib}\mid G_i=g\right]
=
\mathbb{E}\!\left[\,Y_{it}-Y_{ib}\mid G_i=g&#39;\right].
\]</span></p>
<p>Thus, we can test whether the differences in the expected changes of the outcome variable before treatment between different groups are statistically indistinguishable from zero. If this is the case, common practice would suggest that there is evidence in favor of parallel trends. However, we should remember that the parallel trends assumption is essentially untestable because it imposes restrictions on post-treatment periods, not on pre-treatment periods. Consequently, the same recommendations as those at the end of the previous section apply: perform sensitivity analyses regarding potential violations of the parallel trends assumption.</p>
<p>Assuming that parallel trends hold conditional on covariates, we obtain identification under the following assumptions:</p>
<p><em>1. Staggered parallel trends with not-yet-treated comparison (conditional on <span class="math inline">\(\mathbf X_i\)</span>):</em></p>
<p><span class="math display">\[
\mathbb{E}\!\left[Y_{it}(\infty)-Y_{i,t-1}(\infty)\mid G_i=g,\ \mathbf X_i\right]
=
\mathbb{E}\!\left[Y_{it}(\infty)-Y_{i,t-1}(\infty)\mid G_i&gt;t,\ \mathbf X_i\right],
\quad \forall\, g,\ t&lt;g.
\]</span></p>
<p><em>2. Staggered overlap (positivity) for not-yet-treated comparisons:</em></p>
<p><span class="math display">\[
\epsilon \le P(G_i=g \mid \mathbf X_i)
\quad \text{and} \quad
\epsilon \le P(G_i&gt;t \mid \mathbf X_i),
\quad \forall\, g,\ t&lt;g,\ \text{for some } \epsilon&gt;0.
\]</span></p>
<p>Condition 1 means that, conditional on covariates, pre-treatment changes in untreated potential outcomes for cohort <span class="math inline">\(g\)</span> match those of units not yet treated at time <span class="math inline">\(t\)</span>, and condition 2 means that there is positive probability of belonging to cohort <span class="math inline">\(g\)</span> and of being not yet treated at <span class="math inline">\(t\)</span>.</p>
<p>Given these assumptions and no anticipation, the <span class="math inline">\(ATT(g,t)\)</span> can be expressed as</p>
<p><span class="math display">\[\begin{align*}
ATT(g,t)
&amp;= \mathbb{E}[Y_{it} - Y_{i,g-1} \mid G_i = g] \\
&amp;\quad - \mathbb{E}_{\mathbf{X}}\!\left\{\mathbb{E}[Y_{it} - Y_{i,g-1} \mid \mathbf{X}_i, G_i = g&#39;&gt;t]\mid G_i=g\right\}.
\end{align*}\]</span></p>
<p>Again, inference on <span class="math inline">\(ATT(g,t)\)</span> can be conducted using regression adjustment, inverse-probability weighting, or doubly robust estimators. Although TWFE specifications are often used to estimate <span class="math inline">\(ATT(g,t)\)</span>, <span class="citation">Baker et al. (<a href="#ref-baker2025did_guide">2025</a>)</span> recommend avoiding them in staggered DiD settings because they generally do not identify <span class="math inline">\(ATT(g,t)\)</span>. Instead, they recover a complicated, non-convex weighted average of cohort–time effects, with potentially negative weights.</p>
<p><strong>Example: Difference-in-Differences simulation</strong></p>
<p>Let’s simulate a DiD setting where the treatment effect is <span class="math inline">\(1\)</span> and the common trend is <span class="math inline">\(-1.8\)</span>. We assume the default priors in the <em>MCMCpack</em> package. We perform inference on the ATT using</p>
<p><span class="math display">\[\begin{equation}
Y_{i2} - Y_{i1}
= \underbrace{\phi_2 - \phi_1}_{\text{Common change}}
+ \tau_2 D_i + \epsilon_i,
\end{equation}\]</span></p>
<p>The following code implements this example. From the posterior results, we can verify that the 95% credible interval contains the true ATT. We ask in Exercise~8 to repeat exactly the same simulation, and estimate the ATT using the specification with the interaction between treatment and the post-treatment period.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="sec13_5.html#cb6-1" tabindex="-1"></a><span class="fu">rm</span>(<span class="at">list =</span> <span class="fu">ls</span>()); <span class="fu">set.seed</span>(<span class="dv">10101</span>)</span>
<span id="cb6-2"><a href="sec13_5.html#cb6-2" tabindex="-1"></a><span class="fu">library</span>(ggplot2); <span class="fu">library</span>(dplyr); <span class="fu">library</span>(fastDummies)</span>
<span id="cb6-3"><a href="sec13_5.html#cb6-3" tabindex="-1"></a><span class="co"># Parameters</span></span>
<span id="cb6-4"><a href="sec13_5.html#cb6-4" tabindex="-1"></a>N_per_group <span class="ot">&lt;-</span> <span class="dv">200</span>          <span class="co"># units per group</span></span>
<span id="cb6-5"><a href="sec13_5.html#cb6-5" tabindex="-1"></a>T_periods    <span class="ot">&lt;-</span> <span class="dv">2</span>           <span class="co"># keep 2x2 for clarity</span></span>
<span id="cb6-6"><a href="sec13_5.html#cb6-6" tabindex="-1"></a>tau_true     <span class="ot">&lt;-</span> <span class="dv">1</span>           <span class="co"># ATT</span></span>
<span id="cb6-7"><a href="sec13_5.html#cb6-7" tabindex="-1"></a>sigma_eps    <span class="ot">&lt;-</span> <span class="fl">0.5</span>         <span class="co"># noise SD</span></span>
<span id="cb6-8"><a href="sec13_5.html#cb6-8" tabindex="-1"></a><span class="co"># Panel index</span></span>
<span id="cb6-9"><a href="sec13_5.html#cb6-9" tabindex="-1"></a>id  <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">1</span><span class="sc">:</span>(<span class="dv">2</span><span class="sc">*</span>N_per_group), <span class="at">each =</span> T_periods)</span>
<span id="cb6-10"><a href="sec13_5.html#cb6-10" tabindex="-1"></a>t   <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">1</span><span class="sc">:</span>T_periods, <span class="at">times =</span> <span class="dv">2</span><span class="sc">*</span>N_per_group)</span>
<span id="cb6-11"><a href="sec13_5.html#cb6-11" tabindex="-1"></a><span class="co"># Group: treated (D=1) vs control (D=0)</span></span>
<span id="cb6-12"><a href="sec13_5.html#cb6-12" tabindex="-1"></a>D   <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="fu">c</span>(<span class="fu">rep</span>(<span class="dv">0</span>, N_per_group), <span class="fu">rep</span>(<span class="dv">1</span>, N_per_group)), <span class="at">each =</span> T_periods)</span>
<span id="cb6-13"><a href="sec13_5.html#cb6-13" tabindex="-1"></a><span class="co"># Post indicator (t=2 is post)</span></span>
<span id="cb6-14"><a href="sec13_5.html#cb6-14" tabindex="-1"></a>post <span class="ot">&lt;-</span> <span class="fu">as.integer</span>(t <span class="sc">==</span> <span class="dv">2</span>)</span>
<span id="cb6-15"><a href="sec13_5.html#cb6-15" tabindex="-1"></a><span class="co"># Unit fixed effects (random heterogeneity)</span></span>
<span id="cb6-16"><a href="sec13_5.html#cb6-16" tabindex="-1"></a>alpha_i <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">2</span><span class="sc">*</span>N_per_group, <span class="dv">0</span>, <span class="fl">0.8</span>)</span>
<span id="cb6-17"><a href="sec13_5.html#cb6-17" tabindex="-1"></a>alpha   <span class="ot">&lt;-</span> alpha_i[id]</span>
<span id="cb6-18"><a href="sec13_5.html#cb6-18" tabindex="-1"></a><span class="co"># Time effects (common shocks)</span></span>
<span id="cb6-19"><a href="sec13_5.html#cb6-19" tabindex="-1"></a>phi_t <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="sc">-</span><span class="fl">1.8</span>)  <span class="co"># common decline from t=1 to t=2</span></span>
<span id="cb6-20"><a href="sec13_5.html#cb6-20" tabindex="-1"></a>phi   <span class="ot">&lt;-</span> phi_t[t]</span>
<span id="cb6-21"><a href="sec13_5.html#cb6-21" tabindex="-1"></a>treat_effect <span class="ot">&lt;-</span> tau_true <span class="sc">*</span> (D <span class="sc">*</span> post)</span>
<span id="cb6-22"><a href="sec13_5.html#cb6-22" tabindex="-1"></a><span class="co"># Outcome:</span></span>
<span id="cb6-23"><a href="sec13_5.html#cb6-23" tabindex="-1"></a>eps <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="fu">length</span>(id), <span class="dv">0</span>, sigma_eps)</span>
<span id="cb6-24"><a href="sec13_5.html#cb6-24" tabindex="-1"></a>Y   <span class="ot">&lt;-</span> alpha <span class="sc">+</span> phi <span class="sc">+</span> treat_effect <span class="sc">+</span> eps</span>
<span id="cb6-25"><a href="sec13_5.html#cb6-25" tabindex="-1"></a>did <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(id, t, D, post, Y)</span>
<span id="cb6-26"><a href="sec13_5.html#cb6-26" tabindex="-1"></a><span class="co"># Bayesian inference: Model in differences</span></span>
<span id="cb6-27"><a href="sec13_5.html#cb6-27" tabindex="-1"></a>dY <span class="ot">&lt;-</span> did<span class="sc">$</span>Y[did<span class="sc">$</span>t<span class="sc">==</span><span class="dv">2</span>] <span class="sc">-</span> did<span class="sc">$</span>Y[did<span class="sc">$</span>t<span class="sc">==</span><span class="dv">1</span>]</span>
<span id="cb6-28"><a href="sec13_5.html#cb6-28" tabindex="-1"></a>D  <span class="ot">&lt;-</span> did<span class="sc">$</span>D[did<span class="sc">$</span>t<span class="sc">==</span><span class="dv">1</span>]</span>
<span id="cb6-29"><a href="sec13_5.html#cb6-29" tabindex="-1"></a>post_fit <span class="ot">&lt;-</span> MCMCpack<span class="sc">::</span><span class="fu">MCMCregress</span>(dY <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> D, <span class="at">burnin =</span> <span class="dv">100</span>, <span class="at">mcmc =</span> <span class="dv">1000</span>)</span>
<span id="cb6-30"><a href="sec13_5.html#cb6-30" tabindex="-1"></a>tau_draws <span class="ot">&lt;-</span> post_fit[, <span class="st">&quot;D&quot;</span>]</span>
<span id="cb6-31"><a href="sec13_5.html#cb6-31" tabindex="-1"></a><span class="fu">quantile</span>(tau_draws, <span class="fu">c</span>(.<span class="dv">025</span>,.<span class="dv">5</span>,.<span class="dv">975</span>))</span>
<span id="cb6-32"><a href="sec13_5.html#cb6-32" tabindex="-1"></a><span class="fu">quantile</span>(post_fit[,<span class="dv">1</span>], <span class="fu">c</span>(.<span class="dv">025</span>,.<span class="dv">5</span>,.<span class="dv">975</span>))</span></code></pre></div>
</div>
</div>
<h3>References<a href="references.html#references" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-abadie2005semiparametric" class="csl-entry">
Abadie, Alberto. 2005. <span>“Semiparametric Difference-in-Differences Estimators.”</span> <em>Review of Economic Studies</em> 72 (1): 1–19. <a href="https://doi.org/10.1111/0034-6527.00321">https://doi.org/10.1111/0034-6527.00321</a>.
</div>
<div id="ref-baker2025did_guide" class="csl-entry">
Baker, Andrew, Brantly Callaway, Scott Cunningham, Andrew Goodman-Bacon, and Pedro H. C. Sant’Anna. 2025. <span>“Difference-in-Differences Designs: <span>A</span> Practitioner’s Guide.”</span> <em>arXiv Preprint arXiv:2503.13323</em>, June.
</div>
<div id="ref-breunig2025double" class="csl-entry">
Breunig, Christoph, Ruixuan Liu, and Zhengfei Yu. 2025. <span>“Double Robust Bayesian Inference on Average Treatment Effects.”</span> <em>Econometrica</em> 93 (2): 539–68. <a href="https://doi.org/10.3982/ECTA21442">https://doi.org/10.3982/ECTA21442</a>.
</div>
<div id="ref-chernozhukov2024applied" class="csl-entry">
Chernozhukov, Victor, Christian Hansen, Nathan Kallus, Martin Spindler, and Vasilis Syrgkanis. 2024. <span>“Applied Causal Inference Powered by ML and AI.”</span> arXiv preprint 2403.02467. arXiv.
</div>
<div id="ref-LuoGrahamMcCoy2023" class="csl-entry">
Luo, Yu, Daniel J. Graham, and Emma J. McCoy. 2023. <span>“Semiparametric Bayesian Doubly Robust Causal Estimation.”</span> <em>Journal of Statistical Planning and Inference</em> 225: 171–87. <a href="https://doi.org/10.1016/j.jspi.2022.12.005">https://doi.org/10.1016/j.jspi.2022.12.005</a>.
</div>
<div id="ref-normington2022bayesian" class="csl-entry">
Normington, James P, Eric F Lock, Thomas A Murray, and Caroline S Carlin. 2022. <span>“Bayesian Variable Selection in Hierarchical Difference-in-Differences Models.”</span> <em>Statistical Methods in Medical Research</em> 31 (1): 169–83.
</div>
<div id="ref-rosenbaum1983central" class="csl-entry">
Rosenbaum, Paul R., and Donald B. Rubin. 1983. <span>“The Central Role of the Propensity Score in Observational Studies for Causal Effects.”</span> <em>Biometrika</em> 70 (1): 41–55. <a href="https://doi.org/10.1093/biomet/70.1.41">https://doi.org/10.1093/biomet/70.1.41</a>.
</div>
<div id="ref-roth2023whats" class="csl-entry">
Roth, Jonathan, Pedro H. C. Sant’Anna, Alyssa Bilinski, and John Poe. 2023. <span>“What’s Trending in Difference‐in‐differences? A Synthesis of the Recent Econometrics Literature.”</span> <em>Journal of Econometrics</em> 235 (2): 2218–44.
</div>
<div id="ref-SaarelaBelzileStephens2016" class="csl-entry">
Saarela, Olli, Léo R. Belzile, and David A. Stephens. 2016. <span>“A Bayesian View of Doubly Robust Causal Inference.”</span> <em>Biometrika</em> 103 (3): 667–81. <a href="https://doi.org/10.1093/biomet/asw025">https://doi.org/10.1093/biomet/asw025</a>.
</div>
<div id="ref-YiuGoudieTom2020" class="csl-entry">
Yiu, Andrew, Robert J. B. Goudie, and Brian D. M. Tom. 2020. <span>“Inference Under Unequal Probability Sampling with the Bayesian Exponentially Tilted Empirical Likelihood.”</span> <em>Biometrika</em> 107 (4): 857–73. <a href="https://doi.org/10.1093/biomet/asaa028">https://doi.org/10.1093/biomet/asaa028</a>.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="sec13_4.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="sec13_6.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": true,
    "facebook": true,
    "twitter": true,
    "linkedin": false,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": false,
    "all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
  },
  "fontsettings": {
    "theme": "white",
    "family": "sans",
    "size": 2
  },
  "edit": {
    "link": "https://github.com/aramir21/IntroductionBayesianEconometricsBook/10-Diagnostics.Rmd",
    "text": "Edit"
  },
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": null,
    "text": null
  },
  "download": null,
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "subsection"
  }
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
