<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>11.1 Mixture models | Introduction to Bayesian Data Modeling</title>
  <meta name="description" content="The subject of this textbook is Bayesian data modeling, with the primary aim of providing an introduction to its theoretical foundations and facilitating the application of Bayesian inference using a GUI." />
  <meta name="generator" content="bookdown 0.40 and GitBook 2.6.7" />

  <meta property="og:title" content="11.1 Mixture models | Introduction to Bayesian Data Modeling" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="The subject of this textbook is Bayesian data modeling, with the primary aim of providing an introduction to its theoretical foundations and facilitating the application of Bayesian inference using a GUI." />
  <meta name="github-repo" content="https://github.com/aramir21/IntroductionBayesianEconometricsBook" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="11.1 Mixture models | Introduction to Bayesian Data Modeling" />
  
  <meta name="twitter:description" content="The subject of this textbook is Bayesian data modeling, with the primary aim of providing an introduction to its theoretical foundations and facilitating the application of Bayesian inference using a GUI." />
  

<meta name="author" content="Andrés Ramírez-Hassan" />


<meta name="date" content="2025-03-20" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="Chap11.html"/>
<link rel="next" href="Chap12.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Introduction to Bayesian Econometrics: A GUIded tour using R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction</a>
<ul>
<li class="chapter" data-level="" data-path="to-instructors-and-students.html"><a href="to-instructors-and-students.html"><i class="fa fa-check"></i>To instructors and students</a></li>
<li class="chapter" data-level="" data-path="acknowledgments.html"><a href="acknowledgments.html"><i class="fa fa-check"></i>Acknowledgments</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="Chap1.html"><a href="Chap1.html"><i class="fa fa-check"></i><b>1</b> Basic formal concepts</a>
<ul>
<li class="chapter" data-level="1.1" data-path="sec11.html"><a href="sec11.html"><i class="fa fa-check"></i><b>1.1</b> The Bayes’ rule</a></li>
<li class="chapter" data-level="1.2" data-path="sec12.html"><a href="sec12.html"><i class="fa fa-check"></i><b>1.2</b> Bayesian framework: A brief summary of theory</a></li>
<li class="chapter" data-level="1.3" data-path="sec14.html"><a href="sec14.html"><i class="fa fa-check"></i><b>1.3</b> Bayesian reports: Decision theory under uncertainty</a></li>
<li class="chapter" data-level="1.4" data-path="summary.html"><a href="summary.html"><i class="fa fa-check"></i><b>1.4</b> Summary</a></li>
<li class="chapter" data-level="1.5" data-path="exercises.html"><a href="exercises.html"><i class="fa fa-check"></i><b>1.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="Chap2.html"><a href="Chap2.html"><i class="fa fa-check"></i><b>2</b> Conceptual differences between the Bayesian and Frequentist approaches</a>
<ul>
<li class="chapter" data-level="2.1" data-path="sec21.html"><a href="sec21.html"><i class="fa fa-check"></i><b>2.1</b> The concept of probability</a></li>
<li class="chapter" data-level="2.2" data-path="sec22.html"><a href="sec22.html"><i class="fa fa-check"></i><b>2.2</b> Subjectivity is not the key</a></li>
<li class="chapter" data-level="2.3" data-path="sec23.html"><a href="sec23.html"><i class="fa fa-check"></i><b>2.3</b> Estimation, hypothesis testing and prediction</a></li>
<li class="chapter" data-level="2.4" data-path="sec24.html"><a href="sec24.html"><i class="fa fa-check"></i><b>2.4</b> The likelihood principle</a></li>
<li class="chapter" data-level="2.5" data-path="sec25.html"><a href="sec25.html"><i class="fa fa-check"></i><b>2.5</b> Why is not the Bayesian approach that popular?</a></li>
<li class="chapter" data-level="2.6" data-path="sec26.html"><a href="sec26.html"><i class="fa fa-check"></i><b>2.6</b> A simple working example</a></li>
<li class="chapter" data-level="2.7" data-path="sec27.html"><a href="sec27.html"><i class="fa fa-check"></i><b>2.7</b> Summary</a></li>
<li class="chapter" data-level="2.8" data-path="sec28.html"><a href="sec28.html"><i class="fa fa-check"></i><b>2.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="Chap3.html"><a href="Chap3.html"><i class="fa fa-check"></i><b>3</b> Cornerstone models: Conjugate families</a>
<ul>
<li class="chapter" data-level="3.1" data-path="sec41.html"><a href="sec41.html"><i class="fa fa-check"></i><b>3.1</b> Motivation of conjugate families</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="sec41.html"><a href="sec41.html#examples-of-exponential-family-distributions"><i class="fa fa-check"></i><b>3.1.1</b> Examples of exponential family distributions</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="sec42.html"><a href="sec42.html"><i class="fa fa-check"></i><b>3.2</b> Conjugate prior to exponential family</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="sec42.html"><a href="sec42.html#sec421"><i class="fa fa-check"></i><b>3.2.1</b> Examples: Theorem 4.2.1</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="sec43.html"><a href="sec43.html"><i class="fa fa-check"></i><b>3.3</b> Linear regression: The conjugate normal-normal/inverse gamma model</a></li>
<li class="chapter" data-level="3.4" data-path="sec44.html"><a href="sec44.html"><i class="fa fa-check"></i><b>3.4</b> Multivariate linear regression: The conjugate normal-normal/inverse Wishart model</a></li>
<li class="chapter" data-level="3.5" data-path="sec45.html"><a href="sec45.html"><i class="fa fa-check"></i><b>3.5</b> Summary</a></li>
<li class="chapter" data-level="3.6" data-path="sec46.html"><a href="sec46.html"><i class="fa fa-check"></i><b>3.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="Chap4.html"><a href="Chap4.html"><i class="fa fa-check"></i><b>4</b> Simulation methods</a>
<ul>
<li class="chapter" data-level="4.1" data-path="sec51.html"><a href="sec51.html"><i class="fa fa-check"></i><b>4.1</b> Markov Chain Monte Carlo methods</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="sec51.html"><a href="sec51.html#sec511"><i class="fa fa-check"></i><b>4.1.1</b> Gibbs sampler</a></li>
<li class="chapter" data-level="4.1.2" data-path="sec51.html"><a href="sec51.html#sec512"><i class="fa fa-check"></i><b>4.1.2</b> Metropolis-Hastings</a></li>
<li class="chapter" data-level="4.1.3" data-path="sec51.html"><a href="sec51.html#sec513"><i class="fa fa-check"></i><b>4.1.3</b> Hamiltonian Monte Carlo</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="sec52.html"><a href="sec52.html"><i class="fa fa-check"></i><b>4.2</b> Importance sampling</a></li>
<li class="chapter" data-level="4.3" data-path="sec53.html"><a href="sec53.html"><i class="fa fa-check"></i><b>4.3</b> Particle filtering</a></li>
<li class="chapter" data-level="4.4" data-path="sec54.html"><a href="sec54.html"><i class="fa fa-check"></i><b>4.4</b> Convergence diagnostics</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="sec54.html"><a href="sec54.html#numerical-standard-error"><i class="fa fa-check"></i><b>4.4.1</b> Numerical standard error</a></li>
<li class="chapter" data-level="4.4.2" data-path="sec54.html"><a href="sec54.html#effective-number-of-simulation-draws"><i class="fa fa-check"></i><b>4.4.2</b> Effective number of simulation draws</a></li>
<li class="chapter" data-level="4.4.3" data-path="sec54.html"><a href="sec54.html#tests-of-convergence"><i class="fa fa-check"></i><b>4.4.3</b> Tests of convergence</a></li>
<li class="chapter" data-level="4.4.4" data-path="sec54.html"><a href="sec54.html#checking-for-errors-in-the-posterior-simulator"><i class="fa fa-check"></i><b>4.4.4</b> Checking for errors in the posterior simulator</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="sec55.html"><a href="sec55.html"><i class="fa fa-check"></i><b>4.5</b> Summary</a></li>
<li class="chapter" data-level="4.6" data-path="sec56.html"><a href="sec56.html"><i class="fa fa-check"></i><b>4.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="Chap5.html"><a href="Chap5.html"><i class="fa fa-check"></i><b>5</b> Graphical user interface</a>
<ul>
<li class="chapter" data-level="5.1" data-path="secGUI1.html"><a href="secGUI1.html"><i class="fa fa-check"></i><b>5.1</b> Introduction</a></li>
<li class="chapter" data-level="5.2" data-path="secGUI2.html"><a href="secGUI2.html"><i class="fa fa-check"></i><b>5.2</b> Univariate models</a></li>
<li class="chapter" data-level="5.3" data-path="secGUI3.html"><a href="secGUI3.html"><i class="fa fa-check"></i><b>5.3</b> Multivariate models</a></li>
<li class="chapter" data-level="5.4" data-path="secGUI4.html"><a href="secGUI4.html"><i class="fa fa-check"></i><b>5.4</b> Time series models</a></li>
<li class="chapter" data-level="5.5" data-path="secGUI5.html"><a href="secGUI5.html"><i class="fa fa-check"></i><b>5.5</b> Longitudinal/panel models</a></li>
<li class="chapter" data-level="5.6" data-path="secGUI6.html"><a href="secGUI6.html"><i class="fa fa-check"></i><b>5.6</b> Bayesian model average</a></li>
<li class="chapter" data-level="5.7" data-path="secGUI7.html"><a href="secGUI7.html"><i class="fa fa-check"></i><b>5.7</b> Help</a></li>
<li class="chapter" data-level="5.8" data-path="secGUI8.html"><a href="secGUI8.html"><i class="fa fa-check"></i><b>5.8</b> Warning</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="Chap6.html"><a href="Chap6.html"><i class="fa fa-check"></i><b>6</b> Univariate regression</a>
<ul>
<li class="chapter" data-level="6.1" data-path="sec61.html"><a href="sec61.html"><i class="fa fa-check"></i><b>6.1</b> The Gaussian linear model</a></li>
<li class="chapter" data-level="6.2" data-path="sec62.html"><a href="sec62.html"><i class="fa fa-check"></i><b>6.2</b> The logit model</a></li>
<li class="chapter" data-level="6.3" data-path="sec63.html"><a href="sec63.html"><i class="fa fa-check"></i><b>6.3</b> The probit model</a></li>
<li class="chapter" data-level="6.4" data-path="sec64.html"><a href="sec64.html"><i class="fa fa-check"></i><b>6.4</b> The multinomial probit model</a></li>
<li class="chapter" data-level="6.5" data-path="sec65.html"><a href="sec65.html"><i class="fa fa-check"></i><b>6.5</b> The multinomial logit model</a></li>
<li class="chapter" data-level="6.6" data-path="sec66.html"><a href="sec66.html"><i class="fa fa-check"></i><b>6.6</b> Ordered probit model</a></li>
<li class="chapter" data-level="6.7" data-path="negative-binomial-model.html"><a href="negative-binomial-model.html"><i class="fa fa-check"></i><b>6.7</b> Negative binomial model</a></li>
<li class="chapter" data-level="6.8" data-path="sec68.html"><a href="sec68.html"><i class="fa fa-check"></i><b>6.8</b> Tobit model</a></li>
<li class="chapter" data-level="6.9" data-path="sec69.html"><a href="sec69.html"><i class="fa fa-check"></i><b>6.9</b> Quantile regression</a></li>
<li class="chapter" data-level="6.10" data-path="sec610.html"><a href="sec610.html"><i class="fa fa-check"></i><b>6.10</b> Bayesian bootstrap regression</a></li>
<li class="chapter" data-level="6.11" data-path="sec611.html"><a href="sec611.html"><i class="fa fa-check"></i><b>6.11</b> Summary</a></li>
<li class="chapter" data-level="6.12" data-path="sec612.html"><a href="sec612.html"><i class="fa fa-check"></i><b>6.12</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="Chap7.html"><a href="Chap7.html"><i class="fa fa-check"></i><b>7</b> Multivariate regression</a>
<ul>
<li class="chapter" data-level="7.1" data-path="sec71.html"><a href="sec71.html"><i class="fa fa-check"></i><b>7.1</b> Multivariate regression</a></li>
<li class="chapter" data-level="7.2" data-path="sec72.html"><a href="sec72.html"><i class="fa fa-check"></i><b>7.2</b> Seemingly Unrelated Regression</a></li>
<li class="chapter" data-level="7.3" data-path="sec73.html"><a href="sec73.html"><i class="fa fa-check"></i><b>7.3</b> Instrumental variable</a></li>
<li class="chapter" data-level="7.4" data-path="sec74.html"><a href="sec74.html"><i class="fa fa-check"></i><b>7.4</b> Multivariate probit model</a></li>
<li class="chapter" data-level="7.5" data-path="sec75.html"><a href="sec75.html"><i class="fa fa-check"></i><b>7.5</b> Summary</a></li>
<li class="chapter" data-level="7.6" data-path="sec76.html"><a href="sec76.html"><i class="fa fa-check"></i><b>7.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="Chap8.html"><a href="Chap8.html"><i class="fa fa-check"></i><b>8</b> Time series</a>
<ul>
<li class="chapter" data-level="8.1" data-path="sec81.html"><a href="sec81.html"><i class="fa fa-check"></i><b>8.1</b> State-space representation</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="sec81.html"><a href="sec81.html#gaussian-linear-state-space-models"><i class="fa fa-check"></i><b>8.1.1</b> Gaussian linear state-space models</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="sec82.html"><a href="sec82.html"><i class="fa fa-check"></i><b>8.2</b> ARMA processes</a></li>
<li class="chapter" data-level="8.3" data-path="sec83.html"><a href="sec83.html"><i class="fa fa-check"></i><b>8.3</b> Stochastic volatility models</a></li>
<li class="chapter" data-level="8.4" data-path="sec84.html"><a href="sec84.html"><i class="fa fa-check"></i><b>8.4</b> Vector Autoregressive models</a></li>
<li class="chapter" data-level="8.5" data-path="sec85.html"><a href="sec85.html"><i class="fa fa-check"></i><b>8.5</b> Summary</a></li>
<li class="chapter" data-level="8.6" data-path="sec86.html"><a href="sec86.html"><i class="fa fa-check"></i><b>8.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="Chap9.html"><a href="Chap9.html"><i class="fa fa-check"></i><b>9</b> Longitudinal regression</a>
<ul>
<li class="chapter" data-level="9.1" data-path="sec91.html"><a href="sec91.html"><i class="fa fa-check"></i><b>9.1</b> Normal model</a></li>
<li class="chapter" data-level="9.2" data-path="sec92.html"><a href="sec92.html"><i class="fa fa-check"></i><b>9.2</b> Logit model</a></li>
<li class="chapter" data-level="9.3" data-path="sec93.html"><a href="sec93.html"><i class="fa fa-check"></i><b>9.3</b> Poisson model</a></li>
<li class="chapter" data-level="9.4" data-path="sec94.html"><a href="sec94.html"><i class="fa fa-check"></i><b>9.4</b> Summary</a></li>
<li class="chapter" data-level="9.5" data-path="sec95.html"><a href="sec95.html"><i class="fa fa-check"></i><b>9.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="Chap10.html"><a href="Chap10.html"><i class="fa fa-check"></i><b>10</b> Bayesian model averaging in variable selection</a>
<ul>
<li class="chapter" data-level="10.1" data-path="sec10_1.html"><a href="sec10_1.html"><i class="fa fa-check"></i><b>10.1</b> Foundation</a></li>
<li class="chapter" data-level="10.2" data-path="sec102.html"><a href="sec102.html"><i class="fa fa-check"></i><b>10.2</b> The Gaussian linear model</a></li>
<li class="chapter" data-level="10.3" data-path="sec103.html"><a href="sec103.html"><i class="fa fa-check"></i><b>10.3</b> Generalized linear models</a></li>
<li class="chapter" data-level="10.4" data-path="sec10_4.html"><a href="sec10_4.html"><i class="fa fa-check"></i><b>10.4</b> Calculating the marginal likelihood</a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="sec10_4.html"><a href="sec10_4.html#sec10_4_1"><i class="fa fa-check"></i><b>10.4.1</b> Savage-Dickey density ratio</a></li>
<li class="chapter" data-level="10.4.2" data-path="sec10_4.html"><a href="sec10_4.html#sec10_4_2"><i class="fa fa-check"></i><b>10.4.2</b> Chib’s methods</a></li>
<li class="chapter" data-level="10.4.3" data-path="sec10_4.html"><a href="sec10_4.html#sec10_4_3"><i class="fa fa-check"></i><b>10.4.3</b> Gelfand-Dey method</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="sec10_5.html"><a href="sec10_5.html"><i class="fa fa-check"></i><b>10.5</b> Summary</a></li>
<li class="chapter" data-level="10.6" data-path="sec10_6.html"><a href="sec10_6.html"><i class="fa fa-check"></i><b>10.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="Chap11.html"><a href="Chap11.html"><i class="fa fa-check"></i><b>11</b> Semi-parametric and non-parametric models</a>
<ul>
<li class="chapter" data-level="11.1" data-path="sec11_1.html"><a href="sec11_1.html"><i class="fa fa-check"></i><b>11.1</b> Mixture models</a>
<ul>
<li class="chapter" data-level="11.1.1" data-path="sec11_1.html"><a href="sec11_1.html#sec11_11"><i class="fa fa-check"></i><b>11.1.1</b> Finite Gaussian mixtures</a></li>
<li class="chapter" data-level="11.1.2" data-path="sec11_1.html"><a href="sec11_1.html#sec11_12"><i class="fa fa-check"></i><b>11.1.2</b> Direchlet processes</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="Chap12.html"><a href="Chap12.html"><i class="fa fa-check"></i><b>12</b> Machine learning</a>
<ul>
<li class="chapter" data-level="12.1" data-path="sec12_1.html"><a href="sec12_1.html"><i class="fa fa-check"></i><b>12.1</b> Cross validation and Bayes factors</a></li>
<li class="chapter" data-level="12.2" data-path="sec12_2.html"><a href="sec12_2.html"><i class="fa fa-check"></i><b>12.2</b> Regularization</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="sec12_2.html"><a href="sec12_2.html#sec12_21"><i class="fa fa-check"></i><b>12.2.1</b> Bayesian LASSO</a></li>
<li class="chapter" data-level="12.2.2" data-path="sec12_2.html"><a href="sec12_2.html#sec12_22"><i class="fa fa-check"></i><b>12.2.2</b> Stochastic search variable selection</a></li>
<li class="chapter" data-level="12.2.3" data-path="sec12_2.html"><a href="sec12_2.html#sec12_23"><i class="fa fa-check"></i><b>12.2.3</b> Non-local priors</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="sec12_3.html"><a href="sec12_3.html"><i class="fa fa-check"></i><b>12.3</b> Bayesian additive regression trees</a></li>
<li class="chapter" data-level="12.4" data-path="sec12_4.html"><a href="sec12_4.html"><i class="fa fa-check"></i><b>12.4</b> Gaussian processes</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="Chap13.html"><a href="Chap13.html"><i class="fa fa-check"></i><b>13</b> Causal inference</a>
<ul>
<li class="chapter" data-level="13.1" data-path="sec13_1.html"><a href="sec13_1.html"><i class="fa fa-check"></i><b>13.1</b> Instrumental variables</a>
<ul>
<li class="chapter" data-level="13.1.1" data-path="sec13_1.html"><a href="sec13_1.html#sec13_11"><i class="fa fa-check"></i><b>13.1.1</b> Semi-parametric IV model</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="sec13_2.html"><a href="sec13_2.html"><i class="fa fa-check"></i><b>13.2</b> Regression discontinuity design</a></li>
<li class="chapter" data-level="13.3" data-path="sec13_3.html"><a href="sec13_3.html"><i class="fa fa-check"></i><b>13.3</b> Regression kink design</a></li>
<li class="chapter" data-level="13.4" data-path="sec13_4.html"><a href="sec13_4.html"><i class="fa fa-check"></i><b>13.4</b> Synthetic control</a></li>
<li class="chapter" data-level="13.5" data-path="sec13_5.html"><a href="sec13_5.html"><i class="fa fa-check"></i><b>13.5</b> Difference in difference estimation</a></li>
<li class="chapter" data-level="13.6" data-path="sec13_6.html"><a href="sec13_6.html"><i class="fa fa-check"></i><b>13.6</b> Event Analysis</a></li>
<li class="chapter" data-level="13.7" data-path="sec13_7.html"><a href="sec13_7.html"><i class="fa fa-check"></i><b>13.7</b> Bayesian exponential tilted empirical likelihood</a></li>
<li class="chapter" data-level="13.8" data-path="sec13_8.html"><a href="sec13_8.html"><i class="fa fa-check"></i><b>13.8</b> Double-Debiased machine learning causal effects</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="Chap14.html"><a href="Chap14.html"><i class="fa fa-check"></i><b>14</b> Approximation methods</a>
<ul>
<li class="chapter" data-level="14.1" data-path="sec14_1.html"><a href="sec14_1.html"><i class="fa fa-check"></i><b>14.1</b> Approximate Bayesian computation</a></li>
<li class="chapter" data-level="14.2" data-path="sec14_2.html"><a href="sec14_2.html"><i class="fa fa-check"></i><b>14.2</b> Bayesian synthetic likelihood</a></li>
<li class="chapter" data-level="14.3" data-path="sec14_3.html"><a href="sec14_3.html"><i class="fa fa-check"></i><b>14.3</b> Expectation propagation</a></li>
<li class="chapter" data-level="14.4" data-path="sec14_4.html"><a href="sec14_4.html"><i class="fa fa-check"></i><b>14.4</b> Integrated nested Laplace approximations</a></li>
<li class="chapter" data-level="14.5" data-path="sec14_5.html"><a href="sec14_5.html"><i class="fa fa-check"></i><b>14.5</b> Variational Bayes</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i>Appendix</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to Bayesian Data Modeling</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="sec11_1" class="section level2 hasAnchor" number="11.1">
<h2><span class="header-section-number">11.1</span> Mixture models<a href="sec11_1.html#sec11_1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Mixture models naturally arise in situations where a sample consists of draws from different <em>subpopulations</em> (<em>clusters</em>) that cannot be easily distinguished based on observable characteristics. However, performing inference on specific identified subpopulations can be misleading if the assumed distribution for each cluster is misspecified.</p>
<p>Even when distinct subpopulations do not exist, finite and infinite mixture models provide a useful framework for semi-parametric inference. They effectively approximate distributions with skewness, excess kurtosis, and multimodality, making them useful for modeling stochastic errors.</p>
<p>In addition, mixture models help capture unobserved heterogeneity. That is, as data modelers, we may observe individuals with identical sets of observable variables but entirely different response variables. These differences cannot be explained solely by sampling variability; rather, they suggest the presence of an unobserved underlying process, independent of the observable features, that accounts for this pattern.</p>
<div id="sec11_11" class="section level3 hasAnchor" number="11.1.1">
<h3><span class="header-section-number">11.1.1</span> Finite Gaussian mixtures<a href="sec11_1.html#sec11_11" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A finite Gaussian mixture model for regression with <span class="math inline">\(H\)</span> known components assumes that a sample
<span class="math inline">\(\boldsymbol{y}=\left[y_1 \ y_2 \ \dots \ y_N\right]^{\top}\)</span> consists of observations <span class="math inline">\(y_i\)</span>,
for <span class="math inline">\(i=1,2,\dots,N\)</span>, where each <span class="math inline">\(y_i\)</span> is generated from one of the <span class="math inline">\(H\)</span> components,
<span class="math inline">\(h=1,2,\dots,H\)</span>, conditional on the regressors <span class="math inline">\(\boldsymbol{x}_i\)</span>. Specifically, we assume<br />
<span class="math display">\[
y_i \mid \boldsymbol{x}_i \sim N(\boldsymbol{x}_i^{\top}\boldsymbol{\beta}_h, \sigma_h^2).
\]</span></p>
<p>Thus, the sampling distribution of <span class="math inline">\(y_i\)</span> is given by<br />
<span class="math display">\[
p(y_i \mid \{\lambda_h, \boldsymbol{\beta}_h, \sigma_h^2\}_{h=1}^H, \boldsymbol{x}_i) =
\sum_{h=1}^H \lambda_h \phi(y_i \mid \boldsymbol{x}_i^{\top}\boldsymbol{\beta}_h, \sigma_h^2),
\]</span></p>
<p>where <span class="math inline">\(\phi(y_i \mid \boldsymbol{x}_i^{\top}\boldsymbol{\beta}_h, \sigma_h^2)\)</span> is the Gaussian density with mean
<span class="math inline">\(\boldsymbol{x}_i^{\top}\boldsymbol{\beta}_h\)</span> and variance <span class="math inline">\(\sigma_h^2\)</span>, <span class="math inline">\(0 &lt; \lambda_h &lt; 1\)</span> represents
the proportion of the population belonging to subpopulation <span class="math inline">\(h\)</span>, and the weights satisfy
<span class="math inline">\(\sum_{h=1}^H \lambda_h = 1\)</span>.</p>
<p>Then, we allow cross-sectional units to differ according to unobserved clusters (subpopulations) that exhibit homogeneous behavior within each cluster.</p>
<p>To model a finite Gaussian mixture, we introduce an individual cluster indicator or latent class <span class="math inline">\(\psi_{ih}\)</span> such that<br />
<span class="math display">\[
\psi_{ih}=
\begin{cases}
    1, &amp; \text{if the } i\text{-th unit is drawn from the } h\text{-th cluster}, \\
    0, &amp; \text{otherwise}.
\end{cases}
\]</span></p>
<p>Thus, <span class="math inline">\(P(\psi_{ih}=1) = \lambda_h\)</span> for all clusters <span class="math inline">\(h=1,2,\dots,H\)</span> and units <span class="math inline">\(i=1,2,\dots,N\)</span>. Note that a high probability of individuals belonging to the same cluster suggests that these clusters capture similar sources of unobserved heterogeneity.</p>
<p>This setting implies that<br />
<span class="math display">\[
\boldsymbol{\psi}_i = [\psi_{i1} \  \psi_{i2} \ \dots \ \psi_{iH}]^{\top} \sim \text{Categorical}(\boldsymbol{\lambda}),
\]</span></p>
<p>where <span class="math inline">\(\boldsymbol{\lambda} = [\lambda_1 \  \lambda_2 \  \dots \ \lambda_H]^{\top}\)</span> represents the event probabilities.</p>
<p>We know from Subsection <a href="sec42.html#sec42">3.2</a> that the Dirichlet prior distribution is conjugate to the multinomial distribution, where the categorical distribution is a special case in which the number of trials is one. Thus, we assume that<br />
<span class="math display">\[
\pi(\boldsymbol{\lambda}) \sim \text{Dir}(\boldsymbol{\alpha}_0),
\]</span></p>
<p>where <span class="math inline">\(\boldsymbol{\alpha}_0 = [\alpha_{10} \ \alpha_{20} \ \dots \ \alpha_{H0}]^{\top}\)</span>, <span class="math inline">\(\alpha_{h0}=1/H\)</span> is recommended by <span class="citation">(<a href="#ref-gelman2021bayesian">Gelman et al. 2021</a>)</span>.</p>
<p>Observe that we are using a hierarchical structure, as we specify a prior on <span class="math inline">\(\boldsymbol{\lambda}\)</span>, which serves as the hyperparameter for the cluster indicators. In addition, we can assume conjugate families for the location and scale parameters to facilitate computation, that is, <span class="math inline">\(\boldsymbol \beta_h\sim N(\boldsymbol{\beta}_{h0},\boldsymbol{B}_{h0})\)</span> and <span class="math inline">\(\sigma_h^2\sim IG(\alpha_{h0}/2,\delta_{h0}/2)\)</span>.</p>
<p>This setting allows to obtain standard conditional posterior distributions: <span class="math display">\[\boldsymbol{\beta}_{h}\sim N(\boldsymbol{\beta}_{hn},\boldsymbol{B}_{hn}),\]</span> where <span class="math inline">\(\boldsymbol{B}_{hn}=(\boldsymbol{B}_{h0}^{-1}+\sigma_h^{-2}\sum_{\left\{i: \psi_{ih}=1\right\}}\boldsymbol{x}_i\boldsymbol{x}_i^{\top})^{-1}\)</span> and <span class="math inline">\(\boldsymbol{\beta}_{hn}=\boldsymbol{B}_{hn}(\boldsymbol{B}_{h0}^{-1}\boldsymbol{\beta}_{h0}+\sigma_h^{-2}\sum_{\left\{i: \psi_{ih}=1\right\}}\boldsymbol{x}_iy_i)\)</span>.
<span class="math display">\[\sigma_h^2\sim IG(\alpha_{hn}/2,\delta_{hn}/2),\]</span></p>
<p>where <span class="math inline">\(\alpha_{hn}=\alpha_{h0}+N_h\)</span>, <span class="math inline">\(\delta_{hn}=\delta_{h0}+\sum_{\left\{i: \psi_{ih}=1\right\}}(y_i-\boldsymbol{x}_i^{\top}\boldsymbol{\beta}_h)^2\)</span>, and <span class="math inline">\(N_h\)</span> is the number of units in cluster <span class="math inline">\(h\)</span>.</p>
<p><span class="math display">\[\boldsymbol{\lambda}\sim \text{Dir}(\boldsymbol{\alpha}_n),\]</span><br />
where <span class="math inline">\(\boldsymbol{\alpha}_n=[\alpha_{1n} \  \alpha_{2n} \ \dots \ \alpha_{Hn}]^{\top}\)</span>, and <span class="math inline">\(\alpha_{hn}=\alpha_{h0}+N_h\)</span>.</p>
<p><span class="math display">\[\boldsymbol{\psi}_{in}\sim \text{Categorical}(\boldsymbol{\lambda}_n),\]</span>
where <span class="math inline">\(P(\psi_{ih}=1)=\frac{\lambda_{h}\phi(y_i \mid \boldsymbol{x}_i^{\top}\boldsymbol{\beta}_h,\sigma_h^2)}{\sum_{j=1}^H\lambda_{j}\phi(y_i \mid \boldsymbol{x}_i^{\top}\boldsymbol{\beta}_j,\sigma_j^2)}\)</span>.</p>
<p>In general, it is always safer to perform inference in mixture models using informative priors, as non-informative priors may have unintended consequences on posterior inference. One way to facilitate prior elicitation is to work with standardized data, as this removes dependence on measurement units. Another useful approach is to specify the model in log-log form so that the coefficients can be interpreted as elasticities or semi-elasticities. As always in Bayesian inference, it makes sense to perform a sensitivity analysis with respect to the hyperparameters.</p>
<p>Mixture models have the label-switching identification problem, meaning they are nonidentifiable because the distribution remains unchanged if the group labels are permuted <span class="citation">(<a href="#ref-van2011bayesian">Van Hasselt 2011</a>)</span>. For instance, a mixture model with two components can be characterized by <span class="math inline">\(\left\{\lambda_1,\boldsymbol{\beta}_1,\sigma_1^2\right\}\)</span> for the first cluster and <span class="math inline">\(\left\{1-\lambda_1,\boldsymbol{\beta}_2,\sigma_2^2\right\}\)</span> for the second. However, an alternative characterization is <span class="math inline">\(\left\{1-\lambda_1,\boldsymbol{\beta}_2,\sigma_2^2\right\}\)</span> for cluster 1 and <span class="math inline">\(\left\{\lambda_1,\boldsymbol{\beta}_1,\sigma_1^2\right\}\)</span> for cluster 2. This parametrization yields exactly the same likelihood as the first one, meaning any permutation of the cluster labels leaves the likelihood unchanged. Consequently, the posterior draws of each component-specific parameter target the same distribution.</p>
<p>Label switching may pose challenges when performing inference on specific mixture components, such as in the regression analysis presented here. However, it is not an issue when inference on specific components is unnecessary, as in cases where mixtures are used to model stochastic errors in semi-parametric settings. In the former case, post-processing strategies can mitigate the issue, such as <em>random permutation of latent classes</em> (see the simulation exercise below, <span class="citation">(<a href="#ref-gelman2021bayesian">Gelman et al. 2021</a>)</span> and Algorithm 3.5 in <span class="citation">(<a href="#ref-fruhwirth2006finite">Frühwirth-Schnatter 2006</a>)</span>).</p>
<p>A semi-parametric regression imposes a specific structure in part of the model and uses flexible assumptions in another part, for instance
<span class="math display">\[\begin{align*}
    y_i&amp;=\boldsymbol{x}_i^{\top}\boldsymbol{\beta}+\mu_i,\\
    p(\mu_i \mid \left\{\lambda_h,\mu_h,\sigma_h^2\right\}_{h=1}^H)&amp;=\sum_{h=1}^H\lambda_h\phi(\mu_i\mid \mu_h,\sigma_h^2).
\end{align*}\]</span></p>
<p>Thus, the distribution of the stochastic error is a finite Gaussian mixture. Note that the mean of the stochastic error is not equal to zero; consequently, the intercept in the regression should be removed, as these two parameters are not separately identifiable <span class="citation">(<a href="#ref-van2011bayesian">Van Hasselt 2011</a>)</span>. Additionally, this approach allows for multiple modes and asymmetric distributions of the stochastic errors, providing greater flexibility.</p>
<p>We can use a Gibbs sampling algorithm in this semi-parametric specification if we assume conjugate families. The difference from the previous setting is that we have the same slope parameters; thus, <span class="math inline">\(\boldsymbol{\beta} \sim N(\boldsymbol{\beta}_{0},\boldsymbol{B}_{0})\)</span>. Additionally, we must specify the prior distribution for the means of the stochastic errors, given by <span class="math inline">\(\mu_h \sim N(\mu_{h0},\sigma^2_{\mu 0})\)</span>. Then, the posterior distributions are:</p>
<p><span class="math display">\[\boldsymbol{\beta}\sim N(\boldsymbol{\beta}_{n},\boldsymbol{B}_{n}),\]</span> where <span class="math inline">\(\boldsymbol{B}_{n}=(\boldsymbol{B}_{0}^{-1}+\sum_{h=1}^H\sum_{\left\{i: \psi_{ih}=1\right\}}\sigma_h^{-2}\boldsymbol{x}_i\boldsymbol{x}_i^{\top})^{-1}\)</span> and <span class="math inline">\(\boldsymbol{\beta}_{n}=\boldsymbol{B}_{n}(\boldsymbol{B}_{0}^{-1}\boldsymbol{\beta}_{0}+\sum_{h=1}^H\sum_{\left\{i: \psi_{ih}=1\right\}}\sigma_h^{-2}\boldsymbol{x}_i(y_i-\mu_h))\)</span>.
<span class="math display">\[\sigma_h^2\sim IG(\alpha_{hn}/2,\delta_{hn}/2),\]</span></p>
<p>where <span class="math inline">\(\alpha_{hn}=\alpha_{h0}+N_h\)</span>, <span class="math inline">\(\delta_{hn}=\delta_{h0}+\sum_{\left\{i: \psi_{ih}=1\right\}}(y_i-\mu_h-\boldsymbol{x}_i^{\top}\boldsymbol{\beta}_h)^2\)</span>, and <span class="math inline">\(N_h\)</span> is the number of units in cluster <span class="math inline">\(h\)</span>.</p>
<p><span class="math display">\[\mu_h\sim N(\mu_{hn},\sigma_{hn}^2),\]</span></p>
<p>where <span class="math inline">\(\sigma_{hn}^2=\left(\frac{1}{\sigma_{h}^{2}}+\frac{N_h}{\sigma_{h}^2}\right)^{-1}\)</span> and <span class="math inline">\(\mu_{hn}=\sigma_{hn}^2\left(\frac{\mu_{h0}}{\sigma_{\mu0}^2}+\frac{\sum_{\left\{i:\psi_{ih}=1\right\}} (y_i-\boldsymbol{x}_i\boldsymbol{\beta})}{\sigma_h^2}\right)\)</span>.</p>
<p><span class="math display">\[\boldsymbol{\lambda}\sim \text{Dir}(\boldsymbol{\alpha}_n),\]</span><br />
where <span class="math inline">\(\boldsymbol{\alpha}_n=[\alpha_{1n} \  \alpha_{2n} \ \dots \ \alpha_{Hn}]^{\top}\)</span>, and <span class="math inline">\(\alpha_{hn}=\alpha_{h0}+N_h\)</span>.</p>
<p><span class="math display">\[\boldsymbol{\psi}_{in}\sim \text{Categorical}(\boldsymbol{\lambda}_n),\]</span>
where <span class="math inline">\(P(\psi_{ih}=1)=\frac{\lambda_{h}\phi(y_i-\mu_h-\boldsymbol{x}_i^{\top}\boldsymbol{\beta} \mid \mu_h,\sigma_h^2,\boldsymbol{\beta})}{\sum_{j=1}^H\lambda_{j}\phi(y_i-\mu_j-\boldsymbol{x}_i^{\top}\boldsymbol{\beta} \mid \mu_j,\sigma_j^2,\boldsymbol{\beta})}\)</span>.</p>
<p>A potential limitation of finite mixture models is the need to specify the number of components in advance. One approach is to estimate the model for different values of <span class="math inline">\(H\)</span> and then compute the marginal likelihood to select the model best supported by the data. However, this procedure can be tedious. A simpler strategy is to set <span class="math inline">\(H\)</span> large enough (e.g., 10 components), assign <span class="math inline">\(\alpha_{h0} = 1/H\)</span>, and perform an initial run of the algorithm. If we are not interested in the specific composition of clusters, this approach is sufficient. Otherwise, the posterior distribution of <span class="math inline">\(H\)</span> can be obtained by tracking the number of nonempty clusters in each iteration. In a second run, <span class="math inline">\(H\)</span> can then be fixed at the mode of this posterior distribution.</p>
<p>However, the previous approaches ultimately fix the number of components. Consequently, finite mixtures cannot be considered a non-parametric method <span class="citation">(<a href="#ref-rossi2014bayesian">Rossi 2014</a>)</span>, as they lack an automatic mechanism to increase <span class="math inline">\(H\)</span> as the sample size grows. An alternative is to avoid pre-specifying the number of components altogether by using a Dirichlet process mixture (DPM). This is the topic of the next section.</p>
<p><strong>Example: Simulation exercises</strong></p>
<p>First, let’s illustrate the label-switching issue using a simple model without regressors, assuming the same known variance. Consider the following distribution:</p>
<p><span class="math display">\[p(y_i) = 0.75 \phi(y_i \mid \beta_{01},1^2) + 0.25 \phi(y_i \mid \beta_{02},1^2), \quad i = 1,2,\dots,500.\]</span></p>
<p>Initially, we set <span class="math inline">\(\beta_{01} = 0.5\)</span> and <span class="math inline">\(\beta_{02} = 2.5\)</span>. We perform 1,000 MCMC iterations, with a burn-in period of 500 and a thinning factor of 2. The following code demonstrates how to implement the Gibbs sampler using a prior normal distribution with mean 0 and variance 10, with the hyperparameters of the Dirichlet distribution set to <span class="math inline">\(1/2\)</span>.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="sec11_1.html#cb1-1" tabindex="-1"></a><span class="fu">rm</span>(<span class="at">list =</span> <span class="fu">ls</span>()); <span class="fu">set.seed</span>(<span class="dv">010101</span>); <span class="fu">library</span>(ggplot2)</span>
<span id="cb1-2"><a href="sec11_1.html#cb1-2" tabindex="-1"></a><span class="co"># Simulate data from a 2-component mixture model</span></span>
<span id="cb1-3"><a href="sec11_1.html#cb1-3" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">500</span></span>
<span id="cb1-4"><a href="sec11_1.html#cb1-4" tabindex="-1"></a>z <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(n, <span class="dv">1</span>, <span class="fl">0.75</span>)  <span class="co"># Latent class indicator</span></span>
<span id="cb1-5"><a href="sec11_1.html#cb1-5" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(z <span class="sc">==</span> <span class="dv">0</span>, <span class="fu">rnorm</span>(n, <span class="fl">0.5</span>, <span class="dv">1</span>), <span class="fu">rnorm</span>(n, <span class="fl">2.5</span>, <span class="dv">1</span>))</span>
<span id="cb1-6"><a href="sec11_1.html#cb1-6" tabindex="-1"></a>data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(y)</span>
<span id="cb1-7"><a href="sec11_1.html#cb1-7" tabindex="-1"></a><span class="co"># Plot</span></span>
<span id="cb1-8"><a href="sec11_1.html#cb1-8" tabindex="-1"></a><span class="fu">ggplot</span>(data, <span class="fu">aes</span>(<span class="at">x =</span> y)) <span class="sc">+</span></span>
<span id="cb1-9"><a href="sec11_1.html#cb1-9" tabindex="-1"></a><span class="fu">geom_density</span>(<span class="at">fill =</span> <span class="st">&quot;blue&quot;</span>, <span class="at">alpha =</span> <span class="fl">0.3</span>) <span class="sc">+</span> <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Density Plot&quot;</span>, <span class="at">x =</span> <span class="st">&quot;y&quot;</span>, <span class="at">y =</span> <span class="st">&quot;Density&quot;</span>) <span class="sc">+</span> <span class="fu">theme_minimal</span>()</span>
<span id="cb1-10"><a href="sec11_1.html#cb1-10" tabindex="-1"></a><span class="co"># Hyperparameters</span></span>
<span id="cb1-11"><a href="sec11_1.html#cb1-11" tabindex="-1"></a>mu0 <span class="ot">&lt;-</span> <span class="dv">0</span>; sig2mu0 <span class="ot">&lt;-</span> <span class="dv">10</span>; H <span class="ot">&lt;-</span> <span class="dv">2</span>; a0h <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">1</span><span class="sc">/</span>H, H)</span>
<span id="cb1-12"><a href="sec11_1.html#cb1-12" tabindex="-1"></a><span class="co"># MCMC parameters</span></span>
<span id="cb1-13"><a href="sec11_1.html#cb1-13" tabindex="-1"></a>mcmc <span class="ot">&lt;-</span> <span class="dv">1000</span>; burnin <span class="ot">&lt;-</span> <span class="dv">500</span>; tot <span class="ot">&lt;-</span> mcmc <span class="sc">+</span> burnin; thin <span class="ot">&lt;-</span> <span class="dv">2</span></span>
<span id="cb1-14"><a href="sec11_1.html#cb1-14" tabindex="-1"></a><span class="co"># Gibbs sampling functions</span></span>
<span id="cb1-15"><a href="sec11_1.html#cb1-15" tabindex="-1"></a>Postmu <span class="ot">&lt;-</span> <span class="cf">function</span>(yh){</span>
<span id="cb1-16"><a href="sec11_1.html#cb1-16" tabindex="-1"></a>    Nh <span class="ot">&lt;-</span> <span class="fu">length</span>(yh)</span>
<span id="cb1-17"><a href="sec11_1.html#cb1-17" tabindex="-1"></a>    sig2mu <span class="ot">&lt;-</span> (<span class="dv">1</span><span class="sc">/</span>sig2mu0 <span class="sc">+</span> Nh)<span class="sc">^</span>(<span class="sc">-</span><span class="dv">1</span>)</span>
<span id="cb1-18"><a href="sec11_1.html#cb1-18" tabindex="-1"></a>    mun <span class="ot">&lt;-</span> sig2mu<span class="sc">*</span>(mu0<span class="sc">/</span>sig2mu0 <span class="sc">+</span> <span class="fu">sum</span>(yh))</span>
<span id="cb1-19"><a href="sec11_1.html#cb1-19" tabindex="-1"></a>    mu <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">1</span>, mun, sig2mu<span class="sc">^</span><span class="fl">0.5</span>)</span>
<span id="cb1-20"><a href="sec11_1.html#cb1-20" tabindex="-1"></a>    <span class="fu">return</span>(mu)</span>
<span id="cb1-21"><a href="sec11_1.html#cb1-21" tabindex="-1"></a>}</span>
<span id="cb1-22"><a href="sec11_1.html#cb1-22" tabindex="-1"></a>PostPsi <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="cn">NA</span>, tot, n); PostMu <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="cn">NA</span>, tot, H)</span>
<span id="cb1-23"><a href="sec11_1.html#cb1-23" tabindex="-1"></a>PostLambda <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="cn">NA</span>, tot)</span>
<span id="cb1-24"><a href="sec11_1.html#cb1-24" tabindex="-1"></a>Id1 <span class="ot">&lt;-</span> <span class="fu">which</span>(y <span class="sc">&lt;=</span> <span class="dv">1</span>) <span class="co"># 1 is from inspection of the density plot of y </span></span>
<span id="cb1-25"><a href="sec11_1.html#cb1-25" tabindex="-1"></a>Id2 <span class="ot">&lt;-</span> <span class="fu">which</span>(y <span class="sc">&gt;</span> <span class="dv">1</span>)</span>
<span id="cb1-26"><a href="sec11_1.html#cb1-26" tabindex="-1"></a>N1 <span class="ot">&lt;-</span> <span class="fu">length</span>(Id1); N2 <span class="ot">&lt;-</span> <span class="fu">length</span>(Id2)</span>
<span id="cb1-27"><a href="sec11_1.html#cb1-27" tabindex="-1"></a>Lambda <span class="ot">&lt;-</span> <span class="fu">c</span>(N1<span class="sc">/</span>n, N2<span class="sc">/</span>n)</span>
<span id="cb1-28"><a href="sec11_1.html#cb1-28" tabindex="-1"></a>MU <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">mean</span>(y[Id1]), <span class="fu">mean</span>(y[Id2])); Psi <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="cn">NA</span>, n)</span>
<span id="cb1-29"><a href="sec11_1.html#cb1-29" tabindex="-1"></a>pb <span class="ot">&lt;-</span> <span class="fu">winProgressBar</span>(<span class="at">title =</span> <span class="st">&quot;progress bar&quot;</span>, <span class="at">min =</span> <span class="dv">0</span>, <span class="at">max =</span> tot, <span class="at">width =</span> <span class="dv">300</span>)</span>
<span id="cb1-30"><a href="sec11_1.html#cb1-30" tabindex="-1"></a><span class="cf">for</span>(s <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>tot){</span>
<span id="cb1-31"><a href="sec11_1.html#cb1-31" tabindex="-1"></a>    <span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n){</span>
<span id="cb1-32"><a href="sec11_1.html#cb1-32" tabindex="-1"></a>        lambdai <span class="ot">&lt;-</span> <span class="cn">NULL</span></span>
<span id="cb1-33"><a href="sec11_1.html#cb1-33" tabindex="-1"></a>        <span class="cf">for</span>(h <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>H){</span>
<span id="cb1-34"><a href="sec11_1.html#cb1-34" tabindex="-1"></a>            lambdaih <span class="ot">&lt;-</span> Lambda[h]<span class="sc">*</span><span class="fu">dnorm</span>(y[i], MU[h], <span class="dv">1</span>)</span>
<span id="cb1-35"><a href="sec11_1.html#cb1-35" tabindex="-1"></a>            lambdai <span class="ot">&lt;-</span> <span class="fu">c</span>(lambdai, lambdaih)</span>
<span id="cb1-36"><a href="sec11_1.html#cb1-36" tabindex="-1"></a>        }</span>
<span id="cb1-37"><a href="sec11_1.html#cb1-37" tabindex="-1"></a>        Psi[i] <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span>H, <span class="dv">1</span>, <span class="at">prob =</span> lambdai)</span>
<span id="cb1-38"><a href="sec11_1.html#cb1-38" tabindex="-1"></a>    }</span>
<span id="cb1-39"><a href="sec11_1.html#cb1-39" tabindex="-1"></a>    PostPsi[s, ] <span class="ot">&lt;-</span> Psi</span>
<span id="cb1-40"><a href="sec11_1.html#cb1-40" tabindex="-1"></a>    <span class="cf">for</span>(h <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>H){</span>
<span id="cb1-41"><a href="sec11_1.html#cb1-41" tabindex="-1"></a>        idh <span class="ot">&lt;-</span> <span class="fu">which</span>(Psi <span class="sc">==</span> h);         MU[h] <span class="ot">&lt;-</span> <span class="fu">Postmu</span>(<span class="at">yh =</span> y[idh])</span>
<span id="cb1-42"><a href="sec11_1.html#cb1-42" tabindex="-1"></a>    }</span>
<span id="cb1-43"><a href="sec11_1.html#cb1-43" tabindex="-1"></a>    PostMu[s,] <span class="ot">&lt;-</span> MU; </span>
<span id="cb1-44"><a href="sec11_1.html#cb1-44" tabindex="-1"></a>    Lambda <span class="ot">&lt;-</span> <span class="fu">sort</span>(MCMCpack<span class="sc">::</span><span class="fu">rdirichlet</span>(<span class="dv">1</span>, a0h <span class="sc">+</span> <span class="fu">table</span>(Psi)), <span class="at">decreasing =</span> <span class="cn">TRUE</span>)</span>
<span id="cb1-45"><a href="sec11_1.html#cb1-45" tabindex="-1"></a>    PostLambda[s] <span class="ot">&lt;-</span> Lambda[<span class="dv">1</span>]</span>
<span id="cb1-46"><a href="sec11_1.html#cb1-46" tabindex="-1"></a>    <span class="fu">setWinProgressBar</span>(pb, s, <span class="at">title=</span><span class="fu">paste</span>( <span class="fu">round</span>(s<span class="sc">/</span>tot<span class="sc">*</span><span class="dv">100</span>, <span class="dv">0</span>),<span class="st">&quot;% done&quot;</span>))</span>
<span id="cb1-47"><a href="sec11_1.html#cb1-47" tabindex="-1"></a>}</span>
<span id="cb1-48"><a href="sec11_1.html#cb1-48" tabindex="-1"></a><span class="fu">close</span>(pb)</span>
<span id="cb1-49"><a href="sec11_1.html#cb1-49" tabindex="-1"></a>keep <span class="ot">&lt;-</span> <span class="fu">seq</span>(burnin, tot, thin)</span>
<span id="cb1-50"><a href="sec11_1.html#cb1-50" tabindex="-1"></a>PosteriorMUs <span class="ot">&lt;-</span> coda<span class="sc">::</span><span class="fu">mcmc</span>(PostMu[keep,])</span>
<span id="cb1-51"><a href="sec11_1.html#cb1-51" tabindex="-1"></a><span class="fu">summary</span>(PosteriorMUs); <span class="fu">plot</span>(PosteriorMUs)</span>
<span id="cb1-52"><a href="sec11_1.html#cb1-52" tabindex="-1"></a>dfMU <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">mu1 =</span> PostMu[keep,<span class="dv">1</span>], <span class="at">mu2 =</span> PostMu[keep,<span class="dv">2</span>])</span>
<span id="cb1-53"><a href="sec11_1.html#cb1-53" tabindex="-1"></a><span class="co"># Plot</span></span>
<span id="cb1-54"><a href="sec11_1.html#cb1-54" tabindex="-1"></a><span class="fu">require</span>(latex2exp)</span>
<span id="cb1-55"><a href="sec11_1.html#cb1-55" tabindex="-1"></a><span class="fu">ggplot</span>(dfMU) <span class="sc">+</span> <span class="fu">geom_density</span>(<span class="fu">aes</span>(<span class="at">x =</span> mu1, <span class="at">color =</span> <span class="st">&quot;mu1&quot;</span>), <span class="at">linewidth =</span> <span class="dv">1</span>) <span class="sc">+</span> <span class="fu">geom_density</span>(<span class="fu">aes</span>(<span class="at">x =</span> mu2, <span class="at">color =</span> <span class="st">&quot;mu2&quot;</span>), <span class="at">linewidth =</span> <span class="dv">1</span>) <span class="sc">+</span> <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Density Plot&quot;</span>, <span class="at">x =</span> <span class="fu">TeX</span>(<span class="st">&quot;$</span><span class="sc">\\</span><span class="st">mu$&quot;</span>), <span class="at">y =</span> <span class="st">&quot;Density&quot;</span>, <span class="at">color =</span> <span class="st">&quot;Variable&quot;</span>) <span class="sc">+</span> <span class="fu">theme_minimal</span>() <span class="sc">+</span> <span class="fu">scale_color_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">&quot;mu1&quot;</span> <span class="ot">=</span> <span class="st">&quot;blue&quot;</span>, <span class="st">&quot;mu2&quot;</span> <span class="ot">=</span> <span class="st">&quot;red&quot;</span>))</span></code></pre></div>
<p>The figure shows the posterior densities of the location parameters. The posterior means are 0.42 and 2.50, with 95% credible intervals of (0.07, 0.71) and (2.34, 2.65), respectively. The posterior mean of the probability is 0.27, with a 95% credible interval of (0.19, 0.35). Note that in this simple simulation exercise, we did not observe unintended consequences from using non-informative priors and not standardizing the data. However, real-world applications should take these aspects into account.</p>
<p>We perform the same exercise assuming <span class="math inline">\(\beta_{01}=0.5\)</span> and <span class="math inline">\(\beta_{02}=1\)</span>. The figure shows the posterior densities, where we observe significant overlap. The posterior means are 0.77 in both cases, with 95% credible intervals of (0.40, 1.05) and (-0.44, 1.71). The posterior mean of the probability is 0.84.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="sec11_1.html#cb2-1" tabindex="-1"></a><span class="fu">rm</span>(<span class="at">list =</span> <span class="fu">ls</span>()); <span class="fu">set.seed</span>(<span class="dv">010101</span>); <span class="fu">library</span>(ggplot2)</span>
<span id="cb2-2"><a href="sec11_1.html#cb2-2" tabindex="-1"></a><span class="co"># Simulate data from a 2-component mixture model</span></span>
<span id="cb2-3"><a href="sec11_1.html#cb2-3" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">500</span></span>
<span id="cb2-4"><a href="sec11_1.html#cb2-4" tabindex="-1"></a>z <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(n, <span class="dv">1</span>, <span class="fl">0.75</span>)  <span class="co"># Latent class indicator</span></span>
<span id="cb2-5"><a href="sec11_1.html#cb2-5" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(z <span class="sc">==</span> <span class="dv">0</span>, <span class="fu">rnorm</span>(n, <span class="fl">0.5</span>, <span class="dv">1</span>), <span class="fu">rnorm</span>(n, <span class="dv">1</span>, <span class="dv">1</span>))</span>
<span id="cb2-6"><a href="sec11_1.html#cb2-6" tabindex="-1"></a>data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(y)</span>
<span id="cb2-7"><a href="sec11_1.html#cb2-7" tabindex="-1"></a><span class="co"># Plot</span></span>
<span id="cb2-8"><a href="sec11_1.html#cb2-8" tabindex="-1"></a><span class="fu">ggplot</span>(data, <span class="fu">aes</span>(<span class="at">x =</span> y)) <span class="sc">+</span></span>
<span id="cb2-9"><a href="sec11_1.html#cb2-9" tabindex="-1"></a><span class="fu">geom_density</span>(<span class="at">fill =</span> <span class="st">&quot;blue&quot;</span>, <span class="at">alpha =</span> <span class="fl">0.3</span>) <span class="sc">+</span> <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Density Plot&quot;</span>, <span class="at">x =</span> <span class="st">&quot;y&quot;</span>, <span class="at">y =</span> <span class="st">&quot;Density&quot;</span>) <span class="sc">+</span> <span class="fu">theme_minimal</span>()</span>
<span id="cb2-10"><a href="sec11_1.html#cb2-10" tabindex="-1"></a><span class="co"># Hyperparameters</span></span>
<span id="cb2-11"><a href="sec11_1.html#cb2-11" tabindex="-1"></a>mu0 <span class="ot">&lt;-</span> <span class="dv">0</span>; sig2mu0 <span class="ot">&lt;-</span> <span class="dv">10</span>; H <span class="ot">&lt;-</span> <span class="dv">2</span>; a0h <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">1</span><span class="sc">/</span>H, H)</span>
<span id="cb2-12"><a href="sec11_1.html#cb2-12" tabindex="-1"></a><span class="co"># MCMC parameters</span></span>
<span id="cb2-13"><a href="sec11_1.html#cb2-13" tabindex="-1"></a>mcmc <span class="ot">&lt;-</span> <span class="dv">1000</span>; burnin <span class="ot">&lt;-</span> <span class="dv">500</span>; tot <span class="ot">&lt;-</span> mcmc <span class="sc">+</span> burnin; thin <span class="ot">&lt;-</span> <span class="dv">2</span></span>
<span id="cb2-14"><a href="sec11_1.html#cb2-14" tabindex="-1"></a><span class="co"># Gibbs sampling functions</span></span>
<span id="cb2-15"><a href="sec11_1.html#cb2-15" tabindex="-1"></a>Postmu <span class="ot">&lt;-</span> <span class="cf">function</span>(yh){</span>
<span id="cb2-16"><a href="sec11_1.html#cb2-16" tabindex="-1"></a>    Nh <span class="ot">&lt;-</span> <span class="fu">length</span>(yh)</span>
<span id="cb2-17"><a href="sec11_1.html#cb2-17" tabindex="-1"></a>    sig2mu <span class="ot">&lt;-</span> (<span class="dv">1</span><span class="sc">/</span>sig2mu0 <span class="sc">+</span> Nh)<span class="sc">^</span>(<span class="sc">-</span><span class="dv">1</span>)</span>
<span id="cb2-18"><a href="sec11_1.html#cb2-18" tabindex="-1"></a>    mun <span class="ot">&lt;-</span> sig2mu<span class="sc">*</span>(mu0<span class="sc">/</span>sig2mu0 <span class="sc">+</span> <span class="fu">sum</span>(yh))</span>
<span id="cb2-19"><a href="sec11_1.html#cb2-19" tabindex="-1"></a>    mu <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">1</span>, mun, sig2mu<span class="sc">^</span><span class="fl">0.5</span>)</span>
<span id="cb2-20"><a href="sec11_1.html#cb2-20" tabindex="-1"></a>    <span class="fu">return</span>(mu)</span>
<span id="cb2-21"><a href="sec11_1.html#cb2-21" tabindex="-1"></a>}</span>
<span id="cb2-22"><a href="sec11_1.html#cb2-22" tabindex="-1"></a>PostPsi <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="cn">NA</span>, tot, n); PostMu <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="cn">NA</span>, tot, H)</span>
<span id="cb2-23"><a href="sec11_1.html#cb2-23" tabindex="-1"></a>PostLambda <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="cn">NA</span>, tot)</span>
<span id="cb2-24"><a href="sec11_1.html#cb2-24" tabindex="-1"></a>Id1 <span class="ot">&lt;-</span> <span class="fu">which</span>(y <span class="sc">&lt;=</span> <span class="dv">1</span>) <span class="co"># 1 is from inspection of the density plot of y </span></span>
<span id="cb2-25"><a href="sec11_1.html#cb2-25" tabindex="-1"></a>Id2 <span class="ot">&lt;-</span> <span class="fu">which</span>(y <span class="sc">&gt;</span> <span class="dv">1</span>)</span>
<span id="cb2-26"><a href="sec11_1.html#cb2-26" tabindex="-1"></a>N1 <span class="ot">&lt;-</span> <span class="fu">length</span>(Id1); N2 <span class="ot">&lt;-</span> <span class="fu">length</span>(Id2)</span>
<span id="cb2-27"><a href="sec11_1.html#cb2-27" tabindex="-1"></a>Lambda <span class="ot">&lt;-</span> <span class="fu">c</span>(N1<span class="sc">/</span>n, N2<span class="sc">/</span>n)</span>
<span id="cb2-28"><a href="sec11_1.html#cb2-28" tabindex="-1"></a>MU <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">mean</span>(y[Id1]), <span class="fu">mean</span>(y[Id2])); Psi <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="cn">NA</span>, n)</span>
<span id="cb2-29"><a href="sec11_1.html#cb2-29" tabindex="-1"></a>pb <span class="ot">&lt;-</span> <span class="fu">winProgressBar</span>(<span class="at">title =</span> <span class="st">&quot;progress bar&quot;</span>, <span class="at">min =</span> <span class="dv">0</span>, <span class="at">max =</span> tot, <span class="at">width =</span> <span class="dv">300</span>)</span>
<span id="cb2-30"><a href="sec11_1.html#cb2-30" tabindex="-1"></a><span class="cf">for</span>(s <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>tot){</span>
<span id="cb2-31"><a href="sec11_1.html#cb2-31" tabindex="-1"></a>    <span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n){</span>
<span id="cb2-32"><a href="sec11_1.html#cb2-32" tabindex="-1"></a>        lambdai <span class="ot">&lt;-</span> <span class="cn">NULL</span></span>
<span id="cb2-33"><a href="sec11_1.html#cb2-33" tabindex="-1"></a>        <span class="cf">for</span>(h <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>H){</span>
<span id="cb2-34"><a href="sec11_1.html#cb2-34" tabindex="-1"></a>            lambdaih <span class="ot">&lt;-</span> Lambda[h]<span class="sc">*</span><span class="fu">dnorm</span>(y[i], MU[h], <span class="dv">1</span>)</span>
<span id="cb2-35"><a href="sec11_1.html#cb2-35" tabindex="-1"></a>            lambdai <span class="ot">&lt;-</span> <span class="fu">c</span>(lambdai, lambdaih)</span>
<span id="cb2-36"><a href="sec11_1.html#cb2-36" tabindex="-1"></a>        }</span>
<span id="cb2-37"><a href="sec11_1.html#cb2-37" tabindex="-1"></a>        Psi[i] <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span>H, <span class="dv">1</span>, <span class="at">prob =</span> lambdai)</span>
<span id="cb2-38"><a href="sec11_1.html#cb2-38" tabindex="-1"></a>    }</span>
<span id="cb2-39"><a href="sec11_1.html#cb2-39" tabindex="-1"></a>    PostPsi[s, ] <span class="ot">&lt;-</span> Psi</span>
<span id="cb2-40"><a href="sec11_1.html#cb2-40" tabindex="-1"></a>    <span class="cf">for</span>(h <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>H){</span>
<span id="cb2-41"><a href="sec11_1.html#cb2-41" tabindex="-1"></a>        idh <span class="ot">&lt;-</span> <span class="fu">which</span>(Psi <span class="sc">==</span> h);         MU[h] <span class="ot">&lt;-</span> <span class="fu">Postmu</span>(<span class="at">yh =</span> y[idh])</span>
<span id="cb2-42"><a href="sec11_1.html#cb2-42" tabindex="-1"></a>    }</span>
<span id="cb2-43"><a href="sec11_1.html#cb2-43" tabindex="-1"></a>    PostMu[s,] <span class="ot">&lt;-</span> MU; </span>
<span id="cb2-44"><a href="sec11_1.html#cb2-44" tabindex="-1"></a>    Lambda <span class="ot">&lt;-</span> <span class="fu">sort</span>(MCMCpack<span class="sc">::</span><span class="fu">rdirichlet</span>(<span class="dv">1</span>, a0h <span class="sc">+</span> <span class="fu">table</span>(Psi)), <span class="at">decreasing =</span> <span class="cn">TRUE</span>)</span>
<span id="cb2-45"><a href="sec11_1.html#cb2-45" tabindex="-1"></a>    PostLambda[s] <span class="ot">&lt;-</span> Lambda[<span class="dv">1</span>]</span>
<span id="cb2-46"><a href="sec11_1.html#cb2-46" tabindex="-1"></a>    <span class="fu">setWinProgressBar</span>(pb, s, <span class="at">title=</span><span class="fu">paste</span>( <span class="fu">round</span>(s<span class="sc">/</span>tot<span class="sc">*</span><span class="dv">100</span>, <span class="dv">0</span>),<span class="st">&quot;% done&quot;</span>))</span>
<span id="cb2-47"><a href="sec11_1.html#cb2-47" tabindex="-1"></a>}</span>
<span id="cb2-48"><a href="sec11_1.html#cb2-48" tabindex="-1"></a><span class="fu">close</span>(pb)</span>
<span id="cb2-49"><a href="sec11_1.html#cb2-49" tabindex="-1"></a>keep <span class="ot">&lt;-</span> <span class="fu">seq</span>(burnin, tot, thin)</span>
<span id="cb2-50"><a href="sec11_1.html#cb2-50" tabindex="-1"></a>PosteriorMUs <span class="ot">&lt;-</span> coda<span class="sc">::</span><span class="fu">mcmc</span>(PostMu[keep,])</span>
<span id="cb2-51"><a href="sec11_1.html#cb2-51" tabindex="-1"></a><span class="fu">summary</span>(PosteriorMUs); <span class="fu">plot</span>(PosteriorMUs)</span>
<span id="cb2-52"><a href="sec11_1.html#cb2-52" tabindex="-1"></a>dfMU <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">mu1 =</span> PostMu[keep,<span class="dv">1</span>], <span class="at">mu2 =</span> PostMu[keep,<span class="dv">2</span>])</span>
<span id="cb2-53"><a href="sec11_1.html#cb2-53" tabindex="-1"></a><span class="co"># Plot</span></span>
<span id="cb2-54"><a href="sec11_1.html#cb2-54" tabindex="-1"></a><span class="fu">require</span>(latex2exp)</span>
<span id="cb2-55"><a href="sec11_1.html#cb2-55" tabindex="-1"></a><span class="fu">ggplot</span>(dfMU) <span class="sc">+</span> <span class="fu">geom_density</span>(<span class="fu">aes</span>(<span class="at">x =</span> mu1, <span class="at">color =</span> <span class="st">&quot;mu1&quot;</span>), <span class="at">linewidth =</span> <span class="dv">1</span>) <span class="sc">+</span> <span class="fu">geom_density</span>(<span class="fu">aes</span>(<span class="at">x =</span> mu2, <span class="at">color =</span> <span class="st">&quot;mu2&quot;</span>), <span class="at">linewidth =</span> <span class="dv">1</span>) <span class="sc">+</span> <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Density Plot&quot;</span>, <span class="at">x =</span> <span class="fu">TeX</span>(<span class="st">&quot;$</span><span class="sc">\\</span><span class="st">mu$&quot;</span>), <span class="at">y =</span> <span class="st">&quot;Density&quot;</span>, <span class="at">color =</span> <span class="st">&quot;Variable&quot;</span>) <span class="sc">+</span> <span class="fu">theme_minimal</span>() <span class="sc">+</span> <span class="fu">scale_color_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">&quot;mu1&quot;</span> <span class="ot">=</span> <span class="st">&quot;blue&quot;</span>, <span class="st">&quot;mu2&quot;</span> <span class="ot">=</span> <span class="st">&quot;red&quot;</span>))</span></code></pre></div>
<p>In the second setting, the posterior draws of the Gibbs sampler can switch between the two means because they are relatively close. This situation contrasts with the first example, where there is a relatively large separation between the means, resulting in a region of the parameter space with zero probability (see the flat region between the two posterior distributions in that example). The key point is that, given a sufficiently large number of Gibbs sampler iterations, the algorithm should eventually explore the entire parameter space and encounter the label-switching issue. This occurs because both posterior chains should exhibit similar behavior, as they are targeting the same distribution.</p>
<p>We can implement <em>random permutation of latent classes</em> to address this issue. This involves sampling a random permutation of the labels at each iteration of the MCMC algorithm. For example, with three clusters, there are <span class="math inline">\(3! = 6\)</span> possible label permutations. Let the permutations be labeled as <span class="math inline">\(\boldsymbol{p}_k=\left\{p_k(1),p_k(2),\dots,p_k(H)\right\}, k=1,2,\dots,H!\)</span>. At the end of each iteration in the MCMC algorithm, we randomly select one of the permutations <span class="math inline">\(\boldsymbol{p}_k\)</span> and replace the cluster probabilities <span class="math inline">\(\lambda_1^{(s)},\dots,\lambda_H^{(s)}\)</span> with <span class="math inline">\(\lambda_{p_k(1)}^{(s)},\dots,\lambda_{p_k(H)}^{(s)}\)</span>. We apply the same permutation to <span class="math inline">\(\boldsymbol{\beta}^{(s)}\)</span>, <span class="math inline">\(\sigma^{2(s)}\)</span>, and <span class="math inline">\(\boldsymbol{\psi}_{i}^{(s)}\)</span>, for <span class="math inline">\(i=1,2,\dots,n\)</span>. The following algorithm illustrates how to implement this in our simple example.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="sec11_1.html#cb3-1" tabindex="-1"></a><span class="do">###### Permutations ######</span></span>
<span id="cb3-2"><a href="sec11_1.html#cb3-2" tabindex="-1"></a><span class="fu">rm</span>(<span class="at">list =</span> <span class="fu">ls</span>()); <span class="fu">set.seed</span>(<span class="dv">010101</span>); <span class="fu">library</span>(ggplot2)</span>
<span id="cb3-3"><a href="sec11_1.html#cb3-3" tabindex="-1"></a><span class="co"># Simulate data from a 2-component mixture model</span></span>
<span id="cb3-4"><a href="sec11_1.html#cb3-4" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">500</span></span>
<span id="cb3-5"><a href="sec11_1.html#cb3-5" tabindex="-1"></a>z <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(n, <span class="dv">1</span>, <span class="fl">0.75</span>)  <span class="co"># Latent class indicator</span></span>
<span id="cb3-6"><a href="sec11_1.html#cb3-6" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(z <span class="sc">==</span> <span class="dv">0</span>, <span class="fu">rnorm</span>(n, <span class="fl">0.5</span>, <span class="dv">1</span>), <span class="fu">rnorm</span>(n, <span class="fl">2.5</span>, <span class="dv">1</span>))</span>
<span id="cb3-7"><a href="sec11_1.html#cb3-7" tabindex="-1"></a><span class="co"># Hyperparameters</span></span>
<span id="cb3-8"><a href="sec11_1.html#cb3-8" tabindex="-1"></a>mu0 <span class="ot">&lt;-</span> <span class="dv">0</span>; sig2mu0 <span class="ot">&lt;-</span> <span class="dv">10</span>; H <span class="ot">&lt;-</span> <span class="dv">2</span>; a0h <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">1</span><span class="sc">/</span>H, H)</span>
<span id="cb3-9"><a href="sec11_1.html#cb3-9" tabindex="-1"></a><span class="co"># MCMC parameters</span></span>
<span id="cb3-10"><a href="sec11_1.html#cb3-10" tabindex="-1"></a>mcmc <span class="ot">&lt;-</span> <span class="dv">2000</span>; burnin <span class="ot">&lt;-</span> <span class="dv">500</span></span>
<span id="cb3-11"><a href="sec11_1.html#cb3-11" tabindex="-1"></a>tot <span class="ot">&lt;-</span> mcmc <span class="sc">+</span> burnin; thin <span class="ot">&lt;-</span> <span class="dv">2</span></span>
<span id="cb3-12"><a href="sec11_1.html#cb3-12" tabindex="-1"></a><span class="co"># Gibbs sampling functions</span></span>
<span id="cb3-13"><a href="sec11_1.html#cb3-13" tabindex="-1"></a>Postmu <span class="ot">&lt;-</span> <span class="cf">function</span>(yh){</span>
<span id="cb3-14"><a href="sec11_1.html#cb3-14" tabindex="-1"></a>    Nh <span class="ot">&lt;-</span> <span class="fu">length</span>(yh)</span>
<span id="cb3-15"><a href="sec11_1.html#cb3-15" tabindex="-1"></a>    sig2mu <span class="ot">&lt;-</span> (<span class="dv">1</span><span class="sc">/</span>sig2mu0 <span class="sc">+</span> Nh)<span class="sc">^</span>(<span class="sc">-</span><span class="dv">1</span>)</span>
<span id="cb3-16"><a href="sec11_1.html#cb3-16" tabindex="-1"></a>    mun <span class="ot">&lt;-</span> sig2mu<span class="sc">*</span>(mu0<span class="sc">/</span>sig2mu0 <span class="sc">+</span> <span class="fu">sum</span>(yh))</span>
<span id="cb3-17"><a href="sec11_1.html#cb3-17" tabindex="-1"></a>    mu <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">1</span>, mun, sig2mu<span class="sc">^</span><span class="fl">0.5</span>)</span>
<span id="cb3-18"><a href="sec11_1.html#cb3-18" tabindex="-1"></a>    <span class="fu">return</span>(mu)</span>
<span id="cb3-19"><a href="sec11_1.html#cb3-19" tabindex="-1"></a>}</span>
<span id="cb3-20"><a href="sec11_1.html#cb3-20" tabindex="-1"></a>PostPsi <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="cn">NA</span>, tot, n); PostMu <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="cn">NA</span>, tot, H)</span>
<span id="cb3-21"><a href="sec11_1.html#cb3-21" tabindex="-1"></a>PostLambda <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="cn">NA</span>, tot)</span>
<span id="cb3-22"><a href="sec11_1.html#cb3-22" tabindex="-1"></a>Id1 <span class="ot">&lt;-</span> <span class="fu">which</span>(y <span class="sc">&lt;=</span> <span class="dv">1</span>); Id2 <span class="ot">&lt;-</span> <span class="fu">which</span>(y <span class="sc">&gt;</span> <span class="dv">1</span>)</span>
<span id="cb3-23"><a href="sec11_1.html#cb3-23" tabindex="-1"></a>N1 <span class="ot">&lt;-</span> <span class="fu">length</span>(Id1); N2 <span class="ot">&lt;-</span> <span class="fu">length</span>(Id2)</span>
<span id="cb3-24"><a href="sec11_1.html#cb3-24" tabindex="-1"></a>Lambda <span class="ot">&lt;-</span> <span class="fu">c</span>(N1<span class="sc">/</span>n, N2<span class="sc">/</span>n); MU <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">mean</span>(y[Id1]), <span class="fu">mean</span>(y[Id2]))</span>
<span id="cb3-25"><a href="sec11_1.html#cb3-25" tabindex="-1"></a>Psi <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="cn">NA</span>, n); per1 <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>); per2 <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">1</span>)</span>
<span id="cb3-26"><a href="sec11_1.html#cb3-26" tabindex="-1"></a>pb <span class="ot">&lt;-</span> <span class="fu">winProgressBar</span>(<span class="at">title =</span> <span class="st">&quot;progress bar&quot;</span>, <span class="at">min =</span> <span class="dv">0</span>, <span class="at">max =</span> tot, <span class="at">width =</span> <span class="dv">300</span>)</span>
<span id="cb3-27"><a href="sec11_1.html#cb3-27" tabindex="-1"></a><span class="cf">for</span>(s <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>tot){</span>
<span id="cb3-28"><a href="sec11_1.html#cb3-28" tabindex="-1"></a>    <span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n){</span>
<span id="cb3-29"><a href="sec11_1.html#cb3-29" tabindex="-1"></a>        lambdai <span class="ot">&lt;-</span> <span class="cn">NULL</span></span>
<span id="cb3-30"><a href="sec11_1.html#cb3-30" tabindex="-1"></a>        <span class="cf">for</span>(h <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>H){</span>
<span id="cb3-31"><a href="sec11_1.html#cb3-31" tabindex="-1"></a>            lambdaih <span class="ot">&lt;-</span> Lambda[h]<span class="sc">*</span><span class="fu">dnorm</span>(y[i], MU[h], <span class="dv">1</span>)</span>
<span id="cb3-32"><a href="sec11_1.html#cb3-32" tabindex="-1"></a>            lambdai <span class="ot">&lt;-</span> <span class="fu">c</span>(lambdai, lambdaih)</span>
<span id="cb3-33"><a href="sec11_1.html#cb3-33" tabindex="-1"></a>        }</span>
<span id="cb3-34"><a href="sec11_1.html#cb3-34" tabindex="-1"></a>        Psi[i] <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span>H, <span class="dv">1</span>, <span class="at">prob =</span> lambdai)</span>
<span id="cb3-35"><a href="sec11_1.html#cb3-35" tabindex="-1"></a>    }</span>
<span id="cb3-36"><a href="sec11_1.html#cb3-36" tabindex="-1"></a>    <span class="cf">for</span>(h <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>H){</span>
<span id="cb3-37"><a href="sec11_1.html#cb3-37" tabindex="-1"></a>        idh <span class="ot">&lt;-</span> <span class="fu">which</span>(Psi <span class="sc">==</span> h)</span>
<span id="cb3-38"><a href="sec11_1.html#cb3-38" tabindex="-1"></a>        MU[h] <span class="ot">&lt;-</span> <span class="fu">Postmu</span>(<span class="at">yh =</span> y[idh])</span>
<span id="cb3-39"><a href="sec11_1.html#cb3-39" tabindex="-1"></a>    }</span>
<span id="cb3-40"><a href="sec11_1.html#cb3-40" tabindex="-1"></a>    Lambda <span class="ot">&lt;-</span> MCMCpack<span class="sc">::</span><span class="fu">rdirichlet</span>(<span class="dv">1</span>, a0h <span class="sc">+</span> <span class="fu">table</span>(Psi))</span>
<span id="cb3-41"><a href="sec11_1.html#cb3-41" tabindex="-1"></a>    <span class="co"># Permutations</span></span>
<span id="cb3-42"><a href="sec11_1.html#cb3-42" tabindex="-1"></a>    labels <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>, <span class="dv">1</span>, <span class="at">prob =</span> <span class="fu">c</span>(<span class="fl">0.5</span>, <span class="fl">0.5</span>))</span>
<span id="cb3-43"><a href="sec11_1.html#cb3-43" tabindex="-1"></a>    <span class="cf">if</span>(labels <span class="sc">==</span> <span class="dv">2</span>){</span>
<span id="cb3-44"><a href="sec11_1.html#cb3-44" tabindex="-1"></a>        Lambda <span class="ot">&lt;-</span> Lambda[per2]</span>
<span id="cb3-45"><a href="sec11_1.html#cb3-45" tabindex="-1"></a>        MU <span class="ot">&lt;-</span> MU[per2]</span>
<span id="cb3-46"><a href="sec11_1.html#cb3-46" tabindex="-1"></a>        <span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n){</span>
<span id="cb3-47"><a href="sec11_1.html#cb3-47" tabindex="-1"></a>            <span class="cf">if</span>(Psi[i] <span class="sc">==</span> <span class="dv">1</span>){Psi[i] <span class="ot">&lt;-</span> <span class="dv">2</span></span>
<span id="cb3-48"><a href="sec11_1.html#cb3-48" tabindex="-1"></a>            }<span class="cf">else</span>{Psi[i] <span class="ot">&lt;-</span> <span class="dv">1</span>}</span>
<span id="cb3-49"><a href="sec11_1.html#cb3-49" tabindex="-1"></a>        }</span>
<span id="cb3-50"><a href="sec11_1.html#cb3-50" tabindex="-1"></a>    }</span>
<span id="cb3-51"><a href="sec11_1.html#cb3-51" tabindex="-1"></a>    PostPsi[s, ] <span class="ot">&lt;-</span> Psi; PostMu[s,] <span class="ot">&lt;-</span> MU</span>
<span id="cb3-52"><a href="sec11_1.html#cb3-52" tabindex="-1"></a>    PostLambda[s] <span class="ot">&lt;-</span> Lambda[<span class="dv">1</span>]</span>
<span id="cb3-53"><a href="sec11_1.html#cb3-53" tabindex="-1"></a>    <span class="fu">setWinProgressBar</span>(pb, s, <span class="at">title=</span><span class="fu">paste</span>( <span class="fu">round</span>(s<span class="sc">/</span>tot<span class="sc">*</span><span class="dv">100</span>, <span class="dv">0</span>),<span class="st">&quot;% done&quot;</span>))</span>
<span id="cb3-54"><a href="sec11_1.html#cb3-54" tabindex="-1"></a>}</span>
<span id="cb3-55"><a href="sec11_1.html#cb3-55" tabindex="-1"></a><span class="fu">close</span>(pb)</span>
<span id="cb3-56"><a href="sec11_1.html#cb3-56" tabindex="-1"></a>keep <span class="ot">&lt;-</span> <span class="fu">seq</span>(burnin, tot, thin)</span>
<span id="cb3-57"><a href="sec11_1.html#cb3-57" tabindex="-1"></a>PosteriorMUs <span class="ot">&lt;-</span> coda<span class="sc">::</span><span class="fu">mcmc</span>(PostMu[keep,])</span>
<span id="cb3-58"><a href="sec11_1.html#cb3-58" tabindex="-1"></a><span class="fu">summary</span>(PosteriorMUs)</span>
<span id="cb3-59"><a href="sec11_1.html#cb3-59" tabindex="-1"></a><span class="fu">plot</span>(PosteriorMUs)</span>
<span id="cb3-60"><a href="sec11_1.html#cb3-60" tabindex="-1"></a>dfMU <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">mu1 =</span> PostMu[keep,<span class="dv">1</span>], <span class="at">mu2 =</span> PostMu[keep,<span class="dv">2</span>])</span>
<span id="cb3-61"><a href="sec11_1.html#cb3-61" tabindex="-1"></a><span class="co"># Plot</span></span>
<span id="cb3-62"><a href="sec11_1.html#cb3-62" tabindex="-1"></a><span class="fu">require</span>(latex2exp)</span>
<span id="cb3-63"><a href="sec11_1.html#cb3-63" tabindex="-1"></a><span class="fu">ggplot</span>(dfMU) <span class="sc">+</span></span>
<span id="cb3-64"><a href="sec11_1.html#cb3-64" tabindex="-1"></a><span class="fu">geom_density</span>(<span class="fu">aes</span>(<span class="at">x =</span> mu1, <span class="at">color =</span> <span class="st">&quot;mu1&quot;</span>), <span class="at">linewidth =</span> <span class="dv">1</span>) <span class="sc">+</span>  <span class="co"># First density plot</span></span>
<span id="cb3-65"><a href="sec11_1.html#cb3-65" tabindex="-1"></a><span class="fu">geom_density</span>(<span class="fu">aes</span>(<span class="at">x =</span> mu2, <span class="at">color =</span> <span class="st">&quot;mu2&quot;</span>), <span class="at">linewidth =</span> <span class="dv">1</span>) <span class="sc">+</span>  <span class="co"># Second density plot</span></span>
<span id="cb3-66"><a href="sec11_1.html#cb3-66" tabindex="-1"></a><span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Density Plot&quot;</span>, <span class="at">x =</span> <span class="fu">TeX</span>(<span class="st">&quot;$</span><span class="sc">\\</span><span class="st">mu$&quot;</span>), <span class="at">y =</span> <span class="st">&quot;Density&quot;</span>, <span class="at">color =</span> <span class="st">&quot;Variable&quot;</span>) <span class="sc">+</span></span>
<span id="cb3-67"><a href="sec11_1.html#cb3-67" tabindex="-1"></a><span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb3-68"><a href="sec11_1.html#cb3-68" tabindex="-1"></a><span class="fu">scale_color_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">&quot;mu1&quot;</span> <span class="ot">=</span> <span class="st">&quot;blue&quot;</span>, <span class="st">&quot;mu2&quot;</span> <span class="ot">=</span> <span class="st">&quot;red&quot;</span>))  <span class="co"># Custom colors</span></span>
<span id="cb3-69"><a href="sec11_1.html#cb3-69" tabindex="-1"></a>PosteriorLAMBDA <span class="ot">&lt;-</span> coda<span class="sc">::</span><span class="fu">mcmc</span>(PostLambda[keep])</span>
<span id="cb3-70"><a href="sec11_1.html#cb3-70" tabindex="-1"></a><span class="fu">summary</span>(PosteriorLAMBDA)</span>
<span id="cb3-71"><a href="sec11_1.html#cb3-71" tabindex="-1"></a><span class="fu">plot</span>(PosteriorLAMBDA)</span></code></pre></div>
<p>The figure shows the posterior distributions from the random permutation of latent classes in the first simulation setting. We observe that both posterior distributions look similar, as both are targeting a bimodal distribution given by two clusters.</p>
<p>In the following setting we simulate a simple regression mixture with two components such that <span class="math inline">\(\psi_{i1}\sim \text{Ber}(0.5)\)</span>, consequently, <span class="math inline">\(\psi_{i2}=1-\psi_{i1}\)</span>, and assume one regressor, <span class="math inline">\(x_i\sim N(0,1)\)</span>, <span class="math inline">\(i=1,2,\dots,1,000\)</span>. Then,
<span class="math display">\[p(y_i \mid \boldsymbol{x}_i) =
0.5 \phi(y_i \mid 2+1.5x_i,1^2)+0.5 \phi(y_i \mid -1+0.5x_i,0.8^2).\]</span></p>
<p>The following code shows how to perform inference in this model, assuming <span class="math inline">\(N(0,5)\)</span> and <span class="math inline">\(N(0,2)\)</span> priors for the intercepts and slopes, respectively. Additionally, we use a <span class="math inline">\(Cauchy(0,2)\)</span> prior truncated at 0 for the standard deviations, and a <span class="math inline">\(Dirichlet(1,1)\)</span> prior for the probabilities. We use the <em>brms</em> package in <strong>R</strong>, which in turn uses <em>Stan</em>, setting number of MCMC iterations 2,000, a burn-in (warm-up) equal to 1,000, and 4 chains. Remember that <em>Stan</em> software uses Hamiltonian Monte Carlo.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="sec11_1.html#cb4-1" tabindex="-1"></a><span class="do">####### Simulation exercise: Gaussian mixture: 2 components #############</span></span>
<span id="cb4-2"><a href="sec11_1.html#cb4-2" tabindex="-1"></a><span class="fu">rm</span>(<span class="at">list =</span> <span class="fu">ls</span>())</span>
<span id="cb4-3"><a href="sec11_1.html#cb4-3" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">010101</span>)</span>
<span id="cb4-4"><a href="sec11_1.html#cb4-4" tabindex="-1"></a><span class="fu">library</span>(brms)</span>
<span id="cb4-5"><a href="sec11_1.html#cb4-5" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb4-6"><a href="sec11_1.html#cb4-6" tabindex="-1"></a></span>
<span id="cb4-7"><a href="sec11_1.html#cb4-7" tabindex="-1"></a><span class="co"># Simulate data from a 2-component mixture model</span></span>
<span id="cb4-8"><a href="sec11_1.html#cb4-8" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb4-9"><a href="sec11_1.html#cb4-9" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n)</span>
<span id="cb4-10"><a href="sec11_1.html#cb4-10" tabindex="-1"></a>z <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(n, <span class="dv">1</span>, <span class="fl">0.5</span>)  <span class="co"># Latent class indicator</span></span>
<span id="cb4-11"><a href="sec11_1.html#cb4-11" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(z <span class="sc">==</span> <span class="dv">0</span>, <span class="fu">rnorm</span>(n, <span class="dv">2</span> <span class="sc">+</span> <span class="fl">1.5</span><span class="sc">*</span>x, <span class="dv">1</span>), <span class="fu">rnorm</span>(n, <span class="sc">-</span><span class="dv">1</span> <span class="sc">+</span> <span class="fl">0.5</span><span class="sc">*</span>x, <span class="fl">0.8</span>))</span>
<span id="cb4-12"><a href="sec11_1.html#cb4-12" tabindex="-1"></a>data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(y, x)</span>
<span id="cb4-13"><a href="sec11_1.html#cb4-13" tabindex="-1"></a></span>
<span id="cb4-14"><a href="sec11_1.html#cb4-14" tabindex="-1"></a><span class="co"># Plot</span></span>
<span id="cb4-15"><a href="sec11_1.html#cb4-15" tabindex="-1"></a><span class="fu">ggplot</span>(data, <span class="fu">aes</span>(<span class="at">x =</span> y)) <span class="sc">+</span></span>
<span id="cb4-16"><a href="sec11_1.html#cb4-16" tabindex="-1"></a><span class="fu">geom_density</span>(<span class="at">fill =</span> <span class="st">&quot;blue&quot;</span>, <span class="at">alpha =</span> <span class="fl">0.3</span>) <span class="sc">+</span>  <span class="co"># Density plot with fill color</span></span>
<span id="cb4-17"><a href="sec11_1.html#cb4-17" tabindex="-1"></a><span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Density Plot&quot;</span>, <span class="at">x =</span> <span class="st">&quot;y&quot;</span>, <span class="at">y =</span> <span class="st">&quot;Density&quot;</span>) <span class="sc">+</span></span>
<span id="cb4-18"><a href="sec11_1.html#cb4-18" tabindex="-1"></a><span class="fu">theme_minimal</span>()</span>
<span id="cb4-19"><a href="sec11_1.html#cb4-19" tabindex="-1"></a></span>
<span id="cb4-20"><a href="sec11_1.html#cb4-20" tabindex="-1"></a><span class="co"># Define priors</span></span>
<span id="cb4-21"><a href="sec11_1.html#cb4-21" tabindex="-1"></a>priors <span class="ot">&lt;-</span> <span class="fu">c</span>(</span>
<span id="cb4-22"><a href="sec11_1.html#cb4-22" tabindex="-1"></a><span class="fu">set_prior</span>(<span class="st">&quot;normal(0, 5)&quot;</span>, <span class="at">class =</span> <span class="st">&quot;Intercept&quot;</span>, <span class="at">dpar =</span> <span class="st">&quot;mu1&quot;</span>),  <span class="co"># First component intercept</span></span>
<span id="cb4-23"><a href="sec11_1.html#cb4-23" tabindex="-1"></a><span class="fu">set_prior</span>(<span class="st">&quot;normal(0, 5)&quot;</span>, <span class="at">class =</span> <span class="st">&quot;Intercept&quot;</span>, <span class="at">dpar =</span> <span class="st">&quot;mu2&quot;</span>),  <span class="co"># Second component intercept</span></span>
<span id="cb4-24"><a href="sec11_1.html#cb4-24" tabindex="-1"></a><span class="fu">set_prior</span>(<span class="st">&quot;normal(0, 2)&quot;</span>, <span class="at">class =</span> <span class="st">&quot;b&quot;</span>, <span class="at">dpar =</span> <span class="st">&quot;mu1&quot;</span>),  <span class="co"># First component slope</span></span>
<span id="cb4-25"><a href="sec11_1.html#cb4-25" tabindex="-1"></a><span class="fu">set_prior</span>(<span class="st">&quot;normal(0, 2)&quot;</span>, <span class="at">class =</span> <span class="st">&quot;b&quot;</span>, <span class="at">dpar =</span> <span class="st">&quot;mu2&quot;</span>),  <span class="co"># Second component slope</span></span>
<span id="cb4-26"><a href="sec11_1.html#cb4-26" tabindex="-1"></a><span class="fu">set_prior</span>(<span class="st">&quot;cauchy(0, 2)&quot;</span>, <span class="at">class =</span> <span class="st">&quot;sigma1&quot;</span>, <span class="at">lb =</span> <span class="dv">0</span>),  <span class="co"># First component sigma</span></span>
<span id="cb4-27"><a href="sec11_1.html#cb4-27" tabindex="-1"></a><span class="fu">set_prior</span>(<span class="st">&quot;cauchy(0, 2)&quot;</span>, <span class="at">class =</span> <span class="st">&quot;sigma2&quot;</span>, <span class="at">lb =</span> <span class="dv">0</span>),  <span class="co"># Second component sigma</span></span>
<span id="cb4-28"><a href="sec11_1.html#cb4-28" tabindex="-1"></a><span class="fu">set_prior</span>(<span class="st">&quot;dirichlet(1, 1)&quot;</span>, <span class="at">class =</span> <span class="st">&quot;theta&quot;</span>)  <span class="co"># Mixing proportions</span></span>
<span id="cb4-29"><a href="sec11_1.html#cb4-29" tabindex="-1"></a>)</span>
<span id="cb4-30"><a href="sec11_1.html#cb4-30" tabindex="-1"></a></span>
<span id="cb4-31"><a href="sec11_1.html#cb4-31" tabindex="-1"></a><span class="co"># Fit a 2-component Gaussian mixture regression model</span></span>
<span id="cb4-32"><a href="sec11_1.html#cb4-32" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">brm</span>(</span>
<span id="cb4-33"><a href="sec11_1.html#cb4-33" tabindex="-1"></a><span class="fu">bf</span>(y <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> x, <span class="at">family =</span> <span class="fu">mixture</span>(gaussian, gaussian)),  <span class="co"># Two normal distributions</span></span>
<span id="cb4-34"><a href="sec11_1.html#cb4-34" tabindex="-1"></a><span class="at">data =</span> data,</span>
<span id="cb4-35"><a href="sec11_1.html#cb4-35" tabindex="-1"></a><span class="at">prior =</span> priors,</span>
<span id="cb4-36"><a href="sec11_1.html#cb4-36" tabindex="-1"></a><span class="at">chains =</span> <span class="dv">4</span>, <span class="at">iter =</span> <span class="dv">2000</span>, <span class="at">warmup =</span> <span class="dv">1000</span>, <span class="at">cores =</span> <span class="dv">4</span></span>
<span id="cb4-37"><a href="sec11_1.html#cb4-37" tabindex="-1"></a>)</span>
<span id="cb4-38"><a href="sec11_1.html#cb4-38" tabindex="-1"></a><span class="fu">prior_summary</span>(fit) <span class="co"># Summary of priors</span></span>
<span id="cb4-39"><a href="sec11_1.html#cb4-39" tabindex="-1"></a><span class="fu">summary</span>(fit) <span class="co"># Summary of posterior draws</span></span>
<span id="cb4-40"><a href="sec11_1.html#cb4-40" tabindex="-1"></a><span class="fu">plot</span>(fit) <span class="co"># Plots of posterior draws</span></span></code></pre></div>
<p>The following code performs inference in this simulation from scratch using Gibbs sampling. We do not implement the random permutation of latent classes algorithm for facilitating exposition and comparability with the results from the package <em>brms</em>. We use non-informative priors, setting <span class="math inline">\(\alpha_{h0}=\delta_{h0}=0.01\)</span>, <span class="math inline">\(\boldsymbol{\beta}_{h0}=\boldsymbol{0}_2\)</span>, <span class="math inline">\(\boldsymbol{B}_{h0}=\boldsymbol{I}_2\)</span>, and <span class="math inline">\(\boldsymbol{\alpha}_0=[1/2 \ 1/2]^{\top}\)</span>. The number of MCMC iterations is 5,000, the burn-in is 1,000, and the thinning parameter is 2. In general, the Gibbs sampler appears to yield good posterior results as all 95% intervals encompass the population parameters.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="sec11_1.html#cb5-1" tabindex="-1"></a><span class="do">########### Perform inference from scratch ###############</span></span>
<span id="cb5-2"><a href="sec11_1.html#cb5-2" tabindex="-1"></a><span class="fu">rm</span>(<span class="at">list =</span> <span class="fu">ls</span>()); <span class="fu">set.seed</span>(<span class="dv">010101</span>)</span>
<span id="cb5-3"><a href="sec11_1.html#cb5-3" tabindex="-1"></a><span class="fu">library</span>(brms); <span class="fu">library</span>(ggplot2)</span>
<span id="cb5-4"><a href="sec11_1.html#cb5-4" tabindex="-1"></a><span class="co"># Simulate data from a 2-component mixture model</span></span>
<span id="cb5-5"><a href="sec11_1.html#cb5-5" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb5-6"><a href="sec11_1.html#cb5-6" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n)</span>
<span id="cb5-7"><a href="sec11_1.html#cb5-7" tabindex="-1"></a>z <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(n, <span class="dv">1</span>, <span class="fl">0.5</span>)  <span class="co"># Latent class indicator</span></span>
<span id="cb5-8"><a href="sec11_1.html#cb5-8" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(z <span class="sc">==</span> <span class="dv">0</span>, <span class="fu">rnorm</span>(n, <span class="dv">2</span> <span class="sc">+</span> <span class="fl">1.5</span><span class="sc">*</span>x, <span class="dv">1</span>), <span class="fu">rnorm</span>(n, <span class="sc">-</span><span class="dv">1</span> <span class="sc">+</span> <span class="fl">0.5</span><span class="sc">*</span>x, <span class="fl">0.8</span>))</span>
<span id="cb5-9"><a href="sec11_1.html#cb5-9" tabindex="-1"></a><span class="co"># Hyperparameters</span></span>
<span id="cb5-10"><a href="sec11_1.html#cb5-10" tabindex="-1"></a>d0 <span class="ot">&lt;-</span> <span class="fl">0.001</span>; a0 <span class="ot">&lt;-</span> <span class="fl">0.001</span></span>
<span id="cb5-11"><a href="sec11_1.html#cb5-11" tabindex="-1"></a>b0 <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">0</span>, <span class="dv">2</span>); B0 <span class="ot">&lt;-</span> <span class="fu">diag</span>(<span class="dv">2</span>); B0i <span class="ot">&lt;-</span> <span class="fu">solve</span>(B0)</span>
<span id="cb5-12"><a href="sec11_1.html#cb5-12" tabindex="-1"></a>a01 <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">/</span><span class="dv">2</span>; a02 <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">/</span><span class="dv">2</span></span>
<span id="cb5-13"><a href="sec11_1.html#cb5-13" tabindex="-1"></a><span class="co"># MCMC parameters</span></span>
<span id="cb5-14"><a href="sec11_1.html#cb5-14" tabindex="-1"></a>mcmc <span class="ot">&lt;-</span> <span class="dv">5000</span>; burnin <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb5-15"><a href="sec11_1.html#cb5-15" tabindex="-1"></a>tot <span class="ot">&lt;-</span> mcmc <span class="sc">+</span> burnin; thin <span class="ot">&lt;-</span> <span class="dv">2</span></span>
<span id="cb5-16"><a href="sec11_1.html#cb5-16" tabindex="-1"></a><span class="co"># Gibbs sampling functions</span></span>
<span id="cb5-17"><a href="sec11_1.html#cb5-17" tabindex="-1"></a>PostSig2 <span class="ot">&lt;-</span> <span class="cf">function</span>(Betah, Xh, yh){</span>
<span id="cb5-18"><a href="sec11_1.html#cb5-18" tabindex="-1"></a>    Nh <span class="ot">&lt;-</span> <span class="fu">length</span>(yh); an <span class="ot">&lt;-</span> a0 <span class="sc">+</span> Nh</span>
<span id="cb5-19"><a href="sec11_1.html#cb5-19" tabindex="-1"></a>    dn <span class="ot">&lt;-</span> d0 <span class="sc">+</span> <span class="fu">t</span>(yh <span class="sc">-</span> Xh<span class="sc">%*%</span>Betah)<span class="sc">%*%</span>(yh <span class="sc">-</span> Xh<span class="sc">%*%</span>Betah)</span>
<span id="cb5-20"><a href="sec11_1.html#cb5-20" tabindex="-1"></a>    sig2 <span class="ot">&lt;-</span> invgamma<span class="sc">::</span><span class="fu">rinvgamma</span>(<span class="dv">1</span>, <span class="at">shape =</span> an<span class="sc">/</span><span class="dv">2</span>, <span class="at">rate =</span> dn<span class="sc">/</span><span class="dv">2</span>)</span>
<span id="cb5-21"><a href="sec11_1.html#cb5-21" tabindex="-1"></a>    <span class="fu">return</span>(sig2)</span>
<span id="cb5-22"><a href="sec11_1.html#cb5-22" tabindex="-1"></a>}</span>
<span id="cb5-23"><a href="sec11_1.html#cb5-23" tabindex="-1"></a>PostBeta <span class="ot">&lt;-</span> <span class="cf">function</span>(sig2h, Xh, yh){</span>
<span id="cb5-24"><a href="sec11_1.html#cb5-24" tabindex="-1"></a>    Bn <span class="ot">&lt;-</span> <span class="fu">solve</span>(B0i <span class="sc">+</span> sig2h<span class="sc">^</span>(<span class="sc">-</span><span class="dv">1</span>)<span class="sc">*</span><span class="fu">t</span>(Xh)<span class="sc">%*%</span>Xh)</span>
<span id="cb5-25"><a href="sec11_1.html#cb5-25" tabindex="-1"></a>    bn <span class="ot">&lt;-</span> Bn<span class="sc">%*%</span>(B0i<span class="sc">%*%</span>b0 <span class="sc">+</span> sig2h<span class="sc">^</span>(<span class="sc">-</span><span class="dv">1</span>)<span class="sc">*</span><span class="fu">t</span>(Xh)<span class="sc">%*%</span>yh)</span>
<span id="cb5-26"><a href="sec11_1.html#cb5-26" tabindex="-1"></a>    Beta <span class="ot">&lt;-</span> MASS<span class="sc">::</span><span class="fu">mvrnorm</span>(<span class="dv">1</span>, bn, Bn)</span>
<span id="cb5-27"><a href="sec11_1.html#cb5-27" tabindex="-1"></a>    <span class="fu">return</span>(Beta)</span>
<span id="cb5-28"><a href="sec11_1.html#cb5-28" tabindex="-1"></a>}</span>
<span id="cb5-29"><a href="sec11_1.html#cb5-29" tabindex="-1"></a>PostBetas1 <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="dv">0</span>, mcmc<span class="sc">+</span>burnin, <span class="dv">2</span>)</span>
<span id="cb5-30"><a href="sec11_1.html#cb5-30" tabindex="-1"></a>PostBetas2 <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="dv">0</span>, mcmc<span class="sc">+</span>burnin, <span class="dv">2</span>)</span>
<span id="cb5-31"><a href="sec11_1.html#cb5-31" tabindex="-1"></a>PostSigma21 <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">0</span>, mcmc<span class="sc">+</span>burnin)</span>
<span id="cb5-32"><a href="sec11_1.html#cb5-32" tabindex="-1"></a>PostSigma22 <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">0</span>, mcmc<span class="sc">+</span>burnin)</span>
<span id="cb5-33"><a href="sec11_1.html#cb5-33" tabindex="-1"></a>PostPsi <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="dv">0</span>, mcmc<span class="sc">+</span>burnin, n)</span>
<span id="cb5-34"><a href="sec11_1.html#cb5-34" tabindex="-1"></a>PostLambda <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">0</span>, mcmc<span class="sc">+</span>burnin)</span>
<span id="cb5-35"><a href="sec11_1.html#cb5-35" tabindex="-1"></a>Id1 <span class="ot">&lt;-</span> <span class="fu">which</span>(y<span class="sc">&lt;</span><span class="dv">1</span>) <span class="co"># 1 is from inspection of the density plot of y </span></span>
<span id="cb5-36"><a href="sec11_1.html#cb5-36" tabindex="-1"></a>N1 <span class="ot">&lt;-</span> <span class="fu">length</span>(Id1); Lambda1 <span class="ot">&lt;-</span> N1<span class="sc">/</span>n</span>
<span id="cb5-37"><a href="sec11_1.html#cb5-37" tabindex="-1"></a>Id2 <span class="ot">&lt;-</span> <span class="fu">which</span>(y<span class="sc">&gt;=</span><span class="dv">1</span>)</span>
<span id="cb5-38"><a href="sec11_1.html#cb5-38" tabindex="-1"></a>N2 <span class="ot">&lt;-</span> <span class="fu">length</span>(Id2); Lambda2 <span class="ot">&lt;-</span> N2<span class="sc">/</span>n</span>
<span id="cb5-39"><a href="sec11_1.html#cb5-39" tabindex="-1"></a>Reg1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x, <span class="at">subset =</span> Id1)</span>
<span id="cb5-40"><a href="sec11_1.html#cb5-40" tabindex="-1"></a>SumReg1 <span class="ot">&lt;-</span> <span class="fu">summary</span>(Reg1); Beta1 <span class="ot">&lt;-</span> Reg1<span class="sc">$</span>coefficients</span>
<span id="cb5-41"><a href="sec11_1.html#cb5-41" tabindex="-1"></a>sig21 <span class="ot">&lt;-</span> SumReg1<span class="sc">$</span>sigma<span class="sc">^</span><span class="dv">2</span> </span>
<span id="cb5-42"><a href="sec11_1.html#cb5-42" tabindex="-1"></a>Reg2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x, <span class="at">subset =</span> Id2); SumReg2 <span class="ot">&lt;-</span> <span class="fu">summary</span>(Reg2)</span>
<span id="cb5-43"><a href="sec11_1.html#cb5-43" tabindex="-1"></a>Beta2 <span class="ot">&lt;-</span> Reg2<span class="sc">$</span>coefficients</span>
<span id="cb5-44"><a href="sec11_1.html#cb5-44" tabindex="-1"></a>sig22 <span class="ot">&lt;-</span> SumReg2<span class="sc">$</span>sigma<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb5-45"><a href="sec11_1.html#cb5-45" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="dv">1</span>, x); Psi <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="cn">NA</span>, n)</span>
<span id="cb5-46"><a href="sec11_1.html#cb5-46" tabindex="-1"></a>pb <span class="ot">&lt;-</span> <span class="fu">winProgressBar</span>(<span class="at">title =</span> <span class="st">&quot;progress bar&quot;</span>, <span class="at">min =</span> <span class="dv">0</span>, <span class="at">max =</span> tot, <span class="at">width =</span> <span class="dv">300</span>)</span>
<span id="cb5-47"><a href="sec11_1.html#cb5-47" tabindex="-1"></a><span class="cf">for</span>(s <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>tot){</span>
<span id="cb5-48"><a href="sec11_1.html#cb5-48" tabindex="-1"></a>    <span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n){</span>
<span id="cb5-49"><a href="sec11_1.html#cb5-49" tabindex="-1"></a>        lambdai1 <span class="ot">&lt;-</span> Lambda1<span class="sc">*</span><span class="fu">dnorm</span>(y[i], X[i,]<span class="sc">%*%</span>Beta1, sig21<span class="sc">^</span><span class="fl">0.5</span>)</span>
<span id="cb5-50"><a href="sec11_1.html#cb5-50" tabindex="-1"></a>        lambdai2 <span class="ot">&lt;-</span> Lambda2<span class="sc">*</span><span class="fu">dnorm</span>(y[i], X[i,]<span class="sc">%*%</span>Beta2, sig22<span class="sc">^</span><span class="fl">0.5</span>)</span>
<span id="cb5-51"><a href="sec11_1.html#cb5-51" tabindex="-1"></a>        Psi[i] <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>), <span class="dv">1</span>, <span class="at">prob =</span> <span class="fu">c</span>(lambdai1, lambdai2))</span>
<span id="cb5-52"><a href="sec11_1.html#cb5-52" tabindex="-1"></a>    }</span>
<span id="cb5-53"><a href="sec11_1.html#cb5-53" tabindex="-1"></a>    PostPsi[s, ] <span class="ot">&lt;-</span> Psi</span>
<span id="cb5-54"><a href="sec11_1.html#cb5-54" tabindex="-1"></a>    Id1 <span class="ot">&lt;-</span> <span class="fu">which</span>(Psi <span class="sc">==</span> <span class="dv">1</span>); Id2 <span class="ot">&lt;-</span> <span class="fu">which</span>(Psi <span class="sc">==</span> <span class="dv">2</span>)</span>
<span id="cb5-55"><a href="sec11_1.html#cb5-55" tabindex="-1"></a>    N1 <span class="ot">&lt;-</span> <span class="fu">length</span>(Id1); N2 <span class="ot">&lt;-</span> <span class="fu">length</span>(Id2)</span>
<span id="cb5-56"><a href="sec11_1.html#cb5-56" tabindex="-1"></a>    sig21 <span class="ot">&lt;-</span> <span class="fu">PostSig2</span>(<span class="at">Betah =</span> Beta1, <span class="at">Xh =</span> X[Id1, ], <span class="at">yh =</span> y[Id1])</span>
<span id="cb5-57"><a href="sec11_1.html#cb5-57" tabindex="-1"></a>    sig22 <span class="ot">&lt;-</span> <span class="fu">PostSig2</span>(<span class="at">Betah =</span> Beta2, <span class="at">Xh =</span> X[Id2, ], <span class="at">yh =</span> y[Id2])</span>
<span id="cb5-58"><a href="sec11_1.html#cb5-58" tabindex="-1"></a>    PostSigma21[s] <span class="ot">&lt;-</span> sig21; PostSigma22[s] <span class="ot">&lt;-</span> sig22</span>
<span id="cb5-59"><a href="sec11_1.html#cb5-59" tabindex="-1"></a>    Beta1 <span class="ot">&lt;-</span> <span class="fu">PostBeta</span>(<span class="at">sig2h =</span> sig21, <span class="at">Xh =</span> X[Id1, ], <span class="at">yh =</span> y[Id1])</span>
<span id="cb5-60"><a href="sec11_1.html#cb5-60" tabindex="-1"></a>    Beta2 <span class="ot">&lt;-</span> <span class="fu">PostBeta</span>(<span class="at">sig2h =</span> sig22, <span class="at">Xh =</span> X[Id2, ], <span class="at">yh =</span> y[Id2])</span>
<span id="cb5-61"><a href="sec11_1.html#cb5-61" tabindex="-1"></a>    PostBetas1[s,] <span class="ot">&lt;-</span> Beta1; PostBetas2[s,] <span class="ot">&lt;-</span> Beta2</span>
<span id="cb5-62"><a href="sec11_1.html#cb5-62" tabindex="-1"></a>    Lambda <span class="ot">&lt;-</span> <span class="fu">sort</span>(MCMCpack<span class="sc">::</span><span class="fu">rdirichlet</span>(<span class="dv">1</span>, <span class="fu">c</span>(a01 <span class="sc">+</span> N1, a02 <span class="sc">+</span> N2)), <span class="at">decreasing =</span> <span class="cn">TRUE</span>)</span>
<span id="cb5-63"><a href="sec11_1.html#cb5-63" tabindex="-1"></a>    Lambda1 <span class="ot">&lt;-</span> Lambda[<span class="dv">1</span>]; Lambda2 <span class="ot">&lt;-</span> Lambda[<span class="dv">2</span>]</span>
<span id="cb5-64"><a href="sec11_1.html#cb5-64" tabindex="-1"></a>    PostLambda[s] <span class="ot">&lt;-</span> Lambda1 </span>
<span id="cb5-65"><a href="sec11_1.html#cb5-65" tabindex="-1"></a>  <span class="fu">setWinProgressBar</span>(pb, s, <span class="at">title=</span><span class="fu">paste</span>( <span class="fu">round</span>(s<span class="sc">/</span>tot<span class="sc">*</span><span class="dv">100</span>, <span class="dv">0</span>),<span class="st">&quot;% done&quot;</span>))</span>
<span id="cb5-66"><a href="sec11_1.html#cb5-66" tabindex="-1"></a>}</span>
<span id="cb5-67"><a href="sec11_1.html#cb5-67" tabindex="-1"></a><span class="fu">close</span>(pb)</span>
<span id="cb5-68"><a href="sec11_1.html#cb5-68" tabindex="-1"></a>keep <span class="ot">&lt;-</span> <span class="fu">seq</span>((burnin<span class="sc">+</span><span class="dv">1</span>), tot, thin)</span>
<span id="cb5-69"><a href="sec11_1.html#cb5-69" tabindex="-1"></a>PosteriorBetas1 <span class="ot">&lt;-</span> coda<span class="sc">::</span><span class="fu">mcmc</span>(PostBetas1[keep,])</span>
<span id="cb5-70"><a href="sec11_1.html#cb5-70" tabindex="-1"></a><span class="fu">summary</span>(PosteriorBetas1)</span>
<span id="cb5-71"><a href="sec11_1.html#cb5-71" tabindex="-1"></a><span class="fu">plot</span>(PosteriorBetas1)</span>
<span id="cb5-72"><a href="sec11_1.html#cb5-72" tabindex="-1"></a>PosteriorBetas2 <span class="ot">&lt;-</span> coda<span class="sc">::</span><span class="fu">mcmc</span>(PostBetas2[keep,])</span>
<span id="cb5-73"><a href="sec11_1.html#cb5-73" tabindex="-1"></a><span class="fu">summary</span>(PosteriorBetas2)</span>
<span id="cb5-74"><a href="sec11_1.html#cb5-74" tabindex="-1"></a><span class="fu">plot</span>(PosteriorBetas2)</span>
<span id="cb5-75"><a href="sec11_1.html#cb5-75" tabindex="-1"></a>PosteriorSigma21 <span class="ot">&lt;-</span> coda<span class="sc">::</span><span class="fu">mcmc</span>(PostSigma21[keep])</span>
<span id="cb5-76"><a href="sec11_1.html#cb5-76" tabindex="-1"></a><span class="fu">summary</span>(PosteriorSigma21)</span>
<span id="cb5-77"><a href="sec11_1.html#cb5-77" tabindex="-1"></a><span class="fu">plot</span>(PosteriorSigma21)</span>
<span id="cb5-78"><a href="sec11_1.html#cb5-78" tabindex="-1"></a>PosteriorSigma22 <span class="ot">&lt;-</span> coda<span class="sc">::</span><span class="fu">mcmc</span>(PostSigma22[keep])</span>
<span id="cb5-79"><a href="sec11_1.html#cb5-79" tabindex="-1"></a><span class="fu">summary</span>(PosteriorSigma22)</span>
<span id="cb5-80"><a href="sec11_1.html#cb5-80" tabindex="-1"></a><span class="fu">plot</span>(PosteriorSigma22)</span></code></pre></div>
<p>Let’s perform another simulation exercise in which we conduct a semi-parametric analysis where the stochastic error follows a Student’s t-distribution with 3 degrees of freedom. Specifically,<br />
<span class="math display">\[\begin{align*}
    y_i &amp;= 1 - 0.5x_{i1} + 1.5x_{i2} + \mu_i, \ i=1,2,\dots,500.
\end{align*}\]</span>
The variables <span class="math inline">\(x_{i1}\)</span> and <span class="math inline">\(x_{i2}\)</span> are standard normally distributed. Let’s set <span class="math inline">\(H=5\)</span>, and use non-informative priors setting <span class="math inline">\(\alpha_{h0}=\delta_{h0}=0.01\)</span>, <span class="math inline">\(\boldsymbol{\beta}_0=\boldsymbol{0}_2\)</span>, <span class="math inline">\(\boldsymbol{B}_0=\boldsymbol{I}_2\)</span>, <span class="math inline">\(\mu_{h0}=0\)</span>, <span class="math inline">\(\sigma^2_{\mu 0}=10\)</span> and <span class="math inline">\(\boldsymbol{\alpha}_0=[1/H \ \dots \ 1/H]^{\top}\)</span>. Use 6,000 MCMC iterations, burn-in equal to 4,000, and thinning parameter equal to 2. In this exercise, there is no need to address the label-switching issue, as we are not specifically interested in the individual components of the posterior distributions of the clusters. Exercise 1 asks how to get the posterior density of the stochastic errors in semi-parametric specifications.</p>
<p>We can see from the posterior estimates that three components disappear after the burn-in iterations. The 95% credible intervals encompass the population values of the slope parameters. The 95% credible intervals for the probabilities are (0.70, 0.89) and (0.11, 0.30), and the 95% credible interval for the weighted average of the intercepts encompasses the population parameter.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="sec11_1.html#cb6-1" tabindex="-1"></a><span class="fu">rm</span>(<span class="at">list =</span> <span class="fu">ls</span>()); <span class="fu">set.seed</span>(<span class="dv">010101</span>)</span>
<span id="cb6-2"><a href="sec11_1.html#cb6-2" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb6-3"><a href="sec11_1.html#cb6-3" tabindex="-1"></a><span class="co"># Simulate data from a 2-component mixture model</span></span>
<span id="cb6-4"><a href="sec11_1.html#cb6-4" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">500</span></span>
<span id="cb6-5"><a href="sec11_1.html#cb6-5" tabindex="-1"></a>x1 <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n); x2 <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n)</span>
<span id="cb6-6"><a href="sec11_1.html#cb6-6" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">cbind</span>(x1,x2); B <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="sc">-</span><span class="fl">0.5</span>, <span class="fl">1.5</span>)</span>
<span id="cb6-7"><a href="sec11_1.html#cb6-7" tabindex="-1"></a>u <span class="ot">&lt;-</span> <span class="fu">rt</span>(n, <span class="dv">3</span>); y <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">+</span> X<span class="sc">%*%</span>B <span class="sc">+</span> u</span>
<span id="cb6-8"><a href="sec11_1.html#cb6-8" tabindex="-1"></a>Reg <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> X)</span>
<span id="cb6-9"><a href="sec11_1.html#cb6-9" tabindex="-1"></a>Res <span class="ot">&lt;-</span> Reg<span class="sc">$</span>residuals</span>
<span id="cb6-10"><a href="sec11_1.html#cb6-10" tabindex="-1"></a>data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(Res)</span>
<span id="cb6-11"><a href="sec11_1.html#cb6-11" tabindex="-1"></a><span class="co"># Plot</span></span>
<span id="cb6-12"><a href="sec11_1.html#cb6-12" tabindex="-1"></a><span class="fu">ggplot</span>(data, <span class="fu">aes</span>(<span class="at">x =</span> Res)) <span class="sc">+</span></span>
<span id="cb6-13"><a href="sec11_1.html#cb6-13" tabindex="-1"></a><span class="fu">geom_density</span>(<span class="at">fill =</span> <span class="st">&quot;blue&quot;</span>, <span class="at">alpha =</span> <span class="fl">0.3</span>) <span class="sc">+</span>  <span class="co"># Density plot with fill color</span></span>
<span id="cb6-14"><a href="sec11_1.html#cb6-14" tabindex="-1"></a><span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Density Plot&quot;</span>, <span class="at">x =</span> <span class="st">&quot;Residuals&quot;</span>, <span class="at">y =</span> <span class="st">&quot;Density&quot;</span>) <span class="sc">+</span></span>
<span id="cb6-15"><a href="sec11_1.html#cb6-15" tabindex="-1"></a><span class="fu">theme_minimal</span>()</span>
<span id="cb6-16"><a href="sec11_1.html#cb6-16" tabindex="-1"></a><span class="co"># Hyperparameters</span></span>
<span id="cb6-17"><a href="sec11_1.html#cb6-17" tabindex="-1"></a>d0 <span class="ot">&lt;-</span> <span class="fl">0.001</span>; a0 <span class="ot">&lt;-</span> <span class="fl">0.001</span>; b0 <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">0</span>, <span class="dv">2</span>)</span>
<span id="cb6-18"><a href="sec11_1.html#cb6-18" tabindex="-1"></a>B0 <span class="ot">&lt;-</span> <span class="fu">diag</span>(<span class="dv">2</span>); B0i <span class="ot">&lt;-</span> <span class="fu">solve</span>(B0)</span>
<span id="cb6-19"><a href="sec11_1.html#cb6-19" tabindex="-1"></a>mu0 <span class="ot">&lt;-</span> <span class="dv">0</span>; sig2mu0 <span class="ot">&lt;-</span> <span class="dv">10</span>; H <span class="ot">&lt;-</span> <span class="dv">5</span>; a0h <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">1</span><span class="sc">/</span>H, H)</span>
<span id="cb6-20"><a href="sec11_1.html#cb6-20" tabindex="-1"></a><span class="co"># MCMC parameters</span></span>
<span id="cb6-21"><a href="sec11_1.html#cb6-21" tabindex="-1"></a>mcmc <span class="ot">&lt;-</span> <span class="dv">2000</span>; burnin <span class="ot">&lt;-</span> <span class="dv">4000</span></span>
<span id="cb6-22"><a href="sec11_1.html#cb6-22" tabindex="-1"></a>tot <span class="ot">&lt;-</span> mcmc <span class="sc">+</span> burnin; thin <span class="ot">&lt;-</span> <span class="dv">2</span></span>
<span id="cb6-23"><a href="sec11_1.html#cb6-23" tabindex="-1"></a><span class="co"># Gibbs sampling functions</span></span>
<span id="cb6-24"><a href="sec11_1.html#cb6-24" tabindex="-1"></a>PostSig2 <span class="ot">&lt;-</span> <span class="cf">function</span>(Beta, muh, Xh, yh){</span>
<span id="cb6-25"><a href="sec11_1.html#cb6-25" tabindex="-1"></a>    Nh <span class="ot">&lt;-</span> <span class="fu">length</span>(yh); an <span class="ot">&lt;-</span> a0 <span class="sc">+</span> Nh</span>
<span id="cb6-26"><a href="sec11_1.html#cb6-26" tabindex="-1"></a>    dn <span class="ot">&lt;-</span> d0 <span class="sc">+</span> <span class="fu">t</span>(yh <span class="sc">-</span> muh <span class="sc">-</span> Xh<span class="sc">%*%</span>Beta)<span class="sc">%*%</span>(yh <span class="sc">-</span> muh <span class="sc">-</span> Xh<span class="sc">%*%</span>Beta)</span>
<span id="cb6-27"><a href="sec11_1.html#cb6-27" tabindex="-1"></a>    sig2 <span class="ot">&lt;-</span> invgamma<span class="sc">::</span><span class="fu">rinvgamma</span>(<span class="dv">1</span>, <span class="at">shape =</span> an<span class="sc">/</span><span class="dv">2</span>, <span class="at">rate =</span> dn<span class="sc">/</span><span class="dv">2</span>)</span>
<span id="cb6-28"><a href="sec11_1.html#cb6-28" tabindex="-1"></a>    <span class="fu">return</span>(sig2)</span>
<span id="cb6-29"><a href="sec11_1.html#cb6-29" tabindex="-1"></a>}</span>
<span id="cb6-30"><a href="sec11_1.html#cb6-30" tabindex="-1"></a>PostBeta <span class="ot">&lt;-</span> <span class="cf">function</span>(sig2, mu, X, y, Psi){</span>
<span id="cb6-31"><a href="sec11_1.html#cb6-31" tabindex="-1"></a>    XtX <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">2</span>); Xty <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb6-32"><a href="sec11_1.html#cb6-32" tabindex="-1"></a>    Hs <span class="ot">&lt;-</span> <span class="fu">length</span>(mu)</span>
<span id="cb6-33"><a href="sec11_1.html#cb6-33" tabindex="-1"></a>    <span class="cf">for</span>(h <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>Hs){</span>
<span id="cb6-34"><a href="sec11_1.html#cb6-34" tabindex="-1"></a>        idh <span class="ot">&lt;-</span> <span class="fu">which</span>(Psi <span class="sc">==</span> h)</span>
<span id="cb6-35"><a href="sec11_1.html#cb6-35" tabindex="-1"></a>        <span class="cf">if</span>(<span class="fu">length</span>(idh) <span class="sc">==</span> <span class="dv">1</span>){</span>
<span id="cb6-36"><a href="sec11_1.html#cb6-36" tabindex="-1"></a>            Xh <span class="ot">&lt;-</span> <span class="fu">matrix</span>(X[idh,], <span class="dv">1</span>, <span class="dv">2</span>)</span>
<span id="cb6-37"><a href="sec11_1.html#cb6-37" tabindex="-1"></a>            XtXh <span class="ot">&lt;-</span> sig2[h]<span class="sc">^</span>(<span class="sc">-</span><span class="dv">1</span>)<span class="sc">*</span><span class="fu">t</span>(Xh)<span class="sc">%*%</span>Xh</span>
<span id="cb6-38"><a href="sec11_1.html#cb6-38" tabindex="-1"></a>            yh <span class="ot">&lt;-</span> y[idh]</span>
<span id="cb6-39"><a href="sec11_1.html#cb6-39" tabindex="-1"></a>            Xtyh <span class="ot">&lt;-</span> sig2[h]<span class="sc">^</span>(<span class="sc">-</span><span class="dv">1</span>)<span class="sc">*</span><span class="fu">t</span>(Xh)<span class="sc">%*%</span>(yh <span class="sc">-</span> mu[h])</span>
<span id="cb6-40"><a href="sec11_1.html#cb6-40" tabindex="-1"></a>        }<span class="cf">else</span>{</span>
<span id="cb6-41"><a href="sec11_1.html#cb6-41" tabindex="-1"></a>            Xh <span class="ot">&lt;-</span> X[idh,]</span>
<span id="cb6-42"><a href="sec11_1.html#cb6-42" tabindex="-1"></a>            XtXh <span class="ot">&lt;-</span> sig2[h]<span class="sc">^</span>(<span class="sc">-</span><span class="dv">1</span>)<span class="sc">*</span><span class="fu">t</span>(Xh)<span class="sc">%*%</span>Xh</span>
<span id="cb6-43"><a href="sec11_1.html#cb6-43" tabindex="-1"></a>            yh <span class="ot">&lt;-</span> y[idh]</span>
<span id="cb6-44"><a href="sec11_1.html#cb6-44" tabindex="-1"></a>            Xtyh <span class="ot">&lt;-</span> sig2[h]<span class="sc">^</span>(<span class="sc">-</span><span class="dv">1</span>)<span class="sc">*</span><span class="fu">t</span>(Xh)<span class="sc">%*%</span>(yh <span class="sc">-</span> mu[h])</span>
<span id="cb6-45"><a href="sec11_1.html#cb6-45" tabindex="-1"></a>        }</span>
<span id="cb6-46"><a href="sec11_1.html#cb6-46" tabindex="-1"></a>        XtX <span class="ot">&lt;-</span> XtX <span class="sc">+</span> XtXh; Xty <span class="ot">&lt;-</span> Xty <span class="sc">+</span> Xtyh</span>
<span id="cb6-47"><a href="sec11_1.html#cb6-47" tabindex="-1"></a>    }</span>
<span id="cb6-48"><a href="sec11_1.html#cb6-48" tabindex="-1"></a>    Bn <span class="ot">&lt;-</span> <span class="fu">solve</span>(B0i <span class="sc">+</span> XtX); bn <span class="ot">&lt;-</span> Bn<span class="sc">%*%</span>(B0i<span class="sc">%*%</span>b0 <span class="sc">+</span> Xty)</span>
<span id="cb6-49"><a href="sec11_1.html#cb6-49" tabindex="-1"></a>    Beta <span class="ot">&lt;-</span> MASS<span class="sc">::</span><span class="fu">mvrnorm</span>(<span class="dv">1</span>, bn, Bn)</span>
<span id="cb6-50"><a href="sec11_1.html#cb6-50" tabindex="-1"></a>    <span class="fu">return</span>(Beta)</span>
<span id="cb6-51"><a href="sec11_1.html#cb6-51" tabindex="-1"></a>}</span>
<span id="cb6-52"><a href="sec11_1.html#cb6-52" tabindex="-1"></a>Postmu <span class="ot">&lt;-</span> <span class="cf">function</span>(sig2h, Beta, Xh, yh){</span>
<span id="cb6-53"><a href="sec11_1.html#cb6-53" tabindex="-1"></a>    Nh <span class="ot">&lt;-</span> <span class="fu">length</span>(yh)</span>
<span id="cb6-54"><a href="sec11_1.html#cb6-54" tabindex="-1"></a>    sig2mu <span class="ot">&lt;-</span> (<span class="dv">1</span><span class="sc">/</span>sig2mu0 <span class="sc">+</span> Nh<span class="sc">/</span>sig2h)<span class="sc">^</span>(<span class="sc">-</span><span class="dv">1</span>)</span>
<span id="cb6-55"><a href="sec11_1.html#cb6-55" tabindex="-1"></a>    mun <span class="ot">&lt;-</span> sig2mu<span class="sc">*</span>(mu0<span class="sc">/</span>sig2mu0 <span class="sc">+</span> <span class="fu">sum</span>((yh <span class="sc">-</span> Xh<span class="sc">%*%</span>Beta))<span class="sc">/</span>sig2h)</span>
<span id="cb6-56"><a href="sec11_1.html#cb6-56" tabindex="-1"></a>    mu <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">1</span>, mun, sig2mu<span class="sc">^</span><span class="fl">0.5</span>)</span>
<span id="cb6-57"><a href="sec11_1.html#cb6-57" tabindex="-1"></a>    <span class="fu">return</span>(mu)</span>
<span id="cb6-58"><a href="sec11_1.html#cb6-58" tabindex="-1"></a>}</span>
<span id="cb6-59"><a href="sec11_1.html#cb6-59" tabindex="-1"></a>PostBetas <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="dv">0</span>, mcmc<span class="sc">+</span>burnin, <span class="dv">2</span>)</span>
<span id="cb6-60"><a href="sec11_1.html#cb6-60" tabindex="-1"></a>PostPsi <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="dv">0</span>, mcmc<span class="sc">+</span>burnin, n)</span>
<span id="cb6-61"><a href="sec11_1.html#cb6-61" tabindex="-1"></a>PostSigma2 <span class="ot">&lt;-</span> <span class="fu">list</span>(); PostMu <span class="ot">&lt;-</span> <span class="fu">list</span>()</span>
<span id="cb6-62"><a href="sec11_1.html#cb6-62" tabindex="-1"></a>PostLambda <span class="ot">&lt;-</span> <span class="fu">list</span>()</span>
<span id="cb6-63"><a href="sec11_1.html#cb6-63" tabindex="-1"></a>Resq <span class="ot">&lt;-</span> <span class="fu">quantile</span>(Res, <span class="fu">c</span>(<span class="fl">0.2</span>, <span class="fl">0.4</span>, <span class="fl">0.6</span>, <span class="fl">0.8</span>))</span>
<span id="cb6-64"><a href="sec11_1.html#cb6-64" tabindex="-1"></a>Id1 <span class="ot">&lt;-</span> <span class="fu">which</span>(Res <span class="sc">&lt;=</span> Resq[<span class="dv">1</span>])</span>
<span id="cb6-65"><a href="sec11_1.html#cb6-65" tabindex="-1"></a>Id2 <span class="ot">&lt;-</span> <span class="fu">which</span>(Res <span class="sc">&gt;</span> Resq[<span class="dv">1</span>] <span class="sc">&amp;</span> Res <span class="sc">&lt;=</span> Resq[<span class="dv">2</span>])</span>
<span id="cb6-66"><a href="sec11_1.html#cb6-66" tabindex="-1"></a>Id3 <span class="ot">&lt;-</span> <span class="fu">which</span>(Res <span class="sc">&gt;</span> Resq[<span class="dv">2</span>] <span class="sc">&amp;</span> Res <span class="sc">&lt;=</span> Resq[<span class="dv">3</span>])</span>
<span id="cb6-67"><a href="sec11_1.html#cb6-67" tabindex="-1"></a>Id4 <span class="ot">&lt;-</span> <span class="fu">which</span>(Res <span class="sc">&gt;</span> Resq[<span class="dv">3</span>] <span class="sc">&amp;</span> Res <span class="sc">&lt;=</span> Resq[<span class="dv">4</span>])</span>
<span id="cb6-68"><a href="sec11_1.html#cb6-68" tabindex="-1"></a>Id5 <span class="ot">&lt;-</span> <span class="fu">which</span>(Res <span class="sc">&gt;</span> Resq[<span class="dv">4</span>])</span>
<span id="cb6-69"><a href="sec11_1.html#cb6-69" tabindex="-1"></a>Nh <span class="ot">&lt;-</span> <span class="fu">rep</span>(n<span class="sc">/</span>H, H); Lambda <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">1</span><span class="sc">/</span>H, H)</span>
<span id="cb6-70"><a href="sec11_1.html#cb6-70" tabindex="-1"></a>MU <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">mean</span>(Res[Id1]), <span class="fu">mean</span>(Res[Id2]), <span class="fu">mean</span>(Res[Id3]), <span class="fu">mean</span>(Res[Id4]), <span class="fu">mean</span>(Res[Id5]))</span>
<span id="cb6-71"><a href="sec11_1.html#cb6-71" tabindex="-1"></a>Sig2 <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">var</span>(Res[Id1]), <span class="fu">var</span>(Res[Id2]), <span class="fu">var</span>(Res[Id3]), <span class="fu">var</span>(Res[Id4]), <span class="fu">var</span>(Res[Id5]))</span>
<span id="cb6-72"><a href="sec11_1.html#cb6-72" tabindex="-1"></a>Beta <span class="ot">&lt;-</span> Reg<span class="sc">$</span>coefficients[<span class="dv">2</span><span class="sc">:</span><span class="dv">3</span>]</span>
<span id="cb6-73"><a href="sec11_1.html#cb6-73" tabindex="-1"></a>Psi <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="cn">NA</span>, n); Hs <span class="ot">&lt;-</span> <span class="fu">length</span>(MU)</span>
<span id="cb6-74"><a href="sec11_1.html#cb6-74" tabindex="-1"></a>pb <span class="ot">&lt;-</span> <span class="fu">winProgressBar</span>(<span class="at">title =</span> <span class="st">&quot;progress bar&quot;</span>, <span class="at">min =</span> <span class="dv">0</span>, <span class="at">max =</span> tot, <span class="at">width =</span> <span class="dv">300</span>)</span>
<span id="cb6-75"><a href="sec11_1.html#cb6-75" tabindex="-1"></a><span class="cf">for</span>(s <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>tot){</span>
<span id="cb6-76"><a href="sec11_1.html#cb6-76" tabindex="-1"></a>    <span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n){</span>
<span id="cb6-77"><a href="sec11_1.html#cb6-77" tabindex="-1"></a>        lambdai <span class="ot">&lt;-</span> <span class="cn">NULL</span></span>
<span id="cb6-78"><a href="sec11_1.html#cb6-78" tabindex="-1"></a>        <span class="cf">for</span>(h <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>Hs){</span>
<span id="cb6-79"><a href="sec11_1.html#cb6-79" tabindex="-1"></a>            lambdaih <span class="ot">&lt;-</span> Lambda[h]<span class="sc">*</span><span class="fu">dnorm</span>(y[i] <span class="sc">-</span> X[i,]<span class="sc">%*%</span>Beta, MU[h], Sig2[h]<span class="sc">^</span><span class="fl">0.5</span>)</span>
<span id="cb6-80"><a href="sec11_1.html#cb6-80" tabindex="-1"></a>            lambdai <span class="ot">&lt;-</span> <span class="fu">c</span>(lambdai, lambdaih)</span>
<span id="cb6-81"><a href="sec11_1.html#cb6-81" tabindex="-1"></a>        }</span>
<span id="cb6-82"><a href="sec11_1.html#cb6-82" tabindex="-1"></a>        Psi[i] <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span>Hs, <span class="dv">1</span>, <span class="at">prob =</span> lambdai)</span>
<span id="cb6-83"><a href="sec11_1.html#cb6-83" tabindex="-1"></a>    }</span>
<span id="cb6-84"><a href="sec11_1.html#cb6-84" tabindex="-1"></a>    PostPsi[s, ] <span class="ot">&lt;-</span> Psi</span>
<span id="cb6-85"><a href="sec11_1.html#cb6-85" tabindex="-1"></a>    Hs <span class="ot">&lt;-</span> <span class="fu">length</span>(<span class="fu">table</span>(Psi))</span>
<span id="cb6-86"><a href="sec11_1.html#cb6-86" tabindex="-1"></a>    <span class="cf">for</span>(h <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>Hs){</span>
<span id="cb6-87"><a href="sec11_1.html#cb6-87" tabindex="-1"></a>        idh <span class="ot">&lt;-</span> <span class="fu">which</span>(Psi <span class="sc">==</span> h)</span>
<span id="cb6-88"><a href="sec11_1.html#cb6-88" tabindex="-1"></a>        Sig2[h] <span class="ot">&lt;-</span> <span class="fu">PostSig2</span>(<span class="at">Beta =</span> Beta, <span class="at">muh =</span> MU[h], <span class="at">Xh =</span> X[idh,], <span class="at">yh =</span> y[idh])</span>
<span id="cb6-89"><a href="sec11_1.html#cb6-89" tabindex="-1"></a>        MU[h] <span class="ot">&lt;-</span> <span class="fu">Postmu</span>(<span class="at">sig2h =</span> Sig2[h], <span class="at">Beta =</span> Beta, <span class="at">Xh =</span> X[idh,], <span class="at">yh =</span> y[idh])</span>
<span id="cb6-90"><a href="sec11_1.html#cb6-90" tabindex="-1"></a>    }</span>
<span id="cb6-91"><a href="sec11_1.html#cb6-91" tabindex="-1"></a>    PostSigma2[[s]] <span class="ot">&lt;-</span> Sig2</span>
<span id="cb6-92"><a href="sec11_1.html#cb6-92" tabindex="-1"></a>    PostMu[[s]] <span class="ot">&lt;-</span> MU </span>
<span id="cb6-93"><a href="sec11_1.html#cb6-93" tabindex="-1"></a>    Beta <span class="ot">&lt;-</span> <span class="fu">PostBeta</span>(<span class="at">sig2 =</span> Sig2, <span class="at">mu =</span> MU, <span class="at">X =</span> X, <span class="at">y =</span> y, <span class="at">Psi =</span> Psi)</span>
<span id="cb6-94"><a href="sec11_1.html#cb6-94" tabindex="-1"></a>    PostBetas[s,] <span class="ot">&lt;-</span> Beta</span>
<span id="cb6-95"><a href="sec11_1.html#cb6-95" tabindex="-1"></a>    Lambda <span class="ot">&lt;-</span> <span class="fu">sort</span>(MCMCpack<span class="sc">::</span><span class="fu">rdirichlet</span>(<span class="dv">1</span>, a0h[<span class="dv">1</span><span class="sc">:</span>Hs] <span class="sc">+</span> <span class="fu">table</span>(Psi)), <span class="at">decreasing =</span> <span class="cn">TRUE</span>)</span>
<span id="cb6-96"><a href="sec11_1.html#cb6-96" tabindex="-1"></a>    PostLambda[[s]] <span class="ot">&lt;-</span> Lambda</span>
<span id="cb6-97"><a href="sec11_1.html#cb6-97" tabindex="-1"></a>    <span class="fu">setWinProgressBar</span>(pb, s, <span class="at">title=</span><span class="fu">paste</span>( <span class="fu">round</span>(s<span class="sc">/</span>tot<span class="sc">*</span><span class="dv">100</span>, <span class="dv">0</span>),<span class="st">&quot;% done&quot;</span>))</span>
<span id="cb6-98"><a href="sec11_1.html#cb6-98" tabindex="-1"></a>}</span>
<span id="cb6-99"><a href="sec11_1.html#cb6-99" tabindex="-1"></a><span class="fu">close</span>(pb)</span>
<span id="cb6-100"><a href="sec11_1.html#cb6-100" tabindex="-1"></a>keep <span class="ot">&lt;-</span> <span class="fu">seq</span>(burnin, tot, thin)</span>
<span id="cb6-101"><a href="sec11_1.html#cb6-101" tabindex="-1"></a>PosteriorBetas <span class="ot">&lt;-</span> coda<span class="sc">::</span><span class="fu">mcmc</span>(PostBetas[keep,])</span>
<span id="cb6-102"><a href="sec11_1.html#cb6-102" tabindex="-1"></a><span class="fu">summary</span>(PosteriorBetas)</span>
<span id="cb6-103"><a href="sec11_1.html#cb6-103" tabindex="-1"></a><span class="fu">plot</span>(PosteriorBetas)</span>
<span id="cb6-104"><a href="sec11_1.html#cb6-104" tabindex="-1"></a>PosteriorPsi <span class="ot">&lt;-</span> PostPsi[keep,]</span>
<span id="cb6-105"><a href="sec11_1.html#cb6-105" tabindex="-1"></a>Clusters <span class="ot">&lt;-</span> <span class="fu">sapply</span>(<span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(keep), <span class="cf">function</span>(i){<span class="fu">length</span>(<span class="fu">table</span>(PosteriorPsi[i,]))})</span>
<span id="cb6-106"><a href="sec11_1.html#cb6-106" tabindex="-1"></a>NClus <span class="ot">&lt;-</span> <span class="dv">2</span></span>
<span id="cb6-107"><a href="sec11_1.html#cb6-107" tabindex="-1"></a>PosteriorSIGMA <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="cn">NA</span>, <span class="fu">length</span>(keep), NClus)</span>
<span id="cb6-108"><a href="sec11_1.html#cb6-108" tabindex="-1"></a>PosteriorMU <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="cn">NA</span>, <span class="fu">length</span>(keep), NClus)</span>
<span id="cb6-109"><a href="sec11_1.html#cb6-109" tabindex="-1"></a>PosteriorLAMBDA <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="cn">NA</span>, <span class="fu">length</span>(keep), NClus)</span>
<span id="cb6-110"><a href="sec11_1.html#cb6-110" tabindex="-1"></a>l <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb6-111"><a href="sec11_1.html#cb6-111" tabindex="-1"></a><span class="cf">for</span> (s <span class="cf">in</span> keep){</span>
<span id="cb6-112"><a href="sec11_1.html#cb6-112" tabindex="-1"></a>    PosteriorSIGMA[l,] <span class="ot">&lt;-</span> PostSigma2[[s]][<span class="dv">1</span><span class="sc">:</span>NClus]</span>
<span id="cb6-113"><a href="sec11_1.html#cb6-113" tabindex="-1"></a>    PosteriorMU[l,] <span class="ot">&lt;-</span> PostMu[[s]][<span class="dv">1</span><span class="sc">:</span>NClus]</span>
<span id="cb6-114"><a href="sec11_1.html#cb6-114" tabindex="-1"></a>    PosteriorLAMBDA[l,] <span class="ot">&lt;-</span> PostLambda[[s]][<span class="dv">1</span><span class="sc">:</span>NClus]</span>
<span id="cb6-115"><a href="sec11_1.html#cb6-115" tabindex="-1"></a>    l <span class="ot">&lt;-</span> l <span class="sc">+</span> <span class="dv">1</span></span>
<span id="cb6-116"><a href="sec11_1.html#cb6-116" tabindex="-1"></a>}</span>
<span id="cb6-117"><a href="sec11_1.html#cb6-117" tabindex="-1"></a></span>
<span id="cb6-118"><a href="sec11_1.html#cb6-118" tabindex="-1"></a><span class="fu">summary</span>(coda<span class="sc">::</span><span class="fu">mcmc</span>(PosteriorSIGMA))</span>
<span id="cb6-119"><a href="sec11_1.html#cb6-119" tabindex="-1"></a><span class="fu">summary</span>(coda<span class="sc">::</span><span class="fu">mcmc</span>(PosteriorMU))</span>
<span id="cb6-120"><a href="sec11_1.html#cb6-120" tabindex="-1"></a><span class="fu">summary</span>(coda<span class="sc">::</span><span class="fu">mcmc</span>(PosteriorLAMBDA))</span></code></pre></div>
</div>
<div id="sec11_12" class="section level3 hasAnchor" number="11.1.2">
<h3><span class="header-section-number">11.1.2</span> Direchlet processes<a href="sec11_1.html#sec11_12" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A Dirichlet process (DP) is a probability distribution over probability distributions, and a generalization of the Dirichlet distribution. It was introduced by <span class="citation">(<a href="#ref-Ferguson1973">Ferguson 1973</a>)</span>, and it is commonly used as a prior for unknown distributions, making it particularly useful in non-parametric settings. Unlike finite Gaussian mixture models, a Dirichlet process does not require pre-specifying the number of components, allowing for greater flexibility in modeling complex data structures. In this sense, DPs can be viewed as the limiting case of finite mixtures when the number of components approaches infinity.</p>
<p>A Dirichlet process <span class="math inline">\(G\sim DP(\alpha G_0)\)</span> is defined by a precision parameter <span class="math inline">\(\alpha&gt;0\)</span>, and a base probability measure <span class="math inline">\(G_0\)</span> on a probability space <span class="math inline">\(\Omega\)</span>.<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a> The DP assigns probability <span class="math inline">\(G(B)\)</span> to any (measurable) set <span class="math inline">\(B\)</span> in <span class="math inline">\(\Omega\)</span> such that for any finite (measurable) partition <span class="math inline">\(\left\{B_1, B_2, \dots, B_k\right\}\)</span> of <span class="math inline">\(\Omega\)</span>,</p>
<p><span class="math display">\[
G(B_1), G(B_2), \dots, G(B_k) \sim \text{Dirichlet}(\alpha G_0(B_1), \alpha G_0(B_2), \dots, \alpha G_0(B_k)).
\]</span></p>
<p>In particular, <span class="math inline">\(\mathbb{E}\left[G(B)\right]=G_0(B)\)</span> and <span class="math inline">\(\mathbb{V}ar\left[G(B)\right]=G_0(B)\left[1-G_0(B)\right]/(1+\alpha)\)</span> <span class="citation">(<a href="#ref-Muller2015">Müller et al. 2015</a>)</span>. Observe that as <span class="math inline">\(\alpha \rightarrow \infty\)</span>, <span class="math inline">\(G\)</span> concentrates at <span class="math inline">\(G_0\)</span>, which is why <span class="math inline">\(\alpha\)</span> is called the precision parameter.</p>
<p>A key property of the DP is its discrete nature, which allows it to be expressed as<br />
<span class="math display">\[
G(\cdot)=\sum_{h=1}^{\infty}\lambda_h\delta_{\boldsymbol{\theta}_h}(\cdot),
\]</span>
where <span class="math inline">\(\lambda_h\)</span> is the probability mass at <span class="math inline">\(\boldsymbol{\theta}_h\)</span>, and <span class="math inline">\(\delta_{\boldsymbol{\theta}_h}(\cdot)\)</span> denotes the Dirac measure that assigns mass one to the atom <span class="math inline">\(\boldsymbol{\theta}_h\)</span>.<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a> Given this property, a particularly useful construction of the DP is the <em>stick-breaking</em> representation <span class="citation">(<a href="#ref-Sethuraman1994">Sethuraman 1994</a>)</span>, which is given by<br />
<span class="math display">\[\begin{align*}
    G(\cdot)&amp;=\sum_{h=1}^{\infty}\lambda_h\delta_{\boldsymbol{\theta}_h}(\cdot),\\
    \lambda_h&amp;=V_h\prod_{m&lt;h}(1-V_m), \quad V_h\sim \text{Beta}(1,\alpha),\\
    \boldsymbol{\theta}_h&amp;\stackrel{iid}{\sim} G_0.
\end{align*}\]</span></p>
<p>The intuition behind this representation is straightforward. We begin with a stick of length 1 and break off a random proportion <span class="math inline">\(V_1\)</span> drawn from a <span class="math inline">\(\text{Beta}(1,\alpha)\)</span> distribution. This assigns a probability mass of <span class="math inline">\(\lambda_1=V_1\)</span> to <span class="math inline">\(\boldsymbol{\theta}_1\)</span>, which is sampled from <span class="math inline">\(G_0\)</span>. Next, from the remaining stick of length <span class="math inline">\((1-V_1)\)</span>, we break off a fraction proportional to <span class="math inline">\(V_2 \sim \text{Beta}(1,\alpha)\)</span>, assigning a probability mass of <span class="math inline">\(\lambda_2=V_2(1-V_1)\)</span> to a new draw <span class="math inline">\(\boldsymbol{\theta}_2\)</span> from <span class="math inline">\(G_0\)</span>. This process continues indefinitely.</p>
<p>Since <span class="math inline">\(\mathbb{E}(V_h) = \frac{1}{1+\alpha}\)</span>, as <span class="math inline">\(\alpha \rightarrow \infty\)</span>, we have <span class="math inline">\(\mathbb{E}(V_h) \rightarrow 0\)</span>. Consequently, the DP places mass on a large number of atoms, leading to convergence to the base distribution <span class="math inline">\(G_0\)</span>.</p>
<p>Note that DPs give as realizations discrete distributions, this poses challenges when working with continuous distributions. One way to overcome this limitation is to use the DP as a mixing distribution for simple parametric distributions, such as the normal distribution <span class="citation">(<a href="#ref-Escobar1995">Escobar and West 1995</a>)</span>. This leads to Dirichlet process mixtures (DPM), which are defined as<br />
<span class="math display">\[\begin{align*}
    f_G(y) &amp;= \int f_{\boldsymbol{\theta}}(y) dG(\boldsymbol{\theta}).
\end{align*}\]</span></p>
<p>Observe that the mixing measure <span class="math inline">\(G\)</span> is discrete when a DP is the prior, with mass concentrated at an infinite number of atoms <span class="math inline">\(\boldsymbol{\theta}_h\)</span>. Consequently, if <span class="math inline">\(f_{\boldsymbol{\theta}}(y)\)</span> follows a Gaussian distribution, the resulting mixture resembles a finite Gaussian mixture. However, unlike finite mixtures, the DP-based approach eliminates the need to pre-specify the number of components, as it provides an automatic mechanism for determining them.</p>
<p>Thus, if we assume <span class="math inline">\(y\sim N(\boldsymbol{x}_i^{\top}\boldsymbol{\beta},\sigma^2)\)</span>, then the DPM is
<span class="math display">\[
p(y_i \mid \{\lambda_h, \boldsymbol{\beta}_h, \sigma_h^2\}_{h=1}^{\infty}, \boldsymbol{x}_i) =
\sum_{h=1}^{\infty} \lambda_h \phi(y_i \mid \boldsymbol{x}_i^{\top}\boldsymbol{\beta}_h, \sigma_h^2),
\]</span>
where <span class="math inline">\(\lambda_h\)</span> are drawn from the stick-breaking representation of the DP, and <span class="math inline">\(\boldsymbol{\theta}_h=[\boldsymbol{\beta}_h^{\top} \ \sigma^2_h]^{\top}\)</span>.</p>
<p>This mixture model can be expressed in a hierarchical structure:
<span class="math display">\[\begin{align*}
    y_i\mid \boldsymbol{\theta}_i &amp; \stackrel{ind}{\sim}f_{\boldsymbol{\theta}_i}\\
    \boldsymbol{\theta}_i \mid G &amp; \stackrel{iid}{\sim} G\\
    G \mid \alpha,G_0 &amp; \sim DP(\alpha G_0).
\end{align*}\]</span></p>
<p>Note that the hierarchical representation induces specific unit parameters, leading to a probabilistic clustering model <span class="citation">(<a href="#ref-Antoniak1974">Antoniak 1974</a>)</span>, similar to a finite Gaussian mixture. However, the DPM is not consistent in estimating the number of clusters, it tends to overestimate the number of clusters (see simulation exercise below); although there is posterior asymptotic concentration in the other model components <span class="citation">(<a href="#ref-Miller2014">Miller and Harrison 2014</a>)</span>.</p>
<p>The hierarchical representation implies that there are latent assignment variables <span class="math inline">\(s_i = h\)</span>, such that when <span class="math inline">\(\boldsymbol{\theta}_i\)</span> is equal to the <span class="math inline">\(h\)</span>-th unique <span class="math inline">\(\boldsymbol{\theta}_h^*\)</span> — that is, <span class="math inline">\(\boldsymbol{\theta}_i = \boldsymbol{\theta}_h^*\)</span>— then <span class="math inline">\(s_i = h\)</span>. Then,
<span class="math display">\[\begin{align*}
    s_i&amp;\sim \sum_{h=0}^{\infty}\lambda_h\delta_h,\\
    y_i\mid s_i, \boldsymbol{\theta}_{s_i}&amp;\sim N(\boldsymbol{x}_i^{\top}\boldsymbol{\beta}_{s_i},\sigma^2_{s_i}),
\end{align*}\]</span>
where <span class="math inline">\(\lambda_h=P(\boldsymbol{\theta}_{i}=\boldsymbol{\theta}_{h}^*)\)</span>.</p>
<p>This latent assignment structure, the <em>Pólya urn</em> representation of the DP <span class="citation">(<a href="#ref-Blackwell1973">Blackwell and MacQueen 1973</a>)</span>, which is obtained when <span class="math inline">\(G\)</span> is marginalized out to avoid infinite atoms, and the use of conjugate priors allow for convenient computational inference in DPM.</p>
<p>Specifically, we assume <span class="math inline">\(\boldsymbol{\beta}_i\mid \sigma^2_i\sim N(\boldsymbol{\beta}_0, \sigma^2_i\boldsymbol{B}_0)\)</span> and <span class="math inline">\(\sigma_i^2\sim IG(\alpha_0/2,\delta_0/2)\)</span>. In addition, we can add a layer in the hierarchical representation, <span class="math inline">\(\alpha\sim G(a,b)\)</span> such that introducing the latent variable <span class="math inline">\(\xi|\alpha,N\sim Be(\alpha+1,N)\)</span>, allows to easily sample the posterior draws of <span class="math inline">\(\alpha|\xi,H,\pi_{\xi}\sim\pi_{\xi}{G}(a+H,b-log(\xi))+(1-\pi_{\xi}){G}(a+H-1,b-log(\xi))\)</span>, where <span class="math inline">\(\frac{\pi_{\xi}}{1-\pi_{\xi}}=\frac{a+H-1}{N(b-log(\xi))}\)</span>, <span class="math inline">\(H\)</span> is the number of atoms (mixture components) <span class="citation">(<a href="#ref-Escobar1995">Escobar and West 1995</a>)</span>.</p>
<p>The conditional posterior distribution of <span class="math inline">\(\boldsymbol\theta_i\)</span> is
<span class="math display">\[\begin{align*}
    \boldsymbol\theta_i|\left\{\boldsymbol\theta_{i&#39;},\boldsymbol s_{i&#39;}:i&#39;\neq i\right\}, y_i, \alpha &amp; \sim \sum_{i&#39;\neq i}\frac{N_h^{(i)}}{\alpha+N-1}f_N(y_i|\boldsymbol{x}_i^{\top}\boldsymbol{\beta}_h,\sigma_h^2)\\
    &amp; +\frac{\alpha}{\alpha+N-1}\int_{\mathcal{R}^K}\int_{0}^{\infty}f_N(y_i|\boldsymbol{x}_i^{\top}\boldsymbol{\beta},\sigma^2)f_N\left(\boldsymbol\beta\Big|\boldsymbol\beta_0,\sigma^2\boldsymbol B_0\right)f_{IG}(\sigma^2|\alpha_0,\delta_0)d\sigma^2 d\boldsymbol\beta,
\end{align*}\]</span>
where <span class="math inline">\(N_h^{(i)}\)</span> is the number of observations such that <span class="math inline">\(s_{i&#39;}=h\)</span>, <span class="math inline">\(i&#39;\neq i\)</span>.</p>
<p>Observe that the probability of belonging to a particular cluster has a reinforcement property, as it increases with the cluster size; therefore, a DPM exhibits a self-reinforcing property, the more often a given value has been sampled in the past, the more likely it is to be sampled again.</p>
<p>Observe that the integral in the previous equation has exactly the same form as in the marginal likelihood presented in Section <a href="sec43.html#sec43">3.3</a>. Thus,
<span class="math display">\[\begin{align*}
    p(y_i)&amp;=\int_{\mathcal{R}^K}\int_{0}^{\infty}f_N(y_i|\boldsymbol{x}_i^{\top}\boldsymbol{\beta},\sigma^2)f_N\left(\boldsymbol\beta\Big|\boldsymbol\beta_0,\sigma^2\boldsymbol B_0\right)f_{IG}(\sigma^2|\alpha_0,\delta_0)d\sigma^2 d\boldsymbol\beta\\
    &amp;=\frac{1}{\pi^{1/2}}\frac{\delta_0^{\alpha_0/2}}{\delta_n^{\alpha_n/2}}\frac{|{\boldsymbol{B}}_n|^{1/2}}{|{\boldsymbol{B}}_0|^{1/2}}\frac{\Gamma(\alpha_n/2)}{\Gamma(\alpha_0/2)},
\end{align*}\]</span>
where <span class="math inline">\(\alpha_n=1+\alpha_0\)</span>, <span class="math inline">\(\delta_n=\delta_0 + y^{\top}y + \boldsymbol{\beta}_0^{\top}{\boldsymbol{B}}_0^{-1}\boldsymbol{\beta}_0 - \boldsymbol{\beta}_n^{\top}{\boldsymbol{B}}_n^{-1}\boldsymbol{\beta}_n\)</span>, <span class="math inline">\(\boldsymbol{B}_n = (\boldsymbol{B}_0^{-1} + \boldsymbol{x}\boldsymbol{x}^{\top})^{-1}\)</span> and <span class="math inline">\(\boldsymbol{\beta}_n = \boldsymbol{B}_n(\boldsymbol{B}_0^{-1}\boldsymbol{\beta}_0 + \boldsymbol{x}y)\)</span>.</p>
<p>Therefore, we sample <span class="math inline">\(s_i\)</span> as follows,
<span class="math display">\[\begin{equation*}
    s_i|\left\{\boldsymbol\beta_{i&#39;},\sigma_{i&#39;}^2,\boldsymbol s_{i&#39;}:i&#39;\neq i\right\}, y_i, \alpha\sim\begin{Bmatrix}P(s_i=0|\cdot)=q_0^*\\
        P(s_i=h|\cdot)=q_h^*, h=1,2,\dots,H^{(i)}\end{Bmatrix},
\end{equation*}\]</span></p>
<p>where <span class="math inline">\(H^{(i)}\)</span> is the number of clusters excluding <span class="math inline">\(i\)</span>, which may have its own cluster (singleton cluster), <span class="math inline">\(q^*_c=\frac{q_c}{q_0+\sum_h q_h}\)</span>, <span class="math inline">\(q_c=\left\{q_0,q_h\right\}\)</span>, <span class="math inline">\(q_h=\frac{N_h^{(i)}}{\alpha+N-1}f_N(y_i|\boldsymbol{x}_i^{\top}\boldsymbol\beta_h,\sigma_h^2)\)</span> and <span class="math inline">\(q_0=\frac{\alpha}{\alpha+N-1}p(y_i)\)</span>.</p>
<p>If <span class="math inline">\(s_i=0\)</span> is sampled, then <span class="math inline">\(s_i=H+1\)</span>, and a new <span class="math inline">\(\sigma_h^2\)</span> is sampled from <span class="math inline">\(IG\left(\alpha_n/2,\delta_n/2\right)\)</span>, a new <span class="math inline">\(\boldsymbol\beta_h\)</span> is sample from <span class="math inline">\(N(\boldsymbol\beta_n,\sigma_h^2\boldsymbol B_n)\)</span>.</p>
<p>Discarding <span class="math inline">\(\boldsymbol\theta_h\)</span>’s from last step, we use <span class="math inline">\(\boldsymbol s\)</span> and the total number of components to sample <span class="math inline">\(\sigma_h^2\)</span> from</p>
<p><span class="math display">\[\begin{equation*}
    IG\left(\frac{\alpha_0+N_m}{2},\frac{\delta_0+\boldsymbol y_h^{\top}\boldsymbol y_h+\boldsymbol{\beta}_0^{\top}{\boldsymbol{B}}_0^{-1}\boldsymbol{\beta}_0-\boldsymbol{\beta}_{hn}^{\top}{\boldsymbol{B}}_{hn}^{-1}\boldsymbol{\beta}_{hn}}{2}\right),
\end{equation*}\]</span></p>
<p>where <span class="math inline">\(\boldsymbol{B}_{hn}=(\boldsymbol{B}_0^{-1}+\boldsymbol{X}_h^{\top}\boldsymbol{X}_h)^{-1}\)</span> and <span class="math inline">\(\boldsymbol{\beta}_{hn}=\boldsymbol{B}_{hn}(\boldsymbol{B}_0^{-1}\boldsymbol{\beta}_0+\boldsymbol{X}_h^{\top}\boldsymbol{y}_h)\)</span>, <span class="math inline">\(\boldsymbol{X}_h\)</span> and <span class="math inline">\(\boldsymbol{y}_h\)</span> have the <span class="math inline">\(\boldsymbol{x}_i\)</span> and <span class="math inline">\(y_i\)</span> of individuals in component <span class="math inline">\(h\)</span>. We sample <span class="math inline">\(\boldsymbol\beta_h\)</span> from
<span class="math display">\[\begin{equation*}
    N\left({\boldsymbol\beta}_{hn},\sigma_h^2\boldsymbol B_{hn}\right),
\end{equation*}\]</span>
<span class="math inline">\(h=1,2,\dots,H\)</span>.</p>
<p>We can also use DPMs in a semi-parametric setting, as we did in the finite Gaussian mixtures case. In Exercise 3, we ask to get the posterior sampler in this setting, that is,
<span class="math display">\[\begin{align*}
    y_i&amp;=\boldsymbol{x}_i^{\top}\boldsymbol{\beta}+e_i\\
    e_i\mid \mu_i,\sigma_i^2 &amp;\stackrel{iid}{\sim} N(\mu_i,\sigma_i^2).
\end{align*}\]</span>
We should not include the intercept in <span class="math inline">\(\boldsymbol{\beta}\)</span>, such that <span class="math inline">\(\mu_i\)</span> allows to get flexibility in the distribution of the stochastic errors.</p>
<p>Note that mixture models can be easily extended to non-linear models, where posterior inference is based on data augmentation, such as the probit and tobit models in Chapter <a href="Chap6.html#Chap6">6</a>. The basic idea is to incorporate the mixture (finite or infinite) into the specification of the latent variable implicit in the data-generating process. For instance, <span class="citation">Basu and Chib (<a href="#ref-basu2003marginal">2003</a>)</span> perform inference in the probit model using DPMs. Furthermore, mixtures can also be used in the multivariate models presented in Chapter <a href="#Cap7"><strong>??</strong></a> and the hierarchical models presented in Chapter <a href="Chap9.html#Chap9">9</a>. <span class="citation">Ramı́rez–Hassan and López-Vera (<a href="#ref-ramirez2024welfare">2024</a>)</span> perform semi-parametric inference in the exact affine demand system <span class="citation">(<a href="#ref-lewbel2009tricks">Lewbel and Pendakur 2009</a>)</span> using DPMs, while <span class="citation">Basu and Chib (<a href="#ref-basu2003marginal">2003</a>)</span> apply them in hierarchical models.</p>
<p>To sum up, a Dirichlet process mixture is a flexible way to model non-parametrically a distribution using an infinite weighted sum of discrete distributions, where each individual weight increases with the number of observations that belongs to it.</p>

</div>
</div>
<!-- </div> -->
<h3>References<a href="references.html#references" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Antoniak1974" class="csl-entry">
Antoniak, C. 1974. <span>“Mixtures of <span>D</span>irichlet Processes with Applications to <span>B</span>ayesian Nonparametric Problems.”</span> <em>The Annals of Statistics</em> 2 (6): 1152–74.
</div>
<div id="ref-basu2003marginal" class="csl-entry">
Basu, Sanjib, and Siddhartha Chib. 2003. <span>“Marginal Likelihood and Bayes Factors for Dirichlet Process Mixture Models.”</span> <em>Journal of the American Statistical Association</em> 98 (461): 224–35.
</div>
<div id="ref-Blackwell1973" class="csl-entry">
Blackwell, D., and J. MacQueen. 1973. <span>“Ferguson Distributions via <span>P</span>ólya Urn Schemes.”</span> <em>The Annals of Statistics</em> 1: 353–55.
</div>
<div id="ref-Escobar1995" class="csl-entry">
Escobar, M., and M. West. 1995. <span>“Bayesian Density Estimation and Inference Using Mixtures.”</span> <em>Journal of the American Statistical Association</em> 90 (430): 577–88.
</div>
<div id="ref-Ferguson1973" class="csl-entry">
Ferguson, T. 1973. <span>“A <span>B</span>ayesian Analysis of Some Nonparametric Problems.”</span> <em>The Annals of Statistics</em> 1 (2): 209–30.
</div>
<div id="ref-fruhwirth2006finite" class="csl-entry">
Frühwirth-Schnatter, Sylvia. 2006. <em>Finite Mixture and Markov Switching Models</em>. Springer.
</div>
<div id="ref-gelman2021bayesian" class="csl-entry">
Gelman, Andrew, John B Carlin, Hal S Stern, David Dunson, Aki Vehtari, and Donald B Rubin. 2021. <em>Bayesian Data Analysis</em>. Chapman; Hall/CRC.
</div>
<div id="ref-lewbel2009tricks" class="csl-entry">
Lewbel, Arthur, and Krishna Pendakur. 2009. <span>“Tricks with Hicks: The EASI Demand System.”</span> <em>American Economic Review</em> 99 (3): 827–63.
</div>
<div id="ref-Miller2014" class="csl-entry">
Miller, J., and M. Harrison. 2014. <span>“Inconsistency of <span>P</span>itman-<span>Y</span>or Process Mixtures for the Number of Components.”</span> <em>Journal of Machine Learning Research</em> 15: 3333–70.
</div>
<div id="ref-Muller2015" class="csl-entry">
Müller, P., F. Quintana, A. Jara, and T. Hanson. 2015. <em><span>Bayesian Nonparametric Data Analysis</span></em>. <span>New York</span>: <span>Springer</span>.
</div>
<div id="ref-ramirez2024welfare" class="csl-entry">
Ramı́rez–Hassan, Andrés, and Alejandro López-Vera. 2024. <span>“Welfare Implications of a Tax on Electricity: A Semi-Parametric Specification of the Incomplete EASI Demand System.”</span> <em>Energy Economics</em> 131: 1–13.
</div>
<div id="ref-rossi2014bayesian" class="csl-entry">
Rossi, Peter E. 2014. <em>Bayesian Non- and Semi-Parametric Methods and Applications</em>. Princeton, NJ: Princeton University Press. <a href="https://ideas.repec.org/b/pup/pbooks/10259.html">https://ideas.repec.org/b/pup/pbooks/10259.html</a>.
</div>
<div id="ref-Sethuraman1994" class="csl-entry">
Sethuraman, J. 1994. <span>“A Constructive Definition of <span>D</span>irichlet Priors.”</span> <em>Statistica Sinica</em> 4: 639–50.
</div>
<div id="ref-van2011bayesian" class="csl-entry">
Van Hasselt, Martijn. 2011. <span>“Bayesian Inference in a Sample Selection Model.”</span> <em>Journal of Econometrics</em> 165 (2): 221–32.
</div>
</div>
<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p>Measurability ensures that we can compute probabilities and expectations properly. If a set is not measurable, we cannot define its probability meaningfully.<a href="sec11_1.html#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p>An atom is a set that has positive probability but cannot be further decomposed into smaller sets with strictly smaller probability.<a href="sec11_1.html#fnref2" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="Chap11.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="Chap12.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/aramir21/IntroductionBayesianEconometricsBook/12-Nonparametric.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
