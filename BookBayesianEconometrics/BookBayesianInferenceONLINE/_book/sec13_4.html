<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>13.4 Instrumental variables (IV) | Introduction to Bayesian Econometrics</title>
  <meta name="description" content="The subject of this textbook is Bayesian data modeling, with the primary aim of providing an introduction to its theoretical foundations and facilitating the application of Bayesian inference using a GUI." />
  <meta name="generator" content="bookdown 0.43 and GitBook 2.6.7" />

  <meta property="og:title" content="13.4 Instrumental variables (IV) | Introduction to Bayesian Econometrics" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="The subject of this textbook is Bayesian data modeling, with the primary aim of providing an introduction to its theoretical foundations and facilitating the application of Bayesian inference using a GUI." />
  <meta name="github-repo" content="https://github.com/aramir21/IntroductionBayesianEconometricsBook" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="13.4 Instrumental variables (IV) | Introduction to Bayesian Econometrics" />
  
  <meta name="twitter:description" content="The subject of this textbook is Bayesian data modeling, with the primary aim of providing an introduction to its theoretical foundations and facilitating the application of Bayesian inference using a GUI." />
  

<meta name="author" content="Andrés Ramírez-Hassan" />


<meta name="date" content="2025-09-18" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="sec13_3.html"/>
<link rel="next" href="sec13_5.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Introduction to Bayesian Econometrics: A GUIded tour using R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction</a>
<ul>
<li class="chapter" data-level="" data-path="to-instructors-and-students.html"><a href="to-instructors-and-students.html"><i class="fa fa-check"></i>To instructors and students</a></li>
<li class="chapter" data-level="" data-path="acknowledgments.html"><a href="acknowledgments.html"><i class="fa fa-check"></i>Acknowledgments</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="Chap1.html"><a href="Chap1.html"><i class="fa fa-check"></i><b>1</b> Basic formal concepts</a>
<ul>
<li class="chapter" data-level="1.1" data-path="sec11.html"><a href="sec11.html"><i class="fa fa-check"></i><b>1.1</b> The Bayes’ rule</a></li>
<li class="chapter" data-level="1.2" data-path="sec12.html"><a href="sec12.html"><i class="fa fa-check"></i><b>1.2</b> Bayesian framework: A brief summary of theory</a></li>
<li class="chapter" data-level="1.3" data-path="sec14.html"><a href="sec14.html"><i class="fa fa-check"></i><b>1.3</b> Bayesian reports: Decision theory under uncertainty</a></li>
<li class="chapter" data-level="1.4" data-path="summary.html"><a href="summary.html"><i class="fa fa-check"></i><b>1.4</b> Summary</a></li>
<li class="chapter" data-level="1.5" data-path="exercises.html"><a href="exercises.html"><i class="fa fa-check"></i><b>1.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="Chap2.html"><a href="Chap2.html"><i class="fa fa-check"></i><b>2</b> Conceptual differences between the Bayesian and Frequentist approaches</a>
<ul>
<li class="chapter" data-level="2.1" data-path="sec21.html"><a href="sec21.html"><i class="fa fa-check"></i><b>2.1</b> The concept of probability</a></li>
<li class="chapter" data-level="2.2" data-path="sec22.html"><a href="sec22.html"><i class="fa fa-check"></i><b>2.2</b> Subjectivity is not the key</a></li>
<li class="chapter" data-level="2.3" data-path="sec23.html"><a href="sec23.html"><i class="fa fa-check"></i><b>2.3</b> Estimation, hypothesis testing and prediction</a></li>
<li class="chapter" data-level="2.4" data-path="sec24.html"><a href="sec24.html"><i class="fa fa-check"></i><b>2.4</b> The likelihood principle</a></li>
<li class="chapter" data-level="2.5" data-path="sec25.html"><a href="sec25.html"><i class="fa fa-check"></i><b>2.5</b> Why is not the Bayesian approach that popular?</a></li>
<li class="chapter" data-level="2.6" data-path="sec26.html"><a href="sec26.html"><i class="fa fa-check"></i><b>2.6</b> A simple working example</a></li>
<li class="chapter" data-level="2.7" data-path="sec27.html"><a href="sec27.html"><i class="fa fa-check"></i><b>2.7</b> Summary</a></li>
<li class="chapter" data-level="2.8" data-path="sec28.html"><a href="sec28.html"><i class="fa fa-check"></i><b>2.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="Chap3.html"><a href="Chap3.html"><i class="fa fa-check"></i><b>3</b> Cornerstone models: Conjugate families</a>
<ul>
<li class="chapter" data-level="3.1" data-path="sec41.html"><a href="sec41.html"><i class="fa fa-check"></i><b>3.1</b> Motivation of conjugate families</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="sec41.html"><a href="sec41.html#examples-of-exponential-family-distributions"><i class="fa fa-check"></i><b>3.1.1</b> Examples of exponential family distributions</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="sec42.html"><a href="sec42.html"><i class="fa fa-check"></i><b>3.2</b> Conjugate prior to exponential family</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="sec42.html"><a href="sec42.html#sec421"><i class="fa fa-check"></i><b>3.2.1</b> Examples: Theorem 4.2.1</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="sec43.html"><a href="sec43.html"><i class="fa fa-check"></i><b>3.3</b> Linear regression: The conjugate normal-normal/inverse gamma model</a></li>
<li class="chapter" data-level="3.4" data-path="sec44.html"><a href="sec44.html"><i class="fa fa-check"></i><b>3.4</b> Multivariate linear regression: The conjugate normal-normal/inverse Wishart model</a></li>
<li class="chapter" data-level="3.5" data-path="sec45.html"><a href="sec45.html"><i class="fa fa-check"></i><b>3.5</b> Summary</a></li>
<li class="chapter" data-level="3.6" data-path="sec46.html"><a href="sec46.html"><i class="fa fa-check"></i><b>3.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="Chap4.html"><a href="Chap4.html"><i class="fa fa-check"></i><b>4</b> Simulation methods</a>
<ul>
<li class="chapter" data-level="4.1" data-path="sec51.html"><a href="sec51.html"><i class="fa fa-check"></i><b>4.1</b> Markov Chain Monte Carlo methods</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="sec51.html"><a href="sec51.html#sec511"><i class="fa fa-check"></i><b>4.1.1</b> Gibbs sampler</a></li>
<li class="chapter" data-level="4.1.2" data-path="sec51.html"><a href="sec51.html#sec512"><i class="fa fa-check"></i><b>4.1.2</b> Metropolis-Hastings</a></li>
<li class="chapter" data-level="4.1.3" data-path="sec51.html"><a href="sec51.html#sec513"><i class="fa fa-check"></i><b>4.1.3</b> Hamiltonian Monte Carlo</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="sec52.html"><a href="sec52.html"><i class="fa fa-check"></i><b>4.2</b> Importance sampling</a></li>
<li class="chapter" data-level="4.3" data-path="sec53.html"><a href="sec53.html"><i class="fa fa-check"></i><b>4.3</b> Particle filtering</a></li>
<li class="chapter" data-level="4.4" data-path="sec54.html"><a href="sec54.html"><i class="fa fa-check"></i><b>4.4</b> Convergence diagnostics</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="sec54.html"><a href="sec54.html#numerical-standard-error"><i class="fa fa-check"></i><b>4.4.1</b> Numerical standard error</a></li>
<li class="chapter" data-level="4.4.2" data-path="sec54.html"><a href="sec54.html#effective-number-of-simulation-draws"><i class="fa fa-check"></i><b>4.4.2</b> Effective number of simulation draws</a></li>
<li class="chapter" data-level="4.4.3" data-path="sec54.html"><a href="sec54.html#tests-of-convergence"><i class="fa fa-check"></i><b>4.4.3</b> Tests of convergence</a></li>
<li class="chapter" data-level="4.4.4" data-path="sec54.html"><a href="sec54.html#checking-for-errors-in-the-posterior-simulator"><i class="fa fa-check"></i><b>4.4.4</b> Checking for errors in the posterior simulator</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="sec55.html"><a href="sec55.html"><i class="fa fa-check"></i><b>4.5</b> Summary</a></li>
<li class="chapter" data-level="4.6" data-path="sec56.html"><a href="sec56.html"><i class="fa fa-check"></i><b>4.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="Chap5.html"><a href="Chap5.html"><i class="fa fa-check"></i><b>5</b> Graphical user interface</a>
<ul>
<li class="chapter" data-level="5.1" data-path="secGUI1.html"><a href="secGUI1.html"><i class="fa fa-check"></i><b>5.1</b> Introduction</a></li>
<li class="chapter" data-level="5.2" data-path="secGUI2.html"><a href="secGUI2.html"><i class="fa fa-check"></i><b>5.2</b> Univariate models</a></li>
<li class="chapter" data-level="5.3" data-path="secGUI3.html"><a href="secGUI3.html"><i class="fa fa-check"></i><b>5.3</b> Multivariate models</a></li>
<li class="chapter" data-level="5.4" data-path="secGUI4.html"><a href="secGUI4.html"><i class="fa fa-check"></i><b>5.4</b> Time series models</a></li>
<li class="chapter" data-level="5.5" data-path="secGUI5.html"><a href="secGUI5.html"><i class="fa fa-check"></i><b>5.5</b> Longitudinal/panel models</a></li>
<li class="chapter" data-level="5.6" data-path="secGUI6.html"><a href="secGUI6.html"><i class="fa fa-check"></i><b>5.6</b> Bayesian model average</a></li>
<li class="chapter" data-level="5.7" data-path="secGUI7.html"><a href="secGUI7.html"><i class="fa fa-check"></i><b>5.7</b> Help</a></li>
<li class="chapter" data-level="5.8" data-path="secGUI8.html"><a href="secGUI8.html"><i class="fa fa-check"></i><b>5.8</b> Warning</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="Chap6.html"><a href="Chap6.html"><i class="fa fa-check"></i><b>6</b> Univariate regression</a>
<ul>
<li class="chapter" data-level="6.1" data-path="sec61.html"><a href="sec61.html"><i class="fa fa-check"></i><b>6.1</b> The Gaussian linear model</a></li>
<li class="chapter" data-level="6.2" data-path="sec62.html"><a href="sec62.html"><i class="fa fa-check"></i><b>6.2</b> The logit model</a></li>
<li class="chapter" data-level="6.3" data-path="sec63.html"><a href="sec63.html"><i class="fa fa-check"></i><b>6.3</b> The probit model</a></li>
<li class="chapter" data-level="6.4" data-path="sec64.html"><a href="sec64.html"><i class="fa fa-check"></i><b>6.4</b> The multinomial probit model</a></li>
<li class="chapter" data-level="6.5" data-path="sec65.html"><a href="sec65.html"><i class="fa fa-check"></i><b>6.5</b> The multinomial logit model</a></li>
<li class="chapter" data-level="6.6" data-path="sec66.html"><a href="sec66.html"><i class="fa fa-check"></i><b>6.6</b> Ordered probit model</a></li>
<li class="chapter" data-level="6.7" data-path="negative-binomial-model.html"><a href="negative-binomial-model.html"><i class="fa fa-check"></i><b>6.7</b> Negative binomial model</a></li>
<li class="chapter" data-level="6.8" data-path="sec68.html"><a href="sec68.html"><i class="fa fa-check"></i><b>6.8</b> Tobit model</a></li>
<li class="chapter" data-level="6.9" data-path="sec69.html"><a href="sec69.html"><i class="fa fa-check"></i><b>6.9</b> Quantile regression</a></li>
<li class="chapter" data-level="6.10" data-path="sec610.html"><a href="sec610.html"><i class="fa fa-check"></i><b>6.10</b> Bayesian bootstrap regression</a></li>
<li class="chapter" data-level="6.11" data-path="sec611.html"><a href="sec611.html"><i class="fa fa-check"></i><b>6.11</b> Summary</a></li>
<li class="chapter" data-level="6.12" data-path="sec612.html"><a href="sec612.html"><i class="fa fa-check"></i><b>6.12</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="Chap7.html"><a href="Chap7.html"><i class="fa fa-check"></i><b>7</b> Multivariate regression</a>
<ul>
<li class="chapter" data-level="7.1" data-path="sec71.html"><a href="sec71.html"><i class="fa fa-check"></i><b>7.1</b> Multivariate regression</a></li>
<li class="chapter" data-level="7.2" data-path="sec72.html"><a href="sec72.html"><i class="fa fa-check"></i><b>7.2</b> Seemingly Unrelated Regression</a></li>
<li class="chapter" data-level="7.3" data-path="sec73.html"><a href="sec73.html"><i class="fa fa-check"></i><b>7.3</b> Instrumental variable</a></li>
<li class="chapter" data-level="7.4" data-path="sec74.html"><a href="sec74.html"><i class="fa fa-check"></i><b>7.4</b> Multivariate probit model</a></li>
<li class="chapter" data-level="7.5" data-path="sec75.html"><a href="sec75.html"><i class="fa fa-check"></i><b>7.5</b> Summary</a></li>
<li class="chapter" data-level="7.6" data-path="sec76.html"><a href="sec76.html"><i class="fa fa-check"></i><b>7.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="Chap8.html"><a href="Chap8.html"><i class="fa fa-check"></i><b>8</b> Time series</a>
<ul>
<li class="chapter" data-level="8.1" data-path="sec81.html"><a href="sec81.html"><i class="fa fa-check"></i><b>8.1</b> State-space representation</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="sec81.html"><a href="sec81.html#gaussian-linear-state-space-models"><i class="fa fa-check"></i><b>8.1.1</b> Gaussian linear state-space models</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="sec82.html"><a href="sec82.html"><i class="fa fa-check"></i><b>8.2</b> ARMA processes</a></li>
<li class="chapter" data-level="8.3" data-path="sec83.html"><a href="sec83.html"><i class="fa fa-check"></i><b>8.3</b> Stochastic volatility models</a></li>
<li class="chapter" data-level="8.4" data-path="sec84.html"><a href="sec84.html"><i class="fa fa-check"></i><b>8.4</b> Vector Autoregressive models</a></li>
<li class="chapter" data-level="8.5" data-path="sec85.html"><a href="sec85.html"><i class="fa fa-check"></i><b>8.5</b> Summary</a></li>
<li class="chapter" data-level="8.6" data-path="sec86.html"><a href="sec86.html"><i class="fa fa-check"></i><b>8.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="Chap9.html"><a href="Chap9.html"><i class="fa fa-check"></i><b>9</b> Longitudinal regression</a>
<ul>
<li class="chapter" data-level="9.1" data-path="sec91.html"><a href="sec91.html"><i class="fa fa-check"></i><b>9.1</b> Normal model</a></li>
<li class="chapter" data-level="9.2" data-path="sec92.html"><a href="sec92.html"><i class="fa fa-check"></i><b>9.2</b> Logit model</a></li>
<li class="chapter" data-level="9.3" data-path="sec93.html"><a href="sec93.html"><i class="fa fa-check"></i><b>9.3</b> Poisson model</a></li>
<li class="chapter" data-level="9.4" data-path="sec94.html"><a href="sec94.html"><i class="fa fa-check"></i><b>9.4</b> Summary</a></li>
<li class="chapter" data-level="9.5" data-path="sec95.html"><a href="sec95.html"><i class="fa fa-check"></i><b>9.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="Chap10.html"><a href="Chap10.html"><i class="fa fa-check"></i><b>10</b> Bayesian model averaging in variable selection</a>
<ul>
<li class="chapter" data-level="10.1" data-path="sec10_1.html"><a href="sec10_1.html"><i class="fa fa-check"></i><b>10.1</b> Foundation</a></li>
<li class="chapter" data-level="10.2" data-path="sec102.html"><a href="sec102.html"><i class="fa fa-check"></i><b>10.2</b> The Gaussian linear model</a></li>
<li class="chapter" data-level="10.3" data-path="sec103.html"><a href="sec103.html"><i class="fa fa-check"></i><b>10.3</b> Generalized linear models</a></li>
<li class="chapter" data-level="10.4" data-path="sec10_4.html"><a href="sec10_4.html"><i class="fa fa-check"></i><b>10.4</b> Calculating the marginal likelihood</a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="sec10_4.html"><a href="sec10_4.html#sec10_4_1"><i class="fa fa-check"></i><b>10.4.1</b> Savage-Dickey density ratio</a></li>
<li class="chapter" data-level="10.4.2" data-path="sec10_4.html"><a href="sec10_4.html#sec10_4_2"><i class="fa fa-check"></i><b>10.4.2</b> Chib’s methods</a></li>
<li class="chapter" data-level="10.4.3" data-path="sec10_4.html"><a href="sec10_4.html#sec10_4_3"><i class="fa fa-check"></i><b>10.4.3</b> Gelfand-Dey method</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="sec10_5.html"><a href="sec10_5.html"><i class="fa fa-check"></i><b>10.5</b> Summary</a></li>
<li class="chapter" data-level="10.6" data-path="sec10_6.html"><a href="sec10_6.html"><i class="fa fa-check"></i><b>10.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="Chap11.html"><a href="Chap11.html"><i class="fa fa-check"></i><b>11</b> Semi-parametric and non-parametric models</a>
<ul>
<li class="chapter" data-level="11.1" data-path="sec11_1.html"><a href="sec11_1.html"><i class="fa fa-check"></i><b>11.1</b> Mixture models</a>
<ul>
<li class="chapter" data-level="11.1.1" data-path="sec11_1.html"><a href="sec11_1.html#sec11_11"><i class="fa fa-check"></i><b>11.1.1</b> Finite Gaussian mixtures</a></li>
<li class="chapter" data-level="11.1.2" data-path="sec11_1.html"><a href="sec11_1.html#sec11_12"><i class="fa fa-check"></i><b>11.1.2</b> Direchlet processes</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="sec11_2.html"><a href="sec11_2.html"><i class="fa fa-check"></i><b>11.2</b> Splines</a></li>
<li class="chapter" data-level="11.3" data-path="sec11_3.html"><a href="sec11_3.html"><i class="fa fa-check"></i><b>11.3</b> Summary</a></li>
<li class="chapter" data-level="11.4" data-path="sec11_4.html"><a href="sec11_4.html"><i class="fa fa-check"></i><b>11.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="Chap12.html"><a href="Chap12.html"><i class="fa fa-check"></i><b>12</b> Bayesian machine learning</a>
<ul>
<li class="chapter" data-level="12.1" data-path="sec12_1.html"><a href="sec12_1.html"><i class="fa fa-check"></i><b>12.1</b> Cross-validation and Bayes factors</a></li>
<li class="chapter" data-level="12.2" data-path="sec12_2.html"><a href="sec12_2.html"><i class="fa fa-check"></i><b>12.2</b> Regularization</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="sec12_2.html"><a href="sec12_2.html#sec12_21"><i class="fa fa-check"></i><b>12.2.1</b> Bayesian LASSO</a></li>
<li class="chapter" data-level="12.2.2" data-path="sec12_2.html"><a href="sec12_2.html#sec12_22"><i class="fa fa-check"></i><b>12.2.2</b> Stochastic search variable selection</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="sec12_3.html"><a href="sec12_3.html"><i class="fa fa-check"></i><b>12.3</b> Bayesian additive regression trees</a></li>
<li class="chapter" data-level="12.4" data-path="sec12_4.html"><a href="sec12_4.html"><i class="fa fa-check"></i><b>12.4</b> Gaussian processes</a></li>
<li class="chapter" data-level="12.5" data-path="sec12_5.html"><a href="sec12_5.html"><i class="fa fa-check"></i><b>12.5</b> Tall data problems</a>
<ul>
<li class="chapter" data-level="12.5.1" data-path="sec12_5.html"><a href="sec12_5.html#sec12_51"><i class="fa fa-check"></i><b>12.5.1</b> Divide-and-conquer methods</a></li>
<li class="chapter" data-level="12.5.2" data-path="sec12_5.html"><a href="sec12_5.html#sec12_52"><i class="fa fa-check"></i><b>12.5.2</b> Subsampling-based algorithms</a></li>
</ul></li>
<li class="chapter" data-level="12.6" data-path="id_13_6.html"><a href="id_13_6.html"><i class="fa fa-check"></i><b>12.6</b> Summary</a></li>
<li class="chapter" data-level="12.7" data-path="id_13_7.html"><a href="id_13_7.html"><i class="fa fa-check"></i><b>12.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="Chap13.html"><a href="Chap13.html"><i class="fa fa-check"></i><b>13</b> Causal inference</a>
<ul>
<li class="chapter" data-level="13.1" data-path="sec13_1.html"><a href="sec13_1.html"><i class="fa fa-check"></i><b>13.1</b> Identification setting</a></li>
<li class="chapter" data-level="13.2" data-path="sec13_2.html"><a href="sec13_2.html"><i class="fa fa-check"></i><b>13.2</b> Randomized controlled trial (RCT)</a></li>
<li class="chapter" data-level="13.3" data-path="sec13_3.html"><a href="sec13_3.html"><i class="fa fa-check"></i><b>13.3</b> Conditional independence assumption (CIA)</a></li>
<li class="chapter" data-level="13.4" data-path="sec13_4.html"><a href="sec13_4.html"><i class="fa fa-check"></i><b>13.4</b> Instrumental variables (IV)</a></li>
<li class="chapter" data-level="13.5" data-path="sec13_5.html"><a href="sec13_5.html"><i class="fa fa-check"></i><b>13.5</b> Difference-in-differences design (DiD)</a>
<ul>
<li class="chapter" data-level="13.5.1" data-path="sec13_5.html"><a href="sec13_5.html#sec13_51"><i class="fa fa-check"></i><b>13.5.1</b> Classic DiD: two-group and two-period (<span class="math inline">\(2\times2\)</span>) setup</a></li>
<li class="chapter" data-level="13.5.2" data-path="sec13_5.html"><a href="sec13_5.html#sec13_52"><i class="fa fa-check"></i><b>13.5.2</b> Staggered (SDiD): G-group and T-period (<span class="math inline">\(G\times T\)</span>) setup</a></li>
</ul></li>
<li class="chapter" data-level="13.6" data-path="sec13_6.html"><a href="sec13_6.html"><i class="fa fa-check"></i><b>13.6</b> Regression discontinuity design (RD)</a>
<ul>
<li class="chapter" data-level="13.6.1" data-path="sec13_6.html"><a href="sec13_6.html#sec13_61"><i class="fa fa-check"></i><b>13.6.1</b> Sharp regression discontinuity design (SRD)</a></li>
<li class="chapter" data-level="13.6.2" data-path="sec13_6.html"><a href="sec13_6.html#sec13_62"><i class="fa fa-check"></i><b>13.6.2</b> Fuzzy regression discontinuity design (FRD)</a></li>
</ul></li>
<li class="chapter" data-level="13.7" data-path="sec13_7.html"><a href="sec13_7.html"><i class="fa fa-check"></i><b>13.7</b> Sample selection</a></li>
<li class="chapter" data-level="13.8" data-path="sec13_8.html"><a href="sec13_8.html"><i class="fa fa-check"></i><b>13.8</b> Bayesian exponentially tilted empirical likelihood</a></li>
<li class="chapter" data-level="13.9" data-path="sec13_10.html"><a href="sec13_10.html"><i class="fa fa-check"></i><b>13.9</b> Doubly robust Bayesian inferential framework (DRB)</a></li>
<li class="chapter" data-level="13.10" data-path="sec13_11.html"><a href="sec13_11.html"><i class="fa fa-check"></i><b>13.10</b> Summary</a></li>
<li class="chapter" data-level="13.11" data-path="sec13_12.html"><a href="sec13_12.html"><i class="fa fa-check"></i><b>13.11</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="Chap14.html"><a href="Chap14.html"><i class="fa fa-check"></i><b>14</b> Approximate Bayesian methods</a>
<ul>
<li class="chapter" data-level="14.1" data-path="sec14_1.html"><a href="sec14_1.html"><i class="fa fa-check"></i><b>14.1</b> Simulation-based approaches</a>
<ul>
<li class="chapter" data-level="14.1.1" data-path="sec14_1.html"><a href="sec14_1.html#sec14_11"><i class="fa fa-check"></i><b>14.1.1</b> Approximate Bayesian computation</a></li>
<li class="chapter" data-level="14.1.2" data-path="sec14_1.html"><a href="sec14_1.html#sec14_12"><i class="fa fa-check"></i><b>14.1.2</b> Bayesian synthetic likelihood</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="sec14_2.html"><a href="sec14_2.html"><i class="fa fa-check"></i><b>14.2</b> Optimization approaches</a>
<ul>
<li class="chapter" data-level="14.2.1" data-path="sec14_2.html"><a href="sec14_2.html#sec14_21"><i class="fa fa-check"></i><b>14.2.1</b> Integrated nested Laplace approximations</a></li>
<li class="chapter" data-level="14.2.2" data-path="sec14_2.html"><a href="sec14_2.html#sec14_22"><i class="fa fa-check"></i><b>14.2.2</b> Variational Bayes</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="summary-1.html"><a href="summary-1.html"><i class="fa fa-check"></i><b>14.3</b> Summary</a></li>
<li class="chapter" data-level="14.4" data-path="sec14_4.html"><a href="sec14_4.html"><i class="fa fa-check"></i><b>14.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i>Appendix</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to Bayesian Econometrics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="sec13_4" class="section level2 hasAnchor" number="13.4">
<h2><span class="header-section-number">13.4</span> Instrumental variables (IV)<a href="sec13_4.html#sec13_4" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In many real-world situations, we face biases such as those described in the previous paragraph, arising from measurement errors, omission of relevant variables, and similar issues. Even in these cases, it is still possible to identify the causal effect. One common strategy is to use a set of <em>instrumental variables</em> (<span class="math inline">\(\mathbf{Z}\)</span>) that satisfy two key conditions:</p>
<ol style="list-style-type: decimal">
<li><p><em>Relevance</em>, meaning the instruments are correlated with the treatment:
<span class="math display">\[
\mathbf{Z}_i \not\perp D_i.
\]</span></p></li>
<li><p><em>Exogeneity</em>, which in the linear model requires:
<span class="math display">\[\begin{equation*}
\mathbb{E}[\mu_i \mid \mathbf{Z}_i] = 0
\end{equation*}\]</span></p>
<p>and, in terms of potential outcomes, entails:</p>
<ul>
<li><em>Exclusion restriction</em>: instruments affect the outcome only through the treatment:
<span class="math display">\[
Y_i(D_i = d, \mathbf{Z}_i = \mathbf{z}) = Y_i(D_i = d, \mathbf{Z}_i = \mathbf{z}&#39;) = Y_i(D_i = d), \quad d \in \{0,1\},
\]</span></li>
<li><em>Marginal exchangeability</em>: instruments are independent of the potential outcomes:
<span class="math display">\[
\mathbf{Z}_i \perp \{ Y_i(1), Y_i(0) \}.
\]</span></li>
</ul></li>
</ol>
<p>Relevance is testable, typically by checking whether instruments significantly predict the endogenous variable <span class="citation">(<a href="#ref-staiger1997instrumental">Staiger and Stock 1997</a>; <a href="#ref-cragg1993testing">Cragg and Donald 1993</a>; <a href="#ref-kleibergen2006generalized">Kleibergen and Paap 2006</a>; <a href="#ref-stock2005asymptotic">Stock and Yogo 2005</a>)</span>. However, <em>weak instruments</em>—those that exhibit only a weak association with the treatment—can lead to serious consequences, including a high level of uncertainty and the potential amplification of even small biases when estimating the causal effect.</p>
<p>Exogeneity is fundamentally untestable <span class="citation">(<a href="#ref-imbens1994identification">Guido W. Imbens and Angrist 1994</a>)</span>. However, when the number of instruments exceeds the number of endogenous variables, the Sargan test (or its robust version, the Hansen <span class="math inline">\(J\)</span>-test) can be used to assess the validity of overidentifying restrictions. This test should not be misinterpreted as a direct test of the exclusion restriction. Instead, it evaluates whether the overidentifying restrictions implied by the IV model hold. Specifically, the null hypothesis states that all instruments are jointly uncorrelated with the structural error term, <span class="math inline">\(\mathbb{E}[\mathbf{Z}^\top \mu] = \mathbf{0}\)</span> <span class="citation">(<a href="#ref-sargan1958econometric">Sargan 1958</a>; <a href="#ref-hansen1982large">Hansen 1982</a>)</span>.</p>
<p>If the test rejects, it indicates that at least one instrument is invalid, but it does not reveal whether the violation arises from a failure of the exclusion restriction, correlation with unobserved confounders, or model misspecification. Conversely, if the test fails to reject, it only suggests that the sample moment conditions do not provide evidence against instrument validity under the maintained model. This outcome does not prove that the exclusion restrictions hold: the test may have low power, a mix of valid and invalid instruments could pass if violations “cancel out”, and if the model is misspecified, a “passing” test is uninformative.</p>
<p>In general, the exclusion restriction concerns unobservables (no correlation with the error term). Since the error term is not observed, the exclusion restriction can never be proven from the data; we can only look for evidence against it. Therefore, while the Sargan test is informative about overall instrument validity, it is not a separate or definitive test of the exclusion restriction <span class="citation">(<a href="#ref-wooldridge2010econometric">Wooldridge 2010</a>; <a href="#ref-hayashi2000econometrics">Hayashi 2000</a>)</span>.</p>
<p>The following figure illustrates a situation where pre-treatment variables that influence both the treatment and the outcome are partially observed or measured with error. In such cases, an instrument can help identify the causal effect of the treatment on the outcome.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:unnamed-chunk-10"></span>
<img src="figures/FigChap13_7.png" alt="Directed Acyclic Graph (DAG) showing an instrumental variable $Z$ used to identify the causal effect of $D$ on $Y$ when some confounders $U$ (dashed) are unobserved or measured with error." width="300px" />
<p class="caption">
Figure 13.7: Directed Acyclic Graph (DAG) showing an instrumental variable <span class="math inline">\(Z\)</span> used to identify the causal effect of <span class="math inline">\(D\)</span> on <span class="math inline">\(Y\)</span> when some confounders <span class="math inline">\(U\)</span> (dashed) are unobserved or measured with error.
</p>
</div>
<p>However, the two conditions for instruments (relevance and exogeneity) only imply <em>partial identification</em> of the Local Average Treatment Effect (LATE; see below, and <span class="citation">Manski (<a href="#ref-Manski1989">1989</a>)</span>; <span class="citation">Manski (<a href="#ref-manski1990nonparametric">1990</a>)</span>; <span class="citation">Manski (<a href="#ref-manski1995identification">1995</a>)</span>; <span class="citation">Manski (<a href="#ref-manski2003partial">2003</a>)</span> for detailed treatments of partial identification). Thus, it is necessary to impose a third condition to achieve <em>point identification</em> of a particular treatment effect using IV. This condition is <em>monotonicity</em>, which asserts that the instrument moves all units’ treatment decisions in the same direction, that is,<br />
<span class="math display">\[
D_i(1)\geq D_i(0), \quad i=1,2,\dots,N,
\]</span>
assuming a binary instrument <span class="math inline">\(Z_i \in \{0,1\}\)</span>.</p>
<p>Note that monotonicity is also fundamentally untestable <span class="citation">(<a href="#ref-imbens1994identification">Guido W. Imbens and Angrist 1994</a>)</span>, as it refers to unobserved potential outcomes. However, its validity can be argued in the context of each application. We can examine whether the instrument shifts treatment in the expected direction. Moreover, if rich covariates are available, we can stratify by them and verify that, within each subgroup, the instrument increases (or at least does not decrease) the probability of treatment. For instance, we can analyze the cumulative distribution functions of the outcome when the binary instrumental variable takes values of 0 and 1; if the functions do not cross, this would suggest plausibility of the monotonicity assumption <span class="citation">(<a href="#ref-RamirezHassan2023">Ramı́rez-Hassan et al. 2023</a>)</span>.</p>
<p>In the case where <span class="math inline">\(Z_i\)</span> denotes the assignment to treatment and <span class="math inline">\(D_i\)</span> the actual treatment status, there are four potential groups: <em>always-takers</em> (<span class="math inline">\(D = 1 \mid Z = 1\)</span> and <span class="math inline">\(D = 1 \mid Z = 0\)</span>), <em>never-takers</em> (<span class="math inline">\(D = 0 \mid Z = 1\)</span> and <span class="math inline">\(D = 0 \mid Z = 0\)</span>), <em>compliers</em> (<span class="math inline">\(D = 1 \mid Z = 1\)</span> and <span class="math inline">\(D = 0 \mid Z = 0\)</span>), and <em>defiers</em> (<span class="math inline">\(D = 0 \mid Z = 1\)</span> and <span class="math inline">\(D = 1 \mid Z = 0\)</span>). Note that these groups are not identified; for instance, we do not know whether an individual with <span class="math inline">\(Z_i = 1\)</span> and <span class="math inline">\(D_i = 1\)</span> is a complier or an always-taker. The monotonicity assumption rules out defiers, meaning that the instrument (assignment to treatment) either does not change treatment status or only increases it.</p>
<p>The table displays the distribution of unit types when defiers are ruled out by the monotonicity assumption.</p>
<table>
<caption><span id="tab:2x2">Table 13.2: </span> Distribution of compliance types by instrument and treatment</caption>
<colgroup>
<col width="19%" />
<col width="40%" />
<col width="40%" />
</colgroup>
<thead>
<tr class="header">
<th><strong>Instrument</strong></th>
<th align="center"><strong><span class="math inline">\(D_i = 0\)</span></strong></th>
<th align="center"><strong><span class="math inline">\(D_i = 1\)</span></strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(Z_i = 0\)</span></td>
<td align="center">Compliers, Never-takers</td>
<td align="center">Always-takers</td>
</tr>
<tr class="even">
<td><span class="math inline">\(Z_i = 1\)</span></td>
<td align="center">Never-takers</td>
<td align="center">Compliers, Always-takers</td>
</tr>
</tbody>
</table>
<p>From this table we can identify the proportions of compliance types (<span class="math inline">\(C\)</span>) as follows. The probability of always-takers (a) is<br />
<span class="math display">\[
P(C_i = a) = P(D_i=1 \mid Z_i=0),
\]</span>
and the probability of never-takers (n) is<br />
<span class="math display">\[
P(C_i = n) = P(D_i=0 \mid Z_i=1).
\]</span></p>
<p>For compliers (c), note that<br />
<span class="math display">\[
P(D_i=1 \mid Z_i=1) = P(C_i=c) + P(C_i=a),
\]</span>
so that<br />
<span class="math display">\[
P(C_i = c) = P(D_i=1 \mid Z_i=1) - P(D_i=1 \mid Z_i=0).
\]</span></p>
<p>Equivalently, using <span class="math inline">\(D_i=0\)</span>,<br />
<span class="math display">\[
P(D_i=0 \mid Z_i=0) = P(C_i=n) + P(C_i=c),
\]</span>
so that<br />
<span class="math display">\[
P(C_i = c) = P(D_i=0 \mid Z_i=0) - P(D_i=0 \mid Z_i=1).
\]</span></p>
<p>Therefore, under relevance, exogeneity, monotonicity, and SUTVA, IV methods allow identification of the causal effect for the subgroup of <em>compliers</em>, that is, individuals who take the treatment when encouraged by the instrument and do not take it otherwise <span class="citation">(<a href="#ref-imbens1994identification">Guido W. Imbens and Angrist 1994</a>; <a href="#ref-angrist1996identification">Angrist, Imbens, and Rubin 1996</a>)</span>. This estimand is known as the <em>Local Average Treatment Effect</em> (LATE) because it applies to a specific subpopulation rather than the entire population <span class="citation">(<a href="#ref-hernan2020causal">Hernán and Robins 2020</a>)</span>:
<span class="math display">\[
\tau_{LATE} = \mathbb{E}[Y_i(1)-Y_i(0)\mid D_i(1)=1, D_i(0)=0].
\]</span></p>
We define <span class="math inline">\(Y_i(z_i,D_i(z))\)</span> to be the outcome for unit <span class="math inline">\(i\)</span> if exposed to treatment <span class="math inline">\(D_i(z)\)</span> after being assigned to treatment <span class="math inline">\(z\)</span>. Therefore, the <em>Intention-to-Treat</em> (ITT) causal effect of <span class="math inline">\(Z_i\)</span> on <span class="math inline">\(Y_i\)</span> is:
<div style="font-size:80%">
<p><span class="math display">\[
\begin{aligned}
\mathbb{E}[Y_i(1,D_i(1))-Y_i(0,D_i(0))] &amp;=
\underbrace{\mathbb{E}[Y_i(1,D_i(1))-Y_i(0,D_i(0))\mid D_i(1)=1,D_i(0)=1]\times P(D_i(1)=1,D_i(0)=1)}_{\text{always-takers}} \\
&amp;+\underbrace{\mathbb{E}[Y_i(1,D_i(1))-Y_i(0,D_i(0))\mid D_i(1)=0,D_i(0)=0]\times P(D_i(1)=0,D_i(0)=0)}_{\text{never-takers}} \\
&amp;+\underbrace{\mathbb{E}[Y_i(1,D_i(1))-Y_i(0,D_i(0))\mid D_i(1)=1,D_i(0)=0]\times P(D_i(1)=1,D_i(0)=0)}_{\text{compliers}} \\
&amp;+\underbrace{\mathbb{E}[Y_i(1,D_i(1))-Y_i(0,D_i(0))\mid D_i(1)=0,D_i(0)=1]\times P(D_i(1)=0,D_i(0)=1)}_{\text{defiers}}.
\end{aligned}
\]</span></p>
</div>
<p>That is, ITT is a mixture over the four potential groups.</p>
<p>We know that the ITT effect of <span class="math inline">\(Z_i\)</span> on <span class="math inline">\(Y_i\)</span> is zero for always-takers and never-takers due to the exclusion restriction, i.e., <span class="math inline">\(Z_i\)</span> affects <span class="math inline">\(Y_i\)</span> only through <span class="math inline">\(D_i\)</span>, and <span class="math inline">\(D_i\)</span> does not vary with <span class="math inline">\(Z_i\)</span> for always-takers and never-takers. Moreover, the monotonicity assumption rules out the existence of defiers. Hence, only compliers contribute to the effect of <span class="math inline">\(Z_i\)</span> on <span class="math inline">\(Y_i\)</span>.</p>
<div style="font-size:80%">
<p><span class="math display">\[
\begin{aligned}
\mathbb{E}[Y_i(1,D_i(1)) - Y_i(0,D_i(0))]
&amp;= \mathbb{E}[Y_i(1,D_i(1)) - Y_i(0,D_i(0)) \mid D_i(1)=1, D_i(0)=0]\cdot P(D_i(1)=1, D_i(0)=0)
\end{aligned}
\]</span></p>
</div>
<p>For compliers, <span class="math inline">\(D_i = Z_i\)</span>, so we can simplify <span class="math inline">\(Y_i(1,D_i(1)) = Y_i(1,1) = Y_i(1)\)</span> and <span class="math inline">\(Y_i(0,D_i(0)) = Y_i(0,0) = Y_i(0)\)</span>. Thus,
<span class="math display">\[
\mathbb{E}[Y_i(1) - Y_i(0)]
= \mathbb{E}[Y_i(1) - Y_i(0) \mid D_i(1) = 1, D_i(0) = 0] \cdot P(D_i(1) = 1, D_i(0) = 0),
\]</span>
which implies that
<span class="math display">\[
\tau_{LATE} = \mathbb{E}[Y_i(1) - Y_i(0) \mid D_i(1) = 1, D_i(0) = 0]
= \frac{\mathbb{E}[Y_i(1) - Y_i(0)]}{P(D_i(1) = 1, D_i(0) = 0)}.
\]</span></p>
<p>Under the assumption that the instrument <span class="math inline">\(Z_i\)</span> is independent of the potential outcomes (i.e., marginal exchangeability), we have
<span class="math display">\[
\tau_{LATE}
= \mathbb{E}[Y_i(1) - Y_i(0) \mid D_i(1) = 1, D_i(0) = 0]
= \frac{\mathbb{E}[Y_i \mid Z_i = 1] - \mathbb{E}[Y_i \mid Z_i = 0]}{P(D_i(1) = 1, D_i(0) = 0)}.
\]</span></p>
<p>We know that
<span class="math display">\[
P(D_i(1) = 1, D_i(0) = 0) = P(D_i = 1 \mid Z_i = 1) - P(D_i = 1 \mid Z_i = 0),
\]</span>
and taking into account that <span class="math inline">\(\mathbb{E}[D_i \mid Z_i] = P(D_i = 1 \mid Z_i)\)</span>, we obtain
<span class="math display">\[
\tau_{LATE}
= \frac{\mathbb{E}[Y_i \mid Z_i = 1] - \mathbb{E}[Y_i \mid Z_i = 0]}{\mathbb{E}[D_i \mid Z_i = 1] - \mathbb{E}[D_i \mid Z_i = 0]}.
\]</span></p>
<p>This is the standard instrumental variables (IV) estimand, often referred to as the <em>Wald estimator</em>. Note that the <em>relevance condition</em> is required to ensure identification, i.e.,
<span class="math display">\[
\mathbb{E}[D_i \mid Z_i = 1] - \mathbb{E}[D_i \mid Z_i = 0] \neq 0,
\]</span>
that is, the instrument is strong enough that some units actually comply, there is a proportion of compliers in the population.</p>
<p>The IV estimand represents the ratio of the intention-to-treat effect on the outcome to the intention-to-treat effect on the treatment (i.e., the proportion of compliers). The instrument induces random variation in treatment: the numerator captures how outcomes respond to the instrument, and the denominator captures how treatment responds to the instrument. Dividing the two isolates the causal effect for compliers.</p>
<p>Note that the LATE is not the global average causal effect, and has been subject to several criticisms. First, the proportion of compliers in the population may be small, raising concerns about the policy relevance of this estimand. Observe that while we cannot identify all four principal strata (compliers, never-takers, always-takers, and defiers), the proportion of compliers is identifiable. Second, the monotonicity assumption is not always plausible, particularly in observational studies where instruments may induce heterogeneous behavioral responses. Third, partitioning the population into four strata can become ill-defined in settings where instruments arise from different mechanisms or individual-specific criteria <span class="citation">(<a href="#ref-deaton2010instruments">Deaton 2010</a>; <a href="#ref-hernan2020causal">Hernán and Robins 2020</a>)</span>. For arguments in defense of LATE against these critiques, see <span class="citation">Angrist and Pischke (<a href="#ref-angrist2010better">2010</a>)</span>.</p>
<p><strong>Example: A simple setting for point- and set-identified LATE</strong></p>
<p>Assume we observe the following table.</p>
<table>
<caption><span id="tab:types">Table 13.3: </span> Distribution of units by type, instrument, treatment, and outcomes</caption>
<colgroup>
<col width="42%" />
<col width="15%" />
<col width="15%" />
<col width="15%" />
<col width="10%" />
</colgroup>
<thead>
<tr class="header">
<th>Type</th>
<th align="center"><span class="math inline">\(Z_{obs}\)</span></th>
<th align="center"><span class="math inline">\(D_{obs}\)</span></th>
<th align="center"><span class="math inline">\(Y_{obs}\)</span></th>
<th align="center">Units</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Compliers, Never-takers</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">3</td>
<td align="center">50</td>
</tr>
<tr class="even">
<td>Never-takers</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">4</td>
<td align="center">20</td>
</tr>
<tr class="odd">
<td>Compliers, Always-takers</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">7</td>
<td align="center">100</td>
</tr>
<tr class="even">
<td>Always-takers</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">5</td>
<td align="center">30</td>
</tr>
</tbody>
</table>
<p>Let’s calculate the LATE assuming exclusion restrictions, and without assuming exclusion restrictions.</p>
<p>We first estimate the <em>first stage</em> and <em>reduced form</em>:
<span class="math display">\[
\mathbb{E}[D\mid Z=0]=\tfrac{30}{80}=0.375,\qquad
\mathbb{E}[D\mid Z=1]=\tfrac{100}{120}\approx0.833,
\]</span>
<span class="math display">\[
\Delta_D=\mathbb{E}[D\mid Z=1]-\mathbb{E}[D\mid Z=0]\approx0.458.
\]</span></p>
<p><span class="math display">\[
\mathbb{E}[Y\mid Z=0]=\tfrac{3\cdot 50+5\cdot 30}{80}=3.75,\qquad
\mathbb{E}[Y\mid Z=1]=\tfrac{4\cdot 20+7\cdot 100}{120}=6.50,
\]</span>
<span class="math display">\[
\Delta_Y=\mathbb{E}[Y\mid Z=1]-\mathbb{E}[Y\mid Z=0]=2.75.
\]</span></p>
<p>Compliance shares:
<span class="math display">\[
\eta_a=P(D=1\mid Z=0)=\tfrac{3}{8}=0.375,\quad
\eta_c=\Delta_D=\tfrac{11}{24}\approx0.458,\quad
\eta_n=1-\eta_a-\eta_c=\tfrac{1}{6}\approx0.167.
\]</span></p>
<p>Then, we can <em>point-identified</em> the LATE under exclusion restriction,
the Wald estimand gives
<span class="math display">\[
\text{LATE}=\frac{\Delta_Y}{\Delta_D}=\frac{2.75}{0.458}=6.
\]</span></p>
<p>We achieved point identification by imposing the exclusion restriction, which requires that treatment assignment is unrelated to potential outcomes for never-takers and always-takers.<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a> This is,
<span class="math display">\[
\mathbb{E}[Y \mid Z=1, C=n] = \mathbb{E}[Y \mid Z=0, C=n],
\]</span>
and
<span class="math display">\[
\mathbb{E}[Y \mid Z=1, C=a] = \mathbb{E}[Y \mid Z=0, C=a].
\]</span></p>
<p>Without exclusion restrictions, we should take into account that
<span class="math display">\[
\delta_n = \mathbb{E}[Y \mid Z=1, C=n] - \mathbb{E}[Y \mid Z=0, C=n] \neq 0,
\]</span>
<span class="math display">\[
\delta_a = \mathbb{E}[Y \mid Z=1, C=a] - \mathbb{E}[Y \mid Z=0, C=a] \neq 0.
\]</span></p>
<p>Then
<span class="math display">\[
\Delta_Y = \eta_c \cdot \text{LATE} + \eta_n \delta_n + \eta_a \delta_a,
\]</span>
so that
<span class="math display">\[
\text{LATE} = \frac{\Delta_Y - \eta_n \delta_n - \eta_a \delta_a}{\eta_c}.
\]</span></p>
<p>From the table we know
<span class="math display">\[
\mathbb{E}[Y \mid Z=1, C=n] = 4, \quad \mathbb{E}[Y \mid Z=0, C=a] = 5.
\]</span></p>
<p>We assume that the bounding outcomes come from the observed support <span class="math inline">\(Y \in [3,7]\)</span>. Then,
<span class="math display">\[
\delta_n \in [-3,1], \quad \delta_a \in [-2,2].
\]</span></p>
<p>Therefore,
<span class="math display">\[
\text{LATE}_{\min} = \frac{\Delta_Y - \eta_n \cdot 1 - \eta_a \cdot 2}{\eta_c}
= 4,
\]</span></p>
<p><span class="math display">\[
\text{LATE}_{\max} = \frac{\Delta_Y - \eta_n (-3) - \eta_a (-2)}{\eta_c}
\approx 8.73.
\]</span></p>
<p>Then, without exclusion restrictions the LATE is <em>set identified</em>, <span class="math inline">\(\text{LATE} \in [4, 8.73]\)</span>, and with exclusion restrictions, the LATE is <em>point identified</em>, <span class="math inline">\(\text{LATE} = 6\)</span>.</p>
<p><strong>Example: Effects of vitamin A supplements on children’s survival</strong></p>
<p>This example is taken from <span class="citation">Guido W. Imbens and Rubin (<a href="#ref-imbens1997bayesian">1997</a>)</span>. The authors perform Bayesian inference for causal effects in a completely randomized experiment with no covariates and partial compliance. The experiment was conducted in Indonesia, where children were randomly assigned to receive vitamin A supplements. No individual assigned to the control group (<span class="math inline">\(Z_i = 0\)</span>) actually took the vitamin, meaning that <span class="math inline">\(D_i(0) = 1\)</span> was never observed. This rules out always-takers and defiers. However, some individuals assigned to the treatment group (<span class="math inline">\(Z_i = 1\)</span>) did not take the vitamin, so <span class="math inline">\(D_i(1) = 0\)</span> occurred for some units. Consequently, <span class="math inline">\(D_i(1) \geq D_i(0)\)</span> holds for all individuals (there are not defiers), satisfying the monotonicity assumption. Under this setting, the population consists only of compliers and never-takers.</p>
<table style="width:100%;">
<caption><span id="tab:exVit">Table 13.4: </span> Effects of vitamin A supplements on children’s survival</caption>
<colgroup>
<col width="22%" />
<col width="24%" />
<col width="23%" />
<col width="22%" />
<col width="6%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">Type</th>
<th align="center">Assignment <span class="math inline">\(Z_{\text{obs},i}\)</span></th>
<th align="center">Treatment <span class="math inline">\(D_{\text{obs},i}\)</span></th>
<th align="center">Survival <span class="math inline">\(Y_{\text{obs},i}\)</span></th>
<th align="center">Units</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Complier or never-taker</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">74</td>
</tr>
<tr class="even">
<td align="center">Complier or never-taker</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">11,514</td>
</tr>
<tr class="odd">
<td align="center">Never-taker</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">34</td>
</tr>
<tr class="even">
<td align="center">Never-taker</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">2,385</td>
</tr>
<tr class="odd">
<td align="center">Complier</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">12</td>
</tr>
<tr class="even">
<td align="center">Complier</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">9,663</td>
</tr>
</tbody>
</table>
<p>This table summarizes the data. Using this table, we can illustrate key concepts in the identification of causal effects with noncompliance. Let <span class="math inline">\(C_i\)</span> denote the compliance type of individual <span class="math inline">\(i\)</span>, which in this case can be either a complier (<span class="math inline">\(c\)</span>) or a never-taker (<span class="math inline">\(n\)</span>). The probability of being a complier, <span class="math inline">\(\omega := P(C_i = c)\)</span>, is given by</p>
<p><span class="math display">\[
P(C_i = c)
= \underbrace{P(D_i = 1 \mid Z_i = 1)}_{P(\text{compliers}) + P(\text{always-takers})}
- \underbrace{P(D_i = 1 \mid Z_i = 0)}_{P(\text{always-takers}) = 0}
= \frac{P(D_i = 1, Z_i = 1)}{P(Z_i = 1)}.
\]</span></p>
<p>Thus, the ML estimate is</p>
<p><span class="math display">\[
\hat{\omega} = \frac{12 + 9{,}663}{12 + 9{,}663 + 34 + 2{,}385}= 0.8.
\]</span></p>
<p>Note that <span class="math inline">\(P(C_i = n) = 1 - P(C_i = c)\)</span> in this example; thus, the ML estimate is <span class="math inline">\(1-\hat{\omega} = 0.2\)</span>.</p>
<p>The probability of survival for compliers assigned to treatment, <span class="math inline">\(\eta_{c1} := P(Y_i = 1 \mid C_i = c, Z_i = 1)\)</span>, is</p>
<p><span class="math display">\[
P(Y_i = 1 \mid C_i = c, Z_i = 1)
= \frac{P(Y_i = 1, C_i = c \mid Z_i = 1) \times P(Z_i = 1)}{P(C_i = c \mid Z_i = 1) \times P(Z_i = 1)}.
\]</span></p>
<p>Thus, the ML estimate is <span class="math inline">\(\hat{\eta}_{c1}= \tfrac{9{,}663}{9{,}663 + 12}= 0.999.\)</span></p>
<p>Similarly, the probability of survival for never-takers assigned to treatment, <span class="math inline">\(\eta_{n1} := P(Y_i = 1 \mid C_i = n, Z_i = 1)\)</span>, is</p>
<p><span class="math display">\[
P(Y_i = 1 \mid C_i = n, Z_i = 1)
= \frac{P(Y_i = 1, C_i = n \mid Z_i = 1) \times P(Z_i = 1)}{P(C_i = n \mid Z_i = 1) \times P(Z_i = 1)}.
\]</span></p>
<p>Consequently, the ML estimate is <span class="math inline">\(\hat{\eta}_{n1} = \tfrac{2{,}385}{2{,}385 + 34} = 0.986.\)</span></p>
<p>Note that <span class="math inline">\(\eta_{c0} = P(Y_i = 1 \mid C_i = c, Z_i = 0)\)</span> and <span class="math inline">\(\eta_{n0} = P(Y_i = 1 \mid C_i = n, Z_i = 0)\)</span> cannot be <em>point-identified</em>. However, we can obtain <em>set identification</em> because</p>
<div style="font-size:75%">
<p><span class="math display">\[
\eta_0:=P(Y_i = 1 \mid Z_i = 0)
= P(Y_i = 1 \mid Z_i = 0, C_i = c) \times P(C_i = c)
+ P(Y_i = 1 \mid Z_i = 0, C_i = n) \times P(C_i = n)
= \frac{P(Y_i = 1, Z_i = 0)}{P(Z_i = 0)},
\]</span></p>
</div>
<p>where the ML estimate is <span class="math inline">\(\hat{\eta}_0= \tfrac{11{,}514}{11{,}514 + 74}= 0.9936.\)</span></p>
<p>The first equality holds because the probability of survival given no treatment assignment is expressed as a mixture by the law of total probability, and the second equality follows from Bayes’ rule.</p>
<p>This implies that</p>
<p><span class="math display">\[
0.9936 = \hat{\omega} \hat{\eta}_{c0} + (1-\hat{\omega})\hat{\eta}_{n0},
\]</span></p>
<p>which leads to</p>
<p><span class="math display">\[
\hat{\eta}_{n0} = 4.968 - 4\hat{\eta}_{c0}.
\]</span></p>
<p>Given that probabilities must lie in the unit interval, such that <span class="math inline">\(0 \leq 4.968 - 4\hat{\eta}_{c0} \leq 1\)</span>, we obtain:<br />
(i) <span class="math inline">\(\hat{\eta}_{c0} \leq 1 \leq 1.242\)</span> (automatically satisfied), and<br />
(ii) <span class="math inline">\(4\hat{\eta}_{c0} \geq 4.968 - 1 = 3.968\)</span>, which implies <span class="math inline">\(\hat{\eta}_{c0} \geq 0.992\)</span>.</p>
<p>Consequently, the ML estimates are <span class="math inline">\(\hat{\eta}_{c0} \in [0.992, 1]\)</span> and <span class="math inline">\(\hat{\eta}_{n0} \in [0.968, 1]\)</span>.</p>
These results imply that the <em>complier average causal effect</em> (CACE) is<br />

<div style="font-size:80%">
<p><span class="math display">\[
\tau_{CACE} = \mathbb{E}[Y_i(1)-Y_i(0)\mid D_i(1)=1,D_i(0)=0]
= P[Y_i = 1 \mid C_i = c, Z_i = 1] - P[Y_i = 1 \mid C_i = c, Z_i = 0]
= \eta_{c1} - \eta_{c0}.
\]</span></p>
</div>
<p>The CACE is only set-identified, yielding the interval</p>
<p><span class="math display">\[
\hat{\tau}_{CACE} \in [-0.001, 0.007],
\]</span></p>
<p>meaning that the survival rate among compliers can vary between -1 and 7 per 1,000 children due to vitamin A supplementation.</p>
<p>Remember that point identification can be achieved by imposing the exclusion restriction, which requires that treatment assignment is unrelated to potential outcomes for never-takers and always-takers. Under this assumption,</p>
<p><span class="math display">\[
P(Y_i = y \mid C_i = n, Z_i = z) = P(Y_i = y \mid C_i = n),
\]</span></p>
<p>so that <span class="math inline">\(\hat{\eta}_{n1} = \hat{\eta}_{n0} = \hat{\eta}_n = 0.986\)</span>. Substituting into the mixture equation yields <span class="math inline">\(\hat{\eta}_{c0} = 0.9955\)</span>, and consequently,</p>
<p><span class="math display">\[
\hat{\tau}_{CACE} = 0.0035,
\]</span></p>
<p>indicating that survival increases by approximately 3.5 per 1,000 children due to vitamin A supplementation.<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a></p>
<p>We use conjugate families to perform Bayesian inference in this example. Specifically, we adopt the Bernoulli-Beta model (see Section <a href="sec42.html#sec42">3.2</a>) with independent non-informative Beta priors, each having parameters equal to 1. This corresponds to a uniform distribution on the interval <span class="math inline">\((0,1)\)</span>.</p>
<p>An advantage of the Bayesian formulation is that, after applying data augmentation with the compliance type <span class="math inline">\(C_i\)</span>, all the conditional posterior distributions are Beta (see <span class="citation">Guido W. Imbens and Rubin (<a href="#ref-imbens1997bayesian">1997</a>)</span> for details in derivations). In particular:</p>
<p><span class="math display">\[
\omega \mid \mathbf{C}, \mathbf{Z}_{\text{obs}}, \mathbf{D}_{\text{obs}}, \mathbf{Y}_{\text{obs}} \sim \text{Beta}(1 + N_c,\, 1 + N_n),
\]</span></p>
<p>where <span class="math inline">\(N_c\)</span> and <span class="math inline">\(N_n\)</span> denote the number of compliers and never-takers, respectively.</p>
<p><span class="math display">\[
\eta_{c1} \mid \mathbf{C}, \mathbf{Z}_{\text{obs}}, \mathbf{D}_{\text{obs}}, \mathbf{Y}_{\text{obs}} \sim \text{Beta}(1 + 9{,}663,\, 1 + 12),
\]</span></p>
<p><span class="math display">\[
\eta_{n1} \mid \mathbf{C}, \mathbf{Z}_{\text{obs}}, \mathbf{D}_{\text{obs}}, \mathbf{Y}_{\text{obs}} \sim \text{Beta}(1 + 2{,}385,\, 1 + 34),
\]</span></p>
<p><span class="math display">\[
\eta_{c0} \mid \mathbf{C}, \mathbf{Z}_{\text{obs}}, \mathbf{D}_{\text{obs}}, \mathbf{Y}_{\text{obs}} \sim \text{Beta}(1 + N_{c01},\, 1 + N_{c00}),
\]</span></p>
<p>where <span class="math inline">\(N_{c01}\)</span> and <span class="math inline">\(N_{c00}\)</span> are the numbers of compliers in the control group who survived and did not survive, respectively.</p>
<p><span class="math display">\[
\eta_{n0} \mid \mathbf{C}, \mathbf{Z}_{\text{obs}}, \mathbf{D}_{\text{obs}}, \mathbf{Y}_{\text{obs}} \sim \text{Beta}(1 + N_{n01},\, 1 + N_{n00}),
\]</span></p>
<p>where <span class="math inline">\(N_{n01}\)</span> and <span class="math inline">\(N_{n00}\)</span> are the numbers of never-takers in the control group who survived and did not survive, respectively.</p>
<p>In addition, the conditional probability of being a complier is given by:</p>
<p><span class="math display">\[
P(C_i = c \mid Z_{\text{obs},i}, D_{\text{obs},i}, Y_{\text{obs},i}) =
\begin{cases}
    0, &amp; i \in \{Z_i = 1, D_i = 0\},\\
    1, &amp; i \in \{Z_i = 1, D_i = 1\},\\
    \dfrac{\omega g_{c0,i}}{\omega g_{c0,i} + (1-\omega) g_{n0,i}}, &amp; i \in \{Z_i = 0\},
\end{cases}
\]</span></p>
<p>where <span class="math inline">\(g_{c0,i} = \eta_{c0}^{Y_{\text{obs},i}} (1 - \eta_{c0})^{1 - Y_{\text{obs},i}}\)</span> and <span class="math inline">\(g_{n0,i} = \eta_{n0}^{Y_{\text{obs},i}} (1 - \eta_{n0})^{1 - Y_{\text{obs},i}}\)</span>. Note that <span class="math inline">\(Y_{\text{obs},i} = 1\)</span> implies <span class="math inline">\(g_{c0,i} = \eta_{c0}\)</span> and <span class="math inline">\(g_{n0,i} = \eta_{n0}\)</span>, while <span class="math inline">\(Y_{\text{obs},i} = 0\)</span> implies <span class="math inline">\(g_{c0,i} = (1 - \eta_{c0})\)</span> and <span class="math inline">\(g_{n0,i} = (1 - \eta_{n0})\)</span>.</p>
<p>The following code shows the implementation, and the corresponding figure displays the posterior distribution of the CACE. The mean is 0.0024, and the 95% credible interval is (-0.0012, 0.0071).</p>
<p>We can perform inference by imposing the exclusion restriction, setting <span class="math inline">\(\eta_{n} = \eta_{n0} = \eta_{n1}\)</span>, so that the posterior distribution is</p>
<p><span class="math display">\[
\eta_{n} \mid \mathbf{C}, \mathbf{Z}_{\text{obs}}, \mathbf{D}_{\text{obs}}, \mathbf{Y}_{\text{obs}} \sim \text{Beta}(1 + N_{n1},\, 1 + N_{n0}),
\]</span></p>
<p>where <span class="math inline">\(N_{n1}\)</span> and <span class="math inline">\(N_{n0}\)</span> denote the numbers of never-takers who survived and did not survive, respectively. This is the only modification to the Gibbs sampler.</p>
<p>The second part of the code shows the implementation, and the second figure displays the posterior distribution of the CACE (which equals the LATE under the exclusion restriction). The posterior mean is 0.0030, and the 95% credible interval is (0.0008, 0.0054). Therefore, imposing the exclusion restriction leaves the posterior mean approximately unchanged but increases the precision and informativeness of the posterior distribution. Without the restriction, the posterior was relatively flat within the 95% credible interval, whereas under the exclusion restriction, the posterior distribution is approximately normal, resulting in a narrower 95% credible interval.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="sec13_4.html#cb4-1" tabindex="-1"></a><span class="fu">rm</span>(<span class="at">list =</span> <span class="fu">ls</span>()); <span class="fu">set.seed</span>(<span class="dv">10101</span>)</span>
<span id="cb4-2"><a href="sec13_4.html#cb4-2" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb4-3"><a href="sec13_4.html#cb4-3" tabindex="-1"></a><span class="co"># Simulate data</span></span>
<span id="cb4-4"><a href="sec13_4.html#cb4-4" tabindex="-1"></a>Nc111 <span class="ot">&lt;-</span> <span class="dv">9663</span></span>
<span id="cb4-5"><a href="sec13_4.html#cb4-5" tabindex="-1"></a>c111 <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="fu">rep</span>(<span class="dv">1</span>, Nc111), <span class="fu">rep</span>(<span class="dv">1</span>, Nc111), <span class="fu">rep</span>(<span class="dv">1</span>, Nc111)) </span>
<span id="cb4-6"><a href="sec13_4.html#cb4-6" tabindex="-1"></a>Nc110 <span class="ot">&lt;-</span> <span class="dv">12</span></span>
<span id="cb4-7"><a href="sec13_4.html#cb4-7" tabindex="-1"></a>c110 <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="fu">rep</span>(<span class="dv">1</span>, Nc110), <span class="fu">rep</span>(<span class="dv">1</span>, Nc110), <span class="fu">rep</span>(<span class="dv">0</span>, Nc110)) </span>
<span id="cb4-8"><a href="sec13_4.html#cb4-8" tabindex="-1"></a>Nn101 <span class="ot">&lt;-</span> <span class="dv">2385</span></span>
<span id="cb4-9"><a href="sec13_4.html#cb4-9" tabindex="-1"></a>n101 <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="fu">rep</span>(<span class="dv">1</span>, Nn101), <span class="fu">rep</span>(<span class="dv">0</span>, Nn101), <span class="fu">rep</span>(<span class="dv">1</span>, Nn101)) </span>
<span id="cb4-10"><a href="sec13_4.html#cb4-10" tabindex="-1"></a>Nn100 <span class="ot">&lt;-</span> <span class="dv">34</span></span>
<span id="cb4-11"><a href="sec13_4.html#cb4-11" tabindex="-1"></a>n100 <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="fu">rep</span>(<span class="dv">1</span>, Nn100), <span class="fu">rep</span>(<span class="dv">0</span>, Nn100), <span class="fu">rep</span>(<span class="dv">0</span>, Nn100)) </span>
<span id="cb4-12"><a href="sec13_4.html#cb4-12" tabindex="-1"></a>Ncn001 <span class="ot">&lt;-</span> <span class="dv">11514</span></span>
<span id="cb4-13"><a href="sec13_4.html#cb4-13" tabindex="-1"></a>cn001 <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="fu">rep</span>(<span class="dv">0</span>, Ncn001), <span class="fu">rep</span>(<span class="dv">0</span>, Ncn001), <span class="fu">rep</span>(<span class="dv">1</span>, Ncn001)) </span>
<span id="cb4-14"><a href="sec13_4.html#cb4-14" tabindex="-1"></a>Ncn000 <span class="ot">&lt;-</span> <span class="dv">74</span></span>
<span id="cb4-15"><a href="sec13_4.html#cb4-15" tabindex="-1"></a>cn000 <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="fu">rep</span>(<span class="dv">0</span>, Ncn000), <span class="fu">rep</span>(<span class="dv">0</span>, Ncn000), <span class="fu">rep</span>(<span class="dv">0</span>, Ncn000)) </span>
<span id="cb4-16"><a href="sec13_4.html#cb4-16" tabindex="-1"></a></span>
<span id="cb4-17"><a href="sec13_4.html#cb4-17" tabindex="-1"></a>mydata <span class="ot">&lt;-</span> <span class="fu">rbind</span>(c111, c110, n101, n100, cn001, cn000)</span>
<span id="cb4-18"><a href="sec13_4.html#cb4-18" tabindex="-1"></a>mydata <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">Z =</span> mydata[,<span class="dv">1</span>], <span class="at">D =</span> mydata[,<span class="dv">2</span>], <span class="at">Y =</span> mydata[,<span class="dv">3</span>])</span>
<span id="cb4-19"><a href="sec13_4.html#cb4-19" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="fu">dim</span>(mydata)[<span class="dv">1</span>]</span>
<span id="cb4-20"><a href="sec13_4.html#cb4-20" tabindex="-1"></a><span class="fu">attach</span>(mydata)</span>
<span id="cb4-21"><a href="sec13_4.html#cb4-21" tabindex="-1"></a></span>
<span id="cb4-22"><a href="sec13_4.html#cb4-22" tabindex="-1"></a><span class="co"># Sampling function C (type)</span></span>
<span id="cb4-23"><a href="sec13_4.html#cb4-23" tabindex="-1"></a>SampleType <span class="ot">&lt;-</span> <span class="cf">function</span>(z, d, y, wc, nc0, nn0){</span>
<span id="cb4-24"><a href="sec13_4.html#cb4-24" tabindex="-1"></a>    <span class="cf">if</span>(z <span class="sc">==</span> <span class="dv">1</span> <span class="sc">&amp;</span> d <span class="sc">==</span> <span class="dv">0</span>){</span>
<span id="cb4-25"><a href="sec13_4.html#cb4-25" tabindex="-1"></a>        pc <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb4-26"><a href="sec13_4.html#cb4-26" tabindex="-1"></a>    }<span class="cf">else</span>{</span>
<span id="cb4-27"><a href="sec13_4.html#cb4-27" tabindex="-1"></a>        <span class="cf">if</span>(z <span class="sc">==</span> <span class="dv">1</span> <span class="sc">&amp;</span> d <span class="sc">==</span> <span class="dv">1</span>){</span>
<span id="cb4-28"><a href="sec13_4.html#cb4-28" tabindex="-1"></a>            pc <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb4-29"><a href="sec13_4.html#cb4-29" tabindex="-1"></a>        }<span class="cf">else</span>{</span>
<span id="cb4-30"><a href="sec13_4.html#cb4-30" tabindex="-1"></a>            <span class="cf">if</span>(y <span class="sc">==</span> <span class="dv">1</span>){</span>
<span id="cb4-31"><a href="sec13_4.html#cb4-31" tabindex="-1"></a>                pc <span class="ot">&lt;-</span> (wc <span class="sc">*</span> nc0) <span class="sc">/</span> (wc <span class="sc">*</span> nc0 <span class="sc">+</span>  (<span class="dv">1</span> <span class="sc">-</span> wc) <span class="sc">*</span> nn0)</span>
<span id="cb4-32"><a href="sec13_4.html#cb4-32" tabindex="-1"></a>            }<span class="cf">else</span>{</span>
<span id="cb4-33"><a href="sec13_4.html#cb4-33" tabindex="-1"></a>                pc <span class="ot">&lt;-</span> (wc <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> nc0)) <span class="sc">/</span> (wc <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> nc0) <span class="sc">+</span>  (<span class="dv">1</span> <span class="sc">-</span> wc) <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> nn0))</span>
<span id="cb4-34"><a href="sec13_4.html#cb4-34" tabindex="-1"></a>            }</span>
<span id="cb4-35"><a href="sec13_4.html#cb4-35" tabindex="-1"></a>        }</span>
<span id="cb4-36"><a href="sec13_4.html#cb4-36" tabindex="-1"></a>    }</span>
<span id="cb4-37"><a href="sec13_4.html#cb4-37" tabindex="-1"></a>    <span class="fu">rbinom</span>(<span class="dv">1</span>, <span class="dv">1</span>, <span class="at">prob =</span> pc) <span class="co"># 1: Complier/ 0: Never taker</span></span>
<span id="cb4-38"><a href="sec13_4.html#cb4-38" tabindex="-1"></a>}</span>
<span id="cb4-39"><a href="sec13_4.html#cb4-39" tabindex="-1"></a>z <span class="ot">=</span> <span class="dv">0</span>; d <span class="ot">=</span> <span class="dv">0</span>; y <span class="ot">=</span> <span class="dv">0</span>; wc <span class="ot">=</span> <span class="fl">0.8</span>; nc0 <span class="ot">=</span> <span class="fl">0.9</span>; nn0 <span class="ot">=</span> <span class="fl">0.05</span></span>
<span id="cb4-40"><a href="sec13_4.html#cb4-40" tabindex="-1"></a><span class="fu">SampleType</span>(<span class="at">z =</span> z, <span class="at">d =</span> d, <span class="at">y =</span> y, <span class="at">wc =</span> wc, <span class="at">nc0 =</span> nc0, <span class="at">nn0 =</span> nn0)</span>
<span id="cb4-41"><a href="sec13_4.html#cb4-41" tabindex="-1"></a>Clat <span class="ot">&lt;-</span> <span class="fu">sapply</span>(<span class="dv">1</span><span class="sc">:</span>N, <span class="cf">function</span>(i){<span class="fu">SampleType</span>(<span class="at">z =</span> Z[i], <span class="at">d =</span> D[i], <span class="at">y =</span> Y[i], <span class="at">wc =</span> wc, <span class="at">nc0 =</span> nc0, <span class="at">nn0 =</span> nn0)})</span>
<span id="cb4-42"><a href="sec13_4.html#cb4-42" tabindex="-1"></a><span class="co"># Gibbs sampler</span></span>
<span id="cb4-43"><a href="sec13_4.html#cb4-43" tabindex="-1"></a>a0 <span class="ot">&lt;-</span> <span class="dv">1</span>; b0 <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="co"># Hyperparameters beta priors</span></span>
<span id="cb4-44"><a href="sec13_4.html#cb4-44" tabindex="-1"></a>burnin <span class="ot">&lt;-</span> <span class="dv">500</span>; S <span class="ot">&lt;-</span> <span class="dv">2000</span>; tot <span class="ot">&lt;-</span> S <span class="sc">+</span> burnin </span>
<span id="cb4-45"><a href="sec13_4.html#cb4-45" tabindex="-1"></a>PosteriorDraws <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="cn">NA</span>, tot, <span class="dv">5</span>)</span>
<span id="cb4-46"><a href="sec13_4.html#cb4-46" tabindex="-1"></a>pb <span class="ot">&lt;-</span> <span class="fu">txtProgressBar</span>(<span class="at">min =</span> <span class="dv">0</span>, <span class="at">max =</span> tot, <span class="at">style =</span> <span class="dv">3</span>)</span>
<span id="cb4-47"><a href="sec13_4.html#cb4-47" tabindex="-1"></a><span class="cf">for</span>(s <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>tot){</span>
<span id="cb4-48"><a href="sec13_4.html#cb4-48" tabindex="-1"></a>    dataLat <span class="ot">&lt;-</span> <span class="fu">cbind</span>(mydata, Clat)</span>
<span id="cb4-49"><a href="sec13_4.html#cb4-49" tabindex="-1"></a>    Nc011 <span class="ot">&lt;-</span> <span class="fu">sum</span>(dataLat<span class="sc">$</span>Z <span class="sc">==</span> <span class="dv">0</span> <span class="sc">&amp;</span> dataLat<span class="sc">$</span>Clat <span class="sc">==</span> <span class="dv">1</span> <span class="sc">&amp;</span> dataLat<span class="sc">$</span>Y <span class="sc">==</span> <span class="dv">1</span>)</span>
<span id="cb4-50"><a href="sec13_4.html#cb4-50" tabindex="-1"></a>    Nc010 <span class="ot">&lt;-</span> <span class="fu">sum</span>(dataLat<span class="sc">$</span>Z <span class="sc">==</span> <span class="dv">0</span> <span class="sc">&amp;</span> dataLat<span class="sc">$</span>Clat <span class="sc">==</span> <span class="dv">1</span> <span class="sc">&amp;</span> dataLat<span class="sc">$</span>Y <span class="sc">==</span> <span class="dv">0</span>)</span>
<span id="cb4-51"><a href="sec13_4.html#cb4-51" tabindex="-1"></a>    Nn001 <span class="ot">&lt;-</span> <span class="fu">sum</span>(dataLat<span class="sc">$</span>Z <span class="sc">==</span> <span class="dv">0</span> <span class="sc">&amp;</span> dataLat<span class="sc">$</span>Clat <span class="sc">==</span> <span class="dv">0</span> <span class="sc">&amp;</span> dataLat<span class="sc">$</span>Y <span class="sc">==</span> <span class="dv">1</span>)</span>
<span id="cb4-52"><a href="sec13_4.html#cb4-52" tabindex="-1"></a>    Nn000 <span class="ot">&lt;-</span> <span class="fu">sum</span>(dataLat<span class="sc">$</span>Z <span class="sc">==</span> <span class="dv">0</span> <span class="sc">&amp;</span> dataLat<span class="sc">$</span>Clat <span class="sc">==</span> <span class="dv">0</span> <span class="sc">&amp;</span> dataLat<span class="sc">$</span>Y <span class="sc">==</span> <span class="dv">0</span>)</span>
<span id="cb4-53"><a href="sec13_4.html#cb4-53" tabindex="-1"></a>    Nc <span class="ot">&lt;-</span> <span class="fu">sum</span>(Clat <span class="sc">==</span> <span class="dv">1</span>)</span>
<span id="cb4-54"><a href="sec13_4.html#cb4-54" tabindex="-1"></a>    Nn <span class="ot">&lt;-</span> <span class="fu">sum</span>(Clat <span class="sc">==</span> <span class="dv">0</span>)</span>
<span id="cb4-55"><a href="sec13_4.html#cb4-55" tabindex="-1"></a>    wc <span class="ot">&lt;-</span> <span class="fu">rbeta</span>(<span class="dv">1</span>, <span class="dv">1</span> <span class="sc">+</span> Nc, <span class="dv">1</span> <span class="sc">+</span> Nn)</span>
<span id="cb4-56"><a href="sec13_4.html#cb4-56" tabindex="-1"></a>    nc1 <span class="ot">&lt;-</span> <span class="fu">rbeta</span>(<span class="dv">1</span>, <span class="dv">1</span> <span class="sc">+</span> Nc111, <span class="dv">1</span> <span class="sc">+</span> Nc110)</span>
<span id="cb4-57"><a href="sec13_4.html#cb4-57" tabindex="-1"></a>    nn1 <span class="ot">&lt;-</span> <span class="fu">rbeta</span>(<span class="dv">1</span>, <span class="dv">1</span> <span class="sc">+</span> Nn101, <span class="dv">1</span> <span class="sc">+</span> Nn100)</span>
<span id="cb4-58"><a href="sec13_4.html#cb4-58" tabindex="-1"></a>    nc0 <span class="ot">&lt;-</span> <span class="fu">rbeta</span>(<span class="dv">1</span>, <span class="dv">1</span> <span class="sc">+</span> Nc011, <span class="dv">1</span> <span class="sc">+</span> Nc010)</span>
<span id="cb4-59"><a href="sec13_4.html#cb4-59" tabindex="-1"></a>    nn0 <span class="ot">&lt;-</span> <span class="fu">rbeta</span>(<span class="dv">1</span>, <span class="dv">1</span> <span class="sc">+</span> Nn001, <span class="dv">1</span> <span class="sc">+</span> Nn000)</span>
<span id="cb4-60"><a href="sec13_4.html#cb4-60" tabindex="-1"></a>    Clat <span class="ot">&lt;-</span> <span class="fu">sapply</span>(<span class="dv">1</span><span class="sc">:</span>N, <span class="cf">function</span>(i){<span class="fu">SampleType</span>(<span class="at">z =</span> Z[i], <span class="at">d =</span> D[i], <span class="at">y =</span> Y[i], <span class="at">wc =</span> wc, <span class="at">nc0 =</span> nc0, <span class="at">nn0 =</span> nn0)})</span>
<span id="cb4-61"><a href="sec13_4.html#cb4-61" tabindex="-1"></a>    PosteriorDraws[s, ] <span class="ot">&lt;-</span> <span class="fu">c</span>(wc, nc1, nc0, nn1, nn0)</span>
<span id="cb4-62"><a href="sec13_4.html#cb4-62" tabindex="-1"></a>    <span class="fu">setTxtProgressBar</span>(pb, s)</span>
<span id="cb4-63"><a href="sec13_4.html#cb4-63" tabindex="-1"></a>}</span>
<span id="cb4-64"><a href="sec13_4.html#cb4-64" tabindex="-1"></a><span class="fu">close</span>(pb)</span>
<span id="cb4-65"><a href="sec13_4.html#cb4-65" tabindex="-1"></a>keep <span class="ot">&lt;-</span> <span class="fu">seq</span>((burnin<span class="sc">+</span><span class="dv">1</span>), tot)</span>
<span id="cb4-66"><a href="sec13_4.html#cb4-66" tabindex="-1"></a>LATE <span class="ot">&lt;-</span> PosteriorDraws[keep, <span class="dv">2</span>] <span class="sc">-</span> PosteriorDraws[keep, <span class="dv">3</span>]</span>
<span id="cb4-67"><a href="sec13_4.html#cb4-67" tabindex="-1"></a>LATEmean <span class="ot">&lt;-</span> <span class="fu">mean</span>(LATE)</span>
<span id="cb4-68"><a href="sec13_4.html#cb4-68" tabindex="-1"></a>LATEci <span class="ot">&lt;-</span> <span class="fu">quantile</span>(LATE, <span class="fu">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>))</span>
<span id="cb4-69"><a href="sec13_4.html#cb4-69" tabindex="-1"></a></span>
<span id="cb4-70"><a href="sec13_4.html#cb4-70" tabindex="-1"></a><span class="co"># Plot posterior distribution of CATE</span></span>
<span id="cb4-71"><a href="sec13_4.html#cb4-71" tabindex="-1"></a><span class="fu">hist</span>(LATE, <span class="at">breaks =</span> <span class="dv">40</span>, <span class="at">freq =</span> <span class="cn">FALSE</span>,</span>
<span id="cb4-72"><a href="sec13_4.html#cb4-72" tabindex="-1"></a><span class="at">main =</span> <span class="st">&quot;Posterior Distribution of CACE&quot;</span>,</span>
<span id="cb4-73"><a href="sec13_4.html#cb4-73" tabindex="-1"></a><span class="at">xlab =</span> <span class="st">&quot;CACE&quot;</span>, <span class="at">col =</span> <span class="st">&quot;lightblue&quot;</span>, <span class="at">border =</span> <span class="st">&quot;white&quot;</span>)</span>
<span id="cb4-74"><a href="sec13_4.html#cb4-74" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> LATEmean, <span class="at">col =</span> <span class="st">&quot;red&quot;</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb4-75"><a href="sec13_4.html#cb4-75" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> LATEci, <span class="at">col =</span> <span class="st">&quot;darkgreen&quot;</span>, <span class="at">lty =</span> <span class="dv">2</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb4-76"><a href="sec13_4.html#cb4-76" tabindex="-1"></a></span>
<span id="cb4-77"><a href="sec13_4.html#cb4-77" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;topright&quot;</span>, <span class="at">legend =</span> <span class="fu">c</span>(<span class="st">&quot;Posterior Mean&quot;</span>, <span class="st">&quot;95% Credible Interval&quot;</span>),</span>
<span id="cb4-78"><a href="sec13_4.html#cb4-78" tabindex="-1"></a><span class="at">col =</span> <span class="fu">c</span>(<span class="st">&quot;red&quot;</span>, <span class="st">&quot;darkgreen&quot;</span>), <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">lty =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>),</span>
<span id="cb4-79"><a href="sec13_4.html#cb4-79" tabindex="-1"></a><span class="at">bty =</span> <span class="st">&quot;n&quot;</span>, <span class="at">cex =</span> <span class="fl">0.8</span>)  <span class="co"># Smaller legend using cex</span></span>
<span id="cb4-80"><a href="sec13_4.html#cb4-80" tabindex="-1"></a></span>
<span id="cb4-81"><a href="sec13_4.html#cb4-81" tabindex="-1"></a><span class="do">######## Imposing exclusion restrictions #########</span></span>
<span id="cb4-82"><a href="sec13_4.html#cb4-82" tabindex="-1"></a>PosteriorDrawsER <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="cn">NA</span>, tot, <span class="dv">4</span>)</span>
<span id="cb4-83"><a href="sec13_4.html#cb4-83" tabindex="-1"></a>pb <span class="ot">&lt;-</span> <span class="fu">txtProgressBar</span>(<span class="at">min =</span> <span class="dv">0</span>, <span class="at">max =</span> tot, <span class="at">style =</span> <span class="dv">3</span>)</span>
<span id="cb4-84"><a href="sec13_4.html#cb4-84" tabindex="-1"></a><span class="cf">for</span>(s <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>tot){</span>
<span id="cb4-85"><a href="sec13_4.html#cb4-85" tabindex="-1"></a>    dataLat <span class="ot">&lt;-</span> <span class="fu">cbind</span>(mydata, Clat)</span>
<span id="cb4-86"><a href="sec13_4.html#cb4-86" tabindex="-1"></a>    Nc011 <span class="ot">&lt;-</span> <span class="fu">sum</span>(dataLat<span class="sc">$</span>Z <span class="sc">==</span> <span class="dv">0</span> <span class="sc">&amp;</span> dataLat<span class="sc">$</span>Clat <span class="sc">==</span> <span class="dv">1</span> <span class="sc">&amp;</span> dataLat<span class="sc">$</span>Y <span class="sc">==</span> <span class="dv">1</span>)</span>
<span id="cb4-87"><a href="sec13_4.html#cb4-87" tabindex="-1"></a>    Nc010 <span class="ot">&lt;-</span> <span class="fu">sum</span>(dataLat<span class="sc">$</span>Z <span class="sc">==</span> <span class="dv">0</span> <span class="sc">&amp;</span> dataLat<span class="sc">$</span>Clat <span class="sc">==</span> <span class="dv">1</span> <span class="sc">&amp;</span> dataLat<span class="sc">$</span>Y <span class="sc">==</span> <span class="dv">0</span>)</span>
<span id="cb4-88"><a href="sec13_4.html#cb4-88" tabindex="-1"></a>    Nn01 <span class="ot">&lt;-</span> <span class="fu">sum</span>(dataLat<span class="sc">$</span>Clat <span class="sc">==</span> <span class="dv">0</span> <span class="sc">&amp;</span> dataLat<span class="sc">$</span>Y <span class="sc">==</span> <span class="dv">1</span>)</span>
<span id="cb4-89"><a href="sec13_4.html#cb4-89" tabindex="-1"></a>    Nn00 <span class="ot">&lt;-</span> <span class="fu">sum</span>(dataLat<span class="sc">$</span>Clat <span class="sc">==</span> <span class="dv">0</span> <span class="sc">&amp;</span> dataLat<span class="sc">$</span>Y <span class="sc">==</span> <span class="dv">0</span>)</span>
<span id="cb4-90"><a href="sec13_4.html#cb4-90" tabindex="-1"></a>    Nc <span class="ot">&lt;-</span> <span class="fu">sum</span>(Clat <span class="sc">==</span> <span class="dv">1</span>)</span>
<span id="cb4-91"><a href="sec13_4.html#cb4-91" tabindex="-1"></a>    Nn <span class="ot">&lt;-</span> <span class="fu">sum</span>(Clat <span class="sc">==</span> <span class="dv">0</span>)</span>
<span id="cb4-92"><a href="sec13_4.html#cb4-92" tabindex="-1"></a>    wc <span class="ot">&lt;-</span> <span class="fu">rbeta</span>(<span class="dv">1</span>, <span class="dv">1</span> <span class="sc">+</span> Nc, <span class="dv">1</span> <span class="sc">+</span> Nn)</span>
<span id="cb4-93"><a href="sec13_4.html#cb4-93" tabindex="-1"></a>    nc1 <span class="ot">&lt;-</span> <span class="fu">rbeta</span>(<span class="dv">1</span>, <span class="dv">1</span> <span class="sc">+</span> Nc111, <span class="dv">1</span> <span class="sc">+</span> Nc110)</span>
<span id="cb4-94"><a href="sec13_4.html#cb4-94" tabindex="-1"></a>    nn <span class="ot">&lt;-</span> <span class="fu">rbeta</span>(<span class="dv">1</span>, <span class="dv">1</span> <span class="sc">+</span> Nn01, <span class="dv">1</span> <span class="sc">+</span> Nn00)</span>
<span id="cb4-95"><a href="sec13_4.html#cb4-95" tabindex="-1"></a>    nc0 <span class="ot">&lt;-</span> <span class="fu">rbeta</span>(<span class="dv">1</span>, <span class="dv">1</span> <span class="sc">+</span> Nc011, <span class="dv">1</span> <span class="sc">+</span> Nc010)</span>
<span id="cb4-96"><a href="sec13_4.html#cb4-96" tabindex="-1"></a>    Clat <span class="ot">&lt;-</span> <span class="fu">sapply</span>(<span class="dv">1</span><span class="sc">:</span>N, <span class="cf">function</span>(i){<span class="fu">SampleType</span>(<span class="at">z =</span> Z[i], <span class="at">d =</span> D[i], <span class="at">y =</span> Y[i], <span class="at">wc =</span> wc, <span class="at">nc0 =</span> nc0, <span class="at">nn0 =</span> nn)})</span>
<span id="cb4-97"><a href="sec13_4.html#cb4-97" tabindex="-1"></a>    PosteriorDrawsER[s, ] <span class="ot">&lt;-</span> <span class="fu">c</span>(wc, nc1, nc0, nn)</span>
<span id="cb4-98"><a href="sec13_4.html#cb4-98" tabindex="-1"></a>    <span class="fu">setTxtProgressBar</span>(pb, s)</span>
<span id="cb4-99"><a href="sec13_4.html#cb4-99" tabindex="-1"></a>}</span>
<span id="cb4-100"><a href="sec13_4.html#cb4-100" tabindex="-1"></a><span class="fu">close</span>(pb)</span>
<span id="cb4-101"><a href="sec13_4.html#cb4-101" tabindex="-1"></a>keep <span class="ot">&lt;-</span> <span class="fu">seq</span>((burnin<span class="sc">+</span><span class="dv">1</span>), tot)</span>
<span id="cb4-102"><a href="sec13_4.html#cb4-102" tabindex="-1"></a>LATEER <span class="ot">&lt;-</span> PosteriorDrawsER[keep, <span class="dv">2</span>] <span class="sc">-</span> PosteriorDrawsER[keep, <span class="dv">3</span>]</span>
<span id="cb4-103"><a href="sec13_4.html#cb4-103" tabindex="-1"></a>LATEERmean <span class="ot">&lt;-</span> <span class="fu">mean</span>(LATEER)</span>
<span id="cb4-104"><a href="sec13_4.html#cb4-104" tabindex="-1"></a>LATEERci <span class="ot">&lt;-</span> <span class="fu">quantile</span>(LATEER, <span class="fu">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>))</span>
<span id="cb4-105"><a href="sec13_4.html#cb4-105" tabindex="-1"></a><span class="co"># Plot posterior distribution of LATE</span></span>
<span id="cb4-106"><a href="sec13_4.html#cb4-106" tabindex="-1"></a><span class="fu">hist</span>(LATEER, <span class="at">breaks =</span> <span class="dv">40</span>, <span class="at">freq =</span> <span class="cn">FALSE</span>, <span class="at">main =</span> <span class="st">&quot;Posterior Distribution of LATE: Exclusion restrictions&quot;</span>, <span class="at">xlab =</span> <span class="st">&quot;LATE&quot;</span>, <span class="at">col =</span> <span class="st">&quot;lightblue&quot;</span>, <span class="at">border =</span> <span class="st">&quot;white&quot;</span>)</span>
<span id="cb4-107"><a href="sec13_4.html#cb4-107" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> LATEERmean, <span class="at">col =</span> <span class="st">&quot;red&quot;</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb4-108"><a href="sec13_4.html#cb4-108" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> LATEERci, <span class="at">col =</span> <span class="st">&quot;darkgreen&quot;</span>, <span class="at">lty =</span> <span class="dv">2</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb4-109"><a href="sec13_4.html#cb4-109" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;topright&quot;</span>, <span class="at">legend =</span> <span class="fu">c</span>(<span class="st">&quot;Posterior Mean&quot;</span>, <span class="st">&quot;95% Credible Interval&quot;</span>), <span class="at">col =</span> <span class="fu">c</span>(<span class="st">&quot;red&quot;</span>, <span class="st">&quot;darkgreen&quot;</span>), <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">lty =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>), <span class="at">bty =</span> <span class="st">&quot;n&quot;</span>, <span class="at">cex =</span> <span class="fl">0.8</span>)</span></code></pre></div>
<p>This example illustrates how the Bayesian framework provides a way to quantify uncertainty and conduct sensitivity analysis regarding the exclusion restriction. See <span class="citation">Hirano et al. (<a href="#ref-hirano2000assessing">2000</a>)</span> for an extension controlling for covariates.</p>
<p>In addition, it is worth mentioning that in partially identified models, the asymptotic equivalence between Bayesian and Frequentist inference breaks down. In particular, credible sets for partially identified parameters tend to be smaller than confidence sets asymptotically <span class="citation">(<a href="#ref-MoonSchorfheide2012">Moon and Schorfheide 2012</a>)</span>. This occurs because the posterior remains asymptotically sensitive to the prior, and Bayesian credible sets lie strictly inside the true identified set. To address this disagreement, <span class="citation">Giacomini and Kitagawa (<a href="#ref-Giacomini2021">2021</a>)</span> propose a multi-prior robust Bayesian approach that helps reconcile Bayesian and Frequentist inference in set-identified models, which are a special case of partially identified models.</p>
<p><strong>Example: Treatment effect of 401(k) participation on net financial assets</strong></p>
<p>In the example of the effect of <em>eligibility</em> on 401(k) on net financial assets, we calculate the ITT effect. Now, following <span class="citation">Chernozhukov and Hansen (<a href="#ref-chernozhukov2004effects">2004</a>)</span>, we use eligibility as an instrument for <em>participation</em> and perform inference on the (local) average treatment effect. We adopt the framework described in Section <a href="sec73.html#sec73">7.3</a> for this example. The following code illustrates the procedure, and the figure displays the posterior distribution of the (local) average treatment effect of participation. The 95% credible interval is (USD 5,102, USD 12,010), and the posterior mean is USD 8,520, which is higher than the intention-to-treat effect associated with eligibility (USD 5,903).</p>
<p>Exercise~6 asks how to recover the ITT from the LATE and the effect of eligibility on participation. See <span class="citation">T. Conley, Hansen, and Rossi (<a href="#ref-Conley2012">2012</a>)</span> for practical methods to conduct sensitivity analysis of posterior results when relaxing the exclusion restriction in IV settings. In addition, <span class="citation">T. G. Conley et al. (<a href="#ref-conley2008semi">2008</a>)</span> present a Bayesian inferential framework using a semi-parametric approach in which stochastic errors are modeled using a Dirichlet process (see Exercise 7), and <span class="citation">Ramı́rez–Hassan and López-Vera (<a href="#ref-ramirez2024welfare">2024</a>)</span> extend this approach to systems of equations.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="sec13_4.html#cb5-1" tabindex="-1"></a><span class="fu">rm</span>(<span class="at">list =</span> <span class="fu">ls</span>()); <span class="fu">set.seed</span>(<span class="dv">10101</span>)</span>
<span id="cb5-2"><a href="sec13_4.html#cb5-2" tabindex="-1"></a><span class="fu">library</span>(coda); <span class="fu">library</span>(ggplot2)</span>
<span id="cb5-3"><a href="sec13_4.html#cb5-3" tabindex="-1"></a>mydata <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">&quot;https://raw.githubusercontent.com/BEsmarter-consultancy/BSTApp/refs/heads/master/DataApp/401k.csv&quot;</span>, <span class="at">sep =</span> <span class="st">&quot;,&quot;</span>, <span class="at">header =</span> <span class="cn">TRUE</span>, <span class="at">quote =</span> <span class="st">&quot;&quot;</span>)</span>
<span id="cb5-4"><a href="sec13_4.html#cb5-4" tabindex="-1"></a><span class="co"># Attach variables</span></span>
<span id="cb5-5"><a href="sec13_4.html#cb5-5" tabindex="-1"></a><span class="fu">attach</span>(mydata)</span>
<span id="cb5-6"><a href="sec13_4.html#cb5-6" tabindex="-1"></a>y <span class="ot">&lt;-</span> net_tfa<span class="sc">/</span><span class="dv">1000</span>  <span class="co"># Outcome: net financial assets</span></span>
<span id="cb5-7"><a href="sec13_4.html#cb5-7" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">as.vector</span>(p401) <span class="co"># Endogenous regressor: participation</span></span>
<span id="cb5-8"><a href="sec13_4.html#cb5-8" tabindex="-1"></a>w <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(<span class="fu">cbind</span>(<span class="dv">1</span>, age, inc, fsize, educ, marr, twoearn, db, pira, hown))  <span class="co"># Exogenous regressors with intercept</span></span>
<span id="cb5-9"><a href="sec13_4.html#cb5-9" tabindex="-1"></a>z <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(e401)  <span class="co"># Instrument: eligibility (NO intercept here)</span></span>
<span id="cb5-10"><a href="sec13_4.html#cb5-10" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">cbind</span>(x, w); Z <span class="ot">&lt;-</span> <span class="fu">cbind</span>(z, w)</span>
<span id="cb5-11"><a href="sec13_4.html#cb5-11" tabindex="-1"></a><span class="co"># Dimensions</span></span>
<span id="cb5-12"><a href="sec13_4.html#cb5-12" tabindex="-1"></a>k <span class="ot">&lt;-</span> <span class="fu">ncol</span>(X); kz <span class="ot">&lt;-</span> <span class="fu">ncol</span>(Z)  </span>
<span id="cb5-13"><a href="sec13_4.html#cb5-13" tabindex="-1"></a><span class="co"># Priors</span></span>
<span id="cb5-14"><a href="sec13_4.html#cb5-14" tabindex="-1"></a>b0 <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">0</span>, k); B0i <span class="ot">&lt;-</span> <span class="fu">diag</span>(<span class="fl">1e-5</span>, k)</span>
<span id="cb5-15"><a href="sec13_4.html#cb5-15" tabindex="-1"></a>g0 <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">0</span>, kz); G0i <span class="ot">&lt;-</span> <span class="fu">diag</span>(<span class="fl">1e-5</span>, kz)</span>
<span id="cb5-16"><a href="sec13_4.html#cb5-16" tabindex="-1"></a>nu <span class="ot">&lt;-</span> <span class="dv">3</span>; Psi0 <span class="ot">&lt;-</span> nu <span class="sc">*</span> <span class="dv">1000</span> <span class="sc">*</span> <span class="fu">diag</span>(<span class="dv">2</span>); Psi0i <span class="ot">&lt;-</span> <span class="fu">solve</span>(Psi0)</span>
<span id="cb5-17"><a href="sec13_4.html#cb5-17" tabindex="-1"></a><span class="co"># MCMC parameters</span></span>
<span id="cb5-18"><a href="sec13_4.html#cb5-18" tabindex="-1"></a>mcmc <span class="ot">&lt;-</span> <span class="dv">5000</span>; burnin <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb5-19"><a href="sec13_4.html#cb5-19" tabindex="-1"></a>tot <span class="ot">&lt;-</span> mcmc <span class="sc">+</span> burnin; thin <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb5-20"><a href="sec13_4.html#cb5-20" tabindex="-1"></a><span class="co"># Auxiliary elements</span></span>
<span id="cb5-21"><a href="sec13_4.html#cb5-21" tabindex="-1"></a>XtX <span class="ot">&lt;-</span> <span class="fu">t</span>(X)<span class="sc">%*%</span>X; ZtZ <span class="ot">&lt;-</span> <span class="fu">t</span>(Z)<span class="sc">%*%</span>Z; nun <span class="ot">&lt;-</span> nu <span class="sc">+</span> <span class="fu">length</span>(y)</span>
<span id="cb5-22"><a href="sec13_4.html#cb5-22" tabindex="-1"></a><span class="co"># Gibbs sampling</span></span>
<span id="cb5-23"><a href="sec13_4.html#cb5-23" tabindex="-1"></a>PostBeta <span class="ot">&lt;-</span> <span class="cf">function</span>(Sigma, Gamma){</span>
<span id="cb5-24"><a href="sec13_4.html#cb5-24" tabindex="-1"></a>    w1 <span class="ot">&lt;-</span> Sigma[<span class="dv">1</span>,<span class="dv">1</span>] <span class="sc">-</span> Sigma[<span class="dv">1</span>,<span class="dv">2</span>]<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span>Sigma[<span class="dv">2</span>,<span class="dv">2</span>]</span>
<span id="cb5-25"><a href="sec13_4.html#cb5-25" tabindex="-1"></a>    Bn <span class="ot">&lt;-</span> <span class="fu">solve</span>(w1<span class="sc">^</span>(<span class="sc">-</span><span class="dv">1</span>)<span class="sc">*</span>XtX <span class="sc">+</span> B0i)</span>
<span id="cb5-26"><a href="sec13_4.html#cb5-26" tabindex="-1"></a>    yaux <span class="ot">&lt;-</span> y <span class="sc">-</span> (Sigma[<span class="dv">1</span>,<span class="dv">2</span>]<span class="sc">/</span>Sigma[<span class="dv">2</span>,<span class="dv">2</span>])<span class="sc">*</span>(x <span class="sc">-</span> Z<span class="sc">%*%</span>Gamma)</span>
<span id="cb5-27"><a href="sec13_4.html#cb5-27" tabindex="-1"></a>    bn <span class="ot">&lt;-</span> Bn<span class="sc">%*%</span>(B0i<span class="sc">%*%</span>b0 <span class="sc">+</span> w1<span class="sc">^</span>(<span class="sc">-</span><span class="dv">1</span>)<span class="sc">*</span><span class="fu">t</span>(X)<span class="sc">%*%</span>yaux)</span>
<span id="cb5-28"><a href="sec13_4.html#cb5-28" tabindex="-1"></a>    Beta <span class="ot">&lt;-</span> MASS<span class="sc">::</span><span class="fu">mvrnorm</span>(<span class="dv">1</span>, bn, Bn)</span>
<span id="cb5-29"><a href="sec13_4.html#cb5-29" tabindex="-1"></a>    <span class="fu">return</span>(Beta)</span>
<span id="cb5-30"><a href="sec13_4.html#cb5-30" tabindex="-1"></a>}</span>
<span id="cb5-31"><a href="sec13_4.html#cb5-31" tabindex="-1"></a>PostGamma <span class="ot">&lt;-</span> <span class="cf">function</span>(Sigma, Beta){</span>
<span id="cb5-32"><a href="sec13_4.html#cb5-32" tabindex="-1"></a>    w2 <span class="ot">&lt;-</span> Sigma[<span class="dv">2</span>,<span class="dv">2</span>] <span class="sc">-</span> Sigma[<span class="dv">1</span>,<span class="dv">2</span>]<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span>Sigma[<span class="dv">1</span>,<span class="dv">1</span>]</span>
<span id="cb5-33"><a href="sec13_4.html#cb5-33" tabindex="-1"></a>    Gn <span class="ot">&lt;-</span> <span class="fu">solve</span>(w2<span class="sc">^</span>(<span class="sc">-</span><span class="dv">1</span>)<span class="sc">*</span>ZtZ <span class="sc">+</span> G0i)</span>
<span id="cb5-34"><a href="sec13_4.html#cb5-34" tabindex="-1"></a>    xaux <span class="ot">&lt;-</span> x <span class="sc">-</span> (Sigma[<span class="dv">1</span>,<span class="dv">2</span>]<span class="sc">/</span>Sigma[<span class="dv">1</span>,<span class="dv">1</span>])<span class="sc">*</span>(y <span class="sc">-</span> X<span class="sc">%*%</span>Beta)</span>
<span id="cb5-35"><a href="sec13_4.html#cb5-35" tabindex="-1"></a>    gn <span class="ot">&lt;-</span> Gn<span class="sc">%*%</span>(G0i<span class="sc">%*%</span>g0 <span class="sc">+</span> w2<span class="sc">^</span>(<span class="sc">-</span><span class="dv">1</span>)<span class="sc">*</span><span class="fu">t</span>(Z)<span class="sc">%*%</span>xaux)</span>
<span id="cb5-36"><a href="sec13_4.html#cb5-36" tabindex="-1"></a>    Gamma <span class="ot">&lt;-</span> MASS<span class="sc">::</span><span class="fu">mvrnorm</span>(<span class="dv">1</span>, gn, Gn)</span>
<span id="cb5-37"><a href="sec13_4.html#cb5-37" tabindex="-1"></a>    <span class="fu">return</span>(Gamma)</span>
<span id="cb5-38"><a href="sec13_4.html#cb5-38" tabindex="-1"></a>}</span>
<span id="cb5-39"><a href="sec13_4.html#cb5-39" tabindex="-1"></a>PostSigma <span class="ot">&lt;-</span> <span class="cf">function</span>(Beta, Gamma){</span>
<span id="cb5-40"><a href="sec13_4.html#cb5-40" tabindex="-1"></a>    Uy <span class="ot">&lt;-</span> y <span class="sc">-</span> X<span class="sc">%*%</span>Beta; Ux <span class="ot">&lt;-</span> x <span class="sc">-</span> Z<span class="sc">%*%</span>Gamma</span>
<span id="cb5-41"><a href="sec13_4.html#cb5-41" tabindex="-1"></a>    U <span class="ot">&lt;-</span> <span class="fu">cbind</span>(Uy, Ux)</span>
<span id="cb5-42"><a href="sec13_4.html#cb5-42" tabindex="-1"></a>    Psin <span class="ot">&lt;-</span> <span class="fu">solve</span>(Psi0i <span class="sc">+</span> <span class="fu">t</span>(U)<span class="sc">%*%</span>U)</span>
<span id="cb5-43"><a href="sec13_4.html#cb5-43" tabindex="-1"></a>    Sigmai <span class="ot">&lt;-</span> rWishart<span class="sc">::</span><span class="fu">rWishart</span>(<span class="dv">1</span>, <span class="at">df =</span> nun, <span class="at">Sigma =</span> Psin)</span>
<span id="cb5-44"><a href="sec13_4.html#cb5-44" tabindex="-1"></a>    Sigma <span class="ot">&lt;-</span> <span class="fu">solve</span>(Sigmai[,,<span class="dv">1</span>]) </span>
<span id="cb5-45"><a href="sec13_4.html#cb5-45" tabindex="-1"></a>    <span class="fu">return</span>(Sigma)</span>
<span id="cb5-46"><a href="sec13_4.html#cb5-46" tabindex="-1"></a>}</span>
<span id="cb5-47"><a href="sec13_4.html#cb5-47" tabindex="-1"></a>PostBetas <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="dv">0</span>, tot, k)</span>
<span id="cb5-48"><a href="sec13_4.html#cb5-48" tabindex="-1"></a>PostGammas <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="dv">0</span>, tot, kz)</span>
<span id="cb5-49"><a href="sec13_4.html#cb5-49" tabindex="-1"></a>PostSigmas <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="dv">0</span>, tot, <span class="dv">2</span><span class="sc">*</span>(<span class="dv">2</span><span class="sc">+</span><span class="dv">1</span>)<span class="sc">/</span><span class="dv">2</span>)</span>
<span id="cb5-50"><a href="sec13_4.html#cb5-50" tabindex="-1"></a>Beta <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">0</span>, k); Gamma <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">0</span>, kz)</span>
<span id="cb5-51"><a href="sec13_4.html#cb5-51" tabindex="-1"></a>pb <span class="ot">&lt;-</span> <span class="fu">txtProgressBar</span>(<span class="at">min =</span> <span class="dv">0</span>, <span class="at">max =</span> tot, <span class="at">style =</span> <span class="dv">3</span>)</span>
<span id="cb5-52"><a href="sec13_4.html#cb5-52" tabindex="-1"></a><span class="cf">for</span>(s <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>tot){</span>
<span id="cb5-53"><a href="sec13_4.html#cb5-53" tabindex="-1"></a>    Sigma <span class="ot">&lt;-</span> <span class="fu">PostSigma</span>(<span class="at">Beta =</span> Beta, <span class="at">Gamma =</span> Gamma)</span>
<span id="cb5-54"><a href="sec13_4.html#cb5-54" tabindex="-1"></a>    Beta <span class="ot">&lt;-</span> <span class="fu">PostBeta</span>(<span class="at">Sigma =</span> Sigma, <span class="at">Gamma =</span> Gamma)</span>
<span id="cb5-55"><a href="sec13_4.html#cb5-55" tabindex="-1"></a>    Gamma <span class="ot">&lt;-</span> <span class="fu">PostGamma</span>(<span class="at">Sigma =</span> Sigma, <span class="at">Beta =</span> Beta)</span>
<span id="cb5-56"><a href="sec13_4.html#cb5-56" tabindex="-1"></a>    PostBetas[s,] <span class="ot">&lt;-</span> Beta</span>
<span id="cb5-57"><a href="sec13_4.html#cb5-57" tabindex="-1"></a>    PostGammas[s,] <span class="ot">&lt;-</span> Gamma</span>
<span id="cb5-58"><a href="sec13_4.html#cb5-58" tabindex="-1"></a>    PostSigmas[s,] <span class="ot">&lt;-</span> matrixcalc<span class="sc">::</span><span class="fu">vech</span>(Sigma)</span>
<span id="cb5-59"><a href="sec13_4.html#cb5-59" tabindex="-1"></a>    <span class="fu">setTxtProgressBar</span>(pb, s)</span>
<span id="cb5-60"><a href="sec13_4.html#cb5-60" tabindex="-1"></a>}</span>
<span id="cb5-61"><a href="sec13_4.html#cb5-61" tabindex="-1"></a><span class="fu">close</span>(pb)</span>
<span id="cb5-62"><a href="sec13_4.html#cb5-62" tabindex="-1"></a>keep <span class="ot">&lt;-</span> <span class="fu">seq</span>((burnin<span class="sc">+</span><span class="dv">1</span>), tot, thin)</span>
<span id="cb5-63"><a href="sec13_4.html#cb5-63" tabindex="-1"></a>Bs <span class="ot">&lt;-</span> PostBetas[keep,]</span>
<span id="cb5-64"><a href="sec13_4.html#cb5-64" tabindex="-1"></a>Gs <span class="ot">&lt;-</span> PostGammas[keep,]</span>
<span id="cb5-65"><a href="sec13_4.html#cb5-65" tabindex="-1"></a>Sigmas <span class="ot">&lt;-</span> PostSigmas[keep,]</span>
<span id="cb5-66"><a href="sec13_4.html#cb5-66" tabindex="-1"></a><span class="fu">summary</span>(coda<span class="sc">::</span><span class="fu">mcmc</span>(Bs))</span>
<span id="cb5-67"><a href="sec13_4.html#cb5-67" tabindex="-1"></a><span class="fu">summary</span>(coda<span class="sc">::</span><span class="fu">mcmc</span>(Gs))</span>
<span id="cb5-68"><a href="sec13_4.html#cb5-68" tabindex="-1"></a><span class="fu">summary</span>(coda<span class="sc">::</span><span class="fu">mcmc</span>(Sigmas))</span>
<span id="cb5-69"><a href="sec13_4.html#cb5-69" tabindex="-1"></a><span class="co"># Extract posterior draws for the treatment effect (participation = p401)</span></span>
<span id="cb5-70"><a href="sec13_4.html#cb5-70" tabindex="-1"></a>beta_draws <span class="ot">&lt;-</span> Bs[,<span class="dv">1</span>]</span>
<span id="cb5-71"><a href="sec13_4.html#cb5-71" tabindex="-1"></a><span class="co"># Plot posterior distribution of treatment effect</span></span>
<span id="cb5-72"><a href="sec13_4.html#cb5-72" tabindex="-1"></a>df_beta <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">effect =</span> <span class="fu">as.vector</span>(beta_draws))</span>
<span id="cb5-73"><a href="sec13_4.html#cb5-73" tabindex="-1"></a><span class="fu">ggplot</span>(df_beta, <span class="fu">aes</span>(<span class="at">x =</span> effect)) <span class="sc">+</span> <span class="fu">geom_density</span>(<span class="at">fill =</span> <span class="st">&quot;steelblue&quot;</span>, <span class="at">alpha =</span> <span class="fl">0.6</span>) <span class="sc">+</span></span>
<span id="cb5-74"><a href="sec13_4.html#cb5-74" tabindex="-1"></a><span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="fu">mean</span>(beta_draws), <span class="at">color =</span> <span class="st">&quot;red&quot;</span>, <span class="at">linetype =</span> <span class="st">&quot;dashed&quot;</span>, <span class="at">linewidth =</span> <span class="dv">1</span>) <span class="sc">+</span> <span class="fu">labs</span>( <span class="at">title =</span> <span class="st">&quot;Posterior Distribution of 401(k) Participation Effect&quot;</span>, <span class="at">x =</span> <span class="fu">expression</span>(beta[<span class="st">&quot;p401&quot;</span>]), <span class="at">y =</span> <span class="st">&quot;Density&quot;</span>) <span class="sc">+</span> <span class="fu">theme_minimal</span>(<span class="at">base_size =</span> <span class="dv">14</span>)</span></code></pre></div>
</div>
<h3>References<a href="references.html#references" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-angrist1996identification" class="csl-entry">
Angrist, Joshua D., Guido W. Imbens, and Donald B. Rubin. 1996. <span>“Identification of Causal Effects Using Instrumental Variables.”</span> <em>Journal of the American Statistical Association</em> 91 (434): 444–55. <a href="https://doi.org/10.2307/2291629">https://doi.org/10.2307/2291629</a>.
</div>
<div id="ref-angrist2010better" class="csl-entry">
———. 2010. <span>“Better LATE Than Nothing: Some Comments on Deaton (2009) and Heckman and Urzua (2009).”</span> <em>Journal of Economic Literature</em> 48 (2): 399–423. <a href="https://doi.org/10.1257/jel.48.2.399">https://doi.org/10.1257/jel.48.2.399</a>.
</div>
<div id="ref-chernozhukov2004effects" class="csl-entry">
Chernozhukov, Victor, and Christian Hansen. 2004. <span>“The Effects of 401(k) Participation on the Wealth Distribution: An Instrumental Quantile Regression Analysis.”</span> <em>The Review of Economics and Statistics</em> 86 (3): 735–51. <a href="https://doi.org/10.1162/0034653041811749">https://doi.org/10.1162/0034653041811749</a>.
</div>
<div id="ref-Conley2012" class="csl-entry">
Conley, T., C. Hansen, and P. Rossi. 2012. <span>“Plausibly Exogenous.”</span> <em>The Review of Economics and Statistics</em> 94 (1): 260–72.
</div>
<div id="ref-conley2008semi" class="csl-entry">
Conley, Timothy G, Christian B Hansen, Robert E McCulloch, and Peter E Rossi. 2008. <span>“A Semi-Parametric Bayesian Approach to the Instrumental Variable Problem.”</span> <em>Journal of Econometrics</em> 144 (1): 276–305.
</div>
<div id="ref-cragg1993testing" class="csl-entry">
Cragg, John G., and Stephen G. Donald. 1993. <span>“Testing Identifiability and Specification in Instrumental Variable Models.”</span> <em>Econometric Theory</em> 9 (2): 222–40. <a href="https://doi.org/10.1017/S0266466600007519">https://doi.org/10.1017/S0266466600007519</a>.
</div>
<div id="ref-deaton2010instruments" class="csl-entry">
Deaton, Angus. 2010. <span>“Instruments, Randomization, and Learning about Development.”</span> <em>Journal of Economic Literature</em> 48 (2): 424–55. <a href="https://doi.org/10.1257/jel.48.2.424">https://doi.org/10.1257/jel.48.2.424</a>.
</div>
<div id="ref-Giacomini2021" class="csl-entry">
Giacomini, Raffaella, and Tetsuya Kitagawa. 2021. <span>“Robust Bayesian Inference for Set-Identified Models.”</span> <em>Econometrica</em> 89 (4): 1519–56. <a href="https://doi.org/10.3982/ECTA17276">https://doi.org/10.3982/ECTA17276</a>.
</div>
<div id="ref-hansen1982large" class="csl-entry">
Hansen, Lars Peter. 1982. <span>“Large Sample Properties of Generalized Method of Moments Estimators.”</span> <em>Econometrica</em> 50 (4): 1029–54. <a href="https://doi.org/10.2307/1912775">https://doi.org/10.2307/1912775</a>.
</div>
<div id="ref-hayashi2000econometrics" class="csl-entry">
Hayashi, Fumio. 2000. <em>Econometrics</em>. Princeton University Press.
</div>
<div id="ref-hernan2020causal" class="csl-entry">
Hernán, Miguel A., and James M. Robins. 2020. <em>Causal Inference: What If</em>. Boca Raton, FL: Chapman &amp; Hall/CRC. <a href="https://www.hsph.harvard.edu/miguel-hernan/causal-inference-book/">https://www.hsph.harvard.edu/miguel-hernan/causal-inference-book/</a>.
</div>
<div id="ref-hirano2000assessing" class="csl-entry">
Hirano, Keisuke, Guido W. Imbens, Donald B. Rubin, and Xiaohong Zhou. 2000. <span>“Assessing the Effect of an Influenza Vaccine in an Encouragement Design.”</span> <em>Biostatistics</em> 1 (1): 69–88. <a href="https://doi.org/10.1093/biostatistics/1.1.69">https://doi.org/10.1093/biostatistics/1.1.69</a>.
</div>
<div id="ref-imbens1994identification" class="csl-entry">
Imbens, Guido W., and Joshua D. Angrist. 1994. <span>“Identification and Estimation of Local Average Treatment Effects.”</span> <em>Econometrica</em> 62 (2): 467–75. <a href="https://doi.org/10.2307/2951620">https://doi.org/10.2307/2951620</a>.
</div>
<div id="ref-imbens1997bayesian" class="csl-entry">
Imbens, Guido W, and Donald B Rubin. 1997. <span>“Bayesian Inference for Causal Effects in Randomized Experiments with Noncompliance.”</span> <em>The Annals of Statistics</em>, 305–27.
</div>
<div id="ref-kleibergen2006generalized" class="csl-entry">
Kleibergen, Frank, and Richard Paap. 2006. <span>“Generalized Reduced Rank Tests Using the Singular Value Decomposition.”</span> <em>Journal of Econometrics</em> 133 (1): 97–126. <a href="https://doi.org/10.1016/j.jeconom.2005.02.011">https://doi.org/10.1016/j.jeconom.2005.02.011</a>.
</div>
<div id="ref-Manski1989" class="csl-entry">
Manski, Charles F. 1989. <span>“Anatomy of the Selection Problem.”</span> <em>The Journal of Human Resources</em> 24 (3): 343–60. <a href="https://doi.org/10.2307/145829">https://doi.org/10.2307/145829</a>.
</div>
<div id="ref-manski1990nonparametric" class="csl-entry">
———. 1990. <span>“Nonparametric Bounds on Treatment Effects.”</span> <em>American Economic Review</em> 80 (2): 319–23. <a href="https://www.jstor.org/stable/2006592">https://www.jstor.org/stable/2006592</a>.
</div>
<div id="ref-manski1995identification" class="csl-entry">
———. 1995. <em>Identification Problems in the Social Sciences</em>. Cambridge, MA: Harvard University Press.
</div>
<div id="ref-manski2003partial" class="csl-entry">
———. 2003. <em>Partial Identification of Probability Distributions</em>. New York: Springer. <a href="https://doi.org/10.1007/b97446">https://doi.org/10.1007/b97446</a>.
</div>
<div id="ref-MoonSchorfheide2012" class="csl-entry">
Moon, Hyungsik Roger, and Frank Schorfheide. 2012. <span>“Bayesian and Frequentist Inference in Partially Identified Models.”</span> <em>Econometrica</em> 80 (2): 755–82. <a href="https://doi.org/10.3982/ECTA8969">https://doi.org/10.3982/ECTA8969</a>.
</div>
<div id="ref-RamirezHassan2023" class="csl-entry">
Ramı́rez-Hassan, Andrés, Gustavo A. Garcı́a, Estefanı́a Saravia, Juan Fernando Duque, and Daniel Londoño. 2023. <span>“What Kind of Schools Parents Choose When They Have More Options? Effects of School Transport Subsidies.”</span> <em>Socio-Economic Planning Sciences</em> 87: 101509. <a href="https://doi.org/10.1016/j.seps.2023.101509">https://doi.org/10.1016/j.seps.2023.101509</a>.
</div>
<div id="ref-ramirez2024welfare" class="csl-entry">
Ramı́rez–Hassan, Andrés, and Alejandro López-Vera. 2024. <span>“Welfare Implications of a Tax on Electricity: A Semi-Parametric Specification of the Incomplete EASI Demand System.”</span> <em>Energy Economics</em> 131: 1–13.
</div>
<div id="ref-sargan1958econometric" class="csl-entry">
Sargan, John Denis. 1958. <span>“The Estimation of Economic Relationships Using Instrumental Variables.”</span> <em>Econometrica</em> 26 (3): 393–415. <a href="https://doi.org/10.2307/1907619">https://doi.org/10.2307/1907619</a>.
</div>
<div id="ref-staiger1997instrumental" class="csl-entry">
Staiger, Douglas, and James H. Stock. 1997. <span>“Instrumental Variables Regression with Weak Instruments.”</span> <em>Econometrica</em> 65 (3): 557–86. <a href="https://doi.org/10.2307/2171753">https://doi.org/10.2307/2171753</a>.
</div>
<div id="ref-stock2005asymptotic" class="csl-entry">
Stock, James H., and Motohiro Yogo. 2005. <span>“Asymptotic Distributions of Instrumental Variables Statistics with Many Instruments.”</span> In <em>Identification and Inference for Econometric Models: Essays in Honor of Thomas Rothenberg</em>, edited by Donald W. K. Andrews and James H. Stock, 109–20. Cambridge University Press.
</div>
<div id="ref-wooldridge2010econometric" class="csl-entry">
Wooldridge, Jeffrey M. 2010. <em>Econometric Analysis of Cross Section and Panel Data</em>. MIT press.
</div>
</div>
<div class="footnotes">
<hr />
<ol start="2">
<li id="fn2"><p>Note that under monotonicity, defiers are ruled out, whereas for compliers, the exclusion restriction is not a separate assumption: by construction, their potential outcomes are indexed only by treatment status, since the instrument deterministically shifts them between <span class="math inline">\(D_i=0\)</span> and <span class="math inline">\(D_i=1\)</span>. Thus, the exclusion restriction applies only to never-takers and always-takers, whose treatment status does not vary with the instrument.<a href="sec13_4.html#fnref2" class="footnote-back">↩︎</a></p></li>
<li id="fn3"><p>CACE and LATE refer to the same estimand —the average causal effect for compliers— under monotonicity and the exclusion restriction. If the exclusion restriction fails, they differ because LATE (as identified by IV) no longer equals the complier-specific causal effect (CACE).<a href="sec13_4.html#fnref3" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="sec13_3.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="sec13_5.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": true,
    "facebook": true,
    "twitter": true,
    "linkedin": false,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": false,
    "all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
  },
  "fontsettings": {
    "theme": "white",
    "family": "sans",
    "size": 2
  },
  "edit": {
    "link": "https://github.com/aramir21/IntroductionBayesianEconometricsBook/10-Diagnostics.Rmd",
    "text": "Edit"
  },
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": null,
    "text": null
  },
  "download": null,
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "subsection"
  }
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
