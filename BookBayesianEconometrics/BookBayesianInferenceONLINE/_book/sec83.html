<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>8.3 Stochastic volatility models | Introduction to Bayesian Econometrics</title>
  <meta name="description" content="The subject of this textbook is Bayesian data modeling, with the primary aim of providing an introduction to its theoretical foundations and facilitating the application of Bayesian inference using a GUI." />
  <meta name="generator" content="bookdown 0.43 and GitBook 2.6.7" />

  <meta property="og:title" content="8.3 Stochastic volatility models | Introduction to Bayesian Econometrics" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="The subject of this textbook is Bayesian data modeling, with the primary aim of providing an introduction to its theoretical foundations and facilitating the application of Bayesian inference using a GUI." />
  <meta name="github-repo" content="https://github.com/aramir21/IntroductionBayesianEconometricsBook" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="8.3 Stochastic volatility models | Introduction to Bayesian Econometrics" />
  
  <meta name="twitter:description" content="The subject of this textbook is Bayesian data modeling, with the primary aim of providing an introduction to its theoretical foundations and facilitating the application of Bayesian inference using a GUI." />
  

<meta name="author" content="Andrés Ramírez-Hassan" />


<meta name="date" content="2025-11-12" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="sec82.html"/>
<link rel="next" href="sec84.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Introduction to Bayesian Econometrics: A GUIded tour using R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction</a>
<ul>
<li class="chapter" data-level="" data-path="to-instructors-and-students.html"><a href="to-instructors-and-students.html"><i class="fa fa-check"></i>To instructors and students</a></li>
<li class="chapter" data-level="" data-path="acknowledgments.html"><a href="acknowledgments.html"><i class="fa fa-check"></i>Acknowledgments</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="Chap1.html"><a href="Chap1.html"><i class="fa fa-check"></i><b>1</b> Basic formal concepts</a>
<ul>
<li class="chapter" data-level="1.1" data-path="sec11.html"><a href="sec11.html"><i class="fa fa-check"></i><b>1.1</b> The Bayes’ rule</a></li>
<li class="chapter" data-level="1.2" data-path="sec12.html"><a href="sec12.html"><i class="fa fa-check"></i><b>1.2</b> Bayesian framework: A brief summary of theory</a></li>
<li class="chapter" data-level="1.3" data-path="sec14.html"><a href="sec14.html"><i class="fa fa-check"></i><b>1.3</b> Bayesian reports: Decision theory under uncertainty</a></li>
<li class="chapter" data-level="1.4" data-path="summary.html"><a href="summary.html"><i class="fa fa-check"></i><b>1.4</b> Summary</a></li>
<li class="chapter" data-level="1.5" data-path="exercises.html"><a href="exercises.html"><i class="fa fa-check"></i><b>1.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="Chap2.html"><a href="Chap2.html"><i class="fa fa-check"></i><b>2</b> Conceptual differences between the Bayesian and Frequentist approaches</a>
<ul>
<li class="chapter" data-level="2.1" data-path="sec21.html"><a href="sec21.html"><i class="fa fa-check"></i><b>2.1</b> The concept of probability</a></li>
<li class="chapter" data-level="2.2" data-path="sec22.html"><a href="sec22.html"><i class="fa fa-check"></i><b>2.2</b> Subjectivity is not the key</a></li>
<li class="chapter" data-level="2.3" data-path="sec23.html"><a href="sec23.html"><i class="fa fa-check"></i><b>2.3</b> Estimation, hypothesis testing and prediction</a></li>
<li class="chapter" data-level="2.4" data-path="sec24.html"><a href="sec24.html"><i class="fa fa-check"></i><b>2.4</b> The likelihood principle</a></li>
<li class="chapter" data-level="2.5" data-path="sec25.html"><a href="sec25.html"><i class="fa fa-check"></i><b>2.5</b> Why is not the Bayesian approach that popular?</a></li>
<li class="chapter" data-level="2.6" data-path="sec26.html"><a href="sec26.html"><i class="fa fa-check"></i><b>2.6</b> A simple working example</a></li>
<li class="chapter" data-level="2.7" data-path="sec27.html"><a href="sec27.html"><i class="fa fa-check"></i><b>2.7</b> Summary</a></li>
<li class="chapter" data-level="2.8" data-path="sec28.html"><a href="sec28.html"><i class="fa fa-check"></i><b>2.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="Chap3.html"><a href="Chap3.html"><i class="fa fa-check"></i><b>3</b> Cornerstone models: Conjugate families</a>
<ul>
<li class="chapter" data-level="3.1" data-path="sec41.html"><a href="sec41.html"><i class="fa fa-check"></i><b>3.1</b> Motivation of conjugate families</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="sec41.html"><a href="sec41.html#examples-of-exponential-family-distributions"><i class="fa fa-check"></i><b>3.1.1</b> Examples of exponential family distributions</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="sec42.html"><a href="sec42.html"><i class="fa fa-check"></i><b>3.2</b> Conjugate prior to exponential family</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="sec42.html"><a href="sec42.html#sec421"><i class="fa fa-check"></i><b>3.2.1</b> Examples: Theorem 4.2.1</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="sec43.html"><a href="sec43.html"><i class="fa fa-check"></i><b>3.3</b> Linear regression: The conjugate normal-normal/inverse gamma model</a></li>
<li class="chapter" data-level="3.4" data-path="sec44.html"><a href="sec44.html"><i class="fa fa-check"></i><b>3.4</b> Multivariate linear regression: The conjugate normal-normal/inverse Wishart model</a></li>
<li class="chapter" data-level="3.5" data-path="sec45.html"><a href="sec45.html"><i class="fa fa-check"></i><b>3.5</b> Summary</a></li>
<li class="chapter" data-level="3.6" data-path="sec46.html"><a href="sec46.html"><i class="fa fa-check"></i><b>3.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="Chap4.html"><a href="Chap4.html"><i class="fa fa-check"></i><b>4</b> Simulation methods</a>
<ul>
<li class="chapter" data-level="4.1" data-path="sec51.html"><a href="sec51.html"><i class="fa fa-check"></i><b>4.1</b> Markov Chain Monte Carlo methods</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="sec51.html"><a href="sec51.html#sec511"><i class="fa fa-check"></i><b>4.1.1</b> Gibbs sampler</a></li>
<li class="chapter" data-level="4.1.2" data-path="sec51.html"><a href="sec51.html#sec512"><i class="fa fa-check"></i><b>4.1.2</b> Metropolis-Hastings</a></li>
<li class="chapter" data-level="4.1.3" data-path="sec51.html"><a href="sec51.html#sec513"><i class="fa fa-check"></i><b>4.1.3</b> Hamiltonian Monte Carlo</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="sec52.html"><a href="sec52.html"><i class="fa fa-check"></i><b>4.2</b> Importance sampling</a></li>
<li class="chapter" data-level="4.3" data-path="sec53.html"><a href="sec53.html"><i class="fa fa-check"></i><b>4.3</b> Particle filtering</a></li>
<li class="chapter" data-level="4.4" data-path="sec54.html"><a href="sec54.html"><i class="fa fa-check"></i><b>4.4</b> Convergence diagnostics</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="sec54.html"><a href="sec54.html#numerical-standard-error"><i class="fa fa-check"></i><b>4.4.1</b> Numerical standard error</a></li>
<li class="chapter" data-level="4.4.2" data-path="sec54.html"><a href="sec54.html#effective-number-of-simulation-draws"><i class="fa fa-check"></i><b>4.4.2</b> Effective number of simulation draws</a></li>
<li class="chapter" data-level="4.4.3" data-path="sec54.html"><a href="sec54.html#tests-of-convergence"><i class="fa fa-check"></i><b>4.4.3</b> Tests of convergence</a></li>
<li class="chapter" data-level="4.4.4" data-path="sec54.html"><a href="sec54.html#checking-for-errors-in-the-posterior-simulator"><i class="fa fa-check"></i><b>4.4.4</b> Checking for errors in the posterior simulator</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="sec55.html"><a href="sec55.html"><i class="fa fa-check"></i><b>4.5</b> Summary</a></li>
<li class="chapter" data-level="4.6" data-path="sec56.html"><a href="sec56.html"><i class="fa fa-check"></i><b>4.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="Chap5.html"><a href="Chap5.html"><i class="fa fa-check"></i><b>5</b> Graphical user interface</a>
<ul>
<li class="chapter" data-level="5.1" data-path="secGUI1.html"><a href="secGUI1.html"><i class="fa fa-check"></i><b>5.1</b> Introduction</a></li>
<li class="chapter" data-level="5.2" data-path="secGUI2.html"><a href="secGUI2.html"><i class="fa fa-check"></i><b>5.2</b> Univariate models</a></li>
<li class="chapter" data-level="5.3" data-path="secGUI3.html"><a href="secGUI3.html"><i class="fa fa-check"></i><b>5.3</b> Multivariate models</a></li>
<li class="chapter" data-level="5.4" data-path="secGUI4.html"><a href="secGUI4.html"><i class="fa fa-check"></i><b>5.4</b> Time series models</a></li>
<li class="chapter" data-level="5.5" data-path="secGUI5.html"><a href="secGUI5.html"><i class="fa fa-check"></i><b>5.5</b> Longitudinal/panel models</a></li>
<li class="chapter" data-level="5.6" data-path="secGUI6.html"><a href="secGUI6.html"><i class="fa fa-check"></i><b>5.6</b> Bayesian model average</a></li>
<li class="chapter" data-level="5.7" data-path="secGUI7.html"><a href="secGUI7.html"><i class="fa fa-check"></i><b>5.7</b> Help</a></li>
<li class="chapter" data-level="5.8" data-path="secGUI8.html"><a href="secGUI8.html"><i class="fa fa-check"></i><b>5.8</b> Warning</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="Chap6.html"><a href="Chap6.html"><i class="fa fa-check"></i><b>6</b> Univariate models</a>
<ul>
<li class="chapter" data-level="6.1" data-path="sec61.html"><a href="sec61.html"><i class="fa fa-check"></i><b>6.1</b> The Gaussian linear model</a></li>
<li class="chapter" data-level="6.2" data-path="sec62.html"><a href="sec62.html"><i class="fa fa-check"></i><b>6.2</b> The logit model</a></li>
<li class="chapter" data-level="6.3" data-path="sec63.html"><a href="sec63.html"><i class="fa fa-check"></i><b>6.3</b> The probit model</a></li>
<li class="chapter" data-level="6.4" data-path="sec64.html"><a href="sec64.html"><i class="fa fa-check"></i><b>6.4</b> The multinomial probit model</a></li>
<li class="chapter" data-level="6.5" data-path="sec65.html"><a href="sec65.html"><i class="fa fa-check"></i><b>6.5</b> The multinomial logit model</a></li>
<li class="chapter" data-level="6.6" data-path="sec66.html"><a href="sec66.html"><i class="fa fa-check"></i><b>6.6</b> Ordered probit model</a></li>
<li class="chapter" data-level="6.7" data-path="negative-binomial-model.html"><a href="negative-binomial-model.html"><i class="fa fa-check"></i><b>6.7</b> Negative binomial model</a></li>
<li class="chapter" data-level="6.8" data-path="sec68.html"><a href="sec68.html"><i class="fa fa-check"></i><b>6.8</b> Tobit model</a></li>
<li class="chapter" data-level="6.9" data-path="sec69.html"><a href="sec69.html"><i class="fa fa-check"></i><b>6.9</b> Quantile regression</a></li>
<li class="chapter" data-level="6.10" data-path="sec610.html"><a href="sec610.html"><i class="fa fa-check"></i><b>6.10</b> Bayesian bootstrap regression</a></li>
<li class="chapter" data-level="6.11" data-path="sec611.html"><a href="sec611.html"><i class="fa fa-check"></i><b>6.11</b> Summary</a></li>
<li class="chapter" data-level="6.12" data-path="sec612.html"><a href="sec612.html"><i class="fa fa-check"></i><b>6.12</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="Chap7.html"><a href="Chap7.html"><i class="fa fa-check"></i><b>7</b> Multivariate models</a>
<ul>
<li class="chapter" data-level="7.1" data-path="sec71.html"><a href="sec71.html"><i class="fa fa-check"></i><b>7.1</b> Multivariate regression</a></li>
<li class="chapter" data-level="7.2" data-path="sec72.html"><a href="sec72.html"><i class="fa fa-check"></i><b>7.2</b> Seemingly Unrelated Regression</a></li>
<li class="chapter" data-level="7.3" data-path="sec73.html"><a href="sec73.html"><i class="fa fa-check"></i><b>7.3</b> Instrumental variable</a></li>
<li class="chapter" data-level="7.4" data-path="sec74.html"><a href="sec74.html"><i class="fa fa-check"></i><b>7.4</b> Multivariate probit model</a></li>
<li class="chapter" data-level="7.5" data-path="sec75.html"><a href="sec75.html"><i class="fa fa-check"></i><b>7.5</b> Summary</a></li>
<li class="chapter" data-level="7.6" data-path="sec76.html"><a href="sec76.html"><i class="fa fa-check"></i><b>7.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="Chap8.html"><a href="Chap8.html"><i class="fa fa-check"></i><b>8</b> Time series models</a>
<ul>
<li class="chapter" data-level="8.1" data-path="sec81.html"><a href="sec81.html"><i class="fa fa-check"></i><b>8.1</b> State-space representation</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="sec81.html"><a href="sec81.html#gaussian-linear-state-space-models"><i class="fa fa-check"></i><b>8.1.1</b> Gaussian linear state-space models</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="sec82.html"><a href="sec82.html"><i class="fa fa-check"></i><b>8.2</b> ARMA processes</a></li>
<li class="chapter" data-level="8.3" data-path="sec83.html"><a href="sec83.html"><i class="fa fa-check"></i><b>8.3</b> Stochastic volatility models</a></li>
<li class="chapter" data-level="8.4" data-path="sec84.html"><a href="sec84.html"><i class="fa fa-check"></i><b>8.4</b> Vector Autoregressive models</a></li>
<li class="chapter" data-level="8.5" data-path="sec85.html"><a href="sec85.html"><i class="fa fa-check"></i><b>8.5</b> Summary</a></li>
<li class="chapter" data-level="8.6" data-path="sec86.html"><a href="sec86.html"><i class="fa fa-check"></i><b>8.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="Chap9.html"><a href="Chap9.html"><i class="fa fa-check"></i><b>9</b> Longitudinal/Panel data models</a>
<ul>
<li class="chapter" data-level="9.1" data-path="sec91.html"><a href="sec91.html"><i class="fa fa-check"></i><b>9.1</b> Normal model</a></li>
<li class="chapter" data-level="9.2" data-path="sec92.html"><a href="sec92.html"><i class="fa fa-check"></i><b>9.2</b> Logit model</a></li>
<li class="chapter" data-level="9.3" data-path="sec93.html"><a href="sec93.html"><i class="fa fa-check"></i><b>9.3</b> Poisson model</a></li>
<li class="chapter" data-level="9.4" data-path="sec94.html"><a href="sec94.html"><i class="fa fa-check"></i><b>9.4</b> Summary</a></li>
<li class="chapter" data-level="9.5" data-path="sec95.html"><a href="sec95.html"><i class="fa fa-check"></i><b>9.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="Chap10.html"><a href="Chap10.html"><i class="fa fa-check"></i><b>10</b> Bayesian model averaging in variable selection</a>
<ul>
<li class="chapter" data-level="10.1" data-path="sec10_1.html"><a href="sec10_1.html"><i class="fa fa-check"></i><b>10.1</b> Foundation</a></li>
<li class="chapter" data-level="10.2" data-path="sec102.html"><a href="sec102.html"><i class="fa fa-check"></i><b>10.2</b> The Gaussian linear model</a></li>
<li class="chapter" data-level="10.3" data-path="sec103.html"><a href="sec103.html"><i class="fa fa-check"></i><b>10.3</b> Generalized linear models</a></li>
<li class="chapter" data-level="10.4" data-path="sec10_4.html"><a href="sec10_4.html"><i class="fa fa-check"></i><b>10.4</b> Calculating the marginal likelihood</a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="sec10_4.html"><a href="sec10_4.html#sec10_4_1"><i class="fa fa-check"></i><b>10.4.1</b> Savage-Dickey density ratio</a></li>
<li class="chapter" data-level="10.4.2" data-path="sec10_4.html"><a href="sec10_4.html#sec10_4_2"><i class="fa fa-check"></i><b>10.4.2</b> Chib’s methods</a></li>
<li class="chapter" data-level="10.4.3" data-path="sec10_4.html"><a href="sec10_4.html#sec10_4_3"><i class="fa fa-check"></i><b>10.4.3</b> Gelfand-Dey method</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="sec10_5.html"><a href="sec10_5.html"><i class="fa fa-check"></i><b>10.5</b> Summary</a></li>
<li class="chapter" data-level="10.6" data-path="sec10_6.html"><a href="sec10_6.html"><i class="fa fa-check"></i><b>10.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="Chap11.html"><a href="Chap11.html"><i class="fa fa-check"></i><b>11</b> Semi-parametric and non-parametric models</a>
<ul>
<li class="chapter" data-level="11.1" data-path="sec11_1.html"><a href="sec11_1.html"><i class="fa fa-check"></i><b>11.1</b> Mixture models</a>
<ul>
<li class="chapter" data-level="11.1.1" data-path="sec11_1.html"><a href="sec11_1.html#sec11_11"><i class="fa fa-check"></i><b>11.1.1</b> Finite Gaussian mixtures</a></li>
<li class="chapter" data-level="11.1.2" data-path="sec11_1.html"><a href="sec11_1.html#sec11_12"><i class="fa fa-check"></i><b>11.1.2</b> Direchlet processes</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="sec11_2.html"><a href="sec11_2.html"><i class="fa fa-check"></i><b>11.2</b> Splines</a></li>
<li class="chapter" data-level="11.3" data-path="sec11_3.html"><a href="sec11_3.html"><i class="fa fa-check"></i><b>11.3</b> Summary</a></li>
<li class="chapter" data-level="11.4" data-path="sec11_4.html"><a href="sec11_4.html"><i class="fa fa-check"></i><b>11.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="Chap12.html"><a href="Chap12.html"><i class="fa fa-check"></i><b>12</b> Bayesian machine learning</a>
<ul>
<li class="chapter" data-level="12.1" data-path="sec12_1.html"><a href="sec12_1.html"><i class="fa fa-check"></i><b>12.1</b> Cross-validation and Bayes factors</a></li>
<li class="chapter" data-level="12.2" data-path="sec12_2.html"><a href="sec12_2.html"><i class="fa fa-check"></i><b>12.2</b> Regularization</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="sec12_2.html"><a href="sec12_2.html#sec12_21"><i class="fa fa-check"></i><b>12.2.1</b> Bayesian LASSO</a></li>
<li class="chapter" data-level="12.2.2" data-path="sec12_2.html"><a href="sec12_2.html#sec12_22"><i class="fa fa-check"></i><b>12.2.2</b> Stochastic search variable selection</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="sec12_3.html"><a href="sec12_3.html"><i class="fa fa-check"></i><b>12.3</b> Bayesian additive regression trees</a></li>
<li class="chapter" data-level="12.4" data-path="sec12_4.html"><a href="sec12_4.html"><i class="fa fa-check"></i><b>12.4</b> Gaussian processes</a></li>
<li class="chapter" data-level="12.5" data-path="sec12_5.html"><a href="sec12_5.html"><i class="fa fa-check"></i><b>12.5</b> Tall data problems</a>
<ul>
<li class="chapter" data-level="12.5.1" data-path="sec12_5.html"><a href="sec12_5.html#sec12_51"><i class="fa fa-check"></i><b>12.5.1</b> Divide-and-conquer methods</a></li>
<li class="chapter" data-level="12.5.2" data-path="sec12_5.html"><a href="sec12_5.html#sec12_52"><i class="fa fa-check"></i><b>12.5.2</b> Subsampling-based algorithms</a></li>
</ul></li>
<li class="chapter" data-level="12.6" data-path="id_13_6.html"><a href="id_13_6.html"><i class="fa fa-check"></i><b>12.6</b> Summary</a></li>
<li class="chapter" data-level="12.7" data-path="id_13_7.html"><a href="id_13_7.html"><i class="fa fa-check"></i><b>12.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="Chap13.html"><a href="Chap13.html"><i class="fa fa-check"></i><b>13</b> Causal inference</a>
<ul>
<li class="chapter" data-level="13.1" data-path="sec13_1.html"><a href="sec13_1.html"><i class="fa fa-check"></i><b>13.1</b> Identification setting</a></li>
<li class="chapter" data-level="13.2" data-path="sec13_2.html"><a href="sec13_2.html"><i class="fa fa-check"></i><b>13.2</b> Randomized controlled trial (RCT)</a></li>
<li class="chapter" data-level="13.3" data-path="sec13_3.html"><a href="sec13_3.html"><i class="fa fa-check"></i><b>13.3</b> Conditional independence assumption (CIA)</a></li>
<li class="chapter" data-level="13.4" data-path="sec13_4.html"><a href="sec13_4.html"><i class="fa fa-check"></i><b>13.4</b> Instrumental variables (IV)</a></li>
<li class="chapter" data-level="13.5" data-path="sec13_5.html"><a href="sec13_5.html"><i class="fa fa-check"></i><b>13.5</b> Difference-in-differences design (DiD)</a>
<ul>
<li class="chapter" data-level="13.5.1" data-path="sec13_5.html"><a href="sec13_5.html#sec13_51"><i class="fa fa-check"></i><b>13.5.1</b> Classic DiD: two-group and two-period (<span class="math inline">\(2\times2\)</span>) setup</a></li>
<li class="chapter" data-level="13.5.2" data-path="sec13_5.html"><a href="sec13_5.html#sec13_52"><i class="fa fa-check"></i><b>13.5.2</b> Staggered (SDiD): G-group and T-period (<span class="math inline">\(G\times T\)</span>) setup</a></li>
</ul></li>
<li class="chapter" data-level="13.6" data-path="sec13_6.html"><a href="sec13_6.html"><i class="fa fa-check"></i><b>13.6</b> Regression discontinuity design (RD)</a>
<ul>
<li class="chapter" data-level="13.6.1" data-path="sec13_6.html"><a href="sec13_6.html#sec13_61"><i class="fa fa-check"></i><b>13.6.1</b> Sharp regression discontinuity design (SRD)</a></li>
<li class="chapter" data-level="13.6.2" data-path="sec13_6.html"><a href="sec13_6.html#sec13_62"><i class="fa fa-check"></i><b>13.6.2</b> Fuzzy regression discontinuity design (FRD)</a></li>
</ul></li>
<li class="chapter" data-level="13.7" data-path="sec13_7.html"><a href="sec13_7.html"><i class="fa fa-check"></i><b>13.7</b> Sample selection</a></li>
<li class="chapter" data-level="13.8" data-path="sec13_8.html"><a href="sec13_8.html"><i class="fa fa-check"></i><b>13.8</b> Bayesian exponentially tilted empirical likelihood</a></li>
<li class="chapter" data-level="13.9" data-path="sec13_9.html"><a href="sec13_9.html"><i class="fa fa-check"></i><b>13.9</b> General Bayes posteriors</a></li>
<li class="chapter" data-level="13.10" data-path="sec13_10.html"><a href="sec13_10.html"><i class="fa fa-check"></i><b>13.10</b> Doubly robust Bayesian inferential framework (DRB)</a></li>
<li class="chapter" data-level="13.11" data-path="sec13_11.html"><a href="sec13_11.html"><i class="fa fa-check"></i><b>13.11</b> Summary</a></li>
<li class="chapter" data-level="13.12" data-path="sec13_12.html"><a href="sec13_12.html"><i class="fa fa-check"></i><b>13.12</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="Chap14.html"><a href="Chap14.html"><i class="fa fa-check"></i><b>14</b> Approximate Bayesian methods</a>
<ul>
<li class="chapter" data-level="14.1" data-path="sec14_1.html"><a href="sec14_1.html"><i class="fa fa-check"></i><b>14.1</b> Simulation-based approaches</a>
<ul>
<li class="chapter" data-level="14.1.1" data-path="sec14_1.html"><a href="sec14_1.html#sec14_11"><i class="fa fa-check"></i><b>14.1.1</b> Approximate Bayesian computation</a></li>
<li class="chapter" data-level="14.1.2" data-path="sec14_1.html"><a href="sec14_1.html#sec14_12"><i class="fa fa-check"></i><b>14.1.2</b> Bayesian synthetic likelihood</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="sec14_2.html"><a href="sec14_2.html"><i class="fa fa-check"></i><b>14.2</b> Optimization approaches</a>
<ul>
<li class="chapter" data-level="14.2.1" data-path="sec14_2.html"><a href="sec14_2.html#sec14_21"><i class="fa fa-check"></i><b>14.2.1</b> Integrated nested Laplace approximations</a></li>
<li class="chapter" data-level="14.2.2" data-path="sec14_2.html"><a href="sec14_2.html#sec14_22"><i class="fa fa-check"></i><b>14.2.2</b> Variational Bayes</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="summary-1.html"><a href="summary-1.html"><i class="fa fa-check"></i><b>14.3</b> Summary</a></li>
<li class="chapter" data-level="14.4" data-path="sec14_4.html"><a href="sec14_4.html"><i class="fa fa-check"></i><b>14.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i>Appendix</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to Bayesian Econometrics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="sec83" class="section level2 hasAnchor" number="8.3">
<h2><span class="header-section-number">8.3</span> Stochastic volatility models<a href="sec83.html#sec83" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>A notable example of non-linear and non-Gaussian <em>state-space models</em> is stochastic volatility models (SVMs), which are widely used to model the volatility of financial returns. SVMs have gained significant attention due to their flexibility, ability to capture complex dynamics such as asymmetries, and ease of generalization to simultaneously model multiple returns, making them advantageous over generalized autoregressive conditional heteroskedasticity (GARCH) models proposed by <span class="citation">Bollerslev (<a href="#ref-bollerslev_1986">1986</a>)</span>. However, estimating SVMs is more challenging than estimating GARCH models. This is because GARCH models set variance in a deterministic manner, whereas SVMs do so stochastically. Consequently, GARCH models are typically estimated using maximum likelihood methods, while SVMs require Bayesian approaches, adding complexity to the estimation process.</p>
<p>The specification of the stochastic volatility model is given by
<span class="math display" id="eq:eqsvst" id="eq:eqsvobs">\[\begin{align}
    y_t&amp;=\boldsymbol{x}_t^{\top}\boldsymbol{\beta}+\exp\left\{0.5h_t\right\}\mu_t&amp; \text{(Observation equation)} \tag{8.8}\\
    h_t&amp;=\mu+\phi(h_{t-1}-\mu)+\sigma w_t&amp; \text{(State equation)} \tag{8.9},
\end{align}\]</span>
where <span class="math inline">\(y_t\)</span> are the log-returns, <span class="math inline">\(\boldsymbol{x}_t\)</span> are controls, <span class="math inline">\(\boldsymbol{\beta}\)</span> are time-invariant location parameters, <span class="math inline">\(\mu_t\sim N(0,1)\)</span>, <span class="math inline">\(w_t\sim N(0,1)\)</span>, <span class="math inline">\(\mu_t\perp w_t\)</span>, the initial log-variance process <span class="math inline">\(h_0\sim N(\mu, \sigma^2/(1-\phi^2))\)</span>, <span class="math inline">\(\mu\)</span>, <span class="math inline">\(\phi\)</span> and <span class="math inline">\(\sigma\)</span> are the level, persistence and standard deviation of the log-variance, respectively.</p>
<p>Given the specification in Equations <a href="sec83.html#eq:eqsvobs">(8.8)</a> and <a href="sec83.html#eq:eqsvst">(8.9)</a>, we can write the observation equation as
<span class="math display">\[
\log\left\{(y_t-\boldsymbol{x}_t^{\top}\boldsymbol{\beta})^2\right\} = h_t + \log(\mu_t^2),
\]</span>
which leads to a linear, but non-Gaussian, <em>state-space model</em>. <span class="citation">Kastner and Frühwirth-Schnatter (<a href="#ref-kastner2014ancillarity">2014</a>)</span> approximate the distribution of <span class="math inline">\(\log(\mu_t^2)\)</span> by a mixture of normal distributions, that is,
<span class="math display">\[
\log(\mu_t^2)\mid l_t \sim N(m_{l_t},s_{l_t}^2),
\]</span>
where <span class="math inline">\(l_t \in \{1, 2, \dots, 10\}\)</span> defines the mixture component indicator at time <span class="math inline">\(t\)</span>. Thus, the model can be written as
<span class="math display">\[
\log\left\{(y_t-\boldsymbol{x}_t^{\top}\boldsymbol{\beta})^2\right\} = h_t + \log(\mu_t^2),
\]</span>
and
<span class="math display">\[
h_t = \mu + \phi(h_{t-1} - \mu) + \sigma w_t.
\]</span>
This forms a linear and conditionally Gaussian <em>state-space model</em>, where
<span class="math display">\[
\log\left\{(y_t-\boldsymbol{x}_t^{\top}\boldsymbol{\beta})^2\right\} = m_{l_t} + h_t + \mu_t,
\]</span>
and
<span class="math display">\[
\mu_t \sim N(0, s_{l_t}^2).
\]</span></p>
<p>We use the <em>stochvol</em> package in our GUI to perform MCMC inference in the SVMs <span class="citation">(<a href="#ref-hosszejni_kastner_2021">Hosszejni and Kastner 2021</a>)</span>; this package is based on the MCMC algorithms proposed by <span class="citation">Kastner and Frühwirth-Schnatter (<a href="#ref-kastner2014ancillarity">2014</a>)</span>. The default prior distributions in the <em>stochvol</em> package are:
<span class="math display">\[
\boldsymbol{\beta} \sim N(\boldsymbol{b}_0, \boldsymbol{B}_0), \quad \mu \sim N(\mu_0, \sigma_{\mu0}^2), \quad \frac{\phi+1}{2} \sim B(\alpha_0, \beta_0), \quad \sigma^2 \sim G\left(\frac{1}{2}, \frac{1}{2\sigma^2_{\sigma^2}}\right).
\]</span>
The prior distribution for <span class="math inline">\(\phi\)</span> is set to ensure stationarity of the process (<span class="math inline">\(\phi \in (-1,1)\)</span>). In most applications, <span class="math inline">\(\phi \approx 1\)</span>, so the authors of the package recommend setting <span class="math inline">\(\alpha_0 \gtrsim 5\)</span> and <span class="math inline">\(\beta_0 \approx 1.5\)</span>. The prior distribution for <span class="math inline">\(\sigma\)</span> is <span class="math inline">\(|N(0, \sigma^2_{\sigma^2})|\)</span> (a half-normal distribution). This is recommended by the authors since the conjugate inverse-gamma distribution does not work well in this case, as it bounds <span class="math inline">\(\sigma\)</span> away from 0, which is undesirable when modeling the log-variance of log-returns.</p>
<p>The following Algorithm shows how to perform inference in stochastic volatility models using our GUI. See also Chapter <a href="Chap5.html#Chap5">5</a> for details regarding the dataset structure.</p>
<div class="algorithm">
<div style="background-color: #f8f9fa; padding: 15px; border-left: 5px solid #343a40; box-shadow: 4px 4px 10px rgba(0, 0, 0, 0.1); border-radius: 5px;">
<p><strong>Algorithm: Stochastic Volatility Models</strong></p>
<ol style="list-style-type: decimal">
<li><p>Select <em>Time series Model</em> on the top panel</p></li>
<li><p>Select <em>Stochastic volatility</em> using the left radio button</p></li>
<li><p>Upload the dataset selecting first if there is a header in the file, and the kind of separator in the <em>csv</em> file of the dataset (comma, semicolon, or tab). Then, use the <em>Browse</em> button under the <strong>Choose File</strong> legend</p></li>
<li><p>Select MCMC iterations, burn-in, and thinning parameters using the <em>Range sliders</em></p></li>
<li><p>Set the hyperparameters: the mean and standard deviation of the Gaussian prior for the regression parameters, mean and standard deviation for the Gaussian prior distribution of the level of the log-volatility, shape parameters for the Beta prior distribution of the transformed persistence parameter, and the positive real number, which stands for the scaling of the transformed volatility of log-volatility. This step is not necessary as by default our GUI uses default values in the <em>stochvol</em> package</p></li>
<li><p>Click the <em>Go!</em> button</p></li>
<li><p>Analyze results</p></li>
<li><p>Download posterior chains of the fixed coefficients, and the states using the <em>Download Results</em> button</p></li>
</ol>
</div>
</div>
<p><strong>Example: Simulation exercise of the stochastic volatility model</strong></p>
<p>The following code shows how to simulate and perform Bayesian inference in the stochastic volatility model using the function <em>svsample</em> from the <em>stochvol</em> package. We set the stochastic volatility parameters to <span class="math inline">\(\mu = -10\)</span>, <span class="math inline">\(\phi = 0.95\)</span>, and <span class="math inline">\(\sigma = 0.3\)</span>. We assume two regressors, which are distributed as standard normal, with <span class="math inline">\(\boldsymbol{\beta} = [0.5 \ 0.3]^{\top}\)</span>, and the sample size is 1,250, which corresponds to approximately 5 years of daily returns. We use the default hyperparameters: 10,000 MCMC iterations, a burn-in of 5,000, and a thinning parameter of 5.</p>
<p>The summary statistics of the posterior draws show that all 95% credible intervals encompass the population parameters, and the posterior chains appear to have converged. The Figure displays the posterior results for the volatility (<span class="math inline">\(h_t\)</span>). The posterior mean (blue) follows the “observed” series (black), and the 95% credible intervals (light blue) typically encompass the “observed” series.</p>
<div class="sourceCode" id="cb61"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb61-1"><a href="sec83.html#cb61-1" tabindex="-1"></a><span class="fu">rm</span>(<span class="at">list =</span> <span class="fu">ls</span>()); <span class="fu">set.seed</span>(<span class="dv">010101</span>)</span>
<span id="cb61-2"><a href="sec83.html#cb61-2" tabindex="-1"></a>T <span class="ot">&lt;-</span> <span class="dv">1250</span>; K <span class="ot">&lt;-</span> <span class="dv">2</span></span>
<span id="cb61-3"><a href="sec83.html#cb61-3" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">rnorm</span>(T<span class="sc">*</span>K), T, K)</span>
<span id="cb61-4"><a href="sec83.html#cb61-4" tabindex="-1"></a>B <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">0.5</span>, <span class="fl">0.3</span>); mu <span class="ot">&lt;-</span> <span class="sc">-</span><span class="dv">10</span>; phi <span class="ot">&lt;-</span> <span class="fl">0.95</span>; sigma <span class="ot">&lt;-</span> <span class="fl">0.3</span></span>
<span id="cb61-5"><a href="sec83.html#cb61-5" tabindex="-1"></a>h <span class="ot">&lt;-</span> <span class="fu">numeric</span>(T); y <span class="ot">&lt;-</span> <span class="fu">numeric</span>(T)</span>
<span id="cb61-6"><a href="sec83.html#cb61-6" tabindex="-1"></a>h[<span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">1</span>, mu, sigma <span class="sc">/</span> <span class="fu">sqrt</span>(<span class="dv">1</span> <span class="sc">-</span> phi<span class="sc">^</span><span class="dv">2</span>))  <span class="co"># Initial state</span></span>
<span id="cb61-7"><a href="sec83.html#cb61-7" tabindex="-1"></a>y[<span class="dv">1</span>] <span class="ot">&lt;-</span> X[<span class="dv">1</span>,]<span class="sc">%*%</span>B <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="dv">1</span>, <span class="dv">0</span>, <span class="fu">exp</span>(h[<span class="dv">1</span>] <span class="sc">/</span> <span class="dv">2</span>))           <span class="co"># Initial observation</span></span>
<span id="cb61-8"><a href="sec83.html#cb61-8" tabindex="-1"></a><span class="cf">for</span> (t <span class="cf">in</span> <span class="dv">2</span><span class="sc">:</span>T) {</span>
<span id="cb61-9"><a href="sec83.html#cb61-9" tabindex="-1"></a>    h[t] <span class="ot">&lt;-</span> mu <span class="sc">+</span> phi<span class="sc">*</span>(h[t<span class="dv">-1</span>]<span class="sc">-</span>mu) <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="dv">1</span>, <span class="dv">0</span>, sigma)</span>
<span id="cb61-10"><a href="sec83.html#cb61-10" tabindex="-1"></a>    y[t] <span class="ot">&lt;-</span> X[t,]<span class="sc">%*%</span>B <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="dv">1</span>, <span class="dv">0</span>, <span class="at">sd =</span> <span class="fu">exp</span>(<span class="fl">0.5</span><span class="sc">*</span>h[t]))</span>
<span id="cb61-11"><a href="sec83.html#cb61-11" tabindex="-1"></a>}</span>
<span id="cb61-12"><a href="sec83.html#cb61-12" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(<span class="fu">cbind</span>(y, X))</span>
<span id="cb61-13"><a href="sec83.html#cb61-13" tabindex="-1"></a><span class="fu">colnames</span>(df) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;y&quot;</span>, <span class="st">&quot;x1&quot;</span>, <span class="st">&quot;x2&quot;</span>)</span>
<span id="cb61-14"><a href="sec83.html#cb61-14" tabindex="-1"></a>MCMC <span class="ot">&lt;-</span> <span class="dv">10000</span>; burnin <span class="ot">&lt;-</span> <span class="dv">10000</span>; thin <span class="ot">&lt;-</span> <span class="dv">5</span></span>
<span id="cb61-15"><a href="sec83.html#cb61-15" tabindex="-1"></a>res <span class="ot">&lt;-</span> stochvol<span class="sc">::</span><span class="fu">svsample</span>(y, <span class="at">designmatrix =</span> X, <span class="at">draws =</span> MCMC, <span class="at">burnin =</span> burnin, <span class="at">thin =</span> thin, <span class="at">priormu =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">100</span>), <span class="at">priorsigma =</span> <span class="fu">c</span>(<span class="dv">1</span>), <span class="at">priorphi =</span> <span class="fu">c</span>(<span class="dv">5</span>, <span class="fl">1.5</span>), <span class="at">priorbeta =</span>  <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">10000</span>))</span></code></pre></div>
<pre><code>## Done!</code></pre>
<pre><code>## Summarizing posterior draws...</code></pre>
<div class="sourceCode" id="cb64"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb64-1"><a href="sec83.html#cb64-1" tabindex="-1"></a><span class="fu">summary</span>(res[[<span class="st">&quot;para&quot;</span>]][[<span class="dv">1</span>]][,<span class="sc">-</span><span class="fu">c</span>(<span class="dv">4</span>,<span class="dv">5</span>)])</span></code></pre></div>
<pre><code>## 
## Iterations = 10005:20000
## Thinning interval = 5 
## Number of chains = 1 
## Sample size per chain = 2000 
## 
## 1. Empirical mean and standard deviation for each variable,
##    plus standard error of the mean:
## 
##          Mean      SD  Naive SE Time-series SE
## mu    -9.9350 0.14258 0.0031882      0.0034505
## phi    0.9414 0.01661 0.0003714      0.0009051
## sigma  0.2733 0.03855 0.0008619      0.0024256
## 
## 2. Quantiles for each variable:
## 
##           2.5%      25%     50%     75%   97.5%
## mu    -10.2077 -10.0238 -9.9301 -9.8439 -9.6508
## phi     0.9032   0.9315  0.9434  0.9531  0.9689
## sigma   0.2077   0.2461  0.2700  0.2961  0.3608</code></pre>
<div class="sourceCode" id="cb66"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb66-1"><a href="sec83.html#cb66-1" tabindex="-1"></a><span class="fu">summary</span>(res[[<span class="st">&quot;beta&quot;</span>]])</span></code></pre></div>
<pre><code>## 
## Iterations = 10005:20000
## Thinning interval = 5 
## Number of chains = 1 
## Sample size per chain = 2000 
## 
## 1. Empirical mean and standard deviation for each variable,
##    plus standard error of the mean:
## 
##          Mean        SD  Naive SE Time-series SE
## beta_0 0.5001 0.0001851 4.139e-06      3.936e-06
## beta_1 0.2999 0.0001799 4.023e-06      4.023e-06
## 
## 2. Quantiles for each variable:
## 
##          2.5%    25%    50%    75%  97.5%
## beta_0 0.4997 0.4999 0.5001 0.5002 0.5004
## beta_1 0.2995 0.2998 0.2999 0.3000 0.3002</code></pre>
<div class="sourceCode" id="cb68"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb68-1"><a href="sec83.html#cb68-1" tabindex="-1"></a>ht <span class="ot">&lt;-</span> res[[<span class="st">&quot;latent&quot;</span>]][[<span class="dv">1</span>]]</span>
<span id="cb68-2"><a href="sec83.html#cb68-2" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span></code></pre></div>
<pre><code>## 
## Attaching package: &#39;dplyr&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:stats&#39;:
## 
##     filter, lag</code></pre>
<pre><code>## The following objects are masked from &#39;package:base&#39;:
## 
##     intersect, setdiff, setequal, union</code></pre>
<div class="sourceCode" id="cb72"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb72-1"><a href="sec83.html#cb72-1" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb72-2"><a href="sec83.html#cb72-2" tabindex="-1"></a><span class="fu">library</span>(latex2exp)</span>
<span id="cb72-3"><a href="sec83.html#cb72-3" tabindex="-1"></a>ggplot2<span class="sc">::</span><span class="fu">theme_set</span>(<span class="fu">theme_bw</span>())</span>
<span id="cb72-4"><a href="sec83.html#cb72-4" tabindex="-1"></a>x_means <span class="ot">&lt;-</span> <span class="fu">colMeans</span>(ht)</span>
<span id="cb72-5"><a href="sec83.html#cb72-5" tabindex="-1"></a>x_quantiles <span class="ot">&lt;-</span> <span class="fu">apply</span>(ht, <span class="dv">2</span>, <span class="cf">function</span>(x) <span class="fu">quantile</span>(x, <span class="at">probs =</span> <span class="fu">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>)))</span>
<span id="cb72-6"><a href="sec83.html#cb72-6" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">t =</span> <span class="fu">seq</span>(<span class="dv">1</span>, T), <span class="at">mean =</span> x_means, <span class="at">lower =</span> x_quantiles[<span class="dv">1</span>, ], <span class="at">upper =</span> x_quantiles[<span class="dv">2</span>, ], <span class="at">x_true =</span> h, <span class="at">observations =</span> y)</span>
<span id="cb72-7"><a href="sec83.html#cb72-7" tabindex="-1"></a>plot_filtering_estimates <span class="ot">&lt;-</span> <span class="cf">function</span>(df) {</span>
<span id="cb72-8"><a href="sec83.html#cb72-8" tabindex="-1"></a>    pchap8 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(<span class="at">data =</span> df, <span class="fu">aes</span>(<span class="at">x =</span> t)) <span class="sc">+</span> <span class="fu">geom_ribbon</span>(<span class="fu">aes</span>(<span class="at">ymin =</span> lower, <span class="at">ymax =</span> upper), <span class="at">alpha =</span> <span class="dv">1</span>, <span class="at">fill =</span> <span class="st">&quot;lightblue&quot;</span>) <span class="sc">+</span> <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> x_true), <span class="at">colour =</span> <span class="st">&quot;black&quot;</span>, <span class="at">alpha =</span> <span class="dv">1</span>, <span class="at">linewidth =</span> <span class="fl">0.5</span>) <span class="sc">+</span> <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> mean), <span class="at">colour =</span> <span class="st">&quot;blue&quot;</span>, <span class="at">linewidth =</span> <span class="fl">0.5</span>) <span class="sc">+</span>     <span class="fu">ylab</span>(<span class="fu">TeX</span>(<span class="st">&quot;$h_{t}$&quot;</span>)) <span class="sc">+</span> <span class="fu">xlab</span>(<span class="st">&quot;Time&quot;</span>)</span>
<span id="cb72-9"><a href="sec83.html#cb72-9" tabindex="-1"></a>    <span class="fu">print</span>(pchap8)</span>
<span id="cb72-10"><a href="sec83.html#cb72-10" tabindex="-1"></a>}</span>
<span id="cb72-11"><a href="sec83.html#cb72-11" tabindex="-1"></a><span class="fu">plot_filtering_estimates</span>(df)</span></code></pre></div>
<p><img src="BayesianEconometrics_files/figure-html/unnamed-chunk-6-1.svg" width="672" /></p>
<p>So far, we have used MCMC algorithms to perform inference in <em>state-space models</em>. These algorithms require all observations to estimate the unknown parameters, a process referred to as offline or batch inference. However, this approach has limitations when online inference is needed, as every new observation requires simulating a new posterior chain. This is because MCMC algorithms do not naturally adapt to sequential updates. In contrast, particle filter algorithms, which are a subset of sequential Monte Carlo (SMC) methods, are specifically designed for sequential use, making them suitable for online inference.</p>
<p>Remember from Chapter <a href="Chap4.html#Chap4">4</a> that particle filters (sequential Monte Carlo) are algorithms that allow computing a numerical approximation to the filtering distribution <span class="math inline">\(\pi(\boldsymbol{\theta}_{1:t}\mid \boldsymbol{y}_{1:t})\)</span> sequentially in time. This is particularly relevant in non-linear and non-Gaussian models where there is no analytical solution for the filtering distribution.</p>
<p>The following code shows how to perform particle filtering in the vanilla stochastic volatility model assuming that the proposal distribution is the conditional prior distribution, that is, <span class="math inline">\(q(h_t\mid h_{t-1},y_t)=\pi(h_t\mid h_{t-1})\)</span>, which is normal with mean <span class="math inline">\(\mu+\phi(h_{t-1}-\mu)\)</span> and variance <span class="math inline">\(\sigma^2\)</span>. This choice implies that the incremental importance weights are equal to <span class="math inline">\(p(y_t\mid h_t)\)</span>, which is <span class="math inline">\(N(0,\exp(h_t))\)</span>. Therefore, the weights are proportional to the likelihood function. We perform multinomial resampling every time period in the code, and start the algorithm in the stationary distribution of <span class="math inline">\(h_t\)</span>. Remember that there are other resampling approaches that are more efficient, for instance, residual resampling. We ask in Exercise 7 to modify this code to perform resampling when the effective sample size is lower than 50% of the initial number of particles. In addition, we ask to program a sequential importance sampling, and check why is important to perform resampling in this simple example.</p>
<div class="sourceCode" id="cb73"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb73-1"><a href="sec83.html#cb73-1" tabindex="-1"></a><span class="fu">rm</span>(<span class="at">list =</span> <span class="fu">ls</span>()); <span class="fu">set.seed</span>(<span class="dv">010101</span>)</span>
<span id="cb73-2"><a href="sec83.html#cb73-2" tabindex="-1"></a>T <span class="ot">&lt;-</span> <span class="dv">1250</span>; mu <span class="ot">&lt;-</span> <span class="sc">-</span><span class="dv">10</span>; phi <span class="ot">&lt;-</span> <span class="fl">0.95</span>; sigma <span class="ot">&lt;-</span> <span class="fl">0.3</span></span>
<span id="cb73-3"><a href="sec83.html#cb73-3" tabindex="-1"></a>h <span class="ot">&lt;-</span> <span class="fu">numeric</span>(T); y <span class="ot">&lt;-</span> <span class="fu">numeric</span>(T)</span>
<span id="cb73-4"><a href="sec83.html#cb73-4" tabindex="-1"></a>h[<span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">1</span>, mu, sigma <span class="sc">/</span> <span class="fu">sqrt</span>(<span class="dv">1</span> <span class="sc">-</span> phi<span class="sc">^</span><span class="dv">2</span>))  </span>
<span id="cb73-5"><a href="sec83.html#cb73-5" tabindex="-1"></a>y[<span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">1</span>, <span class="dv">0</span>, <span class="fu">exp</span>(h[<span class="dv">1</span>] <span class="sc">/</span> <span class="dv">2</span>))           </span>
<span id="cb73-6"><a href="sec83.html#cb73-6" tabindex="-1"></a><span class="cf">for</span> (t <span class="cf">in</span> <span class="dv">2</span><span class="sc">:</span>T) {</span>
<span id="cb73-7"><a href="sec83.html#cb73-7" tabindex="-1"></a>    h[t] <span class="ot">&lt;-</span> mu <span class="sc">+</span> phi<span class="sc">*</span>(h[t<span class="dv">-1</span>]<span class="sc">-</span>mu) <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="dv">1</span>, <span class="dv">0</span>, sigma)</span>
<span id="cb73-8"><a href="sec83.html#cb73-8" tabindex="-1"></a>    y[t] <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">1</span>, <span class="dv">0</span>, <span class="at">sd =</span> <span class="fu">exp</span>(<span class="fl">0.5</span><span class="sc">*</span>h[t]))</span>
<span id="cb73-9"><a href="sec83.html#cb73-9" tabindex="-1"></a>}</span>
<span id="cb73-10"><a href="sec83.html#cb73-10" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">10000</span></span>
<span id="cb73-11"><a href="sec83.html#cb73-11" tabindex="-1"></a>log_Weights <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="cn">NA</span>, N, T)  <span class="co"># Log weights</span></span>
<span id="cb73-12"><a href="sec83.html#cb73-12" tabindex="-1"></a>Weights <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="cn">NA</span>, N, T)  <span class="co"># Weights </span></span>
<span id="cb73-13"><a href="sec83.html#cb73-13" tabindex="-1"></a>WeightsST <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="cn">NA</span>, N, T)  <span class="co"># Normalized weights </span></span>
<span id="cb73-14"><a href="sec83.html#cb73-14" tabindex="-1"></a>WeightsSTT <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="dv">1</span><span class="sc">/</span>N, N, T)  <span class="co"># Normalized weights bar </span></span>
<span id="cb73-15"><a href="sec83.html#cb73-15" tabindex="-1"></a>particles <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="cn">NA</span>, N, T)   <span class="co"># Particles</span></span>
<span id="cb73-16"><a href="sec83.html#cb73-16" tabindex="-1"></a>particlesT <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="cn">NA</span>, N, T)   <span class="co"># Particles bar</span></span>
<span id="cb73-17"><a href="sec83.html#cb73-17" tabindex="-1"></a>logalphas <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="cn">NA</span>, N, T)   <span class="co"># Incremental importance </span></span>
<span id="cb73-18"><a href="sec83.html#cb73-18" tabindex="-1"></a>particles[, <span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N, mu, sigma <span class="sc">/</span> <span class="fu">sqrt</span>(<span class="dv">1</span> <span class="sc">-</span> phi<span class="sc">^</span><span class="dv">2</span>))  <span class="co"># Stationary prior</span></span>
<span id="cb73-19"><a href="sec83.html#cb73-19" tabindex="-1"></a>log_Weights[, <span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="fu">dnorm</span>(y[<span class="dv">1</span>], <span class="dv">0</span>, <span class="at">sd =</span> <span class="fu">exp</span>(<span class="fl">0.5</span><span class="sc">*</span>particles[,<span class="dv">1</span>]), <span class="at">log =</span> <span class="cn">TRUE</span>)  <span class="co"># Likelihood</span></span>
<span id="cb73-20"><a href="sec83.html#cb73-20" tabindex="-1"></a>Weights[, <span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="fu">exp</span>(log_Weights[, <span class="dv">1</span>])</span>
<span id="cb73-21"><a href="sec83.html#cb73-21" tabindex="-1"></a>WeightsST[, <span class="dv">1</span>] <span class="ot">&lt;-</span> Weights[, <span class="dv">1</span>] <span class="sc">/</span> <span class="fu">sum</span>(Weights[, <span class="dv">1</span>])</span>
<span id="cb73-22"><a href="sec83.html#cb73-22" tabindex="-1"></a>ind <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span>N, <span class="at">size =</span> N, <span class="at">replace =</span> <span class="cn">TRUE</span>, <span class="at">prob =</span> WeightsST[, <span class="dv">1</span>]) <span class="co"># Resample </span></span>
<span id="cb73-23"><a href="sec83.html#cb73-23" tabindex="-1"></a>particles[, <span class="dv">1</span>] <span class="ot">&lt;-</span> particles[ind, <span class="dv">1</span>] <span class="co"># Resampled particles</span></span>
<span id="cb73-24"><a href="sec83.html#cb73-24" tabindex="-1"></a>particlesT[, <span class="dv">1</span>] <span class="ot">&lt;-</span> particles[, <span class="dv">1</span>] <span class="co"># Resampled particles</span></span>
<span id="cb73-25"><a href="sec83.html#cb73-25" tabindex="-1"></a>WeightsST[, <span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">1</span><span class="sc">/</span>N, N) <span class="co"># Resampled weights</span></span>
<span id="cb73-26"><a href="sec83.html#cb73-26" tabindex="-1"></a>pb <span class="ot">&lt;-</span> <span class="fu">txtProgressBar</span>(<span class="at">min =</span> <span class="dv">0</span>, <span class="at">max =</span> T, <span class="at">style =</span> <span class="dv">3</span>)</span></code></pre></div>
<pre><code>##   |                                                                              |                                                                      |   0%</code></pre>
<div class="sourceCode" id="cb75"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb75-1"><a href="sec83.html#cb75-1" tabindex="-1"></a><span class="cf">for</span> (t <span class="cf">in</span> <span class="dv">2</span><span class="sc">:</span>T) {</span>
<span id="cb75-2"><a href="sec83.html#cb75-2" tabindex="-1"></a>    particles[, t] <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N, mu <span class="sc">+</span> phi<span class="sc">*</span>(particles[, t <span class="sc">-</span> <span class="dv">1</span>] <span class="sc">-</span> mu), sigma)  <span class="co"># Sample from proposal</span></span>
<span id="cb75-3"><a href="sec83.html#cb75-3" tabindex="-1"></a>    logalphas[, t] <span class="ot">&lt;-</span> <span class="fu">dnorm</span>(y[t], <span class="dv">0</span>, <span class="at">sd =</span> <span class="fu">exp</span>(<span class="fl">0.5</span><span class="sc">*</span>particles[,t]), <span class="at">log =</span> <span class="cn">TRUE</span>) </span>
<span id="cb75-4"><a href="sec83.html#cb75-4" tabindex="-1"></a>    Weights[, t] <span class="ot">&lt;-</span> <span class="fu">exp</span>(logalphas[, t])</span>
<span id="cb75-5"><a href="sec83.html#cb75-5" tabindex="-1"></a>    WeightsST[, t] <span class="ot">&lt;-</span> Weights[, t] <span class="sc">/</span> <span class="fu">sum</span>(Weights[, t])</span>
<span id="cb75-6"><a href="sec83.html#cb75-6" tabindex="-1"></a>    <span class="cf">if</span>(t <span class="sc">&lt;</span> T){</span>
<span id="cb75-7"><a href="sec83.html#cb75-7" tabindex="-1"></a>        ind <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span>N, <span class="at">size =</span> N, <span class="at">replace =</span> <span class="cn">TRUE</span>, <span class="at">prob =</span> WeightsST[, t])</span>
<span id="cb75-8"><a href="sec83.html#cb75-8" tabindex="-1"></a>        particles[, <span class="dv">1</span><span class="sc">:</span>t] <span class="ot">&lt;-</span> particles[ind, <span class="dv">1</span><span class="sc">:</span>t]</span>
<span id="cb75-9"><a href="sec83.html#cb75-9" tabindex="-1"></a>    }<span class="cf">else</span>{</span>
<span id="cb75-10"><a href="sec83.html#cb75-10" tabindex="-1"></a>        ind <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span>N, <span class="at">size =</span> N, <span class="at">replace =</span> <span class="cn">TRUE</span>, <span class="at">prob =</span> WeightsST[, t])</span>
<span id="cb75-11"><a href="sec83.html#cb75-11" tabindex="-1"></a>        particlesT[, <span class="dv">1</span><span class="sc">:</span>t] <span class="ot">&lt;-</span> particles[ind, <span class="dv">1</span><span class="sc">:</span>t]</span>
<span id="cb75-12"><a href="sec83.html#cb75-12" tabindex="-1"></a>    }</span>
<span id="cb75-13"><a href="sec83.html#cb75-13" tabindex="-1"></a>    <span class="fu">setTxtProgressBar</span>(pb, t)</span>
<span id="cb75-14"><a href="sec83.html#cb75-14" tabindex="-1"></a>}</span></code></pre></div>
<pre><code>##   |                                                                              |                                                                      |   1%  |                                                                              |=                                                                     |   1%  |                                                                              |=                                                                     |   2%  |                                                                              |==                                                                    |   2%  |                                                                              |==                                                                    |   3%  |                                                                              |==                                                                    |   4%  |                                                                              |===                                                                   |   4%  |                                                                              |===                                                                   |   5%  |                                                                              |====                                                                  |   5%  |                                                                              |====                                                                  |   6%  |                                                                              |=====                                                                 |   6%  |                                                                              |=====                                                                 |   7%  |                                                                              |=====                                                                 |   8%  |                                                                              |======                                                                |   8%  |                                                                              |======                                                                |   9%  |                                                                              |=======                                                               |   9%  |                                                                              |=======                                                               |  10%  |                                                                              |=======                                                               |  11%  |                                                                              |========                                                              |  11%  |                                                                              |========                                                              |  12%  |                                                                              |=========                                                             |  12%  |                                                                              |=========                                                             |  13%  |                                                                              |=========                                                             |  14%  |                                                                              |==========                                                            |  14%  |                                                                              |==========                                                            |  15%  |                                                                              |===========                                                           |  15%  |                                                                              |===========                                                           |  16%  |                                                                              |============                                                          |  16%  |                                                                              |============                                                          |  17%  |                                                                              |============                                                          |  18%  |                                                                              |=============                                                         |  18%  |                                                                              |=============                                                         |  19%  |                                                                              |==============                                                        |  19%  |                                                                              |==============                                                        |  20%  |                                                                              |==============                                                        |  21%  |                                                                              |===============                                                       |  21%  |                                                                              |===============                                                       |  22%  |                                                                              |================                                                      |  22%  |                                                                              |================                                                      |  23%  |                                                                              |================                                                      |  24%  |                                                                              |=================                                                     |  24%  |                                                                              |=================                                                     |  25%  |                                                                              |==================                                                    |  25%  |                                                                              |==================                                                    |  26%  |                                                                              |===================                                                   |  26%  |                                                                              |===================                                                   |  27%  |                                                                              |===================                                                   |  28%  |                                                                              |====================                                                  |  28%  |                                                                              |====================                                                  |  29%  |                                                                              |=====================                                                 |  29%  |                                                                              |=====================                                                 |  30%  |                                                                              |=====================                                                 |  31%  |                                                                              |======================                                                |  31%  |                                                                              |======================                                                |  32%  |                                                                              |=======================                                               |  32%  |                                                                              |=======================                                               |  33%  |                                                                              |=======================                                               |  34%  |                                                                              |========================                                              |  34%  |                                                                              |========================                                              |  35%  |                                                                              |=========================                                             |  35%  |                                                                              |=========================                                             |  36%  |                                                                              |==========================                                            |  36%  |                                                                              |==========================                                            |  37%  |                                                                              |==========================                                            |  38%  |                                                                              |===========================                                           |  38%  |                                                                              |===========================                                           |  39%  |                                                                              |============================                                          |  39%  |                                                                              |============================                                          |  40%  |                                                                              |============================                                          |  41%  |                                                                              |=============================                                         |  41%  |                                                                              |=============================                                         |  42%  |                                                                              |==============================                                        |  42%  |                                                                              |==============================                                        |  43%  |                                                                              |==============================                                        |  44%  |                                                                              |===============================                                       |  44%  |                                                                              |===============================                                       |  45%  |                                                                              |================================                                      |  45%  |                                                                              |================================                                      |  46%  |                                                                              |=================================                                     |  46%  |                                                                              |=================================                                     |  47%  |                                                                              |=================================                                     |  48%  |                                                                              |==================================                                    |  48%  |                                                                              |==================================                                    |  49%  |                                                                              |===================================                                   |  49%  |                                                                              |===================================                                   |  50%  |                                                                              |===================================                                   |  51%  |                                                                              |====================================                                  |  51%  |                                                                              |====================================                                  |  52%  |                                                                              |=====================================                                 |  52%  |                                                                              |=====================================                                 |  53%  |                                                                              |=====================================                                 |  54%  |                                                                              |======================================                                |  54%  |                                                                              |======================================                                |  55%  |                                                                              |=======================================                               |  55%  |                                                                              |=======================================                               |  56%  |                                                                              |========================================                              |  56%  |                                                                              |========================================                              |  57%  |                                                                              |========================================                              |  58%  |                                                                              |=========================================                             |  58%  |                                                                              |=========================================                             |  59%  |                                                                              |==========================================                            |  59%  |                                                                              |==========================================                            |  60%  |                                                                              |==========================================                            |  61%  |                                                                              |===========================================                           |  61%  |                                                                              |===========================================                           |  62%  |                                                                              |============================================                          |  62%  |                                                                              |============================================                          |  63%  |                                                                              |============================================                          |  64%  |                                                                              |=============================================                         |  64%  |                                                                              |=============================================                         |  65%  |                                                                              |==============================================                        |  65%  |                                                                              |==============================================                        |  66%  |                                                                              |===============================================                       |  66%  |                                                                              |===============================================                       |  67%  |                                                                              |===============================================                       |  68%  |                                                                              |================================================                      |  68%  |                                                                              |================================================                      |  69%  |                                                                              |=================================================                     |  69%  |                                                                              |=================================================                     |  70%  |                                                                              |=================================================                     |  71%  |                                                                              |==================================================                    |  71%  |                                                                              |==================================================                    |  72%  |                                                                              |===================================================                   |  72%  |                                                                              |===================================================                   |  73%  |                                                                              |===================================================                   |  74%  |                                                                              |====================================================                  |  74%  |                                                                              |====================================================                  |  75%  |                                                                              |=====================================================                 |  75%  |                                                                              |=====================================================                 |  76%  |                                                                              |======================================================                |  76%  |                                                                              |======================================================                |  77%  |                                                                              |======================================================                |  78%  |                                                                              |=======================================================               |  78%  |                                                                              |=======================================================               |  79%  |                                                                              |========================================================              |  79%  |                                                                              |========================================================              |  80%  |                                                                              |========================================================              |  81%  |                                                                              |=========================================================             |  81%  |                                                                              |=========================================================             |  82%  |                                                                              |==========================================================            |  82%  |                                                                              |==========================================================            |  83%  |                                                                              |==========================================================            |  84%  |                                                                              |===========================================================           |  84%  |                                                                              |===========================================================           |  85%  |                                                                              |============================================================          |  85%  |                                                                              |============================================================          |  86%  |                                                                              |=============================================================         |  86%  |                                                                              |=============================================================         |  87%  |                                                                              |=============================================================         |  88%  |                                                                              |==============================================================        |  88%  |                                                                              |==============================================================        |  89%  |                                                                              |===============================================================       |  89%  |                                                                              |===============================================================       |  90%  |                                                                              |===============================================================       |  91%  |                                                                              |================================================================      |  91%  |                                                                              |================================================================      |  92%  |                                                                              |=================================================================     |  92%  |                                                                              |=================================================================     |  93%  |                                                                              |=================================================================     |  94%  |                                                                              |==================================================================    |  94%  |                                                                              |==================================================================    |  95%  |                                                                              |===================================================================   |  95%  |                                                                              |===================================================================   |  96%  |                                                                              |====================================================================  |  96%  |                                                                              |====================================================================  |  97%  |                                                                              |====================================================================  |  98%  |                                                                              |===================================================================== |  98%  |                                                                              |===================================================================== |  99%  |                                                                              |======================================================================|  99%  |                                                                              |======================================================================| 100%</code></pre>
<div class="sourceCode" id="cb77"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb77-1"><a href="sec83.html#cb77-1" tabindex="-1"></a><span class="fu">close</span>(pb)</span></code></pre></div>
<div class="sourceCode" id="cb78"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb78-1"><a href="sec83.html#cb78-1" tabindex="-1"></a>FilterDist <span class="ot">&lt;-</span> <span class="fu">colSums</span>(particles <span class="sc">*</span> WeightsST)</span>
<span id="cb78-2"><a href="sec83.html#cb78-2" tabindex="-1"></a>SDFilterDist <span class="ot">&lt;-</span> (<span class="fu">colSums</span>(particles<span class="sc">^</span><span class="dv">2</span> <span class="sc">*</span> WeightsST) <span class="sc">-</span> FilterDist<span class="sc">^</span><span class="dv">2</span>)<span class="sc">^</span><span class="fl">0.5</span></span>
<span id="cb78-3"><a href="sec83.html#cb78-3" tabindex="-1"></a>FilterDistT <span class="ot">&lt;-</span> <span class="fu">colSums</span>(particlesT <span class="sc">*</span> WeightsSTT)</span>
<span id="cb78-4"><a href="sec83.html#cb78-4" tabindex="-1"></a>SDFilterDistT <span class="ot">&lt;-</span> (<span class="fu">colSums</span>(particlesT<span class="sc">^</span><span class="dv">2</span> <span class="sc">*</span> WeightsSTT) <span class="sc">-</span> FilterDistT<span class="sc">^</span><span class="dv">2</span>)<span class="sc">^</span><span class="fl">0.5</span></span>
<span id="cb78-5"><a href="sec83.html#cb78-5" tabindex="-1"></a>MargLik <span class="ot">&lt;-</span> <span class="fu">colMeans</span>(Weights)</span>
<span id="cb78-6"><a href="sec83.html#cb78-6" tabindex="-1"></a><span class="co"># plot(MargLik, type = &quot;l&quot;)</span></span>
<span id="cb78-7"><a href="sec83.html#cb78-7" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb78-8"><a href="sec83.html#cb78-8" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb78-9"><a href="sec83.html#cb78-9" tabindex="-1"></a><span class="fu">require</span>(latex2exp)</span>
<span id="cb78-10"><a href="sec83.html#cb78-10" tabindex="-1"></a>ggplot2<span class="sc">::</span><span class="fu">theme_set</span>(<span class="fu">theme_bw</span>())</span>
<span id="cb78-11"><a href="sec83.html#cb78-11" tabindex="-1"></a>Tfig <span class="ot">&lt;-</span> <span class="dv">250</span></span>
<span id="cb78-12"><a href="sec83.html#cb78-12" tabindex="-1"></a>keepFig <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">:</span>Tfig</span>
<span id="cb78-13"><a href="sec83.html#cb78-13" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">t =</span> keepFig,</span>
<span id="cb78-14"><a href="sec83.html#cb78-14" tabindex="-1"></a><span class="at">mean =</span> FilterDist[keepFig],</span>
<span id="cb78-15"><a href="sec83.html#cb78-15" tabindex="-1"></a><span class="at">lower =</span> FilterDist[keepFig] <span class="sc">-</span> <span class="dv">2</span><span class="sc">*</span>SDFilterDist[keepFig],</span>
<span id="cb78-16"><a href="sec83.html#cb78-16" tabindex="-1"></a><span class="at">upper =</span> FilterDist[keepFig] <span class="sc">+</span> <span class="dv">2</span><span class="sc">*</span>SDFilterDist[keepFig],</span>
<span id="cb78-17"><a href="sec83.html#cb78-17" tabindex="-1"></a><span class="at">meanT =</span> FilterDistT[keepFig],</span>
<span id="cb78-18"><a href="sec83.html#cb78-18" tabindex="-1"></a><span class="at">lowerT =</span> FilterDistT[keepFig] <span class="sc">-</span> <span class="dv">2</span><span class="sc">*</span>SDFilterDistT[keepFig],</span>
<span id="cb78-19"><a href="sec83.html#cb78-19" tabindex="-1"></a><span class="at">upperT =</span> FilterDistT[keepFig] <span class="sc">+</span> <span class="dv">2</span><span class="sc">*</span>SDFilterDistT[keepFig],</span>
<span id="cb78-20"><a href="sec83.html#cb78-20" tabindex="-1"></a><span class="at">x_true =</span> h[keepFig])</span>
<span id="cb78-21"><a href="sec83.html#cb78-21" tabindex="-1"></a>plot_filtering_estimates <span class="ot">&lt;-</span> <span class="cf">function</span>(df) {</span>
<span id="cb78-22"><a href="sec83.html#cb78-22" tabindex="-1"></a>    pchap8l <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(<span class="at">data =</span> df, <span class="fu">aes</span>(<span class="at">x =</span> t)) <span class="sc">+</span></span>
<span id="cb78-23"><a href="sec83.html#cb78-23" tabindex="-1"></a>    <span class="fu">geom_ribbon</span>(<span class="fu">aes</span>(<span class="at">ymin =</span> lower, <span class="at">ymax =</span> upper), <span class="at">alpha =</span> <span class="dv">1</span>,</span>
<span id="cb78-24"><a href="sec83.html#cb78-24" tabindex="-1"></a>    <span class="at">fill =</span> <span class="st">&quot;lightblue&quot;</span>) <span class="sc">+</span></span>
<span id="cb78-25"><a href="sec83.html#cb78-25" tabindex="-1"></a>    <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> x_true), <span class="at">colour =</span> <span class="st">&quot;black&quot;</span>, <span class="at">alpha =</span> <span class="dv">1</span>,</span>
<span id="cb78-26"><a href="sec83.html#cb78-26" tabindex="-1"></a>    <span class="at">linewidth =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb78-27"><a href="sec83.html#cb78-27" tabindex="-1"></a>    <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> mean), <span class="at">colour =</span> <span class="st">&quot;blue&quot;</span>, <span class="at">linewidth =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb78-28"><a href="sec83.html#cb78-28" tabindex="-1"></a>    <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> meanT), <span class="at">colour =</span> <span class="st">&quot;purple&quot;</span>, <span class="at">linewidth =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb78-29"><a href="sec83.html#cb78-29" tabindex="-1"></a>    <span class="fu">ylab</span>(<span class="fu">TeX</span>(<span class="st">&quot;$h_{t}$&quot;</span>)) <span class="sc">+</span> <span class="fu">xlab</span>(<span class="st">&quot;Time&quot;</span>)</span>
<span id="cb78-30"><a href="sec83.html#cb78-30" tabindex="-1"></a>    <span class="fu">print</span>(pchap8l)</span>
<span id="cb78-31"><a href="sec83.html#cb78-31" tabindex="-1"></a>}</span>
<span id="cb78-32"><a href="sec83.html#cb78-32" tabindex="-1"></a><span class="fu">plot_filtering_estimates</span>(df)</span></code></pre></div>
<p><img src="BayesianEconometrics_files/figure-html/unnamed-chunk-7-1.svg" width="672" /></p>
<p>The Figure illustrates the filtering recursion using SMC with uneven weights (blue line), even weights (purple line), bands corresponding to plus/minus two standard deviations (light blue shaded area), and the true state (black line).<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a> The results indicate that SMC performs well even with a simple implementation, with no significant differences between using even and uneven weights (see Chapter <a href="Chap4.html#Chap4">4</a>).</p>
<p>In this example, we use the population parameters to perform the filtering recursion. However, this is not the case in practice, as we must estimate the time-invariant parameters. Therefore, more elaborate algorithms are required to achieve this. For instance, <span class="citation">Andrieu, Doucet, and Holenstein (<a href="#ref-andrieu2010pmcmc">2010</a>)</span> propose particle Markov chain Monte Carlo, a family of methods that combines MCMC and SMC. See <span class="citation">Dahlin and Schön (<a href="#ref-dahlin2019getting">2019</a>)</span> for a tutorial on particle Metropolis-Hastings in <strong>R</strong>. A potential practical solution for applications that require sequential updating of a posterior distribution over an unbounded time horizon is to estimate the time-invariant parameters offline using MCMC algorithms up to a specific time period, and then update the state vector sequentially online during subsequent time periods, iterating this process. This is not optimal, but it can be practical.</p>
</div>
<h3>References<a href="references.html#references" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-andrieu2010pmcmc" class="csl-entry">
Andrieu, Christophe, Arnaud Doucet, and Roman Holenstein. 2010. <span>“Particle Markov Chain Monte Carlo Methods.”</span> <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em> 72 (3): 269–342. <a href="https://doi.org/10.1111/j.1467-9868.2009.00736.x">https://doi.org/10.1111/j.1467-9868.2009.00736.x</a>.
</div>
<div id="ref-bollerslev_1986" class="csl-entry">
Bollerslev, Tim. 1986. <span>“Generalized Autoregressive Conditional Heteroskedasticity.”</span> <em>Journal of Econometrics</em> 31 (3): 307–27. <a href="https://doi.org/10.1016/0304-4076(86)90063-1">https://doi.org/10.1016/0304-4076(86)90063-1</a>.
</div>
<div id="ref-dahlin2019getting" class="csl-entry">
Dahlin, Johan, and Thomas B Schön. 2019. <span>“Getting Started with Particle Metropolis-Hastings for Inference in Nonlinear Dynamical Models.”</span> <em>Journal of Statistical Software</em> 88: 1–41.
</div>
<div id="ref-hosszejni_kastner_2021" class="csl-entry">
Hosszejni, Daniel, and Gregor Kastner. 2021. <span>“Modeling Univariate and Multivariate Stochastic Volatility in r with <code>stochvol</code> and <code>factorstochvol</code>.”</span> <em>Journal of Statistical Software</em> 100 (12): 1–34. <a href="https://doi.org/10.18637/jss.v100.i12">https://doi.org/10.18637/jss.v100.i12</a>.
</div>
<div id="ref-kastner2014ancillarity" class="csl-entry">
Kastner, Gregor, and Sylvia Frühwirth-Schnatter. 2014. <span>“Ancillarity-Sufficiency Interweaving Strategy (ASIS) for Boosting MCMC Estimation of Stochastic Volatility Models.”</span> <em>Computational Statistics &amp; Data Analysis</em> 76: 408–23.
</div>
</div>
<div class="footnotes">
<hr />
<ol start="2">
<li id="fn2"><p>This standard deviation estimates the conditional posterior’s standard deviation derived from the particles, not the estimator’s standard deviation. The latter requires several independent particle runs on the same data.<a href="sec83.html#fnref2" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="sec82.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="sec84.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": true,
    "facebook": true,
    "twitter": true,
    "linkedin": false,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": false,
    "all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
  },
  "fontsettings": {
    "theme": "white",
    "family": "sans",
    "size": 2
  },
  "edit": {
    "link": "https://github.com/aramir21/IntroductionBayesianEconometricsBook/08-Timeseries.Rmd",
    "text": "Edit"
  },
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": null,
    "text": null
  },
  "download": null,
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "subsection"
  }
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
