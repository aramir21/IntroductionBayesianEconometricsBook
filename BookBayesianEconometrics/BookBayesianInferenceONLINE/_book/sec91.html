<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>9.1 Normal model | Introduction to Bayesian Data Modeling</title>
  <meta name="description" content="The subject of this textbook is Bayesian data modeling, with the primary aim of providing an introduction to its theoretical foundations and facilitating the application of Bayesian inference using a GUI." />
  <meta name="generator" content="bookdown 0.40 and GitBook 2.6.7" />

  <meta property="og:title" content="9.1 Normal model | Introduction to Bayesian Data Modeling" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="The subject of this textbook is Bayesian data modeling, with the primary aim of providing an introduction to its theoretical foundations and facilitating the application of Bayesian inference using a GUI." />
  <meta name="github-repo" content="https://github.com/aramir21/IntroductionBayesianEconometricsBook" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="9.1 Normal model | Introduction to Bayesian Data Modeling" />
  
  <meta name="twitter:description" content="The subject of this textbook is Bayesian data modeling, with the primary aim of providing an introduction to its theoretical foundations and facilitating the application of Bayesian inference using a GUI." />
  

<meta name="author" content="Andrés Ramírez-Hassan" />


<meta name="date" content="2025-02-20" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="Chap9.html"/>
<link rel="next" href="sec92.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Introduction to Bayesian Econometrics: A GUIded tour using R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction</a>
<ul>
<li class="chapter" data-level="" data-path="to-instructors-and-students.html"><a href="to-instructors-and-students.html"><i class="fa fa-check"></i>To instructors and students</a></li>
<li class="chapter" data-level="" data-path="acknowledgments.html"><a href="acknowledgments.html"><i class="fa fa-check"></i>Acknowledgments</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="Chap1.html"><a href="Chap1.html"><i class="fa fa-check"></i><b>1</b> Basic formal concepts</a>
<ul>
<li class="chapter" data-level="1.1" data-path="sec11.html"><a href="sec11.html"><i class="fa fa-check"></i><b>1.1</b> The Bayes’ rule</a></li>
<li class="chapter" data-level="1.2" data-path="sec12.html"><a href="sec12.html"><i class="fa fa-check"></i><b>1.2</b> Bayesian framework: A brief summary of theory</a></li>
<li class="chapter" data-level="1.3" data-path="sec14.html"><a href="sec14.html"><i class="fa fa-check"></i><b>1.3</b> Bayesian reports: Decision theory under uncertainty</a></li>
<li class="chapter" data-level="1.4" data-path="summary.html"><a href="summary.html"><i class="fa fa-check"></i><b>1.4</b> Summary</a></li>
<li class="chapter" data-level="1.5" data-path="exercises.html"><a href="exercises.html"><i class="fa fa-check"></i><b>1.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="Chap2.html"><a href="Chap2.html"><i class="fa fa-check"></i><b>2</b> Conceptual differences between the Bayesian and Frequentist approaches</a>
<ul>
<li class="chapter" data-level="2.1" data-path="sec21.html"><a href="sec21.html"><i class="fa fa-check"></i><b>2.1</b> The concept of probability</a></li>
<li class="chapter" data-level="2.2" data-path="sec22.html"><a href="sec22.html"><i class="fa fa-check"></i><b>2.2</b> Subjectivity is not the key</a></li>
<li class="chapter" data-level="2.3" data-path="sec23.html"><a href="sec23.html"><i class="fa fa-check"></i><b>2.3</b> Estimation, hypothesis testing and prediction</a></li>
<li class="chapter" data-level="2.4" data-path="sec24.html"><a href="sec24.html"><i class="fa fa-check"></i><b>2.4</b> The likelihood principle</a></li>
<li class="chapter" data-level="2.5" data-path="sec25.html"><a href="sec25.html"><i class="fa fa-check"></i><b>2.5</b> Why is not the Bayesian approach that popular?</a></li>
<li class="chapter" data-level="2.6" data-path="sec26.html"><a href="sec26.html"><i class="fa fa-check"></i><b>2.6</b> A simple working example</a></li>
<li class="chapter" data-level="2.7" data-path="sec27.html"><a href="sec27.html"><i class="fa fa-check"></i><b>2.7</b> Summary</a></li>
<li class="chapter" data-level="2.8" data-path="sec28.html"><a href="sec28.html"><i class="fa fa-check"></i><b>2.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="Chap3.html"><a href="Chap3.html"><i class="fa fa-check"></i><b>3</b> Cornerstone models: Conjugate families</a>
<ul>
<li class="chapter" data-level="3.1" data-path="sec41.html"><a href="sec41.html"><i class="fa fa-check"></i><b>3.1</b> Motivation of conjugate families</a></li>
<li class="chapter" data-level="3.2" data-path="sec42.html"><a href="sec42.html"><i class="fa fa-check"></i><b>3.2</b> Conjugate prior to exponential family</a></li>
<li class="chapter" data-level="3.3" data-path="sec43.html"><a href="sec43.html"><i class="fa fa-check"></i><b>3.3</b> Linear regression: The conjugate normal-normal/inverse gamma model</a></li>
<li class="chapter" data-level="3.4" data-path="sec44.html"><a href="sec44.html"><i class="fa fa-check"></i><b>3.4</b> Multivariate linear regression: The conjugate normal-normal/inverse Wishart model</a></li>
<li class="chapter" data-level="3.5" data-path="computational-examples.html"><a href="computational-examples.html"><i class="fa fa-check"></i><b>3.5</b> Computational examples</a></li>
<li class="chapter" data-level="3.6" data-path="summary-chapter-4.html"><a href="summary-chapter-4.html"><i class="fa fa-check"></i><b>3.6</b> Summary: Chapter 4</a></li>
<li class="chapter" data-level="3.7" data-path="exercises-chapter-4.html"><a href="exercises-chapter-4.html"><i class="fa fa-check"></i><b>3.7</b> Exercises: Chapter 4</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="Chap4.html"><a href="Chap4.html"><i class="fa fa-check"></i><b>4</b> Simulation methods</a>
<ul>
<li class="chapter" data-level="4.1" data-path="sec51.html"><a href="sec51.html"><i class="fa fa-check"></i><b>4.1</b> Markov Chain Monte Carlo methods</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="sec51.html"><a href="sec51.html#sec511"><i class="fa fa-check"></i><b>4.1.1</b> Gibbs sampler</a></li>
<li class="chapter" data-level="4.1.2" data-path="sec51.html"><a href="sec51.html#sec512"><i class="fa fa-check"></i><b>4.1.2</b> Metropolis-Hastings</a></li>
<li class="chapter" data-level="4.1.3" data-path="sec51.html"><a href="sec51.html#sec513"><i class="fa fa-check"></i><b>4.1.3</b> Hamiltonian Monte Carlo</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="sec52.html"><a href="sec52.html"><i class="fa fa-check"></i><b>4.2</b> Importance sampling</a></li>
<li class="chapter" data-level="4.3" data-path="sec53.html"><a href="sec53.html"><i class="fa fa-check"></i><b>4.3</b> Particle filtering</a></li>
<li class="chapter" data-level="4.4" data-path="sec54.html"><a href="sec54.html"><i class="fa fa-check"></i><b>4.4</b> Convergence diagnostics</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="sec54.html"><a href="sec54.html#numerical-standard-error"><i class="fa fa-check"></i><b>4.4.1</b> Numerical standard error</a></li>
<li class="chapter" data-level="4.4.2" data-path="sec54.html"><a href="sec54.html#effective-number-of-simulation-draws"><i class="fa fa-check"></i><b>4.4.2</b> Effective number of simulation draws</a></li>
<li class="chapter" data-level="4.4.3" data-path="sec54.html"><a href="sec54.html#tests-of-convergence"><i class="fa fa-check"></i><b>4.4.3</b> Tests of convergence</a></li>
<li class="chapter" data-level="4.4.4" data-path="sec54.html"><a href="sec54.html#checking-for-errors-in-the-posterior-simulator"><i class="fa fa-check"></i><b>4.4.4</b> Checking for errors in the posterior simulator</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="sec55.html"><a href="sec55.html"><i class="fa fa-check"></i><b>4.5</b> Summary</a></li>
<li class="chapter" data-level="4.6" data-path="sec56.html"><a href="sec56.html"><i class="fa fa-check"></i><b>4.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="Chap5.html"><a href="Chap5.html"><i class="fa fa-check"></i><b>5</b> Graphical user interface</a></li>
<li class="chapter" data-level="6" data-path="Chap6.html"><a href="Chap6.html"><i class="fa fa-check"></i><b>6</b> Univariate regression</a>
<ul>
<li class="chapter" data-level="6.1" data-path="sec61.html"><a href="sec61.html"><i class="fa fa-check"></i><b>6.1</b> The Gaussian linear model</a></li>
<li class="chapter" data-level="6.2" data-path="sec62.html"><a href="sec62.html"><i class="fa fa-check"></i><b>6.2</b> The logit model</a></li>
<li class="chapter" data-level="6.3" data-path="sec63.html"><a href="sec63.html"><i class="fa fa-check"></i><b>6.3</b> The probit model</a></li>
<li class="chapter" data-level="6.4" data-path="sec64.html"><a href="sec64.html"><i class="fa fa-check"></i><b>6.4</b> The multinomial probit model</a></li>
<li class="chapter" data-level="6.5" data-path="sec65.html"><a href="sec65.html"><i class="fa fa-check"></i><b>6.5</b> The multinomial logit model</a></li>
<li class="chapter" data-level="6.6" data-path="sec66.html"><a href="sec66.html"><i class="fa fa-check"></i><b>6.6</b> Ordered probit model</a></li>
<li class="chapter" data-level="6.7" data-path="negative-binomial-model.html"><a href="negative-binomial-model.html"><i class="fa fa-check"></i><b>6.7</b> Negative binomial model</a></li>
<li class="chapter" data-level="6.8" data-path="sec68.html"><a href="sec68.html"><i class="fa fa-check"></i><b>6.8</b> Tobit model</a></li>
<li class="chapter" data-level="6.9" data-path="sec69.html"><a href="sec69.html"><i class="fa fa-check"></i><b>6.9</b> Quantile regression</a></li>
<li class="chapter" data-level="6.10" data-path="sec610.html"><a href="sec610.html"><i class="fa fa-check"></i><b>6.10</b> Bayesian bootstrap regression</a></li>
<li class="chapter" data-level="6.11" data-path="sec611.html"><a href="sec611.html"><i class="fa fa-check"></i><b>6.11</b> Summary</a></li>
<li class="chapter" data-level="6.12" data-path="sec612.html"><a href="sec612.html"><i class="fa fa-check"></i><b>6.12</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="Chap7.html"><a href="Chap7.html"><i class="fa fa-check"></i><b>7</b> Multivariate regression</a>
<ul>
<li class="chapter" data-level="7.1" data-path="sec71.html"><a href="sec71.html"><i class="fa fa-check"></i><b>7.1</b> Multivariate regression</a></li>
<li class="chapter" data-level="7.2" data-path="sec72.html"><a href="sec72.html"><i class="fa fa-check"></i><b>7.2</b> Seemingly Unrelated Regression</a></li>
<li class="chapter" data-level="7.3" data-path="sec73.html"><a href="sec73.html"><i class="fa fa-check"></i><b>7.3</b> Instrumental variable</a></li>
<li class="chapter" data-level="7.4" data-path="sec74.html"><a href="sec74.html"><i class="fa fa-check"></i><b>7.4</b> Multivariate probit model</a></li>
<li class="chapter" data-level="7.5" data-path="sec75.html"><a href="sec75.html"><i class="fa fa-check"></i><b>7.5</b> Summary</a></li>
<li class="chapter" data-level="7.6" data-path="sec76.html"><a href="sec76.html"><i class="fa fa-check"></i><b>7.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="Chap8.html"><a href="Chap8.html"><i class="fa fa-check"></i><b>8</b> Time series</a>
<ul>
<li class="chapter" data-level="8.1" data-path="sec81.html"><a href="sec81.html"><i class="fa fa-check"></i><b>8.1</b> State-space representation</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="sec81.html"><a href="sec81.html#gaussian-linear-state-space-models"><i class="fa fa-check"></i><b>8.1.1</b> Gaussian linear state-space models</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="sec82.html"><a href="sec82.html"><i class="fa fa-check"></i><b>8.2</b> ARMA processes</a></li>
<li class="chapter" data-level="8.3" data-path="sec83.html"><a href="sec83.html"><i class="fa fa-check"></i><b>8.3</b> Stochastic volatility models</a></li>
<li class="chapter" data-level="8.4" data-path="sec84.html"><a href="sec84.html"><i class="fa fa-check"></i><b>8.4</b> Vector Autoregressive models</a></li>
<li class="chapter" data-level="8.5" data-path="sec85.html"><a href="sec85.html"><i class="fa fa-check"></i><b>8.5</b> Summary</a></li>
<li class="chapter" data-level="8.6" data-path="sec86.html"><a href="sec86.html"><i class="fa fa-check"></i><b>8.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="Chap9.html"><a href="Chap9.html"><i class="fa fa-check"></i><b>9</b> Longitudinal regression</a>
<ul>
<li class="chapter" data-level="9.1" data-path="sec91.html"><a href="sec91.html"><i class="fa fa-check"></i><b>9.1</b> Normal model</a></li>
<li class="chapter" data-level="9.2" data-path="sec92.html"><a href="sec92.html"><i class="fa fa-check"></i><b>9.2</b> Logit model</a></li>
<li class="chapter" data-level="9.3" data-path="sec93.html"><a href="sec93.html"><i class="fa fa-check"></i><b>9.3</b> Poisson model</a></li>
<li class="chapter" data-level="9.4" data-path="sec94.html"><a href="sec94.html"><i class="fa fa-check"></i><b>9.4</b> Summary</a></li>
<li class="chapter" data-level="9.5" data-path="sec95.html"><a href="sec95.html"><i class="fa fa-check"></i><b>9.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="Chap10.html"><a href="Chap10.html"><i class="fa fa-check"></i><b>10</b> Bayesian model averaging in variable selection</a>
<ul>
<li class="chapter" data-level="10.1" data-path="sec10_1.html"><a href="sec10_1.html"><i class="fa fa-check"></i><b>10.1</b> Foundation</a></li>
<li class="chapter" data-level="10.2" data-path="sec10_2.html"><a href="sec10_2.html"><i class="fa fa-check"></i><b>10.2</b> The Gaussian linear model</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="Chap11.html"><a href="Chap11.html"><i class="fa fa-check"></i><b>11</b> Semi-parametric and non-parametric models</a>
<ul>
<li class="chapter" data-level="11.1" data-path="sec11_1.html"><a href="sec11_1.html"><i class="fa fa-check"></i><b>11.1</b> Mixture models</a>
<ul>
<li class="chapter" data-level="11.1.1" data-path="sec11_1.html"><a href="sec11_1.html#sec11_11"><i class="fa fa-check"></i><b>11.1.1</b> Finite Gaussian mixtures</a></li>
<li class="chapter" data-level="11.1.2" data-path="sec11_1.html"><a href="sec11_1.html#sec11_12"><i class="fa fa-check"></i><b>11.1.2</b> Dirichlet processes</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="sec11_2.html"><a href="sec11_2.html"><i class="fa fa-check"></i><b>11.2</b> Non-parametric generalized additive models</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="Chap12.html"><a href="Chap12.html"><i class="fa fa-check"></i><b>12</b> Machine learning</a>
<ul>
<li class="chapter" data-level="12.1" data-path="sec12_1.html"><a href="sec12_1.html"><i class="fa fa-check"></i><b>12.1</b> Cross validation and Bayes factors</a></li>
<li class="chapter" data-level="12.2" data-path="sec12_2.html"><a href="sec12_2.html"><i class="fa fa-check"></i><b>12.2</b> Regularization</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="sec12_2.html"><a href="sec12_2.html#sec12_21"><i class="fa fa-check"></i><b>12.2.1</b> Bayesian LASSO</a></li>
<li class="chapter" data-level="12.2.2" data-path="sec12_2.html"><a href="sec12_2.html#sec12_22"><i class="fa fa-check"></i><b>12.2.2</b> Stochastic search variable selection</a></li>
<li class="chapter" data-level="12.2.3" data-path="sec12_2.html"><a href="sec12_2.html#sec12_23"><i class="fa fa-check"></i><b>12.2.3</b> Non-local priors</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="sec12_3.html"><a href="sec12_3.html"><i class="fa fa-check"></i><b>12.3</b> Bayesian additive regression trees</a></li>
<li class="chapter" data-level="12.4" data-path="sec12_4.html"><a href="sec12_4.html"><i class="fa fa-check"></i><b>12.4</b> Gaussian processes</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="Chap13.html"><a href="Chap13.html"><i class="fa fa-check"></i><b>13</b> Causal inference</a>
<ul>
<li class="chapter" data-level="13.1" data-path="sec13_1.html"><a href="sec13_1.html"><i class="fa fa-check"></i><b>13.1</b> Instrumental variables</a>
<ul>
<li class="chapter" data-level="13.1.1" data-path="sec13_1.html"><a href="sec13_1.html#sec13_11"><i class="fa fa-check"></i><b>13.1.1</b> Semi-parametric IV model</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="sec13_2.html"><a href="sec13_2.html"><i class="fa fa-check"></i><b>13.2</b> Regression discontinuity design</a></li>
<li class="chapter" data-level="13.3" data-path="sec13_3.html"><a href="sec13_3.html"><i class="fa fa-check"></i><b>13.3</b> Regression kink design</a></li>
<li class="chapter" data-level="13.4" data-path="sec13_4.html"><a href="sec13_4.html"><i class="fa fa-check"></i><b>13.4</b> Synthetic control</a></li>
<li class="chapter" data-level="13.5" data-path="sec13_5.html"><a href="sec13_5.html"><i class="fa fa-check"></i><b>13.5</b> Difference in difference estimation</a></li>
<li class="chapter" data-level="13.6" data-path="sec13_6.html"><a href="sec13_6.html"><i class="fa fa-check"></i><b>13.6</b> Event Analysis</a></li>
<li class="chapter" data-level="13.7" data-path="sec13_7.html"><a href="sec13_7.html"><i class="fa fa-check"></i><b>13.7</b> Bayesian exponential tilted empirical likelihood</a></li>
<li class="chapter" data-level="13.8" data-path="sec13_8.html"><a href="sec13_8.html"><i class="fa fa-check"></i><b>13.8</b> Double-Debiased machine learning causal effects</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="Chap14.html"><a href="Chap14.html"><i class="fa fa-check"></i><b>14</b> Approximation methods</a>
<ul>
<li class="chapter" data-level="14.1" data-path="sec14_1.html"><a href="sec14_1.html"><i class="fa fa-check"></i><b>14.1</b> Approximate Bayesian computation</a></li>
<li class="chapter" data-level="14.2" data-path="sec14_2.html"><a href="sec14_2.html"><i class="fa fa-check"></i><b>14.2</b> Bayesian synthetic likelihood</a></li>
<li class="chapter" data-level="14.3" data-path="sec14_3.html"><a href="sec14_3.html"><i class="fa fa-check"></i><b>14.3</b> Expectation propagation</a></li>
<li class="chapter" data-level="14.4" data-path="sec14_4.html"><a href="sec14_4.html"><i class="fa fa-check"></i><b>14.4</b> Integrated nested Laplace approximations</a></li>
<li class="chapter" data-level="14.5" data-path="sec14_5.html"><a href="sec14_5.html"><i class="fa fa-check"></i><b>14.5</b> Variational Bayes</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i>Appendix</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to Bayesian Data Modeling</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="sec91" class="section level2 hasAnchor" number="9.1">
<h2><span class="header-section-number">9.1</span> Normal model<a href="sec91.html#sec91" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The longitudinal/panel normal model establishes <span class="math inline">\(\boldsymbol{y}_i=\boldsymbol{X}_i\boldsymbol{\beta}+\boldsymbol{W}_i\boldsymbol{b}_i+\boldsymbol{\mu}_i\)</span> where <span class="math inline">\(\boldsymbol{y}_i\)</span> are <span class="math inline">\(T_i\)</span>-dimensional vectors corresponding to units <span class="math inline">\(i=1,2,\dots,N\)</span>, <span class="math inline">\(\boldsymbol{X}_i\)</span> and <span class="math inline">\(\boldsymbol{W}_i\)</span> are <span class="math inline">\(T_i\times K_1\)</span> and <span class="math inline">\(T_i\times K_2\)</span> matrices, respectively. In the statistical literature, <span class="math inline">\(\boldsymbol{\beta}\)</span> is a <span class="math inline">\(K_1\)</span>-dimensional vector of <em>fixed effects</em>, and <span class="math inline">\(\boldsymbol{b}_i\)</span> is a <span class="math inline">\(K_2\)</span>-dimensional vector of unit-specific <em>random effects</em> that allow unit-specific means, and enable capturing marginal dependence among the observations on the cross-sectional units. We assume normal stochastic errors, <span class="math inline">\(\boldsymbol{\mu}_i\sim{N}(\boldsymbol{0},\sigma^2\boldsymbol{I}_{T_i})\)</span>, which means that the likelihood function is</p>
<p><span class="math display">\[\begin{align*}
    p(\boldsymbol{\beta},\boldsymbol{b},\sigma^2\mid \boldsymbol{y}, \boldsymbol{X},\boldsymbol{W}) &amp; \propto \prod_{i=1}^N |\sigma^2\boldsymbol{I}_{T_i}|^{-1/2}\exp\left\{-\frac{1}{2\sigma^2}(\boldsymbol{y}_i-\boldsymbol{X}_i\boldsymbol{\beta}-\boldsymbol{W}_i\boldsymbol{b}_i)^{\top}(\boldsymbol{y}_i-\boldsymbol{X}_i\boldsymbol{\beta}-\boldsymbol{W}_i\boldsymbol{b}_i)\right\}\\
    &amp; = (\sigma^2)^{-\frac{\sum_{i=1}^N T_i}{2}}\exp\left\{-\frac{1}{2\sigma^2}\sum_{i=1}^N(\boldsymbol{y}_i-\boldsymbol{X}_i\boldsymbol{\beta}-\boldsymbol{W}_i\boldsymbol{b}_i)^{\top}(\boldsymbol{y}_i-\boldsymbol{X}_i\boldsymbol{\beta}-\boldsymbol{W}_i\boldsymbol{b}_i)\right\},
\end{align*}\]</span></p>
<p>where <span class="math inline">\(\boldsymbol{b}=[\boldsymbol{b}_1^{\top}, \boldsymbol{b}_2^{\top},\dots, \boldsymbol{b}_N^{\top}]^{\top}\)</span>.</p>
<p>Panel data modeling in the Bayesian approach assumes a hierarchical structure in the <em>random effects</em>. Following <span class="citation">Chib and Carlin (<a href="#ref-Chib1999">1999</a>)</span>, there is a first stage where <span class="math inline">\(\boldsymbol{b}_i\sim{N}(\boldsymbol{0},\boldsymbol{D})\)</span>, <span class="math inline">\(\boldsymbol{D}\)</span> allows serial correlation within each cross-sectional unit <span class="math inline">\(i\)</span>, and then, there is a second stage where <span class="math inline">\(\boldsymbol{D}\sim{I}{W}(d_0,d_0\boldsymbol{D}_0)\)</span>. Thus, we can see that there is an additional layer of priors as there is a prior on the hyperparameter <span class="math inline">\(\boldsymbol{D}\)</span>.</p>
<p>In addition, we have standard conjugate prior distributions for <span class="math inline">\(\boldsymbol{\beta}\)</span> and <span class="math inline">\(\sigma^2\)</span>, <span class="math inline">\(\boldsymbol{\beta} \sim {N}(\boldsymbol{\beta}_0,\boldsymbol{B}_0)\)</span> and
<span class="math inline">\(\sigma^2 \sim {I}{G}(\alpha_0, \delta_0)\)</span>.</p>
<p><span class="citation">Chib and Carlin (<a href="#ref-Chib1999">1999</a>)</span> propose a blocking algorithm to perform inference in longitudinal hierarchical models by considering the distribution of <span class="math inline">\(\boldsymbol{y}_i\)</span> marginalized over the random effects. Given that <span class="math inline">\(\boldsymbol{y}_i\mid \boldsymbol{\beta},\boldsymbol{b}_i,\sigma^2,\boldsymbol{X}_i,\boldsymbol{W}_i\sim N(\boldsymbol{X}_i\boldsymbol{\beta}+\boldsymbol{W}_i\boldsymbol{b}_i,\sigma^2\boldsymbol{I}_{T_i})\)</span>, we can see that <span class="math inline">\(\boldsymbol{y}_i\mid \boldsymbol{\beta},\boldsymbol{D},\sigma^2,\boldsymbol{X}_i,\boldsymbol{W}_i\sim{N}(\boldsymbol{X}_i\boldsymbol{\beta},\boldsymbol{V}_i)\)</span>, where <span class="math inline">\(\boldsymbol{V}_i=\sigma^2\boldsymbol{I}_{T_i}+\boldsymbol{W}_i\boldsymbol{D}\boldsymbol{W}_i^{\top}\)</span> given that <span class="math inline">\(\mathbb{E}[\boldsymbol{b}_i]=\boldsymbol{0}\)</span> and <span class="math inline">\(Var[\boldsymbol{b}_i]=\boldsymbol{D}\)</span>. If we have just random intercepts, then <span class="math inline">\(\boldsymbol{W}_i=\boldsymbol{i}_{T_i}\)</span>, where <span class="math inline">\(\boldsymbol{i}_{T_i}\)</span> is a <span class="math inline">\(T_i\)</span>-dimensional vector of ones. Thus, <span class="math inline">\(\boldsymbol{V}_i=\sigma^2\boldsymbol{I}_{T_i}+\sigma_{b}^2\boldsymbol{i}_{T_i}\boldsymbol{i}_{T_i}^{\top}\)</span>, the variance is <span class="math inline">\(\sigma^2+\sigma^2_{b}\)</span> and the covariance is <span class="math inline">\(\sigma^2_{b}\)</span> within each cross-sectional unit through time.</p>
<p>We can deduce the posterior distribution of <span class="math inline">\(\boldsymbol{\beta}\)</span> given <span class="math inline">\(\sigma^2\)</span> and <span class="math inline">\(\boldsymbol{D}\)</span>,
<span class="math display">\[\begin{align*}
    \pi(\boldsymbol{\beta}\mid \sigma^2, \boldsymbol{D},\boldsymbol{y}, \boldsymbol{X}, \boldsymbol{W}) &amp; \propto \exp\left\{-\frac{1}{2}\sum_{i=1}^N(\boldsymbol{y}_i-\boldsymbol{X}_i\boldsymbol{\beta})^{\top}\boldsymbol{V}_i^{-1}(\boldsymbol{y}_i-\boldsymbol{X}_i\boldsymbol{\beta})\right\}\\
    &amp;\times \exp\left\{-\frac{1}{2}(\boldsymbol{\beta}-\boldsymbol{\beta}_0)^{\top}\boldsymbol{B}_0^{-1}(\boldsymbol{\beta}-\boldsymbol{\beta}_0)\right\}.
\end{align*}\]</span>
This implies that (see Exercise 1)<br />
<span class="math display">\[\begin{equation*}
    \boldsymbol{\beta}\mid \sigma^2,\boldsymbol{D},\boldsymbol{y}, \boldsymbol{X}, \boldsymbol{W} \sim {N}(\boldsymbol{\beta}_n,\boldsymbol{B}_n),
\end{equation*}\]</span>
where <span class="math inline">\(\boldsymbol{B}_n = (\boldsymbol{B}_0^{-1} +\sum_{i=1}^N \boldsymbol{X}_i^{\top}\boldsymbol{V}_i^{-1}\boldsymbol{X}_i)^{-1}\)</span>, <span class="math inline">\(\boldsymbol{\beta}_n= \boldsymbol{B}_n(\boldsymbol{B}_0^{-1}\boldsymbol{\beta}_0 + \sum_{i=1}^N\boldsymbol{X}_i^{\top}\boldsymbol{V}_i^{-1}\boldsymbol{y}_i)\)</span>.</p>
<p>We can use the likelihood <span class="math inline">\(p(\boldsymbol{\beta},\boldsymbol{b}_i,\sigma^2\mid \boldsymbol{y}, \boldsymbol{X},\boldsymbol{W})\)</span> to get the posterior distributions of <span class="math inline">\(\boldsymbol{b}_i\)</span>, <span class="math inline">\(\sigma^2\)</span> and <span class="math inline">\(\boldsymbol{D}\)</span>. In particular,
<span class="math display">\[\begin{align*}
    \pi(\boldsymbol{b}_i\mid \boldsymbol{\beta},\sigma^2,\boldsymbol{D},\boldsymbol{y}, \boldsymbol{X}, \boldsymbol{W})&amp;\propto \exp\left\{-\frac{1}{2\sigma^2}\sum_{i=1}^N(\boldsymbol{y}_i-\boldsymbol{X}_i\boldsymbol{\beta}-\boldsymbol{W}_i\boldsymbol{b}_i)^{\top}(\boldsymbol{y}_i-\boldsymbol{X}_i\boldsymbol{\beta}-\boldsymbol{W}_i\boldsymbol{b}_i)\right\}\\
    &amp;\times \exp\left\{-\frac{1}{2}\sum_{i=1}^N \boldsymbol{b}_i^{\top}\boldsymbol{D}^{-1}\boldsymbol{b}_i\right\}\\
    &amp;\propto\exp\left\{-\frac{1}{2}\sum_{i=1}^N(-2\boldsymbol{b}_i^{\top}(\sigma^{-2}\boldsymbol{W}_i^{\top}(\boldsymbol{y}_i-\boldsymbol{X}_i\boldsymbol{\beta}))+ \boldsymbol{b}_i^{\top}(\sigma^{-2}\boldsymbol{W}_i^{\top}\boldsymbol{W}_i+\boldsymbol{D}^{-1})\boldsymbol{b}_i)\right\}\\
    &amp;\propto\exp\left\{-\frac{1}{2}(-2\boldsymbol{b}_i^{\top}\boldsymbol{B}_{ni}^{-1}\boldsymbol{B}_{ni}(\sigma^{-2}\boldsymbol{W}_i^{\top}(\boldsymbol{y}_i-\boldsymbol{X}_i\boldsymbol{\beta}))+ \boldsymbol{b}_i^{\top}\boldsymbol{B}_{ni}^{-1}\boldsymbol{b}_i)\right\}\\
    &amp;=\exp\left\{-\frac{1}{2}(-2\boldsymbol{b}_i^{\top}\boldsymbol{B}_{ni}^{-1}\boldsymbol{b}_{ni}+ \boldsymbol{b}_i^{\top}\boldsymbol{B}_{ni}^{-1}\boldsymbol{b}_i)\right\},
\end{align*}\]</span>
where <span class="math inline">\(\boldsymbol{B}_{ni}=(\sigma^{-2}\boldsymbol{W}_i^{\top}\boldsymbol{W}_i+\boldsymbol{D}^{-1})^{-1}\)</span> and <span class="math inline">\(\boldsymbol{b}_{ni}=\boldsymbol{B}_{ni}(\sigma^{-2}\boldsymbol{W}_i^{\top}(\boldsymbol{y}_i-\boldsymbol{X}_i\boldsymbol{\beta}))\)</span>.</p>
<p>We can complete the square in this expression by adding and subtracting <span class="math inline">\(\boldsymbol{b}_{ni}^{\top}\boldsymbol{B}_{ni}^{-1}\boldsymbol{b}_{ni}\)</span>. Thus,
<span class="math display">\[\begin{align*}
    \pi(\boldsymbol{b}_i\mid \boldsymbol{\beta},\sigma^2,\boldsymbol{D},\boldsymbol{y}, \boldsymbol{X}, \boldsymbol{W})&amp;\propto \exp\left\{-\frac{1}{2}(-2\boldsymbol{b}_i^{\top}\boldsymbol{B}_{ni}^{-1}\boldsymbol{b}_{ni}+ \boldsymbol{b}_i^{\top}\boldsymbol{B}_{ni}^{-1}\boldsymbol{b}_i+\boldsymbol{b}_{ni}^{\top}\boldsymbol{B}_{ni}^{-1}\boldsymbol{b}_{ni}-\boldsymbol{b}_{ni}^{\top}\boldsymbol{B}_{ni}^{-1}\boldsymbol{b}_{ni})\right\}\\
    &amp;\propto \exp\left\{(\boldsymbol{b}_i-\boldsymbol{b}_{ni})^{\top}\boldsymbol{B}_{ni}^{-1}(\boldsymbol{b}_i-\boldsymbol{b}_{ni})\right\}.
\end{align*}\]</span>
This is the kernel of a multivariate normal distribution with mean <span class="math inline">\(\boldsymbol{b}_{ni}\)</span> and variance <span class="math inline">\(\boldsymbol{B}_{ni}\)</span>. Thus,
<span class="math display">\[\begin{equation*}
    \boldsymbol{b}_i\mid \boldsymbol{\beta},\sigma^2,\boldsymbol{D},\boldsymbol{y}, \boldsymbol{X}, \boldsymbol{W} \sim {N}(\boldsymbol{b}_{ni},\boldsymbol{B}_{ni}),
\end{equation*}\]</span>
Let’s see the posterior distribution of <span class="math inline">\(\sigma^2\)</span>,
<span class="math display">\[\begin{align*}
    \pi(\sigma^2\mid \boldsymbol{\beta},\boldsymbol{b},\boldsymbol{y}, \boldsymbol{X}, \boldsymbol{W})&amp;\propto (\sigma^2)^{-\frac{\sum_{i=1}^N T_i}{2}}\exp\left\{-\frac{1}{2\sigma^2}\sum_{i=1}^N(\boldsymbol{y}_i-\boldsymbol{X}_i\boldsymbol{\beta}-\boldsymbol{W}_i\boldsymbol{b}_i)^{\top}(\boldsymbol{y}_i-\boldsymbol{X}_i\boldsymbol{\beta}-\boldsymbol{W}_i\boldsymbol{b}_i)\right\}\\
    &amp;\times (\sigma^2)^{-\alpha_0-1}\exp\left\{-\frac{\delta_0}{\sigma^2}\right\}\\
    &amp;=(\sigma^2)^{-\frac{\sum_{i=1}^N T_i}{2}-\alpha_0-1}\\
    &amp;\times \exp\left\{-\frac{1}{\sigma^2}\left(\delta_0+\sum_{i=1}^N\frac{(\boldsymbol{y}_i-\boldsymbol{X}_i\boldsymbol{\beta}-\boldsymbol{W}_i\boldsymbol{b}_i)^{\top}(\boldsymbol{y}_i-\boldsymbol{X}_i\boldsymbol{\beta}-\boldsymbol{W}_i\boldsymbol{b}_i)}{2}\right)\right\}.
\end{align*}\]</span>
Thus,
<span class="math display">\[\begin{equation*}
    \sigma^2\mid  \boldsymbol{\beta}, \boldsymbol{b}, \boldsymbol{y}, \boldsymbol{X}, \boldsymbol{W} \sim {I}{G}(\alpha_n, \delta_n),
\end{equation*}\]</span>
where <span class="math inline">\(\alpha_n=\alpha_0+\frac{1}{2}\sum_{i=1}^N T_i\)</span> and <span class="math inline">\(\delta_n=\delta_0+\frac{1}{2}\sum_{i=1}^N(\boldsymbol{y}_i-\boldsymbol{X}_i\boldsymbol{\beta}-\boldsymbol{W}_i\boldsymbol{b}_i)^{\top}(\boldsymbol{y}_i-\boldsymbol{X}_i\boldsymbol{\beta}-\boldsymbol{W}_i\boldsymbol{b}_i)\)</span>.</p>
<p>The posterior distribution of <span class="math inline">\(\boldsymbol{D}\)</span> is the following,
<span class="math display">\[\begin{align*}
    \pi(\boldsymbol{D}\mid \boldsymbol{b})&amp;\propto  |\boldsymbol{D}|^{-N/2} \exp\left\{-\frac{1}{2}\sum_{i=1}^N \boldsymbol{b}_i^{\top}\boldsymbol{D}^{-1}\boldsymbol{b}_i\right\}\\
    &amp;\times |\boldsymbol{D}|^{-(d_0+K_2+1)/2}\exp\left\{-\frac{1}{2}tr(d_0\boldsymbol{D}_0\boldsymbol{D}^{-1})\right\}\\
    &amp;=|\boldsymbol{D}|^{-(d_0+N+K_2+1)/2}\exp\left\{-\frac{1}{2}tr\left(\left(d_0\boldsymbol{D}_0+\sum_{i=1}^N\boldsymbol{b}_i\boldsymbol{b}_i^{\top}\right)\boldsymbol{D}^{-1}\right) \right\}.
\end{align*}\]</span>
This is the kernel of an inverse Wishart distribution with degrees of freedom <span class="math inline">\(d_n=d_0+N\)</span> and scale matrix <span class="math inline">\(\boldsymbol{D}_n=d_0\boldsymbol{D}_0+\sum_{i=1}^N\boldsymbol{b}_i\boldsymbol{b}_i^{\top}\)</span>. Thus,<br />
<span class="math display">\[\begin{equation*}
    \boldsymbol{D}\mid  \boldsymbol{b} \sim {I}{W}(d_n, \boldsymbol{D}_n).
\end{equation*}\]</span>
Observe that the posterior distribution of <span class="math inline">\(\boldsymbol{D}\)</span> dependents just on <span class="math inline">\(\boldsymbol{b}\)</span>.</p>
<p>All the posterior conditional distributions belong to standard families, this implies that we can use a Gibbs sampling algorithm to perform inference in these hierarchical normal models.</p>
<p><strong>Example: The relation between productivity and public investment</strong></p>
<p>We used the dataset named <em>8PublicCap.csv</em> used by <span class="citation">Ramírez Hassan (<a href="#ref-Ramirez2017">2017</a>)</span> to analyze the relation between public investment and gross state product in the setting of a spatial panel dataset consisting of 48 US states from 1970 to 1986.
In particular, we perform inference based on the following equation
<span class="math display">\[\begin{equation*}
    \log(\text{gsp}_{it})=b_i+\beta_1+\beta_2\log(\text{pcap}_{it})+\beta_3\log(\text{pc}_{it})+\beta_4\log(\text{emp}_{it})+\beta_5\text{unemp}_{it}+\mu_{it},
\end{equation*}\]</span></p>
<p>where <em>gsp</em> in the gross state product, <em>pcap</em> is public capital, and <em>pc</em> is private capital all in USD, <em>emp</em> is employment (people), and <em>unemp</em> is the unemployment rate in percentage.</p>
<p>The following Algorithm shows how to perform inference in hierarchical longitudinal normal models in our GUI. See also Chapter <a href="Chap5.html#Chap5">5</a> for details regarding the dataset structure.</p>
<div class="algorithm">
<div style="background-color: #f8f9fa; padding: 15px; border-left: 5px solid #343a40; box-shadow: 4px 4px 10px rgba(0, 0, 0, 0.1); border-radius: 5px;">
<p><strong>Algorithm: Hierarchical Longitudinal Normal Models</strong></p>
<ol style="list-style-type: decimal">
<li><p>Select <em>Hierarchical Longitudinal Model</em> on the top panel</p></li>
<li><p>Select <em>Normal</em> model using the left radio button</p></li>
<li><p>Upload the dataset, selecting first if there is a header in the file, and the kind of separator in the <em>csv</em> file of the dataset (comma, semicolon, or tab). Then, use the <em>Browse</em> button under the <strong>Choose File</strong> legend</p></li>
<li><p>Select MCMC iterations, burn-in, and thinning parameters using the <em>Range sliders</em></p></li>
<li><p>Write down the formula of the <em>fixed effects</em> equation in the <strong>Main Equation: Fixed Effects</strong> box. This formula must be written using the syntax of the <em>formula</em> command of <strong>R</strong> software. This equation includes intercept by default, do not include it in the equation</p></li>
<li><p>Write down the formula of the <em>random effects</em> equation in the <strong>Main Equation: Random Effects</strong> box without writing the dependent variable, that is, starting the equation with the <em>tilde</em> (“~”) symbol. This formula must be written using the syntax of the <em>formula</em> command of <strong>R</strong> software. This equation includes intercept by default, do not include it in the equation. If there are just random intercepts do not write anything in this box</p></li>
<li><p>Write down the name of the grouping variable, that is, the variable that indicates the cross-sectional units</p></li>
<li><p>Set the hyperparameters of the <em>fixed effects</em>: mean vector, covariance matrix, shape and scale parameters. This step is not necessary as by default our GUI uses non-informative priors</p></li>
<li><p>Set the hyperparameters of the <em>random effects</em>: degrees of freedom and scale matrix of the inverse Wishart distribution. This step is not necessary as by default our GUI uses non-informative priors</p></li>
<li><p>Click the <em>Go!</em> button</p></li>
<li><p>Analyze results</p></li>
<li><p>Download posterior chains and diagnostic plots using the <em>Download Posterior Chains</em> and <em>Download Posterior Graphs</em> buttons</p></li>
</ol>
</div>
</div>
<p>We ask in Exercise 2 to run this application in our GUI using 10,000 MCMC iterations plus a burn-in equal to 5,000 iterations, and a thinning parameter equal to 1. We also used the default values for the hyperparameters of the prior distributions, that is, <span class="math inline">\(\boldsymbol{\beta}_0=\boldsymbol{0}_5\)</span>, <span class="math inline">\(\boldsymbol{B}_0=\boldsymbol{I}_5\)</span>, <span class="math inline">\(\alpha_0=\delta_0=0.001\)</span>, <span class="math inline">\(d_0=5\)</span> and <span class="math inline">\(\boldsymbol{D}_0=\boldsymbol{I}_1\)</span>. It seems that all posterior draws come from stationary distributions, as suggested by the diagnostics and posterior plots (see Exercise 2).</p>
<p>The following code uses the command <em>MCMChregress</em> from the package <em>MCMCpack</em> to run this application. This command is also used by our GUI to perform inference in hierarchical longitudinal normal models.</p>
<p>We can see that the 95% symmetric credible intervals for public capital, private capital, employment, and unemployment are (-2.54e-02, -2.06e-02), (2.92e-01, 2.96e-01), (7.62e-01, 7.67e-01) and (-5.47e-03, -5.31e-03), respectively. The posterior mean elasticity estimate of public capital to GSP is -0.023, that is, an increase by 1% in public capital means a 0.023% decrease in gross state product. The posterior mean estimates of private capital and employment elasticities are 0.294 and 0.765, respectively. In addition, a 1 percentage point increase in the unemployment rate means a decrease of 0.54% in GSP. It seems that all these variables are statistically relevant.</p>
<p>In addition, the posterior mean estimates of the variance associated with the unobserved heterogeneity and stochastic errors are 1.06e-01 and 1.45e-03. We obtained the posterior chain of the proportion of the variance associated with the unobserved heterogeneity. The 95% symmetric credible interval is (0.98, 0.99) for this proportion, that is, unobserved heterogeneity is very important to explain the total variability.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="sec91.html#cb1-1" tabindex="-1"></a><span class="fu">rm</span>(<span class="at">list =</span> <span class="fu">ls</span>())</span>
<span id="cb1-2"><a href="sec91.html#cb1-2" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">12345</span>)</span>
<span id="cb1-3"><a href="sec91.html#cb1-3" tabindex="-1"></a>DataGSP <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">&quot;https://raw.githubusercontent.com/besmarter/BSTApp/refs/heads/master/DataApp/8PublicCap.csv&quot;</span>, <span class="at">sep =</span> <span class="st">&quot;,&quot;</span>, <span class="at">header =</span> <span class="cn">TRUE</span>, <span class="at">quote =</span> <span class="st">&quot;&quot;</span>)</span>
<span id="cb1-4"><a href="sec91.html#cb1-4" tabindex="-1"></a><span class="fu">attach</span>(DataGSP)</span>
<span id="cb1-5"><a href="sec91.html#cb1-5" tabindex="-1"></a>K1 <span class="ot">&lt;-</span> <span class="dv">5</span>; K2 <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb1-6"><a href="sec91.html#cb1-6" tabindex="-1"></a>b0 <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">0</span>, K1); B0 <span class="ot">&lt;-</span> <span class="fu">diag</span>(K1)</span>
<span id="cb1-7"><a href="sec91.html#cb1-7" tabindex="-1"></a>r0 <span class="ot">&lt;-</span> <span class="dv">5</span>; R0 <span class="ot">&lt;-</span> <span class="fu">diag</span>(K2)</span>
<span id="cb1-8"><a href="sec91.html#cb1-8" tabindex="-1"></a>a0 <span class="ot">&lt;-</span> <span class="fl">0.001</span>; d0 <span class="ot">&lt;-</span> <span class="fl">0.001</span></span>
<span id="cb1-9"><a href="sec91.html#cb1-9" tabindex="-1"></a>Resultshreg <span class="ot">&lt;-</span> MCMCpack<span class="sc">::</span><span class="fu">MCMChregress</span>(<span class="at">fixed =</span> <span class="fu">log</span>(gsp)<span class="sc">~</span><span class="fu">log</span>(pcap)<span class="sc">+</span><span class="fu">log</span>(pc)<span class="sc">+</span><span class="fu">log</span>(emp)<span class="sc">+</span>unemp, <span class="at">random =</span> <span class="sc">~</span><span class="dv">1</span>, <span class="at">group =</span> <span class="st">&quot;id&quot;</span>, <span class="at">data =</span> DataGSP, <span class="at">burnin =</span> <span class="dv">5000</span>, <span class="at">mcmc =</span> <span class="dv">10000</span>, <span class="at">thin =</span> <span class="dv">1</span>, <span class="at">r =</span> r0, <span class="at">R =</span> R0, <span class="at">nu =</span> a0, <span class="at">delta =</span> d0)</span>
<span id="cb1-10"><a href="sec91.html#cb1-10" tabindex="-1"></a>Betas <span class="ot">&lt;-</span> Resultshreg[[<span class="st">&quot;mcmc&quot;</span>]][,<span class="dv">1</span><span class="sc">:</span>K1]</span>
<span id="cb1-11"><a href="sec91.html#cb1-11" tabindex="-1"></a>Sigma2RanEff <span class="ot">&lt;-</span> Resultshreg[[<span class="st">&quot;mcmc&quot;</span>]][,<span class="dv">54</span>]</span>
<span id="cb1-12"><a href="sec91.html#cb1-12" tabindex="-1"></a>Sigma2 <span class="ot">&lt;-</span> Resultshreg[[<span class="st">&quot;mcmc&quot;</span>]][,<span class="dv">55</span>]</span>
<span id="cb1-13"><a href="sec91.html#cb1-13" tabindex="-1"></a><span class="fu">summary</span>(Betas)</span>
<span id="cb1-14"><a href="sec91.html#cb1-14" tabindex="-1"></a><span class="fu">summary</span>(Sigma2RanEff)</span>
<span id="cb1-15"><a href="sec91.html#cb1-15" tabindex="-1"></a><span class="fu">summary</span>(Sigma2)</span></code></pre></div>
<p>There are many extensions of this model. For instance, <span class="citation">Chib and Carlin (<a href="#ref-Chib1999">1999</a>)</span> propose introducing heteroskedasticity in this model by assuming <span class="math inline">\(\mu_{it} \mid \tau_{it} \sim N(0, \sigma^2/\tau_{it})\)</span>, <span class="math inline">\(\tau_{it} \sim G(v/2,v/2)\)</span>. We ask in Exercise 2 to perform inference on the relationship between productivity and public investment using this setting.</p>
<p>Another potential extension is to allow dependence between <span class="math inline">\(\boldsymbol{b}_i\)</span> and some controls, let’s say <span class="math inline">\(\boldsymbol{z}_i\)</span>, a <span class="math inline">\(K_3\)</span>-dimensional vector, and assume <span class="math inline">\(\boldsymbol{b}_i \sim N(\boldsymbol{Z}_i \boldsymbol{\gamma}, \boldsymbol{D})\)</span> where <span class="math inline">\(\boldsymbol{Z}_i = \mathbf{I}_{K_2} \otimes \boldsymbol{z}_i^{\top}\)</span>, and complete the model using a prior for <span class="math inline">\(\boldsymbol{\gamma}\)</span>, <span class="math inline">\(\boldsymbol{\gamma} \sim N(\boldsymbol{\gamma}_0, \boldsymbol{\Gamma}_0)\)</span>. We ask to perform a simulation using this setting in Exercise 3.</p>
<p><strong>Example: Simulation exercise of the longitudinal normal model with heteroskedasticity</strong></p>
<p>Let’s perform a simulation exercise to assess some potential extensions of the longitudinal hierarchical normal model. The point of departure is to assume that
<span class="math display">\[y_{it}=\beta_0+\beta_1x_{it1}+\beta_2x_{it2}+\beta_3x_{it3}+b_i+w_{it1}b_{i1}+\mu_{it},\]</span>
where <span class="math inline">\(x_{itk}\sim N(0,1)\)</span>, <span class="math inline">\(k=1,2,3\)</span>, <span class="math inline">\(w_{it1}\sim N(0,1)\)</span>, <span class="math inline">\(b_i\sim N(0, 0.7^{1/2})\)</span>, <span class="math inline">\(b_{i1}\sim N(0, 0.6^{1/2})\)</span>, <span class="math inline">\(\mu_{it}\sim N(0, (0.1/\tau)^{1/2})\)</span>, <span class="math inline">\(\tau_{it}\sim G(v/2,v/2)\)</span> and <span class="math inline">\(\boldsymbol{\beta}=[0.5 \ 0.4 \ 0.6 \ -0.6]^{\top}\)</span>, <span class="math inline">\(i=1,2,\dots,50\)</span>. The sample size is 2000 in an <em>unbalanced panel structure</em>.</p>
<p>Following same stages as in this section and Exercise 1, the posterior conditional distributions assuming that <span class="math inline">\(\mu_{it}\mid \tau_{it}\sim N(0, \sigma^2/\tau_{it})\)</span>, <span class="math inline">\(\tau_{it}\sim G(v/2,v/2)\)</span> are given by
<span class="math display">\[\begin{equation*}
    \boldsymbol{\beta}\mid \sigma^2,\boldsymbol{\tau},\boldsymbol{D},\boldsymbol{y}, \boldsymbol{X}, \boldsymbol{W} \sim {N}(\boldsymbol{\beta}_n,\boldsymbol{B}_n),
\end{equation*}\]</span>
where <span class="math inline">\(\boldsymbol{\tau}=[\tau_{it}]^{\top}\)</span>, <span class="math inline">\(\boldsymbol{B}_n = (\boldsymbol{B}_0^{-1} +\sum_{i=1}^N \boldsymbol{X}_i^{\top}\boldsymbol{V}_i^{-1}\boldsymbol{X}_i)^{-1}\)</span>, <span class="math inline">\(\boldsymbol{\beta}_n= \boldsymbol{B}_n(\boldsymbol{B}_0^{-1}\boldsymbol{\beta}_0 + \sum_{i=1}^N\boldsymbol{X}_i^{\top}\boldsymbol{V}_i^{-1}\boldsymbol{y}_i)\)</span>, <span class="math inline">\(\boldsymbol{V}_i=\sigma^2\boldsymbol{\Psi}_i+\sigma_{b}^2\boldsymbol{i}_{T_i}\boldsymbol{i}_{T_i}^{\top}\)</span> and <span class="math inline">\(\boldsymbol{\Psi}_i=diag\left\{\tau_{it}^{-1}\right\}\)</span>.
<span class="math display">\[\begin{equation*}
    \boldsymbol{b}_i\mid \boldsymbol{\beta},\sigma^2,\boldsymbol{\tau},\boldsymbol{D},\boldsymbol{y}, \boldsymbol{X}, \boldsymbol{W} \sim {N}(\boldsymbol{b}_{ni},\boldsymbol{B}_{ni}),
\end{equation*}\]</span>
where <span class="math inline">\(\boldsymbol{B}_{ni}=(\sigma^{-2}\boldsymbol{W}_i^{\top}\boldsymbol{\Psi}_i^{-1}\boldsymbol{W}_i+\boldsymbol{D}^{-1})^{-1}\)</span> and <span class="math inline">\(\boldsymbol{b}_{ni}=\boldsymbol{B}_{ni}(\sigma^{-2}\boldsymbol{W}_i^{\top}\boldsymbol{\Psi}_i^{-1}(\boldsymbol{y}_i-\boldsymbol{X}_i\boldsymbol{\beta}))\)</span>.
<span class="math display">\[\begin{equation*}
    \sigma^2\mid  \boldsymbol{\beta}, \boldsymbol{b}, \boldsymbol{\tau}, \boldsymbol{y}, \boldsymbol{X}, \boldsymbol{W} \sim {I}{G}(\alpha_n, \delta_n),
\end{equation*}\]</span>
where <span class="math inline">\(\alpha_n=\alpha_0+\frac{1}{2}\sum_{i=1}^N T_i\)</span> and <span class="math inline">\(\delta_n=\delta_0+\frac{1}{2}\sum_{i=1}^N(\boldsymbol{y}_i-\boldsymbol{X}_i\boldsymbol{\beta}-\boldsymbol{W}_i\boldsymbol{b}_i)^{\top}\boldsymbol{\Psi}_i^{-1}(\boldsymbol{y}_i-\boldsymbol{X}_i\boldsymbol{\beta}-\boldsymbol{W}_i\boldsymbol{b}_i)\)</span>.<br />
<span class="math display">\[\begin{equation*}
    \boldsymbol{D}\mid  \boldsymbol{b} \sim {I}{W}(d_n, \boldsymbol{D}_n),
\end{equation*}\]</span>
where <span class="math inline">\(d_n=d_0+N\)</span> and <span class="math inline">\(\boldsymbol{D}_n=d_0\boldsymbol{D}_0+\sum_{i=1}^N\boldsymbol{b}_i\boldsymbol{b}_i^{\top}\)</span>. And
<span class="math display">\[\begin{equation*}
    \tau_{it}\mid \sigma^2, \boldsymbol{\beta}, \boldsymbol{b}, \boldsymbol{y}, \boldsymbol{X}, \boldsymbol{W} \sim {G}(v_{1n}/2, v_{2ni}/2),
\end{equation*}\]</span>
where <span class="math inline">\(v_{1n}=v+1\)</span> and <span class="math inline">\(v_{2ni}=v+\sigma^{-2}(y_{it}-\boldsymbol{x}_{it}^{\top}\boldsymbol{\beta}-\boldsymbol{w}_{it}^{\top}\boldsymbol{b}_i)^2\)</span>.</p>
<p>The following code implements this simulation, and gets draws of the posterior distributions. We set MCMC iterations, burn-in and thinning parameters equal to 5000, 1000 and 1, respectively. In addition, <span class="math inline">\(\boldsymbol{\beta}_0=\boldsymbol{0}_5\)</span>, <span class="math inline">\(\boldsymbol{B}_0=\boldsymbol{I}_5\)</span>, <span class="math inline">\(\alpha_0=\delta_0=0.001\)</span>, <span class="math inline">\(d_0=2\)</span>, <span class="math inline">\(\boldsymbol{D}_0=\boldsymbol{I}_2\)</span> and <span class="math inline">\(v=5\)</span>.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="sec91.html#cb2-1" tabindex="-1"></a><span class="fu">rm</span>(<span class="at">list =</span> <span class="fu">ls</span>()); <span class="fu">set.seed</span>(<span class="dv">010101</span>)</span>
<span id="cb2-2"><a href="sec91.html#cb2-2" tabindex="-1"></a>NT <span class="ot">&lt;-</span> <span class="dv">2000</span>; N <span class="ot">&lt;-</span> <span class="dv">50</span></span>
<span id="cb2-3"><a href="sec91.html#cb2-3" tabindex="-1"></a>id <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span>N, <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span>N, NT <span class="sc">-</span> N,<span class="at">replace=</span><span class="cn">TRUE</span>))</span>
<span id="cb2-4"><a href="sec91.html#cb2-4" tabindex="-1"></a><span class="fu">table</span>(id)</span>
<span id="cb2-5"><a href="sec91.html#cb2-5" tabindex="-1"></a>x1 <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(NT); x2 <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(NT); x3 <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(NT) </span>
<span id="cb2-6"><a href="sec91.html#cb2-6" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="dv">1</span>, x1, x2, x3); K1 <span class="ot">&lt;-</span> <span class="fu">dim</span>(X)[<span class="dv">2</span>]</span>
<span id="cb2-7"><a href="sec91.html#cb2-7" tabindex="-1"></a>w1 <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(NT); W <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="dv">1</span>, w1)</span>
<span id="cb2-8"><a href="sec91.html#cb2-8" tabindex="-1"></a>K2 <span class="ot">&lt;-</span> <span class="fu">dim</span>(W)[<span class="dv">2</span>]; B <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">0.5</span>, <span class="fl">0.4</span>, <span class="fl">0.6</span>, <span class="sc">-</span><span class="fl">0.6</span>)</span>
<span id="cb2-9"><a href="sec91.html#cb2-9" tabindex="-1"></a>D <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">0.7</span>, <span class="fl">0.6</span>)</span>
<span id="cb2-10"><a href="sec91.html#cb2-10" tabindex="-1"></a>b1 <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N, <span class="dv">0</span>, <span class="at">sd =</span> D[<span class="dv">1</span>]<span class="sc">^</span><span class="fl">0.5</span>)</span>
<span id="cb2-11"><a href="sec91.html#cb2-11" tabindex="-1"></a>b2 <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N, <span class="dv">0</span>, <span class="at">sd =</span> D[<span class="dv">2</span>]<span class="sc">^</span><span class="fl">0.5</span>)</span>
<span id="cb2-12"><a href="sec91.html#cb2-12" tabindex="-1"></a>b <span class="ot">&lt;-</span> <span class="fu">cbind</span>(b1, b2)</span>
<span id="cb2-13"><a href="sec91.html#cb2-13" tabindex="-1"></a>v <span class="ot">&lt;-</span> <span class="dv">5</span>; tau <span class="ot">&lt;-</span> <span class="fu">rgamma</span>(NT, <span class="at">shape =</span> v<span class="sc">/</span><span class="dv">2</span>, <span class="at">rate =</span> v<span class="sc">/</span><span class="dv">2</span>)</span>
<span id="cb2-14"><a href="sec91.html#cb2-14" tabindex="-1"></a>sig2 <span class="ot">&lt;-</span> <span class="fl">0.1</span>; u <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(NT, <span class="dv">0</span>, <span class="at">sd =</span> (sig2<span class="sc">/</span>tau)<span class="sc">^</span><span class="fl">0.5</span>)</span>
<span id="cb2-15"><a href="sec91.html#cb2-15" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="cn">NULL</span></span>
<span id="cb2-16"><a href="sec91.html#cb2-16" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>NT){</span>
<span id="cb2-17"><a href="sec91.html#cb2-17" tabindex="-1"></a>    yi <span class="ot">&lt;-</span> X[i,]<span class="sc">%*%</span>B <span class="sc">+</span> W[i,]<span class="sc">%*%</span>b[id[i],] <span class="sc">+</span> u[i] </span>
<span id="cb2-18"><a href="sec91.html#cb2-18" tabindex="-1"></a>    y <span class="ot">&lt;-</span> <span class="fu">c</span>(y, yi)</span>
<span id="cb2-19"><a href="sec91.html#cb2-19" tabindex="-1"></a>}</span>
<span id="cb2-20"><a href="sec91.html#cb2-20" tabindex="-1"></a>Data <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(<span class="fu">cbind</span>(y, x1, x2, x3, w1, id))</span>
<span id="cb2-21"><a href="sec91.html#cb2-21" tabindex="-1"></a>mcmc <span class="ot">&lt;-</span> <span class="dv">5000</span>; burnin <span class="ot">&lt;-</span> <span class="dv">1000</span>; thin <span class="ot">&lt;-</span> <span class="dv">1</span>; tot <span class="ot">&lt;-</span> mcmc <span class="sc">+</span> burnin</span>
<span id="cb2-22"><a href="sec91.html#cb2-22" tabindex="-1"></a>b0 <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">0</span>, K1); B0 <span class="ot">&lt;-</span> <span class="fu">diag</span>(K1); B0i <span class="ot">&lt;-</span> <span class="fu">solve</span>(B0) </span>
<span id="cb2-23"><a href="sec91.html#cb2-23" tabindex="-1"></a>r0 <span class="ot">&lt;-</span> K2; R0 <span class="ot">&lt;-</span> <span class="fu">diag</span>(K2); a0 <span class="ot">&lt;-</span> <span class="fl">0.001</span>; d0 <span class="ot">&lt;-</span> <span class="fl">0.001</span></span>
<span id="cb2-24"><a href="sec91.html#cb2-24" tabindex="-1"></a>PostBeta <span class="ot">&lt;-</span> <span class="cf">function</span>(sig2, D, tau){</span>
<span id="cb2-25"><a href="sec91.html#cb2-25" tabindex="-1"></a>    XVX <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="dv">0</span>, K1, K1)</span>
<span id="cb2-26"><a href="sec91.html#cb2-26" tabindex="-1"></a>    XVy <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="dv">0</span>, K1, <span class="dv">1</span>)</span>
<span id="cb2-27"><a href="sec91.html#cb2-27" tabindex="-1"></a>    <span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>N){</span>
<span id="cb2-28"><a href="sec91.html#cb2-28" tabindex="-1"></a>        ids <span class="ot">&lt;-</span> <span class="fu">which</span>(id <span class="sc">==</span> i)</span>
<span id="cb2-29"><a href="sec91.html#cb2-29" tabindex="-1"></a>        Ti <span class="ot">&lt;-</span> <span class="fu">length</span>(ids)</span>
<span id="cb2-30"><a href="sec91.html#cb2-30" tabindex="-1"></a>        Wi <span class="ot">&lt;-</span> W[ids, ]</span>
<span id="cb2-31"><a href="sec91.html#cb2-31" tabindex="-1"></a>        taui <span class="ot">&lt;-</span> tau[ids]</span>
<span id="cb2-32"><a href="sec91.html#cb2-32" tabindex="-1"></a>        Vi <span class="ot">&lt;-</span> sig2<span class="sc">*</span><span class="fu">solve</span>(<span class="fu">diag</span>(<span class="dv">1</span><span class="sc">/</span>taui)) <span class="sc">+</span> Wi<span class="sc">%*%</span>D<span class="sc">%*%</span><span class="fu">t</span>(Wi)</span>
<span id="cb2-33"><a href="sec91.html#cb2-33" tabindex="-1"></a>        ViInv <span class="ot">&lt;-</span> <span class="fu">solve</span>(Vi)</span>
<span id="cb2-34"><a href="sec91.html#cb2-34" tabindex="-1"></a>        Xi <span class="ot">&lt;-</span> X[ids, ]</span>
<span id="cb2-35"><a href="sec91.html#cb2-35" tabindex="-1"></a>        XVXi <span class="ot">&lt;-</span> <span class="fu">t</span>(Xi)<span class="sc">%*%</span>ViInv<span class="sc">%*%</span>Xi</span>
<span id="cb2-36"><a href="sec91.html#cb2-36" tabindex="-1"></a>        XVX <span class="ot">&lt;-</span> XVX <span class="sc">+</span> XVXi</span>
<span id="cb2-37"><a href="sec91.html#cb2-37" tabindex="-1"></a>        yi <span class="ot">&lt;-</span> y[ids]</span>
<span id="cb2-38"><a href="sec91.html#cb2-38" tabindex="-1"></a>        XVyi <span class="ot">&lt;-</span> <span class="fu">t</span>(Xi)<span class="sc">%*%</span>ViInv<span class="sc">%*%</span>yi</span>
<span id="cb2-39"><a href="sec91.html#cb2-39" tabindex="-1"></a>        XVy <span class="ot">&lt;-</span> XVy <span class="sc">+</span> XVyi</span>
<span id="cb2-40"><a href="sec91.html#cb2-40" tabindex="-1"></a>    }</span>
<span id="cb2-41"><a href="sec91.html#cb2-41" tabindex="-1"></a>    Bn <span class="ot">&lt;-</span> <span class="fu">solve</span>(B0i <span class="sc">+</span> XVX)</span>
<span id="cb2-42"><a href="sec91.html#cb2-42" tabindex="-1"></a>    bn <span class="ot">&lt;-</span> Bn<span class="sc">%*%</span>(B0i<span class="sc">%*%</span>b0 <span class="sc">+</span> XVy)</span>
<span id="cb2-43"><a href="sec91.html#cb2-43" tabindex="-1"></a>    Beta <span class="ot">&lt;-</span> MASS<span class="sc">::</span><span class="fu">mvrnorm</span>(<span class="dv">1</span>, bn, Bn)</span>
<span id="cb2-44"><a href="sec91.html#cb2-44" tabindex="-1"></a>    <span class="fu">return</span>(Beta)</span>
<span id="cb2-45"><a href="sec91.html#cb2-45" tabindex="-1"></a>}</span>
<span id="cb2-46"><a href="sec91.html#cb2-46" tabindex="-1"></a>Postb <span class="ot">&lt;-</span> <span class="cf">function</span>(Beta, sig2, D, tau){</span>
<span id="cb2-47"><a href="sec91.html#cb2-47" tabindex="-1"></a>    Di <span class="ot">&lt;-</span> <span class="fu">solve</span>(D);     bis <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="dv">0</span>, N, K2)</span>
<span id="cb2-48"><a href="sec91.html#cb2-48" tabindex="-1"></a>    <span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>N){</span>
<span id="cb2-49"><a href="sec91.html#cb2-49" tabindex="-1"></a>        ids <span class="ot">&lt;-</span> <span class="fu">which</span>(id <span class="sc">==</span> i)</span>
<span id="cb2-50"><a href="sec91.html#cb2-50" tabindex="-1"></a>        Wi <span class="ot">&lt;-</span> W[ids, ]; Xi <span class="ot">&lt;-</span> X[ids, ]</span>
<span id="cb2-51"><a href="sec91.html#cb2-51" tabindex="-1"></a>        yi <span class="ot">&lt;-</span> y[ids]; taui <span class="ot">&lt;-</span> tau[ids]</span>
<span id="cb2-52"><a href="sec91.html#cb2-52" tabindex="-1"></a>        Taui <span class="ot">&lt;-</span> <span class="fu">solve</span>(<span class="fu">diag</span>(<span class="dv">1</span><span class="sc">/</span>taui))</span>
<span id="cb2-53"><a href="sec91.html#cb2-53" tabindex="-1"></a>        Wtei <span class="ot">&lt;-</span> sig2<span class="sc">^</span>(<span class="sc">-</span><span class="dv">1</span>)<span class="sc">*</span><span class="fu">t</span>(Wi)<span class="sc">%*%</span>Taui<span class="sc">%*%</span>(yi <span class="sc">-</span> Xi<span class="sc">%*%</span>Beta)</span>
<span id="cb2-54"><a href="sec91.html#cb2-54" tabindex="-1"></a>        Bni <span class="ot">&lt;-</span> <span class="fu">solve</span>(sig2<span class="sc">^</span>(<span class="sc">-</span><span class="dv">1</span>)<span class="sc">*</span><span class="fu">t</span>(Wi)<span class="sc">%*%</span>Taui<span class="sc">%*%</span>Wi <span class="sc">+</span> Di)</span>
<span id="cb2-55"><a href="sec91.html#cb2-55" tabindex="-1"></a>        bni <span class="ot">&lt;-</span> Bni<span class="sc">%*%</span>Wtei</span>
<span id="cb2-56"><a href="sec91.html#cb2-56" tabindex="-1"></a>        bi <span class="ot">&lt;-</span> MASS<span class="sc">::</span><span class="fu">mvrnorm</span>(<span class="dv">1</span>, bni, Bni)</span>
<span id="cb2-57"><a href="sec91.html#cb2-57" tabindex="-1"></a>        bis[i, ] <span class="ot">&lt;-</span> bi</span>
<span id="cb2-58"><a href="sec91.html#cb2-58" tabindex="-1"></a>    }</span>
<span id="cb2-59"><a href="sec91.html#cb2-59" tabindex="-1"></a>    <span class="fu">return</span>(bis)</span>
<span id="cb2-60"><a href="sec91.html#cb2-60" tabindex="-1"></a>}</span>
<span id="cb2-61"><a href="sec91.html#cb2-61" tabindex="-1"></a>PostSig2 <span class="ot">&lt;-</span> <span class="cf">function</span>(Beta, bs, tau){</span>
<span id="cb2-62"><a href="sec91.html#cb2-62" tabindex="-1"></a>    an <span class="ot">&lt;-</span> a0 <span class="sc">+</span> <span class="fl">0.5</span><span class="sc">*</span>NT</span>
<span id="cb2-63"><a href="sec91.html#cb2-63" tabindex="-1"></a>    ete <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb2-64"><a href="sec91.html#cb2-64" tabindex="-1"></a>    <span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>N){</span>
<span id="cb2-65"><a href="sec91.html#cb2-65" tabindex="-1"></a>        ids <span class="ot">&lt;-</span> <span class="fu">which</span>(id <span class="sc">==</span> i)</span>
<span id="cb2-66"><a href="sec91.html#cb2-66" tabindex="-1"></a>        Xi <span class="ot">&lt;-</span> X[ids, ]; yi <span class="ot">&lt;-</span> y[ids]</span>
<span id="cb2-67"><a href="sec91.html#cb2-67" tabindex="-1"></a>        Wi <span class="ot">&lt;-</span> W[ids, ]; taui <span class="ot">&lt;-</span> tau[ids]</span>
<span id="cb2-68"><a href="sec91.html#cb2-68" tabindex="-1"></a>        Taui <span class="ot">&lt;-</span> <span class="fu">solve</span>(<span class="fu">diag</span>(<span class="dv">1</span><span class="sc">/</span>taui))</span>
<span id="cb2-69"><a href="sec91.html#cb2-69" tabindex="-1"></a>        ei <span class="ot">&lt;-</span> yi <span class="sc">-</span> Xi<span class="sc">%*%</span>Beta <span class="sc">-</span> Wi<span class="sc">%*%</span>bs[i, ]</span>
<span id="cb2-70"><a href="sec91.html#cb2-70" tabindex="-1"></a>        etei <span class="ot">&lt;-</span> <span class="fu">t</span>(ei)<span class="sc">%*%</span>Taui<span class="sc">%*%</span>ei</span>
<span id="cb2-71"><a href="sec91.html#cb2-71" tabindex="-1"></a>        ete <span class="ot">&lt;-</span> ete <span class="sc">+</span> etei</span>
<span id="cb2-72"><a href="sec91.html#cb2-72" tabindex="-1"></a>    }</span>
<span id="cb2-73"><a href="sec91.html#cb2-73" tabindex="-1"></a>    dn <span class="ot">&lt;-</span> d0 <span class="sc">+</span> <span class="fl">0.5</span><span class="sc">*</span>ete </span>
<span id="cb2-74"><a href="sec91.html#cb2-74" tabindex="-1"></a>    sig2 <span class="ot">&lt;-</span> MCMCpack<span class="sc">::</span><span class="fu">rinvgamma</span>(<span class="dv">1</span>, <span class="at">shape =</span> an, <span class="at">scale =</span> dn)</span>
<span id="cb2-75"><a href="sec91.html#cb2-75" tabindex="-1"></a>    <span class="fu">return</span>(sig2)</span>
<span id="cb2-76"><a href="sec91.html#cb2-76" tabindex="-1"></a>}</span>
<span id="cb2-77"><a href="sec91.html#cb2-77" tabindex="-1"></a>PostD <span class="ot">&lt;-</span> <span class="cf">function</span>(bs){</span>
<span id="cb2-78"><a href="sec91.html#cb2-78" tabindex="-1"></a>    rn <span class="ot">&lt;-</span> r0 <span class="sc">+</span> N</span>
<span id="cb2-79"><a href="sec91.html#cb2-79" tabindex="-1"></a>    btb <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="dv">0</span>, K2, K2)</span>
<span id="cb2-80"><a href="sec91.html#cb2-80" tabindex="-1"></a>    <span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>N){</span>
<span id="cb2-81"><a href="sec91.html#cb2-81" tabindex="-1"></a>        bsi <span class="ot">&lt;-</span> bs[i, ]</span>
<span id="cb2-82"><a href="sec91.html#cb2-82" tabindex="-1"></a>        btbi <span class="ot">&lt;-</span> bsi<span class="sc">%*%</span><span class="fu">t</span>(bsi)</span>
<span id="cb2-83"><a href="sec91.html#cb2-83" tabindex="-1"></a>        btb <span class="ot">&lt;-</span> btb <span class="sc">+</span> btbi</span>
<span id="cb2-84"><a href="sec91.html#cb2-84" tabindex="-1"></a>    }</span>
<span id="cb2-85"><a href="sec91.html#cb2-85" tabindex="-1"></a>    Rn <span class="ot">&lt;-</span> d0<span class="sc">*</span>R0 <span class="sc">+</span> btb</span>
<span id="cb2-86"><a href="sec91.html#cb2-86" tabindex="-1"></a>    Sigma <span class="ot">&lt;-</span> MCMCpack<span class="sc">::</span><span class="fu">riwish</span>(<span class="at">v =</span> rn, <span class="at">S =</span> Rn)</span>
<span id="cb2-87"><a href="sec91.html#cb2-87" tabindex="-1"></a>    <span class="fu">return</span>(Sigma)</span>
<span id="cb2-88"><a href="sec91.html#cb2-88" tabindex="-1"></a>}</span>
<span id="cb2-89"><a href="sec91.html#cb2-89" tabindex="-1"></a>PostTau <span class="ot">&lt;-</span> <span class="cf">function</span>(sig2, Beta, bs){</span>
<span id="cb2-90"><a href="sec91.html#cb2-90" tabindex="-1"></a>    v1n <span class="ot">&lt;-</span> v <span class="sc">+</span> <span class="dv">1</span></span>
<span id="cb2-91"><a href="sec91.html#cb2-91" tabindex="-1"></a>    v2n <span class="ot">&lt;-</span> <span class="cn">NULL</span></span>
<span id="cb2-92"><a href="sec91.html#cb2-92" tabindex="-1"></a>    <span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>NT){</span>
<span id="cb2-93"><a href="sec91.html#cb2-93" tabindex="-1"></a>        Xi <span class="ot">&lt;-</span> X[i, ]; yi <span class="ot">&lt;-</span> y[i]</span>
<span id="cb2-94"><a href="sec91.html#cb2-94" tabindex="-1"></a>        Wi <span class="ot">&lt;-</span> W[i, ]; bi <span class="ot">&lt;-</span> bs[id[i],]</span>
<span id="cb2-95"><a href="sec91.html#cb2-95" tabindex="-1"></a>        v2ni <span class="ot">&lt;-</span> v <span class="sc">+</span> sig2<span class="sc">^</span>(<span class="sc">-</span><span class="dv">1</span>)<span class="sc">*</span>(yi <span class="sc">-</span> Xi<span class="sc">%*%</span>Beta <span class="sc">-</span> Wi<span class="sc">%*%</span>bi)<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb2-96"><a href="sec91.html#cb2-96" tabindex="-1"></a>        v2n <span class="ot">&lt;-</span> <span class="fu">c</span>(v2n, v2ni)</span>
<span id="cb2-97"><a href="sec91.html#cb2-97" tabindex="-1"></a>    }</span>
<span id="cb2-98"><a href="sec91.html#cb2-98" tabindex="-1"></a>    tau <span class="ot">&lt;-</span> <span class="fu">rgamma</span>(NT, <span class="at">shape =</span> <span class="fu">rep</span>(v1n<span class="sc">/</span><span class="dv">2</span>, NT), <span class="at">rate =</span> v2n<span class="sc">/</span><span class="dv">2</span>)</span>
<span id="cb2-99"><a href="sec91.html#cb2-99" tabindex="-1"></a>    <span class="fu">return</span>(tau)</span>
<span id="cb2-100"><a href="sec91.html#cb2-100" tabindex="-1"></a>}</span>
<span id="cb2-101"><a href="sec91.html#cb2-101" tabindex="-1"></a>PostBetas <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="dv">0</span>, tot, K1); PostDs <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="dv">0</span>, tot, K2<span class="sc">*</span>(K2<span class="sc">+</span><span class="dv">1</span>)<span class="sc">/</span><span class="dv">2</span>)</span>
<span id="cb2-102"><a href="sec91.html#cb2-102" tabindex="-1"></a>PostSig2s <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">0</span>, tot); Postbs <span class="ot">&lt;-</span> <span class="fu">array</span>(<span class="dv">0</span>, <span class="fu">c</span>(N, K2, tot))</span>
<span id="cb2-103"><a href="sec91.html#cb2-103" tabindex="-1"></a>PostTaus <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="dv">0</span>, tot, NT); RegLS <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> X <span class="sc">-</span> <span class="dv">1</span>)</span>
<span id="cb2-104"><a href="sec91.html#cb2-104" tabindex="-1"></a>SumLS <span class="ot">&lt;-</span> <span class="fu">summary</span>(RegLS)</span>
<span id="cb2-105"><a href="sec91.html#cb2-105" tabindex="-1"></a>Beta <span class="ot">&lt;-</span> SumLS[[<span class="st">&quot;coefficients&quot;</span>]][,<span class="dv">1</span>]</span>
<span id="cb2-106"><a href="sec91.html#cb2-106" tabindex="-1"></a>sig2 <span class="ot">&lt;-</span> SumLS[[<span class="st">&quot;sigma&quot;</span>]]<span class="sc">^</span><span class="dv">2</span>; D <span class="ot">&lt;-</span> <span class="fu">diag</span>(K2)</span>
<span id="cb2-107"><a href="sec91.html#cb2-107" tabindex="-1"></a>tau <span class="ot">&lt;-</span> <span class="fu">rgamma</span>(NT, <span class="at">shape =</span> v<span class="sc">/</span><span class="dv">2</span>, <span class="at">rate =</span> v<span class="sc">/</span><span class="dv">2</span>) </span>
<span id="cb2-108"><a href="sec91.html#cb2-108" tabindex="-1"></a>pb <span class="ot">&lt;-</span> <span class="fu">winProgressBar</span>(<span class="at">title =</span> <span class="st">&quot;progress bar&quot;</span>, <span class="at">min =</span> <span class="dv">0</span>, <span class="at">max =</span> tot, <span class="at">width =</span> <span class="dv">300</span>)</span>
<span id="cb2-109"><a href="sec91.html#cb2-109" tabindex="-1"></a><span class="cf">for</span>(s <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>tot){</span>
<span id="cb2-110"><a href="sec91.html#cb2-110" tabindex="-1"></a>    bs <span class="ot">&lt;-</span> <span class="fu">Postb</span>(<span class="at">Beta =</span> Beta, <span class="at">sig2 =</span> sig2, <span class="at">D =</span> D, <span class="at">tau =</span> tau)</span>
<span id="cb2-111"><a href="sec91.html#cb2-111" tabindex="-1"></a>    D <span class="ot">&lt;-</span> <span class="fu">PostD</span>(<span class="at">bs =</span> bs)</span>
<span id="cb2-112"><a href="sec91.html#cb2-112" tabindex="-1"></a>    Beta <span class="ot">&lt;-</span> <span class="fu">PostBeta</span>(<span class="at">sig2 =</span> sig2, <span class="at">D =</span> D, <span class="at">tau =</span> tau)</span>
<span id="cb2-113"><a href="sec91.html#cb2-113" tabindex="-1"></a>    sig2 <span class="ot">&lt;-</span> <span class="fu">PostSig2</span>(<span class="at">Beta =</span> Beta, <span class="at">bs =</span> bs, <span class="at">tau =</span> tau)</span>
<span id="cb2-114"><a href="sec91.html#cb2-114" tabindex="-1"></a>    tau <span class="ot">&lt;-</span> <span class="fu">PostTau</span>(<span class="at">sig2 =</span> sig2, <span class="at">Beta =</span> Beta, <span class="at">bs =</span> bs)</span>
<span id="cb2-115"><a href="sec91.html#cb2-115" tabindex="-1"></a>    PostBetas[s,] <span class="ot">&lt;-</span> Beta</span>
<span id="cb2-116"><a href="sec91.html#cb2-116" tabindex="-1"></a>    PostDs[s,] <span class="ot">&lt;-</span> matrixcalc<span class="sc">::</span><span class="fu">vech</span>(D)</span>
<span id="cb2-117"><a href="sec91.html#cb2-117" tabindex="-1"></a>    PostSig2s[s] <span class="ot">&lt;-</span> sig2</span>
<span id="cb2-118"><a href="sec91.html#cb2-118" tabindex="-1"></a>    Postbs[, , s] <span class="ot">&lt;-</span> bs</span>
<span id="cb2-119"><a href="sec91.html#cb2-119" tabindex="-1"></a>    PostTaus[s,] <span class="ot">&lt;-</span> tau</span>
<span id="cb2-120"><a href="sec91.html#cb2-120" tabindex="-1"></a>    <span class="fu">setWinProgressBar</span>(pb, s, <span class="at">title=</span><span class="fu">paste</span>( <span class="fu">round</span>(s<span class="sc">/</span>tot<span class="sc">*</span><span class="dv">100</span>, <span class="dv">0</span>),<span class="st">&quot;% done&quot;</span>))</span>
<span id="cb2-121"><a href="sec91.html#cb2-121" tabindex="-1"></a>}</span>
<span id="cb2-122"><a href="sec91.html#cb2-122" tabindex="-1"></a><span class="fu">close</span>(pb)</span>
<span id="cb2-123"><a href="sec91.html#cb2-123" tabindex="-1"></a>keep <span class="ot">&lt;-</span> <span class="fu">seq</span>((burnin<span class="sc">+</span><span class="dv">1</span>), tot, thin)</span>
<span id="cb2-124"><a href="sec91.html#cb2-124" tabindex="-1"></a>Bs <span class="ot">&lt;-</span> PostBetas[keep,]; Ds <span class="ot">&lt;-</span> PostDs[keep,]</span>
<span id="cb2-125"><a href="sec91.html#cb2-125" tabindex="-1"></a>bs <span class="ot">&lt;-</span> Postbs[, , keep]; sig2s <span class="ot">&lt;-</span> PostSig2s[keep]</span>
<span id="cb2-126"><a href="sec91.html#cb2-126" tabindex="-1"></a>taus <span class="ot">&lt;-</span> PostTaus[keep,]</span>
<span id="cb2-127"><a href="sec91.html#cb2-127" tabindex="-1"></a><span class="fu">summary</span>(coda<span class="sc">::</span><span class="fu">mcmc</span>(Bs))</span>
<span id="cb2-128"><a href="sec91.html#cb2-128" tabindex="-1"></a><span class="fu">summary</span>(coda<span class="sc">::</span><span class="fu">mcmc</span>(Ds))</span>
<span id="cb2-129"><a href="sec91.html#cb2-129" tabindex="-1"></a><span class="fu">summary</span>(coda<span class="sc">::</span><span class="fu">mcmc</span>(sig2s))</span></code></pre></div>
<p>We can see that all the 95% credible intervals encompass the population parameters, except for the second <em>fixed effect</em> and the variance of the model, but both for a tiny margin.</p>
</div>
<h3>References<a href="references.html#references" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Chib1999" class="csl-entry">
Chib, S., and B. Carlin. 1999. <span>“On <span>MCMC</span> Sampling in Hierarchical Longitudinal Models.”</span> <em>Statistics and Computing</em> 9: 17–26.
</div>
<div id="ref-Ramirez2017" class="csl-entry">
Ramírez Hassan, A. 2017. <span>“The Interplay Between the <span>B</span>ayesian and Frequentist Approaches: A General Nesting Spatial Panel Data Model.”</span> <em>Spatial Economic Analysis</em> 12 (1): 92–112.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="Chap9.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="sec92.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/aramir21/IntroductionBayesianEconometricsBook/09-Longitudinal.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
