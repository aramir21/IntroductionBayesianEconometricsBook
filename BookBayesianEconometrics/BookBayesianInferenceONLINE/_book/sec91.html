<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>9.1 Normal model | Introduction to Bayesian Econometrics</title>
  <meta name="description" content="The subject of this textbook is Bayesian data modeling, with the primary aim of providing an introduction to its theoretical foundations and facilitating the application of Bayesian inference using a GUI." />
  <meta name="generator" content="bookdown 0.43 and GitBook 2.6.7" />

  <meta property="og:title" content="9.1 Normal model | Introduction to Bayesian Econometrics" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="The subject of this textbook is Bayesian data modeling, with the primary aim of providing an introduction to its theoretical foundations and facilitating the application of Bayesian inference using a GUI." />
  <meta name="github-repo" content="https://github.com/aramir21/IntroductionBayesianEconometricsBook" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="9.1 Normal model | Introduction to Bayesian Econometrics" />
  
  <meta name="twitter:description" content="The subject of this textbook is Bayesian data modeling, with the primary aim of providing an introduction to its theoretical foundations and facilitating the application of Bayesian inference using a GUI." />
  

<meta name="author" content="Andrés Ramírez-Hassan" />


<meta name="date" content="2025-12-06" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="Chap9.html"/>
<link rel="next" href="sec92.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Introduction to Bayesian Econometrics: A GUIded toolkit using R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="to-instructors-and-students.html"><a href="to-instructors-and-students.html"><i class="fa fa-check"></i>To instructors and students</a></li>
<li class="chapter" data-level="" data-path="acknowledgments.html"><a href="acknowledgments.html"><i class="fa fa-check"></i>Acknowledgments</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="Chap1.html"><a href="Chap1.html"><i class="fa fa-check"></i><b>1</b> Basic formal concepts</a>
<ul>
<li class="chapter" data-level="1.1" data-path="sec11.html"><a href="sec11.html"><i class="fa fa-check"></i><b>1.1</b> The Bayes’ rule</a></li>
<li class="chapter" data-level="1.2" data-path="sec12.html"><a href="sec12.html"><i class="fa fa-check"></i><b>1.2</b> Bayesian framework: A brief summary of theory</a></li>
<li class="chapter" data-level="1.3" data-path="sec14.html"><a href="sec14.html"><i class="fa fa-check"></i><b>1.3</b> Bayesian reports: Decision theory under uncertainty</a></li>
<li class="chapter" data-level="1.4" data-path="summary.html"><a href="summary.html"><i class="fa fa-check"></i><b>1.4</b> Summary</a></li>
<li class="chapter" data-level="1.5" data-path="exercises.html"><a href="exercises.html"><i class="fa fa-check"></i><b>1.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="Chap2.html"><a href="Chap2.html"><i class="fa fa-check"></i><b>2</b> Conceptual differences between the Bayesian and Frequentist approaches</a>
<ul>
<li class="chapter" data-level="2.1" data-path="sec21.html"><a href="sec21.html"><i class="fa fa-check"></i><b>2.1</b> The concept of probability</a></li>
<li class="chapter" data-level="2.2" data-path="sec22.html"><a href="sec22.html"><i class="fa fa-check"></i><b>2.2</b> Subjectivity is not the key</a></li>
<li class="chapter" data-level="2.3" data-path="sec23.html"><a href="sec23.html"><i class="fa fa-check"></i><b>2.3</b> Estimation, hypothesis testing and prediction</a></li>
<li class="chapter" data-level="2.4" data-path="sec24.html"><a href="sec24.html"><i class="fa fa-check"></i><b>2.4</b> The likelihood principle</a></li>
<li class="chapter" data-level="2.5" data-path="sec25.html"><a href="sec25.html"><i class="fa fa-check"></i><b>2.5</b> Why is not the Bayesian approach that popular?</a></li>
<li class="chapter" data-level="2.6" data-path="sec26.html"><a href="sec26.html"><i class="fa fa-check"></i><b>2.6</b> A simple working example</a></li>
<li class="chapter" data-level="2.7" data-path="sec27.html"><a href="sec27.html"><i class="fa fa-check"></i><b>2.7</b> Summary</a></li>
<li class="chapter" data-level="2.8" data-path="sec28.html"><a href="sec28.html"><i class="fa fa-check"></i><b>2.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="Chap3.html"><a href="Chap3.html"><i class="fa fa-check"></i><b>3</b> Cornerstone models: Conjugate families</a>
<ul>
<li class="chapter" data-level="3.1" data-path="sec41.html"><a href="sec41.html"><i class="fa fa-check"></i><b>3.1</b> Motivation of conjugate families</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="sec41.html"><a href="sec41.html#examples-of-exponential-family-distributions"><i class="fa fa-check"></i><b>3.1.1</b> Examples of exponential family distributions</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="sec42.html"><a href="sec42.html"><i class="fa fa-check"></i><b>3.2</b> Conjugate prior to exponential family</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="sec42.html"><a href="sec42.html#sec421"><i class="fa fa-check"></i><b>3.2.1</b> Examples: Theorem 4.2.1</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="sec43.html"><a href="sec43.html"><i class="fa fa-check"></i><b>3.3</b> Linear regression: The conjugate normal-normal/inverse gamma model</a></li>
<li class="chapter" data-level="3.4" data-path="sec44.html"><a href="sec44.html"><i class="fa fa-check"></i><b>3.4</b> Multivariate linear regression: The conjugate normal-normal/inverse Wishart model</a></li>
<li class="chapter" data-level="3.5" data-path="sec45.html"><a href="sec45.html"><i class="fa fa-check"></i><b>3.5</b> Summary</a></li>
<li class="chapter" data-level="3.6" data-path="sec46.html"><a href="sec46.html"><i class="fa fa-check"></i><b>3.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="Chap4.html"><a href="Chap4.html"><i class="fa fa-check"></i><b>4</b> Simulation methods</a>
<ul>
<li class="chapter" data-level="4.1" data-path="sec51.html"><a href="sec51.html"><i class="fa fa-check"></i><b>4.1</b> Markov Chain Monte Carlo methods</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="sec51.html"><a href="sec51.html#sec511"><i class="fa fa-check"></i><b>4.1.1</b> Gibbs sampler</a></li>
<li class="chapter" data-level="4.1.2" data-path="sec51.html"><a href="sec51.html#sec512"><i class="fa fa-check"></i><b>4.1.2</b> Metropolis-Hastings</a></li>
<li class="chapter" data-level="4.1.3" data-path="sec51.html"><a href="sec51.html#sec513"><i class="fa fa-check"></i><b>4.1.3</b> Hamiltonian Monte Carlo</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="sec52.html"><a href="sec52.html"><i class="fa fa-check"></i><b>4.2</b> Importance sampling</a></li>
<li class="chapter" data-level="4.3" data-path="sec53.html"><a href="sec53.html"><i class="fa fa-check"></i><b>4.3</b> Particle filtering</a></li>
<li class="chapter" data-level="4.4" data-path="sec54.html"><a href="sec54.html"><i class="fa fa-check"></i><b>4.4</b> Convergence diagnostics</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="sec54.html"><a href="sec54.html#numerical-standard-error"><i class="fa fa-check"></i><b>4.4.1</b> Numerical standard error</a></li>
<li class="chapter" data-level="4.4.2" data-path="sec54.html"><a href="sec54.html#effective-number-of-simulation-draws"><i class="fa fa-check"></i><b>4.4.2</b> Effective number of simulation draws</a></li>
<li class="chapter" data-level="4.4.3" data-path="sec54.html"><a href="sec54.html#tests-of-convergence"><i class="fa fa-check"></i><b>4.4.3</b> Tests of convergence</a></li>
<li class="chapter" data-level="4.4.4" data-path="sec54.html"><a href="sec54.html#checking-for-errors-in-the-posterior-simulator"><i class="fa fa-check"></i><b>4.4.4</b> Checking for errors in the posterior simulator</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="sec55.html"><a href="sec55.html"><i class="fa fa-check"></i><b>4.5</b> Summary</a></li>
<li class="chapter" data-level="4.6" data-path="sec56.html"><a href="sec56.html"><i class="fa fa-check"></i><b>4.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="Chap5.html"><a href="Chap5.html"><i class="fa fa-check"></i><b>5</b> Graphical user interface</a>
<ul>
<li class="chapter" data-level="5.1" data-path="secGUI1.html"><a href="secGUI1.html"><i class="fa fa-check"></i><b>5.1</b> Introduction</a></li>
<li class="chapter" data-level="5.2" data-path="secGUI2.html"><a href="secGUI2.html"><i class="fa fa-check"></i><b>5.2</b> Univariate models</a></li>
<li class="chapter" data-level="5.3" data-path="secGUI3.html"><a href="secGUI3.html"><i class="fa fa-check"></i><b>5.3</b> Multivariate models</a></li>
<li class="chapter" data-level="5.4" data-path="secGUI4.html"><a href="secGUI4.html"><i class="fa fa-check"></i><b>5.4</b> Time series models</a></li>
<li class="chapter" data-level="5.5" data-path="secGUI5.html"><a href="secGUI5.html"><i class="fa fa-check"></i><b>5.5</b> Longitudinal/panel models</a></li>
<li class="chapter" data-level="5.6" data-path="secGUI6.html"><a href="secGUI6.html"><i class="fa fa-check"></i><b>5.6</b> Bayesian model averaging</a></li>
<li class="chapter" data-level="5.7" data-path="secGUI7.html"><a href="secGUI7.html"><i class="fa fa-check"></i><b>5.7</b> Help</a></li>
<li class="chapter" data-level="5.8" data-path="secGUI8.html"><a href="secGUI8.html"><i class="fa fa-check"></i><b>5.8</b> Warning</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="Chap6.html"><a href="Chap6.html"><i class="fa fa-check"></i><b>6</b> Univariate models</a>
<ul>
<li class="chapter" data-level="6.1" data-path="sec61.html"><a href="sec61.html"><i class="fa fa-check"></i><b>6.1</b> The Gaussian linear model</a></li>
<li class="chapter" data-level="6.2" data-path="sec62.html"><a href="sec62.html"><i class="fa fa-check"></i><b>6.2</b> The logit model</a></li>
<li class="chapter" data-level="6.3" data-path="sec63.html"><a href="sec63.html"><i class="fa fa-check"></i><b>6.3</b> The probit model</a></li>
<li class="chapter" data-level="6.4" data-path="sec64.html"><a href="sec64.html"><i class="fa fa-check"></i><b>6.4</b> The multinomial probit model</a></li>
<li class="chapter" data-level="6.5" data-path="sec65.html"><a href="sec65.html"><i class="fa fa-check"></i><b>6.5</b> The multinomial logit model</a></li>
<li class="chapter" data-level="6.6" data-path="sec66.html"><a href="sec66.html"><i class="fa fa-check"></i><b>6.6</b> Ordered probit model</a></li>
<li class="chapter" data-level="6.7" data-path="negative-binomial-model.html"><a href="negative-binomial-model.html"><i class="fa fa-check"></i><b>6.7</b> Negative binomial model</a></li>
<li class="chapter" data-level="6.8" data-path="sec68.html"><a href="sec68.html"><i class="fa fa-check"></i><b>6.8</b> Tobit model</a></li>
<li class="chapter" data-level="6.9" data-path="sec69.html"><a href="sec69.html"><i class="fa fa-check"></i><b>6.9</b> Quantile regression</a></li>
<li class="chapter" data-level="6.10" data-path="sec610.html"><a href="sec610.html"><i class="fa fa-check"></i><b>6.10</b> Bayesian bootstrap regression</a></li>
<li class="chapter" data-level="6.11" data-path="sec611.html"><a href="sec611.html"><i class="fa fa-check"></i><b>6.11</b> Summary</a></li>
<li class="chapter" data-level="6.12" data-path="sec612.html"><a href="sec612.html"><i class="fa fa-check"></i><b>6.12</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="Chap7.html"><a href="Chap7.html"><i class="fa fa-check"></i><b>7</b> Multivariate models</a>
<ul>
<li class="chapter" data-level="7.1" data-path="sec71.html"><a href="sec71.html"><i class="fa fa-check"></i><b>7.1</b> Multivariate regression</a></li>
<li class="chapter" data-level="7.2" data-path="sec72.html"><a href="sec72.html"><i class="fa fa-check"></i><b>7.2</b> Seemingly Unrelated Regression</a></li>
<li class="chapter" data-level="7.3" data-path="sec73.html"><a href="sec73.html"><i class="fa fa-check"></i><b>7.3</b> Instrumental variable</a></li>
<li class="chapter" data-level="7.4" data-path="sec74.html"><a href="sec74.html"><i class="fa fa-check"></i><b>7.4</b> Multivariate probit model</a></li>
<li class="chapter" data-level="7.5" data-path="sec75.html"><a href="sec75.html"><i class="fa fa-check"></i><b>7.5</b> Summary</a></li>
<li class="chapter" data-level="7.6" data-path="sec76.html"><a href="sec76.html"><i class="fa fa-check"></i><b>7.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="Chap8.html"><a href="Chap8.html"><i class="fa fa-check"></i><b>8</b> Time series models</a>
<ul>
<li class="chapter" data-level="8.1" data-path="sec81.html"><a href="sec81.html"><i class="fa fa-check"></i><b>8.1</b> State-space representation</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="sec81.html"><a href="sec81.html#gaussian-linear-state-space-models"><i class="fa fa-check"></i><b>8.1.1</b> Gaussian linear state-space models</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="sec82.html"><a href="sec82.html"><i class="fa fa-check"></i><b>8.2</b> ARMA processes</a></li>
<li class="chapter" data-level="8.3" data-path="sec83.html"><a href="sec83.html"><i class="fa fa-check"></i><b>8.3</b> Stochastic volatility models</a></li>
<li class="chapter" data-level="8.4" data-path="sec84.html"><a href="sec84.html"><i class="fa fa-check"></i><b>8.4</b> Vector Autoregressive models</a></li>
<li class="chapter" data-level="8.5" data-path="sec85.html"><a href="sec85.html"><i class="fa fa-check"></i><b>8.5</b> Summary</a></li>
<li class="chapter" data-level="8.6" data-path="sec86.html"><a href="sec86.html"><i class="fa fa-check"></i><b>8.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="Chap9.html"><a href="Chap9.html"><i class="fa fa-check"></i><b>9</b> Longitudinal/Panel data models</a>
<ul>
<li class="chapter" data-level="9.1" data-path="sec91.html"><a href="sec91.html"><i class="fa fa-check"></i><b>9.1</b> Normal model</a></li>
<li class="chapter" data-level="9.2" data-path="sec92.html"><a href="sec92.html"><i class="fa fa-check"></i><b>9.2</b> Logit model</a></li>
<li class="chapter" data-level="9.3" data-path="sec93.html"><a href="sec93.html"><i class="fa fa-check"></i><b>9.3</b> Poisson model</a></li>
<li class="chapter" data-level="9.4" data-path="sec94.html"><a href="sec94.html"><i class="fa fa-check"></i><b>9.4</b> Summary</a></li>
<li class="chapter" data-level="9.5" data-path="sec95.html"><a href="sec95.html"><i class="fa fa-check"></i><b>9.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="Chap10.html"><a href="Chap10.html"><i class="fa fa-check"></i><b>10</b> Bayesian model averaging</a>
<ul>
<li class="chapter" data-level="10.1" data-path="sec10_1.html"><a href="sec10_1.html"><i class="fa fa-check"></i><b>10.1</b> Foundation</a></li>
<li class="chapter" data-level="10.2" data-path="sec102.html"><a href="sec102.html"><i class="fa fa-check"></i><b>10.2</b> The Gaussian linear model</a></li>
<li class="chapter" data-level="10.3" data-path="sec103.html"><a href="sec103.html"><i class="fa fa-check"></i><b>10.3</b> Generalized linear models</a></li>
<li class="chapter" data-level="10.4" data-path="sec10_4.html"><a href="sec10_4.html"><i class="fa fa-check"></i><b>10.4</b> Calculating the marginal likelihood</a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="sec10_4.html"><a href="sec10_4.html#sec10_4_1"><i class="fa fa-check"></i><b>10.4.1</b> Savage-Dickey density ratio</a></li>
<li class="chapter" data-level="10.4.2" data-path="sec10_4.html"><a href="sec10_4.html#sec10_4_2"><i class="fa fa-check"></i><b>10.4.2</b> Chib’s methods</a></li>
<li class="chapter" data-level="10.4.3" data-path="sec10_4.html"><a href="sec10_4.html#sec10_4_3"><i class="fa fa-check"></i><b>10.4.3</b> Gelfand-Dey method</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="sec10_5.html"><a href="sec10_5.html"><i class="fa fa-check"></i><b>10.5</b> Summary</a></li>
<li class="chapter" data-level="10.6" data-path="sec10_6.html"><a href="sec10_6.html"><i class="fa fa-check"></i><b>10.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="Chap11.html"><a href="Chap11.html"><i class="fa fa-check"></i><b>11</b> Semi-parametric and non-parametric models</a>
<ul>
<li class="chapter" data-level="11.1" data-path="sec11_1.html"><a href="sec11_1.html"><i class="fa fa-check"></i><b>11.1</b> Mixture models</a>
<ul>
<li class="chapter" data-level="11.1.1" data-path="sec11_1.html"><a href="sec11_1.html#sec11_11"><i class="fa fa-check"></i><b>11.1.1</b> Finite Gaussian mixtures</a></li>
<li class="chapter" data-level="11.1.2" data-path="sec11_1.html"><a href="sec11_1.html#sec11_12"><i class="fa fa-check"></i><b>11.1.2</b> Direchlet processes</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="sec11_2.html"><a href="sec11_2.html"><i class="fa fa-check"></i><b>11.2</b> Splines</a></li>
<li class="chapter" data-level="11.3" data-path="sec11_3.html"><a href="sec11_3.html"><i class="fa fa-check"></i><b>11.3</b> Summary</a></li>
<li class="chapter" data-level="11.4" data-path="sec11_4.html"><a href="sec11_4.html"><i class="fa fa-check"></i><b>11.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="Chap12.html"><a href="Chap12.html"><i class="fa fa-check"></i><b>12</b> Bayesian machine learning</a>
<ul>
<li class="chapter" data-level="12.1" data-path="sec12_1.html"><a href="sec12_1.html"><i class="fa fa-check"></i><b>12.1</b> Cross-validation and Bayes factors</a></li>
<li class="chapter" data-level="12.2" data-path="sec12_2.html"><a href="sec12_2.html"><i class="fa fa-check"></i><b>12.2</b> Regularization</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="sec12_2.html"><a href="sec12_2.html#sec12_21"><i class="fa fa-check"></i><b>12.2.1</b> Bayesian LASSO</a></li>
<li class="chapter" data-level="12.2.2" data-path="sec12_2.html"><a href="sec12_2.html#sec12_22"><i class="fa fa-check"></i><b>12.2.2</b> Stochastic search variable selection</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="sec12_3.html"><a href="sec12_3.html"><i class="fa fa-check"></i><b>12.3</b> Bayesian additive regression trees</a></li>
<li class="chapter" data-level="12.4" data-path="sec12_4.html"><a href="sec12_4.html"><i class="fa fa-check"></i><b>12.4</b> Gaussian processes</a></li>
<li class="chapter" data-level="12.5" data-path="sec12_5.html"><a href="sec12_5.html"><i class="fa fa-check"></i><b>12.5</b> Tall data problems</a>
<ul>
<li class="chapter" data-level="12.5.1" data-path="sec12_5.html"><a href="sec12_5.html#sec12_51"><i class="fa fa-check"></i><b>12.5.1</b> Divide-and-conquer methods</a></li>
<li class="chapter" data-level="12.5.2" data-path="sec12_5.html"><a href="sec12_5.html#sec12_52"><i class="fa fa-check"></i><b>12.5.2</b> Subsampling-based algorithms</a></li>
</ul></li>
<li class="chapter" data-level="12.6" data-path="id_13_6.html"><a href="id_13_6.html"><i class="fa fa-check"></i><b>12.6</b> Summary</a></li>
<li class="chapter" data-level="12.7" data-path="id_13_7.html"><a href="id_13_7.html"><i class="fa fa-check"></i><b>12.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="Chap13.html"><a href="Chap13.html"><i class="fa fa-check"></i><b>13</b> Causal inference</a>
<ul>
<li class="chapter" data-level="13.1" data-path="sec13_1.html"><a href="sec13_1.html"><i class="fa fa-check"></i><b>13.1</b> Identification setting</a></li>
<li class="chapter" data-level="13.2" data-path="sec13_2.html"><a href="sec13_2.html"><i class="fa fa-check"></i><b>13.2</b> Randomized controlled trial (RCT)</a></li>
<li class="chapter" data-level="13.3" data-path="sec13_3.html"><a href="sec13_3.html"><i class="fa fa-check"></i><b>13.3</b> Conditional independence assumption (CIA)</a></li>
<li class="chapter" data-level="13.4" data-path="sec13_4.html"><a href="sec13_4.html"><i class="fa fa-check"></i><b>13.4</b> Instrumental variables (IV)</a></li>
<li class="chapter" data-level="13.5" data-path="sec13_5.html"><a href="sec13_5.html"><i class="fa fa-check"></i><b>13.5</b> Difference-in-differences design (DiD)</a>
<ul>
<li class="chapter" data-level="13.5.1" data-path="sec13_5.html"><a href="sec13_5.html#sec13_51"><i class="fa fa-check"></i><b>13.5.1</b> Classic DiD: two-group and two-period (<span class="math inline">\(2\times2\)</span>) setup</a></li>
<li class="chapter" data-level="13.5.2" data-path="sec13_5.html"><a href="sec13_5.html#sec13_52"><i class="fa fa-check"></i><b>13.5.2</b> Staggered (SDiD): G-group and T-period (<span class="math inline">\(G\times T\)</span>) setup</a></li>
</ul></li>
<li class="chapter" data-level="13.6" data-path="sec13_6.html"><a href="sec13_6.html"><i class="fa fa-check"></i><b>13.6</b> Regression discontinuity design (RD)</a>
<ul>
<li class="chapter" data-level="13.6.1" data-path="sec13_6.html"><a href="sec13_6.html#sec13_61"><i class="fa fa-check"></i><b>13.6.1</b> Sharp regression discontinuity design (SRD)</a></li>
<li class="chapter" data-level="13.6.2" data-path="sec13_6.html"><a href="sec13_6.html#sec13_62"><i class="fa fa-check"></i><b>13.6.2</b> Fuzzy regression discontinuity design (FRD)</a></li>
</ul></li>
<li class="chapter" data-level="13.7" data-path="sec13_7.html"><a href="sec13_7.html"><i class="fa fa-check"></i><b>13.7</b> Sample selection</a></li>
<li class="chapter" data-level="13.8" data-path="sec13_8.html"><a href="sec13_8.html"><i class="fa fa-check"></i><b>13.8</b> Bayesian exponentially tilted empirical likelihood</a></li>
<li class="chapter" data-level="13.9" data-path="sec13_9.html"><a href="sec13_9.html"><i class="fa fa-check"></i><b>13.9</b> General Bayes posteriors</a></li>
<li class="chapter" data-level="13.10" data-path="sec13_10.html"><a href="sec13_10.html"><i class="fa fa-check"></i><b>13.10</b> Doubly robust Bayesian inferential framework (DRB)</a></li>
<li class="chapter" data-level="13.11" data-path="sec13_11.html"><a href="sec13_11.html"><i class="fa fa-check"></i><b>13.11</b> Summary</a></li>
<li class="chapter" data-level="13.12" data-path="sec13_12.html"><a href="sec13_12.html"><i class="fa fa-check"></i><b>13.12</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="Chap14.html"><a href="Chap14.html"><i class="fa fa-check"></i><b>14</b> Approximate Bayesian methods</a>
<ul>
<li class="chapter" data-level="14.1" data-path="sec14_1.html"><a href="sec14_1.html"><i class="fa fa-check"></i><b>14.1</b> Simulation-based approaches</a>
<ul>
<li class="chapter" data-level="14.1.1" data-path="sec14_1.html"><a href="sec14_1.html#sec14_11"><i class="fa fa-check"></i><b>14.1.1</b> Approximate Bayesian computation</a></li>
<li class="chapter" data-level="14.1.2" data-path="sec14_1.html"><a href="sec14_1.html#sec14_12"><i class="fa fa-check"></i><b>14.1.2</b> Bayesian synthetic likelihood</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="sec14_2.html"><a href="sec14_2.html"><i class="fa fa-check"></i><b>14.2</b> Optimization approaches</a>
<ul>
<li class="chapter" data-level="14.2.1" data-path="sec14_2.html"><a href="sec14_2.html#sec14_21"><i class="fa fa-check"></i><b>14.2.1</b> Integrated nested Laplace approximations</a></li>
<li class="chapter" data-level="14.2.2" data-path="sec14_2.html"><a href="sec14_2.html#sec14_22"><i class="fa fa-check"></i><b>14.2.2</b> Variational Bayes</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="summary-1.html"><a href="summary-1.html"><i class="fa fa-check"></i><b>14.3</b> Summary</a></li>
<li class="chapter" data-level="14.4" data-path="sec14_4.html"><a href="sec14_4.html"><i class="fa fa-check"></i><b>14.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i>Appendix</a>
<ul>
<li class="chapter" data-level="" data-path="packages-and-commands-in-besmarter-gui.html"><a href="packages-and-commands-in-besmarter-gui.html"><i class="fa fa-check"></i>Packages and commands in BEsmarter GUI</a></li>
<li class="chapter" data-level="" data-path="datasets-templates-in-folder-datasim.html"><a href="datasets-templates-in-folder-datasim.html"><i class="fa fa-check"></i>Datasets templates in folder DataSim</a></li>
<li class="chapter" data-level="" data-path="real-datasets-in-folder-dataapp.html"><a href="real-datasets-in-folder-dataapp.html"><i class="fa fa-check"></i>Real datasets in folder DataApp</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to Bayesian Econometrics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="sec91" class="section level2 hasAnchor" number="9.1">
<h2><span class="header-section-number">9.1</span> Normal model<a href="sec91.html#sec91" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The longitudinal/panel normal model establishes <span class="math inline">\(\boldsymbol{y}_i=\boldsymbol{X}_i\boldsymbol{\beta}+\boldsymbol{W}_i\boldsymbol{b}_i+\boldsymbol{\mu}_i\)</span> where <span class="math inline">\(\boldsymbol{y}_i\)</span> are <span class="math inline">\(T_i\)</span>-dimensional vectors corresponding to units <span class="math inline">\(i=1,2,\dots,N\)</span>, <span class="math inline">\(\boldsymbol{X}_i\)</span> and <span class="math inline">\(\boldsymbol{W}_i\)</span> are <span class="math inline">\(T_i\times K_1\)</span> and <span class="math inline">\(T_i\times K_2\)</span> matrices, respectively. In the statistical literature, <span class="math inline">\(\boldsymbol{\beta}\)</span> is a <span class="math inline">\(K_1\)</span>-dimensional vector of <em>fixed effects</em>, and <span class="math inline">\(\boldsymbol{b}_i\)</span> is a <span class="math inline">\(K_2\)</span>-dimensional vector of unit-specific <em>random effects</em> that allow unit-specific means, and enable capturing marginal dependence among the observations on the cross-sectional units. We assume normal stochastic errors, <span class="math inline">\(\boldsymbol{\mu}_i\sim{N}(\boldsymbol{0},\sigma^2\boldsymbol{I}_{T_i})\)</span>, which means that the likelihood function is</p>
<p><span class="math display">\[\begin{align*}
    p(\boldsymbol{\beta},\boldsymbol{b},\sigma^2\mid \boldsymbol{y}, \boldsymbol{X},\boldsymbol{W}) &amp; \propto \prod_{i=1}^N |\sigma^2\boldsymbol{I}_{T_i}|^{-1/2}\exp\left\{-\frac{1}{2\sigma^2}(\boldsymbol{y}_i-\boldsymbol{X}_i\boldsymbol{\beta}-\boldsymbol{W}_i\boldsymbol{b}_i)^{\top}(\boldsymbol{y}_i-\boldsymbol{X}_i\boldsymbol{\beta}-\boldsymbol{W}_i\boldsymbol{b}_i)\right\}\\
    &amp; = (\sigma^2)^{-\frac{\sum_{i=1}^N T_i}{2}}\exp\left\{-\frac{1}{2\sigma^2}\sum_{i=1}^N(\boldsymbol{y}_i-\boldsymbol{X}_i\boldsymbol{\beta}-\boldsymbol{W}_i\boldsymbol{b}_i)^{\top}(\boldsymbol{y}_i-\boldsymbol{X}_i\boldsymbol{\beta}-\boldsymbol{W}_i\boldsymbol{b}_i)\right\},
\end{align*}\]</span></p>
<p>where <span class="math inline">\(\boldsymbol{b}=[\boldsymbol{b}_1^{\top}, \boldsymbol{b}_2^{\top},\dots, \boldsymbol{b}_N^{\top}]^{\top}\)</span>.</p>
<p>Panel data modeling in the Bayesian approach assumes a hierarchical structure in the <em>random effects</em>. Following <span class="citation">S. Chib and Carlin (<a href="#ref-Chib1999">1999</a>)</span>, there is a first stage where <span class="math inline">\(\boldsymbol{b}_i\sim{N}(\boldsymbol{0},\boldsymbol{D})\)</span>, <span class="math inline">\(\boldsymbol{D}\)</span> allows serial correlation within each cross-sectional unit <span class="math inline">\(i\)</span>, and then, there is a second stage where <span class="math inline">\(\boldsymbol{D}\sim{I}{W}(d_0,d_0\boldsymbol{D}_0)\)</span>. Thus, we can see that there is an additional layer of priors as there is a prior on the hyperparameter <span class="math inline">\(\boldsymbol{D}\)</span>.</p>
<p>In addition, we have standard conjugate prior distributions for <span class="math inline">\(\boldsymbol{\beta}\)</span> and <span class="math inline">\(\sigma^2\)</span>, <span class="math inline">\(\boldsymbol{\beta} \sim {N}(\boldsymbol{\beta}_0,\boldsymbol{B}_0)\)</span> and
<span class="math inline">\(\sigma^2 \sim {I}{G}(\alpha_0, \delta_0)\)</span>.</p>
<p><span class="citation">S. Chib and Carlin (<a href="#ref-Chib1999">1999</a>)</span> propose a blocking algorithm to perform inference in longitudinal hierarchical models by considering the distribution of <span class="math inline">\(\boldsymbol{y}_i\)</span> marginalized over the random effects. Given that <span class="math inline">\(\boldsymbol{y}_i\mid  \boldsymbol{\beta},\boldsymbol{b}_i,\sigma^2,\boldsymbol{X}_i,\boldsymbol{W}_i\sim N(\boldsymbol{X}_i\boldsymbol{\beta}+\boldsymbol{W}_i\boldsymbol{b}_i,\sigma^2\boldsymbol{I}_{T_i})\)</span>, we can see that <span class="math inline">\(\boldsymbol{y}_i\mid \boldsymbol{\beta},\boldsymbol{D},\sigma^2,\boldsymbol{X}_i,\boldsymbol{W}_i\sim{N}(\boldsymbol{X}_i\boldsymbol{\beta},\boldsymbol{V}_i)\)</span>, where <span class="math inline">\(\boldsymbol{V}_i=\sigma^2\boldsymbol{I}_{T_i}+\boldsymbol{W}_i\boldsymbol{D}\boldsymbol{W}_i^{\top}\)</span> given that <span class="math inline">\(\mathbb{E}[\boldsymbol{b}_i]=\boldsymbol{0}\)</span> and <span class="math inline">\(Var[\boldsymbol{b}_i]=\boldsymbol{D}\)</span>. If we have just random intercepts, then <span class="math inline">\(\boldsymbol{W}_i=\boldsymbol{i}_{T_i}\)</span>, where <span class="math inline">\(\boldsymbol{i}_{T_i}\)</span> is a <span class="math inline">\(T_i\)</span>-dimensional vector of ones. Thus, <span class="math inline">\(\boldsymbol{V}_i=\sigma^2\boldsymbol{I}_{T_i}+\sigma_{b}^2\boldsymbol{i}_{T_i}\boldsymbol{i}_{T_i}^{\top}\)</span>, the variance is <span class="math inline">\(\sigma^2+\sigma^2_{b}\)</span> and the covariance is <span class="math inline">\(\sigma^2_{b}\)</span> within each cross-sectional unit through time.</p>
<p>We can deduce the posterior distribution of <span class="math inline">\(\boldsymbol{\beta}\)</span> given <span class="math inline">\(\sigma^2\)</span> and <span class="math inline">\(\boldsymbol{D}\)</span>,
<span class="math display">\[\begin{align*}
    \pi(\boldsymbol{\beta}\mid \sigma^2, \boldsymbol{D},\boldsymbol{y}, \boldsymbol{X}, \boldsymbol{W}) &amp; \propto \exp\left\{-\frac{1}{2}\sum_{i=1}^N(\boldsymbol{y}_i-\boldsymbol{X}_i\boldsymbol{\beta})^{\top}\boldsymbol{V}_i^{-1}(\boldsymbol{y}_i-\boldsymbol{X}_i\boldsymbol{\beta})\right\}\\
    &amp;\times \exp\left\{-\frac{1}{2}(\boldsymbol{\beta}-\boldsymbol{\beta}_0)^{\top}\boldsymbol{B}_0^{-1}(\boldsymbol{\beta}-\boldsymbol{\beta}_0)\right\}.
\end{align*}\]</span>
This implies that (see Exercise 1)<br />
<span class="math display">\[\begin{equation*}
    \boldsymbol{\beta}\mid \sigma^2,\boldsymbol{D},\boldsymbol{y}, \boldsymbol{X}, \boldsymbol{W} \sim {N}(\boldsymbol{\beta}_n,\boldsymbol{B}_n),
\end{equation*}\]</span>
where <span class="math inline">\(\boldsymbol{B}_n = (\boldsymbol{B}_0^{-1} +\sum_{i=1}^N \boldsymbol{X}_i^{\top}\boldsymbol{V}_i^{-1}\boldsymbol{X}_i)^{-1}\)</span>, <span class="math inline">\(\boldsymbol{\beta}_n= \boldsymbol{B}_n(\boldsymbol{B}_0^{-1}\boldsymbol{\beta}_0 + \sum_{i=1}^N\boldsymbol{X}_i^{\top}\boldsymbol{V}_i^{-1}\boldsymbol{y}_i)\)</span>.</p>
<p>We can use the likelihood <span class="math inline">\(p(\boldsymbol{\beta},\boldsymbol{b}_i,\sigma^2\mid \boldsymbol{y}, \boldsymbol{X},\boldsymbol{W})\)</span> to get the posterior distributions of <span class="math inline">\(\boldsymbol{b}_i\)</span>, <span class="math inline">\(\sigma^2\)</span> and <span class="math inline">\(\boldsymbol{D}\)</span>. In particular,
<span class="math display">\[\begin{align*}
    \pi(\boldsymbol{b}_i\mid \boldsymbol{\beta},\sigma^2,\boldsymbol{D},\boldsymbol{y}, \boldsymbol{X}, \boldsymbol{W})&amp;\propto \exp\left\{-\frac{1}{2\sigma^2}\sum_{i=1}^N(\boldsymbol{y}_i-\boldsymbol{X}_i\boldsymbol{\beta}-\boldsymbol{W}_i\boldsymbol{b}_i)^{\top}(\boldsymbol{y}_i-\boldsymbol{X}_i\boldsymbol{\beta}-\boldsymbol{W}_i\boldsymbol{b}_i)\right\}\\
    &amp;\times \exp\left\{-\frac{1}{2}\sum_{i=1}^N \boldsymbol{b}_i^{\top}\boldsymbol{D}^{-1}\boldsymbol{b}_i\right\}\\
    &amp;\propto\exp\left\{-\frac{1}{2}\sum_{i=1}^N(-2\boldsymbol{b}_i^{\top}(\sigma^{-2}\boldsymbol{W}_i^{\top}(\boldsymbol{y}_i-\boldsymbol{X}_i\boldsymbol{\beta}))+ \boldsymbol{b}_i^{\top}(\sigma^{-2}\boldsymbol{W}_i^{\top}\boldsymbol{W}_i+\boldsymbol{D}^{-1})\boldsymbol{b}_i)\right\}\\
    &amp;\propto\exp\left\{-\frac{1}{2}(-2\boldsymbol{b}_i^{\top}\boldsymbol{B}_{ni}^{-1}\boldsymbol{B}_{ni}(\sigma^{-2}\boldsymbol{W}_i^{\top}(\boldsymbol{y}_i-\boldsymbol{X}_i\boldsymbol{\beta}))+ \boldsymbol{b}_i^{\top}\boldsymbol{B}_{ni}^{-1}\boldsymbol{b}_i)\right\}\\
    &amp;=\exp\left\{-\frac{1}{2}(-2\boldsymbol{b}_i^{\top}\boldsymbol{B}_{ni}^{-1}\boldsymbol{b}_{ni}+ \boldsymbol{b}_i^{\top}\boldsymbol{B}_{ni}^{-1}\boldsymbol{b}_i)\right\},
\end{align*}\]</span>
where <span class="math inline">\(\boldsymbol{B}_{ni}=(\sigma^{-2}\boldsymbol{W}_i^{\top}\boldsymbol{W}_i+\boldsymbol{D}^{-1})^{-1}\)</span> and <span class="math inline">\(\boldsymbol{b}_{ni}=\boldsymbol{B}_{ni}(\sigma^{-2}\boldsymbol{W}_i^{\top}(\boldsymbol{y}_i-\boldsymbol{X}_i\boldsymbol{\beta}))\)</span>.</p>
<p>We can complete the square in this expression by adding and subtracting <span class="math inline">\(\boldsymbol{b}_{ni}^{\top}\boldsymbol{B}_{ni}^{-1}\boldsymbol{b}_{ni}\)</span>. Thus,
<span class="math display">\[\begin{align*}
    \pi(\boldsymbol{b}_i\mid \boldsymbol{\beta},\sigma^2,\boldsymbol{D},\boldsymbol{y}, \boldsymbol{X}, \boldsymbol{W})&amp;\propto \exp\left\{-\frac{1}{2}(-2\boldsymbol{b}_i^{\top}\boldsymbol{B}_{ni}^{-1}\boldsymbol{b}_{ni}+ \boldsymbol{b}_i^{\top}\boldsymbol{B}_{ni}^{-1}\boldsymbol{b}_i+\boldsymbol{b}_{ni}^{\top}\boldsymbol{B}_{ni}^{-1}\boldsymbol{b}_{ni}-\boldsymbol{b}_{ni}^{\top}\boldsymbol{B}_{ni}^{-1}\boldsymbol{b}_{ni})\right\}\\
    &amp;\propto \exp\left\{(\boldsymbol{b}_i-\boldsymbol{b}_{ni})^{\top}\boldsymbol{B}_{ni}^{-1}(\boldsymbol{b}_i-\boldsymbol{b}_{ni})\right\}.
\end{align*}\]</span>
This is the kernel of a multivariate normal distribution with mean <span class="math inline">\(\boldsymbol{b}_{ni}\)</span> and variance <span class="math inline">\(\boldsymbol{B}_{ni}\)</span>. Thus,
<span class="math display">\[\begin{equation*}
    \boldsymbol{b}_i\mid \boldsymbol{\beta},\sigma^2,\boldsymbol{D},\boldsymbol{y}, \boldsymbol{X}, \boldsymbol{W} \sim {N}(\boldsymbol{b}_{ni},\boldsymbol{B}_{ni}),
\end{equation*}\]</span>
Let’s see the posterior distribution of <span class="math inline">\(\sigma^2\)</span>,
<span class="math display">\[\begin{align*}
    \pi(\sigma^2\mid \boldsymbol{\beta},\boldsymbol{b},\boldsymbol{y}, \boldsymbol{X}, \boldsymbol{W})&amp;\propto (\sigma^2)^{-\frac{\sum_{i=1}^N T_i}{2}}\exp\left\{-\frac{1}{2\sigma^2}\sum_{i=1}^N(\boldsymbol{y}_i-\boldsymbol{X}_i\boldsymbol{\beta}-\boldsymbol{W}_i\boldsymbol{b}_i)^{\top}(\boldsymbol{y}_i-\boldsymbol{X}_i\boldsymbol{\beta}-\boldsymbol{W}_i\boldsymbol{b}_i)\right\}\\
    &amp;\times (\sigma^2)^{-\alpha_0-1}\exp\left\{-\frac{\delta_0}{\sigma^2}\right\}\\
    &amp;=(\sigma^2)^{-\frac{\sum_{i=1}^N T_i}{2}-\alpha_0-1}\\
    &amp;\times \exp\left\{-\frac{1}{\sigma^2}\left(\delta_0+\sum_{i=1}^N\frac{(\boldsymbol{y}_i-\boldsymbol{X}_i\boldsymbol{\beta}-\boldsymbol{W}_i\boldsymbol{b}_i)^{\top}(\boldsymbol{y}_i-\boldsymbol{X}_i\boldsymbol{\beta}-\boldsymbol{W}_i\boldsymbol{b}_i)}{2}\right)\right\}.
\end{align*}\]</span>
Thus,
<span class="math display">\[\begin{equation*}
    \sigma^2\mid  \boldsymbol{\beta}, \boldsymbol{b}, \boldsymbol{y}, \boldsymbol{X}, \boldsymbol{W} \sim {I}{G}(\alpha_n, \delta_n),
\end{equation*}\]</span>
where <span class="math inline">\(\alpha_n=\alpha_0+\frac{1}{2}\sum_{i=1}^N T_i\)</span> and <span class="math inline">\(\delta_n=\delta_0+\frac{1}{2}\sum_{i=1}^N(\boldsymbol{y}_i-\boldsymbol{X}_i\boldsymbol{\beta}-\boldsymbol{W}_i\boldsymbol{b}_i)^{\top}(\boldsymbol{y}_i-\boldsymbol{X}_i\boldsymbol{\beta}-\boldsymbol{W}_i\boldsymbol{b}_i)\)</span>.</p>
<p>The posterior distribution of <span class="math inline">\(\boldsymbol{D}\)</span> is the following,
<span class="math display">\[\begin{align*}
    \pi(\boldsymbol{D}\mid \boldsymbol{b})&amp;\propto  |\boldsymbol{D}|^{-N/2} \exp\left\{-\frac{1}{2}\sum_{i=1}^N \boldsymbol{b}_i^{\top}\boldsymbol{D}^{-1}\boldsymbol{b}_i\right\}\\
    &amp;\times |\boldsymbol{D}|^{-(d_0+K_2+1)/2}\exp\left\{-\frac{1}{2}tr(d_0\boldsymbol{D}_0\boldsymbol{D}^{-1})\right\}\\
    &amp;=|\boldsymbol{D}|^{-(d_0+N+K_2+1)/2}\exp\left\{-\frac{1}{2}tr\left(\left(d_0\boldsymbol{D}_0+\sum_{i=1}^N\boldsymbol{b}_i\boldsymbol{b}_i^{\top}\right)\boldsymbol{D}^{-1}\right) \right\}.
\end{align*}\]</span>
This is the kernel of an inverse Wishart distribution with degrees of freedom <span class="math inline">\(d_n=d_0+N\)</span> and scale matrix <span class="math inline">\(\boldsymbol{D}_n=d_0\boldsymbol{D}_0+\sum_{i=1}^N\boldsymbol{b}_i\boldsymbol{b}_i^{\top}\)</span>. Thus,<br />
<span class="math display">\[\begin{equation*}
    \boldsymbol{D}\mid  \boldsymbol{b} \sim {I}{W}(d_n, \boldsymbol{D}_n).
\end{equation*}\]</span>
Observe that the posterior distribution of <span class="math inline">\(\boldsymbol{D}\)</span> dependents just on <span class="math inline">\(\boldsymbol{b}\)</span>.</p>
<p>All the posterior conditional distributions belong to standard families, this implies that we can use a Gibbs sampling algorithm to perform inference in these hierarchical normal models.</p>
<p><strong>Example: The relation between productivity and public investment</strong></p>
<p>We used the dataset named <em>8PublicCap.csv</em> used by <span class="citation">Ramírez Hassan (<a href="#ref-Ramirez2017">2017</a>)</span> to analyze the relation between public investment and gross state product in the setting of a spatial panel dataset consisting of 48 US states from 1970 to 1986.
In particular, we perform inference based on the following equation
<span class="math display">\[\begin{equation*}
    \log(\text{gsp}_{it})=b_i+\beta_1+\beta_2\log(\text{pcap}_{it})+\beta_3\log(\text{pc}_{it})+\beta_4\log(\text{emp}_{it})+\beta_5\text{unemp}_{it}+\mu_{it},
\end{equation*}\]</span></p>
<p>where <em>gsp</em> in the gross state product, <em>pcap</em> is public capital, and <em>pc</em> is private capital all in USD, <em>emp</em> is employment (people), and <em>unemp</em> is the unemployment rate in percentage.</p>
<p>The following Algorithm shows how to perform inference in hierarchical longitudinal normal models in our GUI. See also Chapter <a href="Chap5.html#Chap5">5</a> for details regarding the dataset structure.</p>
<div class="algorithm">
<div style="background-color: #f8f9fa; padding: 15px; border-left: 5px solid #343a40; box-shadow: 4px 4px 10px rgba(0, 0, 0, 0.1); border-radius: 5px;">
<p><strong>Algorithm: Hierarchical Longitudinal Normal Models</strong></p>
<ol style="list-style-type: decimal">
<li><p>Select <em>Hierarchical Longitudinal Model</em> on the top panel</p></li>
<li><p>Select <em>Normal</em> model using the left radio button</p></li>
<li><p>Upload the dataset, selecting first if there is a header in the file, and the kind of separator in the <em>csv</em> file of the dataset (comma, semicolon, or tab). Then, use the <em>Browse</em> button under the <strong>Choose File</strong> legend</p></li>
<li><p>Select MCMC iterations, burn-in, and thinning parameters using the <em>Range sliders</em></p></li>
<li><p>Write down the formula of the <em>fixed effects</em> equation in the <strong>Main Equation: Fixed Effects</strong> box. This formula must be written using the syntax of the <em>formula</em> command of <strong>R</strong> software. This equation includes intercept by default, do not include it in the equation</p></li>
<li><p>Write down the formula of the <em>random effects</em> equation in the <strong>Main Equation: Random Effects</strong> box without writing the dependent variable, that is, starting the equation with the <em>tilde</em> (“~”) symbol. This formula must be written using the syntax of the <em>formula</em> command of <strong>R</strong> software. This equation includes intercept by default, do not include it in the equation. If there are just random intercepts do not write anything in this box</p></li>
<li><p>Write down the name of the grouping variable, that is, the variable that indicates the cross-sectional units</p></li>
<li><p>Set the hyperparameters of the <em>fixed effects</em>: mean vector, covariance matrix, shape and scale parameters. This step is not necessary as by default our GUI uses non-informative priors</p></li>
<li><p>Set the hyperparameters of the <em>random effects</em>: degrees of freedom and scale matrix of the inverse Wishart distribution. This step is not necessary as by default our GUI uses non-informative priors</p></li>
<li><p>Click the <em>Go!</em> button</p></li>
<li><p>Analyze results</p></li>
<li><p>Download posterior chains and diagnostic plots using the <em>Download Posterior Chains</em> and <em>Download Posterior Graphs</em> buttons</p></li>
</ol>
</div>
</div>
<p>We ask in Exercise 2 to run this application in our GUI using 10,000 MCMC iterations plus a burn-in equal to 5,000 iterations, and a thinning parameter equal to 1. We also used the default values for the hyperparameters of the prior distributions, that is, <span class="math inline">\(\boldsymbol{\beta}_0=\boldsymbol{0}_5\)</span>, <span class="math inline">\(\boldsymbol{B}_0=\boldsymbol{I}_5\)</span>, <span class="math inline">\(\alpha_0=\delta_0=0.001\)</span>, <span class="math inline">\(d_0=5\)</span> and <span class="math inline">\(\boldsymbol{D}_0=\boldsymbol{I}_1\)</span>. It seems that all posterior draws come from stationary distributions, as suggested by the diagnostics and posterior plots (see Exercise 2).</p>
<p>The following code uses the command <em>MCMChregress</em> from the package <em>MCMCpack</em> to run this application. This command is also used by our GUI to perform inference in hierarchical longitudinal normal models.</p>
<p>We can see that the 95% symmetric credible intervals for public capital, private capital, employment, and unemployment are (-2.54e-02, -2.06e-02), (2.92e-01, 2.96e-01), (7.62e-01, 7.67e-01) and (-5.47e-03, -5.31e-03), respectively. The posterior mean elasticity estimate of public capital to GSP is -0.023, that is, an increase by 1% in public capital means a 0.023% decrease in gross state product. The posterior mean estimates of private capital and employment elasticities are 0.294 and 0.765, respectively. In addition, a 1 percentage point increase in the unemployment rate means a decrease of 0.54% in GSP. It seems that all these variables are statistically relevant.</p>
<p>In addition, the posterior mean estimates of the variance associated with the unobserved heterogeneity and stochastic errors are 1.06e-01 and 1.45e-03. We obtained the posterior chain of the proportion of the variance associated with the unobserved heterogeneity. The 95% symmetric credible interval is (0.98, 0.99) for this proportion, that is, unobserved heterogeneity is very important to explain the total variability.</p>
<div class="sourceCode" id="cb411"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb411-1"><a href="sec91.html#cb411-1" tabindex="-1"></a><span class="fu">rm</span>(<span class="at">list =</span> <span class="fu">ls</span>())</span>
<span id="cb411-2"><a href="sec91.html#cb411-2" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">12345</span>)</span>
<span id="cb411-3"><a href="sec91.html#cb411-3" tabindex="-1"></a>DataGSP <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">&quot;https://raw.githubusercontent.com/besmarter/BSTApp/refs/heads/master/DataApp/8PublicCap.csv&quot;</span>, <span class="at">sep =</span> <span class="st">&quot;,&quot;</span>, <span class="at">header =</span> <span class="cn">TRUE</span>, <span class="at">quote =</span> <span class="st">&quot;&quot;</span>)</span>
<span id="cb411-4"><a href="sec91.html#cb411-4" tabindex="-1"></a><span class="fu">attach</span>(DataGSP)</span></code></pre></div>
<pre><code>## The following object is masked from DataUSfilcal:
## 
##     year</code></pre>
<pre><code>## The following object is masked from Data (pos = 9):
## 
##     id</code></pre>
<pre><code>## The following object is masked from DataUtEst:
## 
##     id</code></pre>
<pre><code>## The following object is masked from Data (pos = 15):
## 
##     id</code></pre>
<pre><code>## The following object is masked from mydata:
## 
##     id</code></pre>
<div class="sourceCode" id="cb417"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb417-1"><a href="sec91.html#cb417-1" tabindex="-1"></a>K1 <span class="ot">&lt;-</span> <span class="dv">5</span>; K2 <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb417-2"><a href="sec91.html#cb417-2" tabindex="-1"></a>b0 <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">0</span>, K1); B0 <span class="ot">&lt;-</span> <span class="fu">diag</span>(K1)</span>
<span id="cb417-3"><a href="sec91.html#cb417-3" tabindex="-1"></a>r0 <span class="ot">&lt;-</span> <span class="dv">5</span>; R0 <span class="ot">&lt;-</span> <span class="fu">diag</span>(K2)</span>
<span id="cb417-4"><a href="sec91.html#cb417-4" tabindex="-1"></a>a0 <span class="ot">&lt;-</span> <span class="fl">0.001</span>; d0 <span class="ot">&lt;-</span> <span class="fl">0.001</span></span>
<span id="cb417-5"><a href="sec91.html#cb417-5" tabindex="-1"></a>Resultshreg <span class="ot">&lt;-</span> MCMCpack<span class="sc">::</span><span class="fu">MCMChregress</span>(<span class="at">fixed =</span> <span class="fu">log</span>(gsp)<span class="sc">~</span><span class="fu">log</span>(pcap)<span class="sc">+</span><span class="fu">log</span>(pc)<span class="sc">+</span><span class="fu">log</span>(emp)<span class="sc">+</span>unemp, <span class="at">random =</span> <span class="sc">~</span><span class="dv">1</span>, <span class="at">group =</span> <span class="st">&quot;id&quot;</span>, <span class="at">data =</span> DataGSP, <span class="at">burnin =</span> <span class="dv">5000</span>, <span class="at">mcmc =</span> <span class="dv">10000</span>, <span class="at">thin =</span> <span class="dv">1</span>, <span class="at">r =</span> r0, <span class="at">R =</span> R0, <span class="at">nu =</span> a0, <span class="at">delta =</span> d0)</span></code></pre></div>
<pre><code>## 
## Running the Gibbs sampler. It may be long, keep cool :)
## 
## **********:10.0%
## **********:20.0%
## **********:30.0%
## **********:40.0%
## **********:50.0%
## **********:60.0%
## **********:70.0%
## **********:80.0%
## **********:90.0%
## **********:100.0%</code></pre>
<div class="sourceCode" id="cb419"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb419-1"><a href="sec91.html#cb419-1" tabindex="-1"></a>Betas <span class="ot">&lt;-</span> Resultshreg[[<span class="st">&quot;mcmc&quot;</span>]][,<span class="dv">1</span><span class="sc">:</span>K1]</span>
<span id="cb419-2"><a href="sec91.html#cb419-2" tabindex="-1"></a>Sigma2RanEff <span class="ot">&lt;-</span> Resultshreg[[<span class="st">&quot;mcmc&quot;</span>]][,<span class="dv">54</span>]</span>
<span id="cb419-3"><a href="sec91.html#cb419-3" tabindex="-1"></a>Sigma2 <span class="ot">&lt;-</span> Resultshreg[[<span class="st">&quot;mcmc&quot;</span>]][,<span class="dv">55</span>]</span>
<span id="cb419-4"><a href="sec91.html#cb419-4" tabindex="-1"></a><span class="fu">summary</span>(Betas)</span></code></pre></div>
<pre><code>## 
## Iterations = 5001:15000
## Thinning interval = 1 
## Number of chains = 1 
## Sample size per chain = 10000 
## 
## 1. Empirical mean and standard deviation for each variable,
##    plus standard error of the mean:
## 
##                       Mean        SD  Naive SE Time-series SE
## beta.(Intercept)  2.330139 7.940e-03 7.940e-05      7.940e-05
## beta.log(pcap)   -0.023082 1.225e-03 1.225e-05      1.225e-05
## beta.log(pc)      0.293729 1.007e-03 1.007e-05      1.007e-05
## beta.log(emp)     0.764645 1.333e-03 1.333e-05      1.340e-05
## beta.unemp       -0.005387 4.114e-05 4.114e-07      4.071e-07
## 
## 2. Quantiles for each variable:
## 
##                       2.5%       25%       50%      75%     97.5%
## beta.(Intercept)  2.314556  2.324656  2.330193  2.33567  2.345548
## beta.log(pcap)   -0.025442 -0.023926 -0.023104 -0.02227 -0.020655
## beta.log(pc)      0.291738  0.293068  0.293721  0.29441  0.295716
## beta.log(emp)     0.761969  0.763755  0.764650  0.76554  0.767220
## beta.unemp       -0.005468 -0.005414 -0.005387 -0.00536 -0.005307</code></pre>
<div class="sourceCode" id="cb421"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb421-1"><a href="sec91.html#cb421-1" tabindex="-1"></a><span class="fu">summary</span>(Sigma2RanEff)</span></code></pre></div>
<pre><code>## 
## Iterations = 5001:15000
## Thinning interval = 1 
## Number of chains = 1 
## Sample size per chain = 10000 
## 
## 1. Empirical mean and standard deviation for each variable,
##    plus standard error of the mean:
## 
##           Mean             SD       Naive SE Time-series SE 
##      0.1058028      0.0215133      0.0002151      0.0002151 
## 
## 2. Quantiles for each variable:
## 
##    2.5%     25%     50%     75%   97.5% 
## 0.07208 0.09086 0.10331 0.11751 0.15600</code></pre>
<div class="sourceCode" id="cb423"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb423-1"><a href="sec91.html#cb423-1" tabindex="-1"></a><span class="fu">summary</span>(Sigma2)</span></code></pre></div>
<pre><code>## 
## Iterations = 5001:15000
## Thinning interval = 1 
## Number of chains = 1 
## Sample size per chain = 10000 
## 
## 1. Empirical mean and standard deviation for each variable,
##    plus standard error of the mean:
## 
##           Mean             SD       Naive SE Time-series SE 
##      1.453e-03      7.361e-05      7.361e-07      7.698e-07 
## 
## 2. Quantiles for each variable:
## 
##     2.5%      25%      50%      75%    97.5% 
## 0.001316 0.001403 0.001451 0.001501 0.001606</code></pre>
<p>There are many extensions of this model. For instance, <span class="citation">S. Chib and Carlin (<a href="#ref-Chib1999">1999</a>)</span> propose introducing heteroskedasticity in this model by assuming <span class="math inline">\(\mu_{it} \mid \tau_{it} \sim N(0, \sigma^2/\tau_{it})\)</span>, <span class="math inline">\(\tau_{it} \sim G(v/2,v/2)\)</span>. We ask in Exercise 2 to perform inference on the relationship between productivity and public investment using this setting.</p>
<p>Another potential extension is to allow dependence between <span class="math inline">\(\boldsymbol{b}_i\)</span> and some controls, let’s say <span class="math inline">\(\boldsymbol{z}_i\)</span>, a <span class="math inline">\(K_3\)</span>-dimensional vector, and assume <span class="math inline">\(\boldsymbol{b}_i \sim N(\boldsymbol{Z}_i \boldsymbol{\gamma}, \boldsymbol{D})\)</span> where <span class="math inline">\(\boldsymbol{Z}_i = \mathbf{I}_{K_2} \otimes \boldsymbol{z}_i^{\top}\)</span>, and complete the model using a prior for <span class="math inline">\(\boldsymbol{\gamma}\)</span>, <span class="math inline">\(\boldsymbol{\gamma} \sim N(\boldsymbol{\gamma}_0, \boldsymbol{\Gamma}_0)\)</span>. We ask to perform a simulation using this setting in Exercise 3.</p>
<p><strong>Example: Simulation exercise of the longitudinal normal model with heteroskedasticity</strong></p>
<p>Let’s perform a simulation exercise to assess some potential extensions of the longitudinal hierarchical normal model. The point of departure is to assume that
<span class="math display">\[y_{it}=\beta_0+\beta_1x_{it1}+\beta_2x_{it2}+\beta_3x_{it3}+b_i+w_{it1}b_{i1}+\mu_{it},\]</span>
where <span class="math inline">\(x_{itk}\sim N(0,1)\)</span>, <span class="math inline">\(k=1,2,3\)</span>, <span class="math inline">\(w_{it1}\sim N(0,1)\)</span>, <span class="math inline">\(b_i\sim N(0, 0.7^{1/2})\)</span>, <span class="math inline">\(b_{i1}\sim N(0, 0.6^{1/2})\)</span>, <span class="math inline">\(\mu_{it}\sim N(0, (0.1/\tau_{it})^{1/2})\)</span>, <span class="math inline">\(\tau_{it}\sim G(v/2,v/2)\)</span> and <span class="math inline">\(\boldsymbol{\beta}=[0.5 \ 0.4 \ 0.6 \ -0.6]^{\top}\)</span>, <span class="math inline">\(i=1,2,\dots,50\)</span>. The sample size is 2,000 in an <em>unbalanced panel structure</em>.</p>
<p>Following same stages as in this section and Exercise 1, the posterior conditional distributions assuming that <span class="math inline">\(\mu_{it}\mid \tau_{it}\sim N(0, \sigma^2/\tau_{it})\)</span>, <span class="math inline">\(\tau_{it}\sim G(v/2,v/2)\)</span> are given by
<span class="math display">\[\begin{equation*}
    \boldsymbol{\beta}\mid \sigma^2,\boldsymbol{\tau},\boldsymbol{D},\boldsymbol{y}, \boldsymbol{X}, \boldsymbol{W} \sim {N}(\boldsymbol{\beta}_n,\boldsymbol{B}_n),
\end{equation*}\]</span>
where <span class="math inline">\(\boldsymbol{\tau}=[\tau_{it}]^{\top}\)</span>, <span class="math inline">\(\boldsymbol{B}_n = (\boldsymbol{B}_0^{-1} +\sum_{i=1}^N \boldsymbol{X}_i^{\top}\boldsymbol{V}_i^{-1}\boldsymbol{X}_i)^{-1}\)</span>, <span class="math inline">\(\boldsymbol{\beta}_n= \boldsymbol{B}_n(\boldsymbol{B}_0^{-1}\boldsymbol{\beta}_0 + \sum_{i=1}^N\boldsymbol{X}_i^{\top}\boldsymbol{V}_i^{-1}\boldsymbol{y}_i)\)</span>, <span class="math inline">\(\boldsymbol{V}_i=\sigma^2\boldsymbol{\Psi}_i+\sigma_{b}^2\boldsymbol{i}_{T_i}\boldsymbol{i}_{T_i}^{\top}\)</span> and <span class="math inline">\(\boldsymbol{\Psi}_i=diag\left\{\tau_{it}^{-1}\right\}\)</span>.
<span class="math display">\[\begin{equation*}
    \boldsymbol{b}_i\mid \boldsymbol{\beta},\sigma^2,\boldsymbol{\tau},\boldsymbol{D},\boldsymbol{y}, \boldsymbol{X}, \boldsymbol{W} \sim {N}(\boldsymbol{b}_{ni},\boldsymbol{B}_{ni}),
\end{equation*}\]</span>
where <span class="math inline">\(\boldsymbol{B}_{ni}=(\sigma^{-2}\boldsymbol{W}_i^{\top}\boldsymbol{\Psi}_i^{-1}\boldsymbol{W}_i+\boldsymbol{D}^{-1})^{-1}\)</span> and <span class="math inline">\(\boldsymbol{b}_{ni}=\boldsymbol{B}_{ni}(\sigma^{-2}\boldsymbol{W}_i^{\top}\boldsymbol{\Psi}_i^{-1}(\boldsymbol{y}_i-\boldsymbol{X}_i\boldsymbol{\beta}))\)</span>.
<span class="math display">\[\begin{equation*}
    \sigma^2\mid  \boldsymbol{\beta}, \boldsymbol{b}, \boldsymbol{\tau}, \boldsymbol{y}, \boldsymbol{X}, \boldsymbol{W} \sim {I}{G}(\alpha_n, \delta_n),
\end{equation*}\]</span>
where <span class="math inline">\(\alpha_n=\alpha_0+\frac{1}{2}\sum_{i=1}^N T_i\)</span> and <span class="math inline">\(\delta_n=\delta_0+\frac{1}{2}\sum_{i=1}^N(\boldsymbol{y}_i-\boldsymbol{X}_i\boldsymbol{\beta}-\boldsymbol{W}_i\boldsymbol{b}_i)^{\top}\boldsymbol{\Psi}_i^{-1}(\boldsymbol{y}_i-\boldsymbol{X}_i\boldsymbol{\beta}-\boldsymbol{W}_i\boldsymbol{b}_i)\)</span>.<br />
<span class="math display">\[\begin{equation*}
    \boldsymbol{D}\mid  \boldsymbol{b} \sim {I}{W}(d_n, \boldsymbol{D}_n),
\end{equation*}\]</span>
where <span class="math inline">\(d_n=d_0+N\)</span> and <span class="math inline">\(\boldsymbol{D}_n=d_0\boldsymbol{D}_0+\sum_{i=1}^N\boldsymbol{b}_i\boldsymbol{b}_i^{\top}\)</span>. And
<span class="math display">\[\begin{equation*}
    \tau_{it}\mid \sigma^2, \boldsymbol{\beta}, \boldsymbol{b}, \boldsymbol{y}, \boldsymbol{X}, \boldsymbol{W} \sim {G}(v_{1n}/2, v_{2ni}/2),
\end{equation*}\]</span>
where <span class="math inline">\(v_{1n}=v+1\)</span> and <span class="math inline">\(v_{2ni}=v+\sigma^{-2}(y_{it}-\boldsymbol{x}_{it}^{\top}\boldsymbol{\beta}-\boldsymbol{w}_{it}^{\top}\boldsymbol{b}_i)^2\)</span>.</p>
<p>The following code implements this simulation, and gets draws of the posterior distributions. We set MCMC iterations, burn-in and thinning parameters equal to 5,000, 1,000 and 1, respectively. In addition, <span class="math inline">\(\boldsymbol{\beta}_0=\boldsymbol{0}_5\)</span>, <span class="math inline">\(\boldsymbol{B}_0=\boldsymbol{I}_5\)</span>, <span class="math inline">\(\alpha_0=\delta_0=0.001\)</span>, <span class="math inline">\(d_0=2\)</span>, <span class="math inline">\(\boldsymbol{D}_0=\boldsymbol{I}_2\)</span> and <span class="math inline">\(v=5\)</span>.</p>
<div class="sourceCode" id="cb425"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb425-1"><a href="sec91.html#cb425-1" tabindex="-1"></a><span class="fu">rm</span>(<span class="at">list =</span> <span class="fu">ls</span>()); <span class="fu">set.seed</span>(<span class="dv">010101</span>)</span>
<span id="cb425-2"><a href="sec91.html#cb425-2" tabindex="-1"></a>NT <span class="ot">&lt;-</span> <span class="dv">2000</span>; N <span class="ot">&lt;-</span> <span class="dv">50</span></span>
<span id="cb425-3"><a href="sec91.html#cb425-3" tabindex="-1"></a>id <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span>N, <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span>N, NT <span class="sc">-</span> N,<span class="at">replace=</span><span class="cn">TRUE</span>))</span>
<span id="cb425-4"><a href="sec91.html#cb425-4" tabindex="-1"></a><span class="fu">table</span>(id)</span></code></pre></div>
<pre><code>## id
##  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 
## 42 35 48 53 44 36 43 34 42 38 40 39 41 43 40 30 27 56 39 51 36 30 45 35 33 48 
## 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 
## 37 51 32 46 47 41 44 39 40 48 37 44 37 42 42 34 42 34 41 35 36 34 31 38</code></pre>
<div class="sourceCode" id="cb427"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb427-1"><a href="sec91.html#cb427-1" tabindex="-1"></a>x1 <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(NT); x2 <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(NT); x3 <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(NT) </span>
<span id="cb427-2"><a href="sec91.html#cb427-2" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="dv">1</span>, x1, x2, x3); K1 <span class="ot">&lt;-</span> <span class="fu">dim</span>(X)[<span class="dv">2</span>]</span>
<span id="cb427-3"><a href="sec91.html#cb427-3" tabindex="-1"></a>w1 <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(NT); W <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="dv">1</span>, w1)</span>
<span id="cb427-4"><a href="sec91.html#cb427-4" tabindex="-1"></a>K2 <span class="ot">&lt;-</span> <span class="fu">dim</span>(W)[<span class="dv">2</span>]; B <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">0.5</span>, <span class="fl">0.4</span>, <span class="fl">0.6</span>, <span class="sc">-</span><span class="fl">0.6</span>)</span>
<span id="cb427-5"><a href="sec91.html#cb427-5" tabindex="-1"></a>D <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">0.7</span>, <span class="fl">0.6</span>)</span>
<span id="cb427-6"><a href="sec91.html#cb427-6" tabindex="-1"></a>b1 <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N, <span class="dv">0</span>, <span class="at">sd =</span> D[<span class="dv">1</span>]<span class="sc">^</span><span class="fl">0.5</span>)</span>
<span id="cb427-7"><a href="sec91.html#cb427-7" tabindex="-1"></a>b2 <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N, <span class="dv">0</span>, <span class="at">sd =</span> D[<span class="dv">2</span>]<span class="sc">^</span><span class="fl">0.5</span>)</span>
<span id="cb427-8"><a href="sec91.html#cb427-8" tabindex="-1"></a>b <span class="ot">&lt;-</span> <span class="fu">cbind</span>(b1, b2)</span>
<span id="cb427-9"><a href="sec91.html#cb427-9" tabindex="-1"></a>v <span class="ot">&lt;-</span> <span class="dv">5</span>; tau <span class="ot">&lt;-</span> <span class="fu">rgamma</span>(NT, <span class="at">shape =</span> v<span class="sc">/</span><span class="dv">2</span>, <span class="at">rate =</span> v<span class="sc">/</span><span class="dv">2</span>)</span>
<span id="cb427-10"><a href="sec91.html#cb427-10" tabindex="-1"></a>sig2 <span class="ot">&lt;-</span> <span class="fl">0.1</span>; u <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(NT, <span class="dv">0</span>, <span class="at">sd =</span> (sig2<span class="sc">/</span>tau)<span class="sc">^</span><span class="fl">0.5</span>)</span>
<span id="cb427-11"><a href="sec91.html#cb427-11" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="cn">NULL</span></span>
<span id="cb427-12"><a href="sec91.html#cb427-12" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>NT){</span>
<span id="cb427-13"><a href="sec91.html#cb427-13" tabindex="-1"></a>    yi <span class="ot">&lt;-</span> X[i,]<span class="sc">%*%</span>B <span class="sc">+</span> W[i,]<span class="sc">%*%</span>b[id[i],] <span class="sc">+</span> u[i] </span>
<span id="cb427-14"><a href="sec91.html#cb427-14" tabindex="-1"></a>    y <span class="ot">&lt;-</span> <span class="fu">c</span>(y, yi)</span>
<span id="cb427-15"><a href="sec91.html#cb427-15" tabindex="-1"></a>}</span>
<span id="cb427-16"><a href="sec91.html#cb427-16" tabindex="-1"></a>Data <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(<span class="fu">cbind</span>(y, x1, x2, x3, w1, id))</span>
<span id="cb427-17"><a href="sec91.html#cb427-17" tabindex="-1"></a>mcmc <span class="ot">&lt;-</span> <span class="dv">5000</span>; burnin <span class="ot">&lt;-</span> <span class="dv">1000</span>; thin <span class="ot">&lt;-</span> <span class="dv">1</span>; tot <span class="ot">&lt;-</span> mcmc <span class="sc">+</span> burnin</span>
<span id="cb427-18"><a href="sec91.html#cb427-18" tabindex="-1"></a>b0 <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">0</span>, K1); B0 <span class="ot">&lt;-</span> <span class="fu">diag</span>(K1); B0i <span class="ot">&lt;-</span> <span class="fu">solve</span>(B0) </span>
<span id="cb427-19"><a href="sec91.html#cb427-19" tabindex="-1"></a>r0 <span class="ot">&lt;-</span> K2; R0 <span class="ot">&lt;-</span> <span class="fu">diag</span>(K2); a0 <span class="ot">&lt;-</span> <span class="fl">0.001</span>; d0 <span class="ot">&lt;-</span> <span class="fl">0.001</span></span>
<span id="cb427-20"><a href="sec91.html#cb427-20" tabindex="-1"></a>PostBeta <span class="ot">&lt;-</span> <span class="cf">function</span>(sig2, D, tau){</span>
<span id="cb427-21"><a href="sec91.html#cb427-21" tabindex="-1"></a>    XVX <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="dv">0</span>, K1, K1)</span>
<span id="cb427-22"><a href="sec91.html#cb427-22" tabindex="-1"></a>    XVy <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="dv">0</span>, K1, <span class="dv">1</span>)</span>
<span id="cb427-23"><a href="sec91.html#cb427-23" tabindex="-1"></a>    <span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>N){</span>
<span id="cb427-24"><a href="sec91.html#cb427-24" tabindex="-1"></a>        ids <span class="ot">&lt;-</span> <span class="fu">which</span>(id <span class="sc">==</span> i)</span>
<span id="cb427-25"><a href="sec91.html#cb427-25" tabindex="-1"></a>        Ti <span class="ot">&lt;-</span> <span class="fu">length</span>(ids)</span>
<span id="cb427-26"><a href="sec91.html#cb427-26" tabindex="-1"></a>        Wi <span class="ot">&lt;-</span> W[ids, ]</span>
<span id="cb427-27"><a href="sec91.html#cb427-27" tabindex="-1"></a>        taui <span class="ot">&lt;-</span> tau[ids]</span>
<span id="cb427-28"><a href="sec91.html#cb427-28" tabindex="-1"></a>        Vi <span class="ot">&lt;-</span> sig2<span class="sc">*</span><span class="fu">solve</span>(<span class="fu">diag</span>(<span class="dv">1</span><span class="sc">/</span>taui)) <span class="sc">+</span> Wi<span class="sc">%*%</span>D<span class="sc">%*%</span><span class="fu">t</span>(Wi)</span>
<span id="cb427-29"><a href="sec91.html#cb427-29" tabindex="-1"></a>        ViInv <span class="ot">&lt;-</span> <span class="fu">solve</span>(Vi)</span>
<span id="cb427-30"><a href="sec91.html#cb427-30" tabindex="-1"></a>        Xi <span class="ot">&lt;-</span> X[ids, ]</span>
<span id="cb427-31"><a href="sec91.html#cb427-31" tabindex="-1"></a>        XVXi <span class="ot">&lt;-</span> <span class="fu">t</span>(Xi)<span class="sc">%*%</span>ViInv<span class="sc">%*%</span>Xi</span>
<span id="cb427-32"><a href="sec91.html#cb427-32" tabindex="-1"></a>        XVX <span class="ot">&lt;-</span> XVX <span class="sc">+</span> XVXi</span>
<span id="cb427-33"><a href="sec91.html#cb427-33" tabindex="-1"></a>        yi <span class="ot">&lt;-</span> y[ids]</span>
<span id="cb427-34"><a href="sec91.html#cb427-34" tabindex="-1"></a>        XVyi <span class="ot">&lt;-</span> <span class="fu">t</span>(Xi)<span class="sc">%*%</span>ViInv<span class="sc">%*%</span>yi</span>
<span id="cb427-35"><a href="sec91.html#cb427-35" tabindex="-1"></a>        XVy <span class="ot">&lt;-</span> XVy <span class="sc">+</span> XVyi</span>
<span id="cb427-36"><a href="sec91.html#cb427-36" tabindex="-1"></a>    }</span>
<span id="cb427-37"><a href="sec91.html#cb427-37" tabindex="-1"></a>    Bn <span class="ot">&lt;-</span> <span class="fu">solve</span>(B0i <span class="sc">+</span> XVX)</span>
<span id="cb427-38"><a href="sec91.html#cb427-38" tabindex="-1"></a>    bn <span class="ot">&lt;-</span> Bn<span class="sc">%*%</span>(B0i<span class="sc">%*%</span>b0 <span class="sc">+</span> XVy)</span>
<span id="cb427-39"><a href="sec91.html#cb427-39" tabindex="-1"></a>    Beta <span class="ot">&lt;-</span> MASS<span class="sc">::</span><span class="fu">mvrnorm</span>(<span class="dv">1</span>, bn, Bn)</span>
<span id="cb427-40"><a href="sec91.html#cb427-40" tabindex="-1"></a>    <span class="fu">return</span>(Beta)</span>
<span id="cb427-41"><a href="sec91.html#cb427-41" tabindex="-1"></a>}</span>
<span id="cb427-42"><a href="sec91.html#cb427-42" tabindex="-1"></a>Postb <span class="ot">&lt;-</span> <span class="cf">function</span>(Beta, sig2, D, tau){</span>
<span id="cb427-43"><a href="sec91.html#cb427-43" tabindex="-1"></a>    Di <span class="ot">&lt;-</span> <span class="fu">solve</span>(D);     bis <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="dv">0</span>, N, K2)</span>
<span id="cb427-44"><a href="sec91.html#cb427-44" tabindex="-1"></a>    <span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>N){</span>
<span id="cb427-45"><a href="sec91.html#cb427-45" tabindex="-1"></a>        ids <span class="ot">&lt;-</span> <span class="fu">which</span>(id <span class="sc">==</span> i)</span>
<span id="cb427-46"><a href="sec91.html#cb427-46" tabindex="-1"></a>        Wi <span class="ot">&lt;-</span> W[ids, ]; Xi <span class="ot">&lt;-</span> X[ids, ]</span>
<span id="cb427-47"><a href="sec91.html#cb427-47" tabindex="-1"></a>        yi <span class="ot">&lt;-</span> y[ids]; taui <span class="ot">&lt;-</span> tau[ids]</span>
<span id="cb427-48"><a href="sec91.html#cb427-48" tabindex="-1"></a>        Taui <span class="ot">&lt;-</span> <span class="fu">solve</span>(<span class="fu">diag</span>(<span class="dv">1</span><span class="sc">/</span>taui))</span>
<span id="cb427-49"><a href="sec91.html#cb427-49" tabindex="-1"></a>        Wtei <span class="ot">&lt;-</span> sig2<span class="sc">^</span>(<span class="sc">-</span><span class="dv">1</span>)<span class="sc">*</span><span class="fu">t</span>(Wi)<span class="sc">%*%</span>Taui<span class="sc">%*%</span>(yi <span class="sc">-</span> Xi<span class="sc">%*%</span>Beta)</span>
<span id="cb427-50"><a href="sec91.html#cb427-50" tabindex="-1"></a>        Bni <span class="ot">&lt;-</span> <span class="fu">solve</span>(sig2<span class="sc">^</span>(<span class="sc">-</span><span class="dv">1</span>)<span class="sc">*</span><span class="fu">t</span>(Wi)<span class="sc">%*%</span>Taui<span class="sc">%*%</span>Wi <span class="sc">+</span> Di)</span>
<span id="cb427-51"><a href="sec91.html#cb427-51" tabindex="-1"></a>        bni <span class="ot">&lt;-</span> Bni<span class="sc">%*%</span>Wtei</span>
<span id="cb427-52"><a href="sec91.html#cb427-52" tabindex="-1"></a>        bi <span class="ot">&lt;-</span> MASS<span class="sc">::</span><span class="fu">mvrnorm</span>(<span class="dv">1</span>, bni, Bni)</span>
<span id="cb427-53"><a href="sec91.html#cb427-53" tabindex="-1"></a>        bis[i, ] <span class="ot">&lt;-</span> bi</span>
<span id="cb427-54"><a href="sec91.html#cb427-54" tabindex="-1"></a>    }</span>
<span id="cb427-55"><a href="sec91.html#cb427-55" tabindex="-1"></a>    <span class="fu">return</span>(bis)</span>
<span id="cb427-56"><a href="sec91.html#cb427-56" tabindex="-1"></a>}</span>
<span id="cb427-57"><a href="sec91.html#cb427-57" tabindex="-1"></a>PostSig2 <span class="ot">&lt;-</span> <span class="cf">function</span>(Beta, bs, tau){</span>
<span id="cb427-58"><a href="sec91.html#cb427-58" tabindex="-1"></a>    an <span class="ot">&lt;-</span> a0 <span class="sc">+</span> <span class="fl">0.5</span><span class="sc">*</span>NT</span>
<span id="cb427-59"><a href="sec91.html#cb427-59" tabindex="-1"></a>    ete <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb427-60"><a href="sec91.html#cb427-60" tabindex="-1"></a>    <span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>N){</span>
<span id="cb427-61"><a href="sec91.html#cb427-61" tabindex="-1"></a>        ids <span class="ot">&lt;-</span> <span class="fu">which</span>(id <span class="sc">==</span> i)</span>
<span id="cb427-62"><a href="sec91.html#cb427-62" tabindex="-1"></a>        Xi <span class="ot">&lt;-</span> X[ids, ]; yi <span class="ot">&lt;-</span> y[ids]</span>
<span id="cb427-63"><a href="sec91.html#cb427-63" tabindex="-1"></a>        Wi <span class="ot">&lt;-</span> W[ids, ]; taui <span class="ot">&lt;-</span> tau[ids]</span>
<span id="cb427-64"><a href="sec91.html#cb427-64" tabindex="-1"></a>        Taui <span class="ot">&lt;-</span> <span class="fu">solve</span>(<span class="fu">diag</span>(<span class="dv">1</span><span class="sc">/</span>taui))</span>
<span id="cb427-65"><a href="sec91.html#cb427-65" tabindex="-1"></a>        ei <span class="ot">&lt;-</span> yi <span class="sc">-</span> Xi<span class="sc">%*%</span>Beta <span class="sc">-</span> Wi<span class="sc">%*%</span>bs[i, ]</span>
<span id="cb427-66"><a href="sec91.html#cb427-66" tabindex="-1"></a>        etei <span class="ot">&lt;-</span> <span class="fu">t</span>(ei)<span class="sc">%*%</span>Taui<span class="sc">%*%</span>ei</span>
<span id="cb427-67"><a href="sec91.html#cb427-67" tabindex="-1"></a>        ete <span class="ot">&lt;-</span> ete <span class="sc">+</span> etei</span>
<span id="cb427-68"><a href="sec91.html#cb427-68" tabindex="-1"></a>    }</span>
<span id="cb427-69"><a href="sec91.html#cb427-69" tabindex="-1"></a>    dn <span class="ot">&lt;-</span> d0 <span class="sc">+</span> <span class="fl">0.5</span><span class="sc">*</span>ete </span>
<span id="cb427-70"><a href="sec91.html#cb427-70" tabindex="-1"></a>    sig2 <span class="ot">&lt;-</span> MCMCpack<span class="sc">::</span><span class="fu">rinvgamma</span>(<span class="dv">1</span>, <span class="at">shape =</span> an, <span class="at">scale =</span> dn)</span>
<span id="cb427-71"><a href="sec91.html#cb427-71" tabindex="-1"></a>    <span class="fu">return</span>(sig2)</span>
<span id="cb427-72"><a href="sec91.html#cb427-72" tabindex="-1"></a>}</span>
<span id="cb427-73"><a href="sec91.html#cb427-73" tabindex="-1"></a>PostD <span class="ot">&lt;-</span> <span class="cf">function</span>(bs){</span>
<span id="cb427-74"><a href="sec91.html#cb427-74" tabindex="-1"></a>    rn <span class="ot">&lt;-</span> r0 <span class="sc">+</span> N</span>
<span id="cb427-75"><a href="sec91.html#cb427-75" tabindex="-1"></a>    btb <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="dv">0</span>, K2, K2)</span>
<span id="cb427-76"><a href="sec91.html#cb427-76" tabindex="-1"></a>    <span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>N){</span>
<span id="cb427-77"><a href="sec91.html#cb427-77" tabindex="-1"></a>        bsi <span class="ot">&lt;-</span> bs[i, ]</span>
<span id="cb427-78"><a href="sec91.html#cb427-78" tabindex="-1"></a>        btbi <span class="ot">&lt;-</span> bsi<span class="sc">%*%</span><span class="fu">t</span>(bsi)</span>
<span id="cb427-79"><a href="sec91.html#cb427-79" tabindex="-1"></a>        btb <span class="ot">&lt;-</span> btb <span class="sc">+</span> btbi</span>
<span id="cb427-80"><a href="sec91.html#cb427-80" tabindex="-1"></a>    }</span>
<span id="cb427-81"><a href="sec91.html#cb427-81" tabindex="-1"></a>    Rn <span class="ot">&lt;-</span> d0<span class="sc">*</span>R0 <span class="sc">+</span> btb</span>
<span id="cb427-82"><a href="sec91.html#cb427-82" tabindex="-1"></a>    Sigma <span class="ot">&lt;-</span> MCMCpack<span class="sc">::</span><span class="fu">riwish</span>(<span class="at">v =</span> rn, <span class="at">S =</span> Rn)</span>
<span id="cb427-83"><a href="sec91.html#cb427-83" tabindex="-1"></a>    <span class="fu">return</span>(Sigma)</span>
<span id="cb427-84"><a href="sec91.html#cb427-84" tabindex="-1"></a>}</span>
<span id="cb427-85"><a href="sec91.html#cb427-85" tabindex="-1"></a>PostTau <span class="ot">&lt;-</span> <span class="cf">function</span>(sig2, Beta, bs){</span>
<span id="cb427-86"><a href="sec91.html#cb427-86" tabindex="-1"></a>    v1n <span class="ot">&lt;-</span> v <span class="sc">+</span> <span class="dv">1</span></span>
<span id="cb427-87"><a href="sec91.html#cb427-87" tabindex="-1"></a>    v2n <span class="ot">&lt;-</span> <span class="cn">NULL</span></span>
<span id="cb427-88"><a href="sec91.html#cb427-88" tabindex="-1"></a>    <span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>NT){</span>
<span id="cb427-89"><a href="sec91.html#cb427-89" tabindex="-1"></a>        Xi <span class="ot">&lt;-</span> X[i, ]; yi <span class="ot">&lt;-</span> y[i]</span>
<span id="cb427-90"><a href="sec91.html#cb427-90" tabindex="-1"></a>        Wi <span class="ot">&lt;-</span> W[i, ]; bi <span class="ot">&lt;-</span> bs[id[i],]</span>
<span id="cb427-91"><a href="sec91.html#cb427-91" tabindex="-1"></a>        v2ni <span class="ot">&lt;-</span> v <span class="sc">+</span> sig2<span class="sc">^</span>(<span class="sc">-</span><span class="dv">1</span>)<span class="sc">*</span>(yi <span class="sc">-</span> Xi<span class="sc">%*%</span>Beta <span class="sc">-</span> Wi<span class="sc">%*%</span>bi)<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb427-92"><a href="sec91.html#cb427-92" tabindex="-1"></a>        v2n <span class="ot">&lt;-</span> <span class="fu">c</span>(v2n, v2ni)</span>
<span id="cb427-93"><a href="sec91.html#cb427-93" tabindex="-1"></a>    }</span>
<span id="cb427-94"><a href="sec91.html#cb427-94" tabindex="-1"></a>    tau <span class="ot">&lt;-</span> <span class="fu">rgamma</span>(NT, <span class="at">shape =</span> <span class="fu">rep</span>(v1n<span class="sc">/</span><span class="dv">2</span>, NT), <span class="at">rate =</span> v2n<span class="sc">/</span><span class="dv">2</span>)</span>
<span id="cb427-95"><a href="sec91.html#cb427-95" tabindex="-1"></a>    <span class="fu">return</span>(tau)</span>
<span id="cb427-96"><a href="sec91.html#cb427-96" tabindex="-1"></a>}</span>
<span id="cb427-97"><a href="sec91.html#cb427-97" tabindex="-1"></a>PostBetas <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="dv">0</span>, tot, K1); PostDs <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="dv">0</span>, tot, K2<span class="sc">*</span>(K2<span class="sc">+</span><span class="dv">1</span>)<span class="sc">/</span><span class="dv">2</span>)</span>
<span id="cb427-98"><a href="sec91.html#cb427-98" tabindex="-1"></a>PostSig2s <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">0</span>, tot); Postbs <span class="ot">&lt;-</span> <span class="fu">array</span>(<span class="dv">0</span>, <span class="fu">c</span>(N, K2, tot))</span>
<span id="cb427-99"><a href="sec91.html#cb427-99" tabindex="-1"></a>PostTaus <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="dv">0</span>, tot, NT); RegLS <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> X <span class="sc">-</span> <span class="dv">1</span>)</span>
<span id="cb427-100"><a href="sec91.html#cb427-100" tabindex="-1"></a>SumLS <span class="ot">&lt;-</span> <span class="fu">summary</span>(RegLS)</span>
<span id="cb427-101"><a href="sec91.html#cb427-101" tabindex="-1"></a>Beta <span class="ot">&lt;-</span> SumLS[[<span class="st">&quot;coefficients&quot;</span>]][,<span class="dv">1</span>]</span>
<span id="cb427-102"><a href="sec91.html#cb427-102" tabindex="-1"></a>sig2 <span class="ot">&lt;-</span> SumLS[[<span class="st">&quot;sigma&quot;</span>]]<span class="sc">^</span><span class="dv">2</span>; D <span class="ot">&lt;-</span> <span class="fu">diag</span>(K2)</span>
<span id="cb427-103"><a href="sec91.html#cb427-103" tabindex="-1"></a>tau <span class="ot">&lt;-</span> <span class="fu">rgamma</span>(NT, <span class="at">shape =</span> v<span class="sc">/</span><span class="dv">2</span>, <span class="at">rate =</span> v<span class="sc">/</span><span class="dv">2</span>) </span>
<span id="cb427-104"><a href="sec91.html#cb427-104" tabindex="-1"></a>pb <span class="ot">&lt;-</span> <span class="fu">txtProgressBar</span>(<span class="at">min =</span> <span class="dv">0</span>, <span class="at">max =</span> tot, <span class="at">style =</span> <span class="dv">3</span>)</span></code></pre></div>
<pre><code>##   |                                                                              |                                                                      |   0%</code></pre>
<div class="sourceCode" id="cb429"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb429-1"><a href="sec91.html#cb429-1" tabindex="-1"></a><span class="cf">for</span>(s <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>tot){</span>
<span id="cb429-2"><a href="sec91.html#cb429-2" tabindex="-1"></a>    bs <span class="ot">&lt;-</span> <span class="fu">Postb</span>(<span class="at">Beta =</span> Beta, <span class="at">sig2 =</span> sig2, <span class="at">D =</span> D, <span class="at">tau =</span> tau)</span>
<span id="cb429-3"><a href="sec91.html#cb429-3" tabindex="-1"></a>    D <span class="ot">&lt;-</span> <span class="fu">PostD</span>(<span class="at">bs =</span> bs)</span>
<span id="cb429-4"><a href="sec91.html#cb429-4" tabindex="-1"></a>    Beta <span class="ot">&lt;-</span> <span class="fu">PostBeta</span>(<span class="at">sig2 =</span> sig2, <span class="at">D =</span> D, <span class="at">tau =</span> tau)</span>
<span id="cb429-5"><a href="sec91.html#cb429-5" tabindex="-1"></a>    sig2 <span class="ot">&lt;-</span> <span class="fu">PostSig2</span>(<span class="at">Beta =</span> Beta, <span class="at">bs =</span> bs, <span class="at">tau =</span> tau)</span>
<span id="cb429-6"><a href="sec91.html#cb429-6" tabindex="-1"></a>    tau <span class="ot">&lt;-</span> <span class="fu">PostTau</span>(<span class="at">sig2 =</span> sig2, <span class="at">Beta =</span> Beta, <span class="at">bs =</span> bs)</span>
<span id="cb429-7"><a href="sec91.html#cb429-7" tabindex="-1"></a>    PostBetas[s,] <span class="ot">&lt;-</span> Beta</span>
<span id="cb429-8"><a href="sec91.html#cb429-8" tabindex="-1"></a>    PostDs[s,] <span class="ot">&lt;-</span> matrixcalc<span class="sc">::</span><span class="fu">vech</span>(D)</span>
<span id="cb429-9"><a href="sec91.html#cb429-9" tabindex="-1"></a>    PostSig2s[s] <span class="ot">&lt;-</span> sig2</span>
<span id="cb429-10"><a href="sec91.html#cb429-10" tabindex="-1"></a>    Postbs[, , s] <span class="ot">&lt;-</span> bs</span>
<span id="cb429-11"><a href="sec91.html#cb429-11" tabindex="-1"></a>    PostTaus[s,] <span class="ot">&lt;-</span> tau</span>
<span id="cb429-12"><a href="sec91.html#cb429-12" tabindex="-1"></a>    <span class="fu">setTxtProgressBar</span>(pb, s)</span>
<span id="cb429-13"><a href="sec91.html#cb429-13" tabindex="-1"></a>}</span></code></pre></div>
<pre><code>##   |                                                                              |                                                                      |   1%  |                                                                              |=                                                                     |   1%  |                                                                              |=                                                                     |   2%  |                                                                              |==                                                                    |   2%  |                                                                              |==                                                                    |   3%  |                                                                              |==                                                                    |   4%  |                                                                              |===                                                                   |   4%  |                                                                              |===                                                                   |   5%  |                                                                              |====                                                                  |   5%  |                                                                              |====                                                                  |   6%  |                                                                              |=====                                                                 |   6%  |                                                                              |=====                                                                 |   7%  |                                                                              |=====                                                                 |   8%  |                                                                              |======                                                                |   8%  |                                                                              |======                                                                |   9%  |                                                                              |=======                                                               |   9%  |                                                                              |=======                                                               |  10%  |                                                                              |=======                                                               |  11%  |                                                                              |========                                                              |  11%  |                                                                              |========                                                              |  12%  |                                                                              |=========                                                             |  12%  |                                                                              |=========                                                             |  13%  |                                                                              |=========                                                             |  14%  |                                                                              |==========                                                            |  14%  |                                                                              |==========                                                            |  15%  |                                                                              |===========                                                           |  15%  |                                                                              |===========                                                           |  16%  |                                                                              |============                                                          |  16%  |                                                                              |============                                                          |  17%  |                                                                              |============                                                          |  18%  |                                                                              |=============                                                         |  18%  |                                                                              |=============                                                         |  19%  |                                                                              |==============                                                        |  19%  |                                                                              |==============                                                        |  20%  |                                                                              |==============                                                        |  21%  |                                                                              |===============                                                       |  21%  |                                                                              |===============                                                       |  22%  |                                                                              |================                                                      |  22%  |                                                                              |================                                                      |  23%  |                                                                              |================                                                      |  24%  |                                                                              |=================                                                     |  24%  |                                                                              |=================                                                     |  25%  |                                                                              |==================                                                    |  25%  |                                                                              |==================                                                    |  26%  |                                                                              |===================                                                   |  26%  |                                                                              |===================                                                   |  27%  |                                                                              |===================                                                   |  28%  |                                                                              |====================                                                  |  28%  |                                                                              |====================                                                  |  29%  |                                                                              |=====================                                                 |  29%  |                                                                              |=====================                                                 |  30%  |                                                                              |=====================                                                 |  31%  |                                                                              |======================                                                |  31%  |                                                                              |======================                                                |  32%  |                                                                              |=======================                                               |  32%  |                                                                              |=======================                                               |  33%  |                                                                              |=======================                                               |  34%  |                                                                              |========================                                              |  34%  |                                                                              |========================                                              |  35%  |                                                                              |=========================                                             |  35%  |                                                                              |=========================                                             |  36%  |                                                                              |==========================                                            |  36%  |                                                                              |==========================                                            |  37%  |                                                                              |==========================                                            |  38%  |                                                                              |===========================                                           |  38%  |                                                                              |===========================                                           |  39%  |                                                                              |============================                                          |  39%  |                                                                              |============================                                          |  40%  |                                                                              |============================                                          |  41%  |                                                                              |=============================                                         |  41%  |                                                                              |=============================                                         |  42%  |                                                                              |==============================                                        |  42%  |                                                                              |==============================                                        |  43%  |                                                                              |==============================                                        |  44%  |                                                                              |===============================                                       |  44%  |                                                                              |===============================                                       |  45%  |                                                                              |================================                                      |  45%  |                                                                              |================================                                      |  46%  |                                                                              |=================================                                     |  46%  |                                                                              |=================================                                     |  47%  |                                                                              |=================================                                     |  48%  |                                                                              |==================================                                    |  48%  |                                                                              |==================================                                    |  49%  |                                                                              |===================================                                   |  49%  |                                                                              |===================================                                   |  50%  |                                                                              |===================================                                   |  51%  |                                                                              |====================================                                  |  51%  |                                                                              |====================================                                  |  52%  |                                                                              |=====================================                                 |  52%  |                                                                              |=====================================                                 |  53%  |                                                                              |=====================================                                 |  54%  |                                                                              |======================================                                |  54%  |                                                                              |======================================                                |  55%  |                                                                              |=======================================                               |  55%  |                                                                              |=======================================                               |  56%  |                                                                              |========================================                              |  56%  |                                                                              |========================================                              |  57%  |                                                                              |========================================                              |  58%  |                                                                              |=========================================                             |  58%  |                                                                              |=========================================                             |  59%  |                                                                              |==========================================                            |  59%  |                                                                              |==========================================                            |  60%  |                                                                              |==========================================                            |  61%  |                                                                              |===========================================                           |  61%  |                                                                              |===========================================                           |  62%  |                                                                              |============================================                          |  62%  |                                                                              |============================================                          |  63%  |                                                                              |============================================                          |  64%  |                                                                              |=============================================                         |  64%  |                                                                              |=============================================                         |  65%  |                                                                              |==============================================                        |  65%  |                                                                              |==============================================                        |  66%  |                                                                              |===============================================                       |  66%  |                                                                              |===============================================                       |  67%  |                                                                              |===============================================                       |  68%  |                                                                              |================================================                      |  68%  |                                                                              |================================================                      |  69%  |                                                                              |=================================================                     |  69%  |                                                                              |=================================================                     |  70%  |                                                                              |=================================================                     |  71%  |                                                                              |==================================================                    |  71%  |                                                                              |==================================================                    |  72%  |                                                                              |===================================================                   |  72%  |                                                                              |===================================================                   |  73%  |                                                                              |===================================================                   |  74%  |                                                                              |====================================================                  |  74%  |                                                                              |====================================================                  |  75%  |                                                                              |=====================================================                 |  75%  |                                                                              |=====================================================                 |  76%  |                                                                              |======================================================                |  76%  |                                                                              |======================================================                |  77%  |                                                                              |======================================================                |  78%  |                                                                              |=======================================================               |  78%  |                                                                              |=======================================================               |  79%  |                                                                              |========================================================              |  79%  |                                                                              |========================================================              |  80%  |                                                                              |========================================================              |  81%  |                                                                              |=========================================================             |  81%  |                                                                              |=========================================================             |  82%  |                                                                              |==========================================================            |  82%  |                                                                              |==========================================================            |  83%  |                                                                              |==========================================================            |  84%  |                                                                              |===========================================================           |  84%  |                                                                              |===========================================================           |  85%  |                                                                              |============================================================          |  85%  |                                                                              |============================================================          |  86%  |                                                                              |=============================================================         |  86%  |                                                                              |=============================================================         |  87%  |                                                                              |=============================================================         |  88%  |                                                                              |==============================================================        |  88%  |                                                                              |==============================================================        |  89%  |                                                                              |===============================================================       |  89%  |                                                                              |===============================================================       |  90%  |                                                                              |===============================================================       |  91%  |                                                                              |================================================================      |  91%  |                                                                              |================================================================      |  92%  |                                                                              |=================================================================     |  92%  |                                                                              |=================================================================     |  93%  |                                                                              |=================================================================     |  94%  |                                                                              |==================================================================    |  94%  |                                                                              |==================================================================    |  95%  |                                                                              |===================================================================   |  95%  |                                                                              |===================================================================   |  96%  |                                                                              |====================================================================  |  96%  |                                                                              |====================================================================  |  97%  |                                                                              |====================================================================  |  98%  |                                                                              |===================================================================== |  98%  |                                                                              |===================================================================== |  99%  |                                                                              |======================================================================|  99%  |                                                                              |======================================================================| 100%</code></pre>
<div class="sourceCode" id="cb431"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb431-1"><a href="sec91.html#cb431-1" tabindex="-1"></a><span class="fu">close</span>(pb)</span></code></pre></div>
<div class="sourceCode" id="cb432"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb432-1"><a href="sec91.html#cb432-1" tabindex="-1"></a>keep <span class="ot">&lt;-</span> <span class="fu">seq</span>((burnin<span class="sc">+</span><span class="dv">1</span>), tot, thin)</span>
<span id="cb432-2"><a href="sec91.html#cb432-2" tabindex="-1"></a>Bs <span class="ot">&lt;-</span> PostBetas[keep,]; Ds <span class="ot">&lt;-</span> PostDs[keep,]</span>
<span id="cb432-3"><a href="sec91.html#cb432-3" tabindex="-1"></a>bs <span class="ot">&lt;-</span> Postbs[, , keep]; sig2s <span class="ot">&lt;-</span> PostSig2s[keep]</span>
<span id="cb432-4"><a href="sec91.html#cb432-4" tabindex="-1"></a>taus <span class="ot">&lt;-</span> PostTaus[keep,]</span>
<span id="cb432-5"><a href="sec91.html#cb432-5" tabindex="-1"></a><span class="fu">summary</span>(coda<span class="sc">::</span><span class="fu">mcmc</span>(Bs))</span></code></pre></div>
<pre><code>## 
## Iterations = 1:5000
## Thinning interval = 1 
## Number of chains = 1 
## Sample size per chain = 5000 
## 
## 1. Empirical mean and standard deviation for each variable,
##    plus standard error of the mean:
## 
##         Mean      SD  Naive SE Time-series SE
## [1,]  0.3215 0.12222 0.0017285      0.0017051
## [2,]  0.3697 0.01480 0.0002093      0.0001592
## [3,]  0.6254 0.01540 0.0002179      0.0001655
## [4,] -0.6068 0.01495 0.0002114      0.0001605
## 
## 2. Quantiles for each variable:
## 
##          2.5%     25%     50%     75%   97.5%
## var1  0.07833  0.2411  0.3231  0.4022  0.5614
## var2  0.34107  0.3598  0.3697  0.3794  0.3990
## var3  0.59625  0.6149  0.6252  0.6350  0.6571
## var4 -0.63694 -0.6166 -0.6067 -0.5967 -0.5780</code></pre>
<div class="sourceCode" id="cb434"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb434-1"><a href="sec91.html#cb434-1" tabindex="-1"></a><span class="fu">summary</span>(coda<span class="sc">::</span><span class="fu">mcmc</span>(Ds))</span></code></pre></div>
<pre><code>## 
## Iterations = 1:5000
## Thinning interval = 1 
## Number of chains = 1 
## Sample size per chain = 5000 
## 
## 1. Empirical mean and standard deviation for each variable,
##    plus standard error of the mean:
## 
##          Mean    SD Naive SE Time-series SE
## [1,]  0.70744 0.150 0.002121       0.002121
## [2,] -0.08456 0.091 0.001287       0.001315
## [3,]  0.54518 0.113 0.001599       0.001647
## 
## 2. Quantiles for each variable:
## 
##         2.5%     25%      50%      75%   97.5%
## var1  0.4720  0.5995  0.68855  0.79227 1.05358
## var2 -0.2722 -0.1405 -0.08183 -0.02477 0.09149
## var3  0.3689  0.4645  0.53005  0.60925 0.81983</code></pre>
<div class="sourceCode" id="cb436"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb436-1"><a href="sec91.html#cb436-1" tabindex="-1"></a><span class="fu">summary</span>(coda<span class="sc">::</span><span class="fu">mcmc</span>(sig2s))</span></code></pre></div>
<pre><code>## 
## Iterations = 1:5000
## Thinning interval = 1 
## Number of chains = 1 
## Sample size per chain = 5000 
## 
## 1. Empirical mean and standard deviation for each variable,
##    plus standard error of the mean:
## 
##           Mean             SD       Naive SE Time-series SE 
##      0.1531815      0.0592860      0.0008384      0.0014393 
## 
## 2. Quantiles for each variable:
## 
##   2.5%    25%    50%    75%  97.5% 
## 0.1022 0.1157 0.1324 0.1684 0.3222</code></pre>
<p>We can see that all the 95% credible intervals encompass the population parameters, except for the second <em>fixed effect</em> and the variance of the model, but both for a tiny margin.</p>
</div>
<h3>References<a href="references.html#references" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-Chib1999" class="csl-entry">
Chib, S., and B. Carlin. 1999. <span>“On <span>MCMC</span> Sampling in Hierarchical Longitudinal Models.”</span> <em>Statistics and Computing</em> 9: 17–26.
</div>
<div id="ref-Ramirez2017" class="csl-entry">
Ramírez Hassan, A. 2017. <span>“The Interplay Between the <span>B</span>ayesian and Frequentist Approaches: A General Nesting Spatial Panel Data Model.”</span> <em>Spatial Economic Analysis</em> 12 (1): 92–112.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="Chap9.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="sec92.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": true,
    "facebook": true,
    "twitter": true,
    "linkedin": false,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": false,
    "all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
  },
  "fontsettings": {
    "theme": "white",
    "family": "sans",
    "size": 2
  },
  "edit": {
    "link": "https://github.com/aramir21/IntroductionBayesianEconometricsBook/09-Longitudinal.Rmd",
    "text": "Edit"
  },
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": null,
    "text": null
  },
  "download": null,
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "subsection"
  }
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
