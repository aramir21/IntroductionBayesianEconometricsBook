<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>6.6 Ordered probit model | Introduction to Bayesian Data Modeling</title>
  <meta name="description" content="The subject of this textbook is Bayesian data modeling, with the primary aim of providing an introduction to its theoretical foundations and facilitating the application of Bayesian inference using a GUI." />
  <meta name="generator" content="bookdown 0.40 and GitBook 2.6.7" />

  <meta property="og:title" content="6.6 Ordered probit model | Introduction to Bayesian Data Modeling" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="The subject of this textbook is Bayesian data modeling, with the primary aim of providing an introduction to its theoretical foundations and facilitating the application of Bayesian inference using a GUI." />
  <meta name="github-repo" content="https://github.com/aramir21/IntroductionBayesianEconometricsBook" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="6.6 Ordered probit model | Introduction to Bayesian Data Modeling" />
  
  <meta name="twitter:description" content="The subject of this textbook is Bayesian data modeling, with the primary aim of providing an introduction to its theoretical foundations and facilitating the application of Bayesian inference using a GUI." />
  

<meta name="author" content="Andrés Ramírez-Hassan" />


<meta name="date" content="2025-02-18" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="sec65.html"/>
<link rel="next" href="negative-binomial-model.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Introduction to Bayesian Econometrics: A GUIded tour using R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction</a>
<ul>
<li class="chapter" data-level="" data-path="to-instructors-and-students.html"><a href="to-instructors-and-students.html"><i class="fa fa-check"></i>To instructors and students</a></li>
<li class="chapter" data-level="" data-path="acknowledgments.html"><a href="acknowledgments.html"><i class="fa fa-check"></i>Acknowledgments</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="Chap1.html"><a href="Chap1.html"><i class="fa fa-check"></i><b>1</b> Basic formal concepts</a>
<ul>
<li class="chapter" data-level="1.1" data-path="sec11.html"><a href="sec11.html"><i class="fa fa-check"></i><b>1.1</b> The Bayes’ rule</a></li>
<li class="chapter" data-level="1.2" data-path="sec12.html"><a href="sec12.html"><i class="fa fa-check"></i><b>1.2</b> Bayesian framework: A brief summary of theory</a></li>
<li class="chapter" data-level="1.3" data-path="sec14.html"><a href="sec14.html"><i class="fa fa-check"></i><b>1.3</b> Bayesian reports: Decision theory under uncertainty</a></li>
<li class="chapter" data-level="1.4" data-path="summary.html"><a href="summary.html"><i class="fa fa-check"></i><b>1.4</b> Summary</a></li>
<li class="chapter" data-level="1.5" data-path="exercises.html"><a href="exercises.html"><i class="fa fa-check"></i><b>1.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="Chap2.html"><a href="Chap2.html"><i class="fa fa-check"></i><b>2</b> Conceptual differences between the Bayesian and Frequentist approaches</a>
<ul>
<li class="chapter" data-level="2.1" data-path="sec21.html"><a href="sec21.html"><i class="fa fa-check"></i><b>2.1</b> The concept of probability</a></li>
<li class="chapter" data-level="2.2" data-path="sec22.html"><a href="sec22.html"><i class="fa fa-check"></i><b>2.2</b> Subjectivity is not the key</a></li>
<li class="chapter" data-level="2.3" data-path="sec23.html"><a href="sec23.html"><i class="fa fa-check"></i><b>2.3</b> Estimation, hypothesis testing and prediction</a></li>
<li class="chapter" data-level="2.4" data-path="sec24.html"><a href="sec24.html"><i class="fa fa-check"></i><b>2.4</b> The likelihood principle</a></li>
<li class="chapter" data-level="2.5" data-path="sec25.html"><a href="sec25.html"><i class="fa fa-check"></i><b>2.5</b> Why is not the Bayesian approach that popular?</a></li>
<li class="chapter" data-level="2.6" data-path="sec26.html"><a href="sec26.html"><i class="fa fa-check"></i><b>2.6</b> A simple working example</a></li>
<li class="chapter" data-level="2.7" data-path="sec27.html"><a href="sec27.html"><i class="fa fa-check"></i><b>2.7</b> Summary</a></li>
<li class="chapter" data-level="2.8" data-path="sec28.html"><a href="sec28.html"><i class="fa fa-check"></i><b>2.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="Chap3.html"><a href="Chap3.html"><i class="fa fa-check"></i><b>3</b> Cornerstone models: Conjugate families</a>
<ul>
<li class="chapter" data-level="3.1" data-path="sec41.html"><a href="sec41.html"><i class="fa fa-check"></i><b>3.1</b> Motivation of conjugate families</a></li>
<li class="chapter" data-level="3.2" data-path="sec42.html"><a href="sec42.html"><i class="fa fa-check"></i><b>3.2</b> Conjugate prior to exponential family</a></li>
<li class="chapter" data-level="3.3" data-path="sec43.html"><a href="sec43.html"><i class="fa fa-check"></i><b>3.3</b> Linear regression: The conjugate normal-normal/inverse gamma model</a></li>
<li class="chapter" data-level="3.4" data-path="multivariate-linear-regression-the-conjugate-normal-normalinverse-wishart-model.html"><a href="multivariate-linear-regression-the-conjugate-normal-normalinverse-wishart-model.html"><i class="fa fa-check"></i><b>3.4</b> Multivariate linear regression: The conjugate normal-normal/inverse Wishart model</a></li>
<li class="chapter" data-level="3.5" data-path="computational-examples.html"><a href="computational-examples.html"><i class="fa fa-check"></i><b>3.5</b> Computational examples</a></li>
<li class="chapter" data-level="3.6" data-path="summary-chapter-4.html"><a href="summary-chapter-4.html"><i class="fa fa-check"></i><b>3.6</b> Summary: Chapter 4</a></li>
<li class="chapter" data-level="3.7" data-path="exercises-chapter-4.html"><a href="exercises-chapter-4.html"><i class="fa fa-check"></i><b>3.7</b> Exercises: Chapter 4</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="Chap4.html"><a href="Chap4.html"><i class="fa fa-check"></i><b>4</b> Simulation methods</a>
<ul>
<li class="chapter" data-level="4.1" data-path="sec51.html"><a href="sec51.html"><i class="fa fa-check"></i><b>4.1</b> Markov Chain Monte Carlo methods</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="sec51.html"><a href="sec51.html#sec511"><i class="fa fa-check"></i><b>4.1.1</b> Gibbs sampler</a></li>
<li class="chapter" data-level="4.1.2" data-path="sec51.html"><a href="sec51.html#sec512"><i class="fa fa-check"></i><b>4.1.2</b> Metropolis-Hastings</a></li>
<li class="chapter" data-level="4.1.3" data-path="sec51.html"><a href="sec51.html#sec513"><i class="fa fa-check"></i><b>4.1.3</b> Hamiltonian Monte Carlo</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="sec52.html"><a href="sec52.html"><i class="fa fa-check"></i><b>4.2</b> Importance sampling</a></li>
<li class="chapter" data-level="4.3" data-path="sec53.html"><a href="sec53.html"><i class="fa fa-check"></i><b>4.3</b> Particle filtering</a></li>
<li class="chapter" data-level="4.4" data-path="sec54.html"><a href="sec54.html"><i class="fa fa-check"></i><b>4.4</b> Convergence diagnostics</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="sec54.html"><a href="sec54.html#numerical-standard-error"><i class="fa fa-check"></i><b>4.4.1</b> Numerical standard error</a></li>
<li class="chapter" data-level="4.4.2" data-path="sec54.html"><a href="sec54.html#effective-number-of-simulation-draws"><i class="fa fa-check"></i><b>4.4.2</b> Effective number of simulation draws</a></li>
<li class="chapter" data-level="4.4.3" data-path="sec54.html"><a href="sec54.html#tests-of-convergence"><i class="fa fa-check"></i><b>4.4.3</b> Tests of convergence</a></li>
<li class="chapter" data-level="4.4.4" data-path="sec54.html"><a href="sec54.html#checking-for-errors-in-the-posterior-simulator"><i class="fa fa-check"></i><b>4.4.4</b> Checking for errors in the posterior simulator</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="sec55.html"><a href="sec55.html"><i class="fa fa-check"></i><b>4.5</b> Summary</a></li>
<li class="chapter" data-level="4.6" data-path="sec56.html"><a href="sec56.html"><i class="fa fa-check"></i><b>4.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="Chap5.html"><a href="Chap5.html"><i class="fa fa-check"></i><b>5</b> Graphical user interface</a></li>
<li class="chapter" data-level="6" data-path="Chap6.html"><a href="Chap6.html"><i class="fa fa-check"></i><b>6</b> Univariate regression</a>
<ul>
<li class="chapter" data-level="6.1" data-path="sec61.html"><a href="sec61.html"><i class="fa fa-check"></i><b>6.1</b> The Gaussian linear model</a></li>
<li class="chapter" data-level="6.2" data-path="sec62.html"><a href="sec62.html"><i class="fa fa-check"></i><b>6.2</b> The logit model</a></li>
<li class="chapter" data-level="6.3" data-path="sec63.html"><a href="sec63.html"><i class="fa fa-check"></i><b>6.3</b> The probit model</a></li>
<li class="chapter" data-level="6.4" data-path="sec64.html"><a href="sec64.html"><i class="fa fa-check"></i><b>6.4</b> The multinomial probit model</a></li>
<li class="chapter" data-level="6.5" data-path="sec65.html"><a href="sec65.html"><i class="fa fa-check"></i><b>6.5</b> The multinomial logit model</a></li>
<li class="chapter" data-level="6.6" data-path="sec66.html"><a href="sec66.html"><i class="fa fa-check"></i><b>6.6</b> Ordered probit model</a></li>
<li class="chapter" data-level="6.7" data-path="negative-binomial-model.html"><a href="negative-binomial-model.html"><i class="fa fa-check"></i><b>6.7</b> Negative binomial model</a></li>
<li class="chapter" data-level="6.8" data-path="sec68.html"><a href="sec68.html"><i class="fa fa-check"></i><b>6.8</b> Tobit model</a></li>
<li class="chapter" data-level="6.9" data-path="sec69.html"><a href="sec69.html"><i class="fa fa-check"></i><b>6.9</b> Quantile regression</a></li>
<li class="chapter" data-level="6.10" data-path="sec610.html"><a href="sec610.html"><i class="fa fa-check"></i><b>6.10</b> Bayesian bootstrap regression</a></li>
<li class="chapter" data-level="6.11" data-path="sec611.html"><a href="sec611.html"><i class="fa fa-check"></i><b>6.11</b> Summary</a></li>
<li class="chapter" data-level="6.12" data-path="sec612.html"><a href="sec612.html"><i class="fa fa-check"></i><b>6.12</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="Chap8.html"><a href="Chap8.html"><i class="fa fa-check"></i><b>7</b> Time series</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to Bayesian Data Modeling</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="sec66" class="section level2 hasAnchor" number="6.6">
<h2><span class="header-section-number">6.6</span> Ordered probit model<a href="sec66.html#sec66" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The ordered probit model is used when there is a natural order in the categorical response variable. In this case, there is a latent variable <span class="math inline">\(y_i^* = \mathbf{x}_i^{\top}\boldsymbol{\beta} + \mu_i\)</span>, where <span class="math inline">\(\mathbf{x}_i\)</span> is a <span class="math inline">\(K\)</span>-dimensional vector of regressors, <span class="math inline">\(\mu_i \stackrel{i.i.d.}{\sim} N(0,1)\)</span>, such that <span class="math inline">\(y_i = l\)</span> if and only if <span class="math inline">\(\alpha_{l-1} &lt; y_i^* \leq \alpha_l\)</span>, for <span class="math inline">\(l \in \{1, 2, \dots, L\}\)</span>, where <span class="math inline">\(\alpha_0 = -\infty\)</span>, <span class="math inline">\(\alpha_1 = 0\)</span>, and <span class="math inline">\(\alpha_L = \infty\)</span>.<a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a> Then, the probability of observing <span class="math inline">\(y_i = l\)</span> is given by:</p>
<p><span class="math display">\[
p(y_i = l) = \Phi(\alpha_l - \mathbf{x}_i^{\top}\boldsymbol{\beta}) - \Phi(\alpha_{l-1} - \mathbf{x}_i^{\top}\boldsymbol{\beta}),
\]</span></p>
<p>and the likelihood function is:</p>
<p><span class="math display">\[
p(\boldsymbol{\beta}, \boldsymbol{\alpha} \mid \mathbf{y}, \mathbf{X}) = \prod_{i=1}^{N} p(y_i = l \mid \boldsymbol{\beta}, \boldsymbol{\alpha}, \mathbf{X}).
\]</span></p>
<p>The priors in this model are independent, i.e., <span class="math inline">\(\pi(\boldsymbol{\beta}, \boldsymbol{\gamma}) = \pi(\boldsymbol{\beta}) \times \pi(\boldsymbol{\gamma})\)</span>, where <span class="math inline">\(\boldsymbol{\beta} \sim N(\boldsymbol{\beta}_0, \boldsymbol{B}_0)\)</span> and <span class="math inline">\(\boldsymbol{\gamma} \sim N(\boldsymbol{\gamma}_0, \boldsymbol{\Gamma}_0)\)</span>, and <span class="math inline">\(\boldsymbol{\gamma} = \left[ \gamma_2 \ \gamma_3 \ \dots \ \gamma_{L-1} \right]^{\top}\)</span>, such that:</p>
<p><span class="math display">\[
\boldsymbol{\alpha} = \left[ \exp\left\{\gamma_2\right\} \ \sum_{l=2}^{3} \exp\left\{\gamma_l\right\} \ \dots \ \sum_{l=2}^{L-1} \exp\left\{\gamma_l\right\} \right]^{\top}.
\]</span></p>
<p>This structure imposes the ordinal condition on the cut-offs.</p>
<p>This model does not have a standard conditional posterior distribution for <span class="math inline">\(\boldsymbol{\gamma}\)</span> (<span class="math inline">\(\boldsymbol{\alpha}\)</span>), but it does have a standard conditional distribution for <span class="math inline">\(\boldsymbol{\beta}\)</span> once data augmentation is used. We can then use a Metropolis-within-Gibbs sampling algorithm. In particular, we use Gibbs sampling to draw <span class="math inline">\(\boldsymbol{\beta}\)</span> and <span class="math inline">\(\boldsymbol{y}^*\)</span>, where:</p>
<p><span class="math display">\[
\boldsymbol{\beta} \mid \boldsymbol{y}^*, \boldsymbol{\alpha}, \boldsymbol{X} \sim N(\boldsymbol{\beta}_n, \boldsymbol{B}_n),
\]</span></p>
<p>with <span class="math inline">\(\boldsymbol{B}_n = (\boldsymbol{B}_0^{-1} + \boldsymbol{X}^{\top}\boldsymbol{X})^{-1}\)</span>, <span class="math inline">\(\boldsymbol{\beta}_n = \boldsymbol{B}_n(\boldsymbol{B}_0^{-1}\boldsymbol{\beta}_0 + \boldsymbol{X}^{\top}\boldsymbol{y}^*)\)</span>, and:</p>
<p><span class="math display">\[
y_i^* \mid \boldsymbol{\beta}, \boldsymbol{\alpha}, \boldsymbol{y}, \boldsymbol{X} \sim TN_{(\alpha_{y_i-1}, \alpha_{y_i})}(\boldsymbol{x}_i^{\top}\boldsymbol{\beta}, 1).
\]</span></p>
<p>We use a random-walk Metropolis–Hastings algorithm for <span class="math inline">\(\boldsymbol{\gamma}\)</span> with a proposal distribution that is Gaussian with mean equal to the current value and covariance matrix <span class="math inline">\(s^2(\boldsymbol{\Gamma}_0^{-1} + \hat{\boldsymbol{\Sigma}}_{\gamma}^{-1})^{-1}\)</span>, where <span class="math inline">\(s &gt; 0\)</span> is a tuning parameter and <span class="math inline">\(\hat{\boldsymbol{\Sigma}}_{\gamma}\)</span> is the sample covariance matrix associated with <span class="math inline">\(\gamma\)</span> from the maximum likelihood estimation.</p>
<p><strong>Example: Determinants of preventive health care visits</strong></p>
<p>We used the file named <em>2HealthMed.csv</em> in this application. In particular, the dependent variable is <em>MedVisPrevOr</em>, which is an ordered variable equal to 1 if the individual did not visit a physician for preventive reasons, 2 if the individual visited once in that year, and so on, until it is equal to 6 for visiting five or more times. The latter category represents 1.6% of the sample. Observe that the dependent variable has six categories.</p>
<p>In this example, the set of regressors is given by <em>SHI</em>, which is an indicator of being in the subsidized health care system (1 means being in the system), sex (<em>Female</em>), age (both linear and squared), socioeconomic conditions indicator (<em>Est2</em> and <em>Est3</em>), with the lowest being the baseline category, self-perception of health status (<em>Fair</em>, <em>Good</em>, and <em>Excellent</em>), where <em>Bad</em> is the baseline, and education level (<em>PriEd</em>, <em>HighEd</em>, <em>VocEd</em>, <em>UnivEd</em>), with <em>no education</em> as the baseline category.</p>
<p>We ran this application with 50,000 MCMC iterations plus 10,000 as burn-in, and a thinning parameter equal to 5. This setting means 10,000 effective posterior draws. We set <span class="math inline">\(\boldsymbol{\beta}_0 = \boldsymbol{0}_{11}\)</span>, <span class="math inline">\(\boldsymbol{B}_0 = 1000\boldsymbol{I}_{11}\)</span>, <span class="math inline">\(\boldsymbol{\gamma}_0 = \boldsymbol{0}_4\)</span>, <span class="math inline">\(\boldsymbol{\Gamma}_0 = \boldsymbol{I}_4\)</span>, and the tuning parameter is 1.</p>
<p>We can run the ordered probit models in our GUI following the steps in the next Algorithm.</p>
<div class="algorithm">
<div style="background-color: #f8f9fa; padding: 15px; border-left: 5px solid #343a40; box-shadow: 4px 4px 10px rgba(0, 0, 0, 0.1); border-radius: 5px;">
<p><strong>Algorithm: Ordered probit models</strong></p>
<ol style="list-style-type: decimal">
<li>Select <em>Univariate Models</em> on the top panel<br />
</li>
<li>Select <em>Ordered Probit</em> model using the left radio button<br />
</li>
<li>Upload the dataset by first selecting whether there is a header in the file, and the kind of separator in the <em>csv</em> file of the dataset (comma, semicolon, or tab). Then, use the <em>Browse</em> button under the <strong>Choose File</strong> legend. You should see a preview of the dataset<br />
</li>
<li>Select MCMC iterations, burn-in, and thinning parameters using the <em>Range sliders</em><br />
</li>
<li>Select dependent and independent variables using the <em>Formula builder</em> table<br />
</li>
<li>Click the <em>Build formula</em> button to generate the formula in <strong>R</strong> syntax. Remember that this formula must have -1 to omit the intercept in the specification.<br />
</li>
<li>Set the hyperparameters: mean vectors and covariance matrices. This step is not necessary as by default our GUI uses non-informative priors</li>
<li>Select the number of ordered alternatives</li>
<li>Set the hyperparameters: mean and covariance matrix of the cutoffs. This step is not necessary as by default our GUI uses non-informative prior</li>
<li>Select the tuning parameter for the Metropolis-Hastings algorithm<br />
</li>
<li>Click the <em>Go!</em> button<br />
</li>
<li>Analyze results<br />
</li>
<li>Download posterior chains and diagnostic plots using the <em>Download Posterior Chains</em> and <em>Download Posterior Graphs</em> buttons</li>
</ol>
</div>
</div>
<p>The following <strong>R</strong> code shows how to perform inference in this model using the command <em>rordprobitGibbs</em> from the <em>bayesm</em> library, which is the command that our GUI uses.</p>
<div class="sourceCode" id="cb35"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb35-1"><a href="sec66.html#cb35-1" tabindex="-1"></a><span class="fu">rm</span>(<span class="at">list =</span> <span class="fu">ls</span>())</span>
<span id="cb35-2"><a href="sec66.html#cb35-2" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">010101</span>)</span>
<span id="cb35-3"><a href="sec66.html#cb35-3" tabindex="-1"></a>Data <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">&quot;https://raw.githubusercontent.com/besmarter/BSTApp/refs/heads/master/DataApp/2HealthMed.csv&quot;</span>, <span class="at">sep =</span> <span class="st">&quot;,&quot;</span>, <span class="at">header =</span> <span class="cn">TRUE</span>, <span class="at">quote =</span> <span class="st">&quot;&quot;</span>)</span>
<span id="cb35-4"><a href="sec66.html#cb35-4" tabindex="-1"></a><span class="fu">attach</span>(Data)</span></code></pre></div>
<pre><code>## The following objects are masked from mydata:
## 
##     Age, Age2, Bad, Est1, Est2, Est3, Excellent, Fair, Female,
##     FemaleAge, Good, HighEd, Hosp, id, MedVisPrev, MedVisPrevOr, NoEd,
##     PriEd, PTL, SHI, UnivEd, VocEd</code></pre>
<pre><code>## The following objects are masked from Data (pos = 4):
## 
##     Age, Age2</code></pre>
<div class="sourceCode" id="cb38"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb38-1"><a href="sec66.html#cb38-1" tabindex="-1"></a>y <span class="ot">&lt;-</span> MedVisPrevOr </span>
<span id="cb38-2"><a href="sec66.html#cb38-2" tabindex="-1"></a><span class="co"># MedVisPrevOr: Oredered variable for preventive visits to doctors in one year: 1 (none), 2 (once), ... 6 (five or more)</span></span>
<span id="cb38-3"><a href="sec66.html#cb38-3" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">cbind</span>(SHI, Female, Age, Age2, Est2, Est3, Fair, Good, Excellent, PriEd, HighEd, VocEd, UnivEd)</span>
<span id="cb38-4"><a href="sec66.html#cb38-4" tabindex="-1"></a>k <span class="ot">&lt;-</span> <span class="fu">dim</span>(X)[<span class="dv">2</span>]</span>
<span id="cb38-5"><a href="sec66.html#cb38-5" tabindex="-1"></a>L <span class="ot">&lt;-</span> <span class="fu">length</span>(<span class="fu">table</span>(y))</span>
<span id="cb38-6"><a href="sec66.html#cb38-6" tabindex="-1"></a><span class="co"># Hyperparameters</span></span>
<span id="cb38-7"><a href="sec66.html#cb38-7" tabindex="-1"></a>b0 <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">0</span>, k); c0 <span class="ot">&lt;-</span> <span class="dv">1000</span>; B0 <span class="ot">&lt;-</span> c0<span class="sc">*</span><span class="fu">diag</span>(k)</span>
<span id="cb38-8"><a href="sec66.html#cb38-8" tabindex="-1"></a>gamma0 <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">0</span>, L<span class="dv">-2</span>); Gamma0 <span class="ot">&lt;-</span> <span class="fu">diag</span>(L<span class="dv">-2</span>)</span>
<span id="cb38-9"><a href="sec66.html#cb38-9" tabindex="-1"></a><span class="co"># MCMC parameters</span></span>
<span id="cb38-10"><a href="sec66.html#cb38-10" tabindex="-1"></a>mcmc <span class="ot">&lt;-</span> <span class="dv">60000</span><span class="sc">+</span><span class="dv">1</span>; thin <span class="ot">&lt;-</span> <span class="dv">5</span>; tuningPar <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">/</span>(L<span class="dv">-2</span>)<span class="sc">^</span><span class="fl">0.5</span></span>
<span id="cb38-11"><a href="sec66.html#cb38-11" tabindex="-1"></a>DataApp <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">y =</span> y, <span class="at">X =</span> X, <span class="at">k =</span> L)</span>
<span id="cb38-12"><a href="sec66.html#cb38-12" tabindex="-1"></a>Prior <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">betabar =</span> b0, <span class="at">A =</span> <span class="fu">solve</span>(B0), <span class="at">dstarbar =</span> gamma0, <span class="at">Ad =</span> Gamma0)</span>
<span id="cb38-13"><a href="sec66.html#cb38-13" tabindex="-1"></a>mcmcpar <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">R =</span> mcmc, <span class="at">keep =</span> <span class="dv">5</span>, <span class="at">s =</span> tuningPar, <span class="at">nprint =</span> <span class="dv">0</span>)</span>
<span id="cb38-14"><a href="sec66.html#cb38-14" tabindex="-1"></a>PostBeta <span class="ot">&lt;-</span> bayesm<span class="sc">::</span><span class="fu">rordprobitGibbs</span>(<span class="at">Data =</span> DataApp, <span class="at">Prior =</span> Prior, <span class="at">Mcmc =</span> mcmcpar)</span></code></pre></div>
<pre><code>##  
## Starting Gibbs Sampler for Ordered Probit Model
##    with  12975 observations
##  
## Table of y values
## y
##    1    2    3    4    5    6 
## 1935 2837 1241 2043 4711  208 
##  
## Prior Parms: 
## betabar
##  [1] 0 0 0 0 0 0 0 0 0 0 0 0 0
##  
## A
##        [,1]  [,2]  [,3]  [,4]  [,5]  [,6]  [,7]  [,8]  [,9] [,10] [,11] [,12]
##  [1,] 0.001 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000
##  [2,] 0.000 0.001 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000
##  [3,] 0.000 0.000 0.001 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000
##  [4,] 0.000 0.000 0.000 0.001 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000
##  [5,] 0.000 0.000 0.000 0.000 0.001 0.000 0.000 0.000 0.000 0.000 0.000 0.000
##  [6,] 0.000 0.000 0.000 0.000 0.000 0.001 0.000 0.000 0.000 0.000 0.000 0.000
##  [7,] 0.000 0.000 0.000 0.000 0.000 0.000 0.001 0.000 0.000 0.000 0.000 0.000
##  [8,] 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.001 0.000 0.000 0.000 0.000
##  [9,] 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.001 0.000 0.000 0.000
## [10,] 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.001 0.000 0.000
## [11,] 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.001 0.000
## [12,] 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.001
## [13,] 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000
##       [,13]
##  [1,] 0.000
##  [2,] 0.000
##  [3,] 0.000
##  [4,] 0.000
##  [5,] 0.000
##  [6,] 0.000
##  [7,] 0.000
##  [8,] 0.000
##  [9,] 0.000
## [10,] 0.000
## [11,] 0.000
## [12,] 0.000
## [13,] 0.001
##  
## dstarbar
## [1] 0 0 0 0
##  
## Ad
##      [,1] [,2] [,3] [,4]
## [1,]    1    0    0    0
## [2,]    0    1    0    0
## [3,]    0    0    1    0
## [4,]    0    0    0    1
##  
## MCMC parms: 
## R=  60001  keep=  5  nprint=  0 s=  0.5
## </code></pre>
<div class="sourceCode" id="cb40"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb40-1"><a href="sec66.html#cb40-1" tabindex="-1"></a>BetasPost <span class="ot">&lt;-</span> coda<span class="sc">::</span><span class="fu">mcmc</span>(PostBeta[[<span class="st">&quot;betadraw&quot;</span>]])</span>
<span id="cb40-2"><a href="sec66.html#cb40-2" tabindex="-1"></a><span class="fu">colnames</span>(BetasPost) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;SHI&quot;</span>, <span class="st">&quot;Female&quot;</span>, <span class="st">&quot;Age&quot;</span>, <span class="st">&quot;Age2&quot;</span>, <span class="st">&quot;Est2&quot;</span>, <span class="st">&quot;Est3&quot;</span>, <span class="st">&quot;Fair&quot;</span>, <span class="st">&quot;Good&quot;</span>, <span class="st">&quot;Excellent&quot;</span>, <span class="st">&quot;PriEd&quot;</span>, <span class="st">&quot;HighEd&quot;</span>, <span class="st">&quot;VocEd&quot;</span>, <span class="st">&quot;UnivEd&quot;</span>)</span>
<span id="cb40-3"><a href="sec66.html#cb40-3" tabindex="-1"></a><span class="fu">summary</span>(BetasPost)      </span></code></pre></div>
<pre><code>## 
## Iterations = 1:12000
## Thinning interval = 1 
## Number of chains = 1 
## Sample size per chain = 12000 
## 
## 1. Empirical mean and standard deviation for each variable,
##    plus standard error of the mean:
## 
##                 Mean        SD  Naive SE Time-series SE
## SHI        0.0654824 2.281e-02 2.082e-04      3.357e-04
## Female    -0.0374788 1.908e-02 1.742e-04      1.742e-04
## Age        0.0190336 1.869e-03 1.706e-05      4.576e-05
## Age2      -0.0002328 2.438e-05 2.225e-07      6.690e-07
## Est2       0.0949445 2.226e-02 2.032e-04      4.659e-04
## Est3      -0.1383965 3.411e-02 3.114e-04      3.459e-04
## Fair       0.6451828 5.375e-02 4.907e-04      3.924e-03
## Good       0.7343932 4.955e-02 4.523e-04      4.491e-03
## Excellent  0.9826531 6.393e-02 5.836e-04      5.261e-03
## PriEd      0.0309418 2.376e-02 2.169e-04      2.221e-04
## HighEd    -0.1805753 2.910e-02 2.656e-04      3.456e-04
## VocEd      0.1395760 9.640e-02 8.800e-04      9.291e-04
## UnivEd    -0.2218120 1.189e-01 1.086e-03      1.086e-03
## 
## 2. Quantiles for each variable:
## 
##                 2.5%        25%        50%        75%      97.5%
## SHI        0.0209045  0.0499525  0.0654041  0.0808572  0.1102130
## Female    -0.0746364 -0.0504288 -0.0377778 -0.0245643  0.0002350
## Age        0.0155088  0.0178114  0.0190228  0.0202305  0.0226864
## Age2      -0.0002804 -0.0002479 -0.0002328 -0.0002168 -0.0001864
## Est2       0.0514963  0.0800442  0.0948246  0.1096800  0.1393326
## Est3      -0.2055927 -0.1614479 -0.1381575 -0.1156348 -0.0717986
## Fair       0.5579955  0.6129584  0.6414878  0.6726800  0.7439563
## Good       0.6669005  0.7080863  0.7303217  0.7540621  0.8106430
## Excellent  0.8891998  0.9477048  0.9783661  1.0102615  1.0846084
## PriEd     -0.0158405  0.0149388  0.0310167  0.0471892  0.0773202
## HighEd    -0.2378212 -0.2003574 -0.1802174 -0.1607329 -0.1243538
## VocEd     -0.0491123  0.0747424  0.1381100  0.2041479  0.3333107
## UnivEd    -0.4538119 -0.3023902 -0.2219313 -0.1414801  0.0086323</code></pre>
<div class="sourceCode" id="cb42"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb42-1"><a href="sec66.html#cb42-1" tabindex="-1"></a><span class="co"># Convergence diagnostics</span></span>
<span id="cb42-2"><a href="sec66.html#cb42-2" tabindex="-1"></a>coda<span class="sc">::</span><span class="fu">geweke.diag</span>(BetasPost)</span></code></pre></div>
<pre><code>## 
## Fraction in 1st window = 0.1
## Fraction in 2nd window = 0.5 
## 
##       SHI    Female       Age      Age2      Est2      Est3      Fair      Good 
##    1.9824    0.1488    1.6564   -1.5988    0.9782   -1.9159    1.2891    1.2890 
## Excellent     PriEd    HighEd     VocEd    UnivEd 
##    1.3675    2.2458   -1.3570    1.0199   -0.6709</code></pre>
<div class="sourceCode" id="cb44"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb44-1"><a href="sec66.html#cb44-1" tabindex="-1"></a>coda<span class="sc">::</span><span class="fu">raftery.diag</span>(BetasPost,<span class="at">q=</span><span class="fl">0.5</span>,<span class="at">r=</span><span class="fl">0.05</span>,<span class="at">s =</span> <span class="fl">0.95</span>)</span></code></pre></div>
<pre><code>## 
## Quantile (q) = 0.5
## Accuracy (r) = +/- 0.05
## Probability (s) = 0.95 
##                                                  
##            Burn-in  Total Lower bound  Dependence
##            (M)      (N)   (Nmin)       factor (I)
##  SHI       2        393   385          1.020     
##  Female    2        382   385          0.992     
##  Age       2        401   385          1.040     
##  Age2      2        399   385          1.040     
##  Est2      2        409   385          1.060     
##  Est3      1        385   385          1.000     
##  Fair      6        1227  385          3.190     
##  Good      12       1792  385          4.650     
##  Excellent 6        1233  385          3.200     
##  PriEd     2        392   385          1.020     
##  HighEd    2        392   385          1.020     
##  VocEd     2        390   385          1.010     
##  UnivEd    2        393   385          1.020</code></pre>
<div class="sourceCode" id="cb46"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb46-1"><a href="sec66.html#cb46-1" tabindex="-1"></a>coda<span class="sc">::</span><span class="fu">heidel.diag</span>(BetasPost)</span></code></pre></div>
<pre><code>##                                         
##           Stationarity start     p-value
##           test         iteration        
## SHI       passed       1201      0.8026 
## Female    passed          1      0.5041 
## Age       passed       1201      0.0812 
## Age2      passed       1201      0.0928 
## Est2      passed       1201      0.1970 
## Est3      passed       1201      0.4047 
## Fair      failed         NA      0.0360 
## Good      failed         NA      0.0156 
## Excellent failed         NA      0.0403 
## PriEd     passed          1      0.1479 
## HighEd    passed       1201      0.0870 
## VocEd     passed          1      0.5223 
## UnivEd    passed          1      0.6614 
##                                        
##           Halfwidth Mean      Halfwidth
##           test                         
## SHI       passed     0.065098 4.19e-04 
## Female    passed    -0.037479 3.41e-04 
## Age       passed     0.018970 3.38e-05 
## Age2      passed    -0.000232 4.40e-07 
## Est2      passed     0.094472 4.10e-04 
## Est3      passed    -0.138067 6.42e-04 
## Fair      &lt;NA&gt;             NA       NA 
## Good      &lt;NA&gt;             NA       NA 
## Excellent &lt;NA&gt;             NA       NA 
## PriEd     passed     0.030942 4.35e-04 
## HighEd    passed    -0.180255 5.47e-04 
## VocEd     passed     0.139576 1.82e-03 
## UnivEd    passed    -0.221812 2.13e-03</code></pre>
<div class="sourceCode" id="cb48"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb48-1"><a href="sec66.html#cb48-1" tabindex="-1"></a><span class="co"># Cut offs</span></span>
<span id="cb48-2"><a href="sec66.html#cb48-2" tabindex="-1"></a>Cutoffs <span class="ot">&lt;-</span> PostBeta[[<span class="st">&quot;cutdraw&quot;</span>]]</span>
<span id="cb48-3"><a href="sec66.html#cb48-3" tabindex="-1"></a><span class="fu">summary</span>(Cutoffs)</span></code></pre></div>
<pre><code>## Summary of Posterior Marginal Distributions 
## Moments 
##   mean std dev   num se rel eff sam size
## 1 0.00   0.000 -1.0e+04   -9999    -9999
## 2 0.71   0.013  1.3e-03     108       99
## 3 0.96   0.014  1.3e-03      96      112
## 4 1.37   0.015  1.3e-03      85      127
## 5 3.20   0.030  1.8e-03      38      277
## 
## Quantiles 
##   2.5%   5%  50%  95% 97.5%
## 1 0.00 0.00 0.00 0.00  0.00
## 2 0.68 0.69 0.71 0.73  0.73
## 3 0.93 0.94 0.96 0.98  0.98
## 4 1.33 1.34 1.37 1.39  1.39
## 5 3.14 3.15 3.20 3.25  3.26
##    based on 10800 valid draws (burn-in=1200)</code></pre>
<div class="sourceCode" id="cb50"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb50-1"><a href="sec66.html#cb50-1" tabindex="-1"></a>coda<span class="sc">::</span><span class="fu">geweke.diag</span>(Cutoffs)</span></code></pre></div>
<pre><code>## 
## Fraction in 1st window = 0.1
## Fraction in 2nd window = 0.5 
## 
##   var1   var2   var3   var4   var5 
##    NaN 0.5305 1.2222 1.2512 1.6850</code></pre>
<div class="sourceCode" id="cb52"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb52-1"><a href="sec66.html#cb52-1" tabindex="-1"></a>coda<span class="sc">::</span><span class="fu">heidel.diag</span>(Cutoffs)</span></code></pre></div>
<pre><code>##                                    
##      Stationarity start     p-value
##      test         iteration        
## [,1] failed         NA          NA 
## [,2] passed       1201      0.2060 
## [,3] passed       1201      0.1192 
## [,4] passed       1201      0.1004 
## [,5] passed       1201      0.0681 
##                              
##      Halfwidth Mean Halfwidth
##      test                    
## [,1] &lt;NA&gt;        NA      NA  
## [,2] passed    0.71 0.00399  
## [,3] passed    0.96 0.00349  
## [,4] passed    1.37 0.00300  
## [,5] passed    3.20 0.00295</code></pre>
<div class="sourceCode" id="cb54"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb54-1"><a href="sec66.html#cb54-1" tabindex="-1"></a>coda<span class="sc">::</span><span class="fu">raftery.diag</span>(Cutoffs[,<span class="sc">-</span><span class="dv">1</span>],<span class="at">q=</span><span class="fl">0.5</span>,<span class="at">r=</span><span class="fl">0.05</span>,<span class="at">s =</span> <span class="fl">0.95</span>)</span></code></pre></div>
<pre><code>## 
## Quantile (q) = 0.5
## Accuracy (r) = +/- 0.05
## Probability (s) = 0.95 
##                                        
##  Burn-in  Total Lower bound  Dependence
##  (M)      (N)   (Nmin)       factor (I)
##  390      49320 385          128.0     
##  340      43214 385          112.0     
##  224      28504 385           74.0     
##  64       7432  385           19.3</code></pre>
<p>The results suggest that older individuals (at a decreasing rate) in the subsidized health program, characterized by being in the second socioeconomic status, with an increasing self-perception of good health, and not having high school as their highest education degree, have a higher probability of visiting a physician for preventive health purposes. Convergence diagnostics look well, except for the self-health perception draws.</p>
<p>We also obtained the posterior estimates of the cutoffs in the ordered probit model. These estimates are necessary to calculate the probability that an individual is in a specific category of physician visits. Due to identification restrictions, the first cutoff is set equal to 0. This is why we observe <em>NaN</em> values in <span class="citation">Geweke (<a href="#ref-Geweke1992">1992</a>)</span> and <span class="citation">Heidelberger and Welch (<a href="#ref-Heidelberger1983">1983</a>)</span> tests, and only four values in the <span class="citation">Raftery and Lewis (<a href="#ref-Raftery1992">1992</a>)</span> test, which correspond to the remaining free cutoffs. It seems that these cutoff estimates have some convergence issues when using the <span class="citation">Raftery and Lewis (<a href="#ref-Raftery1992">1992</a>)</span> test as a diagnostic tool. Furthermore, their dependence factors are also very high.</p>
</div>
<h3>References<a href="references.html#references" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Geweke1992" class="csl-entry">
Geweke, J. 1992. <span>“Bayesian Statistics.”</span> In. Clarendon Press, Oxford, UK.
</div>
<div id="ref-Heidelberger1983" class="csl-entry">
Heidelberger, P., and P. D. Welch. 1983. <span>“Simulation Run Length Control in the Presence of an Initial Transient.”</span> <em>Operations Research</em> 31 (6): 1109–44.
</div>
<div id="ref-Raftery1992" class="csl-entry">
Raftery, A. E., and S. M. Lewis. 1992. <span>“One Long Run with Diagnostics: Implementation Strategies for <span>M</span>arkov Chain <span>M</span>onte <span>C</span>arlo.”</span> <em>Statistical Science</em> 7: 493–97.
</div>
</div>
<div class="footnotes">
<hr />
<ol start="6">
<li id="fn6"><p>Identification issues necessitate setting the variance in this model equal to 1 and <span class="math inline">\(\alpha_1 = 0\)</span>. Observe that multiplying <span class="math inline">\(y_i^*\)</span> by a positive constant or adding a constant to all of the cut-offs and subtracting the same constant from the intercept does not affect <span class="math inline">\(y_i\)</span>.<a href="sec66.html#fnref6" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="sec65.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="negative-binomial-model.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/aramir21/IntroductionBayesianEconometricsBook/06-Univariatereg.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
