<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>7.4 Multivariate probit model | Introduction to Bayesian Econometrics</title>
  <meta name="description" content="The subject of this textbook is Bayesian data modeling, with the primary aim of providing an introduction to its theoretical foundations and facilitating the application of Bayesian inference using a GUI." />
  <meta name="generator" content="bookdown 0.43 and GitBook 2.6.7" />

  <meta property="og:title" content="7.4 Multivariate probit model | Introduction to Bayesian Econometrics" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="The subject of this textbook is Bayesian data modeling, with the primary aim of providing an introduction to its theoretical foundations and facilitating the application of Bayesian inference using a GUI." />
  <meta name="github-repo" content="https://github.com/aramir21/IntroductionBayesianEconometricsBook" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="7.4 Multivariate probit model | Introduction to Bayesian Econometrics" />
  
  <meta name="twitter:description" content="The subject of this textbook is Bayesian data modeling, with the primary aim of providing an introduction to its theoretical foundations and facilitating the application of Bayesian inference using a GUI." />
  

<meta name="author" content="Andrés Ramírez-Hassan" />


<meta name="date" content="2025-07-21" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="sec73.html"/>
<link rel="next" href="sec75.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Introduction to Bayesian Econometrics: A GUIded tour using R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction</a>
<ul>
<li class="chapter" data-level="" data-path="to-instructors-and-students.html"><a href="to-instructors-and-students.html"><i class="fa fa-check"></i>To instructors and students</a></li>
<li class="chapter" data-level="" data-path="acknowledgments.html"><a href="acknowledgments.html"><i class="fa fa-check"></i>Acknowledgments</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="Chap1.html"><a href="Chap1.html"><i class="fa fa-check"></i><b>1</b> Basic formal concepts</a>
<ul>
<li class="chapter" data-level="1.1" data-path="sec11.html"><a href="sec11.html"><i class="fa fa-check"></i><b>1.1</b> The Bayes’ rule</a></li>
<li class="chapter" data-level="1.2" data-path="sec12.html"><a href="sec12.html"><i class="fa fa-check"></i><b>1.2</b> Bayesian framework: A brief summary of theory</a></li>
<li class="chapter" data-level="1.3" data-path="sec14.html"><a href="sec14.html"><i class="fa fa-check"></i><b>1.3</b> Bayesian reports: Decision theory under uncertainty</a></li>
<li class="chapter" data-level="1.4" data-path="summary.html"><a href="summary.html"><i class="fa fa-check"></i><b>1.4</b> Summary</a></li>
<li class="chapter" data-level="1.5" data-path="exercises.html"><a href="exercises.html"><i class="fa fa-check"></i><b>1.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="Chap2.html"><a href="Chap2.html"><i class="fa fa-check"></i><b>2</b> Conceptual differences between the Bayesian and Frequentist approaches</a>
<ul>
<li class="chapter" data-level="2.1" data-path="sec21.html"><a href="sec21.html"><i class="fa fa-check"></i><b>2.1</b> The concept of probability</a></li>
<li class="chapter" data-level="2.2" data-path="sec22.html"><a href="sec22.html"><i class="fa fa-check"></i><b>2.2</b> Subjectivity is not the key</a></li>
<li class="chapter" data-level="2.3" data-path="sec23.html"><a href="sec23.html"><i class="fa fa-check"></i><b>2.3</b> Estimation, hypothesis testing and prediction</a></li>
<li class="chapter" data-level="2.4" data-path="sec24.html"><a href="sec24.html"><i class="fa fa-check"></i><b>2.4</b> The likelihood principle</a></li>
<li class="chapter" data-level="2.5" data-path="sec25.html"><a href="sec25.html"><i class="fa fa-check"></i><b>2.5</b> Why is not the Bayesian approach that popular?</a></li>
<li class="chapter" data-level="2.6" data-path="sec26.html"><a href="sec26.html"><i class="fa fa-check"></i><b>2.6</b> A simple working example</a></li>
<li class="chapter" data-level="2.7" data-path="sec27.html"><a href="sec27.html"><i class="fa fa-check"></i><b>2.7</b> Summary</a></li>
<li class="chapter" data-level="2.8" data-path="sec28.html"><a href="sec28.html"><i class="fa fa-check"></i><b>2.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="Chap3.html"><a href="Chap3.html"><i class="fa fa-check"></i><b>3</b> Cornerstone models: Conjugate families</a>
<ul>
<li class="chapter" data-level="3.1" data-path="sec41.html"><a href="sec41.html"><i class="fa fa-check"></i><b>3.1</b> Motivation of conjugate families</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="sec41.html"><a href="sec41.html#examples-of-exponential-family-distributions"><i class="fa fa-check"></i><b>3.1.1</b> Examples of exponential family distributions</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="sec42.html"><a href="sec42.html"><i class="fa fa-check"></i><b>3.2</b> Conjugate prior to exponential family</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="sec42.html"><a href="sec42.html#sec421"><i class="fa fa-check"></i><b>3.2.1</b> Examples: Theorem 4.2.1</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="sec43.html"><a href="sec43.html"><i class="fa fa-check"></i><b>3.3</b> Linear regression: The conjugate normal-normal/inverse gamma model</a></li>
<li class="chapter" data-level="3.4" data-path="sec44.html"><a href="sec44.html"><i class="fa fa-check"></i><b>3.4</b> Multivariate linear regression: The conjugate normal-normal/inverse Wishart model</a></li>
<li class="chapter" data-level="3.5" data-path="sec45.html"><a href="sec45.html"><i class="fa fa-check"></i><b>3.5</b> Summary</a></li>
<li class="chapter" data-level="3.6" data-path="sec46.html"><a href="sec46.html"><i class="fa fa-check"></i><b>3.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="Chap4.html"><a href="Chap4.html"><i class="fa fa-check"></i><b>4</b> Simulation methods</a>
<ul>
<li class="chapter" data-level="4.1" data-path="sec51.html"><a href="sec51.html"><i class="fa fa-check"></i><b>4.1</b> Markov Chain Monte Carlo methods</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="sec51.html"><a href="sec51.html#sec511"><i class="fa fa-check"></i><b>4.1.1</b> Gibbs sampler</a></li>
<li class="chapter" data-level="4.1.2" data-path="sec51.html"><a href="sec51.html#sec512"><i class="fa fa-check"></i><b>4.1.2</b> Metropolis-Hastings</a></li>
<li class="chapter" data-level="4.1.3" data-path="sec51.html"><a href="sec51.html#sec513"><i class="fa fa-check"></i><b>4.1.3</b> Hamiltonian Monte Carlo</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="sec52.html"><a href="sec52.html"><i class="fa fa-check"></i><b>4.2</b> Importance sampling</a></li>
<li class="chapter" data-level="4.3" data-path="sec53.html"><a href="sec53.html"><i class="fa fa-check"></i><b>4.3</b> Particle filtering</a></li>
<li class="chapter" data-level="4.4" data-path="sec54.html"><a href="sec54.html"><i class="fa fa-check"></i><b>4.4</b> Convergence diagnostics</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="sec54.html"><a href="sec54.html#numerical-standard-error"><i class="fa fa-check"></i><b>4.4.1</b> Numerical standard error</a></li>
<li class="chapter" data-level="4.4.2" data-path="sec54.html"><a href="sec54.html#effective-number-of-simulation-draws"><i class="fa fa-check"></i><b>4.4.2</b> Effective number of simulation draws</a></li>
<li class="chapter" data-level="4.4.3" data-path="sec54.html"><a href="sec54.html#tests-of-convergence"><i class="fa fa-check"></i><b>4.4.3</b> Tests of convergence</a></li>
<li class="chapter" data-level="4.4.4" data-path="sec54.html"><a href="sec54.html#checking-for-errors-in-the-posterior-simulator"><i class="fa fa-check"></i><b>4.4.4</b> Checking for errors in the posterior simulator</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="sec55.html"><a href="sec55.html"><i class="fa fa-check"></i><b>4.5</b> Summary</a></li>
<li class="chapter" data-level="4.6" data-path="sec56.html"><a href="sec56.html"><i class="fa fa-check"></i><b>4.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="Chap5.html"><a href="Chap5.html"><i class="fa fa-check"></i><b>5</b> Graphical user interface</a>
<ul>
<li class="chapter" data-level="5.1" data-path="secGUI1.html"><a href="secGUI1.html"><i class="fa fa-check"></i><b>5.1</b> Introduction</a></li>
<li class="chapter" data-level="5.2" data-path="secGUI2.html"><a href="secGUI2.html"><i class="fa fa-check"></i><b>5.2</b> Univariate models</a></li>
<li class="chapter" data-level="5.3" data-path="secGUI3.html"><a href="secGUI3.html"><i class="fa fa-check"></i><b>5.3</b> Multivariate models</a></li>
<li class="chapter" data-level="5.4" data-path="secGUI4.html"><a href="secGUI4.html"><i class="fa fa-check"></i><b>5.4</b> Time series models</a></li>
<li class="chapter" data-level="5.5" data-path="secGUI5.html"><a href="secGUI5.html"><i class="fa fa-check"></i><b>5.5</b> Longitudinal/panel models</a></li>
<li class="chapter" data-level="5.6" data-path="secGUI6.html"><a href="secGUI6.html"><i class="fa fa-check"></i><b>5.6</b> Bayesian model average</a></li>
<li class="chapter" data-level="5.7" data-path="secGUI7.html"><a href="secGUI7.html"><i class="fa fa-check"></i><b>5.7</b> Help</a></li>
<li class="chapter" data-level="5.8" data-path="secGUI8.html"><a href="secGUI8.html"><i class="fa fa-check"></i><b>5.8</b> Warning</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="Chap6.html"><a href="Chap6.html"><i class="fa fa-check"></i><b>6</b> Univariate regression</a>
<ul>
<li class="chapter" data-level="6.1" data-path="sec61.html"><a href="sec61.html"><i class="fa fa-check"></i><b>6.1</b> The Gaussian linear model</a></li>
<li class="chapter" data-level="6.2" data-path="sec62.html"><a href="sec62.html"><i class="fa fa-check"></i><b>6.2</b> The logit model</a></li>
<li class="chapter" data-level="6.3" data-path="sec63.html"><a href="sec63.html"><i class="fa fa-check"></i><b>6.3</b> The probit model</a></li>
<li class="chapter" data-level="6.4" data-path="sec64.html"><a href="sec64.html"><i class="fa fa-check"></i><b>6.4</b> The multinomial probit model</a></li>
<li class="chapter" data-level="6.5" data-path="sec65.html"><a href="sec65.html"><i class="fa fa-check"></i><b>6.5</b> The multinomial logit model</a></li>
<li class="chapter" data-level="6.6" data-path="sec66.html"><a href="sec66.html"><i class="fa fa-check"></i><b>6.6</b> Ordered probit model</a></li>
<li class="chapter" data-level="6.7" data-path="negative-binomial-model.html"><a href="negative-binomial-model.html"><i class="fa fa-check"></i><b>6.7</b> Negative binomial model</a></li>
<li class="chapter" data-level="6.8" data-path="sec68.html"><a href="sec68.html"><i class="fa fa-check"></i><b>6.8</b> Tobit model</a></li>
<li class="chapter" data-level="6.9" data-path="sec69.html"><a href="sec69.html"><i class="fa fa-check"></i><b>6.9</b> Quantile regression</a></li>
<li class="chapter" data-level="6.10" data-path="sec610.html"><a href="sec610.html"><i class="fa fa-check"></i><b>6.10</b> Bayesian bootstrap regression</a></li>
<li class="chapter" data-level="6.11" data-path="sec611.html"><a href="sec611.html"><i class="fa fa-check"></i><b>6.11</b> Summary</a></li>
<li class="chapter" data-level="6.12" data-path="sec612.html"><a href="sec612.html"><i class="fa fa-check"></i><b>6.12</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="Chap7.html"><a href="Chap7.html"><i class="fa fa-check"></i><b>7</b> Multivariate regression</a>
<ul>
<li class="chapter" data-level="7.1" data-path="sec71.html"><a href="sec71.html"><i class="fa fa-check"></i><b>7.1</b> Multivariate regression</a></li>
<li class="chapter" data-level="7.2" data-path="sec72.html"><a href="sec72.html"><i class="fa fa-check"></i><b>7.2</b> Seemingly Unrelated Regression</a></li>
<li class="chapter" data-level="7.3" data-path="sec73.html"><a href="sec73.html"><i class="fa fa-check"></i><b>7.3</b> Instrumental variable</a></li>
<li class="chapter" data-level="7.4" data-path="sec74.html"><a href="sec74.html"><i class="fa fa-check"></i><b>7.4</b> Multivariate probit model</a></li>
<li class="chapter" data-level="7.5" data-path="sec75.html"><a href="sec75.html"><i class="fa fa-check"></i><b>7.5</b> Summary</a></li>
<li class="chapter" data-level="7.6" data-path="sec76.html"><a href="sec76.html"><i class="fa fa-check"></i><b>7.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="Chap8.html"><a href="Chap8.html"><i class="fa fa-check"></i><b>8</b> Time series</a>
<ul>
<li class="chapter" data-level="8.1" data-path="sec81.html"><a href="sec81.html"><i class="fa fa-check"></i><b>8.1</b> State-space representation</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="sec81.html"><a href="sec81.html#gaussian-linear-state-space-models"><i class="fa fa-check"></i><b>8.1.1</b> Gaussian linear state-space models</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="sec82.html"><a href="sec82.html"><i class="fa fa-check"></i><b>8.2</b> ARMA processes</a></li>
<li class="chapter" data-level="8.3" data-path="sec83.html"><a href="sec83.html"><i class="fa fa-check"></i><b>8.3</b> Stochastic volatility models</a></li>
<li class="chapter" data-level="8.4" data-path="sec84.html"><a href="sec84.html"><i class="fa fa-check"></i><b>8.4</b> Vector Autoregressive models</a></li>
<li class="chapter" data-level="8.5" data-path="sec85.html"><a href="sec85.html"><i class="fa fa-check"></i><b>8.5</b> Summary</a></li>
<li class="chapter" data-level="8.6" data-path="sec86.html"><a href="sec86.html"><i class="fa fa-check"></i><b>8.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="Chap9.html"><a href="Chap9.html"><i class="fa fa-check"></i><b>9</b> Longitudinal regression</a>
<ul>
<li class="chapter" data-level="9.1" data-path="sec91.html"><a href="sec91.html"><i class="fa fa-check"></i><b>9.1</b> Normal model</a></li>
<li class="chapter" data-level="9.2" data-path="sec92.html"><a href="sec92.html"><i class="fa fa-check"></i><b>9.2</b> Logit model</a></li>
<li class="chapter" data-level="9.3" data-path="sec93.html"><a href="sec93.html"><i class="fa fa-check"></i><b>9.3</b> Poisson model</a></li>
<li class="chapter" data-level="9.4" data-path="sec94.html"><a href="sec94.html"><i class="fa fa-check"></i><b>9.4</b> Summary</a></li>
<li class="chapter" data-level="9.5" data-path="sec95.html"><a href="sec95.html"><i class="fa fa-check"></i><b>9.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="Chap10.html"><a href="Chap10.html"><i class="fa fa-check"></i><b>10</b> Bayesian model averaging in variable selection</a>
<ul>
<li class="chapter" data-level="10.1" data-path="sec10_1.html"><a href="sec10_1.html"><i class="fa fa-check"></i><b>10.1</b> Foundation</a></li>
<li class="chapter" data-level="10.2" data-path="sec102.html"><a href="sec102.html"><i class="fa fa-check"></i><b>10.2</b> The Gaussian linear model</a></li>
<li class="chapter" data-level="10.3" data-path="sec103.html"><a href="sec103.html"><i class="fa fa-check"></i><b>10.3</b> Generalized linear models</a></li>
<li class="chapter" data-level="10.4" data-path="sec10_4.html"><a href="sec10_4.html"><i class="fa fa-check"></i><b>10.4</b> Calculating the marginal likelihood</a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="sec10_4.html"><a href="sec10_4.html#sec10_4_1"><i class="fa fa-check"></i><b>10.4.1</b> Savage-Dickey density ratio</a></li>
<li class="chapter" data-level="10.4.2" data-path="sec10_4.html"><a href="sec10_4.html#sec10_4_2"><i class="fa fa-check"></i><b>10.4.2</b> Chib’s methods</a></li>
<li class="chapter" data-level="10.4.3" data-path="sec10_4.html"><a href="sec10_4.html#sec10_4_3"><i class="fa fa-check"></i><b>10.4.3</b> Gelfand-Dey method</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="sec10_5.html"><a href="sec10_5.html"><i class="fa fa-check"></i><b>10.5</b> Summary</a></li>
<li class="chapter" data-level="10.6" data-path="sec10_6.html"><a href="sec10_6.html"><i class="fa fa-check"></i><b>10.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="Chap11.html"><a href="Chap11.html"><i class="fa fa-check"></i><b>11</b> Semi-parametric and non-parametric models</a>
<ul>
<li class="chapter" data-level="11.1" data-path="sec11_1.html"><a href="sec11_1.html"><i class="fa fa-check"></i><b>11.1</b> Mixture models</a>
<ul>
<li class="chapter" data-level="11.1.1" data-path="sec11_1.html"><a href="sec11_1.html#sec11_11"><i class="fa fa-check"></i><b>11.1.1</b> Finite Gaussian mixtures</a></li>
<li class="chapter" data-level="11.1.2" data-path="sec11_1.html"><a href="sec11_1.html#sec11_12"><i class="fa fa-check"></i><b>11.1.2</b> Direchlet processes</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="sec11_2.html"><a href="sec11_2.html"><i class="fa fa-check"></i><b>11.2</b> Splines</a></li>
<li class="chapter" data-level="11.3" data-path="sec11_3.html"><a href="sec11_3.html"><i class="fa fa-check"></i><b>11.3</b> Summary</a></li>
<li class="chapter" data-level="11.4" data-path="sec11_4.html"><a href="sec11_4.html"><i class="fa fa-check"></i><b>11.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="Chap12.html"><a href="Chap12.html"><i class="fa fa-check"></i><b>12</b> Bayesian machine learning</a>
<ul>
<li class="chapter" data-level="12.1" data-path="sec12_1.html"><a href="sec12_1.html"><i class="fa fa-check"></i><b>12.1</b> Cross-validation and Bayes factors</a></li>
<li class="chapter" data-level="12.2" data-path="sec12_2.html"><a href="sec12_2.html"><i class="fa fa-check"></i><b>12.2</b> Regularization</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="sec12_2.html"><a href="sec12_2.html#sec12_21"><i class="fa fa-check"></i><b>12.2.1</b> Bayesian LASSO</a></li>
<li class="chapter" data-level="12.2.2" data-path="sec12_2.html"><a href="sec12_2.html#sec12_22"><i class="fa fa-check"></i><b>12.2.2</b> Stochastic search variable selection</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="sec12_3.html"><a href="sec12_3.html"><i class="fa fa-check"></i><b>12.3</b> Bayesian additive regression trees</a></li>
<li class="chapter" data-level="12.4" data-path="sec12_4.html"><a href="sec12_4.html"><i class="fa fa-check"></i><b>12.4</b> Gaussian processes</a></li>
<li class="chapter" data-level="12.5" data-path="sec12_5.html"><a href="sec12_5.html"><i class="fa fa-check"></i><b>12.5</b> Tall data problems</a>
<ul>
<li class="chapter" data-level="12.5.1" data-path="sec12_5.html"><a href="sec12_5.html#sec12_51"><i class="fa fa-check"></i><b>12.5.1</b> Divide-and-conquer methods</a></li>
<li class="chapter" data-level="12.5.2" data-path="sec12_5.html"><a href="sec12_5.html#sec12_52"><i class="fa fa-check"></i><b>12.5.2</b> Subsampling-based algorithms</a></li>
</ul></li>
<li class="chapter" data-level="12.6" data-path="id_13_6.html"><a href="id_13_6.html"><i class="fa fa-check"></i><b>12.6</b> Summary</a></li>
<li class="chapter" data-level="12.7" data-path="id_13_7.html"><a href="id_13_7.html"><i class="fa fa-check"></i><b>12.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="Chap13.html"><a href="Chap13.html"><i class="fa fa-check"></i><b>13</b> Causal inference</a>
<ul>
<li class="chapter" data-level="13.1" data-path="sec13_1.html"><a href="sec13_1.html"><i class="fa fa-check"></i><b>13.1</b> Instrumental variables</a>
<ul>
<li class="chapter" data-level="13.1.1" data-path="sec13_1.html"><a href="sec13_1.html#sec13_11"><i class="fa fa-check"></i><b>13.1.1</b> Semi-parametric IV model</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="sec13_2.html"><a href="sec13_2.html"><i class="fa fa-check"></i><b>13.2</b> Regression discontinuity design</a></li>
<li class="chapter" data-level="13.3" data-path="sec13_3.html"><a href="sec13_3.html"><i class="fa fa-check"></i><b>13.3</b> Regression kink design</a></li>
<li class="chapter" data-level="13.4" data-path="sec13_4.html"><a href="sec13_4.html"><i class="fa fa-check"></i><b>13.4</b> Synthetic control</a></li>
<li class="chapter" data-level="13.5" data-path="sec13_5.html"><a href="sec13_5.html"><i class="fa fa-check"></i><b>13.5</b> Difference in difference estimation</a></li>
<li class="chapter" data-level="13.6" data-path="sec13_6.html"><a href="sec13_6.html"><i class="fa fa-check"></i><b>13.6</b> Event Analysis</a></li>
<li class="chapter" data-level="13.7" data-path="sec13_7.html"><a href="sec13_7.html"><i class="fa fa-check"></i><b>13.7</b> Bayesian exponential tilted empirical likelihood</a></li>
<li class="chapter" data-level="13.8" data-path="sec13_8.html"><a href="sec13_8.html"><i class="fa fa-check"></i><b>13.8</b> Double-Debiased machine learning causal effects</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="Chap14.html"><a href="Chap14.html"><i class="fa fa-check"></i><b>14</b> Approximate Bayesian methods</a>
<ul>
<li class="chapter" data-level="14.1" data-path="sec14_1.html"><a href="sec14_1.html"><i class="fa fa-check"></i><b>14.1</b> Simulation-based approaches</a>
<ul>
<li class="chapter" data-level="14.1.1" data-path="sec14_1.html"><a href="sec14_1.html#sec14_11"><i class="fa fa-check"></i><b>14.1.1</b> Approximate Bayesian computation</a></li>
<li class="chapter" data-level="14.1.2" data-path="sec14_1.html"><a href="sec14_1.html#sec14_12"><i class="fa fa-check"></i><b>14.1.2</b> Bayesian synthetic likelihood</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="sec14_2.html"><a href="sec14_2.html"><i class="fa fa-check"></i><b>14.2</b> Optimization approaches</a>
<ul>
<li class="chapter" data-level="14.2.1" data-path="sec14_2.html"><a href="sec14_2.html#sec14_21"><i class="fa fa-check"></i><b>14.2.1</b> Integrated nested Laplace approximations</a></li>
<li class="chapter" data-level="14.2.2" data-path="sec14_2.html"><a href="sec14_2.html#sec14_22"><i class="fa fa-check"></i><b>14.2.2</b> Variational Bayes</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="summary-1.html"><a href="summary-1.html"><i class="fa fa-check"></i><b>14.3</b> Summary</a></li>
<li class="chapter" data-level="14.4" data-path="sec14_4.html"><a href="sec14_4.html"><i class="fa fa-check"></i><b>14.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i>Appendix</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to Bayesian Econometrics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="sec74" class="section level2 hasAnchor" number="7.4">
<h2><span class="header-section-number">7.4</span> Multivariate probit model<a href="sec74.html#sec74" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In the multivariate probit model <span class="citation">Edwards and Allenby (<a href="#ref-Edwards2003">2003</a>)</span>, the response variable <span class="math inline">\(y_{il} = \{0, 1\}\)</span> indicates that individual <span class="math inline">\(i\)</span> makes binary choices among <span class="math inline">\(L\)</span> mutually exclusive alternatives, where <span class="math inline">\(l = 1, 2, \dots, L\)</span> and <span class="math inline">\(i = 1, 2, \dots, N\)</span>. Specifically,</p>
<p><span class="math display">\[
    y_{il} =
    \begin{cases}
        0, &amp; \quad y_{il}^* \leq 0 \\
        1, &amp; \quad y_{il}^* &gt; 0
    \end{cases}
\]</span></p>
<p>where <span class="math inline">\(\boldsymbol{y}_i^* = \boldsymbol{X}_i \boldsymbol{\beta} + \boldsymbol{\mu}_i \sim \text{i.i.d.} \, N(\boldsymbol{0}, \boldsymbol{\Sigma})\)</span>. Here, <span class="math inline">\(\boldsymbol{y}_i^*\)</span> is an unobserved latent <span class="math inline">\(L\)</span>-dimensional vector, <span class="math inline">\(\boldsymbol{X}_i = \boldsymbol{x}_i^\top \otimes \mathbf{I}_L\)</span> is an <span class="math inline">\(L \times K\)</span> design matrix of regressors, with <span class="math inline">\(K = L \times k\)</span>, where <span class="math inline">\(k\)</span> is the number of regressors (i.e., the length of <span class="math inline">\(\boldsymbol{x}_i\)</span>). In addition, <span class="math inline">\(\boldsymbol{\beta} = \left[\boldsymbol{\beta}_1^\top \ \boldsymbol{\beta}_2^\top \dots \boldsymbol{\beta}_k^\top\right]^\top\)</span>, where <span class="math inline">\(\boldsymbol{\beta}_j\)</span> forms an <span class="math inline">\(L\)</span>-dimensional vector of coefficients for <span class="math inline">\(j = 1, 2, \dots, k\)</span>.</p>
<p>The likelihood function for this model is given by</p>
<p><span class="math display">\[
p(\boldsymbol{\beta}, \boldsymbol{\Sigma} \mid \boldsymbol{y}, \boldsymbol{X}) = \prod_{i=1}^N \prod_{l=1}^L p_{il}^{y_{il}},
\]</span></p>
<p>where <span class="math inline">\(p_{il} = p(y_{il}^* \geq 0)\)</span>.</p>
<p>Observe that <span class="math inline">\(p({y}_{il}^*\geq 0)=p({\lambda}_{ll}{y}_{il}^*\geq 0)\)</span>, <span class="math inline">\(\lambda_{ll}&gt;0\)</span>. This generates identification issues because only the correlation matrix can be identified, similar to the univariate probit model where the variance of the model is fixed to 1. We follow the post-processing strategy proposed by <span class="citation">Edwards and Allenby (<a href="#ref-Edwards2003">2003</a>)</span> to obtain identified parameters, that is, <span class="math inline">\(\tilde{\boldsymbol{\beta}}=\text{vec}\left\{\boldsymbol{\Lambda}\mathbf{B}\right\}\)</span> and the correlation matrix <span class="math inline">\(\boldsymbol{R}=\boldsymbol{\Lambda}\boldsymbol{\Sigma}\boldsymbol{\Lambda}\)</span>, where <span class="math inline">\(\boldsymbol{\Lambda}=\text{diag}\left\{\sigma_{ll}\right\}^{-1/2}\)</span> and <span class="math inline">\(\mathbf{B}=\left[\boldsymbol{\beta}_1 \ \boldsymbol{\beta}_2 \dots \boldsymbol{\beta}_k\right]\)</span>.<a href="#fn8" class="footnote-ref" id="fnref8"><sup>8</sup></a></p>
<p>We assume independent priors: <span class="math inline">\(\boldsymbol{\beta} \sim N(\boldsymbol{\beta}_0, \boldsymbol{B}_0)\)</span> and <span class="math inline">\(\boldsymbol{\Sigma}^{-1} \sim W(\alpha_0, \boldsymbol{\Psi}_0)\)</span>. We can apply Gibbs sampling to this model, as it is a standard Bayesian linear regression model when data augmentation in <span class="math inline">\(\boldsymbol{y}^*\)</span> is used.</p>
<p>The posterior conditional distributions are
<span class="math display">\[\begin{equation}
    \boldsymbol{\beta}\mid \boldsymbol{\Sigma},\boldsymbol{w} \sim N(\boldsymbol{\beta}_n,\boldsymbol{B}_n),
\end{equation}\]</span>
<span class="math display">\[\begin{equation}
    \boldsymbol{\Sigma}^{-1} \mid \boldsymbol{\beta},\boldsymbol{w} \sim W(\alpha_n,\boldsymbol{\Psi}_n),
\end{equation}\]</span>
<span class="math display">\[\begin{equation}
    y_{il}^* \mid \boldsymbol{y}_{i,-l}^*,\boldsymbol{\beta},\boldsymbol{\Sigma}^{-1},\boldsymbol{y_i} \sim TN_{I_{il}}(m_{il},\tau_{ll}^2)
\end{equation}\]</span></p>
<p>where <span class="math inline">\(\boldsymbol{B}_n=(\boldsymbol{B}_0^{-1}+\boldsymbol{X}^{*\top}\boldsymbol{X}^*)^{-1}\)</span>, <span class="math inline">\(\boldsymbol{\beta}_n=\boldsymbol{B}_n(\boldsymbol{B}_0^{-1}\boldsymbol{\beta}_0+\boldsymbol{X}^{*\top}\boldsymbol{y}^{**})\)</span>, <span class="math inline">\(\boldsymbol{\Sigma}^{-1}=\boldsymbol{C}^{\top}\boldsymbol{C}\)</span>, <span class="math inline">\(\boldsymbol{X}_i^{*}=\boldsymbol{C}^{\top}\boldsymbol{X}_i\)</span>, <span class="math inline">\(\boldsymbol{y}_i^{**}=\boldsymbol{C}^{\top}\boldsymbol{y}_i^*\)</span>, <span class="math inline">\(\alpha_n=\alpha_0+N\)</span>, <span class="math inline">\(\boldsymbol{\Psi}_n=(\boldsymbol{\Psi}_0+\sum_{i=1}^N (\boldsymbol{y}_i^*-\boldsymbol{X}_i\boldsymbol{\beta})(\boldsymbol{y}_i^*-\boldsymbol{X}_i\boldsymbol{\beta})^{\top})^{-1}\)</span>,</p>
<p><span class="math display">\[
m_{il}=\boldsymbol{x}_{il}^{\top}\boldsymbol{\beta}+\boldsymbol{f}_l^{\top}(\boldsymbol{y}_{i,-l}^*-\boldsymbol{X}_{i,-l}\boldsymbol{\beta}),
\]</span></p>
<p>where <span class="math inline">\(\boldsymbol{y}_{i,-l}^*\)</span> is an <span class="math inline">\(L-1\)</span> dimensional vector of all components of <span class="math inline">\(\boldsymbol{y}_i^*\)</span> excluding <span class="math inline">\(y_{il}^*\)</span>, <span class="math inline">\(\boldsymbol{x}_{il}^{\top}\)</span> is the <span class="math inline">\(l\)</span>-th row of <span class="math inline">\(\boldsymbol{X}_i\)</span>, <span class="math inline">\(\boldsymbol{X}_{i,-l}\)</span> is <span class="math inline">\(\boldsymbol{X}_{i}\)</span> after deleting the <span class="math inline">\(l\)</span>-th row,</p>
<p><span class="math display">\[
\boldsymbol{f}_l^{\top}=\boldsymbol{\omega}_{l,-l}^{\top}\boldsymbol{\Sigma}_{-l,-l}^{-1},
\]</span></p>
<p>where <span class="math inline">\(\boldsymbol{\omega}_{l,-l}^{\top}\)</span> and <span class="math inline">\(\boldsymbol{\Sigma}_{-l,-l}\)</span> are the <span class="math inline">\(l\)</span>-th row of <span class="math inline">\(\boldsymbol{\Sigma}\)</span> extracting the <span class="math inline">\(l\)</span>-th element, and the sub-matrix of <span class="math inline">\(\boldsymbol{\Sigma}\)</span> extracting the <span class="math inline">\(l,l\)</span> element, and</p>
<p><span class="math display">\[
\tau_{ll}^2=\sigma_{l,l}-\boldsymbol{\omega}_{l,-l}^{\top}\boldsymbol{\Sigma}_{-l,-l}^{-1}\boldsymbol{\omega}_{-l,l},
\]</span></p>
<p>and</p>
<p><span class="math display">\[
\boldsymbol{X}^*=
\begin{bmatrix}
    \boldsymbol{X}_1^*\\
    \boldsymbol{X}_2^*\\
    \vdots\\
    \boldsymbol{X}_N^*
\end{bmatrix},
\quad
I_{il}=
\begin{Bmatrix}
    y_{il}^*&gt; 0, &amp; y_{il}=1\\
    y_{il}^*\leq 0 , &amp; y_{il}=0
\end{Bmatrix},
\quad
\boldsymbol{\Sigma}=
\begin{bmatrix}
    \boldsymbol{\omega}_1^{\top} \\
    \boldsymbol{\omega}_2^{\top} \\
    \vdots \\
    \boldsymbol{\omega}_{L}^{\top}
\end{bmatrix}.
\]</span></p>
<p>The setting in our GUI has the same regressors in each binary decision. However, we can see that the multivariate probit model is similar to a SUR model in latent variables. We ask in Exercise 9 to implement a Gibbs sampling algorithm for a multivariate probit model with different regressors in each equation.</p>
<p><strong>Example: Self selection in hospitalization due to a subsidized health care program</strong></p>
<p>We use the dataset <em>7HealthMed.csv</em>, where the dependent variable is <span class="math inline">\(y = \left[\text{Hosp} \ \text{SHI}\right]^{\top}\)</span>, with <span class="math inline">\(\text{Hosp} = 1\)</span> if an individual was hospitalized in the year prior to the survey (0 otherwise), and <span class="math inline">\(\text{SHI} = 1\)</span> if the individual had subsidized health insurance (0 otherwise).</p>
<p>Recall that our application of binary response models aimed to uncover the determinants of hospitalization in Medellín (Colombia), where one of the regressors was a binary indicator of participation in a subsidized health care program (Section <a href="sec63.html#sec63">6.3</a>). We can use a bivariate probit model if we suspect there is dependence between the decisions regarding these two variables. A priori, we would expect that being in a subsidized health care program increases the probability of hospitalization <em>ceteris paribus</em>, due to reduced costs for the patient. However, if an individual expects to be hospitalized in the future, and the factors influencing this decision are unobserved by the modeler, a feedback effect may exist from hospitalization to enrollment in the subsidized health care program.</p>
<p>We considered seven regressors: a constant, gender (female), age, self-perception of health status (with categories fair, good, and excellent, using bad as the reference category), and the proportion of the individual’s age spent living in their neighborhood. The last variable attempts to account for social capital, which can affect enrollment in the subsidized health insurance program, as the target population is identified by the local government <span class="citation">(<a href="#ref-Ramirez2019a">Ramírez-Hassan and Guerra-Urzola 2021</a>)</span>. The dataset includes 12,975 individuals who can “choose” two options: hospitalization and enrollment in the subsidized health insurance regime.</p>
<p>The following Algorithm shows how to run a multivariate probit model using our GUI.</p>
<div class="algorithm">
<div style="background-color: #f8f9fa; padding: 15px; border-left: 5px solid #343a40; box-shadow: 4px 4px 10px rgba(0, 0, 0, 0.1); border-radius: 5px;">
<p><strong>Algorithm: Multivariate Probit Model</strong></p>
<ol style="list-style-type: decimal">
<li><p>Select <em>Multivariate Models</em> on the top panel</p></li>
<li><p>Select <em>Multivariate Probit</em> model using the left radio button</p></li>
<li><p>Upload the dataset, selecting first if there is a header in the file, and the kind of separator in the <em>csv</em> file of the dataset (comma, semicolon, or tab). Then, use the <em>Browse</em> button under the <strong>Choose File</strong> legend</p></li>
<li><p>Select MCMC iterations, burn-in, and thinning parameters using the <em>Range sliders</em></p></li>
<li><p>Write down the number of cross-sectional units in the <strong>Number of individuals: n</strong> box</p></li>
<li><p>Write down the number of exogenous variables in the <strong>Number of exogenous variables: k</strong> box</p></li>
<li><p>Write down the number of choices in the <strong>Number of choices: l</strong> box</p></li>
<li><p>Set the hyperparameters: mean vectors, covariance matrix, degrees of freedom, and the scale matrix. This step is not necessary as by default our GUI uses non-informative priors</p></li>
<li><p>Click the <em>Go!</em> button</p></li>
<li><p>Analyze results</p></li>
<li><p>Download posterior chains and diagnostic plots using the <em>Download Posterior Chains</em> and <em>Download Posterior Graphs</em> buttons</p></li>
</ol>
</div>
</div>
<p>We set 20,000 MCMC iterations with a thinning parameter equal to 5. The hyperparameters are <span class="math inline">\(\boldsymbol{\beta}_0 = \boldsymbol{0}_{14}\)</span>, <span class="math inline">\(\boldsymbol{B}_0 = 100\boldsymbol{I}_{14}\)</span>, <span class="math inline">\(\alpha_0 = 4\)</span>, and <span class="math inline">\(\boldsymbol{\Psi}_0 = 4\boldsymbol{I}_2\)</span>.<a href="#fn9" class="footnote-ref" id="fnref9"><sup>9</sup></a></p>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="sec74.html#cb27-1" tabindex="-1"></a><span class="fu">rm</span>(<span class="at">list =</span> <span class="fu">ls</span>()); <span class="fu">set.seed</span>(<span class="dv">010101</span>)</span>
<span id="cb27-2"><a href="sec74.html#cb27-2" tabindex="-1"></a>Data <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">&quot;https://raw.githubusercontent.com/besmarter/BSTApp/refs/heads/master/DataApp/7HealthMed.csv&quot;</span>, <span class="at">sep =</span> <span class="st">&quot;,&quot;</span>, <span class="at">header =</span> <span class="cn">TRUE</span>, <span class="at">quote =</span> <span class="st">&quot;&quot;</span>)</span>
<span id="cb27-3"><a href="sec74.html#cb27-3" tabindex="-1"></a><span class="fu">attach</span>(Data); <span class="fu">str</span>(Data)</span></code></pre></div>
<pre><code>## The following object is masked from DataUtEst:
## 
##     id</code></pre>
<pre><code>## &#39;data.frame&#39;:    25950 obs. of  9 variables:
##  $ id       : int  1 1 2 2 3 3 4 4 5 5 ...
##  $ y        : int  0 1 0 1 0 1 0 1 0 0 ...
##  $ Constant : int  1 1 1 1 1 1 1 1 1 1 ...
##  $ Female   : int  0 0 1 1 1 1 1 1 0 0 ...
##  $ Age      : int  7 7 39 39 23 23 15 15 8 8 ...
##  $ Fair     : int  0 0 0 0 0 0 0 0 0 0 ...
##  $ Good     : int  1 1 1 1 1 1 1 1 0 0 ...
##  $ Excellent: int  0 0 0 0 0 0 0 0 1 1 ...
##  $ PTL      : num  0.43 0.43 0 0 0 0 0 0 0 0 ...</code></pre>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb30-1"><a href="sec74.html#cb30-1" tabindex="-1"></a>p <span class="ot">&lt;-</span> <span class="dv">2</span>; nd <span class="ot">&lt;-</span> <span class="dv">7</span>; N <span class="ot">&lt;-</span> <span class="fu">length</span>(y)<span class="sc">/</span>p; y <span class="ot">&lt;-</span> y</span>
<span id="cb30-2"><a href="sec74.html#cb30-2" tabindex="-1"></a>Xd <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(Data[<span class="fu">seq</span>(<span class="dv">1</span>, p<span class="sc">*</span>N, <span class="dv">2</span>),<span class="dv">3</span><span class="sc">:</span><span class="dv">9</span>])</span>
<span id="cb30-3"><a href="sec74.html#cb30-3" tabindex="-1"></a>XcreateMP<span class="ot">&lt;-</span><span class="cf">function</span>(p,nxs,nind,Data){</span>
<span id="cb30-4"><a href="sec74.html#cb30-4" tabindex="-1"></a>    pandterm <span class="ot">=</span> <span class="cf">function</span>(message) {</span>
<span id="cb30-5"><a href="sec74.html#cb30-5" tabindex="-1"></a>        <span class="fu">stop</span>(message, <span class="at">call. =</span> <span class="cn">FALSE</span>)</span>
<span id="cb30-6"><a href="sec74.html#cb30-6" tabindex="-1"></a>    }</span>
<span id="cb30-7"><a href="sec74.html#cb30-7" tabindex="-1"></a>    <span class="cf">if</span> (<span class="fu">missing</span>(nxs)) </span>
<span id="cb30-8"><a href="sec74.html#cb30-8" tabindex="-1"></a>    <span class="fu">pandterm</span>(<span class="st">&quot;requires number of regressors: include intercept if required&quot;</span>)</span>
<span id="cb30-9"><a href="sec74.html#cb30-9" tabindex="-1"></a>    <span class="cf">if</span> (<span class="fu">missing</span>(nind)) </span>
<span id="cb30-10"><a href="sec74.html#cb30-10" tabindex="-1"></a>    <span class="fu">pandterm</span>(<span class="st">&quot;requires number of units (individuals)&quot;</span>)</span>
<span id="cb30-11"><a href="sec74.html#cb30-11" tabindex="-1"></a>    <span class="cf">if</span> (<span class="fu">missing</span>(Data)) </span>
<span id="cb30-12"><a href="sec74.html#cb30-12" tabindex="-1"></a>    <span class="fu">pandterm</span>(<span class="st">&quot;requires dataset&quot;</span>)</span>
<span id="cb30-13"><a href="sec74.html#cb30-13" tabindex="-1"></a>    <span class="cf">if</span> (<span class="fu">nrow</span>(Data)<span class="sc">!=</span>nind<span class="sc">*</span><span class="dv">2</span>)</span>
<span id="cb30-14"><a href="sec74.html#cb30-14" tabindex="-1"></a>    <span class="fu">pandterm</span>(<span class="st">&quot;check dataset! number of units times number alternatives should be equal to dataset rows&quot;</span>)</span>
<span id="cb30-15"><a href="sec74.html#cb30-15" tabindex="-1"></a>    XXDat<span class="ot">&lt;-</span><span class="fu">array</span>(<span class="dv">0</span>,<span class="fu">c</span>(p,<span class="dv">1</span><span class="sc">+</span>nxs,nind))</span>
<span id="cb30-16"><a href="sec74.html#cb30-16" tabindex="-1"></a>    XX<span class="ot">&lt;-</span><span class="fu">array</span>(<span class="dv">0</span>,<span class="fu">c</span>(p,nxs<span class="sc">*</span>p,nind))</span>
<span id="cb30-17"><a href="sec74.html#cb30-17" tabindex="-1"></a>    YY<span class="ot">&lt;-</span><span class="fu">array</span>(<span class="dv">0</span>,<span class="fu">c</span>(p,<span class="dv">1</span>,nind))</span>
<span id="cb30-18"><a href="sec74.html#cb30-18" tabindex="-1"></a>    is<span class="ot">&lt;-</span> <span class="fu">seq</span>(p,nind<span class="sc">*</span>p,p)</span>
<span id="cb30-19"><a href="sec74.html#cb30-19" tabindex="-1"></a>    cis<span class="ot">&lt;-</span> <span class="fu">seq</span>(nxs,nxs<span class="sc">*</span>p<span class="sc">+</span><span class="dv">1</span>,nxs)</span>
<span id="cb30-20"><a href="sec74.html#cb30-20" tabindex="-1"></a>    <span class="cf">for</span>(i <span class="cf">in</span> is){</span>
<span id="cb30-21"><a href="sec74.html#cb30-21" tabindex="-1"></a>        j<span class="ot">&lt;-</span><span class="fu">which</span>(i<span class="sc">==</span>is)</span>
<span id="cb30-22"><a href="sec74.html#cb30-22" tabindex="-1"></a>        XXDat[,,j]<span class="ot">&lt;-</span><span class="fu">as.matrix</span>(Data[<span class="fu">c</span>((i<span class="sc">-</span>(p<span class="dv">-1</span>))<span class="sc">:</span>i),<span class="sc">-</span><span class="dv">1</span>])</span>
<span id="cb30-23"><a href="sec74.html#cb30-23" tabindex="-1"></a>        YY[,,j]<span class="ot">&lt;-</span>XXDat[,<span class="dv">1</span>,j]</span>
<span id="cb30-24"><a href="sec74.html#cb30-24" tabindex="-1"></a>        <span class="cf">for</span>(l <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>p){</span>
<span id="cb30-25"><a href="sec74.html#cb30-25" tabindex="-1"></a>            XX[l,((cis[l]<span class="sc">-</span>(nxs<span class="dv">-1</span>))<span class="sc">:</span>cis[l]),j]<span class="ot">&lt;-</span>XXDat[l,<span class="sc">-</span><span class="dv">1</span>,j]</span>
<span id="cb30-26"><a href="sec74.html#cb30-26" tabindex="-1"></a>        }</span>
<span id="cb30-27"><a href="sec74.html#cb30-27" tabindex="-1"></a>    }</span>
<span id="cb30-28"><a href="sec74.html#cb30-28" tabindex="-1"></a>    <span class="fu">return</span>(<span class="fu">list</span>(<span class="at">y=</span>YY,<span class="at">X=</span>XX))</span>
<span id="cb30-29"><a href="sec74.html#cb30-29" tabindex="-1"></a>}</span>
<span id="cb30-30"><a href="sec74.html#cb30-30" tabindex="-1"></a>Dat <span class="ot">&lt;-</span> <span class="fu">XcreateMP</span>(<span class="at">p =</span> p, <span class="at">nxs =</span> nd, <span class="at">nind =</span> N, <span class="at">Data =</span> Data)</span>
<span id="cb30-31"><a href="sec74.html#cb30-31" tabindex="-1"></a>y<span class="ot">&lt;-</span><span class="cn">NULL</span>; X<span class="ot">&lt;-</span><span class="cn">NULL</span></span>
<span id="cb30-32"><a href="sec74.html#cb30-32" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">dim</span>(Dat<span class="sc">$</span>y)[<span class="dv">3</span>]){</span>
<span id="cb30-33"><a href="sec74.html#cb30-33" tabindex="-1"></a>    y<span class="ot">&lt;-</span><span class="fu">c</span>(y,Dat<span class="sc">$</span>y[,,i])</span>
<span id="cb30-34"><a href="sec74.html#cb30-34" tabindex="-1"></a>    X<span class="ot">&lt;-</span><span class="fu">rbind</span>(X,Dat<span class="sc">$</span>X[,,i])</span>
<span id="cb30-35"><a href="sec74.html#cb30-35" tabindex="-1"></a>}</span>
<span id="cb30-36"><a href="sec74.html#cb30-36" tabindex="-1"></a>DataMP <span class="ot">=</span> <span class="fu">list</span>(<span class="at">p=</span>p, <span class="at">y=</span>y, <span class="at">X=</span>X)</span>
<span id="cb30-37"><a href="sec74.html#cb30-37" tabindex="-1"></a><span class="co"># Hyperparameters</span></span>
<span id="cb30-38"><a href="sec74.html#cb30-38" tabindex="-1"></a>k <span class="ot">&lt;-</span> <span class="fu">dim</span>(X)[<span class="dv">2</span>]; b0 <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">0</span>, k); c0 <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb30-39"><a href="sec74.html#cb30-39" tabindex="-1"></a>B0 <span class="ot">&lt;-</span> c0<span class="sc">*</span><span class="fu">diag</span>(k); B0i <span class="ot">&lt;-</span> <span class="fu">solve</span>(B0)</span>
<span id="cb30-40"><a href="sec74.html#cb30-40" tabindex="-1"></a>a0 <span class="ot">&lt;-</span> p <span class="sc">-</span> <span class="dv">1</span> <span class="sc">+</span> <span class="dv">3</span>; Psi0 <span class="ot">&lt;-</span> a0<span class="sc">*</span><span class="fu">diag</span>(p)</span>
<span id="cb30-41"><a href="sec74.html#cb30-41" tabindex="-1"></a>Prior <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">betabar =</span> b0, <span class="at">A =</span> B0i, <span class="at">nu =</span> a0, <span class="at">V =</span> Psi0)</span>
<span id="cb30-42"><a href="sec74.html#cb30-42" tabindex="-1"></a><span class="co"># MCMC parameters</span></span>
<span id="cb30-43"><a href="sec74.html#cb30-43" tabindex="-1"></a>mcmc <span class="ot">&lt;-</span> <span class="dv">20000</span>; thin <span class="ot">&lt;-</span> <span class="dv">5</span>; </span>
<span id="cb30-44"><a href="sec74.html#cb30-44" tabindex="-1"></a>Mcmc <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">R =</span> mcmc, <span class="at">keep =</span> thin, <span class="at">nprint =</span> <span class="dv">0</span>)</span>
<span id="cb30-45"><a href="sec74.html#cb30-45" tabindex="-1"></a>Results <span class="ot">&lt;-</span> bayesm<span class="sc">::</span><span class="fu">rmvpGibbs</span>(<span class="at">Data =</span> DataMP, <span class="at">Mcmc =</span> Mcmc, <span class="at">Prior =</span> Prior)</span></code></pre></div>
<pre><code>## Table of y values
## y
##     0     1 
## 15653 10297 
##  
## Starting Gibbs Sampler for MVP
##    12975  obs of  2  binary indicators;  14  indep vars (including intercepts)
##  
## Prior Parms:
## betabar
##  [1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0
## A
##        [,1]  [,2]  [,3]  [,4]  [,5]  [,6]  [,7]  [,8]  [,9] [,10] [,11] [,12]
##  [1,] 0.001 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000
##  [2,] 0.000 0.001 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000
##  [3,] 0.000 0.000 0.001 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000
##  [4,] 0.000 0.000 0.000 0.001 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000
##  [5,] 0.000 0.000 0.000 0.000 0.001 0.000 0.000 0.000 0.000 0.000 0.000 0.000
##  [6,] 0.000 0.000 0.000 0.000 0.000 0.001 0.000 0.000 0.000 0.000 0.000 0.000
##  [7,] 0.000 0.000 0.000 0.000 0.000 0.000 0.001 0.000 0.000 0.000 0.000 0.000
##  [8,] 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.001 0.000 0.000 0.000 0.000
##  [9,] 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.001 0.000 0.000 0.000
## [10,] 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.001 0.000 0.000
## [11,] 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.001 0.000
## [12,] 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.001
## [13,] 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000
## [14,] 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000
##       [,13] [,14]
##  [1,] 0.000 0.000
##  [2,] 0.000 0.000
##  [3,] 0.000 0.000
##  [4,] 0.000 0.000
##  [5,] 0.000 0.000
##  [6,] 0.000 0.000
##  [7,] 0.000 0.000
##  [8,] 0.000 0.000
##  [9,] 0.000 0.000
## [10,] 0.000 0.000
## [11,] 0.000 0.000
## [12,] 0.000 0.000
## [13,] 0.001 0.000
## [14,] 0.000 0.001
## nu
## [1] 4
## V
##      [,1] [,2]
## [1,]    4    0
## [2,]    0    4
##  
## MCMC Parms:
##    20000  reps; keeping every  5 th draw  nprint=  0
## initial beta=  0 0 0 0 0 0 0 0 0 0 0 0 0 0
## initial sigma= 
##      [,1] [,2]
## [1,]    1    0
## [2,]    0    1
## </code></pre>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb32-1"><a href="sec74.html#cb32-1" tabindex="-1"></a>betatilde1 <span class="ot">&lt;-</span> Results<span class="sc">$</span>betadraw[,<span class="dv">1</span><span class="sc">:</span><span class="dv">7</span>] <span class="sc">/</span> <span class="fu">sqrt</span>(Results<span class="sc">$</span>sigmadraw[,<span class="dv">1</span>])</span>
<span id="cb32-2"><a href="sec74.html#cb32-2" tabindex="-1"></a><span class="fu">summary</span>(coda<span class="sc">::</span><span class="fu">mcmc</span>(betatilde1))</span></code></pre></div>
<pre><code>## 
## Iterations = 1:4000
## Thinning interval = 1 
## Number of chains = 1 
## Sample size per chain = 4000 
## 
## 1. Empirical mean and standard deviation for each variable,
##    plus standard error of the mean:
## 
##           Mean      SD  Naive SE Time-series SE
## [1,] -0.973678 0.12756 0.0020170      2.414e-03
## [2,]  0.122745 0.04872 0.0007704      1.326e-03
## [3,]  0.002941 0.00110 0.0000174      2.577e-05
## [4,] -0.522298 0.11435 0.0018080      1.781e-03
## [5,] -1.234641 0.11131 0.0017599      1.859e-03
## [6,] -1.093871 0.13165 0.0020816      2.591e-03
## [7,] -0.064123 0.05942 0.0009395      1.619e-03
## 
## 2. Quantiles for each variable:
## 
##            2.5%       25%       50%       75%     97.5%
## var1 -1.2247602 -1.059257 -0.970870 -0.889741 -0.733411
## var2  0.0269885  0.090098  0.121863  0.155585  0.220662
## var3  0.0007652  0.002207  0.002925  0.003685  0.005049
## var4 -0.7477149 -0.598898 -0.522549 -0.445173 -0.296718
## var5 -1.4520842 -1.309922 -1.234633 -1.160468 -1.018396
## var6 -1.3503717 -1.182381 -1.092511 -1.005472 -0.837939
## var7 -0.1791758 -0.103506 -0.064418 -0.024499  0.051849</code></pre>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb34-1"><a href="sec74.html#cb34-1" tabindex="-1"></a>betatilde2 <span class="ot">&lt;-</span> Results<span class="sc">$</span>betadraw[,<span class="dv">8</span><span class="sc">:</span><span class="dv">14</span>] <span class="sc">/</span> <span class="fu">sqrt</span>(Results<span class="sc">$</span>sigmadraw[,<span class="dv">4</span>])</span>
<span id="cb34-2"><a href="sec74.html#cb34-2" tabindex="-1"></a><span class="fu">summary</span>(coda<span class="sc">::</span><span class="fu">mcmc</span>(betatilde2))</span></code></pre></div>
<pre><code>## 
## Iterations = 1:4000
## Thinning interval = 1 
## Number of chains = 1 
## Sample size per chain = 4000 
## 
## 1. Empirical mean and standard deviation for each variable,
##    plus standard error of the mean:
## 
##           Mean        SD  Naive SE Time-series SE
## [1,]  0.567199 0.1346170 2.128e-03      2.409e-03
## [2,]  0.306014 0.0242202 3.830e-04      3.672e-04
## [3,]  0.009125 0.0006758 1.068e-05      1.109e-05
## [4,] -0.221882 0.1347631 2.131e-03      2.447e-03
## [5,] -0.421087 0.1307593 2.067e-03      2.364e-03
## [6,] -0.435578 0.1370951 2.168e-03      2.449e-03
## [7,]  0.224500 0.0304865 4.820e-04      4.829e-04
## 
## 2. Quantiles for each variable:
## 
##           2.5%       25%       50%       75%    97.5%
## var1  0.306343  0.477265  0.564698  0.656616  0.82932
## var2  0.258347  0.289819  0.305902  0.322116  0.35284
## var3  0.007848  0.008656  0.009124  0.009591  0.01045
## var4 -0.488810 -0.313532 -0.218459 -0.130373  0.04144
## var5 -0.677686 -0.511529 -0.418139 -0.332415 -0.17322
## var6 -0.703355 -0.527642 -0.433378 -0.341355 -0.16989
## var7  0.164388  0.203623  0.224533  0.245306  0.28513</code></pre>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb36-1"><a href="sec74.html#cb36-1" tabindex="-1"></a>sigmadraw12 <span class="ot">&lt;-</span>  Results<span class="sc">$</span>sigmadraw[,<span class="dv">3</span>] <span class="sc">/</span> (Results<span class="sc">$</span>sigmadraw[,<span class="dv">1</span>]<span class="sc">*</span>Results<span class="sc">$</span>sigmadraw[,<span class="dv">4</span>])<span class="sc">^</span><span class="fl">0.5</span></span>
<span id="cb36-2"><a href="sec74.html#cb36-2" tabindex="-1"></a><span class="fu">summary</span>(coda<span class="sc">::</span><span class="fu">mcmc</span>(sigmadraw12))</span></code></pre></div>
<pre><code>## 
## Iterations = 1:4000
## Thinning interval = 1 
## Number of chains = 1 
## Sample size per chain = 4000 
## 
## 1. Empirical mean and standard deviation for each variable,
##    plus standard error of the mean:
## 
##           Mean             SD       Naive SE Time-series SE 
##      -0.003338       0.033076       0.000523       0.001288 
## 
## 2. Quantiles for each variable:
## 
##      2.5%       25%       50%       75%     97.5% 
## -0.070515 -0.025009 -0.002895  0.018432  0.060986</code></pre>
<p>The previous <strong>R</strong> code demonstrates how to obtain the posterior draws using the <em>rmvpGibbs</em> command from the <em>bayesm</em> package. The results suggest that females, older individuals, and those who self-assess their health as poor are more likely to be hospitalized. Furthermore, females, older individuals, and those with a poor or fair self-perception of health, who have lived a larger proportion of their life in their current neighborhood, are more likely to be enrolled in the subsidized health care system. However, the results indicate that there is no unobserved correlation between the two equations, as the 95% credible interval for the correlation is (-0.07, 0.06).</p>
</div>
<h3>References<a href="references.html#references" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-Edwards2003" class="csl-entry">
Edwards, Y. D., and G. M. Allenby. 2003. <span>“Multivariate Analysis of Multiple Response Data.”</span> <em>Journal of Marketing Research</em> 40: 321–34.
</div>
<div id="ref-Ramirez2019a" class="csl-entry">
Ramírez-Hassan, A., and R. Guerra-Urzola. 2021. <span>“Bayesian Treatment Effects Due to a Subsidized Health Program: The Case of Preventive Health Care Utilization in Medellín (<span>C</span>olombia).”</span> <em>Empirical Economics</em> 60: 1477–1506.
</div>
</div>
<div class="footnotes">
<hr />
<ol start="8">
<li id="fn8"><p>In a Bayesian setting, a model can be non-identified; however, the posterior distribution of the model parameters exists as long as a proper prior distribution is specified <span class="citation">Edwards and Allenby (<a href="#ref-Edwards2003">2003</a>)</span>.<a href="sec74.html#fnref8" class="footnote-back">↩︎</a></p></li>
<li id="fn9"><p>Note that the order of the location coefficients in our GUI follows the equations, not the order of the regressors as in the theoretical setting presented in this section. This distinction is important for correctly setting the hyperparameters and interpreting the results of the location parameters.<a href="sec74.html#fnref9" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="sec73.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="sec75.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": true,
    "facebook": true,
    "twitter": true,
    "linkedin": false,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": false,
    "all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
  },
  "fontsettings": {
    "theme": "white",
    "family": "sans",
    "size": 2
  },
  "edit": {
    "link": "https://github.com/aramir21/IntroductionBayesianEconometricsBook/07-Multivariatereg.Rmd",
    "text": "Edit"
  },
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": null,
    "text": null
  },
  "download": null,
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "subsection"
  }
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
