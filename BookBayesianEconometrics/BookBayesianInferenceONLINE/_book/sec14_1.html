<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>14.1 Simulation-based approaches | Introduction to Bayesian Data Modeling</title>
  <meta name="description" content="The subject of this textbook is Bayesian data modeling, with the primary aim of providing an introduction to its theoretical foundations and facilitating the application of Bayesian inference using a GUI." />
  <meta name="generator" content="bookdown 0.43 and GitBook 2.6.7" />

  <meta property="og:title" content="14.1 Simulation-based approaches | Introduction to Bayesian Data Modeling" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="The subject of this textbook is Bayesian data modeling, with the primary aim of providing an introduction to its theoretical foundations and facilitating the application of Bayesian inference using a GUI." />
  <meta name="github-repo" content="https://github.com/aramir21/IntroductionBayesianEconometricsBook" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="14.1 Simulation-based approaches | Introduction to Bayesian Data Modeling" />
  
  <meta name="twitter:description" content="The subject of this textbook is Bayesian data modeling, with the primary aim of providing an introduction to its theoretical foundations and facilitating the application of Bayesian inference using a GUI." />
  

<meta name="author" content="Andrés Ramírez-Hassan" />


<meta name="date" content="2025-04-30" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="Chap14.html"/>
<link rel="next" href="sec14_2.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Introduction to Bayesian Econometrics: A GUIded tour using R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction</a>
<ul>
<li class="chapter" data-level="" data-path="to-instructors-and-students.html"><a href="to-instructors-and-students.html"><i class="fa fa-check"></i>To instructors and students</a></li>
<li class="chapter" data-level="" data-path="acknowledgments.html"><a href="acknowledgments.html"><i class="fa fa-check"></i>Acknowledgments</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="Chap1.html"><a href="Chap1.html"><i class="fa fa-check"></i><b>1</b> Basic formal concepts</a>
<ul>
<li class="chapter" data-level="1.1" data-path="sec11.html"><a href="sec11.html"><i class="fa fa-check"></i><b>1.1</b> The Bayes’ rule</a></li>
<li class="chapter" data-level="1.2" data-path="sec12.html"><a href="sec12.html"><i class="fa fa-check"></i><b>1.2</b> Bayesian framework: A brief summary of theory</a></li>
<li class="chapter" data-level="1.3" data-path="sec14.html"><a href="sec14.html"><i class="fa fa-check"></i><b>1.3</b> Bayesian reports: Decision theory under uncertainty</a></li>
<li class="chapter" data-level="1.4" data-path="summary.html"><a href="summary.html"><i class="fa fa-check"></i><b>1.4</b> Summary</a></li>
<li class="chapter" data-level="1.5" data-path="exercises.html"><a href="exercises.html"><i class="fa fa-check"></i><b>1.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="Chap2.html"><a href="Chap2.html"><i class="fa fa-check"></i><b>2</b> Conceptual differences between the Bayesian and Frequentist approaches</a>
<ul>
<li class="chapter" data-level="2.1" data-path="sec21.html"><a href="sec21.html"><i class="fa fa-check"></i><b>2.1</b> The concept of probability</a></li>
<li class="chapter" data-level="2.2" data-path="sec22.html"><a href="sec22.html"><i class="fa fa-check"></i><b>2.2</b> Subjectivity is not the key</a></li>
<li class="chapter" data-level="2.3" data-path="sec23.html"><a href="sec23.html"><i class="fa fa-check"></i><b>2.3</b> Estimation, hypothesis testing and prediction</a></li>
<li class="chapter" data-level="2.4" data-path="sec24.html"><a href="sec24.html"><i class="fa fa-check"></i><b>2.4</b> The likelihood principle</a></li>
<li class="chapter" data-level="2.5" data-path="sec25.html"><a href="sec25.html"><i class="fa fa-check"></i><b>2.5</b> Why is not the Bayesian approach that popular?</a></li>
<li class="chapter" data-level="2.6" data-path="sec26.html"><a href="sec26.html"><i class="fa fa-check"></i><b>2.6</b> A simple working example</a></li>
<li class="chapter" data-level="2.7" data-path="sec27.html"><a href="sec27.html"><i class="fa fa-check"></i><b>2.7</b> Summary</a></li>
<li class="chapter" data-level="2.8" data-path="sec28.html"><a href="sec28.html"><i class="fa fa-check"></i><b>2.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="Chap3.html"><a href="Chap3.html"><i class="fa fa-check"></i><b>3</b> Cornerstone models: Conjugate families</a>
<ul>
<li class="chapter" data-level="3.1" data-path="sec41.html"><a href="sec41.html"><i class="fa fa-check"></i><b>3.1</b> Motivation of conjugate families</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="sec41.html"><a href="sec41.html#examples-of-exponential-family-distributions"><i class="fa fa-check"></i><b>3.1.1</b> Examples of exponential family distributions</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="sec42.html"><a href="sec42.html"><i class="fa fa-check"></i><b>3.2</b> Conjugate prior to exponential family</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="sec42.html"><a href="sec42.html#sec421"><i class="fa fa-check"></i><b>3.2.1</b> Examples: Theorem 4.2.1</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="sec43.html"><a href="sec43.html"><i class="fa fa-check"></i><b>3.3</b> Linear regression: The conjugate normal-normal/inverse gamma model</a></li>
<li class="chapter" data-level="3.4" data-path="sec44.html"><a href="sec44.html"><i class="fa fa-check"></i><b>3.4</b> Multivariate linear regression: The conjugate normal-normal/inverse Wishart model</a></li>
<li class="chapter" data-level="3.5" data-path="sec45.html"><a href="sec45.html"><i class="fa fa-check"></i><b>3.5</b> Summary</a></li>
<li class="chapter" data-level="3.6" data-path="sec46.html"><a href="sec46.html"><i class="fa fa-check"></i><b>3.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="Chap4.html"><a href="Chap4.html"><i class="fa fa-check"></i><b>4</b> Simulation methods</a>
<ul>
<li class="chapter" data-level="4.1" data-path="sec51.html"><a href="sec51.html"><i class="fa fa-check"></i><b>4.1</b> Markov Chain Monte Carlo methods</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="sec51.html"><a href="sec51.html#sec511"><i class="fa fa-check"></i><b>4.1.1</b> Gibbs sampler</a></li>
<li class="chapter" data-level="4.1.2" data-path="sec51.html"><a href="sec51.html#sec512"><i class="fa fa-check"></i><b>4.1.2</b> Metropolis-Hastings</a></li>
<li class="chapter" data-level="4.1.3" data-path="sec51.html"><a href="sec51.html#sec513"><i class="fa fa-check"></i><b>4.1.3</b> Hamiltonian Monte Carlo</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="sec52.html"><a href="sec52.html"><i class="fa fa-check"></i><b>4.2</b> Importance sampling</a></li>
<li class="chapter" data-level="4.3" data-path="sec53.html"><a href="sec53.html"><i class="fa fa-check"></i><b>4.3</b> Particle filtering</a></li>
<li class="chapter" data-level="4.4" data-path="sec54.html"><a href="sec54.html"><i class="fa fa-check"></i><b>4.4</b> Convergence diagnostics</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="sec54.html"><a href="sec54.html#numerical-standard-error"><i class="fa fa-check"></i><b>4.4.1</b> Numerical standard error</a></li>
<li class="chapter" data-level="4.4.2" data-path="sec54.html"><a href="sec54.html#effective-number-of-simulation-draws"><i class="fa fa-check"></i><b>4.4.2</b> Effective number of simulation draws</a></li>
<li class="chapter" data-level="4.4.3" data-path="sec54.html"><a href="sec54.html#tests-of-convergence"><i class="fa fa-check"></i><b>4.4.3</b> Tests of convergence</a></li>
<li class="chapter" data-level="4.4.4" data-path="sec54.html"><a href="sec54.html#checking-for-errors-in-the-posterior-simulator"><i class="fa fa-check"></i><b>4.4.4</b> Checking for errors in the posterior simulator</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="sec55.html"><a href="sec55.html"><i class="fa fa-check"></i><b>4.5</b> Summary</a></li>
<li class="chapter" data-level="4.6" data-path="sec56.html"><a href="sec56.html"><i class="fa fa-check"></i><b>4.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="Chap5.html"><a href="Chap5.html"><i class="fa fa-check"></i><b>5</b> Graphical user interface</a>
<ul>
<li class="chapter" data-level="5.1" data-path="secGUI1.html"><a href="secGUI1.html"><i class="fa fa-check"></i><b>5.1</b> Introduction</a></li>
<li class="chapter" data-level="5.2" data-path="secGUI2.html"><a href="secGUI2.html"><i class="fa fa-check"></i><b>5.2</b> Univariate models</a></li>
<li class="chapter" data-level="5.3" data-path="secGUI3.html"><a href="secGUI3.html"><i class="fa fa-check"></i><b>5.3</b> Multivariate models</a></li>
<li class="chapter" data-level="5.4" data-path="secGUI4.html"><a href="secGUI4.html"><i class="fa fa-check"></i><b>5.4</b> Time series models</a></li>
<li class="chapter" data-level="5.5" data-path="secGUI5.html"><a href="secGUI5.html"><i class="fa fa-check"></i><b>5.5</b> Longitudinal/panel models</a></li>
<li class="chapter" data-level="5.6" data-path="secGUI6.html"><a href="secGUI6.html"><i class="fa fa-check"></i><b>5.6</b> Bayesian model average</a></li>
<li class="chapter" data-level="5.7" data-path="secGUI7.html"><a href="secGUI7.html"><i class="fa fa-check"></i><b>5.7</b> Help</a></li>
<li class="chapter" data-level="5.8" data-path="secGUI8.html"><a href="secGUI8.html"><i class="fa fa-check"></i><b>5.8</b> Warning</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="Chap6.html"><a href="Chap6.html"><i class="fa fa-check"></i><b>6</b> Univariate regression</a>
<ul>
<li class="chapter" data-level="6.1" data-path="sec61.html"><a href="sec61.html"><i class="fa fa-check"></i><b>6.1</b> The Gaussian linear model</a></li>
<li class="chapter" data-level="6.2" data-path="sec62.html"><a href="sec62.html"><i class="fa fa-check"></i><b>6.2</b> The logit model</a></li>
<li class="chapter" data-level="6.3" data-path="sec63.html"><a href="sec63.html"><i class="fa fa-check"></i><b>6.3</b> The probit model</a></li>
<li class="chapter" data-level="6.4" data-path="sec64.html"><a href="sec64.html"><i class="fa fa-check"></i><b>6.4</b> The multinomial probit model</a></li>
<li class="chapter" data-level="6.5" data-path="sec65.html"><a href="sec65.html"><i class="fa fa-check"></i><b>6.5</b> The multinomial logit model</a></li>
<li class="chapter" data-level="6.6" data-path="sec66.html"><a href="sec66.html"><i class="fa fa-check"></i><b>6.6</b> Ordered probit model</a></li>
<li class="chapter" data-level="6.7" data-path="negative-binomial-model.html"><a href="negative-binomial-model.html"><i class="fa fa-check"></i><b>6.7</b> Negative binomial model</a></li>
<li class="chapter" data-level="6.8" data-path="sec68.html"><a href="sec68.html"><i class="fa fa-check"></i><b>6.8</b> Tobit model</a></li>
<li class="chapter" data-level="6.9" data-path="sec69.html"><a href="sec69.html"><i class="fa fa-check"></i><b>6.9</b> Quantile regression</a></li>
<li class="chapter" data-level="6.10" data-path="sec610.html"><a href="sec610.html"><i class="fa fa-check"></i><b>6.10</b> Bayesian bootstrap regression</a></li>
<li class="chapter" data-level="6.11" data-path="sec611.html"><a href="sec611.html"><i class="fa fa-check"></i><b>6.11</b> Summary</a></li>
<li class="chapter" data-level="6.12" data-path="sec612.html"><a href="sec612.html"><i class="fa fa-check"></i><b>6.12</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="Chap7.html"><a href="Chap7.html"><i class="fa fa-check"></i><b>7</b> Multivariate regression</a>
<ul>
<li class="chapter" data-level="7.1" data-path="sec71.html"><a href="sec71.html"><i class="fa fa-check"></i><b>7.1</b> Multivariate regression</a></li>
<li class="chapter" data-level="7.2" data-path="sec72.html"><a href="sec72.html"><i class="fa fa-check"></i><b>7.2</b> Seemingly Unrelated Regression</a></li>
<li class="chapter" data-level="7.3" data-path="sec73.html"><a href="sec73.html"><i class="fa fa-check"></i><b>7.3</b> Instrumental variable</a></li>
<li class="chapter" data-level="7.4" data-path="sec74.html"><a href="sec74.html"><i class="fa fa-check"></i><b>7.4</b> Multivariate probit model</a></li>
<li class="chapter" data-level="7.5" data-path="sec75.html"><a href="sec75.html"><i class="fa fa-check"></i><b>7.5</b> Summary</a></li>
<li class="chapter" data-level="7.6" data-path="sec76.html"><a href="sec76.html"><i class="fa fa-check"></i><b>7.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="Chap8.html"><a href="Chap8.html"><i class="fa fa-check"></i><b>8</b> Time series</a>
<ul>
<li class="chapter" data-level="8.1" data-path="sec81.html"><a href="sec81.html"><i class="fa fa-check"></i><b>8.1</b> State-space representation</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="sec81.html"><a href="sec81.html#gaussian-linear-state-space-models"><i class="fa fa-check"></i><b>8.1.1</b> Gaussian linear state-space models</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="sec82.html"><a href="sec82.html"><i class="fa fa-check"></i><b>8.2</b> ARMA processes</a></li>
<li class="chapter" data-level="8.3" data-path="sec83.html"><a href="sec83.html"><i class="fa fa-check"></i><b>8.3</b> Stochastic volatility models</a></li>
<li class="chapter" data-level="8.4" data-path="sec84.html"><a href="sec84.html"><i class="fa fa-check"></i><b>8.4</b> Vector Autoregressive models</a></li>
<li class="chapter" data-level="8.5" data-path="sec85.html"><a href="sec85.html"><i class="fa fa-check"></i><b>8.5</b> Summary</a></li>
<li class="chapter" data-level="8.6" data-path="sec86.html"><a href="sec86.html"><i class="fa fa-check"></i><b>8.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="Chap9.html"><a href="Chap9.html"><i class="fa fa-check"></i><b>9</b> Longitudinal regression</a>
<ul>
<li class="chapter" data-level="9.1" data-path="sec91.html"><a href="sec91.html"><i class="fa fa-check"></i><b>9.1</b> Normal model</a></li>
<li class="chapter" data-level="9.2" data-path="sec92.html"><a href="sec92.html"><i class="fa fa-check"></i><b>9.2</b> Logit model</a></li>
<li class="chapter" data-level="9.3" data-path="sec93.html"><a href="sec93.html"><i class="fa fa-check"></i><b>9.3</b> Poisson model</a></li>
<li class="chapter" data-level="9.4" data-path="sec94.html"><a href="sec94.html"><i class="fa fa-check"></i><b>9.4</b> Summary</a></li>
<li class="chapter" data-level="9.5" data-path="sec95.html"><a href="sec95.html"><i class="fa fa-check"></i><b>9.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="Chap10.html"><a href="Chap10.html"><i class="fa fa-check"></i><b>10</b> Bayesian model averaging in variable selection</a>
<ul>
<li class="chapter" data-level="10.1" data-path="sec10_1.html"><a href="sec10_1.html"><i class="fa fa-check"></i><b>10.1</b> Foundation</a></li>
<li class="chapter" data-level="10.2" data-path="sec102.html"><a href="sec102.html"><i class="fa fa-check"></i><b>10.2</b> The Gaussian linear model</a></li>
<li class="chapter" data-level="10.3" data-path="sec103.html"><a href="sec103.html"><i class="fa fa-check"></i><b>10.3</b> Generalized linear models</a></li>
<li class="chapter" data-level="10.4" data-path="sec10_4.html"><a href="sec10_4.html"><i class="fa fa-check"></i><b>10.4</b> Calculating the marginal likelihood</a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="sec10_4.html"><a href="sec10_4.html#sec10_4_1"><i class="fa fa-check"></i><b>10.4.1</b> Savage-Dickey density ratio</a></li>
<li class="chapter" data-level="10.4.2" data-path="sec10_4.html"><a href="sec10_4.html#sec10_4_2"><i class="fa fa-check"></i><b>10.4.2</b> Chib’s methods</a></li>
<li class="chapter" data-level="10.4.3" data-path="sec10_4.html"><a href="sec10_4.html#sec10_4_3"><i class="fa fa-check"></i><b>10.4.3</b> Gelfand-Dey method</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="sec10_5.html"><a href="sec10_5.html"><i class="fa fa-check"></i><b>10.5</b> Summary</a></li>
<li class="chapter" data-level="10.6" data-path="sec10_6.html"><a href="sec10_6.html"><i class="fa fa-check"></i><b>10.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="Chap11.html"><a href="Chap11.html"><i class="fa fa-check"></i><b>11</b> Semi-parametric and non-parametric models</a>
<ul>
<li class="chapter" data-level="11.1" data-path="sec11_1.html"><a href="sec11_1.html"><i class="fa fa-check"></i><b>11.1</b> Mixture models</a>
<ul>
<li class="chapter" data-level="11.1.1" data-path="sec11_1.html"><a href="sec11_1.html#sec11_11"><i class="fa fa-check"></i><b>11.1.1</b> Finite Gaussian mixtures</a></li>
<li class="chapter" data-level="11.1.2" data-path="sec11_1.html"><a href="sec11_1.html#sec11_12"><i class="fa fa-check"></i><b>11.1.2</b> Direchlet processes</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="sec11_2.html"><a href="sec11_2.html"><i class="fa fa-check"></i><b>11.2</b> Splines</a></li>
<li class="chapter" data-level="11.3" data-path="sec11_3.html"><a href="sec11_3.html"><i class="fa fa-check"></i><b>11.3</b> Summary</a></li>
<li class="chapter" data-level="11.4" data-path="sec11_4.html"><a href="sec11_4.html"><i class="fa fa-check"></i><b>11.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="Chap12.html"><a href="Chap12.html"><i class="fa fa-check"></i><b>12</b> Machine learning</a>
<ul>
<li class="chapter" data-level="12.1" data-path="sec12_1.html"><a href="sec12_1.html"><i class="fa fa-check"></i><b>12.1</b> Cross validation and Bayes factors</a></li>
<li class="chapter" data-level="12.2" data-path="sec12_2.html"><a href="sec12_2.html"><i class="fa fa-check"></i><b>12.2</b> Regularization</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="sec12_2.html"><a href="sec12_2.html#sec12_21"><i class="fa fa-check"></i><b>12.2.1</b> Bayesian LASSO</a></li>
<li class="chapter" data-level="12.2.2" data-path="sec12_2.html"><a href="sec12_2.html#sec12_22"><i class="fa fa-check"></i><b>12.2.2</b> Stochastic search variable selection</a></li>
<li class="chapter" data-level="12.2.3" data-path="sec12_2.html"><a href="sec12_2.html#sec12_23"><i class="fa fa-check"></i><b>12.2.3</b> Non-local priors</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="sec12_3.html"><a href="sec12_3.html"><i class="fa fa-check"></i><b>12.3</b> Bayesian additive regression trees</a></li>
<li class="chapter" data-level="12.4" data-path="sec12_4.html"><a href="sec12_4.html"><i class="fa fa-check"></i><b>12.4</b> Gaussian processes</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="Chap13.html"><a href="Chap13.html"><i class="fa fa-check"></i><b>13</b> Causal inference</a>
<ul>
<li class="chapter" data-level="13.1" data-path="sec13_1.html"><a href="sec13_1.html"><i class="fa fa-check"></i><b>13.1</b> Instrumental variables</a>
<ul>
<li class="chapter" data-level="13.1.1" data-path="sec13_1.html"><a href="sec13_1.html#sec13_11"><i class="fa fa-check"></i><b>13.1.1</b> Semi-parametric IV model</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="sec13_2.html"><a href="sec13_2.html"><i class="fa fa-check"></i><b>13.2</b> Regression discontinuity design</a></li>
<li class="chapter" data-level="13.3" data-path="sec13_3.html"><a href="sec13_3.html"><i class="fa fa-check"></i><b>13.3</b> Regression kink design</a></li>
<li class="chapter" data-level="13.4" data-path="sec13_4.html"><a href="sec13_4.html"><i class="fa fa-check"></i><b>13.4</b> Synthetic control</a></li>
<li class="chapter" data-level="13.5" data-path="sec13_5.html"><a href="sec13_5.html"><i class="fa fa-check"></i><b>13.5</b> Difference in difference estimation</a></li>
<li class="chapter" data-level="13.6" data-path="sec13_6.html"><a href="sec13_6.html"><i class="fa fa-check"></i><b>13.6</b> Event Analysis</a></li>
<li class="chapter" data-level="13.7" data-path="sec13_7.html"><a href="sec13_7.html"><i class="fa fa-check"></i><b>13.7</b> Bayesian exponential tilted empirical likelihood</a></li>
<li class="chapter" data-level="13.8" data-path="sec13_8.html"><a href="sec13_8.html"><i class="fa fa-check"></i><b>13.8</b> Double-Debiased machine learning causal effects</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="Chap14.html"><a href="Chap14.html"><i class="fa fa-check"></i><b>14</b> Approximate Bayesian methods</a>
<ul>
<li class="chapter" data-level="14.1" data-path="sec14_1.html"><a href="sec14_1.html"><i class="fa fa-check"></i><b>14.1</b> Simulation-based approaches</a>
<ul>
<li class="chapter" data-level="14.1.1" data-path="sec14_1.html"><a href="sec14_1.html#sec14_11"><i class="fa fa-check"></i><b>14.1.1</b> Approximate Bayesian computation</a></li>
<li class="chapter" data-level="14.1.2" data-path="sec14_1.html"><a href="sec14_1.html#sec14_12"><i class="fa fa-check"></i><b>14.1.2</b> Bayesian synthetic likelihood</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="sec14_2.html"><a href="sec14_2.html"><i class="fa fa-check"></i><b>14.2</b> Optimization approaches</a>
<ul>
<li class="chapter" data-level="14.2.1" data-path="sec14_2.html"><a href="sec14_2.html#sec14_21"><i class="fa fa-check"></i><b>14.2.1</b> Integrated nested Laplace approximations</a></li>
<li class="chapter" data-level="14.2.2" data-path="sec14_2.html"><a href="sec14_2.html#sec14_22"><i class="fa fa-check"></i><b>14.2.2</b> Variational Bayes</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="summary-1.html"><a href="summary-1.html"><i class="fa fa-check"></i><b>14.3</b> Summary</a></li>
<li class="chapter" data-level="14.4" data-path="sec14_4.html"><a href="sec14_4.html"><i class="fa fa-check"></i><b>14.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i>Appendix</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to Bayesian Data Modeling</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="sec14_1" class="section level2 hasAnchor" number="14.1">
<h2><span class="header-section-number">14.1</span> Simulation-based approaches<a href="sec14_1.html#sec14_1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Taking into account the fundamental equation for performing parameter inference in the Bayesian framework,<br />
<span class="math display">\[\begin{align*}
    \pi(\boldsymbol{\theta} \mid \mathbf{y}) &amp; \propto p(\mathbf{y} \mid \boldsymbol{\theta}) \times \pi(\boldsymbol{\theta}),
\end{align*}\]</span><br />
we see in Section <a href="sec51.html#sec51">4.1</a> that MCMC algorithms, such as the Gibbs sampler (Section <a href="sec51.html#sec511">4.1.1</a> and Metropolis-Hastings (Section <a href="sec51.html#sec512">4.1.2</a>), require evaluation of the likelihood function <span class="math inline">\(p(\boldsymbol{y} \mid \boldsymbol{\theta})\)</span> in the posterior conditional distribution or the acceptance probability, respectively. This is also the case for importance sampling when calculating the importance weights (Section <a href="sec52.html#sec52">4.2</a>).</p>
<p>Thus, what happens when the likelihood function does not have an analytical expression? This situation arises in many models involving unobserved heterogeneity (i.e., unobserved taste preferences), models defined by quantile functions (e.g., the g-and-k distribution), or dynamic equilibrium models (e.g., repeated game models).</p>
<p><em>Simulation-based algorithms</em> provide a Bayesian solution when we face this situation, namely, when the likelihood function lacks an analytical expression or is highly complex. The only requirement is that we must be able to simulate synthetic data from the model conditional on the parameters. Therefore, these algorithms obtain an approximation to the posterior draws by simulating from the prior distribution <span class="math inline">\(\pi(\boldsymbol{\theta})\)</span> and then using these draws to simulate from the likelihood <span class="math inline">\(p(\mathbf{y} \mid \boldsymbol{\theta})\)</span>.</p>
<div id="sec14_11" class="section level3 hasAnchor" number="14.1.1">
<h3><span class="header-section-number">14.1.1</span> Approximate Bayesian computation<a href="sec14_1.html#sec14_11" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><em>Approximate Bayesian Computation</em> (ABC) is designed to handle inferential situations where the likelihood function <span class="math inline">\(p(\boldsymbol{y} \mid \boldsymbol{\theta})\)</span> is intractable or highly complex, with <span class="math inline">\(\boldsymbol{y} \in \mathbb{R}^N\)</span>. It was introduced in population genetics by <span class="citation">Tavaré et al. (<a href="#ref-tavare1997inferring">1997</a>)</span> and <span class="citation">Pritchard et al. (<a href="#ref-pritchard1999population">1999</a>)</span>, and later generalized by <span class="citation">Beaumont, Zhang, and Balding (<a href="#ref-beaumont2002approximate">2002</a>)</span>. The basic intuitive origin of ABC appears to have been introduced by <span class="citation">Rubin (<a href="#ref-rubin1984Bayesianly">1984</a>)</span>. A growing body of literature explores its applications in biology, cosmology, finance, economics, and other fields.</p>
<p>The requirement in ABC is the ability to simulate from the parametric model. The process begins by drawing samples from the prior distribution <span class="math inline">\(\pi(\boldsymbol{\theta})\)</span> multiple times, where <span class="math inline">\(\boldsymbol{\theta} \in \mathbb{R}^K\)</span>, and then simulating data from the model given each draw <span class="math inline">\(\boldsymbol{\theta}^{(s)}\)</span>, for <span class="math inline">\(s = 1, 2, \dots, S\)</span>. The resulting synthetic data, <span class="math inline">\(\boldsymbol{z}^{(s)} \in \mathbb{R}^N\)</span>, is used to compute summary statistics <span class="math inline">\(\boldsymbol{\eta}(\boldsymbol{z}^{(s)}) \in \mathbb{R}^L\)</span>, with <span class="math inline">\(L \geq K\)</span>. These summary statistics are crucial for the performance of ABC and should be selected based on a thorough understanding of the model.</p>
<p>Next, we compare the synthetic summary statistics with the observed summary statistics <span class="math inline">\(\boldsymbol{\eta}(\boldsymbol{y})\)</span> using a distance metric <span class="math inline">\(d\left\{ \boldsymbol\eta(\boldsymbol{y}), \boldsymbol\eta(\boldsymbol{z}^{(s)}) \right\}\)</span>, typically the Euclidean distance. We retain the prior draws that generate synthetic summary statistics closest to the observed ones, that is, those for which<br />
<span class="math display">\[ d\left\{ \boldsymbol\eta(\boldsymbol{y}), \boldsymbol\eta(\boldsymbol{z}^{(s)}) \right\} \leq \epsilon, \]</span><br />
forming an approximation of the posterior distribution<br />
<span class="math display">\[ \pi_{\epsilon}(\boldsymbol{\theta}, \boldsymbol{z} \mid \boldsymbol{\eta}(\boldsymbol{y})). \]</span></p>
<p>The simplest algorithm is the accept/reject approximate Bayesian computation (ABC-AR):</p>
<div class="algorithm">
<div style="background-color: #f8f9fa; padding: 15px; border-left: 5px solid #343a40; box-shadow: 4px 4px 10px rgba(0, 0, 0, 0.1); border-radius: 5px;">
<p><strong>Algorithm: Accept/reject ABC</strong></p>
<ol style="list-style-type: decimal">
<li>For <span class="math inline">\(s = 1, \dots, S\)</span>:
<ul>
<li>Draw <span class="math inline">\(\boldsymbol{\theta}^{(s)}\)</span> from the prior <span class="math inline">\(\pi(\boldsymbol{\theta})\)</span></li>
<li>Simulate <span class="math inline">\(\boldsymbol{z}^{(s)} = (z_1^{(s)}, z_2^{(s)}, \dots, z_n^{(s)})^\top\)</span> from the model <span class="math inline">\(p(\cdot \mid \boldsymbol{\theta}^{(s)})\)</span></li>
<li>Calculate the distance<br />
<span class="math display">\[
d_{(s)} = d\left\{ \boldsymbol{\eta}(\boldsymbol{y}), \boldsymbol{\eta}(\boldsymbol{z}^{(s)}) \right\}
\]</span></li>
</ul></li>
</ol>
<p>End for</p>
<ol start="2" style="list-style-type: decimal">
<li>Order the distances:<br />
<span class="math display">\[
d_{(1)} \leq d_{(2)} \leq \cdots \leq d_{(S)}
\]</span></li>
<li>Select all <span class="math inline">\(\boldsymbol{\theta}^{(s)}\)</span> such that <span class="math inline">\(d_{(s)} \leq \epsilon\)</span>, where <span class="math inline">\(\epsilon &gt; 0\)</span> is the tolerance level.</li>
</ol>
</div>
</div>
<p>Note that the posterior distribution is conditional on the summary statistics <span class="math inline">\(\boldsymbol{\eta}(\boldsymbol{y})\)</span> and the tolerance parameter <span class="math inline">\(\epsilon\)</span>. This implies that we obtain an approximation to the target distribution <span class="math inline">\(\pi(\boldsymbol{\theta} \mid \boldsymbol{y})\)</span>, that is, <span class="math inline">\(\pi(\boldsymbol{\theta} \mid \boldsymbol{\eta}(\boldsymbol{y}))\)</span>, because <span class="math inline">\(\boldsymbol{\eta}(\boldsymbol{y})\)</span> is not a sufficient statistic in most cases, and <span class="math inline">\(\epsilon &gt; 0\)</span>; these conditions introduce bias <span class="citation">(<a href="#ref-blum2010approximate">Blum 2010</a>)</span>. However, ABC performs well compared to full-likelihood approaches in low-dimensional parameter spaces <span class="citation">(<a href="#ref-beaumont2002approximate">Beaumont, Zhang, and Balding 2002</a>)</span>.</p>
<p>Furthermore, <span class="citation">D. T. Frazier et al. (<a href="#ref-frazier2018asymptotic">2018</a>)</span> show in Theorems 1 and 2 that Bayesian consistency and asymptotic normality hold, provided that <span class="math inline">\(\epsilon \to 0\)</span> fast enough as <span class="math inline">\(N \to +\infty\)</span>. In particular, the requirement is that the proportion of accepted draws converges to 0 at a rate faster than <span class="math inline">\(N^{-K / 2}\)</span>. Additionally, Theorem 2 in <span class="citation">D. T. Frazier et al. (<a href="#ref-frazier2018asymptotic">2018</a>)</span> shows that <span class="math inline">\(100(1 - \alpha)\%\)</span> Bayesian credible regions using ABC have frequentist coverage of <span class="math inline">\(100(1 - \alpha)\%\)</span>.</p>
<p>We should note from these asymptotic results that ABC suffers from the <em>curse of dimensionality</em>. Specifically, given a sample size of 1,000 and two parameters, the proportion of accepted draws should be 0.1%, meaning we would require one million prior draws to obtain 1,000 posterior draws. On the other hand, if the number of parameters is three, we would require 31.62 million prior draws. This limitation of ABC has attracted attention; see Chapter 8 of <span class="citation">Sisson et al. (<a href="#ref-sisson2018handbook">2018</a>)</span> for some potential solutions.</p>
<p>It is common practice in ABC to perform a regression adjustment after retaining the draws <span class="citation">(<a href="#ref-beaumont2002approximate">Beaumont, Zhang, and Balding 2002</a>; <a href="#ref-leuenberger2010Bayesian">Leuenberger and Wegmann 2010</a>; <a href="#ref-sisson2018handbook">Sisson et al. 2018</a>)</span>. This adjustment reduces bias in posterior draws by performing a simple linear regression between the selected draws and the discrepancy between the observed and simulated summary statistics:
<span class="math display">\[
{\theta}^{(s)}_k = \alpha_k + \left(\boldsymbol{\eta}(\boldsymbol{y}) - \boldsymbol{\eta}(\boldsymbol{z}^{(s)})\right)^{\top} \boldsymbol{\beta}_k + \mu^{(s)}_k, \quad k = 1, 2, \dots, K
\]</span>
Then, the posterior draws are adjusted using the slope estimate:
<span class="math display">\[
{\theta}^{\text{adj},(s)}_k = {\theta}^{(s)}_k - \left(\boldsymbol{\eta}(\boldsymbol{y}) - \boldsymbol{\eta}(\boldsymbol{z}^{(s)})\right)^{\top} \hat{\boldsymbol{\beta}}_k
\]</span>
Other regression adjustment strategies are also used, such as local linear regression, ridge regression, and neural networks. See the <em>abc</em> package in <strong>R</strong>.</p>
<p>The favorable asymptotic sampling properties of ABC rely on correct model specification. <span class="citation">D. T. Frazier, Robert, and Rousseau (<a href="#ref-frazier2020model">2020</a>)</span> demonstrate that when the assumed model is misspecified, the asymptotic behavior of ABC can deteriorate. In particular, the posterior shape becomes asymptotically non-Gaussian, and the behavior of the posterior mean remains generally unknown. Additionally, regression adjustment approaches can produce posteriors that differ significantly from their simpler accept/reject counterparts.</p>
<p>Given these concerns, testing model specification in ABC is essential. This can be done using simulated goodness-of-fit statistics <span class="citation">(<a href="#ref-bertorelle2010abc">Bertorelle, Benazzo, and Mona 2010</a>; <a href="#ref-lintusaari2017fundamentals">Lintusaari et al. 2017</a>)</span>, predictive <em>p</em>-values <span class="citation">(<a href="#ref-bertorelle2010abc">Bertorelle, Benazzo, and Mona 2010</a>)</span>, discrepancy diagnostics <span class="citation">(<a href="#ref-frazier2020model">D. T. Frazier, Robert, and Rousseau 2020</a>)</span>, and asymptotic tests <span class="citation">(<a href="#ref-ramirez2024testing">Ramı́rez-Hassan and Frazier 2024</a>)</span> to evaluate model adequacy.</p>
<p>The accept/reject ABC algorithm is inefficient, as all draws are independent; thus, there is no learning from previous draws. This intensifies the computational burden. Therefore, <span class="citation">Marjoram et al. (<a href="#ref-marjoram2003markov">2003</a>)</span> and <span class="citation">Wegmann, Leuenberger, and Excoffier (<a href="#ref-wegmann2009efficient">2009</a>)</span> introduced Markov Chain Monte Carlo ABC (ABC-MCMC) algorithms, and <span class="citation">S. A. Sisson, Fan, and Tanaka (<a href="#ref-sisson2007sequential">2007</a>)</span>, <span class="citation">C. C. Drovandi and Pettitt (<a href="#ref-drovandi2011estimation">2011a</a>)</span>, <span class="citation">Del Moral, Doucet, and Jasra (<a href="#ref-del2012adaptive">2012</a>)</span>, and <span class="citation">Lenormand, Jabot, and Deffuant (<a href="#ref-lenormand2013adaptive">2013</a>)</span> proposed sequential Monte Carlo approaches (ABC-SMC). However, results comparing ABC-MCMC and ABC-SMC with ABC-AR are controversial regarding computational efficiency <span class="citation">(<a href="#ref-bertorelle2010abc">Bertorelle, Benazzo, and Mona 2010</a>)</span>. In addition, ABC-AR is very simple and easily allows parallel computing <span class="citation">(<a href="#ref-frazier2019approximate">D. T. Frazier et al. 2019</a>)</span>. Nevertheless, ABC-SMC is now the recommended approach, as it does not require tuning the algorithm’s tolerance <span class="citation">(<a href="#ref-martin2024approximating">Martin, Frazier, and Robert 2024</a>)</span>, and there are open-source implementations that facilitate its use.</p>
<p>New developments in ABC have focused on using empirical measures calculated from the observed (<span class="math inline">\(\hat{\mu}_n\)</span>) and synthetic (<span class="math inline">\(\hat{\mu}_{\boldsymbol{\theta}}^{(s)}\)</span>) data to replace summary statistics. Thus, <span class="math inline">\(d\left\{ \boldsymbol\eta (\boldsymbol y), \boldsymbol \eta (\boldsymbol z^{(s)}) \right\}\)</span> is replaced by <span class="math inline">\({D}\left\{ \hat{\mu}_n, \hat{\mu}_{\boldsymbol{\theta}}^{(s)} \right\}\)</span>, where the latter is a discrepancy measure, such as the Kullback-Leibler divergence <span class="citation">(<a href="#ref-jiang2018approximate">Jiang 2018</a>)</span>. However, <span class="citation">C. Drovandi and Frazier (<a href="#ref-drovandi2022comparison">2022</a>)</span> found in their simulation exercises that the best-performing summary statistics approach performs at least as well as the best discrepancy-measure approaches. The key point is to select informative summary statistics.</p>
<p><strong>Example: g-and-k distribution for financial returns</strong></p>
<p>The g-and-k distribution is a highly flexible distribution capable of capturing skewness and heavy tails through its parameters. This makes it particularly useful for modeling real-world data that deviate from normality, especially in fields like finance, where outliers are common. However, this distribution lacks a closed-form expression for its density function.</p>
<p>The g-and-k distribution is defined by its quantile function <span class="citation">(<a href="#ref-drovandi2011likelihood">C. C. Drovandi and Pettitt 2011b</a>)</span>. Specifically, it is specified through its inverse cumulative distribution function,</p>
<p><span class="math display">\[
Q(p \mid \theta) = F^{-1}(p \mid \theta),
\]</span></p>
<p>where <span class="math inline">\(F = P(U \leq u)\)</span>, and <span class="math inline">\(Q\)</span> represents the <span class="math inline">\(p\)</span>-quantile <span class="citation">(<a href="#ref-rayner2002numerical">Rayner and MacGillivray 2002</a>)</span>. The quantile function of the g-and-k distribution is given by</p>
<p><span class="math display">\[
Q^{gk}\left\{z(p) \mid a, b, c, g, k\right\} = a + b\left[1 + c \frac{1 - \exp\left\{-gz(p)\right\}}{1 + \exp\left\{-gz(p)\right\}}\right] \left\{1 + z(p)^2\right\}^k z(p),
\]</span></p>
<p>where <span class="math inline">\(z(p)\)</span> is the standard normal quantile function, and <span class="math inline">\(c = 0.8\)</span> is a commonly suggested value.</p>
<p>In the g-and-k distribution, <span class="math inline">\(a\)</span> is the location parameter, and <span class="math inline">\(b\)</span> is the scale parameter, controlling the dispersion. The parameters <span class="math inline">\(g\)</span> and <span class="math inline">\(k\)</span> determine the levels of skewness and kurtosis, respectively, while <span class="math inline">\(c\)</span> modifies the impact of skewness, and is typically set to 0.8.</p>
<p><span class="citation">C. C. Drovandi and Pettitt (<a href="#ref-drovandi2011likelihood">2011b</a>)</span> propose a moving average of order one using a g-and-k distribution to model exchange rate log returns. In particular,</p>
<p><span class="math display">\[
z_t = \epsilon_t + \theta_1 \epsilon_{t-1}, \quad t = 1, \dots, 524,
\]</span></p>
<p>where <span class="math inline">\(\epsilon_t \sim N(0,1)\)</span>.</p>
<p>The values of <span class="math inline">\(z_t\)</span> are then divided by <span class="math inline">\((1 + \theta_1^2)^{1/2}\)</span> to ensure that they marginally follow a standard normal distribution. Thus, simulating g-and-k data requires only substituting <span class="math inline">\(z_t\)</span> into the quantile function.</p>
<p>We model exchange rate log daily returns from USD/EUR one year before and after the WHO declared the COVID-19 pandemic on 11 March 2020. We use the dataset <em>ExchangeRate.csv</em> from our GitHub repository. Our ABC implementation uses twelve summary statistics: the seven octiles, the interquartile range, robust measures of skewness and kurtosis, and the autocorrelations of order one and two (see <span class="citation">C. C. Drovandi and Pettitt (<a href="#ref-drovandi2011likelihood">2011b</a>)</span> and code below). We adopt the prior distributions proposed by <span class="citation">Ramı́rez-Hassan and Frazier (<a href="#ref-ramirez2024testing">2024</a>)</span>:</p>
<p><span class="math display">\[
\theta_1 \sim U(-1,1), \quad a \sim U(0,5), \quad b \sim U(0,5), \quad g \sim U(-5,5), \quad k \sim U(-0.5, 5)
\]</span></p>
<p>We use the <em>EasyABC</em> package in <strong>R</strong> to implement the ABC accept/reject (ABC-AR) algorithm using 150,000 prior draws with an acceptance rate of 0.67%. We also apply the ABC Markov chain Monte Carlo (ABC-MCMC) method <span class="citation">(<a href="#ref-marjoram2003markov">Marjoram et al. 2003</a>)</span> and the sequential Monte Carlo ABC (ABC-SMC) method <span class="citation">(<a href="#ref-lenormand2013adaptive">Lenormand, Jabot, and Deffuant 2013</a>)</span> to compare the results across different ABC algorithms.<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a> We generate 100,000 samples and retain 1% in ABC-MCMC, and 30,000 samples, keeping 3.4%, with a stopping criterion of 5% in ABC-SMC. These settings imply that the three algorithms require approximately the same computational time. As ABC is a simulation-based method, the computational burden is mostly driven by the speed of simulating the process; thus, the <em>EasyABC</em> package has parallel computing algorithms to speed up the processes. Users can refer to the cited references for algorithmic details, and the <em>EasyABC</em> package for parallel computing implementation.</p>
<p>In <strong>Exercise 1</strong>, we ask to program the ABC accept/reject algorithm from scratch and compare the results with those obtained using the ABC-AR implementation in the <em>EasyABC</em> package.</p>
<p>The following code presents the results, and the figure compares the posterior distributions of <span class="math inline">\(\theta_1\)</span>, <span class="math inline">\(g\)</span>, and <span class="math inline">\(k\)</span> using the three methods. In this figure, we observe that ABC-MCMC (red) and ABC-SMC (green) exhibit similar performance, and both approaches provide more information than ABC-AR (blue). There is marginal positive evidence that the moving average coefficient is positive, and the three algorithms yield similar means, although ABC-AR exhibits lower precision. Since the posterior distribution of <span class="math inline">\(g\)</span> is centered around zero, the distribution appears to be symmetric around its median. Meanwhile, a positive <span class="math inline">\(k\)</span> indicates that the distribution has heavier tails than a normal distribution, implying a higher likelihood of extreme values (outliers) in the exchange rate USD/EURO.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="sec14_1.html#cb1-1" tabindex="-1"></a><span class="do">######### ABC Exchange rate og returns: USD/EURO</span></span>
<span id="cb1-2"><a href="sec14_1.html#cb1-2" tabindex="-1"></a><span class="fu">rm</span>(<span class="at">list =</span> <span class="fu">ls</span>()); <span class="fu">set.seed</span>(<span class="dv">010101</span>)</span>
<span id="cb1-3"><a href="sec14_1.html#cb1-3" tabindex="-1"></a><span class="fu">library</span>(EasyABC)</span>
<span id="cb1-4"><a href="sec14_1.html#cb1-4" tabindex="-1"></a>dfExcRate <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="at">file =</span> <span class="st">&quot;https://raw.githubusercontent.com/BEsmarter-consultancy/BSTApp/refs/heads/master/DataApp/ExchangeRate.csv&quot;</span>, <span class="at">sep =</span> <span class="st">&quot;,&quot;</span>, <span class="at">header =</span> T)</span>
<span id="cb1-5"><a href="sec14_1.html#cb1-5" tabindex="-1"></a><span class="fu">attach</span>(dfExcRate); n <span class="ot">&lt;-</span> <span class="fu">length</span>(USDEUR)</span>
<span id="cb1-6"><a href="sec14_1.html#cb1-6" tabindex="-1"></a><span class="co"># Summary statistics</span></span>
<span id="cb1-7"><a href="sec14_1.html#cb1-7" tabindex="-1"></a>SumSt <span class="ot">&lt;-</span> <span class="cf">function</span>(y) {</span>
<span id="cb1-8"><a href="sec14_1.html#cb1-8" tabindex="-1"></a>  Oct <span class="ot">&lt;-</span> <span class="fu">quantile</span>(y, <span class="fu">c</span>(<span class="fl">0.125</span>, <span class="fl">0.25</span>, <span class="fl">0.375</span>, <span class="fl">0.5</span>, <span class="fl">0.625</span>, <span class="fl">0.75</span>, <span class="fl">0.875</span>))</span>
<span id="cb1-9"><a href="sec14_1.html#cb1-9" tabindex="-1"></a>  eta1 <span class="ot">&lt;-</span> Oct[<span class="dv">6</span>] <span class="sc">-</span> Oct[<span class="dv">2</span>]</span>
<span id="cb1-10"><a href="sec14_1.html#cb1-10" tabindex="-1"></a>  eta2 <span class="ot">&lt;-</span> (Oct[<span class="dv">6</span>] <span class="sc">+</span> Oct[<span class="dv">2</span>] <span class="sc">-</span> <span class="dv">2</span> <span class="sc">*</span> Oct[<span class="dv">4</span>]) <span class="sc">/</span> eta1</span>
<span id="cb1-11"><a href="sec14_1.html#cb1-11" tabindex="-1"></a>  eta3 <span class="ot">&lt;-</span> (Oct[<span class="dv">7</span>] <span class="sc">-</span> Oct[<span class="dv">5</span>] <span class="sc">+</span> Oct[<span class="dv">3</span>] <span class="sc">-</span> Oct[<span class="dv">1</span>]) <span class="sc">/</span> eta1</span>
<span id="cb1-12"><a href="sec14_1.html#cb1-12" tabindex="-1"></a>  autocor <span class="ot">&lt;-</span> <span class="fu">acf</span>(y, <span class="at">lag =</span> <span class="dv">2</span>, <span class="at">plot =</span> <span class="cn">FALSE</span>)</span>
<span id="cb1-13"><a href="sec14_1.html#cb1-13" tabindex="-1"></a>  autocor[[<span class="st">&quot;acf&quot;</span>]][<span class="dv">2</span><span class="sc">:</span><span class="dv">3</span>]</span>
<span id="cb1-14"><a href="sec14_1.html#cb1-14" tabindex="-1"></a>  Etay <span class="ot">&lt;-</span> <span class="fu">c</span>(Oct, eta1, eta2, eta3, autocor[[<span class="st">&quot;acf&quot;</span>]][<span class="dv">2</span><span class="sc">:</span><span class="dv">3</span>])</span>
<span id="cb1-15"><a href="sec14_1.html#cb1-15" tabindex="-1"></a>  <span class="fu">return</span>(Etay)</span>
<span id="cb1-16"><a href="sec14_1.html#cb1-16" tabindex="-1"></a>}</span>
<span id="cb1-17"><a href="sec14_1.html#cb1-17" tabindex="-1"></a><span class="co"># g-and-k distribution</span></span>
<span id="cb1-18"><a href="sec14_1.html#cb1-18" tabindex="-1"></a>RGKnewSum <span class="ot">&lt;-</span> <span class="cf">function</span>(par) {</span>
<span id="cb1-19"><a href="sec14_1.html#cb1-19" tabindex="-1"></a>  z <span class="ot">&lt;-</span> <span class="cn">NULL</span></span>
<span id="cb1-20"><a href="sec14_1.html#cb1-20" tabindex="-1"></a>  theta <span class="ot">&lt;-</span> par[<span class="dv">1</span>]; a <span class="ot">&lt;-</span> par[<span class="dv">2</span>]; b <span class="ot">&lt;-</span> par[<span class="dv">3</span>]; g <span class="ot">&lt;-</span> par[<span class="dv">4</span>]; k <span class="ot">&lt;-</span> par[<span class="dv">5</span>]</span>
<span id="cb1-21"><a href="sec14_1.html#cb1-21" tabindex="-1"></a>  e <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n <span class="sc">+</span> <span class="dv">1</span>)</span>
<span id="cb1-22"><a href="sec14_1.html#cb1-22" tabindex="-1"></a>  <span class="cf">for</span>(t <span class="cf">in</span> <span class="dv">2</span><span class="sc">:</span>(n <span class="sc">+</span> <span class="dv">1</span>)){</span>
<span id="cb1-23"><a href="sec14_1.html#cb1-23" tabindex="-1"></a>    zt <span class="ot">&lt;-</span> e[t] <span class="sc">+</span> theta <span class="sc">*</span> e[t<span class="dv">-1</span>]</span>
<span id="cb1-24"><a href="sec14_1.html#cb1-24" tabindex="-1"></a>    z <span class="ot">&lt;-</span> <span class="fu">c</span>(z, zt)</span>
<span id="cb1-25"><a href="sec14_1.html#cb1-25" tabindex="-1"></a>  }</span>
<span id="cb1-26"><a href="sec14_1.html#cb1-26" tabindex="-1"></a>  zs <span class="ot">&lt;-</span> z <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">+</span> theta<span class="sc">^</span><span class="dv">2</span>)<span class="sc">^</span><span class="fl">0.5</span></span>
<span id="cb1-27"><a href="sec14_1.html#cb1-27" tabindex="-1"></a>  x <span class="ot">&lt;-</span> a <span class="sc">+</span> b <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">+</span> <span class="fl">0.8</span> <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> <span class="fu">exp</span>(<span class="sc">-</span>g <span class="sc">*</span> zs)) <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">+</span> <span class="fu">exp</span>(<span class="sc">-</span>g <span class="sc">*</span> zs))) <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">+</span> zs<span class="sc">^</span><span class="dv">2</span>)<span class="sc">^</span>k <span class="sc">*</span> zs</span>
<span id="cb1-28"><a href="sec14_1.html#cb1-28" tabindex="-1"></a>  Etaz <span class="ot">&lt;-</span> <span class="fu">SumSt</span>(x)</span>
<span id="cb1-29"><a href="sec14_1.html#cb1-29" tabindex="-1"></a>  <span class="fu">return</span>(Etaz)</span>
<span id="cb1-30"><a href="sec14_1.html#cb1-30" tabindex="-1"></a>}</span>
<span id="cb1-31"><a href="sec14_1.html#cb1-31" tabindex="-1"></a>toy_prior <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="fu">c</span>(<span class="st">&quot;unif&quot;</span>,<span class="sc">-</span><span class="dv">1</span>,<span class="dv">1</span>), <span class="fu">c</span>(<span class="st">&quot;unif&quot;</span>,<span class="dv">0</span>,<span class="dv">5</span>), <span class="fu">c</span>(<span class="st">&quot;unif&quot;</span>, <span class="dv">0</span>,<span class="dv">5</span>), <span class="fu">c</span>(<span class="st">&quot;unif&quot;</span>, <span class="sc">-</span><span class="dv">5</span>,<span class="dv">5</span>), <span class="fu">c</span>(<span class="st">&quot;unif&quot;</span>, <span class="sc">-</span><span class="fl">0.5</span>,<span class="dv">5</span>))</span>
<span id="cb1-32"><a href="sec14_1.html#cb1-32" tabindex="-1"></a>sum_stat_obs <span class="ot">&lt;-</span> <span class="fu">SumSt</span>(USDEUR)</span>
<span id="cb1-33"><a href="sec14_1.html#cb1-33" tabindex="-1"></a>tick <span class="ot">&lt;-</span> <span class="fu">Sys.time</span>()</span>
<span id="cb1-34"><a href="sec14_1.html#cb1-34" tabindex="-1"></a>ABC_AR <span class="ot">&lt;-</span> <span class="fu">ABC_rejection</span>(<span class="at">model=</span>RGKnewSum, <span class="at">prior=</span>toy_prior, <span class="at">summary_stat_target =</span> sum_stat_obs, <span class="at">nb_simul=</span><span class="dv">150000</span>, <span class="at">tol =</span> <span class="fl">0.0067</span>,</span>
<span id="cb1-35"><a href="sec14_1.html#cb1-35" tabindex="-1"></a>                        <span class="at">progress_bar =</span> <span class="cn">TRUE</span>)</span>
<span id="cb1-36"><a href="sec14_1.html#cb1-36" tabindex="-1"></a>tock <span class="ot">&lt;-</span> <span class="fu">Sys.time</span>()</span>
<span id="cb1-37"><a href="sec14_1.html#cb1-37" tabindex="-1"></a>tock <span class="sc">-</span> tick</span>
<span id="cb1-38"><a href="sec14_1.html#cb1-38" tabindex="-1"></a>PostABCAR <span class="ot">&lt;-</span> coda<span class="sc">::</span><span class="fu">mcmc</span>(ABC_AR<span class="sc">$</span>param)</span>
<span id="cb1-39"><a href="sec14_1.html#cb1-39" tabindex="-1"></a><span class="fu">summary</span>(PostABCAR)</span>
<span id="cb1-40"><a href="sec14_1.html#cb1-40" tabindex="-1"></a>tick <span class="ot">&lt;-</span> <span class="fu">Sys.time</span>()</span>
<span id="cb1-41"><a href="sec14_1.html#cb1-41" tabindex="-1"></a>ABC_MCMC <span class="ot">&lt;-</span> <span class="fu">ABC_mcmc</span>(<span class="at">method=</span><span class="st">&quot;Marjoram&quot;</span>, <span class="at">model=</span>RGKnewSum, <span class="at">prior=</span>toy_prior, <span class="at">summary_stat_target=</span>sum_stat_obs, <span class="at">n_rec =</span> <span class="dv">100000</span>, <span class="at">progress_bar =</span> <span class="cn">TRUE</span>)</span>
<span id="cb1-42"><a href="sec14_1.html#cb1-42" tabindex="-1"></a>tock <span class="ot">&lt;-</span> <span class="fu">Sys.time</span>()</span>
<span id="cb1-43"><a href="sec14_1.html#cb1-43" tabindex="-1"></a>tock <span class="sc">-</span> tick</span>
<span id="cb1-44"><a href="sec14_1.html#cb1-44" tabindex="-1"></a>PostABCMCMC <span class="ot">&lt;-</span> coda<span class="sc">::</span><span class="fu">mcmc</span>(ABC_MCMC[[<span class="st">&quot;param&quot;</span>]][<span class="fu">order</span>(ABC_MCMC[[<span class="st">&quot;dist&quot;</span>]])[<span class="dv">1</span><span class="sc">:</span><span class="dv">1000</span>],])</span>
<span id="cb1-45"><a href="sec14_1.html#cb1-45" tabindex="-1"></a><span class="fu">summary</span>(PostABCMCMC)</span>
<span id="cb1-46"><a href="sec14_1.html#cb1-46" tabindex="-1"></a>tick <span class="ot">&lt;-</span> <span class="fu">Sys.time</span>()</span>
<span id="cb1-47"><a href="sec14_1.html#cb1-47" tabindex="-1"></a>ABC_SMC<span class="ot">&lt;-</span><span class="fu">ABC_sequential</span>(<span class="at">method=</span><span class="st">&quot;Lenormand&quot;</span>, <span class="at">model=</span>RGKnewSum, <span class="at">prior=</span>toy_prior, <span class="at">summary_stat_target=</span>sum_stat_obs, <span class="at">nb_simul =</span> <span class="dv">30000</span>, <span class="at">alpha =</span> <span class="fl">0.034</span>, <span class="at">p_acc_min =</span> <span class="fl">0.05</span>,</span>
<span id="cb1-48"><a href="sec14_1.html#cb1-48" tabindex="-1"></a>                        <span class="at">progress_bar =</span> <span class="cn">TRUE</span>)</span>
<span id="cb1-49"><a href="sec14_1.html#cb1-49" tabindex="-1"></a>tock <span class="ot">&lt;-</span> <span class="fu">Sys.time</span>()</span>
<span id="cb1-50"><a href="sec14_1.html#cb1-50" tabindex="-1"></a>tock <span class="sc">-</span> tick</span>
<span id="cb1-51"><a href="sec14_1.html#cb1-51" tabindex="-1"></a>PostABCSMC <span class="ot">&lt;-</span> coda<span class="sc">::</span><span class="fu">mcmc</span>(ABC_SMC[[<span class="st">&quot;param&quot;</span>]])</span>
<span id="cb1-52"><a href="sec14_1.html#cb1-52" tabindex="-1"></a><span class="fu">summary</span>(PostABCSMC)</span>
<span id="cb1-53"><a href="sec14_1.html#cb1-53" tabindex="-1"></a></span>
<span id="cb1-54"><a href="sec14_1.html#cb1-54" tabindex="-1"></a><span class="co"># Figures </span></span>
<span id="cb1-55"><a href="sec14_1.html#cb1-55" tabindex="-1"></a><span class="fu">library</span>(ggplot2); <span class="fu">library</span>(latex2exp)</span>
<span id="cb1-56"><a href="sec14_1.html#cb1-56" tabindex="-1"></a>Sp <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb1-57"><a href="sec14_1.html#cb1-57" tabindex="-1"></a>df1 <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb1-58"><a href="sec14_1.html#cb1-58" tabindex="-1"></a>  <span class="at">Value =</span> <span class="fu">c</span>(PostABCAR[<span class="dv">1</span><span class="sc">:</span>Sp,<span class="dv">1</span>], PostABCMCMC[<span class="dv">1</span><span class="sc">:</span>Sp,<span class="dv">1</span>], PostABCSMC[<span class="dv">1</span><span class="sc">:</span>Sp,<span class="dv">1</span>]),</span>
<span id="cb1-59"><a href="sec14_1.html#cb1-59" tabindex="-1"></a>  <span class="at">Distribution =</span> <span class="fu">factor</span>(<span class="fu">c</span>(<span class="fu">rep</span>(<span class="st">&quot;AR&quot;</span>, Sp), <span class="fu">rep</span>(<span class="st">&quot;MCMC&quot;</span>, Sp), <span class="fu">rep</span>(<span class="st">&quot;SMC&quot;</span>, Sp)))</span>
<span id="cb1-60"><a href="sec14_1.html#cb1-60" tabindex="-1"></a>)</span>
<span id="cb1-61"><a href="sec14_1.html#cb1-61" tabindex="-1"></a></span>
<span id="cb1-62"><a href="sec14_1.html#cb1-62" tabindex="-1"></a>dentheta <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(df1, <span class="fu">aes</span>(<span class="at">x =</span> Value, <span class="at">color =</span> Distribution)) <span class="sc">+</span>   <span class="fu">geom_density</span>(<span class="at">linewidth =</span> <span class="dv">1</span>) <span class="sc">+</span> <span class="fu">labs</span>(<span class="at">title =</span> <span class="fu">TeX</span>(<span class="st">&quot;Posterior density plot: $theta$&quot;</span>), <span class="at">x =</span> <span class="fu">TeX</span>(<span class="st">&quot;$theta$&quot;</span>), <span class="at">y =</span> <span class="st">&quot;Posterior density&quot;</span>) <span class="sc">+</span> <span class="fu">scale_color_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">&quot;blue&quot;</span>, <span class="st">&quot;red&quot;</span>, <span class="st">&quot;green&quot;</span>)) <span class="sc">+</span>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb1-63"><a href="sec14_1.html#cb1-63" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.title =</span> <span class="fu">element_blank</span>())</span>
<span id="cb1-64"><a href="sec14_1.html#cb1-64" tabindex="-1"></a></span>
<span id="cb1-65"><a href="sec14_1.html#cb1-65" tabindex="-1"></a>df2 <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb1-66"><a href="sec14_1.html#cb1-66" tabindex="-1"></a>  <span class="at">Value =</span> <span class="fu">c</span>(PostABCAR[<span class="dv">1</span><span class="sc">:</span>Sp,<span class="dv">4</span>], PostABCMCMC[<span class="dv">1</span><span class="sc">:</span>Sp,<span class="dv">4</span>], PostABCSMC[<span class="dv">1</span><span class="sc">:</span>Sp,<span class="dv">4</span>]),</span>
<span id="cb1-67"><a href="sec14_1.html#cb1-67" tabindex="-1"></a>  <span class="at">Distribution =</span> <span class="fu">factor</span>(<span class="fu">c</span>(<span class="fu">rep</span>(<span class="st">&quot;AR&quot;</span>, Sp), <span class="fu">rep</span>(<span class="st">&quot;MCMC&quot;</span>, Sp), <span class="fu">rep</span>(<span class="st">&quot;SMC&quot;</span>, Sp)))</span>
<span id="cb1-68"><a href="sec14_1.html#cb1-68" tabindex="-1"></a>)</span>
<span id="cb1-69"><a href="sec14_1.html#cb1-69" tabindex="-1"></a></span>
<span id="cb1-70"><a href="sec14_1.html#cb1-70" tabindex="-1"></a>deng <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(df2, <span class="fu">aes</span>(<span class="at">x =</span> Value, <span class="at">color =</span> Distribution)) <span class="sc">+</span>   <span class="fu">geom_density</span>(<span class="at">linewidth =</span> <span class="dv">1</span>) <span class="sc">+</span> <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Posterior density plot: g&quot;</span>, <span class="at">x =</span> <span class="st">&quot;g&quot;</span>, <span class="at">y =</span> <span class="st">&quot;Posterior density&quot;</span>) <span class="sc">+</span> <span class="fu">scale_color_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">&quot;blue&quot;</span>, <span class="st">&quot;red&quot;</span>, <span class="st">&quot;green&quot;</span>)) <span class="sc">+</span>  <span class="fu">theme_minimal</span>() <span class="sc">+</span> <span class="fu">theme</span>(<span class="at">legend.title =</span> <span class="fu">element_blank</span>())</span>
<span id="cb1-71"><a href="sec14_1.html#cb1-71" tabindex="-1"></a></span>
<span id="cb1-72"><a href="sec14_1.html#cb1-72" tabindex="-1"></a>df3 <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb1-73"><a href="sec14_1.html#cb1-73" tabindex="-1"></a>  <span class="at">Value =</span> <span class="fu">c</span>(PostABCAR[<span class="dv">1</span><span class="sc">:</span>Sp,<span class="dv">5</span>], PostABCMCMC[<span class="dv">1</span><span class="sc">:</span>Sp,<span class="dv">5</span>], PostABCSMC[<span class="dv">1</span><span class="sc">:</span>Sp,<span class="dv">5</span>]),</span>
<span id="cb1-74"><a href="sec14_1.html#cb1-74" tabindex="-1"></a>  <span class="at">Distribution =</span> <span class="fu">factor</span>(<span class="fu">c</span>(<span class="fu">rep</span>(<span class="st">&quot;AR&quot;</span>, Sp), <span class="fu">rep</span>(<span class="st">&quot;MCMC&quot;</span>, Sp), <span class="fu">rep</span>(<span class="st">&quot;SMC&quot;</span>, Sp)))</span>
<span id="cb1-75"><a href="sec14_1.html#cb1-75" tabindex="-1"></a>)</span>
<span id="cb1-76"><a href="sec14_1.html#cb1-76" tabindex="-1"></a></span>
<span id="cb1-77"><a href="sec14_1.html#cb1-77" tabindex="-1"></a>denk <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(df3, <span class="fu">aes</span>(<span class="at">x =</span> Value, <span class="at">color =</span> Distribution)) <span class="sc">+</span>   <span class="fu">geom_density</span>(<span class="at">linewidth =</span> <span class="dv">1</span>) <span class="sc">+</span> <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Posterior density plot: k&quot;</span>, <span class="at">x =</span> <span class="st">&quot;k&quot;</span>, <span class="at">y =</span> <span class="st">&quot;Posterior density&quot;</span>) <span class="sc">+</span> <span class="fu">scale_color_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">&quot;blue&quot;</span>, <span class="st">&quot;red&quot;</span>, <span class="st">&quot;green&quot;</span>)) <span class="sc">+</span>  <span class="fu">theme_minimal</span>() <span class="sc">+</span> <span class="fu">theme</span>(<span class="at">legend.title =</span> <span class="fu">element_blank</span>())</span>
<span id="cb1-78"><a href="sec14_1.html#cb1-78" tabindex="-1"></a></span>
<span id="cb1-79"><a href="sec14_1.html#cb1-79" tabindex="-1"></a><span class="fu">library</span>(ggpubr)</span>
<span id="cb1-80"><a href="sec14_1.html#cb1-80" tabindex="-1"></a><span class="fu">ggarrange</span>(dentheta, deng, denk, <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">&quot;A&quot;</span>, <span class="st">&quot;B&quot;</span>, <span class="st">&quot;C&quot;</span>), <span class="at">ncol =</span> <span class="dv">3</span>, <span class="at">nrow =</span> <span class="dv">1</span>,</span>
<span id="cb1-81"><a href="sec14_1.html#cb1-81" tabindex="-1"></a>          <span class="at">legend =</span> <span class="st">&quot;bottom&quot;</span>, <span class="at">common.legend =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
</div>
<div id="sec14_12" class="section level3 hasAnchor" number="14.1.2">
<h3><span class="header-section-number">14.1.2</span> Bayesian synthetic likelihood<a href="sec14_1.html#sec14_12" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Note that in ABC, in most cases, we target the posterior distribution <span class="math inline">\(\pi(\boldsymbol{\theta} \mid \boldsymbol{\eta}(\boldsymbol{y}))\)</span> rather than <span class="math inline">\(\pi(\boldsymbol{\theta} \mid \boldsymbol{y})\)</span>, as <span class="math inline">\(\boldsymbol{\eta}(\boldsymbol{y})\)</span> is not a sufficient statistic, <span class="math inline">\(\boldsymbol{y} \in \mathbb{R}^N\)</span>, <span class="math inline">\(\boldsymbol{\theta} \in \mathbb{R}^K\)</span>, <span class="math inline">\(\boldsymbol{\eta}(\boldsymbol{y}) \in \mathbb{R}^L\)</span>, with <span class="math inline">\(L \geq K\)</span>. This can be beneficial since discarding information may improve the behavior of the likelihood or make the inference more robust to model misspecification <span class="citation">(<a href="#ref-price2018bayesian">Price et al. 2018</a>)</span>.</p>
<p>Given the intractability of <span class="math inline">\(p(\boldsymbol{y} \mid \boldsymbol{\theta})\)</span>, it is highly likely that <span class="math inline">\(p(\boldsymbol{\eta}(\boldsymbol{y}) \mid \boldsymbol{\theta})\)</span> is also intractable. <span class="citation">Wood (<a href="#ref-wood2010statistical">2010</a>)</span> addressed this issue by introducing an auxiliary model for the summary statistics, assuming</p>
<p><span class="math display">\[
p_a(\boldsymbol{\eta}(\boldsymbol{y}) \mid \boldsymbol{\theta}) = {N}(\boldsymbol{\mu}_{\boldsymbol{\theta}}, \boldsymbol{\Sigma}_{\boldsymbol{\theta}}).
\]</span></p>
<p>Bayesian synthetic likelihood (BSL) arises when this auxiliary likelihood is combined with a prior distribution on the parameter <span class="citation">(<a href="#ref-drovandi2015bayesian">C. C. Drovandi, Pettitt, and Lee 2015</a>; <a href="#ref-price2018bayesian">Price et al. 2018</a>)</span>:</p>
<p><span class="math display">\[
\pi_a(\boldsymbol{\theta} \mid \boldsymbol{\eta}(\boldsymbol{y})) \propto p_a(\boldsymbol{\eta}(\boldsymbol{y}) \mid \boldsymbol{\theta}) \pi(\boldsymbol{\theta}),
\]</span></p>
<p>where the subscript <span class="math inline">\(a\)</span> indicates that this is an approximation due to the Gaussian assumption. This is referred to as the idealized BSL posterior. However, note that <span class="math inline">\(p_a(\boldsymbol{\eta}(\boldsymbol{y}) \mid \boldsymbol{\theta})\)</span> is rarely available, as <span class="math inline">\(\boldsymbol{\mu}_{\boldsymbol{\theta}}\)</span> and <span class="math inline">\(\boldsymbol{\Sigma}_{\boldsymbol{\theta}}\)</span> are generally unknown. Therefore, we estimate these quantities using simulations from the model given a realization of <span class="math inline">\(\boldsymbol{\theta}\)</span>.<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a></p>
<p>We estimate the mean and covariance as follows:</p>
<p><span class="math display">\[
\widehat{\boldsymbol{\mu}}_{\boldsymbol{\theta}} = \frac{1}{M} \sum_{m=1}^M \boldsymbol{\eta}(\boldsymbol{z}^{(m)}),
\]</span></p>
<p><span class="math display">\[
\widehat{\boldsymbol{\Sigma}}_{\boldsymbol{\theta}} = \frac{1}{M - 1} \sum_{m=1}^M (\boldsymbol{\eta}(\boldsymbol{z}^{(m)}) - \widehat{\boldsymbol{\mu}}_{\boldsymbol{\theta}})(\boldsymbol{\eta}(\boldsymbol{z}^{(m)}) - \widehat{\boldsymbol{\mu}}_{\boldsymbol{\theta}})^\top.
\]</span></p>
<p>Then, we have:</p>
<p><span class="math display">\[
\pi_{a,M}(\boldsymbol{\theta} \mid \boldsymbol{\eta}(\boldsymbol{y})) \propto p_{a,M}(\boldsymbol{\eta}(\boldsymbol{y}) \mid \boldsymbol{\theta}) \pi(\boldsymbol{\theta}),
\]</span></p>
<p>where <span class="math inline">\(p_{a,M}(\boldsymbol{\eta}(\boldsymbol{y}))\)</span> uses the estimates, which depend on the number of draws <span class="math inline">\(M\)</span>. Note that even though we can have unbiased estimators for the mean and covariance, in general,</p>
<p><span class="math display">\[
{N}(\boldsymbol{\eta}(\boldsymbol{y}) \mid \widehat{\boldsymbol{\mu}}_{\boldsymbol{\theta}}, \widehat{\boldsymbol{\Sigma}}_{\boldsymbol{\theta}})
\]</span></p>
<p>is not an unbiased estimator of</p>
<p><span class="math display">\[
{N}(\boldsymbol{\eta}(\boldsymbol{y}) \mid \boldsymbol{\mu}_{\boldsymbol{\theta}}, \boldsymbol{\Sigma}_{\boldsymbol{\theta}}).
\]</span></p>
<p><span class="citation">An, South, and Drovandi (<a href="#ref-an2022bsl">2022</a>)</span> show an unbiased estimator for BSL.</p>
<p><span class="citation">D. Frazier et al. (<a href="#ref-nott2023bayesian">2023</a>)</span> show that <span class="math inline">\(\pi_{a,M}(\boldsymbol{\theta})\)</span> converges asymptotically to a Gaussian distribution and that the <span class="math inline">\(100(1 - \alpha)\%\)</span> Bayesian credible regions using BSL have frequentist coverage of <span class="math inline">\(100(1 - \alpha)\%\)</span>. The posterior mean is also asymptotically Gaussian.</p>
<p>These results require convenient estimation of the covariance matrix and that <span class="math inline">\(M \to \infty\)</span> as <span class="math inline">\(N \to \infty\)</span>:</p>
<p><span class="math display">\[
M = C \lfloor N^\gamma \rfloor, \quad C &gt; 0, \quad \gamma &gt; 0,
\]</span></p>
<p>where <span class="math inline">\(\lfloor x \rfloor\)</span> is the floor function. Thus, the choice of <span class="math inline">\(M\)</span> does not drastically affect the asymptotic properties of BSL <span class="citation">(<a href="#ref-nott2023bayesian">D. Frazier et al. 2023</a>)</span>. <span class="citation">Price et al. (<a href="#ref-price2018bayesian">2018</a>)</span> also find in their examples that posterior inference depends only weakly on <span class="math inline">\(M\)</span>. Therefore, <span class="math inline">\(M\)</span> can be chosen to balance computational efficiency, such that the standard deviation of the log synthetic likelihood is between 1 and 3 <span class="citation">(<a href="#ref-an2019accelerating">An et al. 2019</a>)</span>.</p>
<p>A critical aspect of BSL is the estimation of the covariance matrix, which can be computationally demanding in high-dimensional settings. However, <span class="citation">D. Frazier et al. (<a href="#ref-nott2023bayesian">2023</a>)</span> propose an adjusted BSL approach that allows the use of a simple, though potentially misspecified, covariance estimator (see Equation 5 and the related discussion in their paper).</p>
<p>If the normality assumption for summary statistics is too restrictive, <span class="citation">An, Nott, and Drovandi (<a href="#ref-an2020robust">2020</a>)</span> propose a robust BSL method based on a semi-parametric approach. Moreover, <span class="citation">D. T. Frazier and Drovandi (<a href="#ref-frazier2021robust">2021</a>)</span> show that when the model is misspecified (i.e., the assumed model is incompatible with the true data-generating process), BSL may yield unreliable parameter inference. They propose a new BSL method that detects model misspecification and produces more reliable inference.</p>
<p>We can perform BSL using the following Algorithm. We can use a random walk Metropolis-Hastings to set the proposal distribution. The covariance matrix of the random walk proposal can be tuned using an initial pilot run.</p>
<div class="algorithm">
<div style="background-color: #f8f9fa; padding: 15px; border-left: 5px solid #343a40; box-shadow: 4px 4px 10px rgba(0, 0, 0, 0.1); border-radius: 5px;">
<p><strong>Algorithm: Bayesian Synthetic Likelihood </strong></p>
<p>For <span class="math inline">\(s = 1, \dots, S\)</span>:</p>
<ol style="list-style-type: decimal">
<li><p>Draw <span class="math inline">\(\boldsymbol{\theta}^c \sim q(\boldsymbol{\theta} \mid \boldsymbol{\theta}^{s-1})\)</span></p></li>
<li><p>For <span class="math inline">\(m = 1, \dots, M\)</span>:</p>
<ul>
<li><p>Simulate <span class="math inline">\(\boldsymbol{z}^{(m)} = (z_1^{(m)}, z_2^{(m)}, \dots, z_n^{(m)})^{\top}\)</span> from the model <span class="math inline">\(p(\cdot \mid \boldsymbol{\theta}^c)\)</span></p></li>
<li><p>Calculate <span class="math inline">\(\boldsymbol{\eta}(\boldsymbol{z}^{(m)})\)</span></p></li>
</ul>
<p>End for</p></li>
<li><p>Calculate <span class="math inline">\(\boldsymbol{\mu}_{\boldsymbol{\theta}^c}\)</span> and <span class="math inline">\(\boldsymbol{\Sigma}_{\boldsymbol{\theta}^c}\)</span></p></li>
<li><p>Compute<br />
<span class="math display">\[
p_a^c(\boldsymbol{\eta}(\boldsymbol{y}) \mid \boldsymbol{\theta}^c) = {N}(\boldsymbol{\eta}(\boldsymbol{y}) \mid \boldsymbol{\mu}_{\boldsymbol{\theta}^c}, \boldsymbol{\Sigma}_{\boldsymbol{\theta}^c})
\]</span>
and<br />
<span class="math display">\[
p_a^{s-1}(\boldsymbol{\eta}(\boldsymbol{y}) \mid \boldsymbol{\theta}^{s-1}) = {N}(\boldsymbol{\eta}(\boldsymbol{y}) \mid \boldsymbol{\mu}_{\boldsymbol{\theta}^{s-1}}, \boldsymbol{\Sigma}_{\boldsymbol{\theta}^{s-1}})
\]</span></p></li>
<li><p>Compute the acceptance probability:
<span class="math display">\[
\alpha(\boldsymbol{\theta}^{s-1}, \boldsymbol{\theta}^c) =
\min\left\{1,\,
\frac{
   p_a^c(\boldsymbol{\eta}(\boldsymbol{y}) \mid \boldsymbol{\theta}^c)\,\pi(\boldsymbol{\theta}^c)\,q(\boldsymbol{\theta}^{s-1} \mid \boldsymbol{\theta}^c)
}{
   p_a^{s-1}(\boldsymbol{\eta}(\boldsymbol{y}) \mid \boldsymbol{\theta}^{s-1})\,\pi(\boldsymbol{\theta}^{s-1})\,q(\boldsymbol{\theta}^{c} \mid \boldsymbol{\theta}^{s-1})
}
\right\}
\]</span></p></li>
<li><p>Draw <span class="math inline">\(u \sim {U}(0,1)\)</span></p>
<ul>
<li>If <span class="math inline">\(u &lt; \alpha\)</span>, then:
<ul>
<li>Set <span class="math inline">\(\boldsymbol{\theta}^s = \boldsymbol{\theta}^c\)</span><br />
<span class="math inline">\(\boldsymbol{\mu}_{\boldsymbol{\theta}^s} = \boldsymbol{\mu}_{\boldsymbol{\theta}^c}\)</span><br />
<span class="math inline">\(\boldsymbol{\Sigma}_{\boldsymbol{\theta}^s} = \boldsymbol{\Sigma}_{\boldsymbol{\theta}^c}\)</span></li>
</ul></li>
<li>Else:
<ul>
<li>Set <span class="math inline">\(\boldsymbol{\theta}^s = \boldsymbol{\theta}^{s-1}\)</span><br />
<span class="math inline">\(\boldsymbol{\mu}_{\boldsymbol{\theta}^s} = \boldsymbol{\mu}_{\boldsymbol{\theta}^{s-1}}\)</span><br />
<span class="math inline">\(\boldsymbol{\Sigma}_{\boldsymbol{\theta}^s} = \boldsymbol{\Sigma}_{\boldsymbol{\theta}^{s-1}}\)</span></li>
</ul></li>
</ul></li>
</ol>
<p>End for</p>
</div>
</div>
<p>An advantage of BSL over ABC is that it does not require selecting a tolerance parameter <span class="math inline">\(\epsilon\)</span>. Furthermore, BSL is more computationally efficient than ABC when dealing with a high-dimensional vector of summary statistics, as the acceptance rate of the former is asymptotically non-vanishing <span class="citation">(<a href="#ref-nott2023bayesian">D. Frazier et al. 2023</a>)</span>.</p>
<p>On the other hand, ABC is asymptotically more efficient than BSL, and it imposes very weak requirements on the choice of summary statistics, whereas BSL requires summary statistics that satisfy central limit theorems (CLTs) and consistent estimators of the covariance matrix. However, asymptotically, both approaches provide reliable inference, provided their respective requirements are met <span class="citation">(<a href="#ref-martin2024approximating">Martin, Frazier, and Robert 2024</a>)</span>.</p>
<p>In practice, BSL may be more convenient than ABC when the summary statistics are high-dimensional and satisfy CLT conditions. Otherwise, ABC may be the better alternative.</p>
<p><strong>Example: Simulation exercise</strong></p>
<p>We simulate a dataset following the specification of the g-and-k distribution for the financial returns example, setting <span class="math inline">\(\theta_1 = 0.8\)</span>, <span class="math inline">\(a = 1\)</span>, <span class="math inline">\(b = 0.5\)</span>, <span class="math inline">\(g = -1\)</span>, and <span class="math inline">\(k = 1\)</span>, with a sample size of 500. We use the same priors and summary statistics as in that example.</p>
<p>We use the <em>BSL</em> package in <strong>R</strong> to perform posterior inference using BSL. Additionally, we implement our own BSL sampler to compare the results with the vanilla algorithm from the package. We run the BSL algorithms with <span class="math inline">\(M = 200\)</span>, <span class="math inline">\(S = 11{,}000\)</span>, a burn-in of 1,000, and a thinning parameter of 10, using a random walk proposal distribution. This setting results in similar computational times between the two implementations (scratch and package) and is also comparable to the ABC implementation in Exercise 1.</p>
<p>Take into account that BSL is a simulation-based method; therefore, the computational burden is mostly driven by the speed of simulating the process. The <em>BSL</em> package has parallel computing algorithms to speed up the processes, and users should refer to the <em>BSL</em> package for details.</p>
<p>The following code demonstrates this procedure. The summary statistics appear to be approximately normally distributed, as shown in the first Figure, where the red line represents the normal density and the black line represents the estimated density of the summary statistic. The second Figure displays the posterior distributions from both algorithms for <span class="math inline">\(\theta_1\)</span>, <span class="math inline">\(g\)</span>, and <span class="math inline">\(k\)</span>. In general, the 95% credible intervals encompass the true parameter values. However, the posterior draws from the <em>BSL</em> package are more informative compared to our implementation of Algorithm. Additionally, BSL outperforms the results of ABC in Exercise 1, yielding more precise posterior distributions. This pattern has been observed in other settings <span class="citation">(<a href="#ref-drovandi2022comparison">C. Drovandi and Frazier 2022</a>; <a href="#ref-martin2024approximating">Martin, Frazier, and Robert 2024</a>)</span>.</p>
<p>Both ABC and BSL produce posterior distributions centered at the true parameter values, although the posterior distribution of <span class="math inline">\(\theta_1\)</span> deviates from this pattern.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="sec14_1.html#cb2-1" tabindex="-1"></a><span class="do">######## BSL: g-and-k simulation ############</span></span>
<span id="cb2-2"><a href="sec14_1.html#cb2-2" tabindex="-1"></a><span class="fu">rm</span>(<span class="at">list =</span> <span class="fu">ls</span>()); <span class="fu">set.seed</span>(<span class="dv">010101</span>); <span class="fu">library</span>(BSL)</span>
<span id="cb2-3"><a href="sec14_1.html#cb2-3" tabindex="-1"></a><span class="co"># Simulate g-and-k data</span></span>
<span id="cb2-4"><a href="sec14_1.html#cb2-4" tabindex="-1"></a>RGKnew <span class="ot">&lt;-</span> <span class="cf">function</span>(par) {</span>
<span id="cb2-5"><a href="sec14_1.html#cb2-5" tabindex="-1"></a>    z <span class="ot">&lt;-</span> <span class="cn">NULL</span></span>
<span id="cb2-6"><a href="sec14_1.html#cb2-6" tabindex="-1"></a>    theta <span class="ot">&lt;-</span> par[<span class="dv">1</span>]; a <span class="ot">&lt;-</span> par[<span class="dv">2</span>]; b <span class="ot">&lt;-</span> par[<span class="dv">3</span>]; g <span class="ot">&lt;-</span> par[<span class="dv">4</span>]; k <span class="ot">&lt;-</span> par[<span class="dv">5</span>]</span>
<span id="cb2-7"><a href="sec14_1.html#cb2-7" tabindex="-1"></a>    e <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n <span class="sc">+</span> <span class="dv">1</span>)</span>
<span id="cb2-8"><a href="sec14_1.html#cb2-8" tabindex="-1"></a>    <span class="cf">for</span>(t <span class="cf">in</span> <span class="dv">2</span><span class="sc">:</span>(n <span class="sc">+</span> <span class="dv">1</span>)){</span>
<span id="cb2-9"><a href="sec14_1.html#cb2-9" tabindex="-1"></a>        zt <span class="ot">&lt;-</span> e[t] <span class="sc">+</span> theta <span class="sc">*</span> e[t<span class="dv">-1</span>]</span>
<span id="cb2-10"><a href="sec14_1.html#cb2-10" tabindex="-1"></a>        z <span class="ot">&lt;-</span> <span class="fu">c</span>(z, zt)</span>
<span id="cb2-11"><a href="sec14_1.html#cb2-11" tabindex="-1"></a>    }</span>
<span id="cb2-12"><a href="sec14_1.html#cb2-12" tabindex="-1"></a>    zs <span class="ot">&lt;-</span> z <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">+</span> theta<span class="sc">^</span><span class="dv">2</span>)<span class="sc">^</span><span class="fl">0.5</span></span>
<span id="cb2-13"><a href="sec14_1.html#cb2-13" tabindex="-1"></a>    x <span class="ot">&lt;-</span> a <span class="sc">+</span> b <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">+</span> <span class="fl">0.8</span> <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> <span class="fu">exp</span>(<span class="sc">-</span>g <span class="sc">*</span> zs)) <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">+</span> <span class="fu">exp</span>(<span class="sc">-</span>g <span class="sc">*</span> zs))) <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">+</span> zs<span class="sc">^</span><span class="dv">2</span>)<span class="sc">^</span>k <span class="sc">*</span> zs</span>
<span id="cb2-14"><a href="sec14_1.html#cb2-14" tabindex="-1"></a>    <span class="fu">return</span>(x)</span>
<span id="cb2-15"><a href="sec14_1.html#cb2-15" tabindex="-1"></a>}</span>
<span id="cb2-16"><a href="sec14_1.html#cb2-16" tabindex="-1"></a><span class="co"># Summary statistics</span></span>
<span id="cb2-17"><a href="sec14_1.html#cb2-17" tabindex="-1"></a>SumSt <span class="ot">&lt;-</span> <span class="cf">function</span>(y) {</span>
<span id="cb2-18"><a href="sec14_1.html#cb2-18" tabindex="-1"></a>    Oct <span class="ot">&lt;-</span> <span class="fu">quantile</span>(y, <span class="fu">c</span>(<span class="fl">0.125</span>, <span class="fl">0.25</span>, <span class="fl">0.375</span>, <span class="fl">0.5</span>, <span class="fl">0.625</span>, <span class="fl">0.75</span>, <span class="fl">0.875</span>))</span>
<span id="cb2-19"><a href="sec14_1.html#cb2-19" tabindex="-1"></a>    eta1 <span class="ot">&lt;-</span> Oct[<span class="dv">6</span>] <span class="sc">-</span> Oct[<span class="dv">2</span>]</span>
<span id="cb2-20"><a href="sec14_1.html#cb2-20" tabindex="-1"></a>    eta2 <span class="ot">&lt;-</span> (Oct[<span class="dv">6</span>] <span class="sc">+</span> Oct[<span class="dv">2</span>] <span class="sc">-</span> <span class="dv">2</span> <span class="sc">*</span> Oct[<span class="dv">4</span>]) <span class="sc">/</span> eta1</span>
<span id="cb2-21"><a href="sec14_1.html#cb2-21" tabindex="-1"></a>    eta3 <span class="ot">&lt;-</span> (Oct[<span class="dv">7</span>] <span class="sc">-</span> Oct[<span class="dv">5</span>] <span class="sc">+</span> Oct[<span class="dv">3</span>] <span class="sc">-</span> Oct[<span class="dv">1</span>]) <span class="sc">/</span> eta1</span>
<span id="cb2-22"><a href="sec14_1.html#cb2-22" tabindex="-1"></a>    autocor <span class="ot">&lt;-</span> <span class="fu">acf</span>(y, <span class="at">lag =</span> <span class="dv">2</span>, <span class="at">plot =</span> <span class="cn">FALSE</span>)</span>
<span id="cb2-23"><a href="sec14_1.html#cb2-23" tabindex="-1"></a>    autocor[[<span class="st">&quot;acf&quot;</span>]][<span class="dv">2</span><span class="sc">:</span><span class="dv">3</span>]</span>
<span id="cb2-24"><a href="sec14_1.html#cb2-24" tabindex="-1"></a>    Etay <span class="ot">&lt;-</span> <span class="fu">c</span>(Oct, eta1, eta2, eta3, autocor[[<span class="st">&quot;acf&quot;</span>]][<span class="dv">2</span><span class="sc">:</span><span class="dv">3</span>])</span>
<span id="cb2-25"><a href="sec14_1.html#cb2-25" tabindex="-1"></a>    <span class="fu">return</span>(Etay)</span>
<span id="cb2-26"><a href="sec14_1.html#cb2-26" tabindex="-1"></a>}</span>
<span id="cb2-27"><a href="sec14_1.html#cb2-27" tabindex="-1"></a><span class="co"># Prior function</span></span>
<span id="cb2-28"><a href="sec14_1.html#cb2-28" tabindex="-1"></a>LogPrior <span class="ot">&lt;-</span> <span class="cf">function</span>(par){</span>
<span id="cb2-29"><a href="sec14_1.html#cb2-29" tabindex="-1"></a>    LogPi <span class="ot">&lt;-</span> <span class="fu">log</span>(par[<span class="dv">1</span>] <span class="sc">&gt;</span> <span class="sc">-</span><span class="dv">1</span> <span class="sc">&amp;</span> par[<span class="dv">1</span>] <span class="sc">&lt;</span> <span class="dv">1</span> <span class="sc">&amp;</span> par[<span class="dv">2</span>] <span class="sc">&gt;</span> <span class="dv">0</span> <span class="sc">&amp;</span> par[<span class="dv">2</span>] <span class="sc">&lt;</span> <span class="dv">5</span> <span class="sc">&amp;</span> par[<span class="dv">3</span>] <span class="sc">&gt;</span> <span class="dv">0</span> <span class="sc">&amp;</span> par[<span class="dv">3</span>] <span class="sc">&lt;</span> <span class="dv">5</span> <span class="sc">&amp;</span> par[<span class="dv">4</span>] <span class="sc">&gt;</span> <span class="sc">-</span><span class="dv">5</span> <span class="sc">&amp;</span> par[<span class="dv">4</span>] <span class="sc">&lt;</span> <span class="dv">5</span> <span class="sc">&amp;</span> par[<span class="dv">5</span>] <span class="sc">&gt;</span> <span class="sc">-</span><span class="fl">0.5</span> <span class="sc">&amp;</span> par[<span class="dv">5</span>] <span class="sc">&lt;</span> <span class="dv">5</span>)</span>
<span id="cb2-30"><a href="sec14_1.html#cb2-30" tabindex="-1"></a>    <span class="fu">return</span>(LogPi)</span>
<span id="cb2-31"><a href="sec14_1.html#cb2-31" tabindex="-1"></a>}</span>
<span id="cb2-32"><a href="sec14_1.html#cb2-32" tabindex="-1"></a><span class="co"># Population parameters</span></span>
<span id="cb2-33"><a href="sec14_1.html#cb2-33" tabindex="-1"></a>theta1 <span class="ot">&lt;-</span> <span class="fl">0.8</span>; a <span class="ot">&lt;-</span> <span class="dv">1</span>; b <span class="ot">&lt;-</span> <span class="fl">0.5</span>; g <span class="ot">&lt;-</span> <span class="sc">-</span><span class="dv">1</span>; k <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb2-34"><a href="sec14_1.html#cb2-34" tabindex="-1"></a>parpop <span class="ot">&lt;-</span> <span class="fu">c</span>(theta1, a, b, g, k)</span>
<span id="cb2-35"><a href="sec14_1.html#cb2-35" tabindex="-1"></a>K <span class="ot">&lt;-</span> <span class="dv">5</span></span>
<span id="cb2-36"><a href="sec14_1.html#cb2-36" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">500</span></span>
<span id="cb2-37"><a href="sec14_1.html#cb2-37" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">RGKnew</span>(<span class="at">par =</span> parpop)</span>
<span id="cb2-38"><a href="sec14_1.html#cb2-38" tabindex="-1"></a><span class="co"># Algorithm parameters</span></span>
<span id="cb2-39"><a href="sec14_1.html#cb2-39" tabindex="-1"></a>M <span class="ot">&lt;-</span> <span class="dv">200</span> <span class="co"># Number of iterations to calculate mu and sigma</span></span>
<span id="cb2-40"><a href="sec14_1.html#cb2-40" tabindex="-1"></a>S <span class="ot">&lt;-</span> <span class="dv">11000</span> <span class="co"># Number of MCMC iterations</span></span>
<span id="cb2-41"><a href="sec14_1.html#cb2-41" tabindex="-1"></a>burnin <span class="ot">&lt;-</span> <span class="dv">1000</span> <span class="co"># Burn in iterations</span></span>
<span id="cb2-42"><a href="sec14_1.html#cb2-42" tabindex="-1"></a>thin <span class="ot">&lt;-</span> <span class="dv">10</span> <span class="co"># Thining parameter</span></span>
<span id="cb2-43"><a href="sec14_1.html#cb2-43" tabindex="-1"></a>keep <span class="ot">&lt;-</span> <span class="fu">seq</span>(burnin <span class="sc">+</span> <span class="dv">1</span>, S, thin)</span>
<span id="cb2-44"><a href="sec14_1.html#cb2-44" tabindex="-1"></a>par0 <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">0.5</span>, <span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>) </span>
<span id="cb2-45"><a href="sec14_1.html#cb2-45" tabindex="-1"></a>Modelgk <span class="ot">&lt;-</span> <span class="fu">newModel</span>(<span class="at">fnSim =</span> RGKnew, <span class="at">fnSum =</span> SumSt, <span class="at">theta0 =</span> par0, <span class="at">fnLogPrior =</span> LogPrior, <span class="at">verbose =</span> <span class="cn">FALSE</span>)</span>
<span id="cb2-46"><a href="sec14_1.html#cb2-46" tabindex="-1"></a><span class="fu">validObject</span>(Modelgk)</span>
<span id="cb2-47"><a href="sec14_1.html#cb2-47" tabindex="-1"></a><span class="co"># Check if the summary statistics are roughly normal</span></span>
<span id="cb2-48"><a href="sec14_1.html#cb2-48" tabindex="-1"></a>simgk <span class="ot">&lt;-</span> <span class="fu">simulation</span>(Modelgk, <span class="at">n =</span> M, <span class="at">theta =</span> par0, <span class="at">seed =</span> <span class="dv">10</span>)</span>
<span id="cb2-49"><a href="sec14_1.html#cb2-49" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">4</span>, <span class="dv">3</span>))</span>
<span id="cb2-50"><a href="sec14_1.html#cb2-50" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">12</span>){</span>
<span id="cb2-51"><a href="sec14_1.html#cb2-51" tabindex="-1"></a>    eval <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="fu">min</span>(simgk<span class="sc">$</span>ssx[, i]), <span class="fu">max</span>(simgk<span class="sc">$</span>ssx[, i]), <span class="fl">0.001</span>)</span>
<span id="cb2-52"><a href="sec14_1.html#cb2-52" tabindex="-1"></a>    densnorm <span class="ot">&lt;-</span> <span class="fu">dnorm</span>(eval, <span class="at">mean =</span> <span class="fu">mean</span>(simgk<span class="sc">$</span>ssx[, i]), <span class="fu">sd</span>(simgk<span class="sc">$</span>ssx[, i])) </span>
<span id="cb2-53"><a href="sec14_1.html#cb2-53" tabindex="-1"></a>    <span class="fu">plot</span>(<span class="fu">density</span>(simgk<span class="sc">$</span>ssx[, i]), <span class="at">main =</span> <span class="st">&quot;&quot;</span>, <span class="at">xlab =</span> <span class="st">&quot;&quot;</span>)</span>
<span id="cb2-54"><a href="sec14_1.html#cb2-54" tabindex="-1"></a>    <span class="fu">lines</span>(eval, densnorm, <span class="at">col =</span> <span class="st">&quot;red&quot;</span>)</span>
<span id="cb2-55"><a href="sec14_1.html#cb2-55" tabindex="-1"></a>}</span>
<span id="cb2-56"><a href="sec14_1.html#cb2-56" tabindex="-1"></a><span class="do">##### Program from scratch #######</span></span>
<span id="cb2-57"><a href="sec14_1.html#cb2-57" tabindex="-1"></a>Lims <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="sc">-</span><span class="dv">5</span>, <span class="sc">-</span><span class="fl">0.5</span>, <span class="dv">1</span>, <span class="fu">rep</span>(<span class="dv">5</span>, <span class="dv">4</span>)), <span class="dv">5</span>, <span class="dv">2</span>)</span>
<span id="cb2-58"><a href="sec14_1.html#cb2-58" tabindex="-1"></a>parPost <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="cn">NA</span>, S, K); parPost[<span class="dv">1</span>,] <span class="ot">&lt;-</span> par0 ; EtaY <span class="ot">&lt;-</span> <span class="fu">SumSt</span>(<span class="at">y =</span> y)</span>
<span id="cb2-59"><a href="sec14_1.html#cb2-59" tabindex="-1"></a>Zsl <span class="ot">&lt;-</span> <span class="fu">replicate</span>(M, <span class="fu">RGKnew</span>(<span class="at">par =</span> parPost[<span class="dv">1</span>,]))</span>
<span id="cb2-60"><a href="sec14_1.html#cb2-60" tabindex="-1"></a>EtasZsl <span class="ot">&lt;-</span> <span class="fu">t</span>(<span class="fu">apply</span>(Zsl, <span class="dv">2</span>, SumSt))</span>
<span id="cb2-61"><a href="sec14_1.html#cb2-61" tabindex="-1"></a>Usl <span class="ot">&lt;-</span> <span class="fu">colMeans</span>(EtasZsl); SIGMAsl <span class="ot">&lt;-</span> <span class="fu">var</span>(EtasZsl)</span>
<span id="cb2-62"><a href="sec14_1.html#cb2-62" tabindex="-1"></a>dnormsl <span class="ot">&lt;-</span> mvtnorm<span class="sc">::</span><span class="fu">dmvnorm</span>(EtaY, Usl, SIGMAsl, <span class="at">log =</span> <span class="cn">TRUE</span>)</span>
<span id="cb2-63"><a href="sec14_1.html#cb2-63" tabindex="-1"></a>tune <span class="ot">&lt;-</span> <span class="fl">0.005</span>; CoVarRW <span class="ot">&lt;-</span> tune<span class="sc">*</span><span class="fu">diag</span>(K)</span>
<span id="cb2-64"><a href="sec14_1.html#cb2-64" tabindex="-1"></a>accept <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">0</span>, S); tick1 <span class="ot">&lt;-</span> <span class="fu">Sys.time</span>()</span>
<span id="cb2-65"><a href="sec14_1.html#cb2-65" tabindex="-1"></a>pb <span class="ot">&lt;-</span> <span class="fu">winProgressBar</span>(<span class="at">title =</span> <span class="st">&quot;progress bar&quot;</span>, <span class="at">min =</span> <span class="dv">0</span>, <span class="at">max =</span> S, <span class="at">width =</span> <span class="dv">300</span>)</span>
<span id="cb2-66"><a href="sec14_1.html#cb2-66" tabindex="-1"></a><span class="cf">for</span> (s <span class="cf">in</span> <span class="dv">2</span><span class="sc">:</span>S){</span>
<span id="cb2-67"><a href="sec14_1.html#cb2-67" tabindex="-1"></a>    parc <span class="ot">&lt;-</span> MASS<span class="sc">::</span><span class="fu">mvrnorm</span>(<span class="dv">1</span>, <span class="at">mu =</span> parPost[s<span class="dv">-1</span>,], <span class="at">Sigma =</span> CoVarRW)</span>
<span id="cb2-68"><a href="sec14_1.html#cb2-68" tabindex="-1"></a>    RestCheck <span class="ot">&lt;-</span> <span class="cn">NULL</span></span>
<span id="cb2-69"><a href="sec14_1.html#cb2-69" tabindex="-1"></a>    <span class="cf">for</span>(j <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>K){</span>
<span id="cb2-70"><a href="sec14_1.html#cb2-70" tabindex="-1"></a>        <span class="cf">if</span>(parc[j] <span class="sc">&lt;</span> Lims[j,<span class="dv">1</span>] <span class="sc">|</span> parc[j] <span class="sc">&gt;</span> Lims[j,<span class="dv">2</span>]){</span>
<span id="cb2-71"><a href="sec14_1.html#cb2-71" tabindex="-1"></a>            Rej <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb2-72"><a href="sec14_1.html#cb2-72" tabindex="-1"></a>        }<span class="cf">else</span>{Rej <span class="ot">&lt;-</span> <span class="dv">0</span>}</span>
<span id="cb2-73"><a href="sec14_1.html#cb2-73" tabindex="-1"></a>        RestCheck <span class="ot">&lt;-</span> <span class="fu">c</span>(RestCheck, Rej)</span>
<span id="cb2-74"><a href="sec14_1.html#cb2-74" tabindex="-1"></a>    }</span>
<span id="cb2-75"><a href="sec14_1.html#cb2-75" tabindex="-1"></a>    <span class="cf">if</span>(<span class="fu">sum</span>(RestCheck) <span class="sc">!=</span> <span class="dv">0</span>){</span>
<span id="cb2-76"><a href="sec14_1.html#cb2-76" tabindex="-1"></a>        parPost[s,] <span class="ot">&lt;-</span> parPost[s<span class="dv">-1</span>,]; accept[s] <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb2-77"><a href="sec14_1.html#cb2-77" tabindex="-1"></a>    }<span class="cf">else</span>{</span>
<span id="cb2-78"><a href="sec14_1.html#cb2-78" tabindex="-1"></a>        Z <span class="ot">&lt;-</span> <span class="fu">replicate</span>(M, <span class="fu">RGKnew</span>(<span class="at">par =</span> parc))</span>
<span id="cb2-79"><a href="sec14_1.html#cb2-79" tabindex="-1"></a>        EtasZ <span class="ot">&lt;-</span> <span class="fu">t</span>(<span class="fu">apply</span>(Z, <span class="dv">2</span>, SumSt))</span>
<span id="cb2-80"><a href="sec14_1.html#cb2-80" tabindex="-1"></a>        Um <span class="ot">&lt;-</span> <span class="fu">colMeans</span>(EtasZ); SIGMAm <span class="ot">&lt;-</span> <span class="fu">var</span>(EtasZ)</span>
<span id="cb2-81"><a href="sec14_1.html#cb2-81" tabindex="-1"></a>        dnormc <span class="ot">&lt;-</span> mvtnorm<span class="sc">::</span><span class="fu">dmvnorm</span>(EtaY, Um, SIGMAm, <span class="at">log =</span> <span class="cn">TRUE</span>)</span>
<span id="cb2-82"><a href="sec14_1.html#cb2-82" tabindex="-1"></a>        <span class="cf">if</span>(s <span class="sc">&gt;</span> <span class="fu">round</span>(<span class="fl">0.1</span><span class="sc">*</span>S, <span class="dv">0</span>) <span class="sc">&amp;</span> s <span class="sc">&lt;</span> <span class="fu">round</span>(<span class="fl">0.2</span><span class="sc">*</span>S, <span class="dv">0</span>)){</span>
<span id="cb2-83"><a href="sec14_1.html#cb2-83" tabindex="-1"></a>            CoVarRW <span class="ot">&lt;-</span> <span class="fu">var</span>(parPost, <span class="at">na.rm =</span> <span class="cn">TRUE</span>)</span>
<span id="cb2-84"><a href="sec14_1.html#cb2-84" tabindex="-1"></a>        }</span>
<span id="cb2-85"><a href="sec14_1.html#cb2-85" tabindex="-1"></a>        <span class="cf">if</span>(dnormc <span class="sc">==</span> <span class="sc">-</span><span class="cn">Inf</span>){</span>
<span id="cb2-86"><a href="sec14_1.html#cb2-86" tabindex="-1"></a>            parPost[s,] <span class="ot">&lt;-</span> parPost[s<span class="dv">-1</span>,]; accept[s] <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb2-87"><a href="sec14_1.html#cb2-87" tabindex="-1"></a>        }<span class="cf">else</span>{</span>
<span id="cb2-88"><a href="sec14_1.html#cb2-88" tabindex="-1"></a>            alpha <span class="ot">&lt;-</span> <span class="fu">min</span>(<span class="dv">1</span>, <span class="fu">exp</span>(dnormc <span class="sc">-</span> dnormsl)); U <span class="ot">&lt;-</span> <span class="fu">runif</span>(<span class="dv">1</span>)</span>
<span id="cb2-89"><a href="sec14_1.html#cb2-89" tabindex="-1"></a>            <span class="cf">if</span>(U <span class="sc">&lt;=</span> alpha){</span>
<span id="cb2-90"><a href="sec14_1.html#cb2-90" tabindex="-1"></a>                parPost[s,] <span class="ot">&lt;-</span> parc; Usl <span class="ot">&lt;-</span> Um; SIGMAsl <span class="ot">&lt;-</span> SIGMAm</span>
<span id="cb2-91"><a href="sec14_1.html#cb2-91" tabindex="-1"></a>                dnormsl <span class="ot">&lt;-</span> dnormc; accept[s] <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb2-92"><a href="sec14_1.html#cb2-92" tabindex="-1"></a>            }<span class="cf">else</span>{</span>
<span id="cb2-93"><a href="sec14_1.html#cb2-93" tabindex="-1"></a>                parPost[s,] <span class="ot">&lt;-</span> parPost[s<span class="dv">-1</span>,]; accept[s] <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb2-94"><a href="sec14_1.html#cb2-94" tabindex="-1"></a>            }</span>
<span id="cb2-95"><a href="sec14_1.html#cb2-95" tabindex="-1"></a>        }</span>
<span id="cb2-96"><a href="sec14_1.html#cb2-96" tabindex="-1"></a>    }</span>
<span id="cb2-97"><a href="sec14_1.html#cb2-97" tabindex="-1"></a>    <span class="fu">setWinProgressBar</span>(pb, s, <span class="at">title=</span><span class="fu">paste</span>( <span class="fu">round</span>(s<span class="sc">/</span>S<span class="sc">*</span><span class="dv">100</span>, <span class="dv">0</span>),<span class="st">&quot;% done&quot;</span>))</span>
<span id="cb2-98"><a href="sec14_1.html#cb2-98" tabindex="-1"></a>}</span>
<span id="cb2-99"><a href="sec14_1.html#cb2-99" tabindex="-1"></a><span class="fu">close</span>(pb); tock1 <span class="ot">&lt;-</span> <span class="fu">Sys.time</span>(); tock1 <span class="sc">-</span> tick1</span>
<span id="cb2-100"><a href="sec14_1.html#cb2-100" tabindex="-1"></a><span class="fu">mean</span>(accept)</span>
<span id="cb2-101"><a href="sec14_1.html#cb2-101" tabindex="-1"></a>PostChainOwn <span class="ot">&lt;-</span> coda<span class="sc">::</span><span class="fu">mcmc</span>(parPost[keep,])</span>
<span id="cb2-102"><a href="sec14_1.html#cb2-102" tabindex="-1"></a><span class="fu">summary</span>(PostChainOwn)</span>
<span id="cb2-103"><a href="sec14_1.html#cb2-103" tabindex="-1"></a><span class="do">#### BSL package</span></span>
<span id="cb2-104"><a href="sec14_1.html#cb2-104" tabindex="-1"></a>tick <span class="ot">&lt;-</span> <span class="fu">Sys.time</span>()</span>
<span id="cb2-105"><a href="sec14_1.html#cb2-105" tabindex="-1"></a>Resultsgk <span class="ot">&lt;-</span> <span class="fu">bsl</span>(<span class="at">y =</span> y, <span class="at">n =</span> M, <span class="at">M =</span> S, <span class="at">model =</span> Modelgk, <span class="at">covRandWalk =</span> CoVarRW,</span>
<span id="cb2-106"><a href="sec14_1.html#cb2-106" tabindex="-1"></a><span class="at">method =</span> <span class="st">&quot;BSL&quot;</span>, <span class="at">thetaNames =</span> <span class="fu">expression</span>(theta, a, b, g, k), <span class="at">plotOnTheFly =</span> <span class="cn">TRUE</span>)</span>
<span id="cb2-107"><a href="sec14_1.html#cb2-107" tabindex="-1"></a>tock <span class="ot">&lt;-</span> <span class="fu">Sys.time</span>(); tock <span class="sc">-</span> tick</span>
<span id="cb2-108"><a href="sec14_1.html#cb2-108" tabindex="-1"></a>PostChain <span class="ot">&lt;-</span> coda<span class="sc">::</span><span class="fu">mcmc</span>(Resultsgk<span class="sc">@</span>theta[keep,])</span>
<span id="cb2-109"><a href="sec14_1.html#cb2-109" tabindex="-1"></a><span class="fu">summary</span>(PostChain)</span>
<span id="cb2-110"><a href="sec14_1.html#cb2-110" tabindex="-1"></a>Resultsgk<span class="sc">@</span>acceptanceRate</span>
<span id="cb2-111"><a href="sec14_1.html#cb2-111" tabindex="-1"></a><span class="fu">plot</span>(Resultsgk<span class="sc">@</span>loglike[keep], <span class="at">type =</span> <span class="st">&quot;l&quot;</span>)</span>
<span id="cb2-112"><a href="sec14_1.html#cb2-112" tabindex="-1"></a><span class="fu">sd</span>(Resultsgk<span class="sc">@</span>loglike[keep])</span>
<span id="cb2-113"><a href="sec14_1.html#cb2-113" tabindex="-1"></a><span class="co"># Figures </span></span>
<span id="cb2-114"><a href="sec14_1.html#cb2-114" tabindex="-1"></a><span class="fu">library</span>(ggplot2); <span class="fu">library</span>(latex2exp)</span>
<span id="cb2-115"><a href="sec14_1.html#cb2-115" tabindex="-1"></a>Sp <span class="ot">&lt;-</span> <span class="fu">length</span>(keep)</span>
<span id="cb2-116"><a href="sec14_1.html#cb2-116" tabindex="-1"></a>df1 <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">Value =</span> <span class="fu">c</span>(PostChain[,<span class="dv">1</span>], PostChainOwn[,<span class="dv">1</span>]), <span class="at">Distribution =</span> <span class="fu">factor</span>(<span class="fu">c</span>(<span class="fu">rep</span>(<span class="st">&quot;BSL&quot;</span>, Sp), <span class="fu">rep</span>(<span class="st">&quot;BSLscratch&quot;</span>, Sp))))</span>
<span id="cb2-117"><a href="sec14_1.html#cb2-117" tabindex="-1"></a>dentheta <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(df1, <span class="fu">aes</span>(<span class="at">x =</span> Value, <span class="at">color =</span> Distribution)) <span class="sc">+</span> <span class="fu">geom_density</span>(<span class="at">linewidth =</span> <span class="dv">1</span>) <span class="sc">+</span> <span class="fu">labs</span>(<span class="at">title =</span> <span class="fu">TeX</span>(<span class="st">&quot;Posterior density plot: $theta$&quot;</span>), <span class="at">x =</span> <span class="fu">TeX</span>(<span class="st">&quot;$theta$&quot;</span>), <span class="at">y =</span> <span class="st">&quot;Posterior density&quot;</span>) <span class="sc">+</span> <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> theta1, <span class="at">linetype =</span> <span class="st">&quot;dashed&quot;</span>, <span class="at">color =</span> <span class="st">&quot;red&quot;</span>, <span class="at">linewidth =</span> <span class="dv">1</span>) <span class="sc">+</span> <span class="fu">scale_color_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">&quot;blue&quot;</span>, <span class="st">&quot;red&quot;</span>)) <span class="sc">+</span>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb2-118"><a href="sec14_1.html#cb2-118" tabindex="-1"></a><span class="fu">theme</span>(<span class="at">legend.title =</span> <span class="fu">element_blank</span>())</span>
<span id="cb2-119"><a href="sec14_1.html#cb2-119" tabindex="-1"></a>df2 <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">Value =</span> <span class="fu">c</span>(PostChain[,<span class="dv">4</span>], PostChainOwn[,<span class="dv">4</span>]), <span class="at">Distribution =</span> <span class="fu">factor</span>(<span class="fu">c</span>(<span class="fu">rep</span>(<span class="st">&quot;BSL&quot;</span>, Sp), <span class="fu">rep</span>(<span class="st">&quot;BSLscratch&quot;</span>, Sp))))</span>
<span id="cb2-120"><a href="sec14_1.html#cb2-120" tabindex="-1"></a>deng <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(df2, <span class="fu">aes</span>(<span class="at">x =</span> Value, <span class="at">color =</span> Distribution)) <span class="sc">+</span> <span class="fu">geom_density</span>(<span class="at">linewidth =</span> <span class="dv">1</span>) <span class="sc">+</span> <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Posterior density plot: g&quot;</span>, <span class="at">x =</span> <span class="st">&quot;g&quot;</span>, <span class="at">y =</span> <span class="st">&quot;Posterior density&quot;</span>) <span class="sc">+</span></span>
<span id="cb2-121"><a href="sec14_1.html#cb2-121" tabindex="-1"></a><span class="fu">geom_vline</span>(<span class="at">xintercept =</span> g, <span class="at">linetype =</span> <span class="st">&quot;dashed&quot;</span>, <span class="at">color =</span> <span class="st">&quot;red&quot;</span>, <span class="at">linewidth =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb2-122"><a href="sec14_1.html#cb2-122" tabindex="-1"></a><span class="fu">scale_color_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">&quot;blue&quot;</span>, <span class="st">&quot;red&quot;</span>)) <span class="sc">+</span> <span class="fu">theme_minimal</span>() <span class="sc">+</span> <span class="fu">theme</span>(<span class="at">legend.title =</span> <span class="fu">element_blank</span>())</span>
<span id="cb2-123"><a href="sec14_1.html#cb2-123" tabindex="-1"></a>df3 <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">Value =</span> <span class="fu">c</span>(PostChain[,<span class="dv">5</span>], PostChainOwn[,<span class="dv">5</span>]), <span class="at">Distribution =</span> <span class="fu">factor</span>(<span class="fu">c</span>(<span class="fu">rep</span>(<span class="st">&quot;BSL&quot;</span>, Sp), <span class="fu">rep</span>(<span class="st">&quot;BSLscratch&quot;</span>, Sp))))</span>
<span id="cb2-124"><a href="sec14_1.html#cb2-124" tabindex="-1"></a>denk <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(df3, <span class="fu">aes</span>(<span class="at">x =</span> Value, <span class="at">color =</span> Distribution)) <span class="sc">+</span>   <span class="fu">geom_density</span>(<span class="at">linewidth =</span> <span class="dv">1</span>) <span class="sc">+</span> <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Posterior density plot: k&quot;</span>, <span class="at">x =</span> <span class="st">&quot;k&quot;</span>, <span class="at">y =</span> <span class="st">&quot;Posterior density&quot;</span>) <span class="sc">+</span> <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> k, <span class="at">linetype =</span> <span class="st">&quot;dashed&quot;</span>, <span class="at">color =</span> <span class="st">&quot;red&quot;</span>, <span class="at">linewidth =</span> <span class="dv">1</span>) <span class="sc">+</span> <span class="fu">scale_color_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">&quot;blue&quot;</span>, <span class="st">&quot;red&quot;</span>)) <span class="sc">+</span>  <span class="fu">theme_minimal</span>() <span class="sc">+</span> <span class="fu">theme</span>(<span class="at">legend.title =</span> <span class="fu">element_blank</span>())</span>
<span id="cb2-125"><a href="sec14_1.html#cb2-125" tabindex="-1"></a><span class="fu">library</span>(ggpubr)</span>
<span id="cb2-126"><a href="sec14_1.html#cb2-126" tabindex="-1"></a><span class="fu">ggarrange</span>(dentheta, deng, denk, <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">&quot;A&quot;</span>, <span class="st">&quot;B&quot;</span>, <span class="st">&quot;C&quot;</span>), <span class="at">ncol =</span> <span class="dv">3</span>, <span class="at">nrow =</span> <span class="dv">1</span>,</span>
<span id="cb2-127"><a href="sec14_1.html#cb2-127" tabindex="-1"></a><span class="at">legend =</span> <span class="st">&quot;bottom&quot;</span>, <span class="at">common.legend =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
</div>
</div>
<h3>References<a href="references.html#references" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-an2020robust" class="csl-entry">
An, Ziwen, David J Nott, and Christopher Drovandi. 2020. <span>“Robust Bayesian Synthetic Likelihood via a Semi-Parametric Approach.”</span> <em>Statistics and Computing</em> 30 (3): 543–57.
</div>
<div id="ref-an2022bsl" class="csl-entry">
An, Ziwen, Leah F South, and Christopher Drovandi. 2022. <span>“BSL: An r Package for Efficient Parameter Estimation for Simulation-Based Models via Bayesian Synthetic Likelihood.”</span> <em>Journal of Statistical Software</em> 101: 1–33.
</div>
<div id="ref-an2019accelerating" class="csl-entry">
An, Ziwen, Leah F South, David J Nott, and Christopher C Drovandi. 2019. <span>“Accelerating Bayesian Synthetic Likelihood with the Graphical Lasso.”</span> <em>Journal of Computational and Graphical Statistics</em> 28 (2): 471–75.
</div>
<div id="ref-beaumont2002approximate" class="csl-entry">
Beaumont, Mark A, Wenyang Zhang, and David J Balding. 2002. <span>“Approximate <span>B</span>ayesian Computation in Population Genetics.”</span> <em>Genetics</em> 162 (4): 2025–35.
</div>
<div id="ref-bertorelle2010abc" class="csl-entry">
Bertorelle, Giorgio, Andrea Benazzo, and S Mona. 2010. <span>“<span>ABC</span> as a Flexible Framework to Estimate Demography over Space and Time: <span>S</span>ome Cons, Many Pros.”</span> <em>Molecular Ecology</em> 19 (13): 2609–25.
</div>
<div id="ref-blum2010approximate" class="csl-entry">
Blum, Michael GB. 2010. <span>“Approximate <span>B</span>ayesian Computation: A Nonparametric Perspective.”</span> <em>Journal of the American Statistical Association</em> 105 (491): 1178–87.
</div>
<div id="ref-del2012adaptive" class="csl-entry">
Del Moral, Pierre, Arnaud Doucet, and Ajay Jasra. 2012. <span>“An Adaptive Sequential <span>M</span>onte <span>C</span>arlo Method for Approximate <span>B</span>ayesian Computation.”</span> <em>Statistics and Computing</em> 22: 1009–20.
</div>
<div id="ref-drovandi2011estimation" class="csl-entry">
Drovandi, Christopher C, and Anthony N Pettitt. 2011a. <span>“Estimation of Parameters for Macroparasite Population Evolution Using Approximate <span>B</span>ayesian Computation.”</span> <em>Biometrics</em> 67 (1): 225–33.
</div>
<div id="ref-drovandi2011likelihood" class="csl-entry">
———. 2011b. <span>“Likelihood-Free Bayesian Estimation of Multivariate Quantile Distributions.”</span> <em>Computational Statistics &amp; Data Analysis</em> 55 (9): 2541–56.
</div>
<div id="ref-drovandi2015bayesian" class="csl-entry">
Drovandi, Christopher C, Anthony N Pettitt, and Anthony Lee. 2015. <span>“Bayesian Indirect Inference Using a Parametric Auxiliary Model.”</span> <em>Statistical Science</em> 30 (1): 72--95.
</div>
<div id="ref-drovandi2022comparison" class="csl-entry">
Drovandi, Christopher, and David T Frazier. 2022. <span>“A Comparison of Likelihood-Free Methods with and Without Summary Statistics.”</span> <em>Statistics and Computing</em> 32 (3): 42.
</div>
<div id="ref-frazier2021robust" class="csl-entry">
Frazier, David T, and Christopher Drovandi. 2021. <span>“Robust Approximate Bayesian Inference with Synthetic Likelihood.”</span> <em>Journal of Computational and Graphical Statistics</em> 30 (4): 958–76.
</div>
<div id="ref-frazier2019approximate" class="csl-entry">
Frazier, David T, Worapree Maneesoonthorn, Gael M Martin, and Brendan PM McCabe. 2019. <span>“Approximate <span>B</span>ayesian Forecasting.”</span> <em>International Journal of Forecasting</em> 35 (2): 521–39.
</div>
<div id="ref-frazier2018asymptotic" class="csl-entry">
Frazier, David T, Gael M Martin, Christian P Robert, and Judith Rousseau. 2018. <span>“Asymptotic Properties of Approximate <span>B</span>ayesian Computation.”</span> <em>Biometrika</em> 105 (3): 593–607.
</div>
<div id="ref-frazier2020model" class="csl-entry">
Frazier, David T, Christian P Robert, and Judith Rousseau. 2020. <span>“Model Misspecification in Approximate <span>B</span>ayesian Computation: Consequences and Diagnostics.”</span> <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em> 82 (2): 421–44.
</div>
<div id="ref-nott2023bayesian" class="csl-entry">
Frazier, David, David J Nott, Christopher Drovandi, and Robert Kohn. 2023. <span>“Bayesian Inference Using Synthetic Likelihood: <span>A</span>symptotics and Adjustments.”</span> <em>Journal of the American Statistical Association</em> 118 (544): 2821--2832.
</div>
<div id="ref-jiang2018approximate" class="csl-entry">
Jiang, Bai. 2018. <span>“Approximate Bayesian Computation with Kullback-Leibler Divergence as Data Discrepancy.”</span> In <em>International Conference on Artificial Intelligence and Statistics</em>, 1711–21. PMLR.
</div>
<div id="ref-lenormand2013adaptive" class="csl-entry">
Lenormand, Maxime, Franck Jabot, and Guillaume Deffuant. 2013. <span>“Adaptive Approximate <span>B</span>ayesian Computation for Complex Models.”</span> <em>Computational Statistics</em> 28 (6): 2777–96.
</div>
<div id="ref-leuenberger2010Bayesian" class="csl-entry">
Leuenberger, Christoph, and Daniel Wegmann. 2010. <span>“<span>B</span>ayesian Computation and Model Selection Without Likelihoods.”</span> <em>Genetics</em> 184 (1): 243–52.
</div>
<div id="ref-lintusaari2017fundamentals" class="csl-entry">
Lintusaari, Jarno, Michael U Gutmann, Ritabrata Dutta, Samuel Kaski, and Jukka Corander. 2017. <span>“Fundamentals and Recent Developments in Approximate Bayesian Computation.”</span> <em>Systematic Biology</em> 66 (1): e66–82.
</div>
<div id="ref-marjoram2003markov" class="csl-entry">
Marjoram, Paul, John Molitor, Vincent Plagnol, and Simon Tavaré. 2003. <span>“Markov Chain <span>M</span>onte <span>C</span>arlo Without Likelihoods.”</span> <em>Proceedings of the National Academy of Sciences of the USA</em> 100 (26): 15324–28.
</div>
<div id="ref-martin2024approximating" class="csl-entry">
Martin, Gael M, David T Frazier, and Christian P Robert. 2024. <span>“Approximating Bayes in the 21st Century.”</span> <em>Statistical Science</em> 39 (1): 20–45.
</div>
<div id="ref-price2018bayesian" class="csl-entry">
Price, Leah F, Christopher C Drovandi, Anthony Lee, and David J Nott. 2018. <span>“Bayesian Synthetic Likelihood.”</span> <em>Journal of Computational and Graphical Statistics</em> 27 (1): 1–11.
</div>
<div id="ref-pritchard1999population" class="csl-entry">
Pritchard, Jonathan K, Mark T Seielstad, Anna Perez-Lezaun, and Marcus W Feldman. 1999. <span>“Population Growth of Human <span>Y</span> Chromosomes: A Study of <span>Y</span> Chromosome Microsatellites.”</span> <em>Molecular Biology and Evolution</em> 16 (12): 1791–98.
</div>
<div id="ref-ramirez2024testing" class="csl-entry">
Ramı́rez-Hassan, Andrés, and David T. Frazier. 2024. <span>“Testing Model Specification in Approximate Bayesian Computation Using Asymptotic Properties.”</span> <em>Journal of Computational and Graphical Statistics</em> 33 (3): 1–14.
</div>
<div id="ref-rayner2002numerical" class="csl-entry">
Rayner, Glen D, and Helen L MacGillivray. 2002. <span>“Numerical Maximum Likelihood Estimation for the g-and-k and Generalized g-and-h Distributions.”</span> <em>Statistics and Computing</em> 12 (1): 57–75.
</div>
<div id="ref-rubin1984Bayesianly" class="csl-entry">
Rubin, Donald B. 1984. <span>“<span>B</span>ayesianly Justifiable and Relevant Frequency Calculations for the Applies Statistician.”</span> <em>The Annals of Statistics</em> 12 (4): 1151–72.
</div>
<div id="ref-sisson2007sequential" class="csl-entry">
Sisson, Scott A, Yanan Fan, and Mark M Tanaka. 2007. <span>“Sequential <span>M</span>onte <span>C</span>arlo Without Likelihoods.”</span> <em>Proceedings of the National Academy of Sciences of the USA</em> 104 (6): 1760–65.
</div>
<div id="ref-sisson2018handbook" class="csl-entry">
Sisson, Scott A, Fan, Yanan, Beaumont, and Mark. 2018. <em>Handbook of <span>A</span>pproximate <span>B</span>ayesian <span>C</span>omputation</em>. CRC Press.
</div>
<div id="ref-tavare1997inferring" class="csl-entry">
Tavaré, Simon, David J Balding, Robert C Griffiths, and Peter Donnelly. 1997. <span>“Inferring Coalescence Times from <span>DNA</span> Sequence Data.”</span> <em>Genetics</em> 145 (2): 505–18.
</div>
<div id="ref-wegmann2009efficient" class="csl-entry">
Wegmann, Daniel, Christoph Leuenberger, and Laurent Excoffier. 2009. <span>“Efficient Approximate <span>B</span>ayesian Computation Coupled with <span>M</span>arkov Chain <span>M</span>onte <span>C</span>arlo Without Likelihood.”</span> <em>Genetics</em> 182 (4): 1207–18.
</div>
<div id="ref-wood2010statistical" class="csl-entry">
Wood, Simon N. 2010. <span>“Statistical Inference for Noisy Nonlinear Ecological Dynamic Systems.”</span> <em>Nature</em> 466 (7310): 1102–4.
</div>
</div>
<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p>Note that this setting does not satisfy the asymptotic requirements for Bayesian consistency. However, it serves as a pedagogical exercise.<a href="sec14_1.html#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p>There are better ways to calculate the covariance matrix, see <span class="citation">D. Frazier et al. (<a href="#ref-nott2023bayesian">2023</a>)</span>.<a href="sec14_1.html#fnref2" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="Chap14.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="sec14_2.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": true,
    "facebook": true,
    "twitter": true,
    "linkedin": false,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": false,
    "all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
  },
  "fontsettings": {
    "theme": "white",
    "family": "sans",
    "size": 2
  },
  "edit": {
    "link": "https://github.com/aramir21/IntroductionBayesianEconometricsBook/14-ApproximationMethods.Rmd",
    "text": "Edit"
  },
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": null,
    "text": null
  },
  "download": null,
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "subsection"
  }
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
