# Basic formal concepts {#basics}

We introduce formal concepts in Bayesian inference starting with the Bayesâ€™ rule, all its components with their formal definitions and basic examples. In addition, we present some nice features of Bayesian inference such as Bayesian updating, and asymptotic sampling properties, and the basics of Bayesian inference based on decision theory under uncertainty, presenting important concepts like loss function, risk function and optimal rules.

## The Bayes' rule {#sec11}

As expected the point of departure to perform Bayesian inference is the Bayes' rule,^[Observe that I use the term "Bayes' rule" rather than "Bayes' theorem. It was Laplace [@laplace1774memoire] who actually generalized the Bayes' theorem [@bayes1763lii]. His generalization is named the Bayes' rule.] that is, the conditional probability of $A_i$ given $B$ is equal to the conditional probability of $B$ given $A_i$ times the marginal probability of $A_i$ over the marginal probability of $B$,

\begin{align}
  P(A_i|B)&=\frac{P(A_i,B)}{P(B)}\\
        &=\frac{P(B|A_i) \times P(A_i)}{P(B)},
  (\#eq:111)
\end{align}

where by the law of total probability $P(B)=\sum_i P(B|A_i)P(A_i)\neq 0$, $\left\{A_i, i=1,2,\dots\right\}$ is a finite or countably infinite partition of a sample space.

In the Bayesian framework, $B$ is sample information that updates a probabilistic statement about an unknown object $A_i$ following probability rules. This is done by means of the Bayes' rule using prior "beliefs" about $A_i$, that is, $P(A_i)$, sample information relating $B$ to the particular state of the nature $A_i$ through a probabilistic statment, $P(B|A_i)$, and the probability of observing that specific sample information $P(B)$.  

Let's see a simple example, *the base rate fallacy*:

Assume that the sample information comes from a positive result from a test whose true positive rate (sensitivity) is 98%, $P(+|\text{disease})=0.98$. On the other hand, the prior information regarding being infected with this disease comes from a base incidence rate that is equal to 0.002, that is $P(\text{disease})=0.002$. Then, **what is the probability of being actually infected?**

This is an example of *the base rate fallacy*, where having a positive test result from a disease whose base incidence rate is tiny gives a low probability of actually having the disease.

The key to answer the question is based on understanding the difference between the probability of having the disease given a positive result, $P(\text{disease}|+)$, versus the probability of a positive result given the disease, $P(+|\text{disease})$. The former is the important result, and the Bayes' rule helps us to get the answer. Using the Bayes' rule (equation \@ref(eq:111)):

\begin{equation}
  P(\text{disease}|+) = \frac{P(+|\text{disease})\times P(\text{disease})}{P(+)},
\end{equation}

where $P(+)=P(+|\text{disease})\times P(\text{disease})+P(+|\lnot\text{disease})\times P( \lnot\text{disease})$,^[$\lnot$ is the negation symbol.]

```{r}
PD <- 0.002 # Probability of disease
PPD <- 0.98 # True positive (Sensitivity)
PDP <- PD * PPD / (PD * PPD + (1 - PD) * (1 - PPD)) # Probability of disease given positive
paste("Probability of disease given a positive test is", sep = " ", round(PDP, 2))
```

We observe that despite of having a positive result, the probability of having the disease is low. This due to the base rate being tiny.

Another interesting example, which is at the heart of the origin of the Bayes' theorem [@bayes1763lii], is related to the existence of God [@stigler2018richard]. The Section X of David Hume's "An Enquiry concerning Human Understanding, 1748" is named *Of Miracles*. There, Hume argues that when someone claims to have seen a miracle, this is poor evidence it actually happened, since it goes against what we see every day. Then, Richard Price, who actually finished and published "An essay towards solving a problem in the doctrine of chances" in 1763 after Bayes died in 1761, argues against Hume saying that there is a huge difference between *impossibility* as used commonly in conversation and *physical impossibility*. Price used an example of a die with a million sides, where the former is getting a particular side when throwing this die, and the latter is getting a side that does not exist. In millions throws, the latter case never would occur, but the former eventually would.

Let's say that there are two cases of resurrection (Res), Jesus Christ and Elvis, and the total number of people who have ever lived is 108.5 trillion,^[https://www.wolframalpha.com/input/?i=number+of+people+who+have+ever+lived+on+Earth] then the prior base rate is 2/108,500,000,000. On the other hand, the sample information comes from a very reliable witness whose true positive rate is  0.9999999. Then, **what is the probability of this miracle?**^[https://www.r-bloggers.com/2019/04/base-rate-fallacy-or-why-no-one-is-justified-to-believe-that-jesus-rose/] 

Using the Bayes' rule:

\begin{equation}
  P(\text{Res}|\text{Witness}) = \frac{P(\text{Witness}|\text{Res})\times P(\text{Res})}{P(\text{Witness})},
\end{equation}

where $P(\text{Witness})=P(\text{Witness}|\text{Res})\times P(\text{Res})+(1-P(\text{Witness}|\text{Res}))\times (1-P(\text{Res}))$,

```{r}
PR <- 2/108500000000 # Probability of resurrection
PWR <- 0.9999999 # Very reliable witness (true positive rate)
PRW <- PR * PWR / (PR * PWR + (1 - PR) * (1 - PWR)) # Probability of resurrection given witness
paste("Probability of resurrection given witness is", sep = " ", PRW)
```

Observe that we can get a conditional version of the Bayes' rule. Let's have two conditioning events $B$ and $C$, then equation \@ref(eq:111) becomes

\begin{align}
  P(A_i|B,C)&=\frac{P(A_i,B,C)}{P(B,C)}\\
        &=\frac{P(B|A_i,C) \times P(A_i|C) \times P(C)}{P(B|C)P(C)},
  (\#eq:112)
\end{align}

Let's use one of the most intriguing statistical puzzles, **the Monty Hall problem**, to illustrate how to use equation \@ref(eq:112)([@selvin1975problem], [@selvin1975bproblem]). This was the situation faced by a contestant in the American television game show *Let's Make a Deal*. There, the contestant was asked to choose a door where behind one door there is a car, and behind the others, goats. Let's say that the contestant picks door No. 1, and the host (Monty Hall), who knows what is behind each door, opens door No. 3, where there is a goat. Then, the host asks the tricky question to the contestant, **do you want to pick door No. 2?**

Let's name $P_i$ the event *contestant picks door No. $i$*, $H_i$ the event *host picks door No. $i$*, and $C_i$ the event *car is behind door No. $i$*. In this particular setting, the contestant is interested in the probability of the event $P(C_2|H_3,P_1)$. A naive answer would be that it is irrelevant as initially $P(C_i)=1/3, \ i=1,2,3$, and now $P(C_i|H_3)=1/2, \ i=1,2$ as the host opened door No. 3. So, why bothering changing the initial guess if the odds are the same? The important point here is that the host knows what is behind each door and randomly picks a door given contestant choice. That is, $P(H_3|C_3,P_1)=0$, $P(H_3|C_2,P_1)=1$ and $P(H_3|C_1,P_1)=1/2$. Then, using equation \@ref(eq:112) 

\begin{align}
  P(C_2|H_3,P_1)&= \frac{P(C_2,H_3,P_1)}{P(H_3,P_1)}\\
                &= \frac{P(H_3|C_2,P_1)P(C_2|P_1)P(P_1)}{P(H_3|P_1)\times P(P_1)}\\
                &= \frac{P(H_3|C_2,P_1)P(C_2)}{P(H_3|P_1)}\\
                &=\frac{1\times 1/3}{1/2}\\
                &=\frac{2}{3},
\end{align}
where the third equation uses the fact that $C_i$ and $P_i$ are independent events, and $P(H_3|P_1)=1/2$ due to this depending just on $P_1$ (not on $C_2$).

Therefore, changing the initial decision increases the probability of getting the car from 1/3 to 2/3!

Let's see a simulation exercise to check this answer:

```{r}
set.seed(0101) # Set simulation seed
S <- 100000 # Simulations
Game <- function(switch = 0){
  # switch = 0 is not change, and switch = 1 is to change
  opts <- 1:3 
  car <- sample(opts, 1) # car location
  guess1 <- sample(opts, 1) # Initial guess pick
  
  if(car != guess1) {
    host <- opts[-c(car, guess1)]
    } else {
    host <- sample(opts[-c(car, guess1)], 1)
    }
  
  win1 <- guess1 == car # Win given no change
  
  guess2 <- opts[-c(host, guess1)]
  
  win2 <- guess2 == car # Win given change
  
  if(switch == 0){
    win <- win1
  } else {
      win <- win2
    }
  
  return(win)
}

Prob <- mean(replicate(S, Game(switch = 0))) #Win probabilities not changing
paste("Winning probabilities no changing door is", Prob, sep = " ")

Prob <- mean(replicate(S, Game(switch = 1))) #Win probabilities changing
paste("Winning probabilities changing door is", Prob, sep = " ")
```

## Bayesian framework: A brief summary of theory {#sec12}

For two random objects $\mathbf{\theta}$ and $\mathbf{y}$, the Bayes' rule may be analogously used,^[From a Bayesian perspective $\mathbf{\theta}$ is fixed, but unknown. Then, it is treated as a random object.]

\begin{align}
  \pi(\mathbf{\theta}|\mathbf{y})&=\frac{p(\mathbf{y}|\mathbf{\theta}) \times \pi(\mathbf{\theta})}{p(\mathbf{y})},
  (\#eq:121)
\end{align}

where $\pi(\mathbf{\theta}|\mathbf{y})$ is the posterior density function, $\pi(\mathbf{\theta})$ is the prior density, $p(\mathbf{y}|\mathbf{\theta})$ is the likelihood (statistical model), and

\begin{equation}
p(\mathbf{y})=\int_{\mathbf{\Theta}}p(\mathbf{y}|\mathbf{\theta})\pi(\mathbf{\theta})d\mathbf{\theta}=\mathbb{E}\left[p(\mathbf{y}|\mathbf{\theta})\right]
(\#eq:121a)
\end{equation}

is the marginal likelihood or prior predictive.

*Remarks*

Observe that $p(\mathbf{y}|\mathbf{\theta})$ is not a density in $\mathbf{\theta}$. In addition, $\pi(\mathbf{\theta})$ does not have to integrate to 1, that is, $\pi(\mathbf{\theta})$ can be an improper density function, $\int_{\mathbf{\Theta}}\pi(\mathbf{\theta})d\mathbf{\theta}=\infty$. However, $\pi(\mathbf{\theta}|\mathbf{y})$ is a proper density function, that is, $\int_{\mathbf{\Theta}}\pi(\mathbf{\theta}|\mathbf{y})=1$. For instance, set $\pi(\mathbf{\theta})=c$, where $c$ is a constant, then $\int_{\mathbf{\Theta}}cd\mathbf{\theta}=\infty$. However, $\int_{\mathbf{\Theta}}\pi(\mathbf{\theta}|\mathbf{y})d\mathbf{\theta}=\int_{\mathbf{\Theta}}\frac{p(\mathbf{y}|\mathbf{\theta})\times c}{\int_{\mathbf{\Theta}} p(\mathbf{y}|\mathbf{\theta})\times c d\mathbf{\theta}}d\mathbf{\theta}=1$ where $c$ cancels out.  

$\pi(\mathbf{\theta}|\mathbf{y})$ is a sample updated "probabilistic belief" version of $\pi(\mathbf{\theta})$, where $\pi(\mathbf{\theta})$ is a prior probabilistic belief which can be constructed from previous empirical work, theory foundations, expert knowledge and/or mathematical convenience. This prior usually depends on parameters, which are named *hyperparameters*. In addition, the Bayesian approach implies using a probabilistic model about $\mathbf{y}$ given $\mathbf{\theta}$, that is, $p(\mathbf{y}|\mathbf{\theta})$, where its integral over $\mathbf{\Theta}$, $p(\mathbf{y})$ is named *the model evidence* due to being a measure of model fit to the data.

Observe that the Bayesian inferential approach is conditional, that is, what can we learn about an unknown object $\mathbf{\theta}$ given that we already observed $\mathbf{y}$? The answer is also conditional on the probabilistic model, that is $p(\mathbf{y}|\mathbf{\theta})$. So, what if we want to compare different models, let's say $\mathcal{M}_m$, $m=\left\{1,2,\dots,M\right\}$. Then, we should make explicit this in the Bayes' rule formulation, 

\begin{align}
  \pi(\mathbf{\theta}|\mathbf{y},\mathcal{M}_m)&=\frac{p(\mathbf{y}|\mathbf{\theta},\mathcal{M}_m) \times \pi(\mathbf{\theta}|\mathcal{M}_m)}{p(\mathbf{y}|\mathcal{M}_m)}.
  (\#eq:122)
\end{align}

The posterior model probability is

\begin{align}
  \pi(\mathcal{M}_m|\mathbf{y})&=\frac{p(\mathbf{y}|\mathcal{M}_m) \times \pi(\mathcal{M}_m)}{p(\mathbf{y})}, 
  (\#eq:123)
\end{align}

  where $p(\mathbf{y}|\mathcal{M}_m)=\int_{\mathbf{\Theta}}p(\mathbf{y}|\mathbf{\theta},\mathcal{M}_m) \times \pi(\mathbf{\theta}|\mathcal{M}_m)d\mathbf{\theta}$ due to equation \@ref(eq:122), and $\pi(\mathcal{M}_m)$ is the prior model probability. 
  
Calculating $p(\mathbf{y})$ in equations \@ref(eq:121) and \@ref(eq:123) is very demanding most of the realistic cases. Fortunately, it is not required when performing inference about $\mathbf{\theta}$ as this is integrated out from it. Then, all what you need to know about the shape of $\mathbf{\theta}$ is in $p(\mathbf{y}|\mathbf{\theta},\mathcal{M}_m) \times \pi(\mathbf{\theta}|\mathcal{M}_m)$ or without explicitly conditioning on $\mathcal{M}_m$,^[$\propto$ is the proportional symbol.]

\begin{align}
  \pi(\mathbf{\theta}|\mathbf{y})& \propto p(\mathbf{y}|\mathbf{\theta}) \times \pi(\mathbf{\theta}).
  (\#eq:124)
\end{align}

Equation \@ref(eq:124) is a very good shortcut to perform Bayesian inference about $\mathbf{\theta}$.

We also can avoid calculating $p(\mathbf{y})$ when performing model selection (hypothesis testing) using posterior odds ratio, that is, comparing models $\mathcal{M}_1$ and $\mathcal{M}_2$,

\begin{align}
  PO_{12}&=\frac{\pi(\mathcal{M}_1|\mathbf{y})}{\pi(\mathcal{M}_2|\mathbf{y})}\\
  &=\frac{\pi(\mathbf{y}|\mathcal{M}_1)}{\pi(\mathbf{y}|\mathcal{M}_2)}\times\frac{\pi(\mathcal{M}_1)}{\pi(\mathcal{M}_2)},
  (\#eq:125)
\end{align}

where the first term in equation \@ref(eq:125) is named the Bayes Factor, and the second term is the prior odds. Observe that the Bayes Factor is a ratio of ordinates for $\mathbf{y}$ under different models. Then, the Bayes Factor is a measure of relative sample evidence in favor of model 1 compared to model 2. 

However, we still need to calculate $p(\mathbf{y}|\mathcal{M}_m)=\int_{\mathbf{\Theta}}p(\mathbf{y}|\mathbf{\theta},\mathcal{M}_m)\pi(\mathbf{\theta}|\mathcal{M}_m)d\mathbf{\theta}=\mathbb{E}\left[p(\mathbf{y}|\mathbf{\theta},\mathcal{M}_m)\right]$. For this integral to be meaningful, the prior must be proper. Using improper prior has unintended consequences when comparing models. 

A nice feature of this approach is that if we have an exhaustive set of compiting models such that $\sum_{m=1}^M \pi(\mathcal{M}_m|\mathbf{y})=1$, then we can recover $\pi(\mathcal{M}_m|\mathbf{y})$ without calculating $p(\mathbf{y})$. In particular, given two models $\mathcal{M}_1$ and $\mathcal{M}_2$ such that $\pi(\mathcal{M}_1|\mathbf{y})+\pi(\mathcal{M}_2|\mathbf{y})=1$. Then, $\pi(\mathcal{M}_1|\mathbf{y})=\frac{PO_{12}}{1+PO_{12}}$ and $\pi(\mathcal{M}_2|\mathbf{y})=1-\pi(\mathcal{M}_1|\mathbf{y})$. In general, $\pi(\mathcal{M}_m|\mathbf{y})=\frac{\pi(\mathbf{y}|\mathcal{M}_m)\times \pi(\mathcal{M}_m)}{\sum_{l=1}^M \pi(\mathbf{y}|\mathcal{M}_l)\times \pi(\mathcal{M}_l)}$.

Table \@ref(tab:guide) shows guidelines for the interpretation of $2\log(PO_{12})$ [@Kass1995]. This is done to replicate the structure of the likelihood ratio test statistic. However, posterior odds do not require nested models as the likelihood ratio test does.

```{r guide, echo=FALSE, results='asis'}

c1 <- c('0 to 2', '2 to 6', '6 to 10', '> 10')
c2 <- c('1 to 3', '3 to 20', '20 to 150', '> 150')
c3 <- c('Not worth more than a bare mention', 'Positive', 'Strong', 'Very strong')
tab <- cbind(c1, c2, c3)
colnames(tab) <- c('$2\\log(PO_{12})$', '$PO_{12}$', 'Evidence against $\\mathcal{M}_{2}$')
knitr::kable(tab, booktabs = TRUE, caption = 'Kass and Raftery guidelines', escape = FALSE)
```

The Bayesian approach is also suitable to get probabilistic predictions, that is, we can obtain a posterior predictive density 

\begin{align}
  \pi(\mathbf{Y}_0|\mathbf{y},\mathcal{M}_m) & =\int_{\mathbf{\Theta}}\pi(\mathbf{Y}_0,\mathbf{\theta}|\mathbf{y},\mathcal{M}_m)d\mathbf{\theta}\\
  &=\int_{\mathbf{\Theta}}\pi(\mathbf{Y}_0|\mathbf{\theta},\mathbf{y},\mathcal{M}_m)\pi(\mathbf{\theta}|\mathbf{y},\mathcal{M}_m)d\mathbf{\theta}.
  (\#eq:126)
\end{align}

Observe that equation \@ref(eq:126) is again an expectation $\mathbb{E}[\pi(\mathbf{Y}_0|\mathbf{\theta},\mathbf{y},\mathcal{M}_m)]$, this time using the posterior distribution. Therefore,  the Bayesian approach takes estimation error into account when performing prediction. 

As we have shown many times, expectation (integration) is a common feature in Bayesian inference. That is why the remarkable relevance of computation based on Monte Carlo integration in the Bayesian framework.  

If we want to consider model uncertainty in prediction or any unknown probabilistic object, we can follow same arguments. In the prediction case, 

\begin{align}
  \pi(\mathbf{Y}_0|\mathbf{y})&=\sum_{m=1}^M \pi(\mathcal{M}_m|\mathbf{y})\pi(\mathbf{Y}_0|\mathbf{y},\mathcal{M}_m),
\end{align}

and parameters case,

\begin{align}
  \pi(\mathbf{\theta}|\mathbf{y})&=\sum_{m=1}^M \pi(\mathcal{M}_m|\mathbf{y})\pi(\mathbf{\theta}|\mathbf{y},\mathcal{M}_m),
\end{align}

where 

\begin{align}
\mathbb{E}(\mathbf{\theta}|\mathbf{y})=\sum_{m=1}^{M}\hat{\mathbf{\theta}}_m \pi(\mathcal{M}_m|\mathbf{y}),
(\#eq:127)
\end{align}

and

\begin{align}
Var(\mathbf{\theta}|\mathbf{y})= \sum_{m=1}^{M}\pi(\mathcal{M}_m|\mathbf{y}) \widehat{Var} (\mathbf{\theta}|\mathbf{y},\mathcal{M}_m)+\sum_{m=1}^{M} \pi(M_m|\mathbf{y}) (\hat{\mathbf{\theta}}_m-\mathbb{E}[\mathbf{\theta}|\mathbf{y})]^2,
(\#eq:128)
\end{align}

$\hat{\mathbf{\theta}}_m$ and $\widehat{Var}(\mathbf{\theta}|\mathbf{y},\mathcal{M}_m)$ are the posterior mean and variance under model $m$, respectively.

Observe how the variance in equation \@ref(eq:128) encloses extra variability due to potential differences between mean posterior estimates associated with each model, and the posterior mean involving model uncertainty in equation \@ref(eq:127). The previous equations illustrates Bayesian model average (BMA).

A nice advantage of the Bayesian approach, which is very useful in *state space* models (See Chapter \@ref(time)), is the way that the posterior distribution updates with new sample information. Given $\mathbf{y}=\mathbf{y}_{1:t+1}$ a sequence of observations, then

\begin{align}
  \pi(\mathbf{\theta}|\mathbf{y}_{1:t+1})&\propto p(\mathbf{y}_{1:t+1}|\mathbf{\theta})\times \pi(\mathbf{\theta})\\
  &= p(y_{t+1}|\mathbf{y}_{1:t},\mathbf{\theta})\times p(\mathbf{y}_{1:t}|\mathbf{\theta})\times \pi(\mathbf{\theta})\\
  &\propto p(y_{t+1}|\mathbf{y}_{1:t},\mathbf{\theta})\times \pi(\mathbf{\theta}|\mathbf{y}_{1:t}). 
\end{align}

We observe that the new prior is just the posterior distribution using the previous observation. This is particular useful under the assumption of *conditional independence*, that is, $y_{t+1}\perp\mathbf{y}_{1:t}|\mathbf{\theta}$,^[$\perp$ is the independence symbol.] then $p(y_{t+1}|\mathbf{y}_{1:t},\mathbf{\theta})=p(y_{t+1}|\mathbf{\theta})$ such that the posterior can be recovered recursively [@petris2009dynamic]. This facilities online updating due to all information up to $t$ being in $\mathbf{\theta}$. Then, $\pi(\mathbf{\theta}|\mathbf{y}_{1:t+1})\propto p(y_{t+1}|\mathbf{\theta})\times \pi(\mathbf{\theta}|\mathbf{y}_{1:t})\propto\prod_{h=1}^{t+1} p(y_h|\mathbf{\theta})\times \pi(\mathbf{\theta})$. This recursive expression can be calculated faster at some specific point in time $t$ compared to a batch mode algoritm, which requires procesing simultaneously all information up to $t$.

It also important to wonder about the sampling properties of Bayesian *estimators*. This topic has attracted attention of econometricians (and statisticians) long time ago. For instance, asymptotic posterior concentration at the population parameter vector is discussed by [@bickel1969some]. Convergence of posterior distributions is stated by the Bernstein-von Mises theorem [@Lehmann2003], which creates a link between credible intervals (sets) and confidence intervals (sets). In particular, it shows that Bayesian credible intervals with $\alpha$ level convergences asymptotically to confidence intervals at $\alpha$ level. This suggests that Bayesian inference is asymptotically correct from a sampling perspective.

A heuristic approach to show this in the simpliest case where we assume random sampling and $\theta\in R$ is the following: $p(\mathbf{y}|\theta)=\prod_{i=1}^N p(y_i|\theta)$ such that the log likelihood is $\mathcal{l}(\mathbf{y}|\theta)\equiv\log p(\mathbf{y}|\theta)=\sum_{i=1}^N \log p(y_i|\theta)=N\times \bar{\mathcal{l}}(\mathbf{y}|\theta)$ where $\bar{\mathcal{l}}\equiv\frac{1}{N}\sum_{i=1}^N \log p(y_i|\theta)$ is the mean likelihood. Then, the posterior distribution is proportional to 

\begin{align}
  \pi(\theta|\mathbf{y})&\propto p(\mathbf{y}|\theta) \times \pi(\theta)\\
  &=\exp\left\{N\times \bar{\mathcal{l}}(\mathbf{y}|\theta)\right\} \times \pi(\theta).
\end{align}

Observe that as the sample size gets large, that is, $N\rightarrow \infty$, the exponential term should dominate the prior distribution as long as this does not depend on $N$ such that the likelihood determines the posterior distribution.

Maximum likelihood theory shows that $\lim_{N\to\infty} \bar{\mathcal{l}}(\mathbf{y}|\theta)\rightarrow \bar{\mathcal{l}}(\mathbf{y}|\theta_0)$ where $\theta_0$ is the population parameter of the data generating process. In addition, doing a second order Taylor expansion of the log likelihood at the Maximum likelihood estimator,

\begin{align}
\mathcal{l}(\mathbf{y}|\theta)&\approx \mathcal{l}(\mathbf{y}|\hat{\theta})+\left.\frac{1}{2}\frac{d\mathcal{l}(\mathbf{y}|{\theta})}{d\theta}\right\vert_{\hat{\theta}}(\hat{\theta}-\theta_0)+\left.\frac{d^2\mathcal{l}(\mathbf{y}|{\theta})}{d\theta^2}\right\vert_{\hat{\theta}}(\hat{\theta}-\theta_0)^2\\
&= \mathcal{l}(\mathbf{y}|\hat{\theta})+\frac{1}{2}\left.\sum_{i=1}^N\frac{d^2\mathcal{l}(y_i|{\theta})}{d\theta^2}\right\vert_{\hat{\theta}}(\hat{\theta}-\theta_0)^2\\
&= \mathcal{l}(\mathbf{y}|\hat{\theta})-\frac{1}{2}\left.N\left[-\bar{\mathcal{l}}''\right\vert_{\hat{\theta}}\right](\hat{\theta}-\theta_0)^2\\
&= \mathcal{l}(\mathbf{y}|\hat{\theta})-\frac{N}{2\sigma^2}(\hat{\theta}-\theta_0)^2\\ 
\end{align}

where $\left.\frac{d\mathcal{l}(\mathbf{y}|\theta)}{d\theta}\right\vert_{\hat{\theta}}=0$, $\bar{\mathcal{l}}''\equiv\frac{1}{N}\left.\sum_{i=1}^N\frac{d^2\mathcal{l}(y_i|{\theta})}{d\theta^2}\right\vert_{\hat{\theta}}$ and $\sigma^2=\left[\left.-\bar{\mathcal{l}}''\right\vert_{\hat{\theta}}\right]^{-1}$. Then,

\begin{align}
  \pi(\theta|\mathbf{y})&\propto \exp\left\{{\mathcal{l}}(\mathbf{y}|\theta)\right\} \times \pi(\theta)\\
  &\approx \exp\left\{\mathcal{l}(\mathbf{y}|\hat{\theta})-\frac{N}{2\sigma^2}(\hat{\theta}-\theta_0)^2\right\} \times \pi(\theta)\\
  &\propto \exp\left\{-\frac{N}{2\sigma^2}(\hat{\theta}-\theta_0)^2\right\} \times \pi(\theta)\\ 
\end{align}

Observe that we have that the posterior density is proportional to the kernel of a normal density with mean $\hat{\theta}$ and variance $\sigma^2/N$ as long as $\pi(\hat{\theta})\neq 0$. This kernel dominates as the sample size gets large due to N in the exponential term. Observe that the prior should not exclude values of $\theta$ that are logically possible, such as $\hat{\theta}$.

**Example: Health insurance**

Suppose that you are analyzing to buy a health insurance next year. To make a better decision you want to know **what is the probability that you visit your Doctor at least once next year?** To answer this question you have records of the number of times that you have visited your Doctor the last 5 years, $\mathbf{y}=[0, 3, 2, 1, 0]$. How to proceed?

Assuming that this is a random sample^[Independent and identically distribuited draws.] from a data generating process (statistical model) that is Poisson, that is, $Y_i\sim P(\lambda)$, and your probabilistic prior beliefs about $\lambda$ are well described by a Gamma distribution with shape and scale parameters $\alpha_0$ and $\beta_0$, $\lambda\sim G(\alpha_0, \beta_0)$, then, you are interested in calculating the probability $P(y_0>0|\mathbf{y})$. You need to calculate the posterior predictive density $\pi(y_0|\mathbf{y})$ to answer this question in a Bayesian way.

In this example, $p(\mathbf{y}|\lambda)$ is Poisson, and $\pi(\lambda)$ is Gamma. Then, using \@ref(eq:126) 

\begin{align}
  \pi(Y_0|\mathbf{y})=&\int_{0}^{\infty}\frac{\lambda^{y_0}\exp\left\{-\lambda\right\}}{y_0!}\times \pi(\lambda|\mathbf{y})d\lambda,\\
\end{align}

where the posterior distribution is 

\begin{align}
  \pi(\lambda|\mathbf{y})&\propto\frac{1}{\Gamma(\alpha_0)\beta_0^{\alpha_0}}\lambda^{\alpha_0-1}\exp\left\{-\lambda/\beta_0\right\}\prod_{i=1}^N \frac{\lambda^{y_i}\exp\left\{-\lambda\right\}}{y_i!}\\
  &\propto \lambda^{\sum_{i=1}^N y_i + \alpha_0 - 1}\exp\left\{-\lambda\left(\frac{\beta_0 N+1}{\beta_0}\right)\right\},
  
\end{align}

by equation \@ref(eq:121). $\Gamma(\cdot)$ is the gamma function.

Observe that the last expression is the kernel of a Gamma distribution with parameters $\alpha_n=\sum_{i=1}^N y_i + \alpha_0$ and $\beta_n=\frac{\beta_0}{\beta_0 N + 1}$. Given that $\int_0^{\infty}\pi(\lambda|\mathbf{y})d\lambda=1$, then the constant of proportionality in the last expression is $\Gamma(\alpha_n)\beta_n^{\alpha_n}$. The posterior density function $\pi(\lambda|\mathbf{y})$ is $G(\alpha_n,\beta_n)$.

Observe that 

\begin{align}
  \mathbb{E}[\lambda|\mathbf{y}]&=\alpha_n\beta_n\\
  &=\left(\sum_{i=1}^N y_i + \alpha_0\right)\left(\frac{\beta_0}{\beta_0 N + 1}\right)\\
  &=\bar{y}\left(\frac{N\beta_0}{N\beta_0+1}\right)+\alpha_0\beta_0\left(\frac{1}{N\beta_0+1}\right)\\
  &=w\bar{y}+(1-w)\mathbb{E}[\lambda],
\end{align}

where $\bar{y}$ is the sample mean, which is the maximum likelihood estimator of $\lambda$, $w=\left(\frac{N\beta_0}{N\beta_0+1}\right)$ and $\mathbb{E}[\lambda]=\alpha_0\beta_0$ is the prior mean. The posterior mean is a weighted average of the maximum likelihood estimator (sample information) and the prior mean. Observe that $\lim_{N\rightarrow\infty}w= 1$, that is, the sample information asymptotically dominates.

The predictive distribution is

\begin{align}
  \pi(Y_0|\mathbf{y})=&\int_{0}^{\infty}\frac{\lambda^{y_0}\exp\left\{-\lambda\right\}}{y_0!}\times \frac{1}{\Gamma(\alpha_n)\beta_n^{\alpha_n}}\lambda^{\alpha_n-1}\exp\left\{-\lambda/\beta_n\right\} d\lambda\\
  =&\frac{1}{y_0!\Gamma(\alpha_n)\beta_n^{\alpha_n}}\int_{0}^{\infty}\lambda^{y_0+\alpha_n-1}\exp\left\{-\lambda\left(\frac{1+\beta_n}{\beta_n}\right)\right\}d\lambda\\
  =&\frac{\Gamma(y_0+\alpha_n)\left(\frac{\beta_n}{\beta_n+1}\right)^{y_0+\alpha_n}}{y_0!\Gamma(\alpha_n)\beta_n^{\alpha_n}}\\
  =&{y_0+\alpha_n-1 \choose y_0}\left(\frac{\beta_n}{\beta_n+1}\right)^{y_0}\left(\frac{1}{\beta_n+1}\right)^{\alpha_n}.
\end{align}

The third equality follows from the kernel of a Gamma density, and the fourth from ${y_0+\alpha_n-1 \choose y_0}=\frac{(y_0+\alpha_n-1)(y_0+\alpha_n-2)\dots\alpha_n}{y_0!}=\frac{\Gamma(y_0+\alpha_n)}{\Gamma(\alpha_n)y_0!}$ using a property of the Gamma function.

Observe that this is a Negative Binomial density, that is $Y_0|\mathbf{y}\sim NB(\alpha_n,p_n)$ where $p_n=\frac{\beta_n}{\beta_n+1}$. 

A key question is how to fix the *hyperparameters*. In this exercise we use two approaches for exposition purposes. We set $\alpha_0=0.001$ and $\beta_0=1/0.001$ which imply vague prior information about $\lambda$ due to having a large degree of variability compared to the mean information.^[We should be aware that there may be technical problems using this king of hyperparameters in this setting [@gelman2006prior].] In particular, $\mathbb{E}[\lambda]=1$ and $\mathbb{V}ar[\lambda]=1000$. 

In this setting, $P(Y_0>0|\mathbf{y})=1-P(Y_0=0|\mathbf{y})\approx 0.67$. That is, the probability of visiting the Doctor at least once next year is approximately 0.67.

Another approach is using *Empirical Bayes*, where we set the hyperparameters maximizing the logarithm of the marginal likelihood, that is, $[\hat{\alpha}_0,\hat{\beta}_0]=\underset{\alpha_0,\beta_0}{\mathrm{argmax}} \ \ln p(\mathbf{y})$ where

\begin{align}
  p(\mathbf{y})&=\int_0^{\infty}\left\{\frac{1}{\Gamma(\alpha_0)\beta_0^{\alpha_0}}\lambda^{\alpha_0-1}\exp\left\{-\lambda/\beta_0\right\} \prod_{i=1}^N\frac{\lambda^{y_i}\exp\left\{-\lambda\right\}}{ y_i!}\right\}d\lambda\\
  &=\frac{\int_0^{\infty}\lambda^{\sum_{i=1}^N y_i+\alpha_0-1}\exp\left\{-\lambda \left(\frac{\beta_0 N +1}{\beta_0}\right) \right\}d\lambda}{\Gamma(\alpha_0)\beta_0^{\alpha_0}\prod_{i=1}^N y_i!}\\
  &=\frac{\Gamma(\sum_{i=1}^N y_i+\alpha_0)\left(\frac{\beta_0}{N\beta_0+1}\right)^{\sum_{i=1}^N y_i}\left(\frac{1}{N\beta_0+1}\right)^{\alpha_0}}{\Gamma(\alpha_0)\prod_{i=1}^N y_i}
\end{align}

Using the empirical Bayes approach, we get $\hat{\alpha}_0=51.8$ and $\hat{\beta}_0=0.023$, then $P(Y_0>0|\mathbf{y})=1-P(Y_0=0|\mathbf{y})\approx 0.70$.

Observe that we can calculate the posterior odds comparing the model using an Empirical Bayes prior (model 1) versus the vague prior (model 2). We assume that $\pi(\mathcal{M}_1)=\pi(\mathcal{M}_2)=0.5$, then

\begin{align}
  PO_{12}&=\frac{\pi(\mathbf{y}|\text{Empirical Bayes})}{\pi(\mathbf{y}|\text{Vague prior})}\\
        &=\frac{\frac{\Gamma(\sum_{i=1}^N y_i+51.807)\left(\frac{0.023}{N\times 0.023+1}\right)^{\sum_{i=1}^N y_i}\left(\frac{1}{N\times 0.023+1}\right)^{51.807}}{\Gamma(51.807)}}{\frac{\Gamma(\sum_{i=1}^N y_i+0.001)\left(\frac{1/0.001}{N/0.001+1}\right)^{\sum_{i=1}^N y_i}\left(\frac{1}{N/0.001+1}\right)^{0.001}}{\Gamma(0.001)}}\\
        &\approx 919.
\end{align}

Then, $2\times \log(PO_{12})=13.64$, there is very strong evidence against the vague prior model (see Table \@ref(tab:guide)). In particular, $\pi(\text{Empirical Bayes}|\mathbf{y})=\frac{919}{1+919}=0.999$ and $\pi(\text{Vague prior}|\mathbf{y})=1-0.999=0.001$. These probabilities can be used to perform Bayesian model average (BMA). In particular,

\begin{align}
  \mathbb{E}(\lambda|\mathbf{y})&=1.2\times 0.999+1.2\times 0.001=1.2\\
  Var(\lambda|\mathbf{y})&=0.025\times 0.999+0.24\times 0.001\\
  & + (1.2-1.2)^2\times 0.999 + (1.2-1.2)^2\times 0.001= 0.025.
\end{align}

The BMA predictive distribution is a mix of negative binomial distributions, that is, $y_0|\mathbf{y}\sim 0.999\times NB(57.8, 0.02)+0.001\times NB(6.001, 0.17)$.



```{r}
set.seed(010101)
y <- c(0, 3, 2, 1, 0) # Data
N <- length(y)

paste("The sample mean is", mean(y), sep = " ")
paste("The sample variance is", var(y), sep = " ")

ProbBo <- function(y, a0, b0){
  N <- length(y)
  an <- a0 + sum(y) # Posterior shape parameter
  bn <- b0 / ((b0 * N) + 1) # Posterior scale parameter
  p <- bn / (bn + 1) # Probability negative binomial density
  Pr <- 1 - pnbinom(0, size = an, prob = (1 - p)) # Probability of visiting the Doctor at least once next year
  # Observe that in R there is a slightly different parametrization.
  return(Pr)
} 

# Using a vague prior:

a0 <- 0.001 # Prior shape parameter
b0 <- 1 / 0.001 # Prior scale parameter
PriMeanV <- a0 * b0 # Prior mean
PriVarV <- a0 * b0^2 # Prior variance
paste("Prior mean and prior variance using vague information are", PriMeanV, "and", PriVarV, "respectively", sep = " ")
Pp <- ProbBo(y, a0 = 0.001, b0 = 1 / 0.001) # This setting is defining vague prior information.
paste("The probability of visiting the Doctor at least once next year using a vague prior is", Pp, sep = " ")

# Using Emprirical Bayes
LogMgLik <- function(theta, y){
  N <- length(y) #sample size
  a0 <- theta[1] # prior shape hyperparameter
  b0 <- theta[2] # prior scale hyperparameter
  an <- sum(y) + a0 # posterior shape parameter
  if(a0 <= 0 || b0 <= 0){ #Avoiding negative values
    lnp <- -Inf
  }else{lnp <- lgamma(an) + sum(y)*log(b0/(N*b0+1)) - a0*log(N*b0+1) - lgamma(a0)} # log marginal likelihood
  return(-lnp)
}

theta0 <- c(0.01, 1/0.1) # Initial values
control <- list(maxit = 1000) # Number of iterations in optimization
EmpBay <- optim(theta0, LogMgLik, method = "BFGS", control = control, hessian = TRUE, y = y) # Optimization
EmpBay$convergence # Checking convergence
EmpBay$value # Maximum
a0EB <- EmpBay$par[1] # Prior shape using empirical Bayes
b0EB <- EmpBay$par[2] # Prior scale using empirical Bayes
paste("The prior shape and scale parameters are", a0EB, "and", b0EB, "respectively", sep = " ")

PriMeanEB <- a0EB * b0EB # Prior mean
PriVarEB <- a0EB * b0EB^2 # Prior variance
paste("Prior mean and variance using empirical Bayes are", PriMeanEB, "and", PriVarEB, "respectively", sep = " ")
PpEB <- ProbBo(y, a0 = a0EB, b0 = b0EB) # This setting is using emprical Bayes.
paste("The probability of visiting the Doctor at least once next year using empirical Bayes is", PpEB, sep = " ")

# Density figures
lambda <- seq(0.01, 10, 0.01) # Values of lambda
VaguePrior <- dgamma(lambda, shape = a0, scale = b0)
EBPrior <- dgamma(lambda, shape = a0EB, scale = b0EB)
PosteriorV <- dgamma(lambda, shape = a0 + sum(y), scale = b0 / ((b0 * N) + 1)) 
PosteriorEB <- dgamma(lambda, shape = a0EB + sum(y), scale = b0EB / ((b0EB * N) + 1))

# Likelihood function
Likelihood <- function(theta, y){
  LogL <- dpois(y, theta, log = TRUE)
  Lik <- prod(exp(LogL))
  return(Lik)
}
Liks <- sapply(lambda, function(par) {Likelihood(par, y = y)})
Sc <- max(PosteriorEB)/max(Liks) #Scale for displaying in figure
LiksScale <- Liks * Sc

data <- data.frame(cbind(lambda, VaguePrior, EBPrior, PosteriorV, PosteriorEB, LiksScale)) #Data frame

require(ggplot2) # Cool figures
require(latex2exp) # LaTeX equations in figures
require(ggpubr) # Multiple figures in one page

fig1 <- ggplot(data = data, aes(lambda, VaguePrior)) + 
  geom_line() +  
  xlab(TeX("$\\lambda$")) + ylab("Density") +
  ggtitle("Prior: Vague Gamma") 

fig2 <- ggplot(data = data, aes(lambda, EBPrior)) + 
  geom_line() +  
  xlab(TeX("$\\lambda$")) + ylab("Density") +
  ggtitle("Prior: Empirical Bayes Gamma")

fig3 <- ggplot(data = data, aes(lambda, PosteriorV)) + 
  geom_line() +  
  xlab(TeX("$\\lambda$")) + ylab("Density") +
  ggtitle("Posterior: Vague Gamma")

fig4 <- ggplot(data = data, aes(lambda, PosteriorEB)) + 
  geom_line() +  
  xlab(TeX("$\\lambda$")) + ylab("Density") +
  ggtitle("Posterior: Empirical Bayes Gamma")

FIG <- ggarrange(fig1, fig2, fig3, fig4,
                 ncol = 2, nrow = 2)

annotate_figure(FIG,
                top = text_grob("Vague versus Empirical Bayes: Poisson-Gamma model", color = "black", face = "bold", size = 14))

dataNew <- data.frame(cbind(rep(lambda, 3), c(EBPrior, PosteriorEB, LiksScale),
                            rep(1:3, each = 1000))) #Data frame

colnames(dataNew) <- c("Lambda", "Density", "Factor")
dataNew$Factor <- factor(dataNew$Factor, levels=c("1", "3", "2"), 
                         labels=c("Prior", "Likelihood", "Posterior"))

ggplot(data = dataNew, aes_string(x = "Lambda", y = "Density", group = "Factor")) + 
  geom_line(aes(color = Factor)) +
  xlab(TeX("$\\lambda$")) + ylab("Density") +
  ggtitle("Prior, likelihood and posterior: Empirical Bayes Poisson-Gamma model") +
  guides(color=guide_legend(title="Information")) +
  scale_color_manual(values = c("red", "yellow", "blue"))

# Predictive distributions
PredDen <- function(y, y0, a0, b0){
  N <- length(y)
  an <- a0 + sum(y) # Posterior shape parameter
  bn <- b0 / ((b0 * N) + 1) # Posterior scale parameter
  p <- bn / (bn + 1) # Probability negative binomial density
  Pr <- dnbinom(y0, size = an, prob = (1 - p)) # Predictive density
  # Observe that in R there is a slightly different parametrization.
  return(Pr)
}
y0 <- 0:10
PredVague <- PredDen(y = y, y0 = y0, a0 = a0, b0 = b0)
PredEB <- PredDen(y = y, y0 = y0, a0 = a0EB, b0 = b0EB)
dataPred <- as.data.frame(cbind(y0, PredVague, PredEB))
colnames(dataPred) <- c("y0", "PredictiveVague", "PredictiveEB")

ggplot(data = dataPred) + 
  geom_point(aes(y0, PredictiveVague, color = "red")) +  
  xlab(TeX("$y_0$")) + ylab("Density") +
  ggtitle("Predictive density: Vague and Empirical Bayes priors") +
  geom_point(aes(y0, PredictiveEB, color = "yellow")) +
  guides(color = guide_legend(title="Prior")) +
  scale_color_manual(labels = c("Vague", "Empirical Bayes"), values = c("red", "yellow")) +
  scale_x_continuous(breaks=seq(0,10,by=1))


# Posterior odds: Vague vs Empirical Bayes

PO12 <- exp(-LogMgLik(c(a0EB, b0EB), y = y))/exp(-LogMgLik(c(a0, b0), y = y))
paste("The posterior odds: Empirical Bayes vs Vague prior prior is", PO12, sep = " ")

PostProMEM <- PO12/(1 + PO12) # Posterior model probability Empirical Bayes
PostProbMV <- 1 - PostProMEM # Posterior model probability vague prior

paste("These are the posterior model probabilities", PostProMEM, PostProbMV, "for the Empirical Bayes and vague priors, respectively")

# Bayesian model average (BMA)
PostMeanEB <- (a0EB + sum(y)) * (b0EB / (b0EB * N + 1)) # Posterior mean Empirical Bayes 
PostMeanV <- (a0 + sum(y)) * (b0 / (b0 * N + 1)) # Posterior mean vague priors
BMAmean <- PostProMEM * PostMeanEB + PostProbMV * PostMeanV  # BMA posterior mean

PostVarEB <- (a0EB + sum(y)) * (b0EB / (b0EB * N + 1))^2 # Posterior variance Empirical Bayes
PostVarV <- (a0 + sum(y)) * (b0 / (b0 * N + 1))^2 # Posterior variance vague prior 

BMAVar <- PostProMEM * PostVarEB + PostProbMV * PostVarV + PostProMEM * (PostMeanEB - BMAmean)^2 + PostProbMV * (PostMeanV - BMAmean)^2# BMA posterior variance   

paste("The BMA posterior mean and variance are", BMAmean, "and", BMAVar, "respectively", sep = " ")

# BMA: Predictive
BMAPred <- PostProMEM * PredEB + PostProbMV * PredVague    
dataPredBMA <- as.data.frame(cbind(y0, BMAPred))
colnames(dataPredBMA) <- c("y0", "PredictiveBMA")

ggplot(data = dataPredBMA) + 
  geom_point(aes(y0, PredictiveBMA, color = "red")) +  
  xlab(TeX("$y_0$")) + ylab("Density") +
  ggtitle("Predictive density: BMA") 

# Bayesian updating
BayUp <- function(y, lambda, a0, b0){
  N <- length(y)
  an <- a0 + sum(y) # Posterior shape parameter
  bn <- b0 / ((b0 * N) + 1) # Posterior scale parameter
  p <- dgamma(lambda, shape = an, scale = bn) # Posterior density
  return(list(Post = p, a0New = an, b0New = bn))
}

PostUp <- NULL
for(i in 1:N){
  if(i == 1){
    PostUpi <- BayUp(y[i], lambda, a0 = 0.001, b0 = 1/0.001)}
  else{
    PostUpi <- BayUp(y[i], lambda, a0 = PostUpi$a0New, b0 = PostUpi$b0New)
  }
  PostUp <- cbind(PostUp, PostUpi$Post)
}

DataUp <- data.frame(cbind(rep(lambda, 5), c(PostUp),
                            rep(1:5, each = 1000))) #Data frame

colnames(DataUp) <- c("Lambda", "Density", "Factor")

DataUp$Factor <- factor(DataUp$Factor, levels=c("1", "2", "3", "4", "5"), 
                         labels=c("Iter 1", "Iter 2", "Iter 3", "Iter 4", "Iter 5"))

ggplot(data = DataUp, aes_string(x = "Lambda", y = "Density", group = "Factor")) + 
  geom_line(aes(color = Factor)) +
  xlab(TeX("$\\lambda$")) + ylab("Density") +
  ggtitle("Bayesian updating: Poisson-Gamma model with vague prior") +
  guides(color=guide_legend(title="Update")) +
  scale_color_manual(values = c("red", "purple", "blue", "yellow", "black"))

S <- 100000 # Posterior draws
PostMeanLambdaUps <- sapply(1:N, function(i) {mean(sample(lambda, S, replace = TRUE, prob = PostUp[ , i]))}) #Posterior mean update i
paste("Posterior means using all information and sequential updating are:", round(PostMeanV, 2), "and", round(PostMeanLambdaUps[5], 2), sep = " ") 

PostVarLambdaUps <- sapply(1:N, function(i) {var(sample(lambda, S, replace = TRUE, prob = PostUp[ , i]))}) #Posterior variance update i
paste("Posterior variances using all information and sequential updating are:", round(PostVarV, 2), "and", round(PostVarLambdaUps[5], 2), sep = " ")
```


## Bayesian reports: Decision theory under uncertainty {#sec13}

The Bayesian framework allows reporting the full posterior distributions. However, some situations demand to report a specific value of the posterior distribution (point estimate), an informative interval (set), point or interval predictions and/or selecting a specific model. Decision theory offers an elegant framework to make a decision regarding what are the optimal posterior values to report [@berger2013statistical].

The point of departure is a *loss function*, which is a non-negative real value function whose arguments are the unknown *state of nature* at time $t$ ($\mathbf{\Theta}$), and a set of *actions* to be made ($\mathcal{A}$), that is, 
\begin{equation}
L(\mathbf{\theta}, a):\mathbf{\Theta}\times \mathcal{A}\rightarrow R^+.
\end{equation}

This function is a mathematical expression of the loss of making mistakes. In particular, selecting action $a\in\mathcal{A}$ when $\mathbf{\theta}\in\mathbf{\Theta}$ is the true. In our case, the unknown state of nature can be population parameters, functions of them, future or unknown dgp realizations, models, etc.

From a Bayesian perspective, we should choose the action ($\delta(\mathbf{y})$) that minimizes the posterior expected loss, which is the *posterior risk function* ($\mathbb{E}[L(\mathbf{\theta}, a)|\mathbf{y}]$),

\begin{equation}
  \delta(\mathbf{y})=\underset{\mathbf{\theta} \in \mathbf{\Theta}}{argmin} \  \mathbb{E}[L(\mathbf{\theta}, a)|\mathbf{y}], 
\end{equation}

where $\mathbb{E}[L(\mathbf{\theta}, a)|\mathbf{y}]= \int_{\mathbf{\Theta}} L(\mathbf{\theta}, a)\pi(\mathbf{\theta}|\mathbf{y})d\mathbf{\theta}$.^[[@Chernozhukov2003] propose Laplace type estimators (LTE) based on the *quasi-posterior*, $p(\mathbf{\theta})=\frac{\exp\left\{L_n(\mathbf{\theta})\right\}\pi(\mathbf{\theta})}{\int_{\mathbf{\Theta}}\exp\left\{L_n(\mathbf{\theta})\right\}\pi(\mathbf{\theta})d\theta}$ where $L_n(\mathbf{\theta})$ is not necessarily a log-likelihood function. The LTE minimizes the *quasi-posterior risk*.]

Obviously, different loss functions imply different optimal decisions. We illustrate this assuming $\theta \in R$.

* $L({\theta},a)=[{\theta}-a]^2$, then

\begin{equation}
  \mathbb{E}[{\theta}|\mathbf{y}] = \underset{{\theta} \in {\Theta}}{argmin} \  \int_{{\Theta}} [{\theta}-a]^2\pi({\theta}|\mathbf{y})d{\theta}.
\end{equation}

Using the first condition order with respect to $a$, and interchanging differentiation with integrals, we get that the posterior mean is the Bayesian optimal action, that is, $\delta(\mathbf{y})=\mathbb{E}[{\theta}|\mathbf{y}]$.

* $L({\theta},a)=w({\theta})[{\theta}-a]^2$, where $w({\theta})>0$ is a weighting function. Then using same steps as the previous result we have that $\delta(\mathbf{y})=\frac{\mathbb{E}[w({\theta})\times{\theta}|\mathbf{y}]}{\mathbb{E}[w({\theta})|\mathbf{y}]}$, that is, the Bayesian optimal action is a weighted average driven by $w({\theta})$.

* $L({\theta},a)=|{\theta}-a|$, then we have to find $\delta(\mathbf{y})=\underset{{\theta} \in {\Theta}}{argmin} \  \int_{{\Theta}} |{\theta}-a|\pi({\theta}|\mathbf{y})d{\theta}$, this means that $\int_{-\infty}^a \pi({\theta}|\mathbf{y})d{\theta}=1/2$, that is, ${\delta}(\mathbf{y})$ is the median (exercise). 

* Given the loss function,

\begin{equation}
L(\theta,a)=\begin{Bmatrix} K_0(\theta-a), \theta-a\geq 0\\
K_1(a-\theta), \theta-a < 0 \end{Bmatrix},
\end{equation}

then,

\begin{align}
  \mathbb{E}[L(\theta, a)|\mathbf{y}]&=\int_{-\infty}^a K_1(a-\theta)\pi(\theta|\mathbf{y})d\theta + \int_a^{\infty} K_0(\theta-a)\pi(\theta|\mathbf{y})d\theta. 
\end{align}

Differenting w.r.t $a$, and equaliting to zero,
\begin{align}
  K_1\int_{-\infty}^a \pi(\theta|\mathbf{y})d\theta-K_0\int_a^{\infty} \pi(\theta|\mathbf{y})d\theta&=0,
\end{align}

then, $\int_{-\infty}^a \pi(\theta|\mathbf{y})d\theta=\frac{K_0}{K_0+K_1}$, that is, any $K_0/(K_0+K_1)$-percentile of $\pi(\theta|\mathbf{y})$ is an optimal Bayesian estimate of $\theta$.

We can also use decision theory under uncertatinty in hypothesis testing. In particular, testing $H_0:\theta\in\Theta_0$ versus $H_1:\theta\in\Theta_1$, $\Theta=\Theta_0 \cup \Theta_1$ and $\emptyset=\Theta_0 \cap \Theta_1$, there are two actions of interest, $a_0$ and $a_1$, where $a_j$ denotes no rejecting $H_j$, $j=\left\{0,1\right\}$. Given the loss function,

\begin{equation}
L(\theta,a_j)=\begin{Bmatrix} 0, & \theta\in\Theta_j\\
K_j, & \theta\in\Theta_j, j\neq i \end{Bmatrix}.
\end{equation}

The posterior expected loss associated with $a_j$ is $K_jP(\Theta_i|\mathbf{y})$, $j\neq i$. Therefore, the Bayes optimal decision is the one that gives the smallest posterior expected loss, that is, the null hypothesis is rejected ($a_1$ is not rejected), when $K_0P(\Theta_1|\mathbf{y}) > K_1P(\Theta_0|\mathbf{y})$. Given our framework $(\Theta=\Theta_0 \cup \Theta_1, \emptyset=\Theta_0 \cap \Theta_1)$, then $P(\Theta_0|\mathbf{y})=1-P(\Theta_1|\mathbf{y})$, and as a consequence, $P(\Theta_1|\mathbf{y})>\frac{K_1}{K_1+K_0}$, that is, the rejection region of the Bayesian test is $R=\left\{\mathbf{y}:P(\Theta_1|\mathbf{y})>\frac{K_1}{K_1+K_0}\right\}$.

Decision theory also helps to construct interval (region) estimates. Let $\Theta_{C(\mathbf{y})}\subset \Theta$ a *credible* set for $\theta$, and $L(\theta,\Theta_{C(\mathbf{y})})=1-\mathbb{I}\left\{\theta\in \Theta_{C(\mathbf{y})}\right\}$, where 

\begin{equation}
\mathbb{I}\left\{\theta\in \Theta_{C(\mathbf{y})}\right\}=\begin{Bmatrix}1, & \theta\in \Theta_{C(\mathbf{y})}\\  
0, & \theta\notin \Theta_{C(\mathbf{y})}
\end{Bmatrix}.
\end{equation}

Then,

\begin{equation}
L(\theta,\Theta_{C(\mathbf{y})})=\begin{Bmatrix}0, & \theta\in \Theta_{C(\mathbf{y})}\\  
1, & \theta\notin \Theta_{C(\mathbf{y})}
\end{Bmatrix}.
\end{equation}

Then, the risk function is $1-P(\theta\in \Theta_{C(\mathbf{y})})$.

Given a measure of *credibility* ($\alpha(\mathbf{y})$) that defines the level of trust that $\theta\in \Theta_{C(\mathbf{y})}$. We can measure the accuracy of the report by $L(\theta, \alpha(\mathbf{y}))=(\mathbb{I}\left\{\theta\in \Theta_{C(\mathbf{y})}\right\}-\alpha(\mathbf{y}))^2$. This loss function could be used to suggest a choice of the report $\alpha(\mathbf{y})$. The Bayesian optimal action is $P(\theta\in \Theta_{C(\mathbf{y})}|\mathbf{y})$. This can be calculated given the posterior distirbution, that is, $P(\theta\in \Theta_{C(\mathbf{y})}|\mathbf{y})=\int_{\Theta_{C(\mathbf{y})}}\pi(\theta|\mathbf{y})d\theta$. This a measure of the belief that $\theta\in \Theta_{C(\mathbf{y})}$ given the prior beliefs and sample information.

The set $\Theta_{C(\mathbf{y})}\in\Theta$ is a $100(1-\alpha)\%$ credible set with respect to $\pi(\theta|\mathbf{y})$ if $P(\theta\in \Theta_{C(\mathbf{y})}|\mathbf{y})=\int_{\Theta_{C(\mathbf{y})}}\pi(\theta|\mathbf{y})=1-\alpha$.

The $100(1-\alpha)\%$ *highest posterior density set* (HPD) for $\theta$ is a $100(1-\alpha)\%$ credible interval for $\theta$ with the property that it has a smaller space than any other $100(1-\alpha)\%$ credible interval for $\theta$. That is, $C(\mathbf{y})=\left\{\theta:\pi(\theta|\mathbf{y})\geq k(\alpha)\right\}$, where $k(\alpha)$ is the largest number such that $\int_{\theta:\pi(\theta|\mathbf{y})\geq k(\alpha)}\pi(\theta|\mathbf{y})d\theta=1-\alpha$. The HPDs can be a collection of disjoint intervals when working with multimodal posterior densities. In addition, they have the limitation of not necessary being invariant under transformations. 

Finally, decision theory can be used to perform prediction (point, sets or probabilistic). Suppose that one has a loss $L(Y_0,a)$ involving the prediction of $Y_0$. Then, $L(\theta,a)=\mathbb{E}_{\theta}^{Y_0}[Y_0,a]=\int_{\mathcal{Y}_0}L(y_0,a)g(y_0|\theta)dy_0$, where $g(y_0|\theta)$ is the density function of $Y_0$.

Predictive exercises can be based on predictive densities, that is, $\pi(Y_0|\mathbf{y})$. Then, the predictive density can be used to obtain a point prediction given a loss function $L(Y_0,y_0)$, where $y_0$ is a point prediction for $Y_0$. We can seek $y_0$ that minimizes the mathematical expectation of the loss function. 

Other approach is to use scoring rules to assess the quality of the predictive (probabilistic) forecasts. This is assigning a numerical score based on the predictive distribution on the event that realizes [@Gneiting2007]. Then, we can use decision theory to define the most relevant scoring rule for the problem at hand, such that we assign a high ordinate to the realized value (*calibration*). In addition, it is possible to add some reward for accuracy in specific parts of the support of the density function (*sharpness*) [@Diks2011].   

## Summary: Chapter 1  

In this chapter we show that Bayesian inference is based on a single rule, the Bayes' rule, and that decision theory can be used to report summary statistics such that they minimize posterior expected losses.


## Exercises: Chapter 1 

1. **The court case: the blue or green cap**

A cab was involved in a hit and run accident at night. There are two cab companies in the town: blue and green. The former has 150 cabs, and the latter 850 cabs. A witness said that a blue cab was involved in the accident; the court tested his/her reliability under the same circunstances, and got that 80% of the times the witness correctly identified the color of the cab. **what is the probability that the color of the cab involved in the accident was blue given that the witness said it was blue?**

**Solution**
Set $WB$ and $WG$ equal to the events that the witness said the cab was blue and green, respectively. Set $B$ and $G$ equal to the events that the cabs are blue and green, respectively. We need to calculate $P(B|WB)$, then:

\begin{align}
  P(B|WB)&=\frac{P(B,WB)}{P(WB)}\\
         &=\frac{P(WB|B)\times P(B)}{P(WB|B)\times P(B)+(1-P(WB|B))\times (1-P(B))}\\
         &=\frac{0.8\times 0.15}{0.8\times 0.15+0.2\times 0.85}\\
         &=0.41
\end{align}


2. **The Monty Hall problem**

What is the probability of winning a car in the **Monty Hall problem** switching the decision if there are four doors, where there are three goats and one car? Solve this problem analytically and computationally.  What if there are 100 doors, 99 goats and one car? 

**Solution**

Let's name $P_i$ the event *contestant picks door No. $i$*, $H_i$ the event *host picks door No. $i$*, and $C_i$ the event *car is behind door No. $i$*. Let's assume that the contestant picked door number 1, and the host picked door number 3, then the contestant is interested in the probability of the event $P(C_i|H_3,P_1), i = 2 \ \text{or} \ 4$. Then, $P(H_3|C_3,P_1)=0$, $P(H_3|C_2,P_1)=P(H_3|C_4,P_1)=1/2$ and $P(H_3|C_1,P_1)=1/3$. Then, using equation \@ref(eq:112) 

\begin{align}
  P(C_i|H_3,P_1)&= \frac{P(C_i,H_3,P_1)}{P(H_3,P_1)}\\
                &= \frac{P(H_3|C_i,P_1)P(C_i|P_1)P(P_1)}{P(H_3|P_1)\times P(P_1)}\\
                &= \frac{P(H_3|C_i,P_1)P(C_i)}{P(H_3|P_1)}\\
                &=\frac{1/2\times 1/4}{1/3}\\
                &=\frac{3}{8},
\end{align}
where the third equation uses the fact that $C_i$ and $P_i$ are independent events, and $P(H_3|P_1)=1/3$ due to this depending just on $P_1$ (not on $C_i$).

Therefore, changing the initial decision increases the probability of getting the car from 1/4 to 3/8!


```{r}
set.seed(0101) # Set simulation seed
S <- 100000 # Simulations
Game <- function(opt = 3){
  # opt: number of options. opt > 2, it is 3 in the original game
  opts <- 1:opt 
  car <- sample(opts, 1) # car location
  guess1 <- sample(opts, 1) # Initial guess pick
  
  if(opt == 3 && car != guess1) {
    host <- opts[-c(car, guess1)]
    } else {
    host <- sample(opts[-c(car, guess1)], 1)
    }
  
  win1 <- guess1 == car # Win given no change
  
  if(opt == 3) {
    guess2 <- opts[-c(host, guess1)]
  } else {
    guess2 <- sample(opts[-c(host, guess1)], 1)
  } 
  
  win2 <- guess2 == car # Win given change

  return(c(win1, win2))
}

Prob <- rowMeans(replicate(S, Game(opt = 4))) #Win probabilities
paste("Winning probabilities no changing door is", Prob[1], sep = " ")
paste("Winning probabilities changing door is", Prob[2], sep = " ")
```

3. Solve the health insurance example using a Gamma prior in the rate parametrization, that is, $\pi(\lambda)=\frac{\beta_0^{\alpha_0}}{\Gamma(\alpha_0)}\lambda^{\alpha_0-1}\exp\left\{-\lambda\beta_0\right\}$.

4. A preliminar survey regarding detergent preferences found that 20, 30 and 50 people prefer brands A, B and C, respectively. What is the posterior probability of having 25, 40, 35 preferences for brands A, B and C, respectively? Solve this exercise using vague prior and Empirical Bayes.

5. A mayoral election poll with two candidates shows that candidate A will get 350 votes, and candidate B will get 300. What is the probability that candidate A gets more than 50% of votes? Solve this exercise using vague prior and Empirical Bayes.

6. Show that given the loss function, $L({\theta},a)=|{\theta}-a|$, then ${\delta}(\mathbf{y})$ is the median.

**Solution**

$\int_{{\Theta}} |{\theta}-a|\pi({\theta}|\mathbf{y})d{\theta}=\int_{-\infty}^a (a-{\theta})\pi({\theta}|\mathbf{y})d{\theta}+\int_{a}^{\infty} ({\theta}-a)\pi({\theta}|\mathbf{y})d{\theta}$. Differentiating with respect to $a$, and equaliting to zero,

\begin{equation}
  \int_{-\infty}^a \pi({\theta}|\mathbf{y})d{\theta}=\int_{a}^{\infty} \pi({\theta}|\mathbf{y})d{\theta},  
\end{equation}

then,

\begin{equation}
  2\int_{-\infty}^a \pi({\theta}|\mathbf{y})d{\theta}=\int_{-\infty}^{\infty} \pi({\theta}|\mathbf{y})d{\theta}=1,  
\end{equation}

that is, ${\delta}(\mathbf{y})$ is the median.



