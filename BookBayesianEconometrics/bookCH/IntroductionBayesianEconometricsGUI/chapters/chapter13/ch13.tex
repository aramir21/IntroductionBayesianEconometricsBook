\chapter{Machine learning}\label{chap13}

\section{Cross validation and Bayes factors}\label{sec13_1}

\section{Regularization}\label{sec13_2}
The linear normal model using the conjugate family is ridge regression \cite{Ishwaran2005}. We can use empirical Bayes to select the scale parameter of the prior covariance matrix of the location parameters, which is in turn the regularization parameter in the ridge regression (see my class notes in MSc in Data Science and Analytic).

\subsection{Bayesian LASSO}\label{sec13_21}

\subsection{Stochastic search variable selection}\label{sec13_22}

\subsection{Non-local priors}\label{sec13_23}

\cite{johnson2012bayesian}
R package: mombf (Model Selection with Bayesian Methods and Information Criteria)
link: https://cran.r-project.org/web/packages/mombf/index.html

\section{Bayesian additive regression trees}\label{sec13_3}

\section{Gaussian processes}\label{13_4}