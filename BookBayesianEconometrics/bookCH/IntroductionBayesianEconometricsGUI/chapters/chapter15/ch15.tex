\chapter{Approximate Bayesian methods}\label{chap15}

\textit{Approximate Bayesian methods} are a family of techniques designed to handle situations where the likelihood function lacks an analytical expression, is highly complex, or the problem has high dimensionality, whether due to a large parameter space or a massive dataset \cite{martin2024approximating}. In the former case, traditional Markov Chain Monte Carlo (MCMC) and importance sampling algorithms fail to provide a solution, while in the latter, these algorithms struggle to produce accurate estimates within a reasonable time.  

However, there is no free lunch, \textit{Approximate Bayesian methods} address these challenges at the cost of providing an approximation to the posterior distribution rather than the \textit{exact} posterior. Nonetheless, asymptotic results show that the approximation improves as the sample size increases.

In this chapter, I first present \textit{simulation-based approaches}, which are designed to address situations where the likelihood is highly complex and may lack an analytical solution. In the second part, I introduce \textit{optimization approaches}, which are intended to handle high-dimensional problems. Specifically, I discuss approximate Bayesian computation (ABC) and Bayesian synthetic likelihood (BSL), the two most common \textit{simulation-based approaches}. Then, I present integrated nested Laplace approximations (INLA) and \textit{variational Bayes} (VB), the two most common \textit{optimization approaches} for high-dimensional problems.

\section{Simulation-based approaches}\label{sec15_1}
Taking into account the fundamental equation for performing parameter inference in the Bayesian framework,  
\begin{align*}
	\pi(\boldsymbol{\theta} \mid \mathbf{y}) & \propto p(\mathbf{y} \mid \boldsymbol{\theta}) \times \pi(\boldsymbol{\theta}),
\end{align*}  
we see in Section \ref{sec51} that MCMC algorithms, such as the Gibbs sampler (Section \ref{sec511}) and Metropolis-Hastings (Section \ref{sec512}), require evaluation of the likelihood function \( p(\boldsymbol{y} \mid \boldsymbol{\theta}) \) in the posterior conditional distribution or the acceptance probability, respectively. This is also the case for importance sampling when calculating the importance weights (Section \ref{sec52}).  

Thus, what happens when the likelihood function does not have an analytical expression? This situation arises in many models involving unobserved heterogeneity (i.e., unobserved taste preferences), models defined by quantile functions (e.g., the g-and-k distribution), or dynamic equilibrium model (e.g., repeated game models).

\textit{Simulation-based algorithms} provide a Bayesian solution when we face this situation, namely, when the likelihood function lacks an analytical expression or is highly complex. The only requirement is that we must be able to simulate synthetic data from the model conditional on the parameters. Therefore, these algorithms obtain an approximation to the posterior draws by simulating from the prior distribution $\pi(\boldsymbol{\theta})$ and then using these draws to simulate from the likelihood $p(\mathbf{y} \mid \boldsymbol{\theta})$.

\subsection{Approximate Bayesian computation}\label{sec15_12}

Approximate Bayesian computation is a method suitable for handling situations where the likelihood is expressed as an intractable or very complex multidimensional integral $l(\boldsymbol\theta|\boldsymbol y)=\int l^*(\boldsymbol\theta|\boldsymbol y, \boldsymbol{\epsilon})d\boldsymbol{\epsilon}$ where $\boldsymbol y\in \mathcal{D}\subseteq \mathbb{R}^{n}$ is observed, $\boldsymbol{\epsilon}\in \mathbb{R}^p$ is a latent vector and $\boldsymbol\theta\in\mathbb{R}^k$ is the parameter of interest \cite{marin2012approximate}. This method was introduced in population genetics by \cite{tavare1997inferring,pritchard1999population}, and generalized by \cite{beaumont2002approximate}. However, its intuitive origin may be traced back to \cite{rubin1984bayesianly}. There is a growing literature with applications in biology, cosmology, finance and economics, among others.

In ABC, we simulate the parametric model ($p_{\boldsymbol{\theta}}$), including the latent variables ($\boldsymbol{\epsilon}$), by drawing samples from the prior densities ($\pi({\boldsymbol{\theta}})$) multiple times ($S$). For each simulation ($\boldsymbol{z}^{(s)}, s=1,2,\dots,S$), we compute summary statistics from the synthetic data ($\eta_j(\boldsymbol{z}^{(s)}), j=1,2,\dots,l\geq k$) and compare them to the summary statistics of the observed data ($\boldsymbol{\eta}(\boldsymbol{y})$) using a distance metric ($d\left\{{\boldsymbol\eta }({\boldsymbol y}),{\boldsymbol \eta }({\boldsymbol z}^{(s)})\right\}$), typically Euclidean distance. We retain the prior draws that generate synthetic data closest to the observed summary statistics, forming an approximation of the posterior distribution ($\pi(\boldsymbol{\theta},\boldsymbol{z}|\boldsymbol{\eta}(\boldsymbol{y}))$). Our inference on $\boldsymbol{\theta}$ is based on the simple accept/reject version of approximate Bayesian computation (ABC-AR) (see Algorithm \ref{ABC0}).

%Formally, given the observed dataset, ${\boldsymbol{y}}=(y_{1},...,y_{n})^{\top}$, and $\mathcal{P}:=\{{\boldsymbol{\theta}}\in P_{\boldsymbol{\theta}}\}$ the parametric model used in ABC to simulate pseudo-data, so that ${\boldsymbol z}\sim P_{\boldsymbol{\theta}}$, then $\boldsymbol \eta({\boldsymbol y})=(\eta_{1}({\boldsymbol y}),...,\eta_l({\boldsymbol y}))^{\top}$ denotes a $l$-dimensional vector of observed summary statistics ($l\geq k$), $\boldsymbol\eta(\boldsymbol z)$ denotes their simulated counterpart, $d_{}\{\cdot ,\cdot \}$ is a metric, and $\Pi ({ \boldsymbol{\theta} })$ denotes a prior measure with corresponding density $\pi({ \boldsymbol{\theta} })$. We consider as the basis for inference on $\boldsymbol{\theta}$ the simple accept/reject version of approximate Bayesian computation (ABC-AR).
\begin{algorithm}
	\caption{Accept/reject ABC}\label{ABC0}
	\begin{algorithmic}[1]
		\For{\texttt{$s=1,\dots,S$}}
		\State Draw ${\boldsymbol {\theta} }^{s}$ from $\pi({ \boldsymbol{\theta} }),$
		\State Simulate ${\boldsymbol z}^{s}=(z_{1}^{s},z_{2}^{s},...,z_{n}^{s})^{\top}$from the model, $p(\cdot|{\boldsymbol{\theta} }^{s})$
		\State Calculate
		$d_{(s)}=d\{{\boldsymbol\eta }({\boldsymbol y}),{\boldsymbol \eta }({\boldsymbol z}^{s})\}$
		\EndFor
		\State Order the distances $d_{(1)}\leq\cdots\leq d_{(S)}$
		\State Select all $\boldsymbol{\theta}^s$ such that $d_{(i)}\leq \bar{d}$, where $\bar{d}>0$ is the tolerance level. 
	\end{algorithmic}
\end{algorithm}

%\citet{biau2015} note that Algorithm \ref{ABC0} can be seen as selecting draws of $\boldsymbol{\theta}^i$ for which $\boldsymbol \eta(\boldsymbol{z}^{i})$ is among the $S^*$-nearest neighbors of $\boldsymbol\eta(\boldsymbol{y})$, as measured by ranking the $d_{(s)}$. 
Proposition 2.1 of \cite{biau2015} demonstrates that, conditional on a chosen $\bar{d}$, the output from Algorithm \ref{ABC0} is an independent and identically distributed sample from 
\begin{align*}
	\pi(\boldsymbol{\theta},{\boldsymbol z}|\eta(\boldsymbol{y}))=\frac{\mathbbm{1}\left[(\boldsymbol{\theta},\boldsymbol\eta({\boldsymbol z}))\in\Theta\times \mathcal{B}[\boldsymbol\eta({\boldsymbol y}),\bar{d}]\right]\pi(\boldsymbol{\theta})dP_{\boldsymbol{\theta}}(\boldsymbol{z})}{\int_{\Theta}P_{\boldsymbol{\theta}}\left[\boldsymbol\eta({\boldsymbol z})\in\mathcal{B}\left[\boldsymbol\eta({\boldsymbol y}),\bar{d}\right]\right]d\Pi(\boldsymbol{\theta})}, 
\end{align*}
where $\mathbbm{1}(A)$ takes the value of 1 if condition $A$ is satisfied, and 0 otherwise, $\mathcal{B}[\boldsymbol\eta({\boldsymbol y}),\bar d]:=\{\boldsymbol\eta({\boldsymbol z})\in\mathcal{B}:d\{\boldsymbol\eta({\boldsymbol y}),\boldsymbol\eta({\boldsymbol z})\}\leq \bar d\}$, $P_{\boldsymbol{\theta}}(\boldsymbol z)$ and $\Pi(\boldsymbol{\theta})$ are the distribution functions of $\boldsymbol z$ and $\boldsymbol \theta$, respectively.

This joint posterior distribution is conditional on the summary statistic $\boldsymbol\eta(\boldsymbol y)$. This is not an issue if $\boldsymbol\eta(\boldsymbol y)$ is a sufficient statistic, as $\pi(\boldsymbol\theta,\boldsymbol z|\boldsymbol\eta(\boldsymbol y))=\pi(\boldsymbol\theta,\boldsymbol z|\boldsymbol y)$. But, most of the time, $\boldsymbol\eta(\boldsymbol y)$ is not a sufficient statistic, as a consequence, this is an approximation to the target distribution $\pi(\boldsymbol\theta,\boldsymbol z|\boldsymbol y)$, which introduces bias \cite{blum2010approximate}. However, \cite{beaumont2002approximate} found that it performed well compared to the full-likelihood approaches.

In addition, Theorems 1 and 2 in \cite{frazier2018asymptotic} show that there is Bayesian consistency and asymptotic normality so long as $\bar{d}\rightarrow 0$ fast enough as $n\rightarrow +\infty$. In particular, it is required that $\delta=o(1/n^{k / 2})$, where $\delta=S^*/S$ is the proportion of accepted draws and $S^*$ is number of accepted draws such that $S^*<<S$. Theorem 2 in \cite{frazier2018asymptotic} shows that $100(1 -\alpha)$\% Bayesian credible regions using ABC have frequentist coverage of $100(1 -\alpha)$\%. For instance, we can set $\delta=n^{-k/2}\times\log^{-1}(n)$ and $S$ such that we achieve a specific target $S^*$ in Algorithm \ref{ABC0}. We should note from these asymptotic results that ABC suffers from the \textit{curse of dimensionality}, as the number of required draws increases at a polynomial rate with the dimension of the parameter space given the sample size.

The accept/reject ABC algorithm is inefficient, as all draws are independent; thus, there is no learning from previous draws, and consequently, there is no optimal path traversing the parameter space.
This intensifies the computational burden.
Therefore, \cite{marjoram2003markov,wegmann2009efficient} introduced Markov chain Monte Carlo ABC (ABC-MCMC) algorithms, and \cite{buchholz2019improving} a quasi-Monte Carlo approach to improve the computational efficiency, \cite{sisson2007sequential,drovandi2011estimation,del2012adaptive,lenormand2013adaptive} proposed sequential Monte Carlo approaches (ABC-SMC), and \cite{Beaumont2009adaptivity} proposed a population Monte Carlo approach (ABC-PMC), the last two approaches based on importance sampling arguments.
However, results comparing these new refinements with the ABC-AR are controversial regarding computational efficiency \cite{bertorelle2010abc}.
In addition, ABC-AR is very simple, and easily allows parallel computing \cite{frazier2019approximate}. %Although, \cite{Barthelme2018} proposed an expectation-propagation (ABC-EP) algorithm that can be implemented in parallel computing. 

It is also a common practice in ABC to perform a regression adjustment after retained draws \cite{beaumont2002approximate,leuenberger2010bayesian, sisson2018handbook}. This adjustment reduces bias in posterior draws by performing a simple linear regression between the selected draws and the discrepancy between the observed and simulated summary statistics ($\boldsymbol{\theta}^{(s)} = \alpha + \beta \left(\boldsymbol{\eta}(\boldsymbol{y}) - \boldsymbol{\eta}(\boldsymbol{z}^{(s)})\right) + \varepsilon^{(s)}$). Then, the posterior draws are adjusted using the slope estimate ($\boldsymbol{\theta}^{\text{adj},(s)} = \boldsymbol{\theta}^{(s)} - \hat{\beta} \left(\boldsymbol{\eta}(\boldsymbol{y}) - \boldsymbol{\eta}(\boldsymbol{z}^{(s)})\right)$). We perform this adjustment in our simulation exercises, and calculate measures of the performance of the estimation and prediction. However, ABC posterior draws without regression adjustment got better results than ABC posterior draws with regression adjustments (results available on request). In summary, ABC-AR seems to work well in terms of computational efficiency and statistical sampling properties. Nevertheless, our applications use ABC-AR, ABC-MCMC \cite{marjoram2003markov} and ABC-SMC \cite{lenormand2013adaptive}. 


\subsection{Bayesian synthetic likelihood}\label{sec15_13}

\section{Optimization approaches}\label{sec15_2}

Even in situations where the likelihood function has an analytical expression, but there are huge datasets, MCMC and IS algorithms require pointwise evaluation of the likelihood function. This implies a huge number of operations, and these methods are not designed to be \textit{scalable}. Further, if there is a large parameter space, these methods are neither \textit{scalable} in the number of parameters.

\textit{Optimization approaches} are designed to scale to high parameter spaces and large datasets. The trick is to change simulation with optimization. 

\subsection{Integrated nested Laplace approximations}\label{sec15_21}
\textit{Integrated nested Laplace approximations} approximates $\pi(\boldsymbol{\theta} \mid \mathbf{y})$ by a combination of low-dimensional deterministic integration and optimization steps. 

\subsection{Variational Bayes}\label{sec15_22}
\textit{Variational Bayes} replaces $\pi(\boldsymbol{\theta} \mid \mathbf{y})$ by an approximation produced by calculus of variations. 

\section{Summary}\label{sec15_3}
\textit{Simulation-based algorithms} suffer from the \textit{curse of dimensionality} in parameter space, whereas \textit{Optimization approaches} require evaluation of the likelihood functions. Thus, recent approaches mix these two approaches to overcome situations where both phenomena are present.



