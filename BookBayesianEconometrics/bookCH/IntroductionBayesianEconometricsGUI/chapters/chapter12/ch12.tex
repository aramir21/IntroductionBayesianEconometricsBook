\chapter{Causal inference}\label{chap12}

In this chapter, we present some Bayesian methods to perform inference on \textit{causal} effects. The point of departure is the set of conditions required to identify the causal effect from observable data distributions. These identification conditions are conceptually distinct from the econometric or statistical framework used to perform inference once those conditions are satisfied. In other words, the assumptions necessary for identification do not constrain whether we apply a Frequentist or a Bayesian approach for estimation and inference.

Identification addresses the question: \textit{Can the causal effect be expressed as a function of the observable data distribution under certain assumptions?} Once the causal effect is identified in terms of the observed data distribution, we can proceed with statistical inference using either Frequentist methods or Bayesian methods. These inferential frameworks differ in how they estimate and quantify uncertainty but operate on the same identified causal effect. Thus, the identification assumptions are logically prior and independent of whether we adopt a Frequentist or a Bayesian inferential paradigm.

Thus, we present the underlying identification assumptions employed in popular strategies such as randomized controlled trials, conditional independence, and instrumental variables, among others, as well as the Bayesian inferential framework used to estimate causal effects in these settings. 

We should be clear that this is only an introduction to causal inference, and we do not aim to provide an in-depth discussion. There are excellent texts on causal inference, such as \cite{angrist2009mostly,angrist2014mastering,imbens2015causal,hernan2020causal,cunningham2021causal,chernozhukov2024applied}. We recommend that readers consult these references for a deeper understanding of some of the concepts and tools introduced in this chapter.

\section{Identification setting}

The aim is to identify the \textit{causal} or \textit{treatment effect} of a particular regressor or treatment on an outcome. For example, this could involve estimating the causal effect of a labor training program on individuals’ earnings or unemployment, or the price elasticity of demand. The starting point is the \textit{potential outcomes} framework \cite{rubin1974}, which defines a \textit{counterfactual scenario} describing what would happen to the outcome variable if the treatment status or level were different (commonly referred to as the \textit{Rubin causal model}).

In this context, \textit{treatment status} refers to a binary treatment case with two potential outcomes; for instance, what would my earnings be if I had participated in the training program? Conversely, \textit{treatment level} applies to cases where there is a potential outcome for each level of the treatment; for example, what would demand be if the price had increased by 10\%?

Following the potential outcomes notation in the binary treatment case, let $D_i = 1$ and $D_i = 0$ indicate the treatment status, corresponding to \textit{treated} and \textit{control} units, respectively. The potential outcomes $Y_i(1)$ and $Y_i(0)$ represent the outcome for unit $i = 1, 2, \dots, N$ under treatment and control, respectively. For instance, $Y_i(1)$ denotes the employment status an individual would have if she/he would have participated in the training program, regardless of their actual participation, whereas $Y_i(0)$ denotes the employment status if the individual would not have attended the program. The individual-level treatment effect is then defined as
\begin{align*}
	\tau_i = Y_i(1) - Y_i(0).
\end{align*}

The potential outcomes framework can also be extended to situations where the treatment is continuous \cite{imbens2014ivperspective}. In this case, let $Y_i(x_s)$ denote the outcome for unit $i$ under the counterfactual scenario where the treatment variable $X_s$ takes the value $x_s$. The ``treatment effect'' of changing $X_s$ from $x_s$ to $x_s'$, for example, the effect of increasing the price by 10\% on demand, is given by
\begin{align*}
	\beta_{si} = Y_i(x_s') - Y_i(x_s).
\end{align*}
When the change is infinitesimal, the causal effect can be expressed as a marginal effect:
\begin{align*}
	\beta_{si} =\frac{\partial Y_i(x_s)}{\partial x_s}.
\end{align*}
This setting is more complex than the binary treatment case because there is a potential outcome for each possible value of $x_s$ \cite{gill2001causal}. Thus, we begin with the binary treatment case. However, the fundamental challenge in identifying the individual-level causal effect remains that it is impossible to observe the same unit under different \textit{treatment statuses} simultaneously \cite{angrist2009mostly}. Thus, we must learn about the causal effects by comparing the outcomes from treated and untreated units.

\section{Randomized controlled trial (RCT)}

The starting point is to express the observed outcome in terms of the potential outcomes as:
\[
Y_i = [Y_i(1) - Y_i(0)] D_i + Y_i(0),
\]
which shows that the observed outcome equals the control potential outcome plus the treatment effect if treated. Under the assumption of a constant treatment effect, this can be represented as a linear regression model \cite{angrist2009mostly}:
\[
Y_i = \underbrace{\beta_0}_{\mathbb{E}[Y_i(0)]} 
+ \underbrace{\tau}_{\text{constant treatment effect}} D_i 
+ \underbrace{\mu_i}_{Y_i(0) - \mathbb{E}[Y_i(0)]}.
\]

The observed mean difference between treated and untreated units decomposes as:
\[
\mathbb{E}[Y_i \mid D_i=1] - \mathbb{E}[Y_i \mid D_i=0] 
= \tau + \Big( \mathbb{E}[Y_i(0)\mid D_i=1] - \mathbb{E}[Y_i(0)\mid D_i=0]\Big).
\]
If $\tau$ is constant across units, then it represents both the average treatment effect (ATE),
\[
\text{ATE} = \mathbb{E}[Y_i(1) - Y_i(0)],
\]
and the treatment effect on the treated (ATT),
\[
\text{ATT} = \mathbb{E}[Y_i(1) - Y_i(0)\mid D_i=1].
\]
However, when treatment effects are heterogeneous, the ATE differs from the ATT.

On the other hand, 
\[
\mathbb{E}[Y_i(0) \mid D_i=1] - \mathbb{E}[Y_i(0) \mid D_i=0]
\]
is the \textit{selection bias}, which captures the difference between the expected outcome of treated individuals if they would not have been treated, and the expected outcome of untreated individuals. Depending on the context, this selection bias can be zero, positive, or negative. For instance, in a \textit{randomized controlled trial (RCT)}, where treatment assignment is random and independent of potential outcomes, we have
\[
\{ Y_i(1), Y_i(0) \} \perp D_i,
\]
which implies
\begin{equation}\label{eq:12_1}
	\mathbb{E}[\mu_i \mid D_i] = \mathbb{E}[Y_i(0) \mid D_i] - \mathbb{E}[Y_i(0)] = \mathbb{E}[Y_i(0)] - \mathbb{E}[Y_i(0)] = 0.
\end{equation}

Therefore, the error term is mean-independent of treatment status. Equivalently,
\[
\mathbb{E}[Y_i(0) \mid D_i = 1] - \mathbb{E}[Y_i(0) \mid D_i = 0] = 0,
\]
which implies there is no selection bias under random assignment.

Note also that under random assignment, ATT equals ATE:
\[\tau=\mathbb{E}[Y_i(1)\mid D_i=1]-\mathbb{E}[Y_i(0)\mid D_i=1]=\mathbb{E}[Y_i(1)-Y_i(0)].
\]

In addition to \textit{random assignment}, the identification of causal effects in RCTs relies on the assumption that every unit has a positive probability of being assigned to both treatment and control groups ($0 < P(D_i = 1) < 1$), this is called \textit{overlap}, as well as the \textit{Stable Unit Treatment Value Assumption} (SUTVA). The latter requires that one unit’s potential outcome is unaffected by another unit’s treatment (\textit{no interference}) and that the observed outcome equals the potential outcome corresponding to the received treatment (\textit{consistency}).

We can represent the causal mechanism in an RCT using causal diagrams \cite{pearl1995causal,pearl2018book}. These diagrams provide a powerful framework for visualizing and analyzing the underlying structures that enable causal identification. It is important to note that causal diagrams do not impose specific functional forms, such as those assumed in linear regression models, and are closely linked to structural equation models (SEMs). SEMs offer another perspective on causal inference in econometrics, which is closely related to the potential outcomes approach \cite{haavelmo1943statistical,marschak1944random,imbens2014ivperspective}.

In particular, we can depict the causal mechanism using a \textit{Directed Acyclic Graph (DAG)}, which is a graphical representation of a set of variables and their assumed causal relationships. A DAG consists of \textit{nodes}, representing variables, and \textit{directed edges (arrows)}, representing direct causal effects from one variable to another. The graph is \textit{acyclic}, meaning it contains no directed cycles: starting from any node and following the arrows, it is impossible to return to the same node. A defining property of causal DAGs
is that, conditional on its direct causes, any variable on the DAG is independent
of any other variable for which it is not a cause (\textit{causal Markov assumption}). See \cite{hernan2020causal} for a nice introduction. Figure~\ref{DAG1} illustrates the causal structure underlying RCTs.

\begin{figure}[h]
	\centering
	\begin{tikzpicture}[->,>=Stealth,shorten >=1pt,node distance=2.5cm,
		thick,main node/.style={circle,draw,minimum size=7mm}]
		\node[main node] (D) {$D$};
		\node[main node] (Y) [right of=D] {$Y$};
		
		\path (D) edge (Y)
		(D) edge (Y);
	\end{tikzpicture}
	\caption{Directed Acyclic Graph (DAG) implied by a Randomized Controlled Trial (RCT).}
	\label{DAG1}
\end{figure} 

The counterfactual representation of the DAG, known as the \textit{Single-World Intervention Graph} (SWIG), is shown in Figure~\ref{SWIG1}. In this figure, the treatment variable $D$ is split to reflect the intervention: we fix $D$ at a specific value $d$ (the intervention), and replace the outcome $Y$ with its counterfactual representation $Y(d)$, which denotes the value of $Y$ if $D$ were set to $d$. The natural value of $D$ is also shown (dashed) but becomes irrelevant for the outcome once the intervention is imposed.

\begin{figure}[h]
	\centering
	\begin{tikzpicture}[->,>=Stealth,shorten >=1pt,node distance=2.5cm,
		thick,main node/.style={circle,draw,minimum size=7mm}]
		% Nodes
		\node[main node] (Dfix) {$D = d$};    % Fixed intervention
		\node[main node] (Y) [right of=Dfix] {$Y(d)$}; % Counterfactual outcome
		\node[main node] (Dnat) [below of=Dfix, node distance=1.5cm] {$D$}; % Natural value (irrelevant)
		
		% Edges
		\path (Dfix) edge[dashed] (Y); % Dashed arrow
	\end{tikzpicture}
	\caption{Single-World Intervention Graph (SWIG) for intervention $do(D=d)$: $Y$ is replaced by the counterfactual $Y(d)$, and $D$ is split into the fixed value $D=d$ and its natural value $D$. The dashed arrow indicates the fixed causal assignment.}
	\label{SWIG1}
\end{figure}

 

An RCT is considered the gold standard for identifying causal effects because it provides the strongest basis for satisfying the key identification assumption in causal inference: \textit{independence between treatment assignment and potential outcomes}. However, RCTs may face challenges such as \textit{non-compliance}, which occurs when individuals do not adhere to their assigned treatment in an experimental study. This is important because, in many real-world settings, some individuals do not take the treatment they were assigned, leading to deviations from the ideal randomized controlled trial design. In addition, RCTs are sometimes infeasible due to ethical, logistical, or financial constraints. Moreover, they can be too narrowly focused or too localized to provide general conclusions about what works \cite{deaton2010instruments}.

It is also important to note that RCTs primarily identify the mean of the treatment effect distribution but do not capture other features, such as the median or higher-order moments. These additional aspects of the distribution of treatment effects can be highly relevant for policymakers and stakeholders. See \cite{deaton2010instruments} for a detailed discussion of other potential shortcomings of RCTs.


\section{Conditional independence assumption (CIA)}

The simple regression framework can be extended to a multiple linear regression model by including additional \textit{pre-treatment variables} to improve the precision of the estimates:
\begin{align*}
	Y_i = \beta_0 + \tau D_i + \mathbf{X}_i^{\top}\boldsymbol{\beta} + \mu_i.
\end{align*}
Note that, by assumption in RCTs, $D_i$ and $\mathbf{X}_i$ are independent. Thus, the identification of $\tau$ is not affected; however, including $\mathbf{X}_i$ helps explain part of the variability in $Y_i$, thereby improving the precision of the estimates.

In practice, researchers often work with \textit{observational data}, where the treatment status is not randomly assigned because units actively choose the treatment they receive. In an RCT, the assignment mechanism is determined by chance, whereas in observational studies it is driven by choice. In these situations, regression can still be used to identify the causal effect if the \textit{conditional independence assumption} (CIA) holds. This assumption states that the potential outcomes are independent of the treatment status, conditional on a set of observed  \textit{pre-treatment variables}:
\[
\{ Y_i(1), Y_i(0) \} \perp D_i \mid \mathbf{X}_i.
\]
This means that, conditional on the \textit{pre-treatment variables} $\mathbf{X}_i$, treatment assignment is as good as random. This property is known as \textit{unconfoundedness given} $\mathbf{X}_i$, or equivalently, the \textit{no unmeasured confounders} assumption. When this condition is combined with the requirement that, for all possible values of $\mathbf{X}_i$, there is a positive probability of receiving each treatment level ($0 < P(D_i = 1 \mid \mathbf{X}_i) < 1$), the joint condition is referred to as \textit{strong ignorability}. Identification of average causal effects in this setting also requires the SUTVA.

Figure~\ref{DAG2} illustrates the causal structure underlying the CIA. We follow the convention that time flows from left to right. Here, $\mathbf{X}$ -a vector of pre-treatment variables or \textit{confounders}- influences both the treatment ($D$) and the outcome ($Y$). Under the CIA, we can identify the causal effect of $D$ on $Y$ by adjusting for $\mathbf{X}$ because this causal structure satisfies the \textit{back-door criterion}. This criterion states that a set of variables $\mathbf{X}$ satisfies the condition for identifying the effect of $D$ on $Y$ if no variable in $\mathbf{X}$ is a descendant of $D$ and $\mathbf{X}$ blocks every back-door path from $D$ to $Y$. A \textit{back-door path} is any path from $D$ to $Y$ that begins with an arrow pointing into $D$. 

\begin{figure}[h]
	\centering
	\begin{tikzpicture}[->,>=Stealth,shorten >=1pt,node distance=2.5cm,
		thick,main node/.style={circle,draw,minimum size=7mm}]
		\node[main node] (X) {$\mathbf{X}$};
		\node[main node] (D) [right of=X] {$D$};
		\node[main node] (Y) [right of=D] {$Y$};
		
		\path (X) edge (D)
		(X) edge[bend left=20] (Y)
		(D) edge (Y);
	\end{tikzpicture}
	\caption{Directed Acyclic Graph (DAG) implied by the linear model $Y = \beta_0 + \tau D + \mathbf{X}^\top\boldsymbol{\beta} + \mu$ under CIA.}
	\label{DAG2}
\end{figure}

The SWIG of this DAG is displayed in Figure \ref{SWIG2}.  

\begin{figure}[h]
	\centering
	\begin{tikzpicture}[->,>=Stealth,shorten >=1pt,node distance=2.5cm,
		thick,main node/.style={circle,draw,minimum size=7mm}]
		% Nodes
		\node[main node] (X) {$\mathbf{X}$};
		\node[main node] (Dfix) [right of=X] {$D = d$}; % Intervention
		\node[main node] (Y) [right of=Dfix] {$Y(d)$};  % Counterfactual outcome
		\node[main node] (Dnat) [below of=Dfix, node distance=1.5cm] {$D$}; % Natural value
		
		% Edges
		\path (Dfix) edge[dashed] (Y)
		(X) edge[bend left=25] (Y)
		(X) edge (Dnat);
	\end{tikzpicture}
	\caption{Single-World Intervention Graph (SWIG) for $do(D=d)$: The treatment $D$ is split into the fixed intervention $D=d$ and its natural value. The outcome is replaced by $Y(d)$. $\mathbf{X}$ still influences $Y(d)$, so adjustment for $\mathbf{X}$ is needed for identification.}
	\label{SWIG2}
\end{figure}
 

In this setting, the error term is defined as
\[
\mu_i = Y_i(0) - \mathbb{E}[Y_i(0) \mid \mathbf{X}_i].
\]

Thus,
\[
\mathbb{E}[\mu_i \mid D_i, \mathbf{X}_i] = \mathbb{E}[Y_i(0) - \mathbb{E}[Y_i(0) \mid \mathbf{X}_i] \mid D_i, \mathbf{X}_i] 
= \mathbb{E}[Y_i(0) \mid D_i, \mathbf{X}_i] - \mathbb{E}[Y_i(0) \mid \mathbf{X}_i].
\]

By the CIA, $Y_i(0) \perp D_i \mid \mathbf{X}_i$, so:
\[
\mathbb{E}[Y_i(0) \mid D_i, \mathbf{X}_i] = \mathbb{E}[Y_i(0) \mid \mathbf{X}_i].
\]

Therefore:
\begin{equation}\label{eq:12_2}
	\mathbb{E}[\mu_i \mid D_i, \mathbf{X}_i] = 0.
\end{equation}

This condition is known as \textit{conditional mean independence}: after controlling for $\mathbf{X}_i$, treatment assignment is independent of unobserved determinants of the outcome. It justifies unbiased estimation of $\tau$ by regression adjustment in observational studies.

Observe that the identification strategy relies on conditioning on $\mathbf{X}$. However, adding more controls is not always safe because some variables, known as \textit{bad controls}, can introduce bias if included in the adjustment set \cite{angrist2009mostly}. One important type of bad control is a \textit{collider}, a variable that is caused by (or is a common effect of) two or more other variables in a DAG. Colliders play a critical role because conditioning on them can create spurious associations between their causes, leading to what is known as \textit{collider bias} (or selection bias).

Figure~\ref{DAG3} illustrates this situation. Here, $C$ is a common effect of $D$ and $\mathbf{X}$. Conditioning on $C$ opens an additional path between $D$ and $Y$, creating a spurious association that violates the back-door criterion. In particular, the variable $C$ is a collider on the path $D \to C \leftarrow \mathbf{X}$. By default, a collider \textit{blocks} the flow of association along the path on which it lies, so this path is closed when $C$ is not conditioned on. However, conditioning on $C$ (or on any descendant of $C$) opens this path, creating a spurious association between $D$ and $\mathbf{X}$. Since $\mathbf{X}$ also affects $Y$, this induces bias in estimating the causal effect of $D$ on $Y$. 

\begin{figure}[h]
	\centering
	\begin{tikzpicture}[->,>=Stealth,shorten >=1pt,node distance=2.5cm,
		thick,main node/.style={circle,draw,minimum size=7mm}]
		% Nodes
		\node[main node] (X) {$\mathbf{X}$};
		\node[main node] (D) [right of=X] {$D$};
		\node[main node] (Y) [right of=D] {$Y$};
		\node[main node] (C) [below of=Y, node distance=1cm] {$C$}; % Collider
		
		% Edges
		\path (X) edge (D)
		(X) edge[bend left=20] (Y)
		(D) edge (Y)
		(D) edge (C)
		(X) edge (C);
	\end{tikzpicture}
	\caption{Directed Acyclic Graph (DAG) implied by the linear model $Y = \beta_0 + \tau D + \gamma C + \mathbf{X}^\top\boldsymbol{\beta} + \mu$ under CIA, the additional collider $C$ caused by both $D$ and $\mathbf{X}$ would open a path between $D$ and $\mathbf{X}$, inducing bias.}
	\label{DAG3}
\end{figure}

Collider (selection) bias is one possible source of bias in the identification of causal effects. Heckman’s sample selection problem \cite{heckman1979sample} can be interpreted as a form of collider bias because restricting the analysis to selected observations (e.g., those with positive wages) conditions on a variable that is a common effect of observed and unobserved factors, thereby opening a non-causal path and creating bias. In other words, the sample is no longer representative of the population, which undermines the identification of the causal effect. Other sources of bias include the omission of common causes that affect both treatment and outcome, measurement error in regressors leading to \textit{attenuation bias} (where the estimated causal effect is biased toward zero), and \textit{reverse or simultaneous causality}, which often arises in systems of equations (see \cite{wooldridge2010econometric} for details). Simultaneous causality is conceptually challenging because causality is often associated with chronological order, cause preceding effect. In simultaneous systems, such as supply and demand, outcomes are jointly determined in equilibrium, so this temporal order is not explicit in the observed data. Nevertheless, the underlying structural equations still encode causal relationships, even though their effects are realized simultaneously. 

\section{Instrumental variables (IV)}

In many real-world situations, we face biases such as those described in the previous paragraph, arising from measurement errors, omission of relevant variables, and similar issues. Even in these cases, it is still possible to identify the causal effect. One common strategy is to use a set of \textit{instrumental variables} ($\mathbf{Z}$) that satisfy two key conditions:
\begin{enumerate}
	\item \textit{Relevance}, meaning the instruments are correlated with the treatment:
	\[
	\mathbf{Z}_i \not\perp D_i.
	\]
	\item \textit{Exogeneity}, which in the linear model requires:
	\begin{equation}\label{eq:12_3}
		\mathbb{E}[\mu_i \mid \mathbf{Z}_i] = 0,
	\end{equation}
	and, in terms of potential outcomes, entails:
	\begin{itemize}
		\item \textit{Exclusion restriction}: instruments affect the outcome only through the treatment:
		\[
		Y_i(D_i = d, \mathbf{Z}_i = \mathbf{z}) = Y_i(D_i = d, \mathbf{Z}_i = \mathbf{z}') = Y_i(D_i = d), \quad d \in \{0,1\},
		\]
		\item \textit{Marginal exchangeability}: instruments are independent of the potential outcomes:
		\[
		\mathbf{Z}_i \perp \{ Y_i(1), Y_i(0) \}.
		\]
	\end{itemize}
\end{enumerate}

Relevance is testable, typically by checking whether instruments significantly predict the endogenous variable \cite{staiger1997instrumental,cragg1993testing,kleibergen2006generalized,stock2005asymptotic}. However, \textit{weak instruments}, those that exhibit only a weak association with the treatment, can lead to serious consequences, including a high level of uncertainty and the potential amplification of even small biases when estimating the causal effect.

Exogeneity is fundamentally untestable. However, when the number of instruments exceeds the number of endogenous variables, the Sargan test (or its robust version, the Hansen $J$-test) can be used to assess the validity of overidentifying restrictions. However, it should not be misinterpreted as a direct test of the exclusion restriction. Instead, the test evaluates whether the overidentifying restrictions implied by the IV model hold. Specifically, the null hypothesis states that all instruments are jointly uncorrelated with the structural error term: $\mathbb{E}[\mathbf{Z}^\top \mu] = \mathbf{0}$ \cite{sargan1958econometric,hansen1982large}. If the test rejects, it indicates that at least one instrument is invalid, but it does not reveal whether the violation results from a failure of the exclusion restriction, correlation with unobserved confounders, or model misspecification. Conversely, if the test fails to reject, it suggests that the sample moment conditions do not provide evidence against instrument validity under the maintained model, but this does not prove that the exclusion restrictions hold. Therefore, while the Sargan test is informative about overall instrument validity, it is not a separate or definitive test of the exclusion restriction \cite{wooldridge2010econometric,hayashi2000econometrics}. \cite{Conley2012} present practical methods for performing inference while relaxing the exclusion
restriction in IV settings.

Figure~\ref{DAG4} illustrates a situation where pre-treatment variables that influence both the treatment and the outcome are partially observed or measured with error. In such cases, an instrument can help identify the causal effect of the treatment on the outcome.

\begin{figure}[h]
	\centering
	\begin{tikzpicture}[->,>=Stealth,shorten >=1pt,node distance=2.5cm,
		thick,main node/.style={circle,draw,minimum size=7mm}]
		% Nodes
		\node[main node, dashed] (X) {$\mathbf{X}$};
		\node[main node] (D) [right of=X] {$D$};
		\node[main node] (Y) [right of=D] {$Y$};
		\node[main node] (Z) [below of=D, node distance=2cm] {$Z$};
		
		% Edges
		\path (Z) edge (D)
		(X) edge[bend left=20] (Y)
		(D) edge (Y)
		(X) edge (D);
	\end{tikzpicture}
	\caption{Directed Acyclic Graph (DAG) showing an instrumental variable $Z$ used to identify the causal effect of $D$ on $Y$ when some confounders $\mathbf{X}$ (dashed) are unobserved or measured with error.}
	\label{DAG4}
\end{figure}

However, the two conditions of the instruments only imply partial identification of the treatment effect \cite{manski1990nonparametric}. Thus, it is necessary to add a third condition to get point identification of a particular treatment effect using IV. This condition is \textit{monotonicity} which asserts that the instrument moves all units’ treatment decisions in the same direction, that is,
\[
D_i(1)\geq D_i(0), i=1,2,\dots,N,
\]
with equality for at least one unit $i$, and assuming a binary instrument $Z_i=\left\{0,1\right\}$. 

In the case where $Z_i$ denotes the assignment to treatment and $D_i$ the actual treatment status, there are four potential groups: \textit{always takers} ($D = 1 \mid Z = 1$ and $D = 1 \mid Z = 0$), \textit{never takers} ($D = 0 \mid Z = 1$ and $D = 0 \mid Z = 0$), \textit{compliers} ($D = 1 \mid Z = 1$ and $D = 0 \mid Z = 0$), and \textit{defiers} ($D = 0 \mid Z = 1$ and $D = 1 \mid Z = 0$). Note that these groups are not identified; for instance, we do not know whether an individual with $Z_i = 1$ and $D_i = 1$ is a complier or an always taker. The monotonicity assumption rules out defiers, meaning that the instrument (assignment to treatment) either does not change treatment status or only increases it.

Adding the monotonicity assumption and SUTVA, IV methods allow identification of the causal effect for the subgroup of \textit{compliers}, that is, individuals who take the treatment when encouraged by the instrument and do not take it otherwise \cite{imbens1994identification,angrist1996identification}. This estimand is known as the \textit{Local Average Treatment Effect} (LATE) because it applies to a specific subpopulation rather than the entire population:

\begin{align*}
	\tau_{LATE}&=\mathbb{E}[Y_i(1)-Y_i(0)\mid D(1)=1,D(0)=0]\\
	&=\frac{\mathbb{E}[Y_i\mid Z_i=1]-\mathbb{E}[Y_i\mid Z_i=0]}{\mathbb{E}[D_i\mid Z_i=1]-\mathbb{E}[D_i\mid Z_i=0]}.
\end{align*}

Thus, the LATE is the ratio between the intention-to-treat effect on the outcome (ITT), and the effect of the instrument on the treatment. Thus, the instrument induces random variation in treatment. The numerator captures how outcomes change with the instrument, and the denominator captures how treatment changes with the instrument. Dividing isolates the causal effect for compliers.

Note that the LATE is not the global average causal effect, and has been subject to several criticisms. First, the proportion of compliers in the population may be small, raising concerns about the policy relevance of this estimand. Observe that while we cannot identify all four principal strata (compliers, never-takers, always-takers, and defiers), the proportion of compliers is identifiable. Second, the monotonicity assumption is not always plausible, particularly in observational studies where instruments may induce heterogeneous behavioral responses. Third, partitioning the population into four strata can become ill-defined in settings where instruments arise from different mechanisms or individual-specific criteria \cite{deaton2010instruments,hernan2020causal}. For arguments in defense of LATE against these critiques, see \cite{angrist2010better}.

Bayesian inference for causal effects \cite{rubin1978bayesian} is more direct than procedures based on Fisher's \textit{p}-value approach, which relies on the logic of stochastic proof by contradiction, or Neyman's randomization-based inference, which is grounded in the idea of repeated sampling and the construction of confidence intervals for treatment effects \cite{rubin2004teaching}.

Bayesian inference of causal effects treats the potential outcomes as random variables, and involves the calculation of the posterior predictive distribution to evaluate treatments not received, conditionally on given responses to treatments received. This gives the posterior distribution of the causal estimands. The effect of adding or dropping identification conditions can be assessed by examinating how the posterior predictive distribution of causal estimands change \cite{imbens1997bayesian}.

In this framework, there is a model for the assignment mechanism $P(D_i\mid Y_i(1), Y_i(0), \mathbf{X}_i)$, like randomization or propensity score matching \cite{rosenbaum1983central}, supplemented by a model for the data $P(Y_i(1), Y_i(0)\mid \mathbf{X}_i)$. A causal inference is delivered by conditioning in what is observed to calculate the posterior distribution of the causal estimand given also the models for the assignment mechanisms and data. Therefore, there is a model to input the potential outcome missing value that allows to get the predictive distribution, and then, the posterior predictive distribution of the treatment effect ($Y_i(1)-Y_i(0)$) is calculated. We should take into account that the parameters of the models for predicting the missing potential outcomes are generally not causal effects. Due to using models for the data based on simulation, the Bayesian approach is by far the most direct and flexible of the modes of inference for causal effects. However, it relies on assumptions on the assignment mechanism and data.

Given pretreatment variables, it improves the predictive power of the potential outcome missing data

Bayesian inference of causal effects in a completely randomized experiment with no covariates is then presented using a simple normal model \cite{rubin1990neyman}.

Bayesian inference of causal effects in a completely randomized experiment with no compliance and no covariates is then presented in \cite{imbens1997bayesian}.

Bayesian inference of causal effects in a randomized experiment with no compliance and but covariates is then presented in \cite{hirano2000assessing}.

 There, no compliance is explicitly treated as missing data. A nice advantage of the Bayesian approach is to relax the exclusion restriction \cite{rubin2004teaching}.

Propensity matching should be used to create ``assigned treatment" and ``assigned control" groups that are well balanced on all covariates. The covariate modeling should be applied to estimate the effects of ``received treatment" for the subgroup of true compliers \cite{rubin2004teaching}.

In general, association does not imply causation, although causation does imply association. Two variables can be associated for several reasons: one may cause the other, they may share common causes, or they may share a common effect when the analysis is restricted to a specific level of that effect (or one of its descendants) \cite{hernan2020causal}. For this reason, causal graphs are valuable tools for explicitly representing the assumptions about the causal relationships under study and should be among the first steps in establishing an identification strategy.

Introduce maximum entropy using identification conditions to build likelihood functions.

Instrumental variables change the level of the treatment, without affecting the potential outcomes associated with these treatment levels \cite{imbens2014ivperspective}.

 
 
The gold standard in identification of causal effects is \textit{randomized controlled trial (RCT)}, where assignment to treatment is random, independent of the outcome and other potential exogenous determinants of the outcome. However, most of the time practitioners use \textit{observational data}, where the treatment status/level is \textit{endogenous} due to units actively defining the treatment that they receive \cite{imbens2014ivperspective}. Thus the assignment mechanism in RCTs are given by chance, whereas in observational studies by choice. This makes a subtantial methodological difference such that the latter implies looking a source of \textit{exogenous variation} that influences the \textit{treatment status/level}.

Two critical aspects in the identification of causal effects are: (i) the presence of a strong source of \textit{exogenous variation} that influences the \textit{endogenous regressors}, which are often the primary variables of interest to researchers, as they may directly affect the outcome or response variables and can be influenced by policy decisions, for example, identifying the causal effects of social programs on income or education, or evaluating strategic interventions in industry, such as estimating the price elasticity of demand for a specific product; and (ii) the effective \textit{control of other relevant exogenous covariates}, such as pre-treatment characteristics or external factors in a demand model.

In this context, the use of \textit{non-parametric models} (see Chapters~\ref{chap12} and~\ref{chap13}) is valuable due to their flexibility and weaker structural assumptions. Therefore, non-parametric and machine learning approaches serve as \textit{powerful tools} that can be combined with strong exogenous variation to robustly identify causal effects \cite{chernozhukov2018double,chernozhukov2024applied}.


Read this reference \cite{iacovone2023bayesian} before begin working in this chapter! Also read \cite{imbens1997bayesian}.


\section{Instrumental variables}\label{sec12_1}
\subsection{Semi-parametric IV model}\label{sec12_11}
Use function \textit{rivDP} from package \textit{bayesm} in \textbf{R}.

\section{Sample selection}\label{sec12_2}
\cite{greenberg2012introduction}

\section{Regression discontinuity design}\label{sec12_3}
\cite{chib2016bayesian,chib2023nonparametric,kowalska2024bayesian}

\section{Regression kink design}\label{sec12_4}
\cite{chan2025minimum}

\section{Synthetic control}\label{sec12_5}
\cite{amjad2018robust,kim2020bayesian}

\section{Difference in difference estimation}\label{sec12_6}
\cite{normington2019bayesian,normington2022bayesian,breunig2024semiparametric}

\section{Event Analysis}\label{sec12_7}

\section{Bayesian exponential tilted empirical likelihood}\label{sec12_8}
Bayesian parametric approaches are often criticized on the basis that they require arbitrary distribution assumptions which often are not examined. Partial information approaches are based only on certain moment assumptions without making specific distributional assumptions. However, there are no free lunch, as these methods imply efficiency losses.

The point of departure of Bayesian exponential tilted empirical likelihood (BETEL) are moment conditions that are used to build the likelihood function.

\section{A general framework for updating belief distributions}\label{sec12_9}
Introduce \cite{bissiri2016general} as a generalization of \cite{chernozhukov2003mcmc}.

\section{Bayesian model averaging}\label{sec12_10}
We can use BMA as a sensible way to perform robustness analysis regarding model specification (regressors uncertainty) in performing inference of treatment effects.

%\section{Double-Debiased machine learning causal effects}\label{sec12_11a}
