\chapter{Multivariate models}\label{chap7}

We describe how to perform Bayesian inference in multivariate response models: multivariate regression, seemingly unrelated regression, instrumental variables, and multivariate probit model. In particular, we show the posterior distributions of the parameters, and perform some applications and simulations. Again, we show how to perform inference in these models using three levels of programming skills: GUI, packages, and programming from scratch the algorithms. Finally, there are some mathematical and computational exercises.

Remember that we can run our GUI typing

\begin{tcolorbox}[enhanced,width=4.67in,center upper,
	fontupper=\large\bfseries,drop shadow southwest,sharp corners]
	\textit{R code. How to display our graphical user interface}
	\begin{VF}
		\begin{lstlisting}[language=R]
	shiny::runGitHub("besmarter/BSTApp", launch.browser = T)
\end{lstlisting}
	\end{VF}
\end{tcolorbox} 

in the \textbf{R} package console or any \textbf{R} code editor.

\section{Multivariate regression}\label{sec71}

A complete presentation of this model is given in Section \ref{sec44}. We show here the setting, and the posterior distributions for facility in exposition. In particular, there are $M$ multiply dependent variables which share the same set of regressors, and their stochastic errors are contemporaneously correlated. In particular, $\bm{Y}=\left[{\bf{y_{1}}},{\bf{y_{2}}},\ldots,{\bf{y_{M}}}\right]$ is an $ N\times M$ matrix that is generated by $\bm{Y}=\bm{X}\bm{B}+\bm{U}$ where $\bm{X}$ is an $ N\times K$ matrix of regressors, $\bm{B}=\left[\bm{\beta}_{1} \ \bm{\beta}_{2} \ldots \bm{\beta}_{M}\right]$ is a $ K\times M$ matrix of parameters, and $\bm{U}=\left[\bm{\mu}_{1} \ \bm{\mu}_{2}\ldots \bm{\mu}_{M}\right]$ is a matrix of stochastic random errors such that $\bm{\mu}_i\sim{N}(\bm{0},\bm{\Sigma})$, $i=1,2,\dots,N$ is each row of $\bm{U}$.

The prior is given by   $\pi(\bm{B}|\bm{\Sigma})\sim{N}(\bm{B}_0,\bm{V}_0, \bm{\Sigma})$ and $\pi(\bm{\Sigma})\sim{I}{W}(\bm{\Psi}_0,\alpha_0)$. Therefore, the conditional posterior distributions are
\begin{equation*}
	\bm{B}|\bm{\Sigma}, \bm{Y}, \bm{X} \sim{N}(\bm{B}_n, \bm{V}_n, \bm{\Sigma}), 
\end{equation*}
\begin{equation*}
	\bm{\Sigma}| \bm{Y}, \bm{X} \sim {I}{W}(\bm{\Psi}_n, \alpha_n),
\end{equation*}

where $\bm{V}_n=(\bm{X}^{\top}\bm{X}+\bm{V}_0^{-1})^{-1}$, $\bm{B}_n=\bm{V}_n(\bm{V}_0^{-1}\bm{B}_0 + \bm{X}^{\top}\bm{X}\hat{\bm{B}})$, $\hat{\bm{B}}=(\bm{X}^{\top}\bm{X})^{-1}\bm{X}^{\top}\bm{Y}$, $\bm{\Psi}_n = {\bf{\Psi}}_{0}+{\bf{S}}+{\bf{B}}_{0}^{\top}{\bf{V}}_{0}^{-1}{\bf{B}}_{0}+\widehat{\bf{B}}^{\top}{\bf{X}}^{\top}{\bf{X}}\widehat{\bf{B}}-{\bf{B}}_n^{\top}{\bf{V}}_n^{-1}{\bf{B}}_n$, and $\alpha_n = \alpha_0 + N$. We can use a Gibbs sampling algorithm in this model since the conditional posterior distributions are standard.\\

\textbf{Example: The effect of institutions on per capita gross domestic product}

To illustrate multivariate regression models, we used the dataset provided by \cite{Acemoglu2001}, who analyzed the effect of property rights on economic growth.

Let's assume that the point of departure is the following \textit{simultaneous structural} economic model:\footnote{This is a model that captures the potential underlying economic relationship between the variables.}
\begin{align}\label{eq:str1}
	\log(\text{pcGDP95}_i)=\beta_1+\beta_2\text{PAER}_i+\beta_3 \text{Africa}+\beta_4 \text{Asia}+\beta_5 \text{Other}+u_{1i},
\end{align}
\begin{align}\label{eq:str2}
	\text{PAER}_i=\alpha_1+\alpha_2\log(\text{pcGDP95}_i)+\alpha_3\log(\text{Mort}_i)+u_{2i},
\end{align}
where \textit{pcGDP95}, \textit{PAER} and \textit{Mort} are the per capita gross domestic product (GDP) in 1995, the average index of protection against expropriation between 1985 and 1995, and the settler mortality rate during the time of colonization, respectively. \textit{Africa}, \textit{Asia} and \textit{Other} are dummies for continents, with \textit{America} as the baseline group.

In this model, there is \textit{reverse (simultaneous) causality} due to the contemporaneous effect of \textit{GDP} on \textit{PAER}, and vice verse.\footnote{\textit{Simultaneous causality} is the most controversial causation issue from a philosophy of science perspective. The root of the issue is that causation is typically based on the time sequence of cause and effect.} Therefore, estimation of the Equations \ref{eq:str1} and \ref{eq:str2} without taking into account this phenomenon generates posterior mean estimates that are \textit{biased} and \textit{inconsistent} from a sampling (frequentist) point of view.\footnote{Observe that $\mathbb{E}[u_1\text{PAER}]\neq 0$, which means failing to meet a necessary requirement to get \textit{unbiased} and \textit{consistent} estimators of $\bm{\beta}$. See exercise 1.} A potential strategy to tackle this issue is to estimate the \textit{reduced-form} model, that is, a model without \textit{simultaneous causality} where all \textit{endogenous variables} are function of \textit{exogenous variables}. The former variables are determined within the model ($\log(\text{pcGDP95}_i)$ and PAER in this example), and the latter are determined outside the model ($\log(\text{Mort}_i)$, Africa, Asia, and Other in this example).

Replacing Equation \ref{eq:str2} into Equation \ref{eq:str1}, and solving for $\log(\textit{pcGDP95})$,
\begin{align}\label{eq:red1}
	\log(\text{pcGDP95}_i)=\pi_1+\pi_2\log(\text{Mort}_i)+\pi_3 \text{Africa}+\pi_4 \text{Asia}+\pi_5 \text{Other}+e_{1i}.   
\end{align}
Then, replacing Equation \ref{eq:red1} into Equation \ref{eq:str2}, and solving for \textit{PAER},
\begin{align}\label{eq:red2}
	\text{PAER}_i=\gamma_1+\gamma_2\log(\text{Mort}_i)+\gamma_3 \text{Africa}+\gamma_4 \text{Asia}+\gamma_5 \text{Other}+e_{2i},
\end{align}
where $\pi_2=\frac{\beta_2\alpha_3}{1-\beta_2\alpha_2}$ and $\gamma_2=\frac{\alpha_3}{1-\beta_2\alpha_2}$ given $\beta_2\alpha_2\neq 1$, that is, independent equations (see Exercise 2). 

Observe that equations \ref{eq:red1} and \ref{eq:red2} have the form of a multivariate regression model where the common set of regressors is $\bm{X}=\left[\log(\textbf{Mort}) \ \textbf{Africa} \ \textbf{Asia} \ \textbf{Other}\right]$ and $\bm{Y}=\left[\log(\textbf{pcGDP95}) \ \textbf{PAER}\right]$. Thus, we can estimate this model using the setup of this section.

Thus, we estimate in a first stage the parameters from the \textit{reduced-form} model (Equations \ref{eq:red1} and \ref{eq:red2}), but the main interest is the parameters of the \textit{structural} model (Equations \ref{eq:str1} and \ref{eq:str2}). Thus, a valid question is if we can recover the \textit{structural} parameters from the \textit{reduced-form} parameters. There are two criteria to respond this question: the order condition, which is necessary, and the rank condition, which is necessary and sufficient.\\
 
\textit{The order condition}

Given a system of equations with $M$ endogenous variables, and $K$ exogenous variables (including the intercept), there are two ways to assess the order condition:
\begin{itemize}
	\item The parameters of an equation in the system are identified if there are at least $M-1$ variables excluded from the equation (\textit{exclusion restrictions}). The equation is \textit{exactly identified} if the number of excluded variables is $M-1$, and is \textit{over identified} if the number of excluded variables is greater than $M-1$.
	\item The parameters of equation $m$ in the system are identified if $K-K_m\geq M_m-1$, where $K_m$ and $M_m$ are the number of exogenous and endogenous variables in equation $m$, respectively. The $m$-th equation is \textit{exactly identified} if $K-K_m = M_m-1$, and \textit{over identified} if if $K-K_m > M_m-1$. 
\end{itemize}

We can see from Equations \ref{eq:str1} and \ref{eq:str2} in this example that $K=5$, $M=2$, $K_1=4$, $K_2=2$, $M_1=2$ and $M_2=2$. This means that $K-K_1=1=M-1$ and $K-K_2=3>M-1=1$, that is, the order condition says that both equations satisfy the necessary condition of identification, the first equation would be \textit{exactly identified}, and the second equation would be \textit{over identified}. Observe that there is one excluded variable from the first equation, and there are three excluded variables from the second equation.
\\

\textit{The rank condition}

The rank condition (necessary and sufficient) says that given a \textit{structural} model with $M$ equations ($M$ endogenous variables), an equation is identified if and only if there is at least one determinant different from zero from a $(M-1)\times(M-1)$ matrix built using the excluded variables in the analyzed equation, but included in any other equation of the system.

It is useful to build the \textit{identification matrix} to implement the \textit{rank} condition. Table \ref{tab:71} shows this matrix in this example.

\begin{table}[!h]
	%\noautomaticrules
	\tabletitle{Identification matrix.}\label{tab:71}%
	\begin{tabular}{ccccccc}
		$\log(\text{pcGDP95})$ & PAER & Constant & $\log(\text{Mort})$ & Africa & Asia & Other \\
		\hline
		1 & -$\beta_2$ & -$\beta_1$ & 0 & -$\beta_3$ & -$\beta_4$ & -$\beta_5$\\
		-$\alpha_2$ & 1 & $-\alpha_1$ & -$\alpha_3$ & 0 & 0 & 0 \\
	\end{tabular}
\end{table}

The only excluded variable in the $\log(\text{pcGDP95})$ equation is $\log(\text{Mort})$. Then, there is just one matrix that can be built using the excluded variables from this equation $[-\alpha_3]$ (see column 4 in Table \ref{tab:71}). Thus, the determinant of this matrix is $-\alpha_3$, and as far as this coefficient is different to zero, that is, that the mortality rate is relevant in the $PAER$ equation ($\alpha_3\neq 0$), the coefficients in $\log(\text{pcGDP95})$ equation are \textit{exactly identified}. For instance, $\beta_2=\frac{\pi_2}{\gamma_2}$, which is the effect of property rights on GDP, is exactly identified. 

Observe the importance of excluding $\log(\text{Mort})$ from the $\log(\text{pcGDP95})$ equation, but including $\log(\text{Mort})$ in the PAER equation. This is called \textit{exclusion restriction}, and it is the requirement of having an exogenous source of variability in the PAER equation that helps to identify the $\log(\text{pcGDP95})$ equation. Having relevant exogenous sources of variability is a very important aspect in identification, estimation and inference of \textit{structural} parameters.

Regarding the identification of the \textit{structural} parameters in the PAER equation, there are three potential matrices that can be constructed: $[-\beta_3]$, $[-\beta_4]$ and $[-\beta_5]$ (see columns 5, 6 and 7 in Table \ref{tab:71}), as far as any of these parameters are relevant in the $\log(\text{pcGDP95})$ equation, we achieve identification of the PAER equation. In this case, this equation is \textit{over identified}, that is, there are many ways to find the parameters in this equations. For instance, $\alpha_2=\gamma_3/\pi_3=\gamma_4/\pi_4=\gamma_5/\pi_5$ (see Exercise 2).

In general, trying to recover the \textit{structural} parameters from the \textit{reduced-form} parameters can be challenging due to the requirement of relevant identification restrictions that can be hard to find in some applications.\footnote{Good text books at introductory level for identification in linear systems are \cite[Chap. ~19]{gujarati2009basic} and \cite[Chap. ~16]{wooldridge2016introductory}.}

We set non-informative priors in this example, $\bm{B}_0=\left[\bm{0}_5 \ \bm{0}_5\right]$, $\bm{V}_0=100\bm{I}_K$, $\bm{\Psi}_0=5\bm{I}_2$ and $\alpha_0=5$.\footnote{Observe that we are setting the priors in the \textit{reduced-form} model; this may have unintended consequences for the posterior distributions of the \textit{structural} parameters, which are ultimately the parameters researchers are interested in. See \cite[p.~302]{koop2003bayesian} for good references in this topic.} Once our GUI is displayed (see beginning of this chapter), we should follow Algorithm \ref{alg:MultReg} to run multivariate linear models in our GUI (see Chapter \ref{chapGUI} for details):
\begin{algorithm}[h!]
	\caption{Multivariate linear model}\label{alg:MultReg}
	\begin{algorithmic}[1]  		 			
		\State Select \textit{Multivariate Models} on the top panel
		\State Select \textit{Simple Multivariate} model using the left radio button
		\State Upload the dataset selecting first if there is header in the file, and the kind of separator in the \textit{csv} file of the dataset (comma, semicolon, or tab). Then, use the \textit{Browse} button under the \textbf{Choose File} legend
		\State Select MCMC iterations, burn-in and thinning parameters using the \textit{Range sliders}
		\State Select the number of dependent variables in the box \textbf{Number of endogenous variables: m}
		\State Select the number of independent variables (including the intercept) in the box \textbf{Number of exogenous variables: k}
		\State Set the hyperparameters: mean vectors, covariance matrix, degrees of freedom, and the scale matrix. This step is not necessary as by default our GUI uses non-informative priors
		\State Click the \textit{Go!} button
		\State Analyze results
		\State Download posterior chains and diagnostic plots using the \textit{Download Posterior Chains} and \textit{Download Posterior Graphs} buttons
	\end{algorithmic} 
\end{algorithm}

The following \textbf{R} code shows how to perform the Gibss sampling algorithm in this example using the dataset \textit{4Institutions.csv}. We ask to run this example using the \textit{rmultireg} command from the \textit{bayesm} package as an exercise. We find that the posterior mean \textit{structural} effect of property rights on GDP is 0.98, and the 95\% credible interval is (0.56, 2.87). This means that there is evidence supporting a positive effect of property rights on gross domestic product. 

\begin{tcolorbox}[enhanced,width=4.67in,center upper,
	fontupper=\large\bfseries,drop shadow southwest,sharp corners]
	\textit{R code. The effect of institutions on per capita GDP}
	\begin{VF}
		\begin{lstlisting}[language=R]
rm(list = ls())
set.seed(12345)
DataInst <- read.csv("DataApplications/4Institutions.csv", sep = ",", header = TRUE, fileEncoding = "latin1")
attach(DataInst)
Y <- cbind(logpcGDP95, PAER)
X <- cbind(1, logMort, Africa, Asia, Other)
M <- dim(Y)[2]
K <- dim(X)[2]
N <- dim(Y)[1]
# Hyperparameters
B0 <- matrix(0, K, M)
c0 <- 100
V0 <- c0*diag(K)
Psi0 <- 5*diag(M)
a0 <- 5
# Posterior parameters
Bhat <- solve(t(X)%*%X)%*%t(X)%*%Y 
S <- t(Y - X%*%Bhat)%*%(Y - X%*%Bhat)
Vn <- solve(solve(V0) + t(X)%*%X) 
Bn <- Vn%*%(solve(V0)%*%B0 + t(X)%*%X%*%Bhat)
Psin <- Psi0 + S + t(B0)%*%solve(V0)%*%B0 + t(Bhat)%*%t(X)%*%X%*%Bhat - t(Bn)%*%solve(Vn)%*%Bn
an <- a0 + N
#Posterior draws
s <- 10000 #Number of posterior draws
SIGs <- replicate(s, LaplacesDemon::rinvwishart(an, Psin))
BsCond <- sapply(1:s, function(s) {MixMatrix::rmatrixnorm(n = 1, mean=Bn, U = Vn,V = SIGs[,,s])})
summary(coda::mcmc(t(BsCond)))
SIGMs <- t(sapply(1:s, function(l) {gdata::lowerTriangle(SIGs[,,l], diag=TRUE, byrow=FALSE)}))
summary(coda::mcmc(SIGMs))
hdiBs <- HDInterval::hdi(t(BsCond), credMass = 0.95) # Highest posterior density credible interval
hdiBs
hdiSIG <- HDInterval::hdi(SIGMs, credMass = 0.95) # Highest posterior density credible interval
hdiSIG
beta2 <- BsCond[2,]/BsCond[7,] 
summary(coda::mcmc(beta1)) # Effect of property rights on GDP
Iterations = 1:10000
Thinning interval = 1 
Number of chains = 1 
Sample size per chain = 10000 
1. Empirical mean and standard deviation for each variable,
plus standard error of the mean:
Mean             SD       Naive SE Time-series SE 
0.9796        16.8430         0.1684         0.1684 
2. Quantiles for each variable:
2.5%    25%    50%    75%  97.5% 
0.5604 0.7984 0.9677 1.2329 2.8709 
\end{lstlisting}
	\end{VF}
\end{tcolorbox} 

\section{Seemingly unrelated regression}\label{sec72}

In seemingly unrelated regression (SUR) models there are $M$ dependent variables with potentially different regressors such that the stochastic errors are contemporaneously correlated. This is $\bm{y}_{j}=\bm{X}_{j}\bm{\beta}_j+\bm{\mu}_{j}$, where $\bm{y}_j$ is a $N$-dimensional vector, $\bm{X}_j$ is a matrix of dimension $N\times K_m$ of regressors, $\bm{\beta}_j$ is a $K_m$-dimensional vector of location parameters, and $\bm{\mu}_j$ is a $N$-dimensional vector of stochastic errors, $m=1,2,\dots,M$.
	
Setting $\bm{\mu}_i=\left[\mu_{i1} \ \mu_{i2} \dots \mu_{iM}\right]^{\top}$ such that $\bm{\mu}_i\sim{N}(\bm{0},\bm{\Sigma})$, and stacking the $M$ equations, we can write $\bm{y}=\bm{X}\bm{\beta}+\bm{\mu}$ where $\bm{y}=\left[\bm{y}_{1}^{\top} \ \bm{y}_{2}^{\top} \dots \bm{y}_{M}^{\top}\right]^{\top}$ is a $MN$-dimensional vector,  $\bm{\beta}=\left[\bm{\beta}_{1}^{\top} \ \bm{\beta}_{2}^{\top} \ldots \bm{\beta}_{M}^{\top}\right]^{\top}$ is a $ K$ dimensional vector, $K=\sum_{m=1}^{M} K_m$, $\bm{X}$ is an $MN\times K$ block diagonal matrix composed of $\bm{X}_{m}$ and $\bm{\mu}=\left[\bm{\mu}_{1}^{\top} \ \bm{\mu}_{2}^{\top} \dots ,\bm{\mu}_{M}^{\top}\right]^{\top}$ is a $MN$-dimensional vector of stochastic errors such that $\bm{\mu}\sim{N}(\bm{0},\bm{\Sigma}\otimes \bm{I}_N)$.
Then, 
\begin{align*}
	p(\bm{\beta},\bm{\Sigma}|\bm{y},\bm{X})\propto \left|\bm{\Sigma} \right|^{-N/2}\exp\left\{ -\frac{1}{2}(\bm{y}-\bm{X\beta})^{\top}(\bm{\Sigma}^{-1}\otimes \bm{I}_N\})(\bm{y}-\bm{X\beta})\right\}.
\end{align*}

Using independent priors $\pi(\bm{\beta})\sim{N}(\bm{\beta}_0,\bm{B}_0)$ and $\pi(\bm{\Sigma}^{-1})\sim{W}(\alpha_0,\bm{\Psi}_0)$, the posterior distributions are
\begin{equation*}
	\bm{\beta}|\bm{\Sigma}, \bm{y}, \bm{X} \sim {N}(\bm{\beta}_n, \bm{B}_n), 
\end{equation*}
\begin{equation*}
	\bm{\Sigma}^{-1}|\bm{\beta}, \bm{y}, \bm{X} \sim {W}(\alpha_n, \bm{\Psi}_n),
\end{equation*}

where $\bm{B}_n=(\bm{X}^{\top}(\bm{\Sigma}^{-1}\otimes \bm{I}_N )\bm{X}+\bm{B}_0^{-1})^{-1}$, $\bm{\beta}_n=\bm{B}_n(\bm{B}_0^{-1}\bm{\beta}_0 + \bm{X}^{\top}(\bm{\Sigma}^{-1}\otimes \bm{I}_N)\bm{y})$, $\alpha_n = \alpha_0 + N$ and $\bm{\Psi}_n = (\bm{\Psi}_0^{-1} + \bm{U}^{\top}\bm{U})^{-1}$, where $\bm{U}$ is an $N\times M$ matrix whose columns are $\bm{y}_j-\bm{X}_j\bm{\beta}_j$.

Observe that we have standard conditional posteriors, thus, we can employ a Gibbs sampling algorithm to get the posterior draws.\\

\textbf{Example: Utility demand}

Let's use the dataset \textit{Utilities.csv} to estimate a seemingly unrelated regression model for utilities. We use the same setting as in Exercise 14 in Chapter \ref{chap4} where we ask to estimate a multivariate regression model omitting households with no consumption in any utility. We see in this exercise that no all regressors are relevant for the demand of electricity, water and gas. Thus, we estimate the following model:
\begin{align*}
	\log(\text{electricity}_i) & = \beta_1 + \beta_2\log(\text{electricity price}_i)+\beta_3\log(\text{water price}_i)\\
	&+\beta_4\log(\text{gas price}_i)+\beta_5\text{IndSocio1}_i+\beta_6\text{IndSocio2}_i+\beta_7\text{Altitude}_i\\
	&+\beta_8\text{Nrooms}_i+\beta_9\text{HouseholdMem}_i+\beta_{10}\log(\text{Income}_i)+\mu_{i1}\\
	\log(\text{water}_i) & = \alpha_1 + \alpha_2\log(\text{electricity price}_i)+\alpha_3\log(\text{water price}_i)\\
	&+\alpha_4\log(\text{gas price}_i)+\alpha_5\text{IndSocio1}_i+\alpha_6\text{IndSocio2}_i\\
	&+\alpha_7\text{Nrooms}_i+\alpha_8\text{HouseholdMem}_i+\mu_{i2}\\
	\log(\text{gas}_i) & = \gamma_1 + \gamma_2\log(\text{electricity price}_i)+\gamma_3\log(\text{water price}_i)\\
	&+\gamma_4\log(\text{gas price}_i)+\gamma_5\text{IndSocio1}_i+\gamma_6\text{IndSocio2}_i+\gamma_7\text{Altitude}_i\\
	&+\gamma_8\text{Nrooms}_i+\gamma_9\text{HouseholdMem}_i+\mu_{i3},
\end{align*} 
where electricity, water and gas are the monthly consumption of electricity (kWh), water (m$^3$) and gas (m$^3$) of Colombian households. There is information of 2103 households regarding average prices of electricity (USD/kWh), water (USD/m$^3$) and gas (USD/m$^3$), indicators of socioeconomic conditions of the neighborhood where the household is located (IndSocio1 is the lowest and IndSocio3 is the highest), an indicator if the household is located in a municipality that is above 1000 meters above the sea level, the number of rooms in the house, the number of members of the households, and monthly income (USD).

Since there are different sets of regressors in each equation and we suspect correlation between the stochastic errors of the three equations, we should estimate a seemingly unrelated regressions (SUR) model. We expect unobserved correlation in these equations because we are modelling utilities, and in some cases, a single provider handles all three services and issues one bill.

Algorithm \ref{alg:SUR} shows how to estimate SUR models in our GUI. Our GUI uses the command \textit{rsurGibbs} from the \textit{bayesm} package in \textbf{R} software. The following code shows how to program this application using this package. We use 10000 MCMC iterations, $\bm{\beta}_0=\bm{0}_{27}$, $\bm{B}_0=100\bm{I}_{27}$, $\alpha_0=5$ and $\bm{\Psi}=5\bm{I}_3$.

We find that the posterior median estimates of the own-price elasticities of demand of electricity, water and gas are -1.88, -0.36 and -0.62, where there are not 95\% credible intervals that encompass 0. This means that a 1\% increase in the prices of electricity, water and gas imply a 1.88\%, 0.36\% and 0.62\% decrease in the monthly consumption of these utilities, respectively.\footnote{This is an example where there can be concerns regarding \textit{biased} and \textit{inconsistent} posterior mean estimates, for instance, due to \textit{reverse causality} between quantity and demand. These concerns are valid; although, we are using micro-level data, which implies no demand-supply simultaneity. In addition, the utility providers are operating in regulated natural monopoly markets, this implies no endogeneity due to searching provider strategies. Finally, we took prices directly from provider records, this avoids price measurement errors \cite{ramirez2024welfare}.} In general, there is evidence supporting the relevance of all regressors in these equations, except a few exceptions, and unobserved correlation in the demand of these services supporting the relevance of a SUR model in this application.   

\begin{algorithm}[h!]
	\caption{Seemingly unrelated regression}\label{alg:SUR}
	\begin{algorithmic}[1]  		 			
		\State Select \textit{Multivariate Models} on the top panel
		\State Select \textit{Seemingly Unrelated Regression} model using the left radio button
		\State Upload the dataset selecting first if there is header in the file, and the kind of separator in the \textit{csv} file of the dataset (comma, semicolon, or tab). Then, use the \textit{Browse} button under the \textbf{Choose File} legend
		\State Select MCMC iterations, burn-in and thinning parameters using the \textit{Range sliders}
		\State Select the number of dependent variables in the box \textbf{Number of endogenous variables: m}
		\State Select the number of independent variables in the box \textbf{TOTAL number Exogenous Variables: k}. This is the sum of all exogenous variables over all equations including intercepts. In the example of \textbf{Utility demand}, it is equal to 27
		\State Set the hyperparameters: mean vectors, covariance matrix, degrees of freedom, and the scale matrix. This step is not necessary as by default our GUI uses non-informative priors
		\State Click the \textit{Go!} button
		\State Analyze results
		\State Download posterior chains and diagnostic plots using the \textit{Download Posterior Chains} and \textit{Download Posterior Graphs} buttons
	\end{algorithmic} 
\end{algorithm}


\begin{tcolorbox}[enhanced,width=4.67in,center upper,
	fontupper=\large\bfseries,drop shadow southwest,sharp corners]
	\textit{R code. Utility demand in Colombia}
	\begin{VF}
		\begin{lstlisting}[language=R]
rm(list = ls())
set.seed(010101)
library(dplyr)
DataUt <- read.csv("DataApplications/Utilities.csv", sep = ",", header = TRUE, fileEncoding = "latin1")
DataUtEst <- DataUt %>%  
filter(Electricity != 0 & Water !=0 & Gas != 0)
attach(DataUtEst)
y1 <- log(Electricity); y2 <- log(Water); y3 <- log(Gas)
X1 <- cbind(1, LnPriceElect, LnPriceWater, LnPriceGas, IndSocio1, IndSocio2, Altitude, Nrooms, HouseholdMem, Lnincome)
X2 <- cbind(1, LnPriceElect, LnPriceWater, LnPriceGas, IndSocio1, IndSocio2, Nrooms, HouseholdMem)
X3 <- cbind(1, LnPriceElect, LnPriceWater, LnPriceGas, IndSocio1, IndSocio2, Altitude, Nrooms, HouseholdMem)
regdata <- NULL
regdata[[1]] <- list(y = y1, X = X1); regdata[[2]] <- list(y = y2, X = X2); regdata[[3]] <- list(y = y3, X = X3)
M <- length(regdata); K1 <- dim(X1)[2]; K2 <- dim(X2)[2]; K3 <- dim(X3)[2] 
K <- K1 + K2 + K3
# Hyperparameters
b0 <- rep(0, K); c0 <- 100; B0 <- c0*diag(K); V <- 5*diag(M); a0 <- M
Prior <- list(betabar = b0, A = solve(B0), nu = a0, V = V)
#Posterior draws
S <- 10000; keep <- 1; Mcmc <- list(R = S, keep = keep)
PosteriorDraws <- bayesm::rsurGibbs(Data = list(regdata = regdata), Mcmc = Mcmc, Prior = Prior)
\end{lstlisting}
	\end{VF}
\end{tcolorbox}

\begin{tcolorbox}[enhanced,width=4.67in,center upper,
	fontupper=\large\bfseries,drop shadow southwest,sharp corners]
	\textit{R code. Utility demand in Colombia, results}
	\begin{VF}
		\begin{lstlisting}[language=R]
Bs <- PosteriorDraws[["betadraw"]]
Names <- c("Const", "LnPriceElect", "LnPriceWater", "LnPriceGas", "IndSocio1", "IndSocio2", 
"Altitude", "Nrooms", "HouseholdMem", "Lnincome", "Const",
"LnPriceElect", "LnPriceWater", "LnPriceGas", "IndSocio1", "IndSocio2", 
"Nrooms", "HouseholdMem","Const",
"LnPriceElect", "LnPriceWater", "LnPriceGas", "IndSocio1", "IndSocio2", 
"Altitude", "Nrooms", "HouseholdMem")
colnames(Bs) <- Names
summary(coda::mcmc(Bs))
summary(PosteriorDraws[["Sigmadraw"]])
2. Quantiles for each variable:
					2.5%      25%       50%      75%    97.5%
Const         0.44452  1.03120  1.342407  1.65192  2.25376
LnPriceElect -2.39679 -2.06328 -1.882706 -1.70369 -1.36996
LnPriceWater -0.44221 -0.38678 -0.356850 -0.32669 -0.26969
LnPriceGas   -0.21655 -0.13777 -0.098191 -0.05902  0.01872
IndSocio1    -0.87630 -0.78653 -0.737701 -0.68840 -0.59675
IndSocio2    -0.24601 -0.18286 -0.151440 -0.11896 -0.05681
Altitude     -0.27080 -0.23838 -0.220742 -0.20385 -0.17259
Nrooms        0.04596  0.06178  0.070023  0.07835  0.09422
HouseholdMem  0.06600  0.07994  0.086857  0.09411  0.10785
Lnincome      0.03836  0.05421  0.062957  0.07165  0.08717
Const         0.88957  1.73496  2.169638  2.62170  3.47216
LnPriceElect -0.81956 -0.31624 -0.054075  0.21132  0.71842
LnPriceWater -0.49559 -0.40995 -0.364248 -0.32026 -0.23639
LnPriceGas    0.06075  0.16754  0.226690  0.28570  0.39476
IndSocio1    -0.64203 -0.50302 -0.427819 -0.35226 -0.21315
IndSocio2    -0.50401 -0.40949 -0.359821 -0.31063 -0.21199
Nrooms        0.05688  0.08023  0.093139  0.10555  0.12968
HouseholdMem  0.10041  0.12065  0.131506  0.14260  0.16314
Const        -2.28569 -1.58566 -1.220078 -0.84612 -0.14787
LnPriceElect -2.42484 -2.01228 -1.797269 -1.57889 -1.16396
LnPriceWater -0.10684 -0.03923 -0.004088  0.03153  0.09905
LnPriceGas   -0.76526 -0.67445 -0.625899 -0.57734 -0.48125
IndSocio1    -0.91381 -0.80243 -0.744909 -0.68577 -0.57341
IndSocio2    -0.31791 -0.24388 -0.203300 -0.16415 -0.09012
Altitude      0.24896  0.29099  0.311668  0.33256  0.37278
Nrooms        0.06050  0.07921  0.089386  0.09943  0.11793
HouseholdMem  0.14467  0.16144  0.170024  0.17843  0.19431
summary(coda::mcmc(PosteriorDraws[["Sigmadraw"]]))
2. Quantiles for each variable:
				2.5%     25%     50%     75%  97.5%
var1 0.19912 0.20822 0.21332 0.21863 0.2290
var2 0.08183 0.09284 0.09870 0.10475 0.1160
var3 0.05121 0.05973 0.06426 0.06882 0.0781
var4 0.08183 0.09284 0.09870 0.10475 0.1160
var5 0.47763 0.49934 0.51131 0.52387 0.5493
var6 0.07318 0.08653 0.09351 0.10079 0.1145
var7 0.05121 0.05973 0.06426 0.06882 0.0781
var8 0.07318 0.08653 0.09351 0.10079 0.1145
var9 0.29523 0.30900 0.31654 0.32428 0.3397
\end{lstlisting}
	\end{VF}
\end{tcolorbox}

We ask in the Exercise 5 to run this application using our GUI and the information in the dataset \textit{Utilities.csv}. Observe that this file should be modified to agree the structure that requires our GUI (see the dataset \textit{5Institutions.csv} in the folder \textit{DataApp} of our GitHub repository -\textbf{https://github.com/besmarter/BSTApp}- for a template). In addition, we ask to program from scratch the Gibbs sampler algorithm in this application.  

 
\section{Summary}\label{sec75}

\section{Exercises}\label{sec76}
\begin{enumerate}
	\item Show that $\mathbb{E}[u_1\text{PAER}]=\frac{\alpha_1}{1-\beta_1\alpha_1}\sigma^2_1$ assuming that $\mathbb{E}[u_1u_2]=0$ where $Var(u_1)=\sigma^2_1$ in the effect of institutions on per capita GDP.
	
	\item Show that $\beta_1=\pi_1/\gamma_1$ in the effect of institutions on per capita GDP.
	
	\item \textbf{The effect of institutions on per capita gross domestic product continues}
	
	Use the \textit{rmultireg} command from the \textit{bayesm} package to perform inference in the example of the effect of institutions on per capita GDP. 
	
	\item \textbf{Demand and supply simulation}
	
	Given the structural demand-supply model:
	\begin{align*}
		q_i^d&=\beta_1+\beta_2p_i+\beta_3y_i+\beta_4pc_i+\beta_5ps_i+u_{i1}\\
		q_i^s&=\alpha_1+\alpha_2p_i+\alpha_3er_i+u_{i2},
	\end{align*}
where $q^d$ is demand, $q^s$ is supply, $p$, $y$, $pc$, $ps$ and $er$ are price, income, complementary price, substitute price, and exchange rate. Complementary and substitute prices are prices of a complementary and substitute goods of $q$. Assume that $\bm{\beta}=\left[5 \ -0.5 \ 0.8 \ -0.4 \ 0.7\right]^{\top}$, $\bm{\alpha}=\left[-2 \ 0.5 \ -0.4\right]^{\top}$, $u_1\sim N(0, 0.5^2)$ and $u_2\sim N(0, 0.5^2)$. In addition, assume that $y\sim N(10,1)$, $pc\sim N(5,1)$, $ps\sim N(5,1)$ and $tc\sim N(15,1)$.
\begin{itemize}
	\item Find the \textit{reduce-form} model using that in equilibrium demand and supply are equal, that is, $q^d=q^s$. This condition defines the observable quantity ($q$).
	\item Simulate $p$ and $q$ from the \textit{reduce-form} equations.
	\item Preform inference of the \textit{reduce-form} model using the \textit{rmultireg} command from the \textit{bayesm} package.
	\item Use the posterior draws of the \textit{reduce-form} parameters to perform inference of the \textit{structural} parameters. Any issue? Hint: Are all \textit{structural} parameters exactly identified?   
\end{itemize}

\item \textbf{Utility demand continues}

\begin{itemize}
	\item Run the \textbf{Utility demand} application using our GUI and the information in the dataset \textit{Utilities.csv}. Hint: This file should be modified to agree the structure that requires our GUI (see the dataset \textit{5Institutions.csv} in the folder \textit{DataApp} of our GitHub repository -\textbf{https://github.com/besmarter/BSTApp}- for a template).
	\item Program from scratch the Gibbs sampler algorithm in this application.   
\end{itemize}
	
	
\end{enumerate}


