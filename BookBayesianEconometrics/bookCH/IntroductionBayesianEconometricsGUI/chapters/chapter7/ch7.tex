\chapter{Multivariate models}\label{chap7}

We describe how to perform Bayesian inference in multivariate response models: multivariate regression, seemingly unrelated regression, instrumental variables, and multivariate probit model. In particular, we show the posterior distributions of the parameters, and perform some applications and simulations. Again, we show how to perform inference in these models using three levels of programming skills: GUI, packages, and programming from scratch the algorithms. Finally, there are some mathematical and computational exercises.

Remember that we can run our GUI typing

\begin{tcolorbox}[enhanced,width=4.67in,center upper,
	fontupper=\large\bfseries,drop shadow southwest,sharp corners]
	\textit{R code. How to display our graphical user interface}
	\begin{VF}
		\begin{lstlisting}[language=R]
	shiny::runGitHub("besmarter/BSTApp", launch.browser = T)
\end{lstlisting}
	\end{VF}
\end{tcolorbox} 

in the \textbf{R} package console or any \textbf{R} code editor.

\section{Multivariate regression}\label{sec71}

A complete presentation of this model is given in Section \ref{sec44}. We show here the setting, and the posterior distributions for facility in exposition. In particular, there are $M$ multiply dependent variables which share the same set of regressors, and their stochastic errors are contemporaneously correlated. In particular, $\bm{Y}=\left[{\bf{y_{1}}},{\bf{y_{2}}},\ldots,{\bf{y_{M}}}\right]$ is an $ N\times M$ matrix that is generated by $\bm{Y}=\bm{X}\bm{B}+\bm{U}$ where $\bm{X}$ is an $ N\times K$ matrix, $\bm{B}=\left[\bm{\beta}_{1},\bm{\beta}_{2},\ldots,\bm{\beta}_{M}\right]$ is a $ K\times M$ matrix of parameters, and $\bm{U}=\left[\bm{\mu}_{1},\bm{\mu}_{2},\ldots,\bm{\mu}_{M}\right]$ is a matrix of stochastic random errors such that $\bm{\mu}_i\sim{N}(\bm{0},\bm{\Sigma})$, $i=1,2,\dots,N$ is each row of $\bm{U}$.

The prior is given by   $\pi(\bm{B}|\bm{\Sigma})\sim{N}(\bm{B}_0,\bm{V}_0, \bm{\Sigma})$ and $\pi(\bm{\Sigma})\sim{I}{W}(\bm{\Psi}_0,\alpha_0)$. Therefore, the conditional posterior distributions are
\begin{equation*}
	\bm{B}|\bm{\Sigma}, \bm{Y}, \bm{X} \sim{N}(\bm{B}_n, \bm{V}_n, \bm{\Sigma}), 
\end{equation*}
\begin{equation*}
	\bm{\Sigma}| \bm{Y}, \bm{X} \sim {I}{W}(\bm{\Psi}_n, \alpha_n),
\end{equation*}

where $\bm{V}_n=(\bm{X}^{\top}\bm{X}+\bm{V}_0^{-1})^{-1}$, $\bm{B}_n=\bm{V}_n(\bm{V}_0^{-1}\bm{B}_0 + \bm{X}^{\top}\bm{X}\hat{\bm{B}})$, $\hat{\bm{B}}=(\bm{X}^{\top}\bm{X})^{-1}\bm{X}^{\top}\bm{Y}$, $\bm{\Psi}_n = {\bf{\Psi}}_{0}+{\bf{S}}+{\bf{B}}_{0}^{\top}{\bf{V}}_{0}^{-1}{\bf{B}}_{0}+\widehat{\bf{B}}^{\top}{\bf{X}}^{\top}{\bf{X}}\widehat{\bf{B}}-{\bf{B}}_n^{\top}{\bf{V}}_n^{-1}{\bf{B}}_n$, and $\alpha_n = \alpha_0 + N$. We can use a Gibbs sampling algorithm in this model since the conditional posterior distributions are standard.\\

\textbf{Example: The effect of institutions on per capita gross domestic product}

To illustrate multivariate regression models, we used the dataset provided by \cite{Acemoglu2001}, who analyzed the effect of property rights on economic growth.

Let's assume that the point of departure is the following \textit{simultaneous structural} economic model:\footnote{This is a model that captures the potential underlying economic relationship between the variables.}
\begin{align}\label{eq:str1}
	\log(\text{pcGDP95}_i)=\beta_1+\beta_2\text{PAER}_i+\beta_3 \text{Africa}+\beta_4 \text{Asia}+\beta_5 \text{Other}+u_{1i},
\end{align}
\begin{align}\label{eq:str2}
	\text{PAER}_i=\alpha_1+\alpha_2\log(\text{pcGDP95}_i)+\alpha_3\log(\text{Mort}_i)+u_{2i},
\end{align}
where \textit{pcGDP95}, \textit{PAER} and \textit{Mort} are the per capita gross domestic product (GDP) in 1995, the average index of protection against expropriation between 1985 and 1995, and the settler mortality rate during the time of colonization. \textit{Africa}, \textit{Asia} and \textit{Other} are dummies for continents, with \textit{America} as the baseline group.

In this model, there is \textit{reverse (simultaneous) causality} due to the contemporaneous effect of \textit{GDP} on \textit{PAER}, and vice verse.\footnote{\textit{Reverse causality} is the most controversial causation issue from a philosophy of science perspective. The root of the issue is that causation is typically based on the time sequence of cause and effect.} Therefore, estimation of the Equation \ref{eq:str1} without taking into account this phenomenon generates posterior mean estimates that are \textit{biased} and \textit{inconsistent} from a sampling (frequentist) point of view.\footnote{Observe that $\mathbb{E}[u_1\text{PAER}]\neq 0$, which means failing to meet a necessary requirement to get \textit{unbiased} and \textit{consistent} estimators of $\bm{\beta}$. See exercise 1.} A potential strategy to tackle this issue is to estimate the \textit{reduced-form} model, that is, a model without \textit{simultaneous causality} where all \textit{endogenous variables} are function of \textit{exogenous variables}. The former variables are determinate inside the model ($\log(\text{pcGDP95}_i)$ and PAER in this example), and the latter outside the model ($\log(\text{Mort}_i)$, Africa, Asia, and Other in this example).

Replacing Equation \ref{eq:str2} into Equation \ref{eq:str1}, and solving for $\log(\textit{pcGDP95})$,
\begin{align}\label{eq:red1}
	\log(\text{pcGDP95}_i)=\pi_1+\pi_2\log(\text{Mort}_i)+\pi_3 \text{Africa}+\pi_4 \text{Asia}+\pi_5 \text{Other}+e_{1i}.   
\end{align}
Then, replacing Equation \ref{eq:red1} into Equation \ref{eq:str2}, and solving for \textit{PAER},
\begin{align}\label{eq:red2}
	\text{PAER}_i=\gamma_1+\gamma_2\log(\text{Mort}_i)+\gamma_3 \text{Africa}+\gamma_4 \text{Asia}+\gamma_5 \text{Other}+e_{2i},
\end{align}
where $\pi_2=\frac{\beta_2\alpha_3}{1-\beta_2\alpha_2}$ and $\gamma_2=\frac{\alpha_3}{1-\beta_2\alpha_2}$ given $\beta_2\alpha_2\neq 1$, that is, independent equations (see Exercise 2). 

Observe that equations \ref{eq:red1} and \ref{eq:red2} have the form of multivariate regression model where the common set of regressors is $\bm{X}=\left[\log(\textbf{Mort}) \ \textbf{Africa} \ \textbf{Asia} \ \textbf{Other}\right]$ and $\bm{Y}=\left[\log(\textbf{pcGDP95}) \ \textbf{PAER}\right]$. Thus, we can estimate this model using the setup of this section.

Thus, we estimate in a first stage the parameters from the \textit{reduced-form} model (Equations \ref{eq:red1} and \ref{eq:red2}), but the main interest is the parameters of the \textit{structural} model (Equations \ref{eq:str1} and \ref{eq:str2}). Thus, a valid question is if we can recover the \textit{structural} parameters from the \textit{reduced-form} parameters. There are two criteria to respond this question: the order condition, which is necessary, and the rank condition, which is necessary and sufficient.\\
 
\textit{The order condition}

Given a system of equations with $M$ endogenous variables, and $K$ exogenous variables (including the intercept), there are two ways to assess the order condition:
\begin{itemize}
	\item The parameters of an equation in the system are identified if there are at least $M-1$ variables excluded from the equation (\textit{exclusion restrictions}). The equation is \textit{exactly identified} if the number of excluded variables is $M-1$, and is \textit{over identified} if the number of excluded variables is greater than $M-1$.
	\item The parameters of equation $m$ in the system are identified if $K-K_m\geq M_m-1$, where $K_m$ and $M_m$ are the number of exogenous and endogenous variables in equation $m$, respectively. The $m$-th equation is \textit{exactly identified} if $K-K_m = M_m-1$, and \textit{over identified} if if $K-K_m > M_m-1$. 
\end{itemize}

We can see from Equations \ref{eq:str1} and \ref{eq:str2} in this example that $K=5$, $M=2$, $K_1=4$, $K_2=2$, $M_1=2$ and $M_2=2$. This means that $K-K_1=1=M-1$ and $K-K_2=3>M-1=1$, that is, the order condition says that both equations satisfy the necessary condition of identification, the first equation would be \textit{exactly identified}, and the second equation would be \textit{over identified}. Observe that there is one excluded variable from the first equation, and there are three excluded variables from the second equation.
\\

\textit{The rank condition}

The rank condition (necessary and sufficient) says that given a \textit{structural} model with $M$ equations ($M$ endogenous variables), an equation is identified if and only if there is at least one determinant different from zero from a $(M-1)\times(M-1)$ matrix built using the excluded variables in the analyzed equation, but included in any other equation of the system.

It is useful to build the \textit{identification matrix} to implement the \textit{rank} condition. Table \ref{tab:71} shows this matrix in this example.

\begin{table}[!h]
	%\noautomaticrules
	\tabletitle{Identification matrix.}\label{tab:71}%
	\begin{tabular}{ccccccc}
		$\log(\text{pcGDP95})$ & PAER & Constant & $\log(\text{Mort})$ & Africa & Asia & Other \\
		\hline
		1 & -$\beta_2$ & -$\beta_1$ & 0 & -$\beta_3$ & -$\beta_4$ & -$\beta_5$\\
		-$\alpha_2$ & 1 & $-\alpha_1$ & -$\alpha_3$ & 0 & 0 & 0 \\
	\end{tabular}
\end{table}

The only excluded variable in the $\log(\text{pcGDP95})$ equation is $\log(\text{Mort})$. Then, there is just one matrix that can be built using the excluded variables from this equation $[-\alpha_3]$ (see column 4 in Table \ref{tab:71}). Thus, the determinant of this matrix is $-\alpha_3$, and as far as this coefficient is different to zero, that is, that the mortality rate is relevant in the $PAER$ equation ($\alpha_3\neq 0$), the coefficients in $\log(\text{pcGDP95})$ equation are \textit{exactly identified}. For instance, $\beta_2=\frac{\pi_2}{\gamma_2}$, which is the effect of property rights on GDP, is exactly identified. 

Observe the importance of excluding $\log(\text{Mort})$ from the $\log(\text{pcGDP95})$ equation, but including $\log(\text{Mort})$ in the PAER equation. This is called \textit{exclusion restriction}, and it is the requirement of having an exogenous source of variability in the PAER equation that helps to identify the $\log(\text{pcGDP95})$ equation. Having relevant exogenous sources of variability is a very important aspect in identification, estimation and inference of \textit{structural} parameters.

Regarding the identification of the \textit{structural} parameters in the PAER equation, there are three potential matrices that can be constructed: $[-\beta_3]$, $[-\beta_4]$ and $[-\beta_5]$ (see columns 5, 6 and 7 in Table \ref{tab:71}), as far as any of these parameters are relevant in the $\log(\text{pcGDP95})$ equation, we achieve identification of the PAER equation. In this case, this equation is \textit{over identified}, that is, there are many ways to find the parameters in this equations. For instance, $\alpha_2=\gamma_3/\pi_3=\gamma_4/\pi_4=\gamma_5/\pi_5$ (see Exercise 2).

In general, trying to recover the \textit{structural} parameters from the \textit{reduced-form} parameters can be challenging due to the requirement of relevant identification restrictions that can be hard to find in some applications.\footnote{Good references for identification in linear systems are \cite{gujarati2009basic,wooldridge2016introductory}.}

We set non-informative priors in this example, $\bm{B}_0=\left[\bm{0}_5 \ \bm{0}_5\right]$, $\bm{V}_0=100\bm{I}_K$, $\bm{\Psi}_0=5\bm{I}_2$ and $\alpha_0=5$.\footnote{Observe that we are setting the priors in the \textit{reduced-form} model; this may have unintended consequences for the posterior distributions of the \textit{structural} parameters, which are ultimately the parameters researchers are interested in. See \cite[p.~302]{koop2003bayesian} for good references in this topic.} Once our GUI is displayed (see beginning of this chapter), we should follow Algorithm \ref{alg:MultReg} to run multivariate linear models in our GUI (see Chapter \ref{chapGUI} for details):
\begin{algorithm}[h!]
	\caption{Multivariate linear model}\label{alg:MultReg}
	\begin{algorithmic}[1]  		 			
		\State Select \textit{Multivariate Models} on the top panel
		\State Select \textit{Simple Multivariate} model using the left radio button
		\State Upload the dataset selecting first if there is header in the file, and the kind of separator in the \textit{csv} file of the dataset (comma, semicolon, or tab). Then, use the \textit{Browse} button under the \textbf{Choose File} legend. You should see a preview of the dataset
		\State Select MCMC iterations, burn-in and thinning parameters using the \textit{Range sliders}
		\State Select the number of dependent variables in the box \textbf{Number of endogenous variables: m}
		\State Select the number of independent variables (including the intercept) in the box \textbf{Number of exogenous variables: k}
		\State Set the hyperparameters: mean vectors, covariance matrix, degrees of freedom of the Inverse Wishart distribution, and the scale matrix. This step is not necessary as by default our GUI uses non-informative priors
		\State Select the tuning parameter for the Metropolis-Hastings algorithm
		\State Click the \textit{Go!} button
		\State Analyze results
		\State Download posterior chains and diagnostic plots using the \textit{Download Posterior Chains} and \textit{Download Posterior Graphs} buttons
	\end{algorithmic} 
\end{algorithm}

\begin{tcolorbox}[enhanced,width=4.67in,center upper,
	fontupper=\large\bfseries,drop shadow southwest,sharp corners]
	\textit{R code. The effect of institutions on per capita GDP}
	\begin{VF}
		\begin{lstlisting}[language=R]
rm(list = ls())
set.seed(12345)
DataInst <- read.csv("DataApplications/4Institutions.csv", sep = ",", header = TRUE, fileEncoding = "latin1")
attach(DataInst)
Y <- cbind(logpcGDP95, PAER)
X <- cbind(1, logMort, Africa, Asia, Other)
M <- dim(Y)[2]
K <- dim(X)[2]
N <- dim(Y)[1]
# Hyperparameters
B0 <- matrix(0, K, M)
c0 <- 100
V0 <- c0*diag(K)
Psi0 <- 5*diag(M)
a0 <- 5
# Posterior parameters
Bhat <- solve(t(X)%*%X)%*%t(X)%*%Y 
S <- t(Y - X%*%Bhat)%*%(Y - X%*%Bhat)
Vn <- solve(solve(V0) + t(X)%*%X) 
Bn <- Vn%*%(solve(V0)%*%B0 + t(X)%*%X%*%Bhat)
Psin <- Psi0 + S + t(B0)%*%solve(V0)%*%B0 + t(Bhat)%*%t(X)%*%X%*%Bhat - t(Bn)%*%solve(Vn)%*%Bn
an <- a0 + N
#Posterior draws
s <- 10000 #Number of posterior draws
SIGs <- replicate(s, LaplacesDemon::rinvwishart(an, Psin))
BsCond <- sapply(1:s, function(s) {MixMatrix::rmatrixnorm(n = 1, mean=Bn, U = Vn,V = SIGs[,,s])})
summary(coda::mcmc(t(BsCond)))
SIGMs <- t(sapply(1:s, function(l) {gdata::lowerTriangle(SIGs[,,l], diag=TRUE, byrow=FALSE)}))
summary(coda::mcmc(SIGMs))
hdiBs <- HDInterval::hdi(t(BsCond), credMass = 0.95) # Highest posterior density credible interval
hdiBs
hdiSIG <- HDInterval::hdi(SIGMs, credMass = 0.95) # Highest posterior density credible interval
hdiSIG
beta2 <- BsCond[2,]/BsCond[7,] 
summary(coda::mcmc(beta1)) # Effect of property rights on GDP
Iterations = 1:10000
Thinning interval = 1 
Number of chains = 1 
Sample size per chain = 10000 
1. Empirical mean and standard deviation for each variable,
plus standard error of the mean:
Mean             SD       Naive SE Time-series SE 
0.9796        16.8430         0.1684         0.1684 
2. Quantiles for each variable:
2.5%    25%    50%    75%  97.5% 
0.5604 0.7984 0.9677 1.2329 2.8709 
\end{lstlisting}
	\end{VF}
\end{tcolorbox} 
 
The previous \textbf{R} code shows how to perform the Gibss sampling algorithm in this example using the dataset \textit{4Institutions.csv}. We ask to run this example using the \textit{rmultireg} command from the \textit{bayesm} package as an exercise. We find that the posterior mean \textit{structural} effect of property rights on GDP is 0.98, and the 95\% credible interval is (0.56, 2.87). 

\section{Seemingly unrelated regression}\label{sec72}

As there are different sets of regressors in each equation, and we suspect there is correlation between the stochastic errors of these two equations, we should estimate a seemingly unrelated regressions (SUR) model.\\

We should take into account that there are two equations: the first one has five regressors, including the intercept, and the second equation has two regressors (intercept plus the mortality rate).
We used default values for the hyperparameters, this implies ``vague'' prior information, and hence an ``objective'' Bayesian approach.\\

We set 10,000 MCMC iterations plus 1,000 burn-in iterations, and a thinning parameter equal to 1.
It seems that this setting gives posterior chains that converge to stationary distributions.
All stationary tests do not reject the null hypothesis of ``stationarity,'' and the mixing properties look good (dependence factors close to 1, autocorrelation and trace plots seem to indicate no autocorrelation).\\

The most important parameters are the effect of the mortality rate on gross domestic product and property rights.
Their 95\% credible intervals are (-0.67, -0.29) and (-0.85, -0.35), respectively (second and seventh parameters).
This suggests that the settler mortality rate during the time of colonization is negatively associated with economic growth and property rights.
In addition, the 95\% credible interval of the covariance between the stochastic errors of these two equations is (0.33, 0.88), which suggests that there is statistically significant evidence of correlation between the equations.\\

The previous set of equations can be considered as a restricted reduced form system, where the coefficients of the continents are set equal to 0 in the property rights equation.
We can think in the following system of structural equations as producing the previous, but unrestricted, reduced form system,



We used the file \textit{4Institutions.csv}, which has the structure to estimate multivariate Bayesian regressions using our GUI, to identify the causal effect of property rights on per capita GDP.
In particular, we use the same MCMC and hyperparameters setting as in the previous exercise to obtain the posterior estimates of the reduced system without imposing zero restrictions of the effect of continents on property rights.
The structural parameter $\beta_1$ is equal to $\pi_1/\gamma_1$.\footnote{Substituting Equation \ref{eq:str2} into Equation \ref{eq:str1} and comparing with Equation \ref{eq:red1} yields $\pi_1=\frac{\beta_1\alpha_2}{1-\beta_1\alpha_1}$.
	Solving for the PAER as a function of the exogenous regressors in the structural system, and comparing with Equation \ref{eq:red2}, yields $\gamma_1=\frac{\alpha_2}{1-\beta_1\alpha_1}$.
	Observe one needs independent equations ($\beta_1\alpha_1\neq 1$), and the exclusion restriction ($\alpha_2\neq 0$).} We used the posterior draws automatically generated by our GUI to obtain the posterior chain of this structural parameter, which are the causal effects  that \cite{Acemoglu2001} wanted to identify.
The 95\% credible interval is (0.56, 2.93), the posterior mean value is 1.12, and the median value is 0.98.
If we estimate a multivariate system without taking into account the dummy variables associated with the continents, the causal effect has a 95\% credible interval (0.68, 1.43) with posterior mean and median values equal to 0.94 and 0.97, respectively.
Observe that the length of the second interval is shorter than the first.
This is because the dummy variables of the continents are not statistical relevant for the property rights equation. As a consequence, the former estimation is less efficient.\\

Observe that we also obtain the posterior draws of the covariance matrix of these two reduced form equations from our GUI.
All the convergence diagnostics indicate that the posterior draws (location and scale parameters) seem to come from stationary distributions.\\

\section{Summary}\label{sec75}

\section{Exercises}\label{sec76}
\begin{enumerate}
	\item Show that $\mathbb{E}[u_1\text{PAER}]=\frac{\alpha_1}{1-\beta_1\alpha_1}\sigma^2_1$ assuming that $\mathbb{E}[u_1u_2]=0$ where $Var(u_1)=\sigma^2_1$ in the effect of institutions on per capita GDP.
	
	\item Show that $\beta_1=\pi_1/\gamma_1$ in the effect of institutions on per capita GDP.
	
	\item \textbf{The effect of institutions on per capita gross domestic product continues}
	
	Use the \textit{rmultireg} command from the \textit{bayesm} package to perform inference in the example of the effect of institutions on per capita GDP. 
	
	\item \textbf{Demand and supply simulation}
	
	Given the structural demand-supply model:
	\begin{align*}
		q_i^d&=\beta_1+\beta_2p_i+\beta_3y_i+\beta_4pc_i+\beta_5ps_i+u_{i1}\\
		q_i^s&=\alpha_1+\alpha_2p_i+\alpha_3er_i+u_{i2},
	\end{align*}
where $q^d$ is demand, $q^s$ is supply, $p$, $y$, $pc$, $ps$ and $er$ are price, income, complementary price, substitute price, and exchange rate. Complementary and substitute prices are prices of a complementary and substitute goods of $q$. Assume that $\bm{\beta}=\left[5 \ -0.5 \ 0.8 \ -0.4 \ 0.7\right]^{\top}$, $\bm{\alpha}=\left[-2 \ 0.5 \ -0.4\right]^{\top}$, $u_1\sim N(0, 0.5^2)$ and $u_2\sim N(0, 0.5^2)$. In addition, assume that $y\sim N(10,1)$, $pc\sim N(5,1)$, $ps\sim N(5,1)$ and $tc\sim N(15,1)$.
\begin{itemize}
	\item Find the \textit{reduce-form} model using that in equilibrium demand and supply are equal, that is, $q^d=q^s$. This condition defines the observable quantity ($q$).
	\item Simulate $p$ and $q$ from the \textit{reduce-form} equations.
	\item Preform inference of the \textit{reduce-form} model using the \textit{rmultireg} command from the \textit{bayesm} package.
	\item Use the posterior draws of the \textit{reduce-form} parameters to perform inference of the \textit{structural} parameters. Any issue? Hint: Are all \textit{structural} parameters exactly identified?   
\end{itemize}
	
	
\end{enumerate}


