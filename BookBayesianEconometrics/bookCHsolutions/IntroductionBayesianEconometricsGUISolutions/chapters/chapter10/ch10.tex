\chapter{Bayesian model average}\label{chap10}

\section{Solutions of Exercises}\label{sec101}
\begin{enumerate}[leftmargin=*]

		\item The Gaussian linear model specifies $\bf{y}=\alpha\bm{i}_N+\bm{X}_m\bm{\beta}_m+\bm{\mu}_m$ such that $\bm{\mu}_m\sim{N}(\bm{0},\sigma^2\bm{I}_n)$, and $\bm{X}_m$ does not have the column of ones. Assuming that $\pi(\sigma^2)\propto \sqrt{\sigma^2}$, $\pi(\alpha)\propto 1$, and $\bm{\beta}_m|\sigma^2 \sim {N}(\bm{0}_{k_m}, \sigma^2 (g_m\bm{X}_m^{\top}\bm{X}_m)^{-1})$.
	\begin{enumerate}
		\item Show that the posterior conditional distribution of $\bm{\beta}_m$ is $N(\bm{\beta}_{mn},\sigma^2\bm{B}_{mn})$, where $\bm{\beta}_{mn}=\bm{B}_{mn}\bm{X}_m^{\top}(\bm{y}-\alpha\bm{i}_N)$ and $\bm{B}_{mn}=((1+g_m)\bm{X}_m^{\top}\bm{X}_m)^{-1}$.
		\item Show that the marginal the marginal likelihood associated with model $\mathcal{M}_m$ is proportional to
		\begin{align*}
			p(\bm{y}|\mathcal{M}_m)&\propto \left(\frac{g_m}{1+g_m}\right)^{k_m/2}\\
			&\times \left[\frac{1}{1+g_m}(\bm{y}-\bm{X}_m\hat{\bm{\beta}}_m)^{\top}(\bm{y}-\bm{X}_m\hat{\bm{\beta}}_m)+\frac{g_m}{1+g_m}(\bm{y}-\bar{y}\bm{i}_N)^{\top}(\bm{y}-\bar{y}\bm{i}_N)\right]^{-(N-1)/2},
		\end{align*}
		where all parameter are indexed to model $\mathcal{M}_m$, $\hat{\bm{\beta}}_m$ is the maximum likelihood estimator, and $\bar{y}$ is the sample mean of $\bm{y}$.   
	\end{enumerate}  
	
	\textbf{Answer}
	
	\begin{tcolorbox}[enhanced,width=4.67in,center upper,
		fontupper=\large\bfseries,drop shadow southwest,sharp corners]
		\textit{R code. Name}
		\begin{VF}
			\begin{lstlisting}[language=R]
	shiny::runGitHub("besmarter/BSTApp", launch.browser = T)
\end{lstlisting}
		\end{VF}
	\end{tcolorbox} 
	
\end{enumerate}