\chapter{Longitudinal/Panel data models}\label{chap9}

\section{Solutions of Exercises}\label{sec91}
\begin{enumerate}[leftmargin=*]

	\item Show that the posterior distribution of $\bm{\beta}|\sigma^2,\bm{D}$ is $N(\bm{\beta}_n,\bm{B}_n)$, where $\bm{B}_n = (\bm{B}_0^{-1} +\sum_{i=1}^N \bm{X}_i^{\top}\bm{V}_i^{-1}\bm{X}_i)^{-1}$, $\bm{\beta}_n= \bm{B}_n(\bm{B}_0^{-1}\bm{\beta}_0 + \sum_{i=1}^N\bm{X}_i^{\top}\bm{V}_i^{-1}\bm{y}_i)$.
	
	\textbf{Answer}

{\footnotesize	
	\begin{align*}
		\pi(\bm{\beta}|\sigma^2, \bm{D},\bm{y},\bm{X},\bm{W}) & \propto \exp\left\{-\frac{1}{2}\sum_{i=1}^N(\bm{y}_i-\bm{X}_i\bm{\beta})^{\top}\bm{V}_i^{-1}(\bm{y}_i-\bm{X}_i\bm{\beta})\right\}\\
		&\times \exp\left\{-\frac{1}{2}(\bm{\beta}-\bm{\beta}_0)^{\top}\bm{B}_0^{-1}(\bm{\beta}-\bm{\beta}_0)\right\}\\
		& \propto \exp\left\{-\frac{1}{2}\left(-2\bm{\beta}^{\top}\left(\sum_{i=1}^N\bm{X}_i^{\top}\bm{V}_i^{-1}\bm{y}_i+\bm{B}_0^{-1}\bm{\beta}_0\right)+\bm{\beta}^{\top}\left(\sum_{i=1}^N\bm{X}_i^{\top}\bm{V}_i^{-1}\bm{X}_i+\bm{B}_0^{-1}\right)\bm{\beta}\right)\right\}\\
		& = \exp\left\{-\frac{1}{2}(-2\bm{\beta}^{\top}\bm{B}_n^{-1}\bm{B}_n\left(\sum_{i=1}^N\bm{X}_i^{\top}\bm{V}_i^{-1}\bm{y}_i+\bm{B}_0^{-1}\bm{\beta}_0\right)+\bm{\beta}^{\top}\bm{B}_n^{-1}\bm{\beta})\right\}\\
		& = \exp\left\{-\frac{1}{2}(-2\bm{\beta}^{\top}\bm{B}_n^{-1}\bm{\beta}_n+\bm{\beta}^{\top}\bm{B}_n^{-1}\bm{\beta})\right\}. 
	\end{align*} 
}

We can complete the square in this expression by adding and subtracting $\bm{\beta}_n^{\top}\bm{B}_n^{-1}\bm{\beta}_n$. Thus,

	\begin{align*}
	\pi(\bm{\beta}|\sigma^2, \bm{D},\bm{y},\bm{X},\bm{W}) & \propto \exp\left\{-\frac{1}{2}(-2\bm{\beta}^{\top}\bm{B}_n^{-1}\bm{\beta}_n+\bm{\beta}^{\top}\bm{B}_n^{-1}\bm{\beta}+\bm{\beta}_n^{\top}\bm{B}_n^{-1}\bm{\beta}_n-\bm{\beta}_n^{\top}\bm{B}_n^{-1}\bm{\beta}_n)\right\}\\
	&\propto \exp\left\{-\frac{1}{2}(\bm{\beta}-\bm{\beta}_n)^{\top}\bm{B}_n^{-1}(\bm{\beta}-\bm{\beta}_n)\right\}.
\end{align*} 
This is the kernel of a multivariate random variable with mean $\bm{\beta}_n$ and variance matrix $\bm{B}_n$.
	
	\item \textbf{The relation between productivity and public investment example continues}

\begin{itemize}
	\item Perform inference of this example using our GUI.
	\item Program from scratch a Gibbs sampling algorithm to perform this application.
	\item Perform inference in this example assuming that $\mu_{it}|\tau_{it}\sim N(0, \sigma^2/\tau_{it})$ and $\tau_{it}\sim G(v/2,v/2)$ setting $v=5$ 
\end{itemize}

\textbf{Answer}
\begin{tcolorbox}[enhanced,width=4.67in,center upper,
	fontupper=\large\bfseries,drop shadow southwest,sharp corners]
	\textit{R code. The relationship between productivity and public investment, programming from scratch the Gibbs sampler}
	\begin{VF}
		\begin{lstlisting}[language=R]
rm(list = ls())
set.seed(12345)
DataGSP <- read.csv("DataApplications/8PublicCap.csv", sep = ",", header = TRUE, fileEncoding = "latin1")
attach(DataGSP)
K1 <- 5; K2 <- 1
N <- length(unique(id))
y <- log(gsp)
X <- cbind(1, log(pcap), log(pc), log(emp), unemp)
W <- 1
WtW <- t(W)%*%W
table(id)
T <- 17
it <- rep(1, T)
# Hyperparameters
b0 <- rep(0, K1); B0 <- diag(K1); B0i <- solve(B0)
r0 <- 5; R0 <- diag(K2)
a0 <- 0.001; d0 <- 0.001
# MCMC parameters
mcmc <- 10000
burnin <- 5000
tot <- mcmc + burnin
thin <- 1
# Gibbs functions
PostBeta <- function(sig2, D){
	Vi <- sig2*diag(T) + as.numeric(D)*it%*%t(it)
	ViInv <- solve(Vi)
	XVX <- matrix(0, K1, K1)
	XVy <- matrix(0, K1, 1)
	for(i in 1:N){
		ids <- which(id == i)
		Xi <- X[ids, ]
		XVXi <- t(Xi)%*%ViInv%*%Xi
		XVX <- XVX + XVXi
		yi <- y[ids]
		XVyi <- t(Xi)%*%ViInv%*%yi
		XVy <- XVy + XVyi
	}
	Bn <- solve(B0i + XVX)
	bn <- Bn%*%(B0i%*%b0 + XVy)
	Beta <- MASS::mvrnorm(1, bn, Bn)
	return(Beta)
}\end{lstlisting}
	\end{VF}
\end{tcolorbox}


\begin{tcolorbox}[enhanced,width=4.67in,center upper,
	fontupper=\large\bfseries,drop shadow southwest,sharp corners]
	\textit{R code. The relationship between productivity and public investment, programming from scratch the Gibbs sampler}
	\begin{VF}
		\begin{lstlisting}[language=R]
Postb <- function(Beta, sig2, D){
	Di <- solve(D)
	Bni <- solve(sig2^(-1)*WtW + Di)
	bis <- NULL
	for(i in 1:N){
		ids <- which(id == i)
		Xi <- X[ids, ]
		yi <- y[ids]
		Wi <- it
		Wtei <- sig2^(-1)*t(Wi)%*%(yi - Xi%*%Beta)
		bni <- Bni%*%Wtei
		bi <- MASS::mvrnorm(1, bni, Bni)
		bis <- c(bis, bi)
	}
	return(bis)
}
PostSig2 <- function(Beta, D, bs){
	an <- a0 + 0.5*N*T
	ete <- 0
	for(i in 1:N){
		ids <- which(id == i)
		Xi <- X[ids, ]
		yi <- y[ids]
		Wi <- it
		ei <- yi - Xi%*%Beta - bs[i]*Wi
		etei <- t(ei)%*%ei
		ete <- ete + etei
	}
	dn <- 1/d0 + 0.5*ete 
	sig2 <- invgamma::rinvgamma(1, shape = an, scale = dn)
	return(sig2)
}
PostD <- function(bs){
	rn <- r0 + N
	btb <- 0
	for(i in 1:N){
		bsi <- bs[i]
		btbi <- bsi%*%t(bsi)
		btb <- btb + btbi
	}
	Rn <- R0 + btb
	Sigma <- LaplacesDemon::rinvwishart(nu = rn, S = Rn)
	return(Sigma)
}\end{lstlisting}
	\end{VF}
\end{tcolorbox}

\begin{tcolorbox}[enhanced,width=4.67in,center upper,
	fontupper=\large\bfseries,drop shadow southwest,sharp corners]
	\textit{R code. The relationship between productivity and public investment, programming from scratch the Gibbs sampler}
	\begin{VF}
		\begin{lstlisting}[language=R]
PostBetas <- matrix(0, tot, K1)
PostDs <- matrix(0, tot, K2*(K2+1)/2)
PostSig2s <- rep(0, tot)
Postbs <- matrix(0, tot, N)
Beta <- rep(1, K1)
D <- diag(K2)
RegLS <- lm(log(gsp)~log(pcap)+log(pc)+log(emp)+unemp)
SumLS <- summary(RegLS)
sig2 <- SumLS[["sigma"]]^0.5
pb <- winProgressBar(title = "progress bar", min = 0, max = tot, width = 300)
for(s in 1:tot){
	bs <- Postb(Beta = Beta, sig2 = sig2, D = D)
	D <- PostD(bs = bs)
	Beta <- PostBeta(sig2 = sig2, D = D)
	sig2 <- PostSig2(Beta = Beta, bs = bs, D = D)
	PostBetas[s,] <- Beta
	PostDs[s,] <- matrixcalc::vech(D)
	PostSig2s[s] <- sig2
	Postbs[s,] <- bs
	setWinProgressBar(pb, s, title=paste( round(s/tot*100, 0),"% done"))
}
close(pb)
keep <- seq((burnin+1), tot, thin)
Bs <- PostBetas[keep,]
Ds <- PostDs[keep,]
bs <- Postbs[keep,]
sig2s <- PostSig2s[keep]
summary(coda::mcmc(Bs))
summary(coda::mcmc(Ds))
summary(coda::mcmc(bs))
summary(coda::mcmc(sig2s))
summary(coda::mcmc(Ds^0.5/(sig2s+Ds)^0.5))
# Convergence diagnostics
coda::geweke.diag(Bs)
coda::raftery.diag(Bs,q=0.5,r=0.05,s = 0.95)
coda::heidel.diag(Bs)\end{lstlisting}
	\end{VF}
\end{tcolorbox}


\item Given the simulation setting of Section 9.1 in the book, assume that $\bm{b}_i$ dependents on $\bm{z}_i=[1 \ x_{it1} \ x_{it2}]^{\top}$ such that $\bm{b}_i\sim N(\bm{Z}_i\bm{\gamma},\bm{D})$ where $\bm{Z}_i=\bm{I}_{K_2}\otimes \bm{z}_i^{\top}$ and $\bm{\gamma}\sim N(\bm{0}_3,\bm{I}_3)$. Write a code to perform inference in this setting, and compare the posterior estimates with the population parameters.

\end{enumerate}